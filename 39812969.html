<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711357261539" as="style"/><link rel="stylesheet" href="styles.css?v=1711357261539"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://notgull.net/why-not-threads/">Why choose async/await over threads?</a> <span class="domain">(<a href="https://notgull.net">notgull.net</a>)</span></div><div class="subtext"><span>thunderbong</span> | <span>99 comments</span></div><br/><div><div id="39813135" class="c"><input type="checkbox" id="c-39813135" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813525">next</a><span>|</span><label class="collapse" for="c-39813135">[-]</label><label class="expand" for="c-39813135">[20 more]</label></div><br/><div class="children"><div class="content">I think a better question is &quot;why choose async&#x2F;await over fibers?&quot;. Yes, I know that Rust had green threads in the pre-1.0 days and it was intentionally removed, but there are different approaches for implementing fiber-based concurrency, including those which do not require a fat runtime built-in into the language.<p>If I understand the article correctly, it mostly lauds the ability to drop futures at any moment. Yes, you can not do a similar thing with threads for obvious reasons (well, technically, you can, but it&#x27;s extremely unsafe). But this ability comes at a HUGE cost. Not only you can not use stack-based arrays with completion-based executors like io-uring and execute sub-tasks on different executor threads, but it also introduces certain subtle footguns and reliability issues (e.g. see [0]), which become very unpleasant surprises after writing sync Rust.<p>My opinion is that cancellation of tasks fundamentally should be cooperative and uncooperative cancellation is more of a misfeature, which is convenient at the surface level, but has deep issues underneath.<p>Also, praising composability of async&#x2F;await sounds... strange. Its viral nature makes it anything but composable (with the current version of Rust without a proper effect system). For example, try to use async closure with map methods from std. What about using the standard io::Read&#x2F;Write traits?<p>[0]: <a href="https:&#x2F;&#x2F;smallcultfollowing.com&#x2F;babysteps&#x2F;blog&#x2F;2022&#x2F;06&#x2F;13&#x2F;async-cancellation-a-case-study-of-pub-sub-in-mini-redis&#x2F;" rel="nofollow">https:&#x2F;&#x2F;smallcultfollowing.com&#x2F;babysteps&#x2F;blog&#x2F;2022&#x2F;06&#x2F;13&#x2F;asy...</a></div><br/><div id="39813609" class="c"><input type="checkbox" id="c-39813609" checked=""/><div class="controls bullet"><span class="by">dwaite</span><span>|</span><a href="#39813135">parent</a><span>|</span><a href="#39813259">next</a><span>|</span><label class="collapse" for="c-39813609">[-]</label><label class="expand" for="c-39813609">[3 more]</label></div><br/><div class="children"><div class="content">For rust, fibers (as a user-space, cooperative concurrency abstraction) would mandate a lot of design choices, such as whether stacks should be implemented using spaghetti stacks or require some sort of process-level memory mapping library, or even if they were just limited to a fixed size stack.<p>All three of these approaches would cause issues when interacting with code in another language with a different ABI. It can get really complicated, for example, when C code gets called from one fiber and wants to then resume another.<p>One of the benefits of async&#x2F;await is the &#x27;await&#x27; keyword itself. The explicit wait-points give you the ability to actually reason about the interactions of a concurrent program.<p>Yielding fibers are a bit like the &#x27;goto&#x27; of the concurrency world - whenever you call a method, you don&#x27;t know if as a side effect it may cause your processing to pause, and if when it continues the state of the world has changed. The need to be defensive when interfacing with the outside world means fibers tend to be better for tasks which run in isolation and communicate by completion.<p>Green threads, fibers and coroutines all share the same set of problems here, but really user space cooperative concurrency is just shuffling papers on a desk in terms of solving the hard parts of concurrency. Rust async&#x2F;await leaves things more explicit, but as a result doesn&#x27;t hide certain side effects other mechanisms do.</div><br/><div id="39813716" class="c"><input type="checkbox" id="c-39813716" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813609">parent</a><span>|</span><a href="#39813259">next</a><span>|</span><label class="collapse" for="c-39813716">[-]</label><label class="expand" for="c-39813716">[2 more]</label></div><br/><div class="children"><div class="content">In my opinion, by default fibers should use &quot;full&quot; stacks, i.e. a reasonable amount of unpopulated memory pages (e.g. 2 MiB) with guard page. Effectively, the same stack which we use for threads. It should eliminate all issues about interfacing with external code. But it obviously has performance implications, especially for very small tasks.<p>Further, on top of this we can then develop spawning tasks which would use parent&#x27;s stack. It would require certain language development to allow computing maximum stack usage bound of functions. Obviously, such computation would mean that programmers have to take additional restrictions on their code (such as disallowing recursion, alloca, and calling external functions without attributing stack usage), but compilers already routinely compute stack usage of functions, so for pure Rust code it should be doable.<p>&gt;It can get really complicated, for example, when C code gets called from one fiber and wants to then resume another.<p>It&#x27;s a weird example. How would a C library know about fiber runtime used in Rust?<p>&gt;Yielding fibers are a bit like the &#x27;goto&#x27; of the concurrency world - whenever you call a method, you don&#x27;t know if as a side effect it may cause your processing to pause, and if when it continues the state of the world has changed.<p>I find this argument funny. Why don&#x27;t you have the same issue with preemptive multitasking? We live with exactly this &quot;issue&quot; in the threading world just fine. Even worse, we can not even rely on &quot;critical sections&quot;, thread&#x27;s execution can be preempted at ANY moment.<p>As for `await` keyword, in almost all cases I find it nothing more than a visual noise. It does not provide any practically useful information for programmer. How often did you wonder when writing threading-based code about whether function does any IO or not?</div><br/><div id="39814004" class="c"><input type="checkbox" id="c-39814004" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813716">parent</a><span>|</span><a href="#39813259">next</a><span>|</span><label class="collapse" for="c-39814004">[-]</label><label class="expand" for="c-39814004">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It’s a weird example. How would a C library know about the fiber runtime used in Rust.<p>Well, if you green thread were launched on an arbitrary free OS thread (work stealing), then for example your TLS variables would be very wrong when you resume execution. Does it break all FFI? No. But it can cause issues for some FFI in a way that async&#x2F;await cannot.<p>&gt; I find this argument funny. Why don&#x27;t you have the same issue with preemptive multitasking? We live with exactly this &quot;issue&quot; in the threading world just fine. Even worse, we can not even rely on &quot;critical sections&quot;, thread&#x27;s execution can be preempted at ANY moment.<p>It’s not about critical sections as much. Since the author referenced go to, I think the point is that it gets harder to reason about control flow within your own code. Whether or not that’s true is debatable since there’s not really any implementation of green threads for Rust. It does seem to work well enough for Go but it has a required dedicated keyword to create that green thread to ease readability.<p>&gt; As for `await` keyword, in almost all cases I find it nothing more than a visual noise. It does not provide any practically useful information for programmer. How often did you wonder when writing threading-based code about whether function does any IO or not?<p>Agree to disagree. It provides very clear demarcation of which lines are possible suspension points which is important when trying to figure out where “non interruptible” operations need to be written for things to work as intended.</div><br/></div></div></div></div></div></div><div id="39813259" class="c"><input type="checkbox" id="c-39813259" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39813135">parent</a><span>|</span><a href="#39813609">prev</a><span>|</span><a href="#39813276">next</a><span>|</span><label class="collapse" for="c-39813259">[-]</label><label class="expand" for="c-39813259">[5 more]</label></div><br/><div class="children"><div class="content">How do fibers solve your cancellation problem? Aren&#x27;t they more or less equivalent?<p>(I find fiber-based code hard to follow because you&#x27;re effectively forced to reason operationally. Keeping track of in-progress threads in your head is much harder than keeping track of to-be-completed values, at least for me)</div><br/><div id="39813338" class="c"><input type="checkbox" id="c-39813338" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813259">parent</a><span>|</span><a href="#39813337">next</a><span>|</span><label class="collapse" for="c-39813338">[-]</label><label class="expand" for="c-39813338">[3 more]</label></div><br/><div class="children"><div class="content">With fibers you send cancellation signal to a task, then on next IO operation (or more generally yield) it will get cancellation error code with ability to get true result of IO operation, if there is any. Note that it does not mean that the task will sleep until the IO operation gets completed, cancellation signal causes any ongoing IO to &quot;complete&quot; immediately if it&#x27;s possible (e.g. IIRC disk IO can not be cancelled).<p>It then becomes responsibility of the task to handle this signal. It may either finish immediately (e.g. by bubbling the &quot;cancellation&quot; error), finish some critical section before that and do some cleanup IO, or it may even outright ignore the signal.<p>With futures you just drop the task&#x27;s future (i.e. its persistent stack) maybe with some synchronous cleanup and that&#x27;s it, you don&#x27;t give the task a chance to say a word in its cancellation. Hypothetical async Drop could help here (though you would have to rely on async drop guards extensively instead of processing &quot;cancellation errors&quot;), but adding it to Rust is far from easy and AFAIK there are certain fundamental issues with it.<p>With io-uring sending cancellation signals is quite straightforward (though you need to account for different possibilities, such as task being currently executed on a separate executor thread, or its CQE being already in completion queue), but with epoll, unfortunately, it&#x27;s... less pleasant.</div><br/><div id="39813427" class="c"><input type="checkbox" id="c-39813427" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813338">parent</a><span>|</span><a href="#39813337">next</a><span>|</span><label class="collapse" for="c-39813427">[-]</label><label class="expand" for="c-39813427">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Hypothetical async Drop could help here (though you would have to rely on async drop guards extensively instead of processing &quot;cancellation errors&quot;), but adding it to Rust is far from easy and AFAIK there are certain fundamental issues with it.<p>Wouldn&#x27;t fiber cancellation be equivalent and have equivalent implementation difficulties? You say you just send a signal to the task, but in practice picking up and running the task to trigger its cancellation error handling is going to look the same as running a future&#x27;s async drop, isn&#x27;t it?</div><br/><div id="39813466" class="c"><input type="checkbox" id="c-39813466" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813427">parent</a><span>|</span><a href="#39813337">next</a><span>|</span><label class="collapse" for="c-39813466">[-]</label><label class="expand" for="c-39813466">[1 more]</label></div><br/><div class="children"><div class="content">Firstly, Rust does not have async Drop and it&#x27;s unlikely to be added in the foreseeable future. Secondly, cancellation signals is a more general technique than async Drop, i.e. you can implement the latter on top of the former, but not the other way around. For example, with async Drop you can not ignore cancellation event (unless you copy code of your whole task into Drop impl). Some may say that it&#x27;s a good thing, but it&#x27;s just an obvious example of cancellation signals being more powerful than hypothetical async Drop.<p>As for implementation difficulties, I don&#x27;t think so. For async Drop you need to mess with some fundamental parts of the Rust language (since Futures are &quot;just types&quot;), while fiber-based concurrency, in a certain sense, is transparent for compiler and implementation complexity is moved to executors.<p>If you are asking about how it would look in user code, then, yes, they would be somewhat similar. With cancellation signals you would call something like `let res = task_handle.cancell_join();`, while with async Drop you would use `drop(task_future)`. Note that the former also allows to get result from a cancelled task, another example of greater flexibility.</div><br/></div></div></div></div></div></div><div id="39813337" class="c"><input type="checkbox" id="c-39813337" checked=""/><div class="controls bullet"><span class="by">bheadmaster</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813259">parent</a><span>|</span><a href="#39813338">prev</a><span>|</span><a href="#39813276">next</a><span>|</span><label class="collapse" for="c-39813337">[-]</label><label class="expand" for="c-39813337">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Keeping track of in-progress threads in your head is much harder than keeping track of to-be-completed values, at least for me<p>I think that&#x27;s true for everybody. Our minds barely handle state for sequential code - the explosion of complexity of multiple state-modifying threads is almost impossible to follow.<p>There are ways to convert &quot;keeping track of in-progress threads&quot; to &quot;keeping track or to-be-completed&quot; values - in particular, Go uses channels as a communication mechanism which explicitly does the latter, while abstracting away the former.</div><br/></div></div></div></div><div id="39813276" class="c"><input type="checkbox" id="c-39813276" checked=""/><div class="controls bullet"><span class="by">lloeki</span><span>|</span><a href="#39813135">parent</a><span>|</span><a href="#39813259">prev</a><span>|</span><a href="#39813740">next</a><span>|</span><label class="collapse" for="c-39813276">[-]</label><label class="expand" for="c-39813276">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I think a better question is &quot;why choose async&#x2F;await over fibers?<p>&gt; there are different approaches for implementing fiber-based concurrency, including those which do not require a fat runtime built-in into the language<p>This keynote below is Ruby so the thread&#x2F;GVL situation is different than for Rust, but is that the kind of thing you mean?<p><a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=qKQcUDEo-ZI" rel="nofollow">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=qKQcUDEo-ZI</a><p>I think it makes a good case that async&#x2F;await is infectious and awkward, and fibers (at least as implemented in Ruby) is quite simply a better paradigm.</div><br/><div id="39813761" class="c"><input type="checkbox" id="c-39813761" checked=""/><div class="controls bullet"><span class="by">dwaite</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813276">parent</a><span>|</span><a href="#39813299">next</a><span>|</span><label class="collapse" for="c-39813761">[-]</label><label class="expand" for="c-39813761">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think it makes a good case that async&#x2F;await is infectious and awkward, and fibers (at least as implemented in Ruby) is quite simply a better paradigm.<p>As someone who has done fibers development in Ruby, I disagree.<p>CRuby has the disadvantage of a global interpreter lock. This means that parallelism can only be achieved via multiple processes. This is not the case in Rust, where have access to do true parallelism in a single process.<p>Second, this talk is not arguing for use of fibers as much as it is arguing as using fibers to rig up a bespoke green threads-like system for a specific web application server, and advocating for ruby runtime features to make the code burden on them of doing this lighter.<p>Ruby has a global interpreter lock, so even though it uses native threads only one of them can be executing ruby code at a time. Fibers have native stacks, so they have all the resource requirements of a thread sans context switching - but the limitations from the GIL actually mean you aren&#x27;t _saving_ context switching by structuring your code to use fibers in typical (non &quot;hello world&quot; web server) usage.</div><br/></div></div><div id="39813299" class="c"><input type="checkbox" id="c-39813299" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813276">parent</a><span>|</span><a href="#39813761">prev</a><span>|</span><a href="#39813740">next</a><span>|</span><label class="collapse" for="c-39813299">[-]</label><label class="expand" for="c-39813299">[1 more]</label></div><br/><div class="children"><div class="content">I only scrolled the video, but it sounds similar, yes. Though, implementation details would probably vary significantly, since Rust is a lower-level language.</div><br/></div></div></div></div><div id="39813740" class="c"><input type="checkbox" id="c-39813740" checked=""/><div class="controls bullet"><span class="by">ngrilly</span><span>|</span><a href="#39813135">parent</a><span>|</span><a href="#39813276">prev</a><span>|</span><a href="#39813564">next</a><span>|</span><label class="collapse" for="c-39813740">[-]</label><label class="expand" for="c-39813740">[2 more]</label></div><br/><div class="children"><div class="content">Could you share an example of a fiber implementation not relying a fat runtime built in the language?</div><br/><div id="39813787" class="c"><input type="checkbox" id="c-39813787" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813740">parent</a><span>|</span><a href="#39813564">next</a><span>|</span><label class="collapse" for="c-39813787">[-]</label><label class="expand" for="c-39813787">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;Xudong-Huang&#x2F;may">https:&#x2F;&#x2F;github.com&#x2F;Xudong-Huang&#x2F;may</a><p>The project has some serious restrictions and unsound footguns (e.g. around TLS), but otherwise it&#x27;s usable enough. There are also a number of C&#x2F;C++ libraries, but I can not comment on those.</div><br/></div></div></div></div><div id="39813564" class="c"><input type="checkbox" id="c-39813564" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39813135">parent</a><span>|</span><a href="#39813740">prev</a><span>|</span><a href="#39813525">next</a><span>|</span><label class="collapse" for="c-39813564">[-]</label><label class="expand" for="c-39813564">[6 more]</label></div><br/><div class="children"><div class="content">The sole advantage of async&#x2F;await over fibers is the possibility to achieve ultra-low-latency via the compiler converting the async&#x2F;await into a state machine. This is important for Rust as a systems language, but if you don&#x27;t need ultra-low-latency then something with a CSP model built on fibers, like Goroutines or the new Java coroutines, is much easier to reason about.</div><br/><div id="39813594" class="c"><input type="checkbox" id="c-39813594" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813564">parent</a><span>|</span><a href="#39813525">next</a><span>|</span><label class="collapse" for="c-39813594">[-]</label><label class="expand" for="c-39813594">[5 more]</label></div><br/><div class="children"><div class="content">Fibers and async&#x2F;await are backed by the same OS APIs, they can achieve more or less the same latency. The main advantage of async&#x2F;await (or to be more precise stackless coroutines) is that they require less memory for task stacks since tasks can reuse executor&#x27;s stack for non-persistent part of their stack (i.e. stack variables which do not cross yield points). It has very little to do with latency. At most you can argue that executor&#x27;s stack stays in CPU cache, which reduces amount of cache misses a bit.<p>Stackless coroutines also make it easier to use parent&#x27;s stack for its children stacks. But IMO it&#x27;s only because compilers currently do not have tools to communicate maximum stack usage bound of functions to programming languages.</div><br/><div id="39813988" class="c"><input type="checkbox" id="c-39813988" checked=""/><div class="controls bullet"><span class="by">nominatronic</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813594">parent</a><span>|</span><a href="#39813908">next</a><span>|</span><label class="collapse" for="c-39813988">[-]</label><label class="expand" for="c-39813988">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Fibers and async&#x2F;await are backed by the same OS APIs<p>async&#x2F;await doesn&#x27;t require any OS APIs, or even an OS at all.<p>You can write async rust that runs on a microcontroller and poll a future directly from an interrupt handler.<p>And there&#x27;s a huge advantage to doing so, too: you can write out sequences of operations in a straightforward procedural form, and let the compiler do the work of turning that into a state machine with a minimal state representation, rather than doing that manually.</div><br/><div id="39814014" class="c"><input type="checkbox" id="c-39814014" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813988">parent</a><span>|</span><a href="#39813908">next</a><span>|</span><label class="collapse" for="c-39814014">[-]</label><label class="expand" for="c-39814014">[1 more]</label></div><br/><div class="children"><div class="content">Sigh... It gets tiring to hear about embedded from async&#x2F;await advocates as if it&#x27;s a unique advantage. Fibers and similar mechanisms are used routinely in embedded world as demonstrated by various RTOS systems.</div><br/></div></div></div></div><div id="39813908" class="c"><input type="checkbox" id="c-39813908" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813594">parent</a><span>|</span><a href="#39813988">prev</a><span>|</span><a href="#39813525">next</a><span>|</span><label class="collapse" for="c-39813908">[-]</label><label class="expand" for="c-39813908">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Fibers and async&#x2F;await are backed by the same OS APIs, they can achieve more or less the same latency.<p>The key requirement for ultra-low-latency software is minimising&#x2F;eliminating dynamic memory allocation, and stackless coroutines allow avoiding memory allocation. For managed coroutines on the other hand (e.g. goroutines, Java coroutines) as far as I&#x27;m aware it&#x27;s impossible to have an implementation that doesn&#x27;t do any dynamic memory allocation, or at least there aren&#x27;t any such implementations in practice.</div><br/><div id="39813958" class="c"><input type="checkbox" id="c-39813958" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#39813135">root</a><span>|</span><a href="#39813908">parent</a><span>|</span><a href="#39813525">next</a><span>|</span><label class="collapse" for="c-39813958">[-]</label><label class="expand" for="c-39813958">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s what I wrote about in the last paragraph. If you can compute maximum stack size of a function, then you can avoid dynamic allocation with fibers as well (you also could provide stack size manually, but it would break horribly if the provided number is wrong). You are right that such implementations do not exist right now, but I think it&#x27;s technically feasible, as demonstrated by tools such as <a href="https:&#x2F;&#x2F;github.com&#x2F;japaric&#x2F;cargo-call-stack">https:&#x2F;&#x2F;github.com&#x2F;japaric&#x2F;cargo-call-stack</a> The main stumbling block here is FFI, historically shared libraries do not have any annotations about stack usage, so functions with bounded stack usage would not be able to use even libc.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39813525" class="c"><input type="checkbox" id="c-39813525" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#39813135">prev</a><span>|</span><a href="#39813532">next</a><span>|</span><label class="collapse" for="c-39813525">[-]</label><label class="expand" for="c-39813525">[4 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await with one thread is simple and well-understood. That&#x27;s the Javascript model. Threads let you get all those CPUs working on the problem, and Rust helps you manage the locking. Plus, you can have threads at different priorities, which may be necessary if you&#x27;re compute-bound.<p>Multi-threaded async&#x2F;await gets ugly. If you have serious compute-bound sections, the model tends to break down, because you&#x27;re effectively blocking a thread that you share with others.<p>Compute-bound multi-threaded does not work as well in Rust as it should. Problems include:<p>- Futex congestion collapse. This tends to be a problem with some storage allocators. Many threads are hitting the same locks. In particular, growing a buffer can get very expensive in allocators where the recopying takes place with the entire storage allocator locked.
I&#x27;ve mentioned before that Wine&#x27;s library allocator, in a .DLL that&#x27;s emulating a Microsoft library, is badly prone to this problem. Performance drops by two orders of magnitude with all the CPU time going into spinlocks. Microsoft&#x27;s own implementation does not have this problem.<p>- Starvation of unfair mutexes. Both the standard Mutex and crossbeam-channel channels are unfair. If you have multiple threads locking a resource, doing something, unlocking the resource, and repeating that cycle, one thread will win repeatedly and the others will get locked out.[1]
If you need fair mutexes, there&#x27;s &quot;parking-lot&quot;. But you don&#x27;t get the poisoning safety on thread panic that the standard mutexes give you.<p>If you&#x27;re not I&#x2F;O bound, this gets much more complicated.<p>[1] <a href="https:&#x2F;&#x2F;users.rust-lang.org&#x2F;t&#x2F;mutex-starvation&#x2F;89080" rel="nofollow">https:&#x2F;&#x2F;users.rust-lang.org&#x2F;t&#x2F;mutex-starvation&#x2F;89080</a></div><br/><div id="39813744" class="c"><input type="checkbox" id="c-39813744" checked=""/><div class="controls bullet"><span class="by">jmspring</span><span>|</span><a href="#39813525">parent</a><span>|</span><a href="#39813603">next</a><span>|</span><label class="collapse" for="c-39813744">[-]</label><label class="expand" for="c-39813744">[1 more]</label></div><br/><div class="children"><div class="content">You focus on rust rather than generalizing...<p>If you are IO bound, consider threads.  This is almost the same as async &#x2F; await.<p>What was missing above, and the problem with how most compute education is these days, if you are compute bound you need to think about processes.<p>If you were dealing with python concurrent.futures, you would need to consider processpooexecutor vs. threadpoolexecutor.<p>Threadpoolexecutor gives you the same as the above.<p>With multiprocessor executor, you will have multiple processes executing independently but you have to copy a memory space.  Which people don&#x27;t consider. In python DS work - multiprocessor workloads need to determine memory space considerations.<p>It&#x27;s kinda f&#x27;d up how JS doesn&#x27;t have engineers think about their workloads.</div><br/></div></div><div id="39813603" class="c"><input type="checkbox" id="c-39813603" checked=""/><div class="controls bullet"><span class="by">exfalso</span><span>|</span><a href="#39813525">parent</a><span>|</span><a href="#39813744">prev</a><span>|</span><a href="#39813726">next</a><span>|</span><label class="collapse" for="c-39813603">[-]</label><label class="expand" for="c-39813603">[1 more]</label></div><br/><div class="children"><div class="content">Yes, 100%.<p>I&#x27;ve <i>mostly</i> only dealt with IO-bound computations, but the contention issues arise there as well. What&#x27;s the point of having a million coroutines when the IO throughput is bounded again? How will coroutines save me when I immediately exhaust my size 10 DB connection pool? It won&#x27;t, it just makes debugging and working around the issues harder and difficult to reason about.</div><br/></div></div><div id="39813726" class="c"><input type="checkbox" id="c-39813726" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#39813525">parent</a><span>|</span><a href="#39813603">prev</a><span>|</span><a href="#39813532">next</a><span>|</span><label class="collapse" for="c-39813726">[-]</label><label class="expand" for="c-39813726">[1 more]</label></div><br/><div class="children"><div class="content">Jemalloc can use separate arenas for different threads which I imagine mostly solves the futex congestion issue. Perhaps it introduces new ones?</div><br/></div></div></div></div><div id="39813532" class="c"><input type="checkbox" id="c-39813532" checked=""/><div class="controls bullet"><span class="by">exfalso</span><span>|</span><a href="#39813525">prev</a><span>|</span><a href="#39813841">next</a><span>|</span><label class="collapse" for="c-39813532">[-]</label><label class="expand" for="c-39813532">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting to see an almost marketing-like campaign to save face for async&#x2F;await. It is very clear from my experience that it was not only a technical mistake, it also cost the community dearly. Instead of focusing on language features that are <i>actually</i> useful, the Rust effort has been sidetracked by this mess. I&#x27;m still very hopeful for the language though, and it is the best thing we&#x27;ve got at the moment. I&#x27;m just worried that this whole fight will drag on forever.
P.S the AsyncWrite&#x2F;AsyncRead example looks reasonable, but in fact you can do the same thing with threads&#x2F;fds as long as you restrict yourself to *nix.</div><br/><div id="39814003" class="c"><input type="checkbox" id="c-39814003" checked=""/><div class="controls bullet"><span class="by">junon</span><span>|</span><a href="#39813532">parent</a><span>|</span><a href="#39813781">next</a><span>|</span><label class="collapse" for="c-39814003">[-]</label><label class="expand" for="c-39814003">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used async in firmware before. It was a lifesaver. The generalizations you make are unfounded and are clearly biased toward a certain workload.</div><br/></div></div><div id="39813781" class="c"><input type="checkbox" id="c-39813781" checked=""/><div class="controls bullet"><span class="by">ykonstant</span><span>|</span><a href="#39813532">parent</a><span>|</span><a href="#39814003">prev</a><span>|</span><a href="#39813646">next</a><span>|</span><label class="collapse" for="c-39813781">[-]</label><label class="expand" for="c-39813781">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Instead of focusing on language features that are actually useful, the Rust effort has been sidetracked by this mess.<p>I don&#x27;t know if you are correct or not (I am not very familiar with Rust) but empirically 9&#x2F;10 Rust discussions I see nowadays on HN&#x2F;reddit do revolve around async.  It kinda sucks for me because I don&#x27;t care about async at all, and I am interested in reading stuff about Rust.</div><br/></div></div><div id="39813646" class="c"><input type="checkbox" id="c-39813646" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39813532">parent</a><span>|</span><a href="#39813781">prev</a><span>|</span><a href="#39813841">next</a><span>|</span><label class="collapse" for="c-39813646">[-]</label><label class="expand" for="c-39813646">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a technical mistake, it&#x27;s a brilliant solution for when you need ultra-low-latency async code. The mistake is pushing it for the vast majority of use-cases where this isn&#x27;t needed.</div><br/></div></div></div></div><div id="39813841" class="c"><input type="checkbox" id="c-39813841" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#39813532">prev</a><span>|</span><a href="#39813147">next</a><span>|</span><label class="collapse" for="c-39813841">[-]</label><label class="expand" for="c-39813841">[4 more]</label></div><br/><div class="children"><div class="content">Issues with the article:<p>1. Only one example is given (web server), solved incorrectly for threads. I will elaborate below.<p>2. The question is framed as if people specifically want OS threads instead of async&#x2F;await .<p>But programmers want threads conceptually, semantically. Write sequential logic and don&#x27;t use strange annotations like &quot;async&quot;. In other words, if async&#x2F;await is so good, why not make all functions in the language implicitly async, and instead of &quot;await&quot; just write normal function calls? Then you will suddenly be programming in threads.<p>OS threads are expensive due to statically allocated stack, and we don&#x27;t want that. We want cheap threads, that can be run in millions on a single CPU. But without the clumsy &quot;async&#x2F;await&quot; words. (The `wait` word remains in it&#x27;s classic sense: when you wait for an event, for another thread to complete, etc - a blocking operation of waiting. But we don&#x27;t want it for function invocations).<p>Back to #1 - the web server example.<p>When timeout is implemented in async&#x2F;await variant of the solution, using the `driver.race(timeout).await`, what happens to the client socket after the `race` signals the timeout error? Does socket remain open, remains connected to  the client - essentially leaked?<p>The timeout solution for threaded version  may look almost the same, as it looks for async&#x2F;await: `threaded_race(client_thread, timeout).wait`. This threaded_race function uses a timer to track a timeout in parallel with the thread, and when the timeout is reached it calls `client_thread.interrupt()` - the Java way. (The `Thread.interrupt()`, if thread is not blocked, simply sets a flag; and if the thread is blocked in an IO call, this call throws an InterruptedException. That&#x27;s a checked exception, so compiler forces programmer to wrap the `client.read_to_end(&amp;mut data)` into try &#x2F; catch or declare the exception in the `handle_client`. So programmer will not forget to close the client socket).</div><br/><div id="39813891" class="c"><input type="checkbox" id="c-39813891" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#39813841">parent</a><span>|</span><a href="#39813872">next</a><span>|</span><label class="collapse" for="c-39813891">[-]</label><label class="expand" for="c-39813891">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also writing your code with <i>poll()</i> and <i>select()</i>, which is its own thing.</div><br/></div></div><div id="39813872" class="c"><input type="checkbox" id="c-39813872" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39813841">parent</a><span>|</span><a href="#39813891">prev</a><span>|</span><a href="#39813147">next</a><span>|</span><label class="collapse" for="c-39813872">[-]</label><label class="expand" for="c-39813872">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But programmers want threads conceptually, semantically. Write sequential logic and don&#x27;t use strange annotations like &quot;async&quot;. In other words, if async&#x2F;await is so good, why not make all functions in the language implicitly async, and in stead of &quot;await&quot; just use normal function calls? Then you will suddenly be programming in threads.<p>Some programmers do, but many want exactly the opposite as well. Most of the time I don&#x27;t care if it&#x27;s an OS blocking syscall or a non-blocking one, but I do care about understanding the control flow of the program I&#x27;m reading and see where there&#x27;s waiting time and how to make them run concurrently.<p>In fact, I&#x27;d kill to have a <i>blocking&#x2F;block</i> keyword pair whenever I&#x27;m working with blocking functions, because they can surreptitiously slow down everything without you paying attention (I can&#x27;t count how many pieces of software I&#x27;ve seen with blocking syscalls in the UI thread, leading to frustratingly slow apps!).</div><br/><div id="39813986" class="c"><input type="checkbox" id="c-39813986" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#39813841">root</a><span>|</span><a href="#39813872">parent</a><span>|</span><a href="#39813147">next</a><span>|</span><label class="collapse" for="c-39813986">[-]</label><label class="expand" for="c-39813986">[1 more]</label></div><br/><div class="children"><div class="content">But all functions are blocking.<p><pre><code>   fn foo() {bar(1, 2);}
   fn bar(a, b) {return a + b;}
</code></pre>
Here bar is a blocking function.</div><br/></div></div></div></div></div></div><div id="39813147" class="c"><input type="checkbox" id="c-39813147" checked=""/><div class="controls bullet"><span class="by">adontz</span><span>|</span><a href="#39813841">prev</a><span>|</span><a href="#39813206">next</a><span>|</span><label class="collapse" for="c-39813147">[-]</label><label class="expand" for="c-39813147">[21 more]</label></div><br/><div class="children"><div class="content">There are a lot of moments not covered. For example:<p>- async&#x2F;await runs in context of one thread, so there is no need for locks or synchronization. Unless one runs async&#x2F;await in multiple threads to actually utilize CPU cores, then locks and synchronization are necessary again. This complexity may be hidden in some external code. For example instead of synchronizing access to a single database connection it is much easier to open one database connection per async task. However such approach may affect performance, especially with sqlite and postgres.<p>- error propagation in async&#x2F;await is not obvious. Especially when one tries to group up async tasks. Happy eyeballs are a classic example.<p>- since network I&#x2F;O was mentioned, backpressure should also be mentioned. CPython implementation of async&#x2F;await notoriously lacks network backpressure causing some problems.</div><br/><div id="39814012" class="c"><input type="checkbox" id="c-39814012" checked=""/><div class="controls bullet"><span class="by">junon</span><span>|</span><a href="#39813147">parent</a><span>|</span><a href="#39813211">next</a><span>|</span><label class="collapse" for="c-39814012">[-]</label><label class="expand" for="c-39814012">[1 more]</label></div><br/><div class="children"><div class="content">&gt; async&#x2F;await runs in context of one thread,<p>Not in Rust.</div><br/></div></div><div id="39813211" class="c"><input type="checkbox" id="c-39813211" checked=""/><div class="controls bullet"><span class="by">graphenus</span><span>|</span><a href="#39813147">parent</a><span>|</span><a href="#39814012">prev</a><span>|</span><a href="#39813389">next</a><span>|</span><label class="collapse" for="c-39813211">[-]</label><label class="expand" for="c-39813211">[6 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await just like threads is a concurrency mechanism and also always requires locks when accessing the shared memory. Where does your statement come from?</div><br/><div id="39813342" class="c"><input type="checkbox" id="c-39813342" checked=""/><div class="controls bullet"><span class="by">conradludgate</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813211">parent</a><span>|</span><a href="#39813236">next</a><span>|</span><label class="collapse" for="c-39813342">[-]</label><label class="expand" for="c-39813342">[1 more]</label></div><br/><div class="children"><div class="content">If you perform single threaded async in Rust, you can drop down to the cheap single threaded RefCell rather than the expensive multithreaded Mutex&#x2F;RwLock</div><br/></div></div><div id="39813236" class="c"><input type="checkbox" id="c-39813236" checked=""/><div class="controls bullet"><span class="by">romanovcode</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813211">parent</a><span>|</span><a href="#39813342">prev</a><span>|</span><a href="#39813389">next</a><span>|</span><label class="collapse" for="c-39813236">[-]</label><label class="expand" for="c-39813236">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Where does your statement come from?<p>This is how async&#x2F;await works in Node (which is single-threaded) so most developers think this is how it works in every technology.</div><br/><div id="39813318" class="c"><input type="checkbox" id="c-39813318" checked=""/><div class="controls bullet"><span class="by">bheadmaster</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813236">parent</a><span>|</span><a href="#39813354">next</a><span>|</span><label class="collapse" for="c-39813318">[-]</label><label class="expand" for="c-39813318">[2 more]</label></div><br/><div class="children"><div class="content">Even in Node, if you perform asynchronous operations on a shared resource, you need synchronization mechanisms to prevent interleaving of async functions.<p>There has been more than one occasion when I &quot;fixed&quot; a system in NodeJS just by wrapping some complex async function up in a mutex.</div><br/><div id="39813551" class="c"><input type="checkbox" id="c-39813551" checked=""/><div class="controls bullet"><span class="by">nurple</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813318">parent</a><span>|</span><a href="#39813354">next</a><span>|</span><label class="collapse" for="c-39813551">[-]</label><label class="expand" for="c-39813551">[1 more]</label></div><br/><div class="children"><div class="content">This lacks quite a bit of nuance. In node you are guaranteed that synchronous code between two awaits will run to completion before another task(that could access your state) from the event loop gets a turn; with multi-threaded concurrency you could be preempted between any two machine instructions. So while you _do_ have to serialize access to shared IO resources, you do _not_ have to serialize access to memory(just add the connection to the hashset, no locks).<p>What you usually see with JS for concurrency of shared IO resources in practice is that they are &quot;owned&quot; by the closure of a flow of async execution and rarely available to other flows. This architecture often obviates the need to lock on the shared resource at all as the natural serialization orchestrated by the string of state machines already naturally accomplishes this. This pattern was even quite common in the CPS style before async&#x2F;await.<p>For example, one of the first things an app needs do before talking to a DB is to get a connection which is often retrieved by pulling from a pool; acquiring the reservation requires no lock, and by virtue of the connection being exclusively closed over in the async query code, it also needs no locking. When the query is done, the connection can be replaced to the pool sans locking.<p>The place where I found synchronization most useful was in acquiring resources that are unavailable. Interestingly, an async flow waiting on a signal for a shared resource resembles a channel in golang in how it shifts the state and execution to the other flow when a pooled resource is available.<p>All this to say, yeah I&#x27;m one of the huge fans of node that finds rust&#x27;s take on default concurrency painfully over complicated. I really wish there was an event-loop async&#x2F;await that was able to eschew most of the sync, send, lifetime insanity. While I am very comfortable with locks-required multithreaded concurrency as well, I honestly find little use for it and would much prefer to scale by process than thread to preserve the simplicity of single-threaded IO-bound concurrency.</div><br/></div></div></div></div></div></div></div></div><div id="39813389" class="c"><input type="checkbox" id="c-39813389" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#39813147">parent</a><span>|</span><a href="#39813211">prev</a><span>|</span><a href="#39813320">next</a><span>|</span><label class="collapse" for="c-39813389">[-]</label><label class="expand" for="c-39813389">[2 more]</label></div><br/><div class="children"><div class="content">async can be scarier for locks since a block of code might depend on having exclusive access, and since there wasn&#x27;t an await, it got it. Once you add an await in the middle, the code breaks. Threading at least makes you codify what actually needs exclusive access.<p>async also signs you up for managing your own thread scheduling. If you have a lot of IO and short CPU-bound code, this can be OK. If you have (or occasionally have) CPU-bound code, you&#x27;ll find yourself playing scheduler.</div><br/><div id="39813454" class="c"><input type="checkbox" id="c-39813454" checked=""/><div class="controls bullet"><span class="by">cageface</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813389">parent</a><span>|</span><a href="#39813320">next</a><span>|</span><label class="collapse" for="c-39813454">[-]</label><label class="expand" for="c-39813454">[1 more]</label></div><br/><div class="children"><div class="content">Yeah once your app gets to be sufficiently complex you will find yourself needing mutexes after all. Async&#x2F;await makes the easy parts of concurrency easy but the hard parts are still hard.</div><br/></div></div></div></div><div id="39813320" class="c"><input type="checkbox" id="c-39813320" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#39813147">parent</a><span>|</span><a href="#39813389">prev</a><span>|</span><a href="#39813206">next</a><span>|</span><label class="collapse" for="c-39813320">[-]</label><label class="expand" for="c-39813320">[11 more]</label></div><br/><div class="children"><div class="content">I have lots of issues with async&#x2F;await, but this is my primary beef with async&#x2F;await:<p>Remember the Gang of Four book &quot;Design Patterns&quot;?  It was basically a cookbook on how to work around the deficiencies of (mostly) C++.  Yet everybody applied those patterns inside languages that <i>didn&#x27;t have those deficiencies</i>.<p>Rust can run multiple threads <i>just fine</i>--it&#x27;s not Javascript.  As such, it didn&#x27;t <i>have</i> to use async&#x2F;await.  It could have tried any of a bunch of different solutions.  Rust is a systems language, after all.<p>However, async&#x2F;await was necessary in order to shove Rust down the throats of the Javascript programmers who didn&#x27;t know anything else.  Quoting without.boats:<p><a href="https:&#x2F;&#x2F;without.boats&#x2F;blog&#x2F;why-async-rust&#x2F;" rel="nofollow">https:&#x2F;&#x2F;without.boats&#x2F;blog&#x2F;why-async-rust&#x2F;</a><p>&gt; I drove at async&#x2F;await with the diligent fervor of the assumption that Rust’s survival depended on this feature.<p>Whether async&#x2F;await was even a good fit for Rust technically was of <i>no consequence</i>.  Javascript programmers were used to async&#x2F;await so Rust was <i>going</i> to have async&#x2F;await so Rust could be jammed down the throats of the Javascript network services programmers--technical consequences be damned.</div><br/><div id="39813657" class="c"><input type="checkbox" id="c-39813657" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813320">parent</a><span>|</span><a href="#39813572">next</a><span>|</span><label class="collapse" for="c-39813657">[-]</label><label class="expand" for="c-39813657">[1 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await was invented for C#, another multithreaded language. It was not designed to work around a lack of true parallelism. It is instead designed to make it easier to interact with async IO without having to resort to manually managed thread pools. It basically codifies at the language level a very common pattern for writing concurrent code.<p>It is true though that async&#x2F;await has a significant advantage compared to fibers that is related to single threaded code: it makes it very easy to add good concurrency support on a single thread, especially in languages which support both. In C#, it was particularly useful for executing concurrent operations from the single GUI thread of WPF or WinForms, or from parts of the app which interact with COM. This used the SingleThreadedExecutor, which schedules tasks on the current thread, so it&#x27;s safe to run GUI updates or COM interactions from a Task, while also using any other async&#x2F;await code, since tasks inherit their executor.</div><br/></div></div><div id="39813572" class="c"><input type="checkbox" id="c-39813572" checked=""/><div class="controls bullet"><span class="by">yxhuvud</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813320">parent</a><span>|</span><a href="#39813657">prev</a><span>|</span><a href="#39813370">next</a><span>|</span><label class="collapse" for="c-39813572">[-]</label><label class="expand" for="c-39813572">[1 more]</label></div><br/><div class="children"><div class="content">I generally don&#x27;t agree with the direction withoutboats went with asynchricity but you are reading in a whole lot more into that sentence than is really there. It is very clear (based on his writing, in this and other articles) that he went with the solution because he thinks it is the right one, on a technical level.<p>I don&#x27;t agree, but making it sound like it was about marketing the language to JavaScript people is just wrong.</div><br/></div></div><div id="39813370" class="c"><input type="checkbox" id="c-39813370" checked=""/><div class="controls bullet"><span class="by">seabrookmx</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813320">parent</a><span>|</span><a href="#39813572">prev</a><span>|</span><a href="#39813375">next</a><span>|</span><label class="collapse" for="c-39813370">[-]</label><label class="expand" for="c-39813370">[6 more]</label></div><br/><div class="children"><div class="content">Threads have a cost. Context switching between them at the kernel level has a cost. There are some workloads that gain performance by multiplexing requests on a thread. Java virtual threads, golang goroutines, and dotnet async&#x2F;await (which is multi threaded like Rust+tokio) all moved this way for _performance_ reasons not for ergonomic or political ones.<p>It&#x27;s also worth pointing out that async&#x2F;await was not originally a JavaScript thing. It&#x27;s in many languages now but was first introduced in C#. So by your logic Rust introduced it so it could be &quot;jammed down the throats&quot; of all the dotnet devs..</div><br/><div id="39813617" class="c"><input type="checkbox" id="c-39813617" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813370">parent</a><span>|</span><a href="#39813752">next</a><span>|</span><label class="collapse" for="c-39813617">[-]</label><label class="expand" for="c-39813617">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  So by your logic Rust introduced it so it could be &quot;jammed down the throats&quot; of all the dotnet devs..<p>You&#x27;re missing his point. His point is that the <i>most popular</i> language, which has the <i>most number of programmers</i> forced the hand of Rust devs.<p>His point is not that the <i>first</i> language had this feature, it&#x27;s that the <i>most programmers</i> used this feature, and that was due to the most popular programming language having this feature.</div><br/><div id="39813710" class="c"><input type="checkbox" id="c-39813710" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813617">parent</a><span>|</span><a href="#39813752">next</a><span>|</span><label class="collapse" for="c-39813710">[-]</label><label class="expand" for="c-39813710">[3 more]</label></div><br/><div class="children"><div class="content">That Rust needed async&#x2F;await to be palatable to JS devs would only be a problem if we think async&#x2F;await is not needed in Rust, because it is only useful to work around limitations of JS (single-threaded execution, in this case). If instead async&#x2F;await is a good feature in its own right (even if not critical), then JS forcing Rust&#x27;s hand would be at best an annoyance.<p>And the idea that async&#x2F;await was only added to JS to work around its limitations is simply wrong. So the OP is overall wrong: async&#x2F;await is not an example of someone taking something that only makes sense in one language and using it another language for familiarity.</div><br/><div id="39813765" class="c"><input type="checkbox" id="c-39813765" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813710">parent</a><span>|</span><a href="#39813752">next</a><span>|</span><label class="collapse" for="c-39813765">[-]</label><label class="expand" for="c-39813765">[2 more]</label></div><br/><div class="children"><div class="content">&gt; So the OP is overall wrong: async&#x2F;await is not an example of someone taking something that only makes sense in one language and using it another language for familiarity.<p>I don&#x27;t really understand the counter argument here.<p>My reading of the argument[1] is that &quot;Popularity amongst developers forced Rust devs hands in adding async&quot;. If this is the argument, then a counter argument of &quot;It never (or only) made sense in the popular language (either)&quot; is a non-sequitor.<p>IOW, if it wasn&#x27;t added due to technical reasons (which is the original argument, IIRC), then explaining technical reasons for&#x2F;against isn&#x27;t a counter argument.<p>[1] i.e. Maybe I am reading it wrong?</div><br/><div id="39813784" class="c"><input type="checkbox" id="c-39813784" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813765">parent</a><span>|</span><a href="#39813752">next</a><span>|</span><label class="collapse" for="c-39813784">[-]</label><label class="expand" for="c-39813784">[1 more]</label></div><br/><div class="children"><div class="content">You are not reading it wrong, and your statements are accurate.<p>My broader point is that the possibility of there being a &quot;technically better&quot; construct <i>was simply not in scope for Rust</i>.  In order for Rust to capture Javascript programmers, async&#x2F;await was the only construct that could possibly be considered.<p>And, to be fair, <i>it worked</i>.  Rust&#x27;s growth has been almost completely on the back of network services programming.</div><br/></div></div></div></div></div></div></div></div><div id="39813752" class="c"><input type="checkbox" id="c-39813752" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813370">parent</a><span>|</span><a href="#39813617">prev</a><span>|</span><a href="#39813375">next</a><span>|</span><label class="collapse" for="c-39813752">[-]</label><label class="expand" for="c-39813752">[1 more]</label></div><br/><div class="children"><div class="content">&gt; all moved this way for _performance_ reasons<p>They did <i>NOT</i>.<p>Async performance is quite often (I would even go so far as to say &quot;generally&quot;) worse than single threaded performance in both latency <i>AND</i> throughput under most loads that programmers ever see.<p>Most of the complications of async are much like C#:<p>1) Async allows a more ergonomic way to deal with a prima donna GUI that <i>must</i> be the main thread and that you <i>must</i> not block.  This has <i>nothing</i> to do with &quot;performance&quot;--it is a limitation of the GUI toolkit&#x2F;Javascript VM&#x2F;etc..<p>2) Async adds unavoidable latency overhead and everybody hits this issue.<p>3) Async nominally allows throughput scaling.  Most programmers never gain enough throughput to offset the lost latency performance.</div><br/></div></div></div></div><div id="39813375" class="c"><input type="checkbox" id="c-39813375" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813320">parent</a><span>|</span><a href="#39813370">prev</a><span>|</span><a href="#39813683">next</a><span>|</span><label class="collapse" for="c-39813375">[-]</label><label class="expand" for="c-39813375">[1 more]</label></div><br/><div class="children"><div class="content">I would damn this, if Async&#x2F;Await wasn&#x27;t a good enough (TM) solution for certain problems where Threads are NOT good enough.<p>Remember: there is a reason why Async&#x2F;Await was created B E F O R E JavaScript was used for more than sprinkling a few fancy effects on some otherwise static webpages</div><br/></div></div><div id="39813683" class="c"><input type="checkbox" id="c-39813683" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#39813147">root</a><span>|</span><a href="#39813320">parent</a><span>|</span><a href="#39813375">prev</a><span>|</span><a href="#39813206">next</a><span>|</span><label class="collapse" for="c-39813683">[-]</label><label class="expand" for="c-39813683">[1 more]</label></div><br/><div class="children"><div class="content">async&#x2F;await is just a different concurrency paradigm with different strengths and weaknesses than threads. Rust has support for threaded concurrency as well though the ecosystem for it is a lot less mature.</div><br/></div></div></div></div></div></div><div id="39813206" class="c"><input type="checkbox" id="c-39813206" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#39813147">prev</a><span>|</span><a href="#39813831">next</a><span>|</span><label class="collapse" for="c-39813206">[-]</label><label class="expand" for="c-39813206">[2 more]</label></div><br/><div class="children"><div class="content">As one who struggled with thread safe storage since threads started, the amount of code we carry around with us which looks ok, but turns out not to be viable in threads is remarkably high. I bump into this in C, Python3 quite a lot: you have to work harder to do anything which is not synchronous, no matter how you arrive in that place.<p>For long lived work, it is not impossible there is no advantage overall to forking a lot of heavyweight processes which operate fast as a single execution state. If you have the cores, the CPU and the memory. Context switching delay is very possibly not your main problem.<p>For example, I have typically 24 1 hour capture&#x2F;log files, each 300m+ lines big and I need to ungzip them, parse&#x2F;grep out some stuff, calculate some aggregates and then recombine. Its a natural pipeline of 3 or 4 processes. The effort to code this into a single language and uplift it to run threads inside, where it&#x27;s basically 24 forked pipe sequences begs questions: What exactly is going to get faster, when I am probably resource limited by the gunzip process at the front?<p>You think you can code faster than a grep DFA to select inputs? How sure are you that memory structure is faster than awk? Really sure? I tested some. radix tries are nice and have that log(n) length thing, but AWK was as fast. (IP address &quot;hashing&quot; lookup costs)<p>(hint: more than one interpreted language simply forks gzip for you, to unzip an input stream)<p>If you can go to C, then it&#x27;s possible forking heavyweight processes in C, with good IPC buffer selections or mmap is &quot;good enough&quot;</div><br/><div id="39813433" class="c"><input type="checkbox" id="c-39813433" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39813206">parent</a><span>|</span><a href="#39813831">next</a><span>|</span><label class="collapse" for="c-39813433">[-]</label><label class="expand" for="c-39813433">[1 more]</label></div><br/><div class="children"><div class="content">As someone that was big into threading back in the 2000, with the experience gathered through times, I think with modern hardware resources we are better off with OS IPC, as it offers much better safety guarantees, specially in C like languages.</div><br/></div></div></div></div><div id="39813831" class="c"><input type="checkbox" id="c-39813831" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#39813206">prev</a><span>|</span><a href="#39813460">next</a><span>|</span><label class="collapse" for="c-39813831">[-]</label><label class="expand" for="c-39813831">[1 more]</label></div><br/><div class="children"><div class="content">I think its partly down to what you grew up with. If you&#x27;re of the JS (or python 3) generation then you&#x27;re _probably_ more comfortable with async.<p>However there are things where async seems to be more of a semantic fit for what youre doing.<p>for example FastAPI is all async, and it makes sense. I started using it, because it scaled better than anything else. They have don&#x27;t a nice job of making the interface as painless as possible. It almost doesn&#x27;t feel like surprise goto.<p>I do a lot of stream processing, so for me threads is a better fit. It scales well enough, and should I need to either go to multiprocessing (not great) or duplicate to a new stand-alone process, its fairly simple (Keeping everything message based also helps.)<p>async&#x2F;threads is _almost_ like shop bought coke vs sodastream. They are mostly the same, but have slightly different semantics.</div><br/></div></div><div id="39813460" class="c"><input type="checkbox" id="c-39813460" checked=""/><div class="controls bullet"><span class="by">gudzpoz</span><span>|</span><a href="#39813831">prev</a><span>|</span><a href="#39813647">next</a><span>|</span><label class="collapse" for="c-39813460">[-]</label><label class="expand" for="c-39813460">[1 more]</label></div><br/><div class="children"><div class="content">I think the author is confusing two things here:<p>1. User-space threads &#x2F; Green threads<p>2. Structured concurrency<p>The former one is an advantage of async&#x2F;await, but is not unique to it (see Go or Java Loom for examples that involves no function coloring problem). And the latter one can be implemented with both OS threads and green threads (see Structured concurrency JEPS for Java [1]).<p>[1] <a href="https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;462" rel="nofollow">https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;462</a></div><br/></div></div><div id="39813647" class="c"><input type="checkbox" id="c-39813647" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#39813460">prev</a><span>|</span><a href="#39813685">next</a><span>|</span><label class="collapse" for="c-39813647">[-]</label><label class="expand" for="c-39813647">[1 more]</label></div><br/><div class="children"><div class="content">Another discussion where people don&#x27;t get async&#x2F;await, can&#x27;t fathom why you would want a concurrency mechanism on a single thread and assume no one needs it.<p>UI programming, communication with the GPU, and cross runtime communication are good examples but I&#x27;m sure there are more.<p>Threads, green or otherwise, don&#x27;t work for those cases but async&#x2F;await does.</div><br/></div></div><div id="39813685" class="c"><input type="checkbox" id="c-39813685" checked=""/><div class="controls bullet"><span class="by">anacrolix</span><span>|</span><a href="#39813647">prev</a><span>|</span><a href="#39813363">next</a><span>|</span><label class="collapse" for="c-39813685">[-]</label><label class="expand" for="c-39813685">[2 more]</label></div><br/><div class="children"><div class="content">async&#x2F;await is syntax. Most of what people associate with it is actually the benefit of virtual threading. Asynchrony is how virtual threading is achieved in user space. Rust has direct native threading by default and can&#x27;t do virtual threading without a runtime. Async&#x2F;await makes the use of a runtime explicit. It could be possible to have both virtual and OS threading without special syntax but it would require a marker trait, algebraic effects or monads. Without those things you either need to choose user or OS level threads by default. If user level threads are the default, you need a runtime by default. (Even if that runtime is only for concurrency.). Go made that the default. Again, you don&#x27;t need async&#x2F;await to have virtual threading.</div><br/><div id="39813838" class="c"><input type="checkbox" id="c-39813838" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39813685">parent</a><span>|</span><a href="#39813363">next</a><span>|</span><label class="collapse" for="c-39813838">[-]</label><label class="expand" for="c-39813838">[1 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await is syntax, but it&#x27;s not equivalent to virtual threads. It is special syntax for a certain pattern of writing concurrent (and possibly parallel) code: one in which you launch a concurrent operation specifically to get back one result. When you start an OS thread or a virtual thread, that thread can do anything. When you launch a task, it can only do one thing: return one result of the type you asked for.<p>Async&#x2F;await is perfect for operations that map well onto this structure. For example, most IO reads and writes fit well into this model - you trigger the IO operation to get back a specific result, then do some other work while it&#x27;s being prepared, and when you need the result, you block until it&#x27;s available. Other common concurrent operations don&#x27;t map well on this at all - for example, if you want to monitor a resource to do something every time its state changes, then this is not well modeled at all as a single operation with a unique result, and a virtual or real thread would be a much better option.<p>Also, having both virtual and OS threads doesn&#x27;t need any special syntax. You just need two different functions for creating a thread - StartOSThread(func) and StartVirtualThread(func), and a similar split for other functions that directly interact with threads (join, cancel, etc), and a function for telling whether you are currently running in a virtual thread. Everything else stays the same. This is what Java is doing with Project Loom, I&#x27;m not speaking just in principle.<p>The huge difficulty with virtual threads is implementing all blocking operations (IO, synchronization primitives, waits, etc) such that they use async OS primitives and yield to the virtual thread scheduler, instead of actually blocking the OS thread running the virtual thread.</div><br/></div></div></div></div><div id="39813363" class="c"><input type="checkbox" id="c-39813363" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813685">prev</a><span>|</span><a href="#39813383">next</a><span>|</span><label class="collapse" for="c-39813363">[-]</label><label class="expand" for="c-39813363">[6 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;Smart programmers try to avoid complexity. So, they see the extra complexity in async&#x2F;await and question why it is needed. This question is especially pertinent when considering that a reasonable alternative exists in OS threads.&quot;<p>Hm, yes, but is that complexity really avoided if it&#x27;s in the language&#x2F;runtime?<p>Sure, it&#x27;s not in your code and it will probably have way more extensive testing and maybe also people that thought about the problem for months and you&#x27;re just trying to implement Business feature #31514 and not reinventing the wheel, but as someone who has been bitten by specific implementations like the one in Quarkus (not a language, granted), I must say:<p>Complexity is there to stay (and occasionally bite you), even if it&#x27;s hidden!</div><br/><div id="39813398" class="c"><input type="checkbox" id="c-39813398" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#39813363">parent</a><span>|</span><a href="#39813547">next</a><span>|</span><label class="collapse" for="c-39813398">[-]</label><label class="expand" for="c-39813398">[3 more]</label></div><br/><div class="children"><div class="content">I tend to agree, but an important note is that I&#x27;ve never seen an async&#x2F;await system that didn&#x27;t ALSO interact with OS threads. Async await is not an alternative to OS threads but rather an additional layer.</div><br/><div id="39813470" class="c"><input type="checkbox" id="c-39813470" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813363">root</a><span>|</span><a href="#39813398">parent</a><span>|</span><a href="#39813561">next</a><span>|</span><label class="collapse" for="c-39813470">[-]</label><label class="expand" for="c-39813470">[1 more]</label></div><br/><div class="children"><div class="content">I have heard about them in embedded systems where there are no OS threads, because there is no OS, but there is Async tasks and a scheduler</div><br/></div></div><div id="39813561" class="c"><input type="checkbox" id="c-39813561" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#39813363">root</a><span>|</span><a href="#39813398">parent</a><span>|</span><a href="#39813470">prev</a><span>|</span><a href="#39813547">next</a><span>|</span><label class="collapse" for="c-39813561">[-]</label><label class="expand" for="c-39813561">[1 more]</label></div><br/><div class="children"><div class="content">You mean like the async&#x2F;await systems in the two most popular languages in the world - JavaScript and Python?<p>Async&#x2F;await is definitely an alternative to user space threads, especially for IO bound tasks.</div><br/></div></div></div></div><div id="39813547" class="c"><input type="checkbox" id="c-39813547" checked=""/><div class="controls bullet"><span class="by">grumpyprole</span><span>|</span><a href="#39813363">parent</a><span>|</span><a href="#39813398">prev</a><span>|</span><a href="#39813383">next</a><span>|</span><label class="collapse" for="c-39813547">[-]</label><label class="expand" for="c-39813547">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Hm, yes, but is that complexity really avoided if it&#x27;s in the language&#x2F;runtime?<p>Complexity can be abstracted away and this is still a worthwhile goal. Otherwise, we&#x27;d all still be studying Intel CPU documentation.</div><br/><div id="39813601" class="c"><input type="checkbox" id="c-39813601" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813363">root</a><span>|</span><a href="#39813547">parent</a><span>|</span><a href="#39813383">next</a><span>|</span><label class="collapse" for="c-39813601">[-]</label><label class="expand" for="c-39813601">[1 more]</label></div><br/><div class="children"><div class="content">It can and it should, but I disagree with the sentiment that when it&#x27;s abstracted &quot;away&quot; it&#x27;s not there anymore.<p>You just don&#x27;t see it.<p>Abstraction doesn&#x27;t change any fact about how the system actually works.</div><br/></div></div></div></div></div></div><div id="39813383" class="c"><input type="checkbox" id="c-39813383" checked=""/><div class="controls bullet"><span class="by">stevefan1999</span><span>|</span><a href="#39813363">prev</a><span>|</span><a href="#39813138">next</a><span>|</span><label class="collapse" for="c-39813383">[-]</label><label class="expand" for="c-39813383">[1 more]</label></div><br/><div class="children"><div class="content">Because you want to avoid context switching cost. In fact, async&#x2F;await&#x2F;promise&#x2F;future&#x2F;Task is also closely related to fiber as opposed to thread at least in Windows, but fiber is provided from an OS level while async&#x2F;promise&#x2F;future&#x2F;Task is provided by the language itself. You can switch to a different fiber without doing a context switch, just like how you use a state machine to switch to different job using async&#x2F;promise&#x2F;future&#x2F;Task</div><br/></div></div><div id="39813138" class="c"><input type="checkbox" id="c-39813138" checked=""/><div class="controls bullet"><span class="by">hsjsbeebue</span><span>|</span><a href="#39813383">prev</a><span>|</span><a href="#39813449">next</a><span>|</span><label class="collapse" for="c-39813138">[-]</label><label class="expand" for="c-39813138">[7 more]</label></div><br/><div class="children"><div class="content">What is the language agnostic answer to the same question?<p>I imagine something to do with memory usage or avoiding thread or thread pool starvation issues. Maybe performance too?</div><br/><div id="39813213" class="c"><input type="checkbox" id="c-39813213" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#39813138">parent</a><span>|</span><a href="#39813247">next</a><span>|</span><label class="collapse" for="c-39813213">[-]</label><label class="expand" for="c-39813213">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have a lot of experience with async&#x2F;await at high numbers of tasks, but I&#x27;ve run Erlang with millions of processes. It&#x27;s a lot easier to run millions of Erlang processes on one machine than to run a million OS threads. I suspect async tasks would be similar; an OS thread needs its own stack, and that&#x27;s going to use at least a page of memory, but often much more. Otoh, an async task or green thread might be able to use less.<p>If you&#x27;re running real OS threads, I <i>think</i> task switching is going to be real context switches, which might mean spectre mitigations clear your cpu caches, but task switching can avoid that.<p>You may end up with more system calls with OS threads, because your runtime might be able to aggregate things a bit (blocking reads become kqueue&#x2F;epoll&#x2F;select, but maybe that&#x27;s actually a wash, because you do still need a read call when the FD is ready, and real blocking only makes a single call)</div><br/></div></div><div id="39813247" class="c"><input type="checkbox" id="c-39813247" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39813138">parent</a><span>|</span><a href="#39813213">prev</a><span>|</span><a href="#39813449">next</a><span>|</span><label class="collapse" for="c-39813247">[-]</label><label class="expand" for="c-39813247">[5 more]</label></div><br/><div class="children"><div class="content">IMO the biggest reason to avoid threads is simply that it&#x27;s ~impossible to write safe code using threads (e.g. without race conditions). Arguably with Rust&#x27;s ownership system that&#x27;s less true there than in other languages.</div><br/><div id="39813426" class="c"><input type="checkbox" id="c-39813426" checked=""/><div class="controls bullet"><span class="by">treflop</span><span>|</span><a href="#39813138">root</a><span>|</span><a href="#39813247">parent</a><span>|</span><a href="#39813637">next</a><span>|</span><label class="collapse" for="c-39813426">[-]</label><label class="expand" for="c-39813426">[1 more]</label></div><br/><div class="children"><div class="content">Asynchronous code has race conditions and synchronization issues too.<p>I pray for all the code written by people who think they didn’t need to learn about synchronization because they wrote asynchronous code.<p>And unfortunately I’ve come across and had to fix asynchronous code with race conditions.<p>You cannot escape learning about synchronization. Writing race-condition-free code is not hard.<p>What is actually hard is writing fast lock-free routines, but that’s more a parallelism problem that affects both threaded and asynchronous code. And most people will never need to reach that level of code optimization for their work.</div><br/></div></div><div id="39813637" class="c"><input type="checkbox" id="c-39813637" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#39813138">root</a><span>|</span><a href="#39813247">parent</a><span>|</span><a href="#39813426">prev</a><span>|</span><a href="#39813677">next</a><span>|</span><label class="collapse" for="c-39813637">[-]</label><label class="expand" for="c-39813637">[1 more]</label></div><br/><div class="children"><div class="content">&gt; IMO the biggest reason to avoid threads is simply that it&#x27;s ~impossible to write safe code using threads (e.g. without race conditions).<p>Javascript has race conditions too, even with no threads involved.</div><br/></div></div><div id="39813677" class="c"><input type="checkbox" id="c-39813677" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39813138">root</a><span>|</span><a href="#39813247">parent</a><span>|</span><a href="#39813637">prev</a><span>|</span><a href="#39813307">next</a><span>|</span><label class="collapse" for="c-39813677">[-]</label><label class="expand" for="c-39813677">[1 more]</label></div><br/><div class="children"><div class="content">You can write safe code using threads if you enforce that the only way threads can communicate is by sending messages to each other (via copying, not pointers). This is what Erlang does.</div><br/></div></div><div id="39813307" class="c"><input type="checkbox" id="c-39813307" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39813138">root</a><span>|</span><a href="#39813247">parent</a><span>|</span><a href="#39813677">prev</a><span>|</span><a href="#39813449">next</a><span>|</span><label class="collapse" for="c-39813307">[-]</label><label class="expand" for="c-39813307">[1 more]</label></div><br/><div class="children"><div class="content">Async-await is about concurrency, not parallelism. It can work in both a single-threaded and multi-threaded context, the latter exposing all the typical failure modes of multi-threaded code.<p>Also, Rust’s ownership model only prevents data races, that’s only the tip of the iceberg of race conditions, and I don’t think that any general model makes it possible to statically determine that any given multithreaded code is safe. Nonetheless, that’s the only way to speed up most kind of code, so possibly the benefits outweigh the cost in many cases.</div><br/></div></div></div></div></div></div><div id="39813449" class="c"><input type="checkbox" id="c-39813449" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#39813138">prev</a><span>|</span><a href="#39813201">next</a><span>|</span><label class="collapse" for="c-39813449">[-]</label><label class="expand" for="c-39813449">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A common refrain is that threads can do everything that async&#x2F;await can, but simpler.<p>&gt; OS threads don’t require any changes to the programming model, which makes it very easy to express concurrency.<p>I think these claims need a bit of justification, or else why write the article?</div><br/></div></div><div id="39813201" class="c"><input type="checkbox" id="c-39813201" checked=""/><div class="controls bullet"><span class="by">ikekkdcjkfke</span><span>|</span><a href="#39813449">prev</a><span>|</span><a href="#39813381">next</a><span>|</span><label class="collapse" for="c-39813201">[-]</label><label class="expand" for="c-39813201">[5 more]</label></div><br/><div class="children"><div class="content">What i would hope for is implicit async&#x2F;await so i don&#x27;t have to write it out &#x2F; wrap all the time</div><br/><div id="39813290" class="c"><input type="checkbox" id="c-39813290" checked=""/><div class="controls bullet"><span class="by">yodon</span><span>|</span><a href="#39813201">parent</a><span>|</span><a href="#39813269">next</a><span>|</span><label class="collapse" for="c-39813290">[-]</label><label class="expand" for="c-39813290">[2 more]</label></div><br/><div class="children"><div class="content">&gt;implicit async&#x2F;await<p>I keep suspecting C# will be the place where we see this, but probably not for another couple years.</div><br/><div id="39813945" class="c"><input type="checkbox" id="c-39813945" checked=""/><div class="controls bullet"><span class="by">asabla</span><span>|</span><a href="#39813201">root</a><span>|</span><a href="#39813290">parent</a><span>|</span><a href="#39813269">next</a><span>|</span><label class="collapse" for="c-39813945">[-]</label><label class="expand" for="c-39813945">[1 more]</label></div><br/><div class="children"><div class="content">We might not be that far away already. There is this issue[1] on Github, where Microsoft and the community discuss some significant changes.<p>There is still a lot of questions unanswered, but initial tests look promising.<p>Ref: <a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;issues&#x2F;94620">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;issues&#x2F;94620</a></div><br/></div></div></div></div><div id="39813269" class="c"><input type="checkbox" id="c-39813269" checked=""/><div class="controls bullet"><span class="by">groestl</span><span>|</span><a href="#39813201">parent</a><span>|</span><a href="#39813290">prev</a><span>|</span><a href="#39813381">next</a><span>|</span><label class="collapse" for="c-39813269">[-]</label><label class="expand" for="c-39813269">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s eerily similar to what (green) threads are.</div><br/><div id="39813527" class="c"><input type="checkbox" id="c-39813527" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#39813201">root</a><span>|</span><a href="#39813269">parent</a><span>|</span><a href="#39813381">next</a><span>|</span><label class="collapse" for="c-39813527">[-]</label><label class="expand" for="c-39813527">[1 more]</label></div><br/><div class="children"><div class="content">I’ve always thought async await is just a less clunky implementation of green threads. Not as a feature parity replacement, but trying to fill the same niche.</div><br/></div></div></div></div></div></div><div id="39813381" class="c"><input type="checkbox" id="c-39813381" checked=""/><div class="controls bullet"><span class="by">feverzsj</span><span>|</span><a href="#39813201">prev</a><span>|</span><a href="#39813814">next</a><span>|</span><label class="collapse" for="c-39813381">[-]</label><label class="expand" for="c-39813381">[2 more]</label></div><br/><div class="children"><div class="content">Rust async&#x2F;await is as bad as C++ coroutines. They lack one of the most important language counterparts: async drop&#x2F;destructor.</div><br/><div id="39813394" class="c"><input type="checkbox" id="c-39813394" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813381">parent</a><span>|</span><a href="#39813814">next</a><span>|</span><label class="collapse" for="c-39813394">[-]</label><label class="expand" for="c-39813394">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the main gripe imo: Missing features that are not optional for certain problems where the solution would otherwise make perfect sense.<p>I get the pragmatism to &quot;better ship something that is 80% finished now, than wait for it to be 100% finished in some years&quot;, but with Rust&#x27;s async&#x2F;await it was released in 2018 and the more time passes, the more it looks like some sharp edges are here to stay.</div><br/></div></div></div></div><div id="39813814" class="c"><input type="checkbox" id="c-39813814" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#39813381">prev</a><span>|</span><a href="#39813511">next</a><span>|</span><label class="collapse" for="c-39813814">[-]</label><label class="expand" for="c-39813814">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I recall that the thing that made me stick with Rust is the Iterator trait. It blew my mind that you could make something an Iterator, apply a handful of different combinators, then pass the resulting Iterator into any function that took an Iterator.<p>What languages did the author use before? Is this any different from the interface pattern seen in many other languages?</div><br/></div></div><div id="39813511" class="c"><input type="checkbox" id="c-39813511" checked=""/><div class="controls bullet"><span class="by">darthrupert</span><span>|</span><a href="#39813814">prev</a><span>|</span><a href="#39813228">next</a><span>|</span><label class="collapse" for="c-39813511">[-]</label><label class="expand" for="c-39813511">[2 more]</label></div><br/><div class="children"><div class="content">My possibly unpopular opinion is that async&#x2F;await is a mistake as a first class programming construct. That functionality should 100% be in libraries for two reasons: 1) that way it won&#x27;t infect the actual language in any way and 2) it will be more difficult to use so people will only reach for it if they really need it.<p>Sync code and threads is the way to go for 99% of the cases where concurrency is needed. Rust handles most of the footguns of that combination anyway.</div><br/><div id="39813634" class="c"><input type="checkbox" id="c-39813634" checked=""/><div class="controls bullet"><span class="by">nurple</span><span>|</span><a href="#39813511">parent</a><span>|</span><a href="#39813228">next</a><span>|</span><label class="collapse" for="c-39813634">[-]</label><label class="expand" for="c-39813634">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t disagree more. In my experience, single-threaded event-loop driven async&#x2F;await should be used for every possible concurrency need, with the complexity of multi-threaded concurrency being reserved for the rare cases it&#x27;s needed. As auto-scaled services and FaaS began to become popular, I&#x27;ve found most any need for multithreaded programming almost wholly unnecessary.</div><br/></div></div></div></div><div id="39813228" class="c"><input type="checkbox" id="c-39813228" checked=""/><div class="controls bullet"><span class="by">coolThingsFirst</span><span>|</span><a href="#39813511">prev</a><span>|</span><a href="#39813156">next</a><span>|</span><label class="collapse" for="c-39813228">[-]</label><label class="expand" for="c-39813228">[5 more]</label></div><br/><div class="children"><div class="content">How is async&#x2F;await implemented under the hood?</div><br/><div id="39813295" class="c"><input type="checkbox" id="c-39813295" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39813228">parent</a><span>|</span><a href="#39813323">next</a><span>|</span><label class="collapse" for="c-39813295">[-]</label><label class="expand" for="c-39813295">[2 more]</label></div><br/><div class="children"><div class="content">Generally via continuations. An async function is transformed to continuation-passing style, await calls with the current continuation, and then you have a runtime that at its simplest is just, like, a queue of tasks and has special-cased primitives for doing things like async I&#x2F;O where you suspend, and it just pulls tasks off the queue and runs them, and when one task suspends it stores the continuation and runs the next one.</div><br/><div id="39813501" class="c"><input type="checkbox" id="c-39813501" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#39813228">root</a><span>|</span><a href="#39813295">parent</a><span>|</span><a href="#39813323">next</a><span>|</span><label class="collapse" for="c-39813501">[-]</label><label class="expand" for="c-39813501">[1 more]</label></div><br/><div class="children"><div class="content">Does that runtime run the tasks across multiple cores?</div><br/></div></div></div></div><div id="39813351" class="c"><input type="checkbox" id="c-39813351" checked=""/><div class="controls bullet"><span class="by">LtWorf</span><span>|</span><a href="#39813228">parent</a><span>|</span><a href="#39813323">prev</a><span>|</span><a href="#39813156">next</a><span>|</span><label class="collapse" for="c-39813351">[-]</label><label class="expand" for="c-39813351">[1 more]</label></div><br/><div class="children"><div class="content">poll()</div><br/></div></div></div></div><div id="39813156" class="c"><input type="checkbox" id="c-39813156" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#39813228">prev</a><span>|</span><a href="#39813199">next</a><span>|</span><label class="collapse" for="c-39813156">[-]</label><label class="expand" for="c-39813156">[5 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; A common refrain is that threads can do everything that async&#x2F;await can, but simpler.<p>Who says that? Threads and async&#x2F;await are different things, and it doesn’t make sense to say one can do what the other does. And threads definitely are not simpler than AA</div><br/><div id="39813284" class="c"><input type="checkbox" id="c-39813284" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813156">parent</a><span>|</span><a href="#39813199">next</a><span>|</span><label class="collapse" for="c-39813284">[-]</label><label class="expand" for="c-39813284">[4 more]</label></div><br/><div class="children"><div class="content">Threads are easier to spawn and that&#x27;s where all the fuzz comes from, I argue.<p>Especially in Rust, Async isn&#x27;t as easy as in other languages with a runtime and it does indeed have some caveats (e.g. cancellation), but all the real fuzz comes from not understanding that they are different strategies for some similar but not the same problems.<p>It makes little to no sense to use Async&#x2F;Await for number crunching&#x2F;CPU-compute intensive tasks, for example.<p>One can use Threads for some IO waiting though, but it&#x27;s definitely not the best solution for that particular problem.<p>To me this whole discussion has two facets:<p>1) How can Async&#x2F;Await be more ergonomic in Rust
2) How can we teach people that Async&#x2F;Await is a different solution with different tradeoffs to Threads - there is a reason why Async&#x2F;Await was created AFTER WE ALREADY HAD INVENTED THREADS!</div><br/><div id="39813686" class="c"><input type="checkbox" id="c-39813686" checked=""/><div class="controls bullet"><span class="by">nurple</span><span>|</span><a href="#39813156">root</a><span>|</span><a href="#39813284">parent</a><span>|</span><a href="#39813376">next</a><span>|</span><label class="collapse" for="c-39813686">[-]</label><label class="expand" for="c-39813686">[1 more]</label></div><br/><div class="children"><div class="content">My problem with rust&#x27;s async&#x2F;await is that it&#x27;s _not_ a different strategy as the continuation tasks _are_ run multithreaded, so it&#x27;s technically both strategies. IMO one of the biggest selling points of single-threaded async&#x2F;await was how much complexity falls away compared to managing preemptive synchronization in the multi-threaded case.<p>I can see why there&#x27;s so much controversy over async&#x2F;await in rust. If I had to take both the syntax and cognitive hit of using async&#x2F;await _and_ multi-threading, I would also angrily call for its removal.</div><br/></div></div><div id="39813376" class="c"><input type="checkbox" id="c-39813376" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#39813156">root</a><span>|</span><a href="#39813284">parent</a><span>|</span><a href="#39813686">prev</a><span>|</span><a href="#39813199">next</a><span>|</span><label class="collapse" for="c-39813376">[-]</label><label class="expand" for="c-39813376">[2 more]</label></div><br/><div class="children"><div class="content">Async wasn&#x27;t invented after threads. It was primarily popularized in a system that has been designed such that it couldn&#x27;t use threads (the web browser). Everything else is post-justifcation for why it&#x27;s better. It isn&#x27;t better.</div><br/><div id="39813461" class="c"><input type="checkbox" id="c-39813461" checked=""/><div class="controls bullet"><span class="by">OtomotO</span><span>|</span><a href="#39813156">root</a><span>|</span><a href="#39813376">parent</a><span>|</span><a href="#39813199">next</a><span>|</span><label class="collapse" for="c-39813461">[-]</label><label class="expand" for="c-39813461">[1 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;Await as a syntax thing wasn&#x27;t, but Async&#x2F;Await as &quot;don&#x27;t just blindly use Threads for scaling to a myriad of incoming HTTP requests&quot; was.<p>I remember the Apache webserver story and that one has little to nothing to do with Webbrowsers or JavaScript ;)</div><br/></div></div></div></div></div></div></div></div><div id="39813199" class="c"><input type="checkbox" id="c-39813199" checked=""/><div class="controls bullet"><span class="by">plugin-baby</span><span>|</span><a href="#39813156">prev</a><span>|</span><label class="collapse" for="c-39813199">[-]</label><label class="expand" for="c-39813199">[3 more]</label></div><br/><div class="children"><div class="content">is the difference between threads and async&#x2F;await more than syntax? or language-specific?</div><br/><div id="39813730" class="c"><input type="checkbox" id="c-39813730" checked=""/><div class="controls bullet"><span class="by">jokethrowaway</span><span>|</span><a href="#39813199">parent</a><span>|</span><a href="#39813226">next</a><span>|</span><label class="collapse" for="c-39813730">[-]</label><label class="expand" for="c-39813730">[1 more]</label></div><br/><div class="children"><div class="content">Await-async is implemented with a runtime which uses a thread pool or a single thread and allocates work when needed on any thread and waits for IO to yield a result.<p>With threads you just fully control what blocking code is running on a single thread.<p>If you are just running computations (or reading files, as filesystem api are not async) it&#x27;s simpler to just use threads.</div><br/></div></div><div id="39813226" class="c"><input type="checkbox" id="c-39813226" checked=""/><div class="controls bullet"><span class="by">romanovcode</span><span>|</span><a href="#39813199">parent</a><span>|</span><a href="#39813730">prev</a><span>|</span><label class="collapse" for="c-39813226">[-]</label><label class="expand" for="c-39813226">[1 more]</label></div><br/><div class="children"><div class="content">Yes, they are different in most cases.<p>In general await job is to pass the process to 3rd party e.g. database or http and wait for callback whereas thread job is to launch multiple CPU operations in parallel.</div><br/></div></div></div></div></div></div></div></div></div></body></html>