<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698742865399" as="style"/><link rel="stylesheet" href="styles.css?v=1698742865399"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://together.ai/blog/redpajama-data-v2">RedPajama v2 Open Dataset with 30T Tokens for Training LLMs</a> <span class="domain">(<a href="https://together.ai">together.ai</a>)</span></div><div class="subtext"><span>programd</span> | <span>46 comments</span></div><br/><div><div id="38080778" class="c"><input type="checkbox" id="c-38080778" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38080033">next</a><span>|</span><label class="collapse" for="c-38080778">[-]</label><label class="expand" for="c-38080778">[3 more]</label></div><br/><div class="children"><div class="content">Great work, may I suggest more analysis features?<p>- example summary, for better topic embedding<p>- RAG based summary, to have the model critically assess its training data distribution and answer questions on it; to bring together information sitting in separate examples<p>- named entities, for knowledge base; maybe it helps with fact checking later<p>- implicit tasks present in the text, what are the tasks a LLM could learn from a given example?<p>- chain-of-thought augmentation, to bring out implicit deductions and reduce information fragmentation; it has been shown in the Phi-1.5 paper and Orca that synthetic CoT datasets are superior source materials<p>What data fragmentation? Look at the Reversal Curse paper. Models that train on &quot;A is the father of B&quot; fail to generate &quot;B is the son of A&quot;. This kind of connection needs to be explicitly added, and would improve task solving as well.<p>Training on purely organic data is not good enough anymore. All powerful models train on a mix of organic and synthetic data, some models on 50-50 proportions, like the web+synth variant from Phi-1.5.<p>The main idea is to go deeper into the raw data, to infuse it with insight. LLM dataset preprocessing is going to be expensive, comparable to training costs, but the results are worth the effort.</div><br/><div id="38080911" class="c"><input type="checkbox" id="c-38080911" checked=""/><div class="controls bullet"><span class="by">zhangce</span><span>|</span><a href="#38080778">parent</a><span>|</span><a href="#38081032">next</a><span>|</span><label class="collapse" for="c-38080911">[-]</label><label class="expand" for="c-38080911">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the suggestion! We will add this in the pool of features for future release. (We are currently running the current 40+ annotations on the `tail` partitions).<p>If you are interested in contributing the code for these features, feel free to do a PR to <a href="https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data">https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data</a>! Otherwise we will try our best effort implementation :) but we hope that this can become a community effort<p>(feel free to created more issues on github for us to keep track. I created one for this <a href="https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data&#x2F;issues&#x2F;76">https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data&#x2F;issues&#x2F;76</a>)</div><br/></div></div><div id="38081032" class="c"><input type="checkbox" id="c-38081032" checked=""/><div class="controls bullet"><span class="by">sorokod</span><span>|</span><a href="#38080778">parent</a><span>|</span><a href="#38080911">prev</a><span>|</span><a href="#38080033">next</a><span>|</span><label class="collapse" for="c-38081032">[-]</label><label class="expand" for="c-38081032">[1 more]</label></div><br/><div class="children"><div class="content">&quot;B is the son of A&quot; doesn&#x27;t follow from &quot;A is the father of B&quot;.<p>B could be A&#x27;s daughter.</div><br/></div></div></div></div><div id="38080033" class="c"><input type="checkbox" id="c-38080033" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#38080778">prev</a><span>|</span><a href="#38079993">next</a><span>|</span><label class="collapse" for="c-38080033">[-]</label><label class="expand" for="c-38080033">[4 more]</label></div><br/><div class="children"><div class="content">Can someone explain to me like a noob how this (&quot;this&quot; being the data hosting and download access) works? Am I understanding correctly that they are releasing code for filtering common crawl data that is out there, and the result of this filtering is the dataset?<p>To further elaborate on this (possibly wrong) understanding:<p>- Each person can then run their own processing, possibly duplicating effort(?)<p>...but on the good side, giving each person the ability to tweak the pipeline to suit their needs.<p>- There is no torrent of already processed data because __________?<p>- Looking at file lists for this on Hugging Face, some files seem to be stored in Git Large File Storage. Are these already processed files that together constitute the dataset? Or are these Common Crawl files that are selectively listed and pulled for processing?<p>What options are there to preemptively obtain a copy, in case of any possible eventual takedown of the dataset, any assurances about access aside? I am reminded of parts of the pile.<p>Obviously I&#x27;m super clueless here... please be gentle and share anything you know or correct anything I&#x27;ve got wrong.<p>I&#x27;m not asking about training, if that wasn&#x27;t obvious. Just about obtaining the dataset.</div><br/><div id="38080442" class="c"><input type="checkbox" id="c-38080442" checked=""/><div class="controls bullet"><span class="by">zhangce</span><span>|</span><a href="#38080033">parent</a><span>|</span><a href="#38079993">next</a><span>|</span><label class="collapse" for="c-38080442">[-]</label><label class="expand" for="c-38080442">[3 more]</label></div><br/><div class="children"><div class="content">What we make available is:<p>--<p>(A) the dataset after pre-processing the raw CommonCrawl data (e.g., text extraction and language identification) and some minimal filtering; and<p>(B) for each document in (A), we also pre-computed 40+ of &quot;features&quot; (we call the &quot;quality annotations&quot;) you can use to further filter it or deduplicate it. For example, one such feature is &quot;how similar this document is to Wikipedia&quot;.<p>--<p>(A) is around 30T tokens, but you might want to use features in (B) to further filter&#x2F;dedup it down, e.g., to 5T. For example, if in your application documents similar to Wikipedia are the most helpful documents, you can take the top documents with the highest score for the feature &quot;how similar this document is to Wikipedia&quot;. Of course, the really interesting case happens when you consider a larger subset of these features (or maybe even automatically learn what the best way of filtering it is).<p>Our goal is to make this as flexible as possible such that you can fit this into your own application. What we have released is both (A) and (B)<p>If you have any questions, please let us know! Thanks for your interests, have fun with the data!</div><br/><div id="38080655" class="c"><input type="checkbox" id="c-38080655" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#38080033">root</a><span>|</span><a href="#38080442">parent</a><span>|</span><a href="#38079993">next</a><span>|</span><label class="collapse" for="c-38080655">[-]</label><label class="expand" for="c-38080655">[2 more]</label></div><br/><div class="children"><div class="content">Thanks.<p>&gt; how similar this document is to Wikipedia<p>So that’s a measure of how similar it is to the background vector of all (language in focus) Wikipedia data?</div><br/><div id="38080701" class="c"><input type="checkbox" id="c-38080701" checked=""/><div class="controls bullet"><span class="by">zhangce</span><span>|</span><a href="#38080033">root</a><span>|</span><a href="#38080655">parent</a><span>|</span><a href="#38079993">next</a><span>|</span><label class="collapse" for="c-38080701">[-]</label><label class="expand" for="c-38080701">[1 more]</label></div><br/><div class="children"><div class="content">There are actually a few ways to do this; and we have four:<p>- `rps_doc_ml_wikiref_score`: a classifier that classifiers random webpage with Wiki references (used in Llama-1)<p>- `ccnet_perplexity`: perplexity of an LM trained on Wikipedia (used in CCNet)<p>- `rps_doc_ml_wikipedia_score`: classifier prediction for the document being a Wikipedia article<p>- `rps_doc_wikipedia_importance`: Used in <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.03169" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.03169</a><p>You can see the full table here: <a href="https:&#x2F;&#x2F;together.ai&#x2F;blog&#x2F;redpajama-data-v2" rel="nofollow noreferrer">https:&#x2F;&#x2F;together.ai&#x2F;blog&#x2F;redpajama-data-v2</a></div><br/></div></div></div></div></div></div></div></div><div id="38079993" class="c"><input type="checkbox" id="c-38079993" checked=""/><div class="controls bullet"><span class="by">gardnr</span><span>|</span><a href="#38080033">prev</a><span>|</span><a href="#38078852">next</a><span>|</span><label class="collapse" for="c-38079993">[-]</label><label class="expand" for="c-38079993">[2 more]</label></div><br/><div class="children"><div class="content">Anyone know how large it is?<p>They state the 1 trillion token dataset is 5TB.<p>Is it safe to assume this is 5TB * 30 = 150TB?<p>The code in the HuggingFace repo downloads data from url base: <a href="https:&#x2F;&#x2F;data.together.xyz&#x2F;redpajama-data-v2&#x2F;v1.0.0" rel="nofollow noreferrer">https:&#x2F;&#x2F;data.together.xyz&#x2F;redpajama-data-v2&#x2F;v1.0.0</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;togethercomputer&#x2F;RedPajama-Data-V2&#x2F;blob&#x2F;main&#x2F;RedPajama-Data-V2.py" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;togethercomputer&#x2F;RedPajama-D...</a></div><br/><div id="38080445" class="c"><input type="checkbox" id="c-38080445" checked=""/><div class="controls bullet"><span class="by">zhangce</span><span>|</span><a href="#38079993">parent</a><span>|</span><a href="#38078852">next</a><span>|</span><label class="collapse" for="c-38080445">[-]</label><label class="expand" for="c-38080445">[1 more]</label></div><br/><div class="children"><div class="content">It is around 100TB (84 CommonCrawl dumps, roughly 1TB per dump)</div><br/></div></div></div></div><div id="38078852" class="c"><input type="checkbox" id="c-38078852" checked=""/><div class="controls bullet"><span class="by">tydunn</span><span>|</span><a href="#38079993">prev</a><span>|</span><a href="#38078896">next</a><span>|</span><label class="collapse" for="c-38078852">[-]</label><label class="expand" for="c-38078852">[8 more]</label></div><br/><div class="children"><div class="content">This is a lot of tokens. Llama 2 was trained on two trillion tokens [1]<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09288" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09288</a></div><br/><div id="38079502" class="c"><input type="checkbox" id="c-38079502" checked=""/><div class="controls bullet"><span class="by">amilios</span><span>|</span><a href="#38078852">parent</a><span>|</span><a href="#38079561">next</a><span>|</span><label class="collapse" for="c-38079502">[-]</label><label class="expand" for="c-38079502">[6 more]</label></div><br/><div class="children"><div class="content">Loss was still decreasing for the models, there&#x27;s a sense that we can push the training data much much further than we currently are.</div><br/><div id="38079807" class="c"><input type="checkbox" id="c-38079807" checked=""/><div class="controls bullet"><span class="by">npsomaratna</span><span>|</span><a href="#38078852">root</a><span>|</span><a href="#38079502">parent</a><span>|</span><a href="#38080015">next</a><span>|</span><label class="collapse" for="c-38079807">[-]</label><label class="expand" for="c-38079807">[2 more]</label></div><br/><div class="children"><div class="content">Yup. I found this article quite enlightening:<p><a href="https:&#x2F;&#x2F;espadrine.github.io&#x2F;blog&#x2F;posts&#x2F;chinchilla-s-death.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;espadrine.github.io&#x2F;blog&#x2F;posts&#x2F;chinchilla-s-death.ht...</a></div><br/><div id="38080378" class="c"><input type="checkbox" id="c-38080378" checked=""/><div class="controls bullet"><span class="by">rushingcreek</span><span>|</span><a href="#38078852">root</a><span>|</span><a href="#38079807">parent</a><span>|</span><a href="#38080015">next</a><span>|</span><label class="collapse" for="c-38080378">[-]</label><label class="expand" for="c-38080378">[1 more]</label></div><br/><div class="children"><div class="content">Phenomenal blog post about scaling laws.</div><br/></div></div></div></div><div id="38080015" class="c"><input type="checkbox" id="c-38080015" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38078852">root</a><span>|</span><a href="#38079502">parent</a><span>|</span><a href="#38079807">prev</a><span>|</span><a href="#38081205">next</a><span>|</span><label class="collapse" for="c-38080015">[-]</label><label class="expand" for="c-38080015">[1 more]</label></div><br/><div class="children"><div class="content">Prediction as an objective basically forces the models to model the casual processes that create the text itself. It&#x27;s not going to stop getting better unless the data is insufficient&#x2F;unvaried or the architecture creates a bottleneck.<p>I think by the time the former is an &quot;issue&quot;, we&#x27;ll have a Super Intelligence on our hands anyway.<p>The latter is looking less and less likely to be a real hurdle. Very little inductive bias to steer away from crucial solutions, very scalable.</div><br/></div></div><div id="38081205" class="c"><input type="checkbox" id="c-38081205" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#38078852">root</a><span>|</span><a href="#38079502">parent</a><span>|</span><a href="#38080015">prev</a><span>|</span><a href="#38079879">next</a><span>|</span><label class="collapse" for="c-38081205">[-]</label><label class="expand" for="c-38081205">[1 more]</label></div><br/><div class="children"><div class="content">The TinyLlama project is trying to do that pushing by training a small 1.1 billion-parameter model on 3 trillion tokens: <a href="https:&#x2F;&#x2F;github.com&#x2F;jzhang38&#x2F;TinyLlama">https:&#x2F;&#x2F;github.com&#x2F;jzhang38&#x2F;TinyLlama</a></div><br/></div></div></div></div><div id="38079561" class="c"><input type="checkbox" id="c-38079561" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#38078852">parent</a><span>|</span><a href="#38079502">prev</a><span>|</span><a href="#38078896">next</a><span>|</span><label class="collapse" for="c-38079561">[-]</label><label class="expand" for="c-38079561">[1 more]</label></div><br/><div class="children"><div class="content">And Llama 2&#x27;s training data was less aggressively deduplicated.</div><br/></div></div></div></div><div id="38078896" class="c"><input type="checkbox" id="c-38078896" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#38078852">prev</a><span>|</span><a href="#38080952">next</a><span>|</span><label class="collapse" for="c-38078896">[-]</label><label class="expand" for="c-38078896">[3 more]</label></div><br/><div class="children"><div class="content">Nice. Hope somebody makes a torrent of it&#x2F; hosts it in a way that it can&#x27;t be taken down. 
Also, what are some estimates of how many tokens of text are out there? Seems like we are hitting that number pretty quick?</div><br/><div id="38079809" class="c"><input type="checkbox" id="c-38079809" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38078896">parent</a><span>|</span><a href="#38079353">next</a><span>|</span><label class="collapse" for="c-38079809">[-]</label><label class="expand" for="c-38079809">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know about orders of magnitude left but we&#x27;re definitely not close yet. This is just 5 languages(and frankly not even the 5 with the most text) and just as importantly, just what is crawlable from the web. There&#x27;s tons of stuff in popular ebook archives you can&#x27;t crawl from the web.<p>This is also relatively code&#x2F;scientific corpora scant.<p>We&#x27;re just getting started.</div><br/></div></div><div id="38079353" class="c"><input type="checkbox" id="c-38079353" checked=""/><div class="controls bullet"><span class="by">civilitty</span><span>|</span><a href="#38078896">parent</a><span>|</span><a href="#38079809">prev</a><span>|</span><a href="#38080952">next</a><span>|</span><label class="collapse" for="c-38079353">[-]</label><label class="expand" for="c-38079353">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Seems like we are hitting that number pretty quick?</i><p>I don&#x27;t think we&#x27;re even close. Libgen&#x27;s nonfiction archive alone is over 32 terabytes. Total size last year was over 120 terabytes. Between that, SciHub, and the internet, there&#x27;s probably orders of magnitude more tokens out there.</div><br/></div></div></div></div><div id="38080952" class="c"><input type="checkbox" id="c-38080952" checked=""/><div class="controls bullet"><span class="by">shoelessone</span><span>|</span><a href="#38078896">prev</a><span>|</span><a href="#38078800">next</a><span>|</span><label class="collapse" for="c-38080952">[-]</label><label class="expand" for="c-38080952">[2 more]</label></div><br/><div class="children"><div class="content">There are so many articles these days posted on HN like this recently but I&#x27;m realizing I am too far out of touch with the technology to be able to appreciate it.<p>Any recommendations as to how I get a bit of hands on experience in the AI &quot;domain&quot; so when I read some news articles like this it means something more to me? Or is this type of thing really only relevant to a very small subset of software people?</div><br/><div id="38080983" class="c"><input type="checkbox" id="c-38080983" checked=""/><div class="controls bullet"><span class="by">all2</span><span>|</span><a href="#38080952">parent</a><span>|</span><a href="#38078800">next</a><span>|</span><label class="collapse" for="c-38080983">[-]</label><label class="expand" for="c-38080983">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a course available here [0] that might interest you.<p>[0] <a href="https:&#x2F;&#x2F;www.fast.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.fast.ai</a></div><br/></div></div></div></div><div id="38078800" class="c"><input type="checkbox" id="c-38078800" checked=""/><div class="controls bullet"><span class="by">timcobb</span><span>|</span><a href="#38080952">prev</a><span>|</span><a href="#38080612">next</a><span>|</span><label class="collapse" for="c-38078800">[-]</label><label class="expand" for="c-38078800">[3 more]</label></div><br/><div class="children"><div class="content">Super cool people are doing this. But I wonder: how will training data be any different from password lists of yore, which were the arms race secret sauce that no one ever shared?</div><br/><div id="38079457" class="c"><input type="checkbox" id="c-38079457" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38078800">parent</a><span>|</span><a href="#38080612">next</a><span>|</span><label class="collapse" for="c-38079457">[-]</label><label class="expand" for="c-38079457">[2 more]</label></div><br/><div class="children"><div class="content">What password lists?</div><br/><div id="38079960" class="c"><input type="checkbox" id="c-38079960" checked=""/><div class="controls bullet"><span class="by">timcobb</span><span>|</span><a href="#38078800">root</a><span>|</span><a href="#38079457">parent</a><span>|</span><a href="#38080612">next</a><span>|</span><label class="collapse" for="c-38079960">[-]</label><label class="expand" for="c-38079960">[1 more]</label></div><br/><div class="children"><div class="content">Password cracking lists</div><br/></div></div></div></div></div></div><div id="38080612" class="c"><input type="checkbox" id="c-38080612" checked=""/><div class="controls bullet"><span class="by">applgo443</span><span>|</span><a href="#38078800">prev</a><span>|</span><a href="#38079050">next</a><span>|</span><label class="collapse" for="c-38080612">[-]</label><label class="expand" for="c-38080612">[2 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s 5 common crawls, isn&#x27;t data across multiple common crawls mostly similar?</div><br/><div id="38080718" class="c"><input type="checkbox" id="c-38080718" checked=""/><div class="controls bullet"><span class="by">zhangce</span><span>|</span><a href="#38080612">parent</a><span>|</span><a href="#38079050">next</a><span>|</span><label class="collapse" for="c-38080718">[-]</label><label class="expand" for="c-38080718">[1 more]</label></div><br/><div class="children"><div class="content">We did an exact dedup across all 84 dumps; there are 100T tokens before this exact dedup, and 30T tokens after. If we do further fuzzy dedup (we have simhash signatures pre-computed for different similarity level), this can potentially be reduced further.<p>There are quite a lot redundancies across dumps; but also a lot of unique&#x2F;distinct documents</div><br/></div></div></div></div><div id="38079050" class="c"><input type="checkbox" id="c-38079050" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#38080612">prev</a><span>|</span><label class="collapse" for="c-38079050">[-]</label><label class="expand" for="c-38079050">[18 more]</label></div><br/><div class="children"><div class="content">It looks like mass copyright infringement, frankly.</div><br/><div id="38079831" class="c"><input type="checkbox" id="c-38079831" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38079050">parent</a><span>|</span><a href="#38079644">next</a><span>|</span><label class="collapse" for="c-38079831">[-]</label><label class="expand" for="c-38079831">[6 more]</label></div><br/><div class="children"><div class="content">People say this like it’s a fact. Until the courts decide otherwise or your AI model is regurgitating copyrighted data verbatim, generative AI is probably not violating copyright.</div><br/><div id="38081378" class="c"><input type="checkbox" id="c-38081378" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079831">parent</a><span>|</span><a href="#38080552">next</a><span>|</span><label class="collapse" for="c-38081378">[-]</label><label class="expand" for="c-38081378">[1 more]</label></div><br/><div class="children"><div class="content">The courts are in the process of deciding otherwise. <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37962244">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37962244</a><p>Hopefully they won’t, but it’s not looking good.<p>The annoying part is that if they do decide it’s infringement, then open source AI models won’t be allowed to know anything about copyrighted works. It’ll be a big blind spot.</div><br/></div></div><div id="38080552" class="c"><input type="checkbox" id="c-38080552" checked=""/><div class="controls bullet"><span class="by">munchler</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079831">parent</a><span>|</span><a href="#38081378">prev</a><span>|</span><a href="#38080268">next</a><span>|</span><label class="collapse" for="c-38080552">[-]</label><label class="expand" for="c-38080552">[1 more]</label></div><br/><div class="children"><div class="content">Training a model with this data might be legal, but distributing the data without a license probably isn&#x27;t.</div><br/></div></div><div id="38080268" class="c"><input type="checkbox" id="c-38080268" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079831">parent</a><span>|</span><a href="#38080552">prev</a><span>|</span><a href="#38079644">next</a><span>|</span><label class="collapse" for="c-38080268">[-]</label><label class="expand" for="c-38080268">[3 more]</label></div><br/><div class="children"><div class="content">I dunno, at launch if you asked ChatGPT to make up a new Sir Mix-A-Lot song about big butts, it’d write very familiar lyrics more-or-less verbatim…</div><br/><div id="38080835" class="c"><input type="checkbox" id="c-38080835" checked=""/><div class="controls bullet"><span class="by">slyall</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080268">parent</a><span>|</span><a href="#38079644">next</a><span>|</span><label class="collapse" for="c-38080835">[-]</label><label class="expand" for="c-38080835">[2 more]</label></div><br/><div class="children"><div class="content">Lots of people would do the same.<p>I vaguely remember a short science fiction story where people got uploaded to the cloud. There were three options for your memories.<p>The expensive one you got to keep all your memories of Copyright music, video, books. The medium priced one it was replaced with public domain stuff. The cheap one it was all replaced with advertising.</div><br/><div id="38081348" class="c"><input type="checkbox" id="c-38081348" checked=""/><div class="controls bullet"><span class="by">dasyatidprime</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080835">parent</a><span>|</span><a href="#38079644">next</a><span>|</span><label class="collapse" for="c-38081348">[-]</label><label class="expand" for="c-38081348">[1 more]</label></div><br/><div class="children"><div class="content">The results don&#x27;t exactly match your description, but a cloud-run self in which multiple plans are available and in which the implications of copyright enforcement and advertising-supported options figure prominently was depicted in the short video “Welcome to Life: the singularity, ruined by lawyers” on Tom Scott&#x27;s channel. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IFe9wiDfb0E">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IFe9wiDfb0E</a></div><br/></div></div></div></div></div></div></div></div><div id="38079644" class="c"><input type="checkbox" id="c-38079644" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38079050">parent</a><span>|</span><a href="#38079831">prev</a><span>|</span><a href="#38079395">next</a><span>|</span><label class="collapse" for="c-38079644">[-]</label><label class="expand" for="c-38079644">[10 more]</label></div><br/><div class="children"><div class="content">If it gets us to AGI faster, I frankly don&#x27;t give a fuck.<p>AGI-driven drug discovery will save billions of lives. Every day it is delayed costs tens of thousands of lives. No amount of copyright is worth that sacrifice.</div><br/><div id="38079695" class="c"><input type="checkbox" id="c-38079695" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079644">parent</a><span>|</span><a href="#38079953">next</a><span>|</span><label class="collapse" for="c-38079695">[-]</label><label class="expand" for="c-38079695">[1 more]</label></div><br/><div class="children"><div class="content">Heh. Bit too high of a bar. Even if it helps to develop boo about 9000 that&#x27;s fun to prooomt for a while, I think it&#x27;s fair game</div><br/></div></div><div id="38079953" class="c"><input type="checkbox" id="c-38079953" checked=""/><div class="controls bullet"><span class="by">peddling-brink</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079644">parent</a><span>|</span><a href="#38079695">prev</a><span>|</span><a href="#38079395">next</a><span>|</span><label class="collapse" for="c-38079953">[-]</label><label class="expand" for="c-38079953">[8 more]</label></div><br/><div class="children"><div class="content">AGI will mean we’re no longer the dominant life form on the planet. If AGI were achieved tomorrow, how many humans would be left in 200 years?</div><br/><div id="38080348" class="c"><input type="checkbox" id="c-38080348" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079953">parent</a><span>|</span><a href="#38080047">next</a><span>|</span><label class="collapse" for="c-38080348">[-]</label><label class="expand" for="c-38080348">[2 more]</label></div><br/><div class="children"><div class="content">200 years with AGI? I’d be shocked if there weren’t a few hundred billion humans spread across the solar system.</div><br/><div id="38081061" class="c"><input type="checkbox" id="c-38081061" checked=""/><div class="controls bullet"><span class="by">peddling-brink</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080348">parent</a><span>|</span><a href="#38080047">next</a><span>|</span><label class="collapse" for="c-38081061">[-]</label><label class="expand" for="c-38081061">[1 more]</label></div><br/><div class="children"><div class="content">Are you envisioning AGI as something akin to a pet? A fun talking robot? GPT4?<p>Imagine you just woke up on the planet of the apes. You smile and act friendly because you don’t want them to beat you with their clubs. You start helping them with things. Apply some elementary logic that they can’t seem to get, but they appreciate your contributions. But to keep themselves safe from you, they’ve locked up their sharpest sticks and won’t let you touch them.
Are their preventative measures sufficient? Do you even need their sharp sticks to accomplish your goals? Hey, what are your goals anyway? Do they “align” with the apes?</div><br/></div></div></div></div><div id="38080047" class="c"><input type="checkbox" id="c-38080047" checked=""/><div class="controls bullet"><span class="by">soultrees</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38079953">parent</a><span>|</span><a href="#38080348">prev</a><span>|</span><a href="#38079395">next</a><span>|</span><label class="collapse" for="c-38080047">[-]</label><label class="expand" for="c-38080047">[5 more]</label></div><br/><div class="children"><div class="content">I find this notion interesting. What makes you think AI will automatically kill humans?</div><br/><div id="38080088" class="c"><input type="checkbox" id="c-38080088" checked=""/><div class="controls bullet"><span class="by">pr337h4m</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080047">parent</a><span>|</span><a href="#38080873">next</a><span>|</span><label class="collapse" for="c-38080088">[-]</label><label class="expand" for="c-38080088">[2 more]</label></div><br/><div class="children"><div class="content">And moreover, what makes people even think that a desire to commit mass murder is an innate characteristic of an &#x27;intelligent&#x27; being, that increases the more &#x27;intelligent&#x27; it becomes? (If they believe themselves to be &#x27;intelligent&#x27;, do they believe they have a greater desire to commit mass murder?)</div><br/><div id="38081081" class="c"><input type="checkbox" id="c-38081081" checked=""/><div class="controls bullet"><span class="by">peddling-brink</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080088">parent</a><span>|</span><a href="#38080873">next</a><span>|</span><label class="collapse" for="c-38081081">[-]</label><label class="expand" for="c-38081081">[1 more]</label></div><br/><div class="children"><div class="content">This, “desire”, “murder”, “belief” is human thinking about what humans would do. It may not apply to a superhuman machine intelligence.</div><br/></div></div></div></div><div id="38080873" class="c"><input type="checkbox" id="c-38080873" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080047">parent</a><span>|</span><a href="#38080088">prev</a><span>|</span><a href="#38080123">next</a><span>|</span><label class="collapse" for="c-38080873">[-]</label><label class="expand" for="c-38080873">[1 more]</label></div><br/><div class="children"><div class="content">If it isn&#x27;t aligned with humans and doesn&#x27;t understand <i>exactly</i> what humans want it to do, then you&#x27;re just made of matter that it doesn&#x27;t know not to repurpose. It&#x27;s not that it makes a deliberate decision to &quot;kill&quot; you, it&#x27;s that understanding &quot;kill&quot; to a sufficient degree to not do it as a <i>side effect</i> is halfway to alignment already.<p>When we plow a field, we don&#x27;t check for mouse burrows first. When we cut down a tree for lumber, we don&#x27;t check for ants in the way of the chainsaw.<p>Preempting the obvious response: if your thought is &quot;we don&#x27;t let AI do those things directly, we just ask it for information&quot;, consider that for a sufficiently powerful and unaligned AI, you don&#x27;t have to let an AI out of the box, it can let itself out. (And that&#x27;s leaving aside that we hand some AIs Internet access.)</div><br/></div></div><div id="38080123" class="c"><input type="checkbox" id="c-38080123" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#38079050">root</a><span>|</span><a href="#38080047">parent</a><span>|</span><a href="#38080873">prev</a><span>|</span><a href="#38079395">next</a><span>|</span><label class="collapse" for="c-38080123">[-]</label><label class="expand" for="c-38080123">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s certain the AI kills everyone, but it&#x27;s not certainly impossible either. It depends on how the AI works and what it &quot;wants&quot; for some value of &quot;wants&quot;.<p>Humans have not been particularly kind to the species less intelligent than us. Why would we anticipate being well treated by an entity more intelligent than us?<p>Even if we&#x27;re not that relevant to a super intelligence, creating one forfeits human control over the Earth and known universe to the machines. Right now, in a century or two or three or whatever - we might be building Dyson Spheres and colonizing the galaxy. In an alternate and plausible timeline the machines are doing that and we are not.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>