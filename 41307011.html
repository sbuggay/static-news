<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724230876544" as="style"/><link rel="stylesheet" href="styles.css?v=1724230876544"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://csvbase.com/blog/13">Being on The Semantic Web is easy, and, frankly, well worth the bother</a> <span class="domain">(<a href="https://csvbase.com">csvbase.com</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>78 comments</span></div><br/><div><div id="41308298" class="c"><input type="checkbox" id="c-41308298" checked=""/><div class="controls bullet"><span class="by">CaptArmchair</span><span>|</span><a href="#41308062">next</a><span>|</span><label class="collapse" for="c-41308298">[-]</label><label class="expand" for="c-41308298">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit surprised that the author doesn&#x27;t mention key concepts such as linked data, RDF, federation and web querying. Or even the five stars of linked open data. [1] Sure, JSON-LD is part of it, but it&#x27;s just a serialization format.<p>The really neat part is when you start considering universal ontologies and linking to resources published on other domains. This is where your data becomes interoperable and reusable. Even better, through linking you can contextualize and enrich your data. Since linked data is all about creating graphs, creating a link in your data, or publishing data under a specific domain are acts that involves concepts like trust, authority, authenticity and so on. All those murky social concepts that define what we consider more or less objective truths.<p>LLM&#x27;s won&#x27;t replace the semantic web, nor vice versa. They are complementary to each other.  Linked data technologies allow humans to cooperate and evolve domain models with a salience and flexibility which wasn&#x27;t previously possible behind the walls and moats of discrete digital servers or physical buildings. LLM&#x27;s work because they are based on large sets of ground truths, but those sets are always limited which makes inferring new knowledge and asserting its truthiness independent from human intervention next to impossible. LLM&#x27;s may help us to expand linked data graphs, and linked data graphs fashioned by humans may help improve LLM&#x27;s.<p>Creating a juxtaposition between both? Well, that&#x27;s basically comparing apples against pears. They are two different things.<p>[1] <a href="https:&#x2F;&#x2F;5stardata.info&#x2F;en&#x2F;" rel="nofollow">https:&#x2F;&#x2F;5stardata.info&#x2F;en&#x2F;</a></div><br/></div></div><div id="41308062" class="c"><input type="checkbox" id="c-41308062" checked=""/><div class="controls bullet"><span class="by">openrisk</span><span>|</span><a href="#41308298">prev</a><span>|</span><a href="#41307852">next</a><span>|</span><label class="collapse" for="c-41308062">[-]</label><label class="expand" for="c-41308062">[3 more]</label></div><br/><div class="children"><div class="content">The semantic web standards are sorely lacking (for decades now) a killer application. Not in a theoretical universe of decentralized philosopher-computer-scientists but in the dumbed down, swipe-the-next-30sec-video, adtech oligopolized digital landscape of walled gardens. Providing better search metadata is hardly that killer app. Not in 2024.<p>The lack of adoption has, imho, two components.<p>1. bad luck: the Web got worse, a lot worse. There hasn&#x27;t been a Wikipedia-like event for many decades. This was not pre-ordained. Bad stuff happens to societies when they don&#x27;t pay attention. In a parallel universe where the good Web won, the semantic path would have been much more traveled and developed.<p>2. incompleteness of vision: if you dig to their nuclear core, semantic apps offer things like SPARQL queries and reasoners. Great, these functionalities are both unique and have definite utility but there is a reason (pun) that the excellent Protege project [1] is not the new spreadsheet. The calculus of cognitive cost versus tangible benefit to the average user is not favorable. One thing that is missing are abstractions that will help bridge that divide.<p>Still, if we aspire to a better Web, the semantic web direction (if not current state) is our friend. The original visionaries of the semantic web where not out of their mind, they just did not account for the complex socio-economics of digital technology adoption.<p>[1] <a href="https:&#x2F;&#x2F;protege.stanford.edu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;protege.stanford.edu&#x2F;</a></div><br/><div id="41308290" class="c"><input type="checkbox" id="c-41308290" checked=""/><div class="controls bullet"><span class="by">DrScientist</span><span>|</span><a href="#41308062">parent</a><span>|</span><a href="#41308208">next</a><span>|</span><label class="collapse" for="c-41308290">[-]</label><label class="expand" for="c-41308290">[1 more]</label></div><br/><div class="children"><div class="content">I think the problem with <i>any</i> sort of ontology type approach is the problem isn&#x27;t solved when you have defined the one ontology to rule them all after many years of wrangling between experts.<p>As what you have done is spend many years <i>generating a shared understanding</i> of what that ontology means between the experts. Once that&#x27;s done you have the much harder task for pushing that shared understanding to the rest of the world.<p>ie the problem isn&#x27;t defining a tag for a cat - it&#x27;s having a global share vision of what a cat is.<p>I mean we can&#x27;t even agree on what is a man or a women.</div><br/></div></div><div id="41308208" class="c"><input type="checkbox" id="c-41308208" checked=""/><div class="controls bullet"><span class="by">austin-cheney</span><span>|</span><a href="#41308062">parent</a><span>|</span><a href="#41308290">prev</a><span>|</span><a href="#41307852">next</a><span>|</span><label class="collapse" for="c-41308208">[-]</label><label class="expand" for="c-41308208">[1 more]</label></div><br/><div class="children"><div class="content">A killer app is still not enough.<p>People can’t get HTML right for basic accessibility, so something like the semantic web would be super science that people will out of their way to intentionally ignore any profit upon so long as they can raise their laziness and class-action lawsuit liability.</div><br/></div></div></div></div><div id="41307852" class="c"><input type="checkbox" id="c-41307852" checked=""/><div class="controls bullet"><span class="by">bigiain</span><span>|</span><a href="#41308062">prev</a><span>|</span><a href="#41307306">next</a><span>|</span><label class="collapse" for="c-41307852">[-]</label><label class="expand" for="c-41307852">[1 more]</label></div><br/><div class="children"><div class="content">I laughed at this bit:<p>&quot;Googlers, if you&#x27;re reading this, JSON-LD could have the same level of public awareness as RSS if only you could release, and then shut down, some kind of app or service in this area. Please, for the good of the web: consider it.&quot;</div><br/></div></div><div id="41307306" class="c"><input type="checkbox" id="c-41307306" checked=""/><div class="controls bullet"><span class="by">npunt</span><span>|</span><a href="#41307852">prev</a><span>|</span><a href="#41307323">next</a><span>|</span><label class="collapse" for="c-41307306">[-]</label><label class="expand" for="c-41307306">[6 more]</label></div><br/><div class="children"><div class="content">The argument about LLMs is wrong, not because of reasons stated but because semantic meaning shouldn&#x27;t solely be defined by the publisher.<p>The real question is whether the average publisher is better than an LLM at accurately classifying their content. My guess is, when it comes to categorization and summarization, an LLM is going to handily win. An easy test is: are publishers experts on topics they talk about? The truth of the internet is no, they&#x27;re not usually.<p>The entire world of SEO hacks, blogspam, etc exists because publishers were the only source of truth that the search engine used to determine meaning and quality, which has created all the sorts of misaligned incentives that we&#x27;ve lived with for the past 25 years. At best there are some things publishers can provide as guidance for an LLM, social card, etc, but it can&#x27;t be the only truth of the content.<p>Perhaps we will only really reach the promise of &#x27;the semantic web&#x27; when we&#x27;ve adequately overcome the principal-agent problem of who gets to define the meaning of things on the web. My sense is that requires classifiers that are controlled by users.</div><br/><div id="41307669" class="c"><input type="checkbox" id="c-41307669" checked=""/><div class="controls bullet"><span class="by">atoav</span><span>|</span><a href="#41307306">parent</a><span>|</span><a href="#41307980">next</a><span>|</span><label class="collapse" for="c-41307669">[-]</label><label class="expand" for="c-41307669">[2 more]</label></div><br/><div class="children"><div class="content">Yet LLMS fail to make these simple but sometimes meaningful differentiation. See for example this case in which a court reporter is described as <i>being</i> all the things he reported about by Copilot: a child molester, a psychatric escapee, a widow cheat. Presumably because his name was in a lot of articles about said things and LLMS simply associate his name with the crimes without making the connection that he could in fact be simply the messenger and not the criminal. If LLMS had the semantic understanding that the name on top&#x2F;bottom of a news article is the author, it would not have made that mistake.<p><a href="https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;Copilot-turns-a-court-reporter-into-a-child-molester-9840612.html" rel="nofollow">https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;Copilot-turns-a-court-reporter-...</a></div><br/><div id="41308214" class="c"><input type="checkbox" id="c-41308214" checked=""/><div class="controls bullet"><span class="by">npunt</span><span>|</span><a href="#41307306">root</a><span>|</span><a href="#41307669">parent</a><span>|</span><a href="#41307980">next</a><span>|</span><label class="collapse" for="c-41308214">[-]</label><label class="expand" for="c-41308214">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely! Today&#x27;s LLMs can sometimes(&#x2F;often?) enormously suck and should not be relied upon for critical information. There&#x27;s a long way to go to make them better, and I&#x27;m happy that a lot of people are working on that. Finding meaning in a sea of information is a highly imperfect enterprise regardless of the tech we use.<p>My point though was that the core problem we should be trying to solve is overcoming the fundamental misalignment of incentives between publisher and reader, not whether we can put a better schema together that we hope people adopt intelligently &amp; non-adversarially, because we know that won&#x27;t happen in practice. I liked what the author wrote but they also didn&#x27;t really consider this perspective and as such I think they haven&#x27;t hit upon a fundamental understanding of the problem.</div><br/></div></div></div></div><div id="41307980" class="c"><input type="checkbox" id="c-41307980" checked=""/><div class="controls bullet"><span class="by">pickledoyster</span><span>|</span><a href="#41307306">parent</a><span>|</span><a href="#41307669">prev</a><span>|</span><a href="#41308102">next</a><span>|</span><label class="collapse" for="c-41307980">[-]</label><label class="expand" for="c-41307980">[2 more]</label></div><br/><div class="children"><div class="content">&gt;My guess is, when it comes to categorization and summarization, an LLM is going to handily win. An easy test is: are publishers experts on topics they talk about? The truth of the internet is no, they&#x27;re not usually.<p>LLMs are not experts either. Furthermore, from what I gather, LLMs are trained on:<p>&gt;The entire world of SEO hacks, blogspam, etc</div><br/><div id="41308230" class="c"><input type="checkbox" id="c-41308230" checked=""/><div class="controls bullet"><span class="by">npunt</span><span>|</span><a href="#41307306">root</a><span>|</span><a href="#41307980">parent</a><span>|</span><a href="#41308102">next</a><span>|</span><label class="collapse" for="c-41308230">[-]</label><label class="expand" for="c-41308230">[1 more]</label></div><br/><div class="children"><div class="content">This is an excellent rebuttal. I think it is an issue that can be overcome but I appreciate the irony of what you point out :)</div><br/></div></div></div></div><div id="41308102" class="c"><input type="checkbox" id="c-41308102" checked=""/><div class="controls bullet"><span class="by">peoplefromibiza</span><span>|</span><a href="#41307306">parent</a><span>|</span><a href="#41307980">prev</a><span>|</span><a href="#41307323">next</a><span>|</span><label class="collapse" for="c-41308102">[-]</label><label class="expand" for="c-41308102">[1 more]</label></div><br/><div class="children"><div class="content">&gt; because semantic meaning shouldn&#x27;t solely be defined by the publisher<p>LLMs are not that great at understanding semantics though</div><br/></div></div></div></div><div id="41307323" class="c"><input type="checkbox" id="c-41307323" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#41307306">prev</a><span>|</span><a href="#41307259">next</a><span>|</span><label class="collapse" for="c-41307323">[-]</label><label class="expand" for="c-41307323">[1 more]</label></div><br/><div class="children"><div class="content">Metadata in PDFs is also typically based on semantic web standards.<p><a href="https:&#x2F;&#x2F;www.meridiandiscovery.com&#x2F;articles&#x2F;pdf-forensic-analysis-xmp-metadata&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.meridiandiscovery.com&#x2F;articles&#x2F;pdf-forensic-anal...</a><p>Instead of using JSON-LD it uses RDF written as XML. Still uses the same concept of common vocabularies, but instead of schema.org it uses a collection of various vocabularies including Dublin Core.</div><br/></div></div><div id="41307259" class="c"><input type="checkbox" id="c-41307259" checked=""/><div class="controls bullet"><span class="by">mg</span><span>|</span><a href="#41307323">prev</a><span>|</span><a href="#41307502">next</a><span>|</span><label class="collapse" for="c-41307259">[-]</label><label class="expand" for="c-41307259">[23 more]</label></div><br/><div class="children"><div class="content">The author gives two reasons why AI won&#x27;t replace the need for metadata:<p>1: LLMs &quot;routinely get stuff wrong&quot;<p>2: &quot;pricy GPU time&quot;<p>1: I make a lot of tests on how well LLMs get categorization and data extraction right or wrong for my Product Chart (<a href="https:&#x2F;&#x2F;www.productchart.com" rel="nofollow">https:&#x2F;&#x2F;www.productchart.com</a>) project. And they get pretty hard stuff right 99% of the time already. This will only improve.<p>2: Loading the frontpage of Reddit takes hundreds of http requests, parses megabytes of text, image and JavaScript code. In the past, this would have been seen as an impossible task to just show some links to articles. In the near future, nobody will see passing a text through an LLM as a noteworthy amount of compute anymore.</div><br/><div id="41307839" class="c"><input type="checkbox" id="c-41307839" checked=""/><div class="controls bullet"><span class="by">atoav</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307425">next</a><span>|</span><label class="collapse" for="c-41307839">[-]</label><label class="expand" for="c-41307839">[3 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s hope you never write articles about court cases then: <a href="https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;Copilot-turns-a-court-reporter-into-a-child-molester-9840612.html" rel="nofollow">https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;Copilot-turns-a-court-reporter-...</a><p>The alleged low error rate of 1% can ruin your day&#x2F;life&#x2F;company, if it hits the wrong person, regards the wrong problem, etc. And that risk is not adequately addressed by hand-waving and pointing people to low error rates. In fact, if anything such claims would make me less confident in your product.<p>1% error is still a lot if they are the wrong kind of error in the wrong kind of situation. Especially if in that 1% of cases the system is not just <i>slightly</i> wrong, but catastrophically mind-bogglingly wrong.</div><br/><div id="41308004" class="c"><input type="checkbox" id="c-41308004" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307839">parent</a><span>|</span><a href="#41307425">next</a><span>|</span><label class="collapse" for="c-41308004">[-]</label><label class="expand" for="c-41308004">[2 more]</label></div><br/><div class="children"><div class="content">This is the thing with errors and automation. A 1 % error rate in a human process is basically fine. A 1 % error rate in an automated process is hundreds of thousands of errors per day.<p>(See also why automated face recognition in public surveillance cameras might be a bad idea.)</div><br/><div id="41308189" class="c"><input type="checkbox" id="c-41308189" checked=""/><div class="controls bullet"><span class="by">atoav</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41308004">parent</a><span>|</span><a href="#41307425">next</a><span>|</span><label class="collapse" for="c-41308189">[-]</label><label class="expand" for="c-41308189">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. If your system monitors a place like a halfway decent railway station half a million people per day is a number you could expect. Even with an amazingly low error rate of 1% that would result in 5000 wrong signals a day. If we make the assumption that the people are uniformly spread out througout a 24 hour cycle that means a false alarm <i>every 20 seconds</i>.<p>In reality most of the people are there during the day (false alarm every 10 seconds) and the error percentages are nowhere near 1%.<p>If you do the math to figure out the staff needed to react to those false alarms in any meaningful way you have to come to the conclusion that just putting people there instead of cameras would be a safer way to reach the goal.</div><br/></div></div></div></div></div></div><div id="41307425" class="c"><input type="checkbox" id="c-41307425" checked=""/><div class="controls bullet"><span class="by">zaik</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307839">prev</a><span>|</span><a href="#41307972">next</a><span>|</span><label class="collapse" for="c-41307425">[-]</label><label class="expand" for="c-41307425">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Reddit takes hundreds of http requests, parses megabytes of text, image and JavaScript code [...] to show some links to articles<p>Yes, and I hate it. I closed Reddit many times because the wait time wasn&#x27;t worth it.</div><br/><div id="41307507" class="c"><input type="checkbox" id="c-41307507" checked=""/><div class="controls bullet"><span class="by">rfl890</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307425">parent</a><span>|</span><a href="#41307972">next</a><span>|</span><label class="collapse" for="c-41307507">[-]</label><label class="expand" for="c-41307507">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;old.reddit.com" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com</a> ?</div><br/><div id="41308206" class="c"><input type="checkbox" id="c-41308206" checked=""/><div class="controls bullet"><span class="by">jeltz</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307507">parent</a><span>|</span><a href="#41307972">next</a><span>|</span><label class="collapse" for="c-41308206">[-]</label><label class="expand" for="c-41308206">[1 more]</label></div><br/><div class="children"><div class="content">Gets buggier for every year.</div><br/></div></div></div></div></div></div><div id="41307972" class="c"><input type="checkbox" id="c-41307972" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307425">prev</a><span>|</span><a href="#41307311">next</a><span>|</span><label class="collapse" for="c-41307972">[-]</label><label class="expand" for="c-41307972">[2 more]</label></div><br/><div class="children"><div class="content">Only slightly tongue in cheek, but if your measure of success is Reddit, perhaps a better example may serve your argument?</div><br/><div id="41308033" class="c"><input type="checkbox" id="c-41308033" checked=""/><div class="controls bullet"><span class="by">ramon156</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307972">parent</a><span>|</span><a href="#41307311">next</a><span>|</span><label class="collapse" for="c-41308033">[-]</label><label class="expand" for="c-41308033">[1 more]</label></div><br/><div class="children"><div class="content">The argument for &quot;LLMs get it right 99% of the time&quot; is also very generalized and doesn&#x27;t take into account smaller websites</div><br/></div></div></div></div><div id="41307311" class="c"><input type="checkbox" id="c-41307311" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307972">prev</a><span>|</span><a href="#41307288">next</a><span>|</span><label class="collapse" for="c-41307311">[-]</label><label class="expand" for="c-41307311">[3 more]</label></div><br/><div class="children"><div class="content">GPU compute price is dropping fast and will continue to do so.</div><br/><div id="41307875" class="c"><input type="checkbox" id="c-41307875" checked=""/><div class="controls bullet"><span class="by">philjohn</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307311">parent</a><span>|</span><a href="#41307288">next</a><span>|</span><label class="collapse" for="c-41307875">[-]</label><label class="expand" for="c-41307875">[2 more]</label></div><br/><div class="children"><div class="content">But is it dropping faster than the needs of the next model that needs to be trained?</div><br/><div id="41307955" class="c"><input type="checkbox" id="c-41307955" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307875">parent</a><span>|</span><a href="#41307288">next</a><span>|</span><label class="collapse" for="c-41307955">[-]</label><label class="expand" for="c-41307955">[1 more]</label></div><br/><div class="children"><div class="content">Short answer is yes.<p>Also, GPU pricing is hardly relevant. From now on we will see dedicated co-processors on the GPU to handle these things.<p>They will keep on keeping up with the demand until we meet actual physical limits.</div><br/></div></div></div></div></div></div><div id="41307288" class="c"><input type="checkbox" id="c-41307288" checked=""/><div class="controls bullet"><span class="by">monero-xmr</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307311">prev</a><span>|</span><a href="#41307354">next</a><span>|</span><label class="collapse" for="c-41307288">[-]</label><label class="expand" for="c-41307288">[7 more]</label></div><br/><div class="children"><div class="content">LLMs have no soul, so I like content and curation from real people</div><br/><div id="41307318" class="c"><input type="checkbox" id="c-41307318" checked=""/><div class="controls bullet"><span class="by">doe_eyes</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307288">parent</a><span>|</span><a href="#41307684">next</a><span>|</span><label class="collapse" for="c-41307318">[-]</label><label class="expand" for="c-41307318">[2 more]</label></div><br/><div class="children"><div class="content">The main problem is that the incentive for well-intentioned people to add detailed and accurate metadata is much lower than the incentive for SEO dudes to abuse the system if the metadata is used for anything of consequence. There&#x27;s a reason why search engines that trusted website metadata went extinct.<p>That&#x27;s the whole benefit of using LLMs for categorization: they work for you, not for the SEO guy... well, prompt injection tricks aside.</div><br/><div id="41307349" class="c"><input type="checkbox" id="c-41307349" checked=""/><div class="controls bullet"><span class="by">monero-xmr</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307318">parent</a><span>|</span><a href="#41307684">next</a><span>|</span><label class="collapse" for="c-41307349">[-]</label><label class="expand" for="c-41307349">[1 more]</label></div><br/><div class="children"><div class="content">There is value-add if you can prove whatever content you are producing is from an authentic human, because I dislike LLM produced garbage</div><br/></div></div></div></div><div id="41307684" class="c"><input type="checkbox" id="c-41307684" checked=""/><div class="controls bullet"><span class="by">amarant</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307288">parent</a><span>|</span><a href="#41307318">prev</a><span>|</span><a href="#41307464">next</a><span>|</span><label class="collapse" for="c-41307684">[-]</label><label class="expand" for="c-41307684">[3 more]</label></div><br/><div class="children"><div class="content">Huh, it&#x27;s not often you hear a religious argument in a technical discussion. Interesting viewpoint!</div><br/><div id="41308284" class="c"><input type="checkbox" id="c-41308284" checked=""/><div class="controls bullet"><span class="by">MrVandemar</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307684">parent</a><span>|</span><a href="#41307741">next</a><span>|</span><label class="collapse" for="c-41308284">[-]</label><label class="expand" for="c-41308284">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see it as anything religious. I see the comment about something having an intrinsic, instinctive quality, which we can categorise as having &quot;soul&quot;.</div><br/></div></div></div></div><div id="41307464" class="c"><input type="checkbox" id="c-41307464" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307288">parent</a><span>|</span><a href="#41307684">prev</a><span>|</span><a href="#41307354">next</a><span>|</span><label class="collapse" for="c-41307464">[-]</label><label class="expand" for="c-41307464">[1 more]</label></div><br/><div class="children"><div class="content">All the web metadata I consume is organic and responsively farmed.</div><br/></div></div></div></div><div id="41307354" class="c"><input type="checkbox" id="c-41307354" checked=""/><div class="controls bullet"><span class="by">menzoic</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307288">prev</a><span>|</span><a href="#41307383">next</a><span>|</span><label class="collapse" for="c-41307354">[-]</label><label class="expand" for="c-41307354">[2 more]</label></div><br/><div class="children"><div class="content">How does Product Chart use LLMs?</div><br/><div id="41307494" class="c"><input type="checkbox" id="c-41307494" checked=""/><div class="controls bullet"><span class="by">mg</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307354">parent</a><span>|</span><a href="#41307383">next</a><span>|</span><label class="collapse" for="c-41307494">[-]</label><label class="expand" for="c-41307494">[1 more]</label></div><br/><div class="children"><div class="content">We research all product data manually and then have AI cross-check the data and see how well it can replicate what the human has researched and whether it can find errors.<p>Actually, building the AI agent for data research takes up most of my time these days.</div><br/></div></div></div></div><div id="41307383" class="c"><input type="checkbox" id="c-41307383" checked=""/><div class="controls bullet"><span class="by">throwme_123</span><span>|</span><a href="#41307259">parent</a><span>|</span><a href="#41307354">prev</a><span>|</span><a href="#41307502">next</a><span>|</span><label class="collapse" for="c-41307383">[-]</label><label class="expand" for="c-41307383">[2 more]</label></div><br/><div class="children"><div class="content">For my part, I stopped reading at the free bashing of blockchain•.<p>Reminded me of the angst and negativity of these original &quot;Web3&quot; people, already bashing everything that was not in their mood back then.<p>• The crypto ecosystem is shady, I know, but the tech is great</div><br/><div id="41307452" class="c"><input type="checkbox" id="c-41307452" checked=""/><div class="controls bullet"><span class="by">ashkankiani</span><span>|</span><a href="#41307259">root</a><span>|</span><a href="#41307383">parent</a><span>|</span><a href="#41307502">next</a><span>|</span><label class="collapse" for="c-41307452">[-]</label><label class="expand" for="c-41307452">[1 more]</label></div><br/><div class="children"><div class="content">As someone who stopped getting involved in blockchain &quot;tech&quot; 12 years ago because of the prevalence of scams and bad actors and lack of interesting tech beyond the merkle tree, what&#x27;s great about it?<p>FWIW I am genuinely asking. I don&#x27;t know anything about the current tech. There&#x27;s something about &quot;zero knowledge proofs&quot; but I don&#x27;t understand how much of that is used in practice for real blockchain things vs just being research.<p>As far as I know, the throughput of blockchain transactions at scale is miserably slow and expensive and their usual solution is some kind of side channel that skips the full validation.<p>Distributed computation on the blockchain isn&#x27;t really used for anything other than converting between currencies and minting new ones mostly AFAIK as well.<p>What is the great tech that we got from the blockchain revolution?</div><br/></div></div></div></div></div></div><div id="41307502" class="c"><input type="checkbox" id="c-41307502" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41307259">prev</a><span>|</span><a href="#41308193">next</a><span>|</span><label class="collapse" for="c-41307502">[-]</label><label class="expand" for="c-41307502">[5 more]</label></div><br/><div class="children"><div class="content">If even the semantic web people are declaring victory based on a post title and a picture for better integration with Facebook, then it&#x27;s clear that Semantic Web as it was envisioned is fully 100% dead and buried.<p>The concept of OWL and the other standards was to annotate the content of pages, that&#x27;s where the real values lie. Each paragraph the author wrote should have had some metadata about its topic. At the very least, the article metadata was supposed to have included information about the categories of information included in the article.<p>Having a bit of info on the  author, title (redundant, as HTML already has a tag for that), picture, and publication date is almost completely irrelevant for the kinds of things Web 3.0 was supposed to be.</div><br/><div id="41308097" class="c"><input type="checkbox" id="c-41308097" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#41307502">parent</a><span>|</span><a href="#41308237">next</a><span>|</span><label class="collapse" for="c-41308097">[-]</label><label class="expand" for="c-41308097">[1 more]</label></div><br/><div class="children"><div class="content">The blog post does not address why the Semantic Web failed:<p>1. Trust: How should one know that any data available marked up according to Sematic Web principles can be trusted? This is an even more pressing question when the data is free. Sir Berners-Lee (AKA &quot;TimBL&quot;) designed the Semantic Web in a way that makes &quot;trust&quot; a component, when in truth it is an emergent relation between a well-designed system and its users (my own definition).<p>2. Lack of Incentives: There is no way to get paid for uploading content that is financially very valuable. I know many financial companies that would like to offer their data in a &quot;Semantic Web&quot; form, but they cannot, because they would not get compensated, and their existence depends on selling that data; some even use Semantic Web standards for internal-only sharing.<p>3. A lot of SW stuff is either boilerplate or re-discovered formal logic from the 1970s. I read lots of papers that propose some &quot;ontology&quot; but no application that needs it.</div><br/></div></div><div id="41308237" class="c"><input type="checkbox" id="c-41308237" checked=""/><div class="controls bullet"><span class="by">oneeyedpigeon</span><span>|</span><a href="#41307502">parent</a><span>|</span><a href="#41308097">prev</a><span>|</span><a href="#41307826">next</a><span>|</span><label class="collapse" for="c-41308237">[-]</label><label class="expand" for="c-41308237">[1 more]</label></div><br/><div class="children"><div class="content">&gt; title (redundant, as HTML already has a tag for that)<p>Note that `title` isn&#x27;t one of the properties that BlogPosting supports. It supports `headline`, which may well be different from the `&lt;title&#x2F;&gt;`. It&#x27;s probably analogous to the page&#x27;s `&lt;h1&#x2F;&gt;`, but more reliable.</div><br/></div></div><div id="41307826" class="c"><input type="checkbox" id="c-41307826" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#41307502">parent</a><span>|</span><a href="#41308237">prev</a><span>|</span><a href="#41308193">next</a><span>|</span><label class="collapse" for="c-41307826">[-]</label><label class="expand" for="c-41307826">[2 more]</label></div><br/><div class="children"><div class="content">I had pretty much the same reacon while reading the article.  &quot;BlogPosting&quot; isn&#x27;t particularily informative.  The rest of the metadata looked like it could&#x2F;should be put in &lt;meta&gt; tags, done.<p>A very bad example if the intention was to demonstrate how cool and useful semweb is :-)</div><br/><div id="41308262" class="c"><input type="checkbox" id="c-41308262" checked=""/><div class="controls bullet"><span class="by">oneeyedpigeon</span><span>|</span><a href="#41307502">root</a><span>|</span><a href="#41307826">parent</a><span>|</span><a href="#41308193">next</a><span>|</span><label class="collapse" for="c-41308262">[-]</label><label class="expand" for="c-41308262">[1 more]</label></div><br/><div class="children"><div class="content">The schema.org data is much more rich than meta tags, though. Using the latter, an author is just a string of text containing who-knows-what. The former lets you specify a name, email address, and url. And that&#x27;s just for the Person type—you can specify an Organization too.</div><br/></div></div></div></div></div></div><div id="41308193" class="c"><input type="checkbox" id="c-41308193" checked=""/><div class="controls bullet"><span class="by">627467</span><span>|</span><a href="#41307502">prev</a><span>|</span><a href="#41307666">next</a><span>|</span><label class="collapse" for="c-41308193">[-]</label><label class="expand" for="c-41308193">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The Semantic Web is the old Web 3.0. Before &quot;Web 3.0&quot; meant crypto-whatnot, it meant &quot;machine-readable websites&quot;.<p>Using contemporary AI models aren&#x27;t all websites machine-readable? - or potentially even more readable than semantic web unless an ai model actually does the semantic classification while reading it?</div><br/></div></div><div id="41307666" class="c"><input type="checkbox" id="c-41307666" checked=""/><div class="controls bullet"><span class="by">conzept</span><span>|</span><a href="#41308193">prev</a><span>|</span><a href="#41307286">next</a><span>|</span><label class="collapse" for="c-41307666">[-]</label><label class="expand" for="c-41307666">[1 more]</label></div><br/><div class="children"><div class="content">I think the future holds a synthesis of LLM functions with semantic entities and logic from knowledge graphs (this is called &quot;neuro-symbolic AI&quot;), so each topic&#x2F;object can have a clear context, upon which you can start prompting the AI for the preferred action&#x2F;intention.<p>Already implemented in part on my Conzept Encyclopedia project (using OpenAI): <a href="https:&#x2F;&#x2F;conze.pt&#x2F;explore&#x2F;%22Neuro-symbolic%20AI%22?l=en&amp;ds=reference&amp;t=string&amp;batchsize=5&amp;s=true#" rel="nofollow">https:&#x2F;&#x2F;conze.pt&#x2F;explore&#x2F;%22Neuro-symbolic%20AI%22?l=en&amp;ds=r...</a><p>Something like this is much easier done using the semantic web (3D interactive occurence map for an organism): <a href="https:&#x2F;&#x2F;conze.pt&#x2F;explore&#x2F;Trogon?l=en&amp;ds=reference&amp;t=link&amp;batchsize=5&amp;i=Q191469&amp;u=%2Fapp%2Fmap%2Findex.html%3Fl%3Den%26title%3DTrogon%26gbif%3D9356&amp;s=true#" rel="nofollow">https:&#x2F;&#x2F;conze.pt&#x2F;explore&#x2F;Trogon?l=en&amp;ds=reference&amp;t=link&amp;bat...</a><p>On Conzept one or more bookmarks you create, can be used in various LLM functions. One of the next steps is to integrate a local WebGPU-based frontend LLM, and see what &#x27;free&#x27; prompting can unlock.<p>JSON-LD is also created dynamically for each topic, based on Wikidata data, to set the page metadata.</div><br/></div></div><div id="41307286" class="c"><input type="checkbox" id="c-41307286" checked=""/><div class="controls bullet"><span class="by">Devasta</span><span>|</span><a href="#41307666">prev</a><span>|</span><a href="#41307769">next</a><span>|</span><label class="collapse" for="c-41307286">[-]</label><label class="expand" for="c-41307286">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Before JSON-LD there was a nest of other, more XMLy, standards emitted by the various web steering groups. These actually have very, very deep support in many places (for example in library and archival systems) but on the open web they are not a goer.<p>If archival systems and library&#x27;s are using XML, wouldn&#x27;t it be preferable to follow their lead and whatever standards they are using? Since they are the ones who are going to use this stuff most, most likely.<p>If nothing else, you can add a processing instruction to the document they use to convert it to HTML.</div><br/><div id="41307352" class="c"><input type="checkbox" id="c-41307352" checked=""/><div class="controls bullet"><span class="by">whartung</span><span>|</span><a href="#41307286">parent</a><span>|</span><a href="#41307974">next</a><span>|</span><label class="collapse" for="c-41307352">[-]</label><label class="expand" for="c-41307352">[2 more]</label></div><br/><div class="children"><div class="content">The format really isn’t much of an issue. From an information point of view, the content of the different formats are identical, and translation among them is straightforward.<p>Promoting JSON-LD potentially makes it more palatable to the modern web creators, perhaps increasing adoption. The bots have already adapted.</div><br/><div id="41307923" class="c"><input type="checkbox" id="c-41307923" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#41307286">root</a><span>|</span><a href="#41307352">parent</a><span>|</span><a href="#41307974">next</a><span>|</span><label class="collapse" for="c-41307923">[-]</label><label class="expand" for="c-41307923">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re aware of straightforward translations to and from E-ARK SIP and CSIP? Between what formats?<p>As far as I can tell archivists don&#x27;t care about &quot;modern web creators&quot;, and they likely shouldn&#x27;t, since archiving is a long term project. I know I don&#x27;t, and I&#x27;m only building software for digital archiving.</div><br/></div></div></div></div><div id="41307974" class="c"><input type="checkbox" id="c-41307974" checked=""/><div class="controls bullet"><span class="by">tannhaeuser</span><span>|</span><a href="#41307286">parent</a><span>|</span><a href="#41307352">prev</a><span>|</span><a href="#41307769">next</a><span>|</span><label class="collapse" for="c-41307974">[-]</label><label class="expand" for="c-41307974">[2 more]</label></div><br/><div class="children"><div class="content">If by that the author means JSON-LD has replaced MarcXML, BibTex records, and other bibliographic information systems, then that&#x27;s very much not the case.</div><br/><div id="41308179" class="c"><input type="checkbox" id="c-41308179" checked=""/><div class="controls bullet"><span class="by">AlecSchueler</span><span>|</span><a href="#41307286">root</a><span>|</span><a href="#41307974">parent</a><span>|</span><a href="#41307769">next</a><span>|</span><label class="collapse" for="c-41308179">[-]</label><label class="expand" for="c-41308179">[1 more]</label></div><br/><div class="children"><div class="content">They recognise that in the quoted paragraph. The JSON-LD thing was only about the open web:<p>&gt; [MarcXML, BibTex etc] actually have very, very deep support in many places (for example in library and archival systems) but on the open web they are not a goer.</div><br/></div></div></div></div></div></div><div id="41307769" class="c"><input type="checkbox" id="c-41307769" checked=""/><div class="controls bullet"><span class="by">Vinnl</span><span>|</span><a href="#41307286">prev</a><span>|</span><a href="#41307827">next</a><span>|</span><label class="collapse" for="c-41307769">[-]</label><label class="expand" for="c-41307769">[1 more]</label></div><br/><div class="children"><div class="content">The question is: does this bring any of the purported benefits of the Semantic Web? Does it suddenly allow &quot;agents&quot; to understand the <i>meaning</i> of your web pages, or are we just complying with a set of pre-defined schemas that predefined software (or more specifically, Google, in practice) understands and knows how to render. In other words, was all the SemWeb rigmarole actually necessary, or could the same results have been achieved using any of the mentioned simpler alternatives (microdata, OpenGraph tags, or even just JSON schemas)?</div><br/></div></div><div id="41307827" class="c"><input type="checkbox" id="c-41307827" checked=""/><div class="controls bullet"><span class="by">sebstefan</span><span>|</span><a href="#41307769">prev</a><span>|</span><a href="#41307524">next</a><span>|</span><label class="collapse" for="c-41307827">[-]</label><label class="expand" for="c-41307827">[2 more]</label></div><br/><div class="children"><div class="content">Is that really what Discord, Whatsapp &amp; co are using to display the embed widgets they have or is it just &lt;meta&gt; tags like I would expect...?</div><br/><div id="41308032" class="c"><input type="checkbox" id="c-41308032" checked=""/><div class="controls bullet"><span class="by">johneth</span><span>|</span><a href="#41307827">parent</a><span>|</span><a href="#41307524">next</a><span>|</span><label class="collapse" for="c-41308032">[-]</label><label class="expand" for="c-41308032">[1 more]</label></div><br/><div class="children"><div class="content">There are several methods they may use:<p>- OpenGraph (by Facebook, probably used by Whatsapp) – <a href="https:&#x2F;&#x2F;ogp.me&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ogp.me&#x2F;</a><p>- Schema.org markup (the main point of this blog) – <a href="https:&#x2F;&#x2F;schema.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;schema.org&#x2F;</a><p>- oEmbed (used to embed media in another page, e.g. YouTube videos on a WordPress blog) – <a href="https:&#x2F;&#x2F;oembed.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;oembed.com&#x2F;</a></div><br/></div></div></div></div><div id="41307524" class="c"><input type="checkbox" id="c-41307524" checked=""/><div class="controls bullet"><span class="by">trainyperson</span><span>|</span><a href="#41307827">prev</a><span>|</span><a href="#41308016">next</a><span>|</span><label class="collapse" for="c-41307524">[-]</label><label class="expand" for="c-41307524">[2 more]</label></div><br/><div class="children"><div class="content">Are there any tools that employ LLMs to <i>fill out</i> the Semantic Web data? I can see that being a high-impact use case: people don’t generally like manually filling out all the fields in a schema (it is indeed “a bother”), but an LLM could fill it out for you – and then you could tweak for correctness &#x2F; editorializing. Voila, bother reduced!<p>This would also address the two reasons why the author thinks AI is not suited to this task:<p>1. human stays in the loop by (ideally) checking the JSON-LD before publishing; so fewer hallucination errors<p>2. LLM compute is limited to one time per published content and it’s done by the publisher. The bots can continue to be low-GPU crawlers just as they are now, since they can traverse the neat and tidy JSON-LD.<p>——————<p>The author makes a good case for The Semantic Web and I’ll be keeping it in mind for the next time I publish something, and in general this will add some nice color to how I think about the web.</div><br/><div id="41307599" class="c"><input type="checkbox" id="c-41307599" checked=""/><div class="controls bullet"><span class="by">safety1st</span><span>|</span><a href="#41307524">parent</a><span>|</span><a href="#41308016">next</a><span>|</span><label class="collapse" for="c-41307599">[-]</label><label class="expand" for="c-41307599">[1 more]</label></div><br/><div class="children"><div class="content">Bringing an LLM into the picture is just silly. There&#x27;s zero need.<p>The author (and much of HN?) seems to be unaware that it&#x27;s not just thousands of websites using JSON-LD, it&#x27;s millions.<p>For example: install WordPress, install an SEO plugin like Yoast, and boom you&#x27;re done. Basic JSON-LD will be generated expressing semantic information about all your blog posts, videos etc. It only takes a few lines of code to extend what shows up by default, and other CMSes support this took.<p>SEOs know all about this topic because Google looks for JSON-LD in your document and it makes a significant difference to how your site is presented in search results as well as all those other fancy UI modules that show up on Google.<p>Anyone who wants to understand how this is working massively, at scale, across millions of websites today, implemented consciously by thousands of businesses, should start here:<p><a href="https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;appearance&#x2F;structured-data&#x2F;intro-structured-data" rel="nofollow">https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;appearance&#x2F;structu...</a><p><a href="https:&#x2F;&#x2F;search.google.com&#x2F;test&#x2F;rich-results" rel="nofollow">https:&#x2F;&#x2F;search.google.com&#x2F;test&#x2F;rich-results</a><p>Is this the &quot;Semantic Web&quot; that was dreamed of in yesteryear? Well it hasn&#x27;t gone as far and as fast as the academics hoped, but does anything?<p>The rudimentary semantic expression is already out there on the Web, deployed at scale today. Someone creative with market pull could easily expand on this e.g. maybe someday a competitor to Google or another Big Tech expands the set of semantic information a bit if it&#x27;s relevant to their business scenarios.<p>It&#x27;s all happening, it&#x27;s just happening in the way that commercial markets make things happen.</div><br/></div></div></div></div><div id="41308016" class="c"><input type="checkbox" id="c-41308016" checked=""/><div class="controls bullet"><span class="by">druskacik</span><span>|</span><a href="#41307524">prev</a><span>|</span><a href="#41307651">next</a><span>|</span><label class="collapse" for="c-41308016">[-]</label><label class="expand" for="c-41308016">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a project [0] that parses Commoncrawl data for various schemas, it contains some interesting datasets.<p>[0] <a href="http:&#x2F;&#x2F;webdatacommons.org&#x2F;" rel="nofollow">http:&#x2F;&#x2F;webdatacommons.org&#x2F;</a></div><br/></div></div><div id="41307651" class="c"><input type="checkbox" id="c-41307651" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#41308016">prev</a><span>|</span><a href="#41307577">next</a><span>|</span><label class="collapse" for="c-41307651">[-]</label><label class="expand" for="c-41307651">[1 more]</label></div><br/><div class="children"><div class="content">Did json-ld get a lot of traction for link previews? I haven&#x27;t really encountered it much.<p>I actually implemented a simple link preview system a while ago. It uses opengraph and twitter cards meta data that is commonly added to web pages for SEO. That works pretty well.<p>Ironically, I did use chat gpt for helping me implement this stuff. It did a pretty good job too. It suggested some libraries I could use and then added some logic to extract titles, descriptions, icons, images, etc. with some fallbacks between various fields people use for those things. It did not suggest me to add logic for json-ld.</div><br/></div></div><div id="41307577" class="c"><input type="checkbox" id="c-41307577" checked=""/><div class="controls bullet"><span class="by">swiftcoder</span><span>|</span><a href="#41307651">prev</a><span>|</span><a href="#41307397">next</a><span>|</span><label class="collapse" for="c-41307577">[-]</label><label class="expand" for="c-41307577">[1 more]</label></div><br/><div class="children"><div class="content">As much as I like the ideas behind the semantic web, JSON-LD feels like the least friendly of all semantic markup options (compared to something like, say, microformats)</div><br/></div></div><div id="41307397" class="c"><input type="checkbox" id="c-41307397" checked=""/><div class="controls bullet"><span class="by">gostsamo</span><span>|</span><a href="#41307577">prev</a><span>|</span><a href="#41307607">next</a><span>|</span><label class="collapse" for="c-41307397">[-]</label><label class="expand" for="c-41307397">[3 more]</label></div><br/><div class="children"><div class="content">So much jumping to defend llms as the future. I&#x27;d like to point that llms hallucinate, could be injected, and often lack context which well structured metadata can provide. At least, I don&#x27;t want for an llm to hollucinate the author&#x27;s picture and bio based on hints in the article, thank you very much.<p>I don&#x27;t think that one is necessarily better than the other, but imagining that llms are a silver bullet when another trending story in the front pages is about prompt injection used against the slack ai bots sounds a bit over optimistic.</div><br/><div id="41307514" class="c"><input type="checkbox" id="c-41307514" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#41307397">parent</a><span>|</span><a href="#41307607">next</a><span>|</span><label class="collapse" for="c-41307514">[-]</label><label class="expand" for="c-41307514">[2 more]</label></div><br/><div class="children"><div class="content">Sure but do hallucinations matter then much just for categorisation? Hardly the end of the world if they make up a published date occasionally.<p>And prompt injection is irrelevant because the alternative we&#x27;re considering is letting publishers directly choose the metadata.</div><br/><div id="41307818" class="c"><input type="checkbox" id="c-41307818" checked=""/><div class="controls bullet"><span class="by">gostsamo</span><span>|</span><a href="#41307397">root</a><span>|</span><a href="#41307514">parent</a><span>|</span><a href="#41307607">next</a><span>|</span><label class="collapse" for="c-41307818">[-]</label><label class="expand" for="c-41307818">[1 more]</label></div><br/><div class="children"><div class="content">Prompt injection is highly relevant because you end up achieving the same as the publisher choosing the metadata, but on a much higher price for the user. Price which needs to be paid by each user separately instead of using one already generated.<p>LLMs are much better when the user adapts the categories to their needs or crunches the text to pull only the info relevant to them. Communicating those categories and the cutoff criteria would be an issue in some contexts, but still better if communication is not the goal. Domain knowledge is also important, because nitch topics are not represented in the llm datasets and their abilities fail in such scenarios.<p>As I said above, one is not necessarily better than the other and it depends on the use cases.</div><br/></div></div></div></div></div></div><div id="41307607" class="c"><input type="checkbox" id="c-41307607" checked=""/><div class="controls bullet"><span class="by">renegat0x0</span><span>|</span><a href="#41307397">prev</a><span>|</span><a href="#41307559">next</a><span>|</span><label class="collapse" for="c-41307607">[-]</label><label class="expand" for="c-41307607">[1 more]</label></div><br/><div class="children"><div class="content">I think that if you want your page to be well discoverable, to be well asvertised, positioned in search engines and social media you have to support standards. Like open graph protocol, or json ld.<p>Be nice to bots. This is advertisment after all.<p>Support standards even if Google does not. Other bots might not be as sofisticated.<p>For me, yes, it is worth the bother</div><br/></div></div><div id="41307171" class="c"><input type="checkbox" id="c-41307171" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#41307559">prev</a><span>|</span><a href="#41307541">next</a><span>|</span><label class="collapse" for="c-41307171">[-]</label><label class="expand" for="c-41307171">[10 more]</label></div><br/><div class="children"><div class="content">In all honesty, llms are probably going to make all this entirely redundant.<p>As such semantic web was not a natural follower to what we had before, and not web 3.0.</div><br/><div id="41307227" class="c"><input type="checkbox" id="c-41307227" checked=""/><div class="controls bullet"><span class="by">peterlk</span><span>|</span><a href="#41307171">parent</a><span>|</span><a href="#41307238">next</a><span>|</span><label class="collapse" for="c-41307227">[-]</label><label class="expand" for="c-41307227">[3 more]</label></div><br/><div class="children"><div class="content">The article addresses this point with the following:<p>&gt; It would of course be possible to sic Chatty-Jeeps on the raw markup and have it extract all of this stuff automatically. But there are some good reasons why not.
&gt; 
&gt; The first is that large language models (LLMs) routinely get stuff wrong. If you want bots to get it right, provide the metadata to ensure that they do.
&gt; 
&gt; The second is that requiring an LLM to read the web is throughly disproportionate and exclusionary. Everyone parsing the web would need to be paying for pricy GPU time to parse out the meaning of the web. It would feel bizarre if &quot;technological progress&quot; meant that fat GPUs were required for computers to read web pages.</div><br/><div id="41307412" class="c"><input type="checkbox" id="c-41307412" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307227">parent</a><span>|</span><a href="#41307869">next</a><span>|</span><label class="collapse" for="c-41307412">[-]</label><label class="expand" for="c-41307412">[1 more]</label></div><br/><div class="children"><div class="content">The first point is moot, because human annotation would also have some amount of error, either through mistakes (interns being paid nothing to add it) or maliciously (SEO). Plus, human annotation would be multi-lingual, which leads to a host of other problems that LLMs don&#x27;t have to the same extent.<p>The second point is silly, because there is no reason for everyone to train their own LLMs on the raw web. You&#x27;d have a few companies or projects that handle the LLM training, and everyone else uses those LLMs.<p>I&#x27;m not a big fan of LLMs, and not even a big believer in their future, but I still think they have a much better chance of being useful for these types of tasks than the semantic web. Semantic web is a dead idea, people should really allow it to rest.</div><br/></div></div><div id="41307869" class="c"><input type="checkbox" id="c-41307869" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307227">parent</a><span>|</span><a href="#41307412">prev</a><span>|</span><a href="#41307238">next</a><span>|</span><label class="collapse" for="c-41307869">[-]</label><label class="expand" for="c-41307869">[1 more]</label></div><br/><div class="children"><div class="content">While both of these points a valid <i>today</i> they are likely going to be invalidated going forward - assume that what you can conceive is technically possible will become technically possible.<p>In 5 years resource price is likely negligible and accuracy is high enough that you just trust it.</div><br/></div></div></div></div><div id="41307238" class="c"><input type="checkbox" id="c-41307238" checked=""/><div class="controls bullet"><span class="by">null_investor</span><span>|</span><a href="#41307171">parent</a><span>|</span><a href="#41307227">prev</a><span>|</span><a href="#41307215">next</a><span>|</span><label class="collapse" for="c-41307238">[-]</label><label class="expand" for="c-41307238">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s HN, most people don&#x27;t read the article and jump into whatever conclusion they have at the moment despite not being an expert in the field.</div><br/><div id="41307882" class="c"><input type="checkbox" id="c-41307882" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307238">parent</a><span>|</span><a href="#41307256">next</a><span>|</span><label class="collapse" for="c-41307882">[-]</label><label class="expand" for="c-41307882">[1 more]</label></div><br/><div class="children"><div class="content">As I already pointed out, none of the arguments the author brings up are really relevant. Resources and accuracy will not be a concern in 5 years.<p>What makes you think that I am not an expert btw?<p>It indeed seems like you appear to believ that what&#x27;s written on the internet is true. So if someone writes that LLMs are not a contester to semantic web - then it might be true.<p>Could it be, that I merely challenge that author of the blog article and don&#x27;t take his predictions for granted?</div><br/></div></div><div id="41307256" class="c"><input type="checkbox" id="c-41307256" checked=""/><div class="controls bullet"><span class="by">xoac</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307238">parent</a><span>|</span><a href="#41307882">prev</a><span>|</span><a href="#41307215">next</a><span>|</span><label class="collapse" for="c-41307256">[-]</label><label class="expand" for="c-41307256">[1 more]</label></div><br/><div class="children"><div class="content">He had it summarized by chatgpt</div><br/></div></div></div></div><div id="41307215" class="c"><input type="checkbox" id="c-41307215" checked=""/><div class="controls bullet"><span class="by">asymmetric</span><span>|</span><a href="#41307171">parent</a><span>|</span><a href="#41307238">prev</a><span>|</span><a href="#41307541">next</a><span>|</span><label class="collapse" for="c-41307215">[-]</label><label class="expand" for="c-41307215">[3 more]</label></div><br/><div class="children"><div class="content">Have you read the article? It addresses this point towards the end.</div><br/><div id="41307497" class="c"><input type="checkbox" id="c-41307497" checked=""/><div class="controls bullet"><span class="by">tannhaeuser</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307215">parent</a><span>|</span><a href="#41307887">next</a><span>|</span><label class="collapse" for="c-41307497">[-]</label><label class="expand" for="c-41307497">[1 more]</label></div><br/><div class="children"><div class="content">And it fails to address why SemWeb failed in its heyday: that there&#x27;s no business case for releasing open data of any kind &quot;on the web&quot; (unless you&#x27;re wikidata or otherwise financed via public money) the only consequence being that 1. you get less clicks 2. you make it easier for your competitors (including Google) to aggregate your data. And that hasn&#x27;t changed with LLMs, quite the opposite.<p>To think a turd such as JSON-LD can save the &quot;SemWeb&quot; (which doesn&#x27;t really exist), and even add CSV as yet another RDF format to appease &quot;JSON scientists&quot; lol seems beyond absurd. Also, Facebook&#x27;s Open Graph annotations in HTML meta-links are&#x2F;were probably the most widespread (trivial) implementation of SemWeb. SemWeb isn&#x27;t terrible but is entirely driven by TBL&#x27;s long-standing enthusiasm for edge-labelled graph-like databases (predating even his WWW efforts eg [1]), plus academia&#x27;s need for topics to produce papers on. It&#x27;s a good thing to let it go in the last decade and re-focus on other&#x2F;classic logic apps such as Prolog and SAT solvers.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENQUIRE" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENQUIRE</a></div><br/></div></div><div id="41307887" class="c"><input type="checkbox" id="c-41307887" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#41307171">root</a><span>|</span><a href="#41307215">parent</a><span>|</span><a href="#41307497">prev</a><span>|</span><a href="#41307541">next</a><span>|</span><label class="collapse" for="c-41307887">[-]</label><label class="expand" for="c-41307887">[1 more]</label></div><br/><div class="children"><div class="content">yes</div><br/></div></div></div></div></div></div><div id="41307541" class="c"><input type="checkbox" id="c-41307541" checked=""/><div class="controls bullet"><span class="by">nox101</span><span>|</span><a href="#41307171">prev</a><span>|</span><a href="#41307963">next</a><span>|</span><label class="collapse" for="c-41307541">[-]</label><label class="expand" for="c-41307541">[1 more]</label></div><br/><div class="children"><div class="content">No ... because the incentives to lie in metadata are too high</div><br/></div></div><div id="41307963" class="c"><input type="checkbox" id="c-41307963" checked=""/><div class="controls bullet"><span class="by">peter_retief</span><span>|</span><a href="#41307541">prev</a><span>|</span><a href="#41307338">next</a><span>|</span><label class="collapse" for="c-41307963">[-]</label><label class="expand" for="c-41307963">[1 more]</label></div><br/><div class="children"><div class="content">Not totally sure if it is needed, nice to have?
RSS feeds are great but seen less and less.</div><br/></div></div><div id="41307338" class="c"><input type="checkbox" id="c-41307338" checked=""/><div class="controls bullet"><span class="by">kkfx</span><span>|</span><a href="#41307963">prev</a><span>|</span><a href="#41307842">next</a><span>|</span><label class="collapse" for="c-41307338">[-]</label><label class="expand" for="c-41307338">[1 more]</label></div><br/><div class="children"><div class="content">Ehm... The semantic web as an idea was&#x2F;is a totally different thing: the idea is the old libraries of Babel&#x2F;Bibliotheca Universalis by Conrad Gessner (~1545) [1] or the ability to &quot;narrow&quot;|&quot;select&quot;|&quot;find&quot; just &quot;the small bit of information I want&quot;. Observing that a book it&#x27;s excellent to develop and share a specific topic, it have some indexes to help directly find specific information but that&#x27;s not enough, a library of books can&#x27;t be traversed quick enough to find a very specific bit of information like when John Smith was born and where.<p>The semantic web original idea was the interconnection of every bit of information in a format a machine can travel for a human, so the human can find any specific bit ever written with little to no effort without having to humanly scan pages of moderately related stuff.<p>We never achieve such goal. Some have tried to be more on the machine side, like WikiData, some have pushed to the extreme the library science SGML idea of universal classification not ended to JSON but all are failures because they are not universal nor easy to &quot;select and assemble specific bit of information&quot; on human queries.<p>LLMs are a, failed, tentative of achieve such result from another way, their hallucinations and slow formation of a model prove their substantial failure, they SEEMS to succeed for a distracted eye perceiving just the wow effect, but they practically fails.<p>Aside the issue with ALL test done on the metadata side of the spectrum so far is simple: in theory we can all be good citizens and carefully label anything, even classify following Dublin Core at al any single page, in practice very few do so, all the rest do not care, or ignoring the classification at all or badly implemented it, and as a result is like an archive with some missing documents, you&#x27;ll always have holes in information breaking the credibility&#x2F;practical usefulness of the tool.<p>Essentially that&#x27;s why we keep using search engines every day, with classic keyword based matches and some extras around. Words are the common denominator for textual information and the larger slice of our information is textual.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bibliotheca_universalis" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bibliotheca_universalis</a></div><br/></div></div><div id="41307842" class="c"><input type="checkbox" id="c-41307842" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#41307338">prev</a><span>|</span><a href="#41307865">next</a><span>|</span><label class="collapse" for="c-41307842">[-]</label><label class="expand" for="c-41307842">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The first is that large language models (LLMs) routinely get stuff wrong. If you want bots to get it right, provide the metadata to ensure that they do.<p>Yet another reason NOT to use the semantic web. I don&#x27;t want to help any LLMs.</div><br/></div></div><div id="41307701" class="c"><input type="checkbox" id="c-41307701" checked=""/><div class="controls bullet"><span class="by">knallfrosch</span><span>|</span><a href="#41307254">prev</a><span>|</span><label class="collapse" for="c-41307701">[-]</label><label class="expand" for="c-41307701">[1 more]</label></div><br/><div class="children"><div class="content">Here I was, thinking the machines would make our lives easier. Now we have to make our websites Reader-Mode friendly, ARIA[1]-labelled, rendered server-side and now semantic web on top, just so that bots and non-visitors can crawl around?<p>[1] This is also something the screen assist software should do, not the publisher.</div><br/></div></div></div></div></div></div></div></body></html>