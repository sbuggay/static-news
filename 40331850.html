<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715504454133" as="style"/><link rel="stylesheet" href="styles.css?v=1715504454133"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/Technion-Kishony-lab/data-to-paper">Show NH: &quot;data-to-paper&quot; - autonomous stepwise LLM-driven research</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>roykishony</span> | <span>13 comments</span></div><br/><div><div id="40332938" class="c"><input type="checkbox" id="c-40332938" checked=""/><div class="controls bullet"><span class="by">sarusso</span><span>|</span><a href="#40332672">next</a><span>|</span><label class="collapse" for="c-40332938">[-]</label><label class="expand" for="c-40332938">[1 more]</label></div><br/><div class="children"><div class="content">The example paper does not mention what type of diabetes it is about - if type 1 or type 2 - and they have very different risk factors.<p>While it’s kind of clear form the context that it’s about type 2, I doubt a paper like this would pass a peer review without stating it explicitly, in particular with respect to the data set that could potentially include both. Rigor is essential in drawing scientific conclusions.<p>I guess this is a good example  about the statistical nature of LLMs outputs (type 2 is the most common) and consequentially their limitations...</div><br/></div></div><div id="40332672" class="c"><input type="checkbox" id="c-40332672" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#40332938">prev</a><span>|</span><a href="#40332250">next</a><span>|</span><label class="collapse" for="c-40332672">[-]</label><label class="expand" for="c-40332672">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You are solely responsible for the entire content of created manuscripts including their rigour, quality, ethics and any other aspect. The process should be overseen and directed by a human-in-the-loop and created manuscripts should be carefully vetted by a domain expert. The process is NOT error-proof and human intervention is necessary to ensure accuracy and the quality of the results.<p>I&#x27;m happy to see this directly stated. Is there any guidance for domain experts on the types of mistakes an LLM will make? The process will be different from vetting a university student&#x27;s paper so they are unlikely to know what to look out for. How often will a domain expert reject generated papers? Given the large vetting burden, does this save any time versus doing the research the traditional way? I&#x27;m honestly wary domain experts won&#x27;t be used, careful review won&#x27;t be performed, and believable AI slop will spread in academic channels that aren&#x27;t ready to weed out these flawed papers. We&#x27;re relying pretty heavily on personal ethics here, right?</div><br/></div></div><div id="40332250" class="c"><input type="checkbox" id="c-40332250" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#40332672">prev</a><span>|</span><a href="#40333019">next</a><span>|</span><label class="collapse" for="c-40332250">[-]</label><label class="expand" for="c-40332250">[2 more]</label></div><br/><div class="children"><div class="content">Most interesting in the omics era. There is a huge gap between massive well structured data and granular use of these data to both develop and test ideas. For one particular family of mice we have about 15 million vectors of phenome data—all of it mappable as genetic loci.<p>A tool to smoothly catalyze “data to paper” or better yet “data to prevention or treatment” is what we need.</div><br/><div id="40332279" class="c"><input type="checkbox" id="c-40332279" checked=""/><div class="controls bullet"><span class="by">roykishony</span><span>|</span><a href="#40332250">parent</a><span>|</span><a href="#40333019">next</a><span>|</span><label class="collapse" for="c-40332279">[-]</label><label class="expand" for="c-40332279">[1 more]</label></div><br/><div class="children"><div class="content">yes that&#x27;s sounds like the type of data that will be fun to try out with data-to-paper! The repo is now open - you&#x27;re welcome to give it a try. 
and happy to hear suggestions for improvements and development directions. 
data-to-treatment
date-to-insights
data-to-prevention
data-to-???</div><br/></div></div></div></div><div id="40333019" class="c"><input type="checkbox" id="c-40333019" checked=""/><div class="controls bullet"><span class="by">Cyphase</span><span>|</span><a href="#40332250">prev</a><span>|</span><a href="#40332694">next</a><span>|</span><label class="collapse" for="c-40333019">[-]</label><label class="expand" for="c-40333019">[1 more]</label></div><br/><div class="children"><div class="content">@dang typo in title (&quot;Show NH&quot;)</div><br/></div></div><div id="40332694" class="c"><input type="checkbox" id="c-40332694" checked=""/><div class="controls bullet"><span class="by">jeffreygoesto</span><span>|</span><a href="#40333019">prev</a><span>|</span><a href="#40332833">next</a><span>|</span><label class="collapse" for="c-40332694">[-]</label><label class="expand" for="c-40332694">[1 more]</label></div><br/><div class="children"><div class="content">But who wants to spend human time to read all that? To me if seems wet should train an AI to do it. Stanislaw Lem predicted that AI goes on such a tangent that we better not interact with it in his book <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Peace_on_Earth_(novel)" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Peace_on_Earth_(novel)</a></div><br/></div></div><div id="40332833" class="c"><input type="checkbox" id="c-40332833" checked=""/><div class="controls bullet"><span class="by">uniqueuid</span><span>|</span><a href="#40332694">prev</a><span>|</span><a href="#40332224">next</a><span>|</span><label class="collapse" for="c-40332833">[-]</label><label class="expand" for="c-40332833">[1 more]</label></div><br/><div class="children"><div class="content">With all the positive comments here, I feel like someone should play the role of the downer.<p>First of all, it&#x27;s inevitable that LLMs will be&#x2F;are used in this way and it&#x27;s great to see development and discussion in the open! That&#x27;s really important.<p>Secondly, this will absolutely destroy some areas of science even more than they have already been.<p>Why? First, science as all of humankind is always a balance between benevolent and malevolent actors. Science already battles data forgery, p-hacking and replication issues. Giving researchers access to tools like this will mean that some conventional quality assurance processes will fail hard. Double-blind peer review will no longer work when there are 10:1 or 100:1 AI generated to high-quality submissions.<p>Second, doing analysis and writing a paper is one bottleneck of science, but epistemologically, it&#x27;s not the important one. There are innumerable ways to analyze extant data and it&#x27;s completely moot to do any analysis in this way. Simmons, Nelson and Simonsohn &#x2F; Gelman et al. etc have shown: Given a dataset, (1) the findings you can get are practically always from very negative effects to very positive effects, depending on the setup of the analysis. So having <i>one</i> analysis is pointless, especially without theory. (2) even when you give really good labs the same data and question, almost nobody will get the same result (many labs experiment).<p>What does this tell us? There are a few parts of science that are extremely important and without them science is not only low-impact, it even has a harmful effect by creating costs for pruning and distilling findings. The really important part are causal analyses, and they practically always involve data collection. That&#x27;s why sciences with strong experimental traditions fare a bit better - when you need to run a costly experiment yourself in order to publish a paper, this creates a strong incentive to think things through and do high-impact research.<p>So yeah, we&#x27;ve seen this coming and it must create a big backlash that prevents this kind of research from being published, even if vetted humans.<p>Source: am a scientist, am a journal editor.</div><br/></div></div><div id="40332224" class="c"><input type="checkbox" id="c-40332224" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40332833">prev</a><span>|</span><a href="#40332437">next</a><span>|</span><label class="collapse" for="c-40332224">[-]</label><label class="expand" for="c-40332224">[2 more]</label></div><br/><div class="children"><div class="content">You can train idea-to-paper models on tons of papers with code. There are many examples of paper impl on github.</div><br/><div id="40332301" class="c"><input type="checkbox" id="c-40332301" checked=""/><div class="controls bullet"><span class="by">roykishony</span><span>|</span><a href="#40332224">parent</a><span>|</span><a href="#40332437">next</a><span>|</span><label class="collapse" for="c-40332301">[-]</label><label class="expand" for="c-40332301">[1 more]</label></div><br/><div class="children"><div class="content">yes - LLMs tuned based on data science publications will be great. need a dataset of papers with reliable and well-performed analysis. 
Notably though it works quite well even with the general purpose LLMs. The key was to break the complex process into smaller steps where results from upstream steps are used downstream. that also creates papers where every downstream result is programmatically linked to upstream data.</div><br/></div></div></div></div><div id="40332437" class="c"><input type="checkbox" id="c-40332437" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#40332224">prev</a><span>|</span><label class="collapse" for="c-40332437">[-]</label><label class="expand" for="c-40332437">[3 more]</label></div><br/><div class="children"><div class="content">&gt; data-to-paper is a framework for systematically navigating the power of AI to perform complete end-to-end scientific research, starting from raw data and concluding with comprehensive, transparent, and human-verifiable scientific papers (example).<p>Even if this thing works I wouldn’t call it “end-to-end scientific research”. IMHO the most challenging and interesting part of scientific research is coming up with a hypothesis and designing an experiment to test it. Data analysis and paper writing is just a small part of the end-to-end process.</div><br/><div id="40332533" class="c"><input type="checkbox" id="c-40332533" checked=""/><div class="controls bullet"><span class="by">rlt</span><span>|</span><a href="#40332437">parent</a><span>|</span><a href="#40332506">next</a><span>|</span><label class="collapse" for="c-40332533">[-]</label><label class="expand" for="c-40332533">[1 more]</label></div><br/><div class="children"><div class="content">The very next paragraph:<p>&gt; Towards this goal, data-to-paper systematically guides interacting LLM and rule-based agents through the conventional scientific path, from annotated data, through <i>creating research hypotheses</i>, conducting literature search, writing and debugging data analysis code, interpreting the results, and ultimately the step-by-step writing of a complete research paper.</div><br/></div></div></div></div></div></div></div></div></div></body></html>