<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721206870077" as="style"/><link rel="stylesheet" href="styles.css?v=1721206870077"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.infoq.com/articles/java-virtual-threads-a-case-study/">Java Virtual Threads: A Case Study</a> <span class="domain">(<a href="https://www.infoq.com">www.infoq.com</a>)</span></div><div class="subtext"><span>mighty_plant</span> | <span>66 comments</span></div><br/><div><div id="40983731" class="c"><input type="checkbox" id="c-40983731" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#40983647">next</a><span>|</span><label class="collapse" for="c-40983731">[-]</label><label class="expand" for="c-40983731">[1 more]</label></div><br/><div class="children"><div class="content">Virtual threads do one thing: they allow creating lots of threads. This helps throughput due to Little&#x27;s law [1]. But because their server saturates the CPU with only a few threads (it does no fanout as modern servers tend to do), this means that no significant improvements can be provided by virtual threads (or asynchronous programming, which operates on the same principle) <i>while keeping everything else in the system the same</i>, especially since everything else in that server was optimised for over two decades under the constraints of expensive threads.<p>Because virtual threads allow handling a higher load per server, they support a potentially more effective and less wasteful -- but <i>different</i> -- deployment. Rather than deploy many instances with fractions of a CPU, deploy fewer, larger instances.<p>So it looks like their goal was: try adopting a new technology without changing any of the aspects designed for an old technology and optimised around it.<p>[1]: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;07V08SB1l8c" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;07V08SB1l8c</a></div><br/></div></div><div id="40983647" class="c"><input type="checkbox" id="c-40983647" checked=""/><div class="controls bullet"><span class="by">davidtos</span><span>|</span><a href="#40983731">prev</a><span>|</span><a href="#40983054">next</a><span>|</span><label class="collapse" for="c-40983647">[-]</label><label class="expand" for="c-40983647">[1 more]</label></div><br/><div class="children"><div class="content">I did some similar testing a few days ago[1]. Comparing platform threads to virtual threads doing API calls. They mention the right conditions like having high task delays, but it also depends on what the task is. Threads.sleep(1) performs better on virtual threads than platform threads but a rest call taking a few ms performs worse.<p>[1] <a href="https:&#x2F;&#x2F;davidvlijmincx.com&#x2F;posts&#x2F;virtual-thread-performance-api-calls&#x2F;" rel="nofollow">https:&#x2F;&#x2F;davidvlijmincx.com&#x2F;posts&#x2F;virtual-thread-performance-...</a></div><br/></div></div><div id="40983054" class="c"><input type="checkbox" id="c-40983054" checked=""/><div class="controls bullet"><span class="by">taspeotis</span><span>|</span><a href="#40983647">prev</a><span>|</span><a href="#40983541">next</a><span>|</span><label class="collapse" for="c-40983054">[-]</label><label class="expand" for="c-40983054">[11 more]</label></div><br/><div class="children"><div class="content">My rough understanding is that this is similar to async&#x2F;await in .NET?<p>It’s a shame this article paints a neutral (or even negative) experience with virtual threads.<p>We rewrote a boring CRUD app that spent 99% of its time waiting the database to respond to be async&#x2F;await from top-to-bottom. CPU and memory usage went way down on the web server because so many requests could be handled by far fewer threads.</div><br/><div id="40983101" class="c"><input type="checkbox" id="c-40983101" checked=""/><div class="controls bullet"><span class="by">jsiepkes</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983637">next</a><span>|</span><label class="collapse" for="c-40983101">[-]</label><label class="expand" for="c-40983101">[1 more]</label></div><br/><div class="children"><div class="content">&gt; My rough understanding is that this is similar to async&#x2F;await in .NET?<p>Well somewhat but also not really. They are green threads like async&#x2F;await, but it&#x27;s use is more transparent, unlike async&#x2F;await.<p>So there are no special &quot;async methods&quot;. You just instantiate a &quot;VirtualThread&quot; where you normally instantiate a (kernel) &quot;Thread&quot; and then use it like any other (kernel) thread. This works because for example all blocking IO API will be automatically converted to non-blocking IO underwater.</div><br/></div></div><div id="40983637" class="c"><input type="checkbox" id="c-40983637" checked=""/><div class="controls bullet"><span class="by">peteri</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983101">prev</a><span>|</span><a href="#40983202">next</a><span>|</span><label class="collapse" for="c-40983637">[-]</label><label class="expand" for="c-40983637">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a different model. Microsoft did work on green threads a while ago and decided against continuing.<p>Links:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtimelab&#x2F;issues&#x2F;2398">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtimelab&#x2F;issues&#x2F;2398</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtimelab&#x2F;blob&#x2F;feature&#x2F;green-threads&#x2F;docs&#x2F;design&#x2F;features&#x2F;greenthreads.md">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtimelab&#x2F;blob&#x2F;feature&#x2F;green-thre...</a></div><br/><div id="40983795" class="c"><input type="checkbox" id="c-40983795" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40983054">root</a><span>|</span><a href="#40983637">parent</a><span>|</span><a href="#40983202">next</a><span>|</span><label class="collapse" for="c-40983795">[-]</label><label class="expand" for="c-40983795">[1 more]</label></div><br/><div class="children"><div class="content">It should be pointed out, that the main reason they didn&#x27;t go further was because of added complexity in .NET, when async&#x2F;await already exists.<p>&gt; Green threads introduce a completely new async programming model. The interaction between green threads and the existing async model is quite complex for .NET developers. For example, invoking async methods from green thread code requires a sync-over-async code pattern that is a very poor choice if the code is executed on a regular thread.<p>Also to note that even the current model is complex enough to warrant a FAQ,<p><a href="https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;dotnet&#x2F;configureawait-faq" rel="nofollow">https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;dotnet&#x2F;configureawait-faq</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;davidfowl&#x2F;AspNetCoreDiagnosticScenarios&#x2F;blob&#x2F;master&#x2F;AsyncGuidance.md">https:&#x2F;&#x2F;github.com&#x2F;davidfowl&#x2F;AspNetCoreDiagnosticScenarios&#x2F;b...</a></div><br/></div></div></div></div><div id="40983202" class="c"><input type="checkbox" id="c-40983202" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983637">prev</a><span>|</span><a href="#40983335">next</a><span>|</span><label class="collapse" for="c-40983202">[-]</label><label class="expand" for="c-40983202">[3 more]</label></div><br/><div class="children"><div class="content">&gt; My rough understanding is that this is similar to async&#x2F;await in .NET?<p>Not really. What C# does is sort of similar but it has the disadvantages of splitting your code ecosystem into non-blocking&#x2F;blocking code. This means you can “accidentally” start your non-blocking code. Something which may cause your relatively simple API to consume a ridiculous amount of resources. It also makes it much more complicated to update and maintain your code as it grows over the years. What is perhaps worse is that C# lacks an interruption model.<p>Java’s approach is much more modern but then it kind of had to be because the JVM already supported structured concurrency from Kotlin. Which means that Java’s “async&#x2F;await” had to work in a way which wouldn’t break what was already there. Because Java is like that.<p>I think you can sort of view it as another example of how Java has overtaken C# (for now), but I imagine C# will get an improved async&#x2F;await model in the next couple of years. Neither approach is something you would actually chose if concurrency is important to what you build and you don’t have a legacy reason to continue to build on Java&#x2F;C# . This is because Go or Erlang would be the obvious choice, but it’s nice that you at least have the option if your organisation is married to a specific language.</div><br/><div id="40983655" class="c"><input type="checkbox" id="c-40983655" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#40983054">root</a><span>|</span><a href="#40983202">parent</a><span>|</span><a href="#40983263">next</a><span>|</span><label class="collapse" for="c-40983655">[-]</label><label class="expand" for="c-40983655">[1 more]</label></div><br/><div class="children"><div class="content">Maybe C# is going to have a new asynv await model but the fragmentation of libs and codes cannot be undone probably.<p>Java has the power that they make relatively more decisions about the language and the libs that they don’t have to fix later. That’s a great value if you’re not building throw-away software but SaaS or something that has to live long.</div><br/></div></div><div id="40983263" class="c"><input type="checkbox" id="c-40983263" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#40983054">root</a><span>|</span><a href="#40983202">parent</a><span>|</span><a href="#40983655">prev</a><span>|</span><a href="#40983335">next</a><span>|</span><label class="collapse" for="c-40983263">[-]</label><label class="expand" for="c-40983263">[1 more]</label></div><br/><div class="children"><div class="content">From what I recall, and this is a while ago so bare with me, Java Virtual Threads still have a lot of pitfalls where the promise of concurrency isn&#x27;t really fulfilled.<p>I seem to remember that is was some pretty basic operations (like maybe read or something) that caused the thread not to unmount, and therefore just block the underlying os thread. At that point you&#x27;ve just invented the world&#x27;s most complicated thread pool.</div><br/></div></div></div></div><div id="40983335" class="c"><input type="checkbox" id="c-40983335" checked=""/><div class="controls bullet"><span class="by">he0001</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983202">prev</a><span>|</span><a href="#40983312">next</a><span>|</span><label class="collapse" for="c-40983335">[-]</label><label class="expand" for="c-40983335">[2 more]</label></div><br/><div class="children"><div class="content">&gt; My rough understanding is that this is similar to async&#x2F;await in .NET?<p>The biggest difference is that C# async&#x2F;await code is rewritten by the compiler to be able to be async. This means that you see artifacts in the stack that weren’t there when you wrote the code.<p>There are no rewrites with virtual threads and the code is presented on the stack just as you write it.<p>They solve the same problem but in very different ways.</div><br/><div id="40983408" class="c"><input type="checkbox" id="c-40983408" checked=""/><div class="controls bullet"><span class="by">pansa2</span><span>|</span><a href="#40983054">root</a><span>|</span><a href="#40983335">parent</a><span>|</span><a href="#40983312">next</a><span>|</span><label class="collapse" for="c-40983408">[-]</label><label class="expand" for="c-40983408">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>They solve the same problem but in very different ways.</i><p>Yes. Async&#x2F;await is stackless, which leads to the “coloured functions” problem (because it can only suspend function calls one-by-one). Threads are stackful (the whole stack can be suspended at once), which avoids the issue.</div><br/></div></div></div></div><div id="40983312" class="c"><input type="checkbox" id="c-40983312" checked=""/><div class="controls bullet"><span class="by">kimi</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983335">prev</a><span>|</span><a href="#40983291">next</a><span>|</span><label class="collapse" for="c-40983312">[-]</label><label class="expand" for="c-40983312">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more like Erlang threads - they appear to be blocking, so existing code will work with zero changes. But you can create a gazillion of them.</div><br/></div></div><div id="40983291" class="c"><input type="checkbox" id="c-40983291" checked=""/><div class="controls bullet"><span class="by">xxs</span><span>|</span><a href="#40983054">parent</a><span>|</span><a href="#40983312">prev</a><span>|</span><a href="#40983541">next</a><span>|</span><label class="collapse" for="c-40983291">[-]</label><label class="expand" for="c-40983291">[1 more]</label></div><br/><div class="children"><div class="content">&gt;My rough understanding is that this is similar to async&#x2F;await in .NET?<p>No, the I&#x2F;O is still blocking with respect to the application code.</div><br/></div></div></div></div><div id="40983541" class="c"><input type="checkbox" id="c-40983541" checked=""/><div class="controls bullet"><span class="by">LinXitoW</span><span>|</span><a href="#40983054">prev</a><span>|</span><a href="#40983262">next</a><span>|</span><label class="collapse" for="c-40983541">[-]</label><label class="expand" for="c-40983541">[2 more]</label></div><br/><div class="children"><div class="content">From my very limited exposure to virtual threads and the older solution (thread pools), the biggest hurdle was the extensive use of ThreadLocals by most popular libraries.<p>In one project I had to basically turn a reactive framework into a one thread per request framework, because passing around the MDC (a kv map of extra logging information) was a horrible pain. Getting it to actually jump ship from thread to thread AND deleting it at the correct time was basically impossible.<p>Has that improved yet?</div><br/><div id="40983677" class="c"><input type="checkbox" id="c-40983677" checked=""/><div class="controls bullet"><span class="by">bberrry</span><span>|</span><a href="#40983541">parent</a><span>|</span><a href="#40983262">next</a><span>|</span><label class="collapse" for="c-40983677">[-]</label><label class="expand" for="c-40983677">[1 more]</label></div><br/><div class="children"><div class="content">If you are already in a reactive framework, why would you change to virtual threads? Those frameworks pool threads and have their own event loop so I would say they are not suitable for virtual thread migration.</div><br/></div></div></div></div><div id="40983262" class="c"><input type="checkbox" id="c-40983262" checked=""/><div class="controls bullet"><span class="by">pansa2</span><span>|</span><a href="#40983541">prev</a><span>|</span><a href="#40982545">next</a><span>|</span><label class="collapse" for="c-40983262">[-]</label><label class="expand" for="c-40983262">[3 more]</label></div><br/><div class="children"><div class="content">Are these Virtual Threads the feature that was previously known as “Project Loom”? Lightweight threads, more-or-less equivalent to Go’s goroutines?</div><br/><div id="40983332" class="c"><input type="checkbox" id="c-40983332" checked=""/><div class="controls bullet"><span class="by">giamma</span><span>|</span><a href="#40983262">parent</a><span>|</span><a href="#40983323">next</a><span>|</span><label class="collapse" for="c-40983332">[-]</label><label class="expand" for="c-40983332">[1 more]</label></div><br/><div class="children"><div class="content">Yes, at EclipseCon 2022 an Oracle manager working on the Helidon framework presented their results replacing the Helidon core, which was based on Netty (and reactive programming) with Virtual Threads (using imperative programming). [1].<p>Unfortunately the slides from that presentation were not uploaded to the conference site, but this article summarizes [2] the most significant metrics. The Oracle guy claimed that by using Virtual Threads Oracle was able to implement, using imperative Java, a new engine for Helidon (called Nima) that had identical performance to the old engine based on Netty, which is (at least in Oracle&#x27;s opinion) the top performing reactive HTTP engine.<p>The conclusion of the presentation was that based on Oracle&#x27;s experience imperative code is much easier to write, read and maintain with respect to reactive code. Given the identical performance achieved with Virtual Threads,  Oracle was going to abandon reactive programming in favor of imperative programming and virtual threads in all its products.<p>[1] <a href="https:&#x2F;&#x2F;www.eclipsecon.org&#x2F;2022&#x2F;sessions&#x2F;helidon-nima-loom-based-microservices-framework" rel="nofollow">https:&#x2F;&#x2F;www.eclipsecon.org&#x2F;2022&#x2F;sessions&#x2F;helidon-nima-loom-b...</a><p>[2] <a href="https:&#x2F;&#x2F;medium.com&#x2F;helidon&#x2F;helidon-n%C3%ADma-helidon-on-virtual-threads-130bb2ea2088" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;helidon&#x2F;helidon-n%C3%ADma-helidon-on-virt...</a></div><br/></div></div><div id="40983323" class="c"><input type="checkbox" id="c-40983323" checked=""/><div class="controls bullet"><span class="by">Skinney</span><span>|</span><a href="#40983262">parent</a><span>|</span><a href="#40983332">prev</a><span>|</span><a href="#40982545">next</a><span>|</span><label class="collapse" for="c-40983323">[-]</label><label class="expand" for="c-40983323">[1 more]</label></div><br/><div class="children"><div class="content">Yes</div><br/></div></div></div></div><div id="40982545" class="c"><input type="checkbox" id="c-40982545" checked=""/><div class="controls bullet"><span class="by">exabrial</span><span>|</span><a href="#40983262">prev</a><span>|</span><a href="#40983186">next</a><span>|</span><label class="collapse" for="c-40982545">[-]</label><label class="expand" for="c-40982545">[41 more]</label></div><br/><div class="children"><div class="content">What is the virtual thread &#x2F; event loop pattern seeking to optimize? Is it context switching?<p>A number of years ago I remember trying to have a sane discussion about “non blocking” and I remember  saying “something” will block eventually no matter what… anything from the buffer being full on the NIC to your cpu being at anything less than 100%. Does it shake out to any real advantage?</div><br/><div id="40982768" class="c"><input type="checkbox" id="c-40982768" checked=""/><div class="controls bullet"><span class="by">gregopet</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982970">next</a><span>|</span><label class="collapse" for="c-40982768">[-]</label><label class="expand" for="c-40982768">[11 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a brave attempt to release the programmer from worrying or even thinking about thread pools and blocking code. Java has gone all in - they even cancelled a non-blocking rewrite of their database driver architecture because why have that if you won&#x27;t have to worry about blocking code? And the JVM really is a marvel of engineering, it&#x27;s really really good at what it does, so what team to better pull this off?<p>So far, they&#x27;re not quite there yet: the issue of &quot;thread pinning&quot; is something developers still have to be aware of. I hear the newest JVM version has removed a few more cases where it happens, but will we ever truly 100% not have to care about all that anymore?<p>I have to say things are already pretty awesome however. If you avoid the few thread pinning causes (and can avoid libraries that use them - although most of not all modern libraries have already adapted), you can write really clean code. We had to rewrite an old app that made a huge mess tracking a process where multiple event sources can act independently, and virtual threads seemed the perfect thing for it. Now our business logic looks more like a game loop and not the complicated mix of pollers, request handlers, intermediate state persisters (with their endless thirst for various mappers) and whatnot that it was before (granted, all those things weren&#x27;t there just because of threading.. the previous version was really really shitily written).<p>It&#x27;s true that virtual threads sometimes hurt performance (since their main benefit is cleaner simpler code). Not by much, usually, but a precisely written and carefully tuned piece of performance critical code can often still do things better than automatic threading code. And as a fun aside, some very popular libraries assumed the developer is using thread pools (before virtual threads, which non trivial Java app didn&#x27;t? - ok nobody answer that, I&#x27;m sure there are cases :D) so these libraries had performance tricks (ab)using thread pool code specifics. So that&#x27;s another possible performance issue with virtual threads - like always with performance of course: don&#x27;t just assume, try it and measure! :P</div><br/><div id="40983508" class="c"><input type="checkbox" id="c-40983508" checked=""/><div class="controls bullet"><span class="by">pragmatick</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982768">parent</a><span>|</span><a href="#40982818">next</a><span>|</span><label class="collapse" for="c-40983508">[-]</label><label class="expand" for="c-40983508">[1 more]</label></div><br/><div class="children"><div class="content">&gt; although most of not all modern libraries have already adapted<p>Unfortunately kafka, for example, has not: <a href="https:&#x2F;&#x2F;github.com&#x2F;spring-projects&#x2F;spring-kafka&#x2F;commit&#x2F;ae775d804f82483f99d4cab2a16ef2b27649252a">https:&#x2F;&#x2F;github.com&#x2F;spring-projects&#x2F;spring-kafka&#x2F;commit&#x2F;ae775...</a></div><br/></div></div><div id="40982818" class="c"><input type="checkbox" id="c-40982818" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982768">parent</a><span>|</span><a href="#40983508">prev</a><span>|</span><a href="#40982970">next</a><span>|</span><label class="collapse" for="c-40982818">[-]</label><label class="expand" for="c-40982818">[9 more]</label></div><br/><div class="children"><div class="content">So... What is it seeking to optimize? Why did you need a thread pool before but not any more? What resource was exhausted to prevent you from putting every request on a thread?</div><br/><div id="40983081" class="c"><input type="checkbox" id="c-40983081" checked=""/><div class="controls bullet"><span class="by">gregopet</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982818">parent</a><span>|</span><a href="#40983092">next</a><span>|</span><label class="collapse" for="c-40983081">[-]</label><label class="expand" for="c-40983081">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s mainly trying to make you not worry about how many threads you create (and not worry about the caveats that come with optimising how many threads you create, which is something you are very often forced to do).<p>You can create a thread in your code and not worry whether that thing will then be some day run in a huge loop or receive thousands of requests and therefore spend all your memory on thread overhead. Go and other languages (in Java&#x27;s ecosystem there&#x27;s Kotlin for example) employ similar mechanisms to avoid native thread overhead, but you have to think about them. Like, there&#x27;s tutorial code where everything is nice &amp; simple, and then there&#x27;s real world code where a lot of it must run in these special constructs that may have little to do with what you saw in those first &quot;Hello, world&quot; samples.<p>Java&#x27;s approach tries to erase the difference between virtual and real threads. The programmer should have to employ no special techniques when using virtual threads and should be able to use everything the language has to offer (this isn&#x27;t true in many languages&#x27; virtual&#x2F;green threads implementations). Old libraries should continue working and perhaps not even be aware they&#x27;re being run on virtual threads (although, caveats do apply for low level&#x2F;high performance stuff, see above posts). And libraries that you interact with don&#x27;t have to care what &quot;model&quot; of green threading you&#x27;re using or specifically expose &quot;red&quot; and &quot;blue&quot; functions.</div><br/><div id="40983375" class="c"><input type="checkbox" id="c-40983375" checked=""/><div class="controls bullet"><span class="by">giamma</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983081">parent</a><span>|</span><a href="#40983092">next</a><span>|</span><label class="collapse" for="c-40983375">[-]</label><label class="expand" for="c-40983375">[3 more]</label></div><br/><div class="children"><div class="content">You will still have to worry, too many virtual threads will imply too much context switching. However, virtual threads will be always interruptable on I&#x2F;O, as they are not mapped to actual o.s. threads, but rather simulated by the JVM which will executed a number of instructions for each virtual thread.<p>This gives the chance to the JVM to use real threads more efficiently, avoiding that threads remain unused while waiting on I&#x2F;O (e.g. a response from a stream). As soon as the JVM detects that a physical thread is blocked on I&#x2F;O, a semaphore, a lock or anything, it will reallocate that physical thread to running a new virtual thread. This will reduce latency, context switch time (the switching is done by the JVM that already globally manages the memory of the Java process in its heap) and will avoid or at least largely reduce the chance that a real thread remains allocated but idle as it&#x27;s blocked on I&#x2F;O or something else.</div><br/><div id="40983474" class="c"><input type="checkbox" id="c-40983474" checked=""/><div class="controls bullet"><span class="by">frant-hartm</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983375">parent</a><span>|</span><a href="#40983092">next</a><span>|</span><label class="collapse" for="c-40983474">[-]</label><label class="expand" for="c-40983474">[2 more]</label></div><br/><div class="children"><div class="content">What do you mean by context switching?<p>My understanding is that virtual threads mostly eliminate context switching - for N CPUs JVM creates N platform threads and they run virtual threads as needed. There is no real context switching apart from GC and other JVM internal threads.<p>A platform thread picking another virtual thread to run after its current virtual thread is blocked on IO is not a context switch, that is an expensive OS-level operation.</div><br/><div id="40983799" class="c"><input type="checkbox" id="c-40983799" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983474">parent</a><span>|</span><a href="#40983092">next</a><span>|</span><label class="collapse" for="c-40983799">[-]</label><label class="expand" for="c-40983799">[1 more]</label></div><br/><div class="children"><div class="content">Does Java&#x27;s implementation of virtual threads perform any kind of work stealing when a particular physical thread has no virtual threads to run (e.g. they are all blocked on I&#x2F;O)?</div><br/></div></div></div></div></div></div></div></div><div id="40983092" class="c"><input type="checkbox" id="c-40983092" checked=""/><div class="controls bullet"><span class="by">chipdart</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982818">parent</a><span>|</span><a href="#40983081">prev</a><span>|</span><a href="#40982919">next</a><span>|</span><label class="collapse" for="c-40983092">[-]</label><label class="expand" for="c-40983092">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So... What is it seeking to optimize?<p>The goal is to maximize the number of tasks you can run concurrently, while imposing on the developers a low cognitive load to write and maintain the code.<p>&gt; Why did you need a thread pool before but not any more?<p>You still need a thread pool. Except with virtual threads you are no longer bound to run a single task per thread. This is specially desirable when workloads are IO-bound and will expectedly idle while waiting for external events. If you have a never-ending queue of tasks waiting to run, why should you block a thread consuming that task queue by running a task that stays idle while waiting for something to happen? You&#x27;re better off starting the task and setting it aside the moment it awaits for something to happen.<p>&gt; What resource was exhausted to prevent you from putting every request on a thread?</div><br/></div></div><div id="40982919" class="c"><input type="checkbox" id="c-40982919" checked=""/><div class="controls bullet"><span class="by">jmaker</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982818">parent</a><span>|</span><a href="#40983092">prev</a><span>|</span><a href="#40982955">next</a><span>|</span><label class="collapse" for="c-40982919">[-]</label><label class="expand" for="c-40982919">[1 more]</label></div><br/><div class="children"><div class="content">Briefly: The cost of spawning schedulable entities, memory and the time to execution. Virtual threads, i.e., fibers, entertain lightweight stacks. You can spawn as many as you like immediately. Your runtime system won’t go out of memory as easily. In addition, the spawning happens much faster in user space. You’re not creating kernel threads, which is a limited and not cheap resource, whence the pooling you’re comparing it to. With virtual threads you can do thread per request explicitly. It makes most sense for IO-bound tasks.</div><br/></div></div><div id="40982955" class="c"><input type="checkbox" id="c-40982955" checked=""/><div class="controls bullet"><span class="by">gifflar</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982818">parent</a><span>|</span><a href="#40982919">prev</a><span>|</span><a href="#40982906">next</a><span>|</span><label class="collapse" for="c-40982955">[-]</label><label class="expand" for="c-40982955">[1 more]</label></div><br/><div class="children"><div class="content">This article nicely describes the differences between  threads and virtual threads: <a href="https:&#x2F;&#x2F;www.infoq.com&#x2F;articles&#x2F;java-virtual-threads&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.infoq.com&#x2F;articles&#x2F;java-virtual-threads&#x2F;</a><p>I think it’s definitely worth a read.</div><br/></div></div><div id="40982906" class="c"><input type="checkbox" id="c-40982906" checked=""/><div class="controls bullet"><span class="by">davidgay</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982818">parent</a><span>|</span><a href="#40982955">prev</a><span>|</span><a href="#40982970">next</a><span>|</span><label class="collapse" for="c-40982906">[-]</label><label class="expand" for="c-40982906">[1 more]</label></div><br/><div class="children"><div class="content">A thread per request has a high risk of overcommitting on CPU use, leading to a different set of problems. Virtual threads are scheduled on a fixed-size (based on number of cores) underlying (non-virtual) thread pool to avoid this problem.</div><br/></div></div></div></div></div></div><div id="40982970" class="c"><input type="checkbox" id="c-40982970" checked=""/><div class="controls bullet"><span class="by">chipdart</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982768">prev</a><span>|</span><a href="#40982625">next</a><span>|</span><label class="collapse" for="c-40982970">[-]</label><label class="expand" for="c-40982970">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What is the virtual thread &#x2F; event loop pattern seeking to optimize? Is it context switching?<p>Throughput.<p>Some workloads are not CPU-bound or memory-bound, and spend the bulk of their time waiting for external processes to make data available.<p>If your workloads are expected to stay idle while waiting for external events, you can switch to other tasks while you wait for those external events to trigger.<p>This is particularly convenient if the other tasks you&#x27;re hoping to run are also tasks that are bound to stay idle while waiting for external events.<p>One of the textbook scenarios that suits this pattern well is making HTTP requests. Another one is request handlers, such as the controller pattern used so often in HTTP servers.<p>Perhaps the poster child of this pattern is Node.js. It might not be the performance king and might be single-threaded, but it features in the top spots in performance benchmarks such as TechEmpower&#x27;s. Node.js is also highly favoured in function-as-a-service applications, as it&#x27;s event-driven architecture is well suited for applications involving a hefty dose of network calls running on memory- and CPU-constrained systems.</div><br/></div></div><div id="40982625" class="c"><input type="checkbox" id="c-40982625" checked=""/><div class="controls bullet"><span class="by">fzeindl</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982970">prev</a><span>|</span><a href="#40982931">next</a><span>|</span><label class="collapse" for="c-40982625">[-]</label><label class="expand" for="c-40982625">[11 more]</label></div><br/><div class="children"><div class="content">Does it shake out to any real advantage?<p>To put it shortly: Writing single-threaded blocking code is far easier for most people and has many other benefits, like more understandable and readable programs: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=449j7oKQVkc" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=449j7oKQVkc</a><p>The main reason why non-blocking IO with it&#x27;s style of intertwining concurrency and algorithms came along is that starting a thread for every request was too expensive. With virtual threads that problem is eliminated so we can go back to writing blocking code.</div><br/><div id="40982828" class="c"><input type="checkbox" id="c-40982828" checked=""/><div class="controls bullet"><span class="by">nlitened</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982625">parent</a><span>|</span><a href="#40983048">next</a><span>|</span><label class="collapse" for="c-40982828">[-]</label><label class="expand" for="c-40982828">[7 more]</label></div><br/><div class="children"><div class="content">&gt; is far easier for most people<p>I’d say that writing single-threaded code is far easier for _all_ people, even async code experts :)<p>Also, single-threaded code is supported by programming language facilities: you have a proper call stack, thread-local vars, exceptions bubbling up, structured concurrency, simple resource management (RAII, try-with-resources, defer). Easy to reason and debug on language level.<p>Async runtimes are always complicated, filled with leaky abstractions, it’s like another language that one has to learn in addition, but with a less thought-out, ad-hoc design. Difficult to reason and debug, especially in edge cases</div><br/><div id="40983043" class="c"><input type="checkbox" id="c-40983043" checked=""/><div class="controls bullet"><span class="by">bheadmaster</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982828">parent</a><span>|</span><a href="#40983311">next</a><span>|</span><label class="collapse" for="c-40983043">[-]</label><label class="expand" for="c-40983043">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Async runtimes are always complicated, filled with leaky abstractions, it’s like another language that one has to learn in addition, but with a less thought-out, ad-hoc design. Difficult to reason and debug, especially in edge cases<p>Async runtimes themselves are simply attempts to bolt-on green threads on top of a language that doesn&#x27;t support them on a language level. In JavaScript, async&#x2F;await uses Promises to enable callback-code to interact with key language features like try&#x2F;catch, for&#x2F;while&#x2F;break, return, etc. In Python, async&#x2F;await is just syntax sugar for coroutines, which are again just syntax sugar for CPS-style classes with methods split at each &quot;yield&quot;. Not sure about Rust, but it probably also uses some Rust macro magic to do something similar.</div><br/><div id="40983733" class="c"><input type="checkbox" id="c-40983733" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983043">parent</a><span>|</span><a href="#40983264">next</a><span>|</span><label class="collapse" for="c-40983733">[-]</label><label class="expand" for="c-40983733">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Not sure about Rust, but it probably also uses some Rust macro magic to do something similar.<p>Much the same as JavaScript I understand, but no macros; the compiler turns them into Futures that can be polled</div><br/></div></div><div id="40983264" class="c"><input type="checkbox" id="c-40983264" checked=""/><div class="controls bullet"><span class="by">derriz</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983043">parent</a><span>|</span><a href="#40983733">prev</a><span>|</span><a href="#40983161">next</a><span>|</span><label class="collapse" for="c-40983264">[-]</label><label class="expand" for="c-40983264">[1 more]</label></div><br/><div class="children"><div class="content">Indeed.  Async runtimes&#x2F;sytles are attempts to provide a more readable&#x2F;useable syntax for  CPS[1].  CPS originally had nothing to do with blocking&#x2F;non-blocking or multi-threading but arose as a technique to structure compiler code.<p>Its attraction for non-blocking coding is that it allows hiding the multi-threaded event dispatching loop.  But as the parent comment suggests, this abstraction is extremely leaky.  And in addition, CPS in non-functional languages or without syntactic sugar has poor readability.  Improving the readability requires compiler changes in the host language - so many languages have added compiler support to further hide the CPS underpinnings of their async model.<p>I&#x27;ve always felt this was a big mistake in our industry - all this effort not only in compilers but also in debuggers&#x2F;IDE - building on a leaky abstraction.  Adding more layers of leaky abstractions has only made the issue worse.  Async code, at first glance, looks simple but is a minefield for inexperienced&#x2F;non-professional software engineers.<p>It&#x27;s annoying that Rust switched to async style - the abstraction leakiness  immediately hits you, as the &quot;hidden event dispatching loop&quot; remains a real dependency even if it&#x27;s not explicit in the code.  Thus libraries using asycn cannot generally be used together although last time i looked, tokio seems to have become the de-facto standard.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Continuation-passing_style" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Continuation-passing_style</a></div><br/></div></div><div id="40983161" class="c"><input type="checkbox" id="c-40983161" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983043">parent</a><span>|</span><a href="#40983264">prev</a><span>|</span><a href="#40983311">next</a><span>|</span><label class="collapse" for="c-40983161">[-]</label><label class="expand" for="c-40983161">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Async runtimes themselves are simply attempts to bolt-on green threads on top of a language that doesn&#x27;t support them on a language level.<p>Haskell supports async code while also supporting green threads on a language level, and the async code has most of the same issues as async code in any other languages.</div><br/></div></div></div></div><div id="40983311" class="c"><input type="checkbox" id="c-40983311" checked=""/><div class="controls bullet"><span class="by">xxs</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982828">parent</a><span>|</span><a href="#40983043">prev</a><span>|</span><a href="#40983302">next</a><span>|</span><label class="collapse" for="c-40983311">[-]</label><label class="expand" for="c-40983311">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I’d say that writing single-threaded code is far easier for _all_ people, even async code experts :)<p>While &#x27;async&#x27; is just a name, underneath it&#x27;s epoll - and the virtual threads would not perform better than a proper NIO (epoll) server. I dont consider myself an &#x27;async expert&#x27; but I have my share of writing NIO code (dare say not terrible at all)</div><br/></div></div></div></div><div id="40983048" class="c"><input type="checkbox" id="c-40983048" checked=""/><div class="controls bullet"><span class="by">chipdart</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982625">parent</a><span>|</span><a href="#40982828">prev</a><span>|</span><a href="#40983366">next</a><span>|</span><label class="collapse" for="c-40983048">[-]</label><label class="expand" for="c-40983048">[2 more]</label></div><br/><div class="children"><div class="content">&gt; To put it shortly: Writing single-threaded blocking code is far easier for most people and has many other benefits, like more understandable and readable programs:<p>I think you&#x27;re missing the whole point.<p>The reason why so many smart people invest their time on &quot;virtual threads&quot; is developer experience. The goal is to turn writing event-driven concurrent code into something that&#x27;s as easy as writing single-threaded blocking code.<p>Check why C#&#x27;s async&#x2F;await implementation is such a huge success and replaced all past approaches overnight. Check why node.js is such a huge success. Check why Rust&#x27;s async support is such a hot mess. It&#x27;s all about developer experience.</div><br/><div id="40983109" class="c"><input type="checkbox" id="c-40983109" checked=""/><div class="controls bullet"><span class="by">kitd</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983048">parent</a><span>|</span><a href="#40983366">next</a><span>|</span><label class="collapse" for="c-40983109">[-]</label><label class="expand" for="c-40983109">[1 more]</label></div><br/><div class="children"><div class="content">I think he was making the same point as you: writing for virtual threads is like writing for single-threaded blocking code.</div><br/></div></div></div></div><div id="40983366" class="c"><input type="checkbox" id="c-40983366" checked=""/><div class="controls bullet"><span class="by">Nullabillity</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982625">parent</a><span>|</span><a href="#40983048">prev</a><span>|</span><a href="#40982931">next</a><span>|</span><label class="collapse" for="c-40983366">[-]</label><label class="expand" for="c-40983366">[1 more]</label></div><br/><div class="children"><div class="content">&gt; To put it shortly: Writing single-threaded blocking code is far easier for most people. [snip] With virtual threads that problem is eliminated so we can go back to writing blocking code.<p>This is the core misunderstanding&#x2F;dishonesty behind the Loom&#x2F;Virtual Threads hype. Single-threaded blocking code is easy, yes. But that ease comes from being single-threaded, not from not having to await a few Futures.<p>But Loom doesn&#x27;t magically solve the threading problem. It hides the Futures, but that just means that you&#x27;re now writing a multi-threaded program, without the guardrails that modern Future-aware APIs provide. It&#x27;s the worst of all worlds. It&#x27;s the scenario that gave multi-threading such a bad reputation for inscrutable failures in the first place.</div><br/></div></div></div></div><div id="40982931" class="c"><input type="checkbox" id="c-40982931" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982625">prev</a><span>|</span><a href="#40982586">next</a><span>|</span><label class="collapse" for="c-40982931">[-]</label><label class="expand" for="c-40982931">[1 more]</label></div><br/><div class="children"><div class="content">imo the biggest difference between &quot;virtual&quot; threads in a managed runtime and &quot;os&quot; threads is that the latter uses a fixed size stack whereas the former is allowed to resize, it can grow on demand and shrink under pressure.<p>When you spawn an OS thread you are paying at worst the full cost of it, and at best the max depth seen so far in the program, and stack overflows can happen even if the program is written correctly. Whereas a virtual thread can grow the stack to be exactly the size it needs at any point, and when GC runs it can rewrite pointers to any data on the stack safely.<p>Virtual&#x2F;green&#x2F;user space threads aka stackful coroutines have proven to be an excellent tool for scaling concurrency in real programs, while threads and processes have always played catchup.<p>&gt; “something” will block eventually no matter what…<p>The point is to allow <i>everything else</i> to make progress while that resource is busy.<p>---<p>At a broader scale, as a programming model it lets you architect programs that are designed to scale horizontally. With the commodization of compute in the cloud that means it&#x27;s very easy to write a program that can be distributed as i&#x2F;o demand increases. In principle, a &quot;virtual&quot; thread could be spawned on a different machine entirely.</div><br/></div></div><div id="40982586" class="c"><input type="checkbox" id="c-40982586" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982931">prev</a><span>|</span><a href="#40982854">next</a><span>|</span><label class="collapse" for="c-40982586">[-]</label><label class="expand" for="c-40982586">[15 more]</label></div><br/><div class="children"><div class="content">One of the main reasons to do virtual threads is that it allows you to write naive &quot;thread per request&quot; code and still scale up significantly without hitting the kind of scaling limits you would with OS threads.</div><br/><div id="40982639" class="c"><input type="checkbox" id="c-40982639" checked=""/><div class="controls bullet"><span class="by">hashmash</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982586">parent</a><span>|</span><a href="#40982854">next</a><span>|</span><label class="collapse" for="c-40982639">[-]</label><label class="expand" for="c-40982639">[14 more]</label></div><br/><div class="children"><div class="content">The problem with the naïve design is that even with virtual threads, you risk running out of (heap) memory if the threads ever block. Each task makes a bit of progress, allocates some objects, and then lets another one do the same thing.<p>With virtual threads, you can limit the damage by using a semaphore, but you still need to tune the size. This isn&#x27;t much different than sizing a traditional thread pool, and so I&#x27;m not sure what benefit virtual threads will really have in practice. You&#x27;re swapping one config for another.</div><br/><div id="40983004" class="c"><input type="checkbox" id="c-40983004" checked=""/><div class="controls bullet"><span class="by">dikei</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982639">parent</a><span>|</span><a href="#40982829">next</a><span>|</span><label class="collapse" for="c-40983004">[-]</label><label class="expand" for="c-40983004">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The problem with the naïve design is that even with virtual threads, you risk running out of (heap) memory if the threads ever block.<p>The key with virtual threads is they are so light weight that you can have thousands of them running concurrently: even when they block for I&#x2F;O, it doesn&#x27;t matter. It&#x27;s similar to light weight coroutine in other language like Go or Kotlin.</div><br/></div></div><div id="40982829" class="c"><input type="checkbox" id="c-40982829" checked=""/><div class="controls bullet"><span class="by">initplus</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982639">parent</a><span>|</span><a href="#40983004">prev</a><span>|</span><a href="#40982853">next</a><span>|</span><label class="collapse" for="c-40982829">[-]</label><label class="expand" for="c-40982829">[7 more]</label></div><br/><div class="children"><div class="content">The benefits from virtual threads come from the simple API that it presents to the programmer. It&#x27;s not a performance optimization.</div><br/><div id="40982900" class="c"><input type="checkbox" id="c-40982900" checked=""/><div class="controls bullet"><span class="by">hashmash</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982829">parent</a><span>|</span><a href="#40982853">next</a><span>|</span><label class="collapse" for="c-40982900">[-]</label><label class="expand" for="c-40982900">[6 more]</label></div><br/><div class="children"><div class="content">But that same benefit was always available with platform threads -- a simple API. What is the real gain by using virtual threads? It&#x27;s either going to be performance or memory utilization.</div><br/><div id="40983005" class="c"><input type="checkbox" id="c-40983005" checked=""/><div class="controls bullet"><span class="by">groestl</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982900">parent</a><span>|</span><a href="#40983307">next</a><span>|</span><label class="collapse" for="c-40983005">[-]</label><label class="expand" for="c-40983005">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s combining the benefits from async models (state machines separated from os threads, thus more optimal for I&#x2F;O bound workload), with the benefits from proper threading models (namely the simpler human interface).<p>Memory utilization &amp; performance is going to be similar to the async callback mess.</div><br/><div id="40983080" class="c"><input type="checkbox" id="c-40983080" checked=""/><div class="controls bullet"><span class="by">hashmash</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983005">parent</a><span>|</span><a href="#40983307">next</a><span>|</span><label class="collapse" for="c-40983080">[-]</label><label class="expand" for="c-40983080">[3 more]</label></div><br/><div class="children"><div class="content">Why is an async model better than using OS threads for an I&#x2F;O bound workload? The OS is doing async stuff internally and shielding the complexity with threads. With virtual threads this work has shifted to the JVM. Can the JVM do threads better than the OS?</div><br/><div id="40983151" class="c"><input type="checkbox" id="c-40983151" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983080">parent</a><span>|</span><a href="#40983146">next</a><span>|</span><label class="collapse" for="c-40983151">[-]</label><label class="expand" for="c-40983151">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Can the JVM do threads better than the OS?<p>Yes. The JVM has far more opportunities for optimizing threads because it doesn&#x27;t need to uphold 50 years of accumulated invariants and compatibility that current OSes do, and JVM has more visibilty on the application internals.</div><br/></div></div><div id="40983146" class="c"><input type="checkbox" id="c-40983146" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40983080">parent</a><span>|</span><a href="#40983151">prev</a><span>|</span><a href="#40983307">next</a><span>|</span><label class="collapse" for="c-40983146">[-]</label><label class="expand" for="c-40983146">[1 more]</label></div><br/><div class="children"><div class="content">it can do a much better job because there isn&#x27;t a security boundary. OS thread scheduling requires sys calls and invalidate a bunch of cache to prevent timing leaks</div><br/></div></div></div></div></div></div><div id="40983307" class="c"><input type="checkbox" id="c-40983307" checked=""/><div class="controls bullet"><span class="by">lichtenberger</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982900">parent</a><span>|</span><a href="#40983005">prev</a><span>|</span><a href="#40982853">next</a><span>|</span><label class="collapse" for="c-40983307">[-]</label><label class="expand" for="c-40983307">[1 more]</label></div><br/><div class="children"><div class="content">Throughput. The code can be &quot;suspended&quot; on a blocking call (I&#x2F;O, where the platform thread usually is wasted, as the CPU has nothing to do during this time). So, the platform thread can do other work in the meantime.</div><br/></div></div></div></div></div></div><div id="40982853" class="c"><input type="checkbox" id="c-40982853" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982639">parent</a><span>|</span><a href="#40982829">prev</a><span>|</span><a href="#40982822">next</a><span>|</span><label class="collapse" for="c-40982853">[-]</label><label class="expand" for="c-40982853">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, and it&#x27;s generally good to be RAM limited instead of CPU, no? The alternative is blowing a bunch of time on syscalls and OS scheduler overhead.<p>Also the virtual threads run on a &quot;traditional&quot; thread pool to my understanding, so you can just tweak the number of worker threads to cap the total concurrency.<p>The benefit is it&#x27;s overall more efficient (in the general case) and lets you write linear blocking code (as opposed to function coloring). You don&#x27;t have to use it, but it&#x27;s nice that it&#x27;s there. Now hopefully Valhalla actually makes it in eventually</div><br/><div id="40982964" class="c"><input type="checkbox" id="c-40982964" checked=""/><div class="controls bullet"><span class="by">hashmash</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982853">parent</a><span>|</span><a href="#40982822">next</a><span>|</span><label class="collapse" for="c-40982964">[-]</label><label class="expand" for="c-40982964">[3 more]</label></div><br/><div class="children"><div class="content">The OS scheduler is still there (for the carrier threads), but now you&#x27;ve added on top of that FJ pool based scheduler overhead. Although virtual threads don&#x27;t have the syscall overhead when they block, there&#x27;s a new cost caused by allocating the internal continuation object, and copying state into it. This puts more pressure on the garbage collector. Context switching cost due to CPU cache thrashing doesn&#x27;t go away regardless of which type of thread you&#x27;re using.<p>I&#x27;ve not yet seen a study that shows that virtual threads offer a huge benefit. The Open Liberty study suggests that they&#x27;re worse than the existing platform threads.</div><br/><div id="40983656" class="c"><input type="checkbox" id="c-40983656" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982964">parent</a><span>|</span><a href="#40983305">next</a><span>|</span><label class="collapse" for="c-40983656">[-]</label><label class="expand" for="c-40983656">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve not yet seen a study that shows that virtual threads offer a huge benefit.<p>Not exactly Java virtual threads, but a study on how userland threads beat kernel threads.<p><a href="https:&#x2F;&#x2F;cs.uwaterloo.ca&#x2F;~mkarsten&#x2F;papers&#x2F;sigmetrics2020.html" rel="nofollow">https:&#x2F;&#x2F;cs.uwaterloo.ca&#x2F;~mkarsten&#x2F;papers&#x2F;sigmetrics2020.html</a><p>For quick results, check figures 11 and 15 from the (preprint) paper. Userland threads (&quot;fred&quot;) have ~50% higher throughput while having orders of magnitude better latency at high load levels, in a real-world application (memcached).</div><br/></div></div><div id="40983305" class="c"><input type="checkbox" id="c-40983305" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982964">parent</a><span>|</span><a href="#40983656">prev</a><span>|</span><a href="#40982822">next</a><span>|</span><label class="collapse" for="c-40983305">[-]</label><label class="expand" for="c-40983305">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The OS scheduler is still there (for the carrier threads), but now you&#x27;ve added on top of that FJ pool based scheduler overhead.<p>Ideally carrier threads would be pinned to isolated cpu cores, which removes most aspects of OS scheduler from the picture</div><br/></div></div></div></div></div></div><div id="40982822" class="c"><input type="checkbox" id="c-40982822" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#40982545">root</a><span>|</span><a href="#40982639">parent</a><span>|</span><a href="#40982853">prev</a><span>|</span><a href="#40982854">next</a><span>|</span><label class="collapse" for="c-40982822">[-]</label><label class="expand" for="c-40982822">[1 more]</label></div><br/><div class="children"><div class="content">Async does exactly the same by the way.</div><br/></div></div></div></div></div></div><div id="40982854" class="c"><input type="checkbox" id="c-40982854" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#40982545">parent</a><span>|</span><a href="#40982586">prev</a><span>|</span><a href="#40983186">next</a><span>|</span><label class="collapse" for="c-40982854">[-]</label><label class="expand" for="c-40982854">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I remember saying “something” will block eventually no matter what… anything from the buffer being full on the NIC to your cpu being at anything less than 100%.<p>Nope. You can go async all the way down, right to the electrical signals if you want. We usually impose some amount of synchronous clocking&#x2F;polling for sanity, at various levels, but you don&#x27;t have to; the world is not synchronised, the fastest way to respond to a stimulus will always be to respond when it happens.<p>&gt; Does it shake out to any real advantage?<p>Of course it does - did you miss the whole C10K discussions 20+ years ago? Whether it matters for your business is another question, but you can absolutely get a lot more throughput by being nonblocking, and if you&#x27;re doing request-response across the Internet you generally can&#x27;t afford <i>not</i> to.</div><br/></div></div></div></div><div id="40982675" class="c"><input type="checkbox" id="c-40982675" checked=""/><div class="controls bullet"><span class="by">tzahifadida</span><span>|</span><a href="#40983186">prev</a><span>|</span><label class="collapse" for="c-40982675">[-]</label><label class="expand" for="c-40982675">[5 more]</label></div><br/><div class="children"><div class="content">Similarly the power of golang concurrent programming is that you write non-blocking code as you write normal code. You don&#x27;t have to wrap it in functions and pollute the code but moreover, not every coder on the planet knows how to handle blocking code properly and that is the main advantage. Most programming languages can do anything the other languages can do. The problem is that not all coders can make use of it. This is why I see languages like golang as an advantage.</div><br/><div id="40983190" class="c"><input type="checkbox" id="c-40983190" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#40982675">parent</a><span>|</span><a href="#40982898">next</a><span>|</span><label class="collapse" for="c-40983190">[-]</label><label class="expand" for="c-40983190">[3 more]</label></div><br/><div class="children"><div class="content">Kotlin embraced the same thing via co-routines, which are conceptually similar to go routines. It adds a few useful concepts around this though; mainly that of a co-routine context which encapsulates that a tree of co-routine calls needs some notion of failure handling and cancellation. Additionally, co-routines are dispatched to a dispatcher. A dispatcher can be just on the same thread or actually use a thread pool. Or as of recent Java versions a virtual thread pool. There&#x27;s actually very little point in using virtual threads in Kotlin. They are basically a slightly more heavy weight way of doing co-routines. The main benefit is dealing with legacy blocking Java libraries.<p>But the bottom line with virtual threads, go-routines, or kotlin&#x27;s co-routines is that it indeed allows for imperative code style code that is easy to read and understand. Of course you still need to understand all the pitfalls of concurrency bugs and all the weird and wonderful way things can fail to work as you expect. And while Java&#x27;s virtual threads are designed to work like magic pixie dust, it does have some nasty failure modes where a single virtual thread can end up blocking all your virtual threads. Having a lot of synchronized blocks in legacy code could cause that.</div><br/><div id="40983228" class="c"><input type="checkbox" id="c-40983228" checked=""/><div class="controls bullet"><span class="by">tzahifadida</span><span>|</span><a href="#40982675">root</a><span>|</span><a href="#40983190">parent</a><span>|</span><a href="#40982898">next</a><span>|</span><label class="collapse" for="c-40983228">[-]</label><label class="expand" for="c-40983228">[2 more]</label></div><br/><div class="children"><div class="content">Kotlin is not a language I learned so I will avoid commenting.<p>However, the use of JAVA for me is for admin backend or heavy weight services for enterprises or startups I coded for, so for my taste I can&#x27;t use it without spring or jboss, etc.. , and in that way I think simplicity went out the window a long long time ago :) It took me years to learn all the quirks of these frameworks... and the worse thing about it is that they keep changing every few months...</div><br/><div id="40983285" class="c"><input type="checkbox" id="c-40983285" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#40982675">root</a><span>|</span><a href="#40983228">parent</a><span>|</span><a href="#40982898">next</a><span>|</span><label class="collapse" for="c-40983285">[-]</label><label class="expand" for="c-40983285">[1 more]</label></div><br/><div class="children"><div class="content">Kotlin makes a lot of that stuff easier to deal with and there is also a growing number of things that work without Java libraries. Or even the JVM. I use it with Spring Boot. But we also have a lot of kotlin-js code running in a browser. And I use quite a few multiplatform libraries for Kotlin that work pretty much anywhere. I&#x27;ve even written a few myself. It&#x27;s pretty easy to write portable code in Kotlin these days.<p>For example ktor works on the JVM but you can also build native applications with it. And I use ktor client in the browser. When running in the browser it uses the browser fetch API. When running on the jvm you can configure it to use any of a wide range of Java http clients. On native it uses curl.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>