<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710406854150" as="style"/><link rel="stylesheet" href="styles.css?v=1710406854150"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://platform.openai.com/docs/assistants/overview/step-4-create-a-run?context=with-streaming">OpenAI: Streaming is now available in the Assistants API</a>Â <span class="domain">(<a href="https://platform.openai.com">platform.openai.com</a>)</span></div><div class="subtext"><span>jonbraun</span> | <span>64 comments</span></div><br/><div><div id="39701567" class="c"><input type="checkbox" id="c-39701567" checked=""/><div class="controls bullet"><span class="by">zerop</span><span>|</span><a href="#39699147">next</a><span>|</span><label class="collapse" for="c-39701567">[-]</label><label class="expand" for="c-39701567">[1 more]</label></div><br/><div class="children"><div class="content">they should do streaming for voice inputs on the chatgpt app. right now it&#x27;s very slow. Voice interfaces need to be streaming</div><br/></div></div><div id="39699147" class="c"><input type="checkbox" id="c-39699147" checked=""/><div class="controls bullet"><span class="by">andher</span><span>|</span><a href="#39701567">prev</a><span>|</span><a href="#39699562">next</a><span>|</span><label class="collapse" for="c-39699147">[-]</label><label class="expand" for="c-39699147">[6 more]</label></div><br/><div class="children"><div class="content">Finally! I&#x27;ve been using the assistants api in building an ai mock interviewer (<a href="https:&#x2F;&#x2F;comp.lol" rel="nofollow">https:&#x2F;&#x2F;comp.lol</a>) but the responses were painfully slow when using the latest iterations of the gpt-4 model. This will make things so much more responsive</div><br/><div id="39699668" class="c"><input type="checkbox" id="c-39699668" checked=""/><div class="controls bullet"><span class="by">pieterhg</span><span>|</span><a href="#39699147">parent</a><span>|</span><a href="#39699172">next</a><span>|</span><label class="collapse" for="c-39699668">[-]</label><label class="expand" for="c-39699668">[1 more]</label></div><br/><div class="children"><div class="content">Same it was super slow and unusable when I tried. 10 seconds for a reply or smth. GPT4 API itself was way faster</div><br/></div></div><div id="39699172" class="c"><input type="checkbox" id="c-39699172" checked=""/><div class="controls bullet"><span class="by">cosmotic</span><span>|</span><a href="#39699147">parent</a><span>|</span><a href="#39699668">prev</a><span>|</span><a href="#39699562">next</a><span>|</span><label class="collapse" for="c-39699172">[-]</label><label class="expand" for="c-39699172">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;d still want to see the entire response all at once. Having it stream in while I read it would be very distracting and make it difficult for me to read.</div><br/><div id="39699665" class="c"><input type="checkbox" id="c-39699665" checked=""/><div class="controls bullet"><span class="by">TowerTall</span><span>|</span><a href="#39699147">root</a><span>|</span><a href="#39699172">parent</a><span>|</span><a href="#39701067">prev</a><span>|</span><a href="#39699562">next</a><span>|</span><label class="collapse" for="c-39699665">[-]</label><label class="expand" for="c-39699665">[2 more]</label></div><br/><div class="children"><div class="content">yes, it like surfing porn in the early internet year using a dialup modem. One line a the time until you finally can see enough of the picture (reply) to realize that is was not the reply you were looking for.<p>LLM streaming must be a cost saving feature to prevent you from overloading the servers by asking to many questions with in a short time frame. Annoying feature IMHO</div><br/><div id="39701385" class="c"><input type="checkbox" id="c-39701385" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#39699147">root</a><span>|</span><a href="#39699665">parent</a><span>|</span><a href="#39699562">next</a><span>|</span><label class="collapse" for="c-39701385">[-]</label><label class="expand" for="c-39701385">[1 more]</label></div><br/><div class="children"><div class="content">How is hiding it behind a loading spinner any better? You still can&#x27;t spam it with questions since you need to wait for it to finish. With streaming you can at least hit the stop button if it looks incorrect, so you actually spam it more with it enabled.</div><br/></div></div></div></div></div></div></div></div><div id="39699562" class="c"><input type="checkbox" id="c-39699562" checked=""/><div class="controls bullet"><span class="by">AgentME</span><span>|</span><a href="#39699147">prev</a><span>|</span><a href="#39700276">next</a><span>|</span><label class="collapse" for="c-39699562">[-]</label><label class="expand" for="c-39699562">[7 more]</label></div><br/><div class="children"><div class="content">This was one of the limitations of the Assistants API that made me entirely ignore it up until now.<p>I am curious if the Assistants API lets you edit&#x2F;remove&#x2F;retry messages yet. I don&#x27;t see anything implying this has changed. It&#x27;s annoying that the Assistants API doesn&#x27;t give you enough control to support basic things that the ChatGPT app does.</div><br/><div id="39699741" class="c"><input type="checkbox" id="c-39699741" checked=""/><div class="controls bullet"><span class="by">varenc</span><span>|</span><a href="#39699562">parent</a><span>|</span><a href="#39699626">next</a><span>|</span><label class="collapse" for="c-39699741">[-]</label><label class="expand" for="c-39699741">[2 more]</label></div><br/><div class="children"><div class="content">Like the other commenter said, edit&#x2F;remove&#x2F;retry messages can be implemented by the API client already.  The API doesn&#x27;t maintain state so every new message in a &quot;conversation&quot; includes previous messages as context. To edit a message you would re-submit the conversation history with the desired changes.<p>I get what you&#x27;re asking for though. It would be nice if this was easier. But that would require OpenAI changing their API model to one where conversation history is stored on their server. It would be more of a &quot;ChatGPT conversation API&quot; then just an GPT-4&#x2F;3.5 API.</div><br/><div id="39700222" class="c"><input type="checkbox" id="c-39700222" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#39699562">root</a><span>|</span><a href="#39699741">parent</a><span>|</span><a href="#39699626">next</a><span>|</span><label class="collapse" for="c-39700222">[-]</label><label class="expand" for="c-39700222">[1 more]</label></div><br/><div class="children"><div class="content">That is what &quot;assistant api&quot; is, you create a thread and add new user message to the thread. The messages are stored on the server.<p>There is an API to modify messages, though I am not sure of its constraints.</div><br/></div></div></div></div><div id="39699626" class="c"><input type="checkbox" id="c-39699626" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#39699562">parent</a><span>|</span><a href="#39699741">prev</a><span>|</span><a href="#39700276">next</a><span>|</span><label class="collapse" for="c-39699626">[-]</label><label class="expand" for="c-39699626">[4 more]</label></div><br/><div class="children"><div class="content">Edit&#x2F;remove&#x2F;retry is just including the whole conversation over again (IIUC this is even how the app works.) It&#x27;s part of why the API is so expensive</div><br/><div id="39699759" class="c"><input type="checkbox" id="c-39699759" checked=""/><div class="controls bullet"><span class="by">AgentME</span><span>|</span><a href="#39699562">root</a><span>|</span><a href="#39699626">parent</a><span>|</span><a href="#39700276">next</a><span>|</span><label class="collapse" for="c-39699759">[-]</label><label class="expand" for="c-39699759">[3 more]</label></div><br/><div class="children"><div class="content">The Assistants API doesn&#x27;t let you recreate the conversation (with edits or not) because you can&#x27;t (re)create messages with role=assistant.</div><br/><div id="39699847" class="c"><input type="checkbox" id="c-39699847" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#39699562">root</a><span>|</span><a href="#39699759">parent</a><span>|</span><a href="#39700276">next</a><span>|</span><label class="collapse" for="c-39699847">[-]</label><label class="expand" for="c-39699847">[2 more]</label></div><br/><div class="children"><div class="content">Not true</div><br/><div id="39701475" class="c"><input type="checkbox" id="c-39701475" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#39699562">root</a><span>|</span><a href="#39699847">parent</a><span>|</span><a href="#39700276">next</a><span>|</span><label class="collapse" for="c-39701475">[-]</label><label class="expand" for="c-39701475">[1 more]</label></div><br/><div class="children"><div class="content">How do you create messages as role assistant?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39700276" class="c"><input type="checkbox" id="c-39700276" checked=""/><div class="controls bullet"><span class="by">pedrovhb</span><span>|</span><a href="#39699562">prev</a><span>|</span><a href="#39700916">next</a><span>|</span><label class="collapse" for="c-39700276">[-]</label><label class="expand" for="c-39700276">[11 more]</label></div><br/><div class="children"><div class="content">For all the brilliance in the AI and infra departments of OpenAI, their official Python library (which is the flagship one as I understand) feels pretty unidiomatic, designed without much thought for common patterns in the language.<p>2012 JavaScript called, it wants its callbacks wrapped in objects back. Why do we have a context manager named &quot;stream&quot; for which you call `.until_done()`? This could&#x27;ve been an iterator, or better - an asynchronous iterator, since this is streaming over the network. We could be destructing instances of named tuples with pattern matching, or even just doing `&quot;&quot;.join(delta.text for delta in prompt (...)`. But no here subclass this instead, tells me the wrapper around a web API.</div><br/><div id="39700831" class="c"><input type="checkbox" id="c-39700831" checked=""/><div class="controls bullet"><span class="by">rattray</span><span>|</span><a href="#39700276">parent</a><span>|</span><a href="#39700559">next</a><span>|</span><label class="collapse" for="c-39700831">[-]</label><label class="expand" for="c-39700831">[2 more]</label></div><br/><div class="children"><div class="content">Hey there, I helped design the Python library.<p>The `stream` context manager actually does expose an async iterator (in the async client), so you could instead do this for the simple case:<p><pre><code>    with client.beta.threads.runs.create_and_stream(â¦) as stream:
      async for text in stream.text_deltas:
        print(text, end=&quot;&quot;, flush=True)
</code></pre>
which I think is roughly what you want.<p>Perhaps the docs should be updated to highlight this simple case earlier.<p>We are also considering expanding this design, and perhaps replacing the callbacks, like so:<p><pre><code>    with client.beta.threads.runs.create_and_stream(â¦) as stream:
      async for event in stream.all_events:
        if event.type == &#x27;text_delta&#x27;:
          print(event.delta.value, end=&#x27;&#x27;)
        elif event.type == &#x27;run_step_delta&#x27;:
          event.snapshot.id
          event.delta.step_details...
</code></pre>
which I think is also more in line with what you expect. (you could also `match event: case TextDelta: â¦`).<p>Note that the context manager is required because otherwise there&#x27;s no way to tell if you `break` out of the loop (or otherwise stop listening to the stream) which means we can&#x27;t close the request (and you both keep burning tokens and leak resources in your app).</div><br/><div id="39700905" class="c"><input type="checkbox" id="c-39700905" checked=""/><div class="controls bullet"><span class="by">ametrau</span><span>|</span><a href="#39700276">root</a><span>|</span><a href="#39700831">parent</a><span>|</span><a href="#39700559">next</a><span>|</span><label class="collapse" for="c-39700905">[-]</label><label class="expand" for="c-39700905">[1 more]</label></div><br/><div class="children"><div class="content">Context managers are a great abstraction.</div><br/></div></div></div></div><div id="39700559" class="c"><input type="checkbox" id="c-39700559" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#39700276">parent</a><span>|</span><a href="#39700831">prev</a><span>|</span><a href="#39700381">next</a><span>|</span><label class="collapse" for="c-39700559">[-]</label><label class="expand" for="c-39700559">[2 more]</label></div><br/><div class="children"><div class="content">My experience is their official Python library was easy to use, no surprises, everything is typed and generated from the OpenAPI spec in a thoughtful way.<p>The tools are great because they don&#x27;t invent their own DSL, they &quot;just&quot; use JSON schemas.<p>Maybe they ought to contribute changes to OpenAPI to support streaming APIs better.<p>In contrast so many startups make their own annotation-driven DSLs for Python with their branding slapped over everything. It gives desperate-for-lock-in vibes. The last people OpenAI should be taking advice from for their API design is this forum.</div><br/><div id="39700872" class="c"><input type="checkbox" id="c-39700872" checked=""/><div class="controls bullet"><span class="by">pedrovhb</span><span>|</span><a href="#39700276">root</a><span>|</span><a href="#39700559">parent</a><span>|</span><a href="#39700381">next</a><span>|</span><label class="collapse" for="c-39700872">[-]</label><label class="expand" for="c-39700872">[1 more]</label></div><br/><div class="children"><div class="content">How is suggesting the use of iterators and named tuples related to creating domain specific languages? If anything I&#x27;d say they&#x27;re a much more generic and universally recognizable approach than having users subclass `AssistantEventHandler` to be passed to `client.beta.threads.runs.create_and_stream`, the context manager. This is very much a long way past just using JSON schemas but that part is ok - there&#x27;s a REST API, and there&#x27;s a library. If you&#x27;re keen on the simplicity of JSON schema then by all means use the API with `requests` or your preferred http client library. Since that&#x27;s always an option, it stands to reason that the point of having a dedicated library is to provide thoughtful abstractions that make it easier to use the service.<p>What I&#x27;m arguing is precisely that the abstractions in the library (such as the `AssistantEventHandler` shown in the article) are ineffective in making things simpler. They force you to over-engineer solutions and distribute state unnecessarily and be aware of that specific class interface when it could&#x27;ve just been something you use in a `for x in y` loop like everyone would know to do without spending an afternoon looking over docs and figuring out how the underlying implicit FSM works.</div><br/></div></div></div></div><div id="39700381" class="c"><input type="checkbox" id="c-39700381" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#39700276">parent</a><span>|</span><a href="#39700559">prev</a><span>|</span><a href="#39700442">next</a><span>|</span><label class="collapse" for="c-39700381">[-]</label><label class="expand" for="c-39700381">[3 more]</label></div><br/><div class="children"><div class="content">Everything feels unidiomatic. The API design is bad, the frontends they build are horrific, reliability and availability are shocking.<p>And yet the AI is so good I put up with them everyday<p>If they ever grow into a proper product org they&#x27;ll be unstoppable.</div><br/><div id="39701578" class="c"><input type="checkbox" id="c-39701578" checked=""/><div class="controls bullet"><span class="by">athyuttamre</span><span>|</span><a href="#39700276">root</a><span>|</span><a href="#39700381">parent</a><span>|</span><a href="#39700826">next</a><span>|</span><label class="collapse" for="c-39701578">[-]</label><label class="expand" for="c-39701578">[1 more]</label></div><br/><div class="children"><div class="content">Hi there, I help design the OpenAI APIs. Would you be able to share more?<p>You can reply here or email me at atty@openai.com.<p>(Please don&#x27;t hold back; we would love to hear the pain points so we can fix them.)</div><br/></div></div><div id="39700826" class="c"><input type="checkbox" id="c-39700826" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#39700276">root</a><span>|</span><a href="#39700381">parent</a><span>|</span><a href="#39701578">prev</a><span>|</span><a href="#39700442">next</a><span>|</span><label class="collapse" for="c-39700826">[-]</label><label class="expand" for="c-39700826">[1 more]</label></div><br/><div class="children"><div class="content">...except for all the others.<p>Use Claude in Safari and the browser completely locks up after a single response.</div><br/></div></div></div></div><div id="39700442" class="c"><input type="checkbox" id="c-39700442" checked=""/><div class="controls bullet"><span class="by">jilles</span><span>|</span><a href="#39700276">parent</a><span>|</span><a href="#39700381">prev</a><span>|</span><a href="#39700332">next</a><span>|</span><label class="collapse" for="c-39700442">[-]</label><label class="expand" for="c-39700442">[2 more]</label></div><br/><div class="children"><div class="content">Probably written by GPT4</div><br/><div id="39701166" class="c"><input type="checkbox" id="c-39701166" checked=""/><div class="controls bullet"><span class="by">dgellow</span><span>|</span><a href="#39700276">root</a><span>|</span><a href="#39700442">parent</a><span>|</span><a href="#39700332">next</a><span>|</span><label class="collapse" for="c-39701166">[-]</label><label class="expand" for="c-39701166">[1 more]</label></div><br/><div class="children"><div class="content">Itâs not the case. The SDK is a collaboration between OpenAI and Stainless.<p><a href="https:&#x2F;&#x2F;www.stainlessapi.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.stainlessapi.com&#x2F;</a><p>As a Stainless contributor I can guarantee you a lot of thoughts has been put into the design, and it definitely isnât written by an ML model</div><br/></div></div></div></div></div></div><div id="39700916" class="c"><input type="checkbox" id="c-39700916" checked=""/><div class="controls bullet"><span class="by">jerrygoyal</span><span>|</span><a href="#39700276">prev</a><span>|</span><a href="#39701529">next</a><span>|</span><label class="collapse" for="c-39700916">[-]</label><label class="expand" for="c-39700916">[3 more]</label></div><br/><div class="children"><div class="content">I am interested to use the assistant api for my commercial project but it is not clear from the article what the token count looks like?<p>- is it counted for a single user message or the sum of all previous messages?<p>- if there&#x27;s a file, will it be counted every time a user interacts or only the first time?</div><br/><div id="39701300" class="c"><input type="checkbox" id="c-39701300" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39700916">parent</a><span>|</span><a href="#39701529">next</a><span>|</span><label class="collapse" for="c-39701300">[-]</label><label class="expand" for="c-39701300">[2 more]</label></div><br/><div class="children"><div class="content">I think<p>- it is correlated to the sum, every new interaction adds the whole history again<p>- yes, but you probably pay for the retrieved fragments, not the whole file</div><br/><div id="39701408" class="c"><input type="checkbox" id="c-39701408" checked=""/><div class="controls bullet"><span class="by">brandall10</span><span>|</span><a href="#39700916">root</a><span>|</span><a href="#39701300">parent</a><span>|</span><a href="#39701529">next</a><span>|</span><label class="collapse" for="c-39701408">[-]</label><label class="expand" for="c-39701408">[1 more]</label></div><br/><div class="children"><div class="content">On the second point, there was an issue on launch where it would not find a relevant fragment and appear to load the whole file into the context. Unsure if this has changed but it freaked quite a few folks out OpenAI discussion forums w&#x2F; escalating costs.</div><br/></div></div></div></div></div></div><div id="39701529" class="c"><input type="checkbox" id="c-39701529" checked=""/><div class="controls bullet"><span class="by">milar</span><span>|</span><a href="#39700916">prev</a><span>|</span><a href="#39699051">next</a><span>|</span><label class="collapse" for="c-39701529">[-]</label><label class="expand" for="c-39701529">[1 more]</label></div><br/><div class="children"><div class="content">Has tool use accuracy improved?</div><br/></div></div><div id="39699051" class="c"><input type="checkbox" id="c-39699051" checked=""/><div class="controls bullet"><span class="by">ProjectArcturis</span><span>|</span><a href="#39701529">prev</a><span>|</span><a href="#39699917">next</a><span>|</span><label class="collapse" for="c-39699051">[-]</label><label class="expand" for="c-39699051">[4 more]</label></div><br/><div class="children"><div class="content">Has anyone put out a voice-to-text interface for OpenAI? Or anything in the Ollama-verse?</div><br/><div id="39699448" class="c"><input type="checkbox" id="c-39699448" checked=""/><div class="controls bullet"><span class="by">eightysixfour</span><span>|</span><a href="#39699051">parent</a><span>|</span><a href="#39700393">next</a><span>|</span><label class="collapse" for="c-39699448">[-]</label><label class="expand" for="c-39699448">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI has a voice to text interface for OpenAIâ¦</div><br/></div></div><div id="39700393" class="c"><input type="checkbox" id="c-39700393" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#39699051">parent</a><span>|</span><a href="#39699448">prev</a><span>|</span><a href="#39699084">next</a><span>|</span><label class="collapse" for="c-39700393">[-]</label><label class="expand" for="c-39700393">[1 more]</label></div><br/><div class="children"><div class="content">The mobile app is pretty good<p>Horrendous in non english languages though, the accents are extremely American</div><br/></div></div><div id="39699084" class="c"><input type="checkbox" id="c-39699084" checked=""/><div class="controls bullet"><span class="by">the_newest</span><span>|</span><a href="#39699051">parent</a><span>|</span><a href="#39700393">prev</a><span>|</span><a href="#39699917">next</a><span>|</span><label class="collapse" for="c-39699084">[-]</label><label class="expand" for="c-39699084">[1 more]</label></div><br/><div class="children"><div class="content">Thereâs whisper.</div><br/></div></div></div></div><div id="39699917" class="c"><input type="checkbox" id="c-39699917" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39699051">prev</a><span>|</span><a href="#39699414">next</a><span>|</span><label class="collapse" for="c-39699917">[-]</label><label class="expand" for="c-39699917">[4 more]</label></div><br/><div class="children"><div class="content">Throwing a feature request in here just in case someone from OpenAI sees it.<p>I&#x27;d really like it if the streaming versions of their APIs could return a token usage count at the end.<p>The non-streaming APIs do this right now:<p><pre><code>    curl https:&#x2F;&#x2F;api.openai.com&#x2F;v1&#x2F;chat&#x2F;completions \
      -H &quot;Content-Type: application&#x2F;json&quot; \
      -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot; -d &#x27;{
        &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,
        &quot;messages&quot;: [
          {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;A short fun fact about pigeons&quot;
          }
        ]
      }&#x27;
</code></pre>
Returns:<p><pre><code>    {
      &quot;id&quot;: &quot;chatcmpl-92UiIWQaf442wq7Eyp7kF8ge0e3fE&quot;,
      &quot;object&quot;: &quot;chat.completion&quot;,
      &quot;created&quot;: 1710381746,
      &quot;model&quot;: &quot;gpt-3.5-turbo-0125&quot;,
      &quot;choices&quot;: [
        {
          &quot;index&quot;: 0,
          &quot;message&quot;: {
            &quot;role&quot;: &quot;assistant&quot;,
            &quot;content&quot;: &quot;Pigeons are one of the few bird species that can drink water by sucking it up through their beaks, rather than tilting their heads back to swallow.&quot;
          },
          &quot;logprobs&quot;: null,
          &quot;finish_reason&quot;: &quot;stop&quot;
        }
      ],
      &quot;usage&quot;: {
        &quot;prompt_tokens&quot;: 14,
        &quot;completion_tokens&quot;: 33,
        &quot;total_tokens&quot;: 47
      },
      &quot;system_fingerprint&quot;: &quot;fp_4f0b692a78&quot;
    }
</code></pre>
Note the &quot;usage&quot; block there telling me how many tokens were used (which tells me how much this cost).<p>But if I add &quot;stream&quot;: true I get back an SSE stream that looks like this:<p><pre><code>    ...
    data: {&quot;id&quot;:&quot;chatcmpl-92Uk81oNjrcUJQnPX8fSNqFINLfSI&quot;,&quot;object&quot;:&quot;chat.completion.chunk&quot;,&quot;created&quot;:1710381860,&quot;model&quot;:&quot;gpt-3.5-turbo-0125&quot;,&quot;system_fingerprint&quot;:&quot;fp_4f0b692a78&quot;,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;delta&quot;:{&quot;content&quot;:&quot;.&quot;},&quot;logprobs&quot;:null,&quot;finish_reason&quot;:null}]}
    
    data: {&quot;id&quot;:&quot;chatcmpl-92Uk81oNjrcUJQnPX8fSNqFINLfSI&quot;,&quot;object&quot;:&quot;chat.completion.chunk&quot;,&quot;created&quot;:1710381860,&quot;model&quot;:&quot;gpt-3.5-turbo-0125&quot;,&quot;system_fingerprint&quot;:&quot;fp_4f0b692a78&quot;,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;delta&quot;:{},&quot;logprobs&quot;:null,&quot;finish_reason&quot;:&quot;stop&quot;}]}
    
    data: [DONE]
</code></pre>
There&#x27;s no &quot;usage&quot; block, which means I have to try and account for the tokens myself. This is really inconvenient!<p>I noticed the other day that the Claude streaming API returns a &quot;usage&quot; block with the last message. I&#x27;d love it if OpenAI&#x27;s API did the same thing.<p>I need this right now because I&#x27;m starting to build features for end users of my own software, and I want to be able to give them X,000 tokens &quot;free&quot; before starting to charge them for extras. Counting those tokens myself (probably using tiktoken) is code I&#x27;d rather not have to write - especially since features like tools&#x2F;functions or images make counting tokens a lot less obvious.</div><br/><div id="39700193" class="c"><input type="checkbox" id="c-39700193" checked=""/><div class="controls bullet"><span class="by">gtoubassi</span><span>|</span><a href="#39699917">parent</a><span>|</span><a href="#39700187">next</a><span>|</span><label class="collapse" for="c-39700193">[-]</label><label class="expand" for="c-39700193">[2 more]</label></div><br/><div class="children"><div class="content">We do the token counting on our end literally just running tiktoken on the content chunks (although I think usually its one token per chunk).  Its a bit annoying and I too expected they&#x27;d have the usage block but its one line of code if you already have tiktoken available.  I&#x27;ve found the accounting on my side lines up well with what we see on our usage dashboard.</div><br/><div id="39700553" class="c"><input type="checkbox" id="c-39700553" checked=""/><div class="controls bullet"><span class="by">tristanz</span><span>|</span><a href="#39699917">root</a><span>|</span><a href="#39700193">parent</a><span>|</span><a href="#39700187">next</a><span>|</span><label class="collapse" for="c-39700553">[-]</label><label class="expand" for="c-39700553">[1 more]</label></div><br/><div class="children"><div class="content">As an FYI, this is fine for rough usage, but it&#x27;s not accurate.  The OpenAI APIs inject various tokens you are unaware of into the input for things like function calling.</div><br/></div></div></div></div><div id="39700187" class="c"><input type="checkbox" id="c-39700187" checked=""/><div class="controls bullet"><span class="by">harrisonjackson</span><span>|</span><a href="#39699917">parent</a><span>|</span><a href="#39700193">prev</a><span>|</span><a href="#39699414">next</a><span>|</span><label class="collapse" for="c-39700187">[-]</label><label class="expand" for="c-39700187">[1 more]</label></div><br/><div class="children"><div class="content">This and&#x2F;or being able to fetch the responses with their token usage by id. What is that ID for without a way to retrieve the completions with it?</div><br/></div></div></div></div><div id="39699414" class="c"><input type="checkbox" id="c-39699414" checked=""/><div class="controls bullet"><span class="by">XCSme</span><span>|</span><a href="#39699917">prev</a><span>|</span><a href="#39699099">next</a><span>|</span><label class="collapse" for="c-39699414">[-]</label><label class="expand" for="c-39699414">[5 more]</label></div><br/><div class="children"><div class="content">Any way to have a consistent system prompt across queries without sending it (and using tokens) for each completion?</div><br/><div id="39699886" class="c"><input type="checkbox" id="c-39699886" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#39699414">parent</a><span>|</span><a href="#39699437">next</a><span>|</span><label class="collapse" for="c-39699886">[-]</label><label class="expand" for="c-39699886">[2 more]</label></div><br/><div class="children"><div class="content">The assistant has its own &quot;instructions&quot; (replacement for system prompt)<p>and then on each run, you have the option to add more guidance to the run explicitly, without modifying the assistant instructions (system prompt)<p>It&#x27;s a little bit different but kind of the same</div><br/><div id="39701483" class="c"><input type="checkbox" id="c-39701483" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#39699414">root</a><span>|</span><a href="#39699886">parent</a><span>|</span><a href="#39699437">next</a><span>|</span><label class="collapse" for="c-39701483">[-]</label><label class="expand" for="c-39701483">[1 more]</label></div><br/><div class="children"><div class="content">No, adding run instructions will replace existing instructions for that run</div><br/></div></div></div></div><div id="39699437" class="c"><input type="checkbox" id="c-39699437" checked=""/><div class="controls bullet"><span class="by">eightysixfour</span><span>|</span><a href="#39699414">parent</a><span>|</span><a href="#39699886">prev</a><span>|</span><a href="#39699099">next</a><span>|</span><label class="collapse" for="c-39699437">[-]</label><label class="expand" for="c-39699437">[2 more]</label></div><br/><div class="children"><div class="content">The Assistant API handles that, it has the system prompt as part of the assistant that you interact with.</div><br/><div id="39699545" class="c"><input type="checkbox" id="c-39699545" checked=""/><div class="controls bullet"><span class="by">XCSme</span><span>|</span><a href="#39699414">root</a><span>|</span><a href="#39699437">parent</a><span>|</span><a href="#39699099">next</a><span>|</span><label class="collapse" for="c-39699545">[-]</label><label class="expand" for="c-39699545">[1 more]</label></div><br/><div class="children"><div class="content">And can you share the assistant with other users?<p>Also, the system prompt in assistants doesn&#x27;t consume tokens?</div><br/></div></div></div></div></div></div><div id="39699099" class="c"><input type="checkbox" id="c-39699099" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#39699414">prev</a><span>|</span><a href="#39699767">next</a><span>|</span><label class="collapse" for="c-39699099">[-]</label><label class="expand" for="c-39699099">[5 more]</label></div><br/><div class="children"><div class="content"><i>Sigh</i> another week lost to the void</div><br/><div id="39699127" class="c"><input type="checkbox" id="c-39699127" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#39699099">parent</a><span>|</span><a href="#39699767">next</a><span>|</span><label class="collapse" for="c-39699127">[-]</label><label class="expand" for="c-39699127">[4 more]</label></div><br/><div class="children"><div class="content">Elaborate?</div><br/><div id="39699753" class="c"><input type="checkbox" id="c-39699753" checked=""/><div class="controls bullet"><span class="by">castles</span><span>|</span><a href="#39699099">root</a><span>|</span><a href="#39699127">parent</a><span>|</span><a href="#39699767">next</a><span>|</span><label class="collapse" for="c-39699753">[-]</label><label class="expand" for="c-39699753">[3 more]</label></div><br/><div class="children"><div class="content">&quot;YET ANOTHER shiny new toy to distract me. Can&#x27;t help myself even though I think it&#x27;s mostly a waste of time&quot;<p>Am I just projecting? 
Relatable, in any case :)</div><br/><div id="39701627" class="c"><input type="checkbox" id="c-39701627" checked=""/><div class="controls bullet"><span class="by">__m</span><span>|</span><a href="#39699099">root</a><span>|</span><a href="#39699753">parent</a><span>|</span><a href="#39699845">next</a><span>|</span><label class="collapse" for="c-39701627">[-]</label><label class="expand" for="c-39701627">[1 more]</label></div><br/><div class="children"><div class="content">I immediately implemented streaming into my rocketchat gpt bot, was definitely a distraction but my colleagues liked it. No more waiting until the complete response is sent.</div><br/></div></div><div id="39699845" class="c"><input type="checkbox" id="c-39699845" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#39699099">root</a><span>|</span><a href="#39699753">parent</a><span>|</span><a href="#39701627">prev</a><span>|</span><a href="#39699767">next</a><span>|</span><label class="collapse" for="c-39699845">[-]</label><label class="expand" for="c-39699845">[1 more]</label></div><br/><div class="children"><div class="content">Yep, you captured the moment ^_^</div><br/></div></div></div></div></div></div></div></div><div id="39699767" class="c"><input type="checkbox" id="c-39699767" checked=""/><div class="controls bullet"><span class="by">potsandpans</span><span>|</span><a href="#39699099">prev</a><span>|</span><a href="#39700077">next</a><span>|</span><label class="collapse" for="c-39699767">[-]</label><label class="expand" for="c-39699767">[6 more]</label></div><br/><div class="children"><div class="content">Openai banned my account for suspicious payment activities, and I never was able to talk to a real person. Just several layers of chat bots posing as people.<p>I literally want to give them my money and can&#x27;t. Every few weeks for shirts and giggles i send an email to them saying, &quot;any update on this?&quot;</div><br/><div id="39700613" class="c"><input type="checkbox" id="c-39700613" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#39699767">parent</a><span>|</span><a href="#39700357">next</a><span>|</span><label class="collapse" for="c-39700613">[-]</label><label class="expand" for="c-39700613">[1 more]</label></div><br/><div class="children"><div class="content">I suspected as much when one of their support &quot;personnel&quot; used the phrase &quot;I apologize for the earlier confusion...&quot; (there was no confusion, I was simply contradicting what they were saying)</div><br/></div></div><div id="39700357" class="c"><input type="checkbox" id="c-39700357" checked=""/><div class="controls bullet"><span class="by">dbish</span><span>|</span><a href="#39699767">parent</a><span>|</span><a href="#39700613">prev</a><span>|</span><a href="#39700323">next</a><span>|</span><label class="collapse" for="c-39700357">[-]</label><label class="expand" for="c-39700357">[1 more]</label></div><br/><div class="children"><div class="content">One of the reasons I tend to use any of their options through Azure where available. Azure support has a more straight forward (though still sometimes slow) process for account issues.</div><br/></div></div><div id="39700323" class="c"><input type="checkbox" id="c-39700323" checked=""/><div class="controls bullet"><span class="by">slimsag</span><span>|</span><a href="#39699767">parent</a><span>|</span><a href="#39700357">prev</a><span>|</span><a href="#39700235">next</a><span>|</span><label class="collapse" for="c-39700323">[-]</label><label class="expand" for="c-39700323">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to the future. You might be able to get an enterprise sales contract with human support.</div><br/></div></div><div id="39700235" class="c"><input type="checkbox" id="c-39700235" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#39699767">parent</a><span>|</span><a href="#39700323">prev</a><span>|</span><a href="#39700077">next</a><span>|</span><label class="collapse" for="c-39700235">[-]</label><label class="expand" for="c-39700235">[2 more]</label></div><br/><div class="children"><div class="content">I guess it&#x27;s time for Claude 3 (I imagine you were using it for the LLMs).</div><br/><div id="39700568" class="c"><input type="checkbox" id="c-39700568" checked=""/><div class="controls bullet"><span class="by">thejohnconway</span><span>|</span><a href="#39699767">root</a><span>|</span><a href="#39700235">parent</a><span>|</span><a href="#39700077">next</a><span>|</span><label class="collapse" for="c-39700568">[-]</label><label class="expand" for="c-39700568">[1 more]</label></div><br/><div class="children"><div class="content">My Anthropic account was suspended for suspicious activity, even though I never used it. I had forgotten I had signed up, and tried to sign up using a new email with the same phone number. Locked out forever.</div><br/></div></div></div></div></div></div><div id="39700077" class="c"><input type="checkbox" id="c-39700077" checked=""/><div class="controls bullet"><span class="by">megous</span><span>|</span><a href="#39699767">prev</a><span>|</span><a href="#39699173">next</a><span>|</span><label class="collapse" for="c-39700077">[-]</label><label class="expand" for="c-39700077">[9 more]</label></div><br/><div class="children"><div class="content">This website is now like 30% about this probability based autocomplete nonsense.  Feels like all those bitcoin hypes and &quot;running everything on blockchain&quot; fad of few years ago. Now it&#x27;s running everything through &quot;large autocomplete&quot; model.<p>I really hope this will fade and focus will turn back to highlighting some broader actual human ingenuity in IT, rather than constant stream of &quot;we used autocomplete for this new thing&quot; or &quot;we build this new API for this glorified autocomplete&quot;.<p>Boring.</div><br/><div id="39700489" class="c"><input type="checkbox" id="c-39700489" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#39700077">parent</a><span>|</span><a href="#39700310">next</a><span>|</span><label class="collapse" for="c-39700489">[-]</label><label class="expand" for="c-39700489">[2 more]</label></div><br/><div class="children"><div class="content">&quot;old man yells at cloud&quot;<p>Seriously though, it&#x27;s not going away no matter how much anyone hates it.  Emails and blogs will continue to be written with it, letters of recommendation will be&#x2F;are written with it, Presidential speeches will be written with it, academic articles will be &#x2F; are written with it (almost all ml and cs research is), news is written with it...
It&#x27;s not going to stop, but it will _probably_&#x2F;_very likely_ get better.<p>There is no tool, no human, no method to determine if text is generated with one of these models at high F-score (only sometimes high precision, low recall domains for silly examples).<p>We&#x27;re stuck with it.  Like the English teacher and their despised spell check.</div><br/><div id="39700742" class="c"><input type="checkbox" id="c-39700742" checked=""/><div class="controls bullet"><span class="by">romanhn</span><span>|</span><a href="#39700077">root</a><span>|</span><a href="#39700489">parent</a><span>|</span><a href="#39700310">next</a><span>|</span><label class="collapse" for="c-39700742">[-]</label><label class="expand" for="c-39700742">[1 more]</label></div><br/><div class="children"><div class="content">It occurs to me that over time, reading comprehension will become significantly more important than the ability to write. Anyone will be able to write something smart-sounding with AI&#x27;s help, but it&#x27;ll take real skill to make sure the output is correct and appropriate.</div><br/></div></div></div></div><div id="39700310" class="c"><input type="checkbox" id="c-39700310" checked=""/><div class="controls bullet"><span class="by">XCSme</span><span>|</span><a href="#39700077">parent</a><span>|</span><a href="#39700489">prev</a><span>|</span><a href="#39700923">next</a><span>|</span><label class="collapse" for="c-39700310">[-]</label><label class="expand" for="c-39700310">[2 more]</label></div><br/><div class="children"><div class="content">I just added this &quot;autocomplete&quot; in my app, and customers emailed to say they actually love it: <a href="https:&#x2F;&#x2F;docs.uxwizz.com&#x2F;guides&#x2F;ask-ai-new" rel="nofollow">https:&#x2F;&#x2F;docs.uxwizz.com&#x2F;guides&#x2F;ask-ai-new</a></div><br/><div id="39700558" class="c"><input type="checkbox" id="c-39700558" checked=""/><div class="controls bullet"><span class="by">kfajdsl</span><span>|</span><a href="#39700077">root</a><span>|</span><a href="#39700310">parent</a><span>|</span><a href="#39700923">next</a><span>|</span><label class="collapse" for="c-39700558">[-]</label><label class="expand" for="c-39700558">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve gotten so used to having an LLM integrated into my editor that when I work on the occasional spreadsheet (or really anything with syntax that I only use occasionally and no integrated AI) it&#x27;s pretty jarring to have to go to another tab to look up what function to use for a formula (even if that other tab is ChatGPT).</div><br/></div></div></div></div><div id="39700923" class="c"><input type="checkbox" id="c-39700923" checked=""/><div class="controls bullet"><span class="by">ametrau</span><span>|</span><a href="#39700077">parent</a><span>|</span><a href="#39700310">prev</a><span>|</span><a href="#39700822">next</a><span>|</span><label class="collapse" for="c-39700923">[-]</label><label class="expand" for="c-39700923">[1 more]</label></div><br/><div class="children"><div class="content">Nah it&#x27;s got legs as a google replacement &#x2F; competitor if they keep costs lower and take a smaller rent. <i>WHEN</i> they start advertising they&#x27;ll explode. Which is why google is trying to snuff them out in the cradle (sorry about the visual).</div><br/></div></div><div id="39700822" class="c"><input type="checkbox" id="c-39700822" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#39700077">parent</a><span>|</span><a href="#39700923">prev</a><span>|</span><a href="#39699173">next</a><span>|</span><label class="collapse" for="c-39700822">[-]</label><label class="expand" for="c-39700822">[3 more]</label></div><br/><div class="children"><div class="content">If deep learning algorithms are &quot;autocomplete&quot; then so is the human mind when it strings words together. No, that&#x27;s not how it works.</div><br/><div id="39700877" class="c"><input type="checkbox" id="c-39700877" checked=""/><div class="controls bullet"><span class="by">dns_snek</span><span>|</span><a href="#39700077">root</a><span>|</span><a href="#39700822">parent</a><span>|</span><a href="#39699173">next</a><span>|</span><label class="collapse" for="c-39700877">[-]</label><label class="expand" for="c-39700877">[2 more]</label></div><br/><div class="children"><div class="content">[citation needed]<p>Just because that makes for a nice narrative in the copyright infringement argument, doesn&#x27;t make it so.<p>We know next to nothing about how the human brain works.</div><br/><div id="39700926" class="c"><input type="checkbox" id="c-39700926" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#39700077">root</a><span>|</span><a href="#39700877">parent</a><span>|</span><a href="#39699173">next</a><span>|</span><label class="collapse" for="c-39700926">[-]</label><label class="expand" for="c-39700926">[1 more]</label></div><br/><div class="children"><div class="content">Citation: Decades of research in artificial neural networks<p>Here&#x27;s a paper from 1990 by the Godfather himself <a href="https:&#x2F;&#x2F;www.cs.toronto.edu&#x2F;~hinton&#x2F;absps&#x2F;AIJmapping.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cs.toronto.edu&#x2F;~hinton&#x2F;absps&#x2F;AIJmapping.pdf</a><p>&quot;This 1990 paper demonstrated how neural networks could learn to represent and reason about part-whole hierarchical relationships, using family trees as the example domain.<p>By training on examples of family relations like parent-child and grandparent-grandchild, the neural network was able to capture the underlying logical patterns and reason about new family tree instances not seen during training.<p>This seminal work highlighted that neural networks can go beyond just memorizing training examples, and instead learn abstract representations that enable reasoning and generalization&quot;<p>&gt; We know next to nothing about how the human brain works<p>We understand how parts of it work.</div><br/></div></div></div></div></div></div></div></div><div id="39699173" class="c"><input type="checkbox" id="c-39699173" checked=""/><div class="controls bullet"><span class="by">m-p-3</span><span>|</span><a href="#39700077">prev</a><span>|</span><label class="collapse" for="c-39699173">[-]</label><label class="expand" for="c-39699173">[1 more]</label></div><br/><div class="children"><div class="content">I thought this was about making the OpenAI app available as a digital assistant on Android, as a replacement to Google.<p>Oh well..</div><br/></div></div></div></div></div></div></div></body></html>