<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711875653635" as="style"/><link rel="stylesheet" href="styles.css?v=1711875653635"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://bitbashing.io/gc-for-systems-programmers.html">Garbage collection for systems programmers (2023)</a> <span class="domain">(<a href="https://bitbashing.io">bitbashing.io</a>)</span></div><div class="subtext"><span>ingve</span> | <span>180 comments</span></div><br/><div><div id="39875715" class="c"><input type="checkbox" id="c-39875715" checked=""/><div class="controls bullet"><span class="by">teleforce</span><span>|</span><a href="#39875880">next</a><span>|</span><label class="collapse" for="c-39875715">[-]</label><label class="expand" for="c-39875715">[8 more]</label></div><br/><div class="children"><div class="content">For promising modern and parallel GC techniques please check MPL or MaPLe with its novel Automatic Management of Parallelism. It won distinguished paper award in POPL 2024 and ACM SIGPLAN dissertation award 2023 by proposing these two main things [1],[2]:<p>a) Provably efficient parallel garbage collection based on disentanglement<p>b) Provably efficient automatic granularity control<p>[1] MaPLe (MPL):<p><a href="https:&#x2F;&#x2F;github.com&#x2F;MPLLang&#x2F;mpl">https:&#x2F;&#x2F;github.com&#x2F;MPLLang&#x2F;mpl</a><p>[2] Automatic Parallelism Management:<p><a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3632880" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3632880</a></div><br/><div id="39877686" class="c"><input type="checkbox" id="c-39877686" checked=""/><div class="controls bullet"><span class="by">zogrodea</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39877354">next</a><span>|</span><label class="collapse" for="c-39877686">[-]</label><label class="expand" for="c-39877686">[1 more]</label></div><br/><div class="children"><div class="content">Standard ML and the community around it has been pretty impressive as far as contributions to memory management literature goes.<p>There is of course the paper you linked, and there&#x27;s also the MLKit which was among the first users, and one of the pioneers, of region-based memory management.</div><br/></div></div><div id="39877354" class="c"><input type="checkbox" id="c-39877354" checked=""/><div class="controls bullet"><span class="by">bool3max</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39877686">prev</a><span>|</span><a href="#39881712">next</a><span>|</span><label class="collapse" for="c-39877354">[-]</label><label class="expand" for="c-39877354">[1 more]</label></div><br/><div class="children"><div class="content">What does &quot;provably efficient&quot; mean?</div><br/></div></div><div id="39881712" class="c"><input type="checkbox" id="c-39881712" checked=""/><div class="controls bullet"><span class="by">prisenco</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39877354">prev</a><span>|</span><a href="#39878786">next</a><span>|</span><label class="collapse" for="c-39881712">[-]</label><label class="expand" for="c-39881712">[1 more]</label></div><br/><div class="children"><div class="content">Question for people who are more qualified: How applicable is this to other languages? Could this approach significantly speed up garbage collection in Go for example?<p>Or do we run into design issues with existing languages?</div><br/></div></div><div id="39878786" class="c"><input type="checkbox" id="c-39878786" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39881712">prev</a><span>|</span><a href="#39877259">next</a><span>|</span><label class="collapse" for="c-39878786">[-]</label><label class="expand" for="c-39878786">[2 more]</label></div><br/><div class="children"><div class="content">How does this compare against recent efforts in OCaml to support multicore parallelism?</div><br/><div id="39879912" class="c"><input type="checkbox" id="c-39879912" checked=""/><div class="controls bullet"><span class="by">zogrodea</span><span>|</span><a href="#39875715">root</a><span>|</span><a href="#39878786">parent</a><span>|</span><a href="#39877259">next</a><span>|</span><label class="collapse" for="c-39879912">[-]</label><label class="expand" for="c-39879912">[1 more]</label></div><br/><div class="children"><div class="content">One of the people who helped optimise the multi core implementation for OCaml said it was the way to go, but that was in 2020. Don’t know where things are now. <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23776609">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23776609</a></div><br/></div></div></div></div><div id="39877259" class="c"><input type="checkbox" id="c-39877259" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39878786">prev</a><span>|</span><a href="#39875792">next</a><span>|</span><label class="collapse" for="c-39877259">[-]</label><label class="expand" for="c-39877259">[1 more]</label></div><br/><div class="children"><div class="content">Great material, thanks for sharing.</div><br/></div></div><div id="39875792" class="c"><input type="checkbox" id="c-39875792" checked=""/><div class="controls bullet"><span class="by">bugbuddy</span><span>|</span><a href="#39875715">parent</a><span>|</span><a href="#39877259">prev</a><span>|</span><a href="#39875880">next</a><span>|</span><label class="collapse" for="c-39875792">[-]</label><label class="expand" for="c-39875792">[1 more]</label></div><br/><div class="children"><div class="content">Nice links. Thanks for posting these.</div><br/></div></div></div></div><div id="39875880" class="c"><input type="checkbox" id="c-39875880" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#39875715">prev</a><span>|</span><a href="#39875707">next</a><span>|</span><label class="collapse" for="c-39875880">[-]</label><label class="expand" for="c-39875880">[14 more]</label></div><br/><div class="children"><div class="content">The RCU use case is convincing, but my experience with GCs in other situations has been poor.
To me, this reads more like an argument for bespoke memory management solutions being able to yield the best performance (I agree!), which is a totally different case from the more general static lifetimes generally outperforming dynamic lifetimes (especially when a tracing step is needed to determine liveness).<p>&gt; Lies people believe... Calling free() gives the memory back to the OS.<p>I believe calling `free()` gives the memory back to the allocator, which is much better than giving it to the OS; syscalls are slow.
Perhaps not immediately; mimalloc only makes frees available to future `malloc`s periodically.<p>Trying a simple benchmark where I allocate and then immediately `free` 800 bytes, 1 million times, and counting the number of unique pointers I get:
glibc&#x27;s malloc: 1
jemalloc: 1
mimalloc: 4
Julia&#x27;s garbage collector: 62767<p>62767, at about 48 MiB, isn&#x27;t that bad, but it still blows out my computer&#x27;s L3 cache.
Using a GC basically guarantees every new allocation is from RAM, rather than cache. This kills performance of any heavily allocating code; we don&#x27;t care only about how fast memory management can work, but how quickly we can worth with what it gives us.
I gave a benchmark in Julia showcasing this: <a href="https:&#x2F;&#x2F;discourse.julialang.org&#x2F;t&#x2F;blog-post-rust-vs-julia-in-scientific-computing&#x2F;101711&#x2F;80?u=elrod" rel="nofollow">https:&#x2F;&#x2F;discourse.julialang.org&#x2F;t&#x2F;blog-post-rust-vs-julia-in...</a><p>Malloc&#x2F;free gives you a chance at staying hot, if your actual working memory is small enough.<p>Allocators like mimalloc are also designed (like the compacting GC) to have successive allocations be close together. The 4 unique pointers I got from mimalloc were 896 bytes apart.<p>My opinions might be less sour if I had more experience with compacting GCs, but I think GCs are just a vastly more complicated solution to the problem of safe memory management than something like Rust&#x27;s borrow checker.
Given that the complexity is foisted on the compiler and runtime developers, that&#x27;s normally not so bad for users, and an acceptable tradeoff when writing code that isn&#x27;t performance sensitive.
Similarly, RAII with static lifetimes is also a reasonable tradeoff for code not important enough for more bespoke approaches.
The articles example is evidently one of those deserving a more bespoke solution.</div><br/><div id="39876139" class="c"><input type="checkbox" id="c-39876139" checked=""/><div class="controls bullet"><span class="by">chc4</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39878183">next</a><span>|</span><label class="collapse" for="c-39876139">[-]</label><label class="expand" for="c-39876139">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really not enough to just say that a GC gave you more pointers = it has worse cache locality. Compacting GC almost always has <i>better</i> cache utilization than malloc, because heap fragmentation over long-running programs will waste TLB cache entries and slack space between objects. A bump allocator from a compacting GC will give you a new pointer for each allocation because free doesn&#x27;t reclaim the memory...but those allocations will be sequentially, and if you were in the case where you are churning through your heap and only ever touch the most recent object they will always be in cache still. Benchmarking the knock-on effects of allocators and GCs are insanely difficult and I&#x27;m very skeptical of basically any synthetic benchmarks like this.</div><br/><div id="39876293" class="c"><input type="checkbox" id="c-39876293" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39876139">parent</a><span>|</span><a href="#39876345">next</a><span>|</span><label class="collapse" for="c-39876293">[-]</label><label class="expand" for="c-39876293">[1 more]</label></div><br/><div class="children"><div class="content">I think the fact that it is complicated to reason about is precisely why systems developers don’t trust GC’s.<p>It’s far easier to write a threadsafe bump (slab) allocator than to locate and diagnose the code that someone wrote two years ago and, as of last week, started causing the GC to blow up the cache, contend on a lock, fragment the heap, add unbounded pauses, burn an extra cpu, etc, etc.<p>(Though, at this point, most mallocs are so good that the slab allocator loses anyway and there’s no need to bother.)</div><br/></div></div><div id="39876345" class="c"><input type="checkbox" id="c-39876345" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39876139">parent</a><span>|</span><a href="#39876293">prev</a><span>|</span><a href="#39876294">next</a><span>|</span><label class="collapse" for="c-39876345">[-]</label><label class="expand" for="c-39876345">[1 more]</label></div><br/><div class="children"><div class="content">FWIW, that synthetic benchmark was reflective of some real world code we were deploying.
Using malloc&#x2F;free for one function led to something like a 2x performance improvement of the whole program.<p>I think it&#x27;s important to differentiate between malloc implementations&#x2F;algorithms, just like it&#x27;s important to differentiate between GCs.
E.g., mimalloc &quot;shards&quot; size classes into pages, with separate free lists per page. This way, subsequent allocations are all from the same page. Freeing does not free eagerly; only if the entire page is freed, or if we hit a new allocation and the page is empty, then it can hit a periodic slow path to do deferred work.
<a href="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;uploads&#x2F;prod&#x2F;2019&#x2F;06&#x2F;mimalloc-tr-v1.pdf" rel="nofollow">https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;uploads&#x2F;prod&#x2F;2019&#x2F;0...</a><p>Good malloc implementations can also employ techniques to avoid fragmentation.
It&#x27;s unfortunate that the defaults are bad.<p>But I confess, compacting GCs and profiling the effects of heap fragmentation (especially over time in long running programs) are both things I lack experience in. Microbenchmarks are unlikely to capture that accurately.</div><br/></div></div><div id="39876294" class="c"><input type="checkbox" id="c-39876294" checked=""/><div class="controls bullet"><span class="by">convolvatron</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39876139">parent</a><span>|</span><a href="#39876345">prev</a><span>|</span><a href="#39878183">next</a><span>|</span><label class="collapse" for="c-39876294">[-]</label><label class="expand" for="c-39876294">[1 more]</label></div><br/><div class="children"><div class="content">compaction really does help runtimes alot. but I&#x27;m not sure how much it really has to do with line level locality. in general we don&#x27;t try to batch related objects together except in a coarse form by generation.<p>I think the measurable benefit comes from page level savings, both reducing the number of trips to the kernel to get zeroes pages, and from reduced pressure on the tlb.<p>but I have definitely seen numbers like 20% on some workloads for turning on compaction</div><br/></div></div></div></div><div id="39878183" class="c"><input type="checkbox" id="c-39878183" checked=""/><div class="controls bullet"><span class="by">arcticbull</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39876139">prev</a><span>|</span><a href="#39876780">next</a><span>|</span><label class="collapse" for="c-39878183">[-]</label><label class="expand" for="c-39878183">[4 more]</label></div><br/><div class="children"><div class="content">The post explains why this works in the RCU context, why it sucks in general, and then just writes it off and ignores it.<p>&gt; At this point, some folks fire back with non-arguments about how this isn’t “real” garbage collection. Like, uh, because you manually mark the garbage!<p>Yeah. People&#x27;s concerns are that the process of figuring out what memory is not longer used is inefficient and non-deterministic relative to simply telling the allocator when you&#x27;re done with a resource. I&#x27;ve never met someone who&#x27;s been concerned with deferring deallocation.<p>Sure traversing the whole live set is rare and we&#x27;ve spent 30 years tweaking GC algorithms to make them better, and now they&#x27;re practically sentient. However this statement either willfully or unintentionally writes off the thing people actually have an issue with. If you run into GC issues in your services you have to bring in a shaman to tweak things here and there hoping it sends the angry spirits back to the shadow realm.<p>If you&#x27;re just marking the garbage and being notified when it&#x27;s no longer used, that entire process is gone.<p>Yes, it can be very fast to allocate memory in a GC. This ignores the cost of marking and compaction that actually need to be amortized in to get a fair comparison.<p>The other big issue people have with GC is that in general it requires <i>significantly</i> more memory than manual memory management to achieve equivalent performance. And you have to have a bunch of extra CPU power to throw at redundantly checking if things are still referenced over and over. And you have to be okay with a bunch of extra memory copies for optimistic compaction.<p>Finally the post criticizes manual memory management (Rust&#x27;s Arc&#x2F;Rc) as being necessary when you have unclear lifetimes - but ignores that you basically build the exact same infrastructure in GC&#x27;d languages to close external resources as you can&#x27;t rely on finalizers ever being called.<p>Anyways this has been beaten to death for the last 20-30 years and this article doesn&#x27;t seem to bring anything new to the table besides ignoring the legitimate concerns of a GC using memes, which is fine because memes are fun IMO.<p>The correct answer is exactly what you say - there is no general correct answer. You use the tool appropriate to the job to meet the design constraints of the system.</div><br/><div id="39880933" class="c"><input type="checkbox" id="c-39880933" checked=""/><div class="controls bullet"><span class="by">rerdavies</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39878183">parent</a><span>|</span><a href="#39876780">next</a><span>|</span><label class="collapse" for="c-39880933">[-]</label><label class="expand" for="c-39880933">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve never met someone who&#x27;s been concerned with deferring deallocation.<p>Realtime audio processing (instruments and effects), where malloc&#x2F;free can never be called on the realtime audio thread. Deallocations have to be deferred.<p>If it matters for realtime audio, I cannot imagine that it would not matter for twitch games as well.<p>In non-GC languages the audio thread can be kept running even when changing audio plugins, as long as allocations and deallocations are not performed on the audio thread.<p>Realtime audio synthesis is possible in .net; but no memory allocations can occur anywhere in the entire realtime audio process. It is possible to write allocation-free message queues between a UI process and a realtime process. If allocations do occur in the realtime audio process, the realtime thread has to be suspended at some point in order to grab object references on the stack of the realtime thread -- a process that can take 2ms or more in .net GCs (which is more than enough to case audio dropouts).[1]</div><br/><div id="39880998" class="c"><input type="checkbox" id="c-39880998" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39880933">parent</a><span>|</span><a href="#39876780">next</a><span>|</span><label class="collapse" for="c-39880998">[-]</label><label class="expand" for="c-39880998">[2 more]</label></div><br/><div class="children"><div class="content">Many of the systems I have seen that need to be deterministic and fast but still need to allocate will use pool allocators or slab allocators. The edge cases mean that malloc&#x2F;free is not in the conversation. I suppose that pre-allocating objects and deferring deallocation would also work, but that seems roughly equivalent to pool allocation.<p>The null allocator is the fastest allocator, though!</div><br/><div id="39881243" class="c"><input type="checkbox" id="c-39881243" checked=""/><div class="controls bullet"><span class="by">rerdavies</span><span>|</span><a href="#39875880">root</a><span>|</span><a href="#39880998">parent</a><span>|</span><a href="#39876780">next</a><span>|</span><label class="collapse" for="c-39881243">[-]</label><label class="expand" for="c-39881243">[1 more]</label></div><br/><div class="children"><div class="content">Yes. Lots of pool allocators as well. :-)<p>The principle application is making changes to Audio plugin chains without stopping the real-time audio thread. The new chain has to be pre-allocated, and the old chain has to be sent off-thread to get deallocated on a deferred basis. You can&#x27;t pool-allocate a VST or an LV2 audio plugin.<p>Data subscriptions (Audio VU data and control port values) also use a similar deferred deallocation scheme. Doing so allows use of mutexes and shared ptrs in dependent non-realtime data structures.</div><br/></div></div></div></div></div></div></div></div><div id="39876780" class="c"><input type="checkbox" id="c-39876780" checked=""/><div class="controls bullet"><span class="by">louthy</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39878183">prev</a><span>|</span><a href="#39877343">next</a><span>|</span><label class="collapse" for="c-39876780">[-]</label><label class="expand" for="c-39876780">[1 more]</label></div><br/><div class="children"><div class="content">This makes no sense to me. In a generational GC gen-0 is more likely than not to be cached — and that’s where the ‘churn’ is. Outside of that, any longer lived allocations are by definition not easy to control cache-wise.<p>Locality is one of the big wins for GCs, the only issue I’m aware of is the ‘stop the world’ mark&#x2F;sweep (yes, I know modern GCs have a background thread — but you still get stop-the-world events afaik)</div><br/></div></div><div id="39877343" class="c"><input type="checkbox" id="c-39877343" checked=""/><div class="controls bullet"><span class="by">MichaelMoser123</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39876780">prev</a><span>|</span><a href="#39876950">next</a><span>|</span><label class="collapse" for="c-39877343">[-]</label><label class="expand" for="c-39877343">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I believe calling `free()` gives the memory back to the allocator, which is much better than giving it to the OS<p>Having to deal with memory fragmentation in long running servers is no fun at all, especially internal fragmentation of pages maintained by slab allocators.<p>this is not a very common problem, but it is a hard one to deal with.</div><br/></div></div><div id="39876950" class="c"><input type="checkbox" id="c-39876950" checked=""/><div class="controls bullet"><span class="by">darby_eight</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39877343">prev</a><span>|</span><a href="#39879073">next</a><span>|</span><label class="collapse" for="c-39876950">[-]</label><label class="expand" for="c-39876950">[1 more]</label></div><br/><div class="children"><div class="content">If cache usage is that major of a concern, arena allocation works just as well as it does with manual memory allocation. Thankfully there aren&#x27;t too many areas where garbage collection has to compete with such conveniently contrived examples.</div><br/></div></div><div id="39879073" class="c"><input type="checkbox" id="c-39879073" checked=""/><div class="controls bullet"><span class="by">osigurdson</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39876950">prev</a><span>|</span><a href="#39878880">next</a><span>|</span><label class="collapse" for="c-39879073">[-]</label><label class="expand" for="c-39879073">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; My opinions might be less sour if I had more experience with compacting GCs<p>I have quite a bit of experience with the GC in .NET. For projects that deal with large data structures, the GC is something that you are always thinking about though it&#x27;s behavior is conceptually transparent. I think I would ultimately prefer a more explicit approach.</div><br/></div></div><div id="39878880" class="c"><input type="checkbox" id="c-39878880" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#39875880">parent</a><span>|</span><a href="#39879073">prev</a><span>|</span><a href="#39875707">next</a><span>|</span><label class="collapse" for="c-39878880">[-]</label><label class="expand" for="c-39878880">[1 more]</label></div><br/><div class="children"><div class="content">free() gives back memory to your local POSIX. :)</div><br/></div></div></div></div><div id="39875707" class="c"><input type="checkbox" id="c-39875707" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875880">prev</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39875707">[-]</label><label class="expand" for="c-39875707">[77 more]</label></div><br/><div class="children"><div class="content">Except in the special case where all memory can be easily handled in arenas, good tracing GCs have long ago surpassed manual memory management in throughput, and more recently their latency impact is more than acceptable for the vast majority of applications (OpenJDK&#x27;s ZGC has typical pause times measured in double&#x2F;triple-digit microseconds, and the worst case rarely exceeds 1ms for a reasonable allocation rate -- the pauses are in the same ballpark as OS-induced ones). The only real and significant tradeoff is in memory footprint, and outside of specialty niches (where arenas just work for everything and worst-case latency is in the low microseconds range) that is the only high order question: is my application running in a memory-constrained environment (or it&#x27;s really worth it to sacrifice other things to keep down RAM consumption) or not?</div><br/><div id="39882484" class="c"><input type="checkbox" id="c-39882484" checked=""/><div class="controls bullet"><span class="by">mtzet</span><span>|</span><a href="#39875707">parent</a><span>|</span><a href="#39875990">next</a><span>|</span><label class="collapse" for="c-39882484">[-]</label><label class="expand" for="c-39882484">[1 more]</label></div><br/><div class="children"><div class="content">&gt; special case where all memory can be easily handled in arenas
That seems to be an unfair bar to set. If _most_ objects are easily allocated by an arena, then that still removes most of the need for GC.<p>I like Jai&#x27;s thesis that there&#x27;s four types of memory allocations, from most common to least common:<p>1. Extremely short lived. Can be allocated on the function stack.<p>2. Short lived + well-defined lifetime (per frame&#x2F;request). Can be allocated in a memory arena.<p>3. Long lived + well-defined owner. Can be managed by a subsystem-specific pool.<p>4. Long lived + unclear owner. Needs a dynamic memory management approach.<p>If you want to make the claim that tracing GCs surpass manual memory management in general, you should compare to a system written with this in mind, not one that calls malloc&#x2F;free all over the place. I guess it might be more fair if you compare tracing GC with modern c++&#x2F;rust practices.<p>I agree that for most systems, it&#x27;s probably much more _practical_ to rely on tracing GC, but that&#x27;s a very different statement.</div><br/></div></div><div id="39875990" class="c"><input type="checkbox" id="c-39875990" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39875707">parent</a><span>|</span><a href="#39882484">prev</a><span>|</span><a href="#39876125">next</a><span>|</span><label class="collapse" for="c-39875990">[-]</label><label class="expand" for="c-39875990">[29 more]</label></div><br/><div class="children"><div class="content">&gt; Except in the special case ...<p>IME it&#x27;s the other way around, per-object individual lifetimes is a rare special case, in most real world code there will be many related objects of the same or very similar lifetimes. In such code, tracking individual object lifetimes is overkill (in the end, memory management is all about lifetimes, and fewer individual lifetimes instead of many is always better because it means less work, both in manual and automatic memory management).<p>Not having to think about object lifetimes is just very convenient, that&#x27;s why GC languages were successful despite the significant under-the-hood complexity of a good garbage collector.</div><br/><div id="39876083" class="c"><input type="checkbox" id="c-39876083" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39875990">parent</a><span>|</span><a href="#39877326">next</a><span>|</span><label class="collapse" for="c-39876083">[-]</label><label class="expand" for="c-39876083">[9 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not at all a rare special case in most server applications.<p>One way to see that is to consider how much of a program&#x27;s working set is in threads&#x27; stacks vs the heap. If the most of the working set is in the heap, there&#x27;s <i>usually</i> some non-trivial object lifetimes involved (i.e. cases where lifetimes can be encapsulated and abstracted away from client code). Yes, sometimes all of these can be taken care of by arenas (and there are languages, like Zig, that strive to be very arena-friendly), but that -- i.e. the case where all objects are easily arena-able -- is not the more common scenario.</div><br/><div id="39876171" class="c"><input type="checkbox" id="c-39876171" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876083">parent</a><span>|</span><a href="#39877326">next</a><span>|</span><label class="collapse" for="c-39876171">[-]</label><label class="expand" for="c-39876171">[8 more]</label></div><br/><div class="children"><div class="content">Depends on the type of server I guess. I can easily imagine a situation where all allocations of a request are handled through a simple bump allocator, and once the request is done, the bump allocator is reset instead of &#x27;freeing&#x27; each individual allocation.</div><br/><div id="39877456" class="c"><input type="checkbox" id="c-39877456" checked=""/><div class="controls bullet"><span class="by">cogman10</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876171">parent</a><span>|</span><a href="#39877717">next</a><span>|</span><label class="collapse" for="c-39877456">[-]</label><label class="expand" for="c-39877456">[2 more]</label></div><br/><div class="children"><div class="content">This would only work for fairly trivial applications.  The moment you start adding things like http clients or databases you have to start considering having connection pools with lifetimes that don&#x27;t strictly match a request lifecycle.<p>Not saying such an application doesn&#x27;t exist, it certainly does.</div><br/></div></div><div id="39877717" class="c"><input type="checkbox" id="c-39877717" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876171">parent</a><span>|</span><a href="#39877456">prev</a><span>|</span><a href="#39877505">next</a><span>|</span><label class="collapse" for="c-39877717">[-]</label><label class="expand" for="c-39877717">[3 more]</label></div><br/><div class="children"><div class="content">How did we go from &quot;this is the most common case&quot; to &quot;I can imagine it?&quot;  Sure there are cases where a request can be handled by the stack but the point is that the more complex case is extremely common.<p>Any kind of background&#x2F;asynchronous work spawned from a request and your plans are shot.</div><br/><div id="39879548" class="c"><input type="checkbox" id="c-39879548" checked=""/><div class="controls bullet"><span class="by">thefaux</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877717">parent</a><span>|</span><a href="#39877505">next</a><span>|</span><label class="collapse" for="c-39879548">[-]</label><label class="expand" for="c-39879548">[2 more]</label></div><br/><div class="children"><div class="content">Yes and that is yet another case for encapsulation.<p>For me, it is an antipattern for a short lived task to be directly creating long lived resources. Async work ideally is scheduled using message passing to the task manager which may have its own memory management strategy (heck, the background task may well be written in an entirely different language).<p>I just feel that it is very common to have large portions of the application that fit the model of read input&#x2F;write output, free all intermediate data upon completion. Due to a lack of encapsulation, however, we put unnecessary pressure on the allocator or garbage collector by mixing the short and long lived parts of our applications.</div><br/></div></div></div></div><div id="39877505" class="c"><input type="checkbox" id="c-39877505" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876171">parent</a><span>|</span><a href="#39877717">prev</a><span>|</span><a href="#39877326">next</a><span>|</span><label class="collapse" for="c-39877505">[-]</label><label class="expand" for="c-39877505">[2 more]</label></div><br/><div class="children"><div class="content">That “simple bump allocator” is basically allocating everything on the thread&#x27;s stack, as the GP mentioned.<p>It&#x27;s what you put on the heap that has complex lifetimes. Sometimes you can fix that with an arena. If you can&#x27;t, you probably can&#x27;t figure out when the last reference to it dies either.</div><br/></div></div></div></div></div></div><div id="39877326" class="c"><input type="checkbox" id="c-39877326" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39875990">parent</a><span>|</span><a href="#39876083">prev</a><span>|</span><a href="#39876110">next</a><span>|</span><label class="collapse" for="c-39877326">[-]</label><label class="expand" for="c-39877326">[17 more]</label></div><br/><div class="children"><div class="content">&gt; IME it&#x27;s the other way around, per-object individual lifetimes is a rare special case<p>It depends on your application domain.  But in most cases where objects have &quot;individual lifetimes&quot; you can still use reference counting, which has lower latency and memory overhead than tracing GC and interacts well with manual memory management.  Tracing GC can then be &quot;plugged in&quot; for very specific cases, preferably using a high performance concurrent implementation much like <a href="https:&#x2F;&#x2F;github.com&#x2F;chc4&#x2F;samsara">https:&#x2F;&#x2F;github.com&#x2F;chc4&#x2F;samsara</a> (for Rust) or <a href="https:&#x2F;&#x2F;github.com&#x2F;pebal&#x2F;sgcl">https:&#x2F;&#x2F;github.com&#x2F;pebal&#x2F;sgcl</a> (for C++).</div><br/><div id="39877959" class="c"><input type="checkbox" id="c-39877959" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877326">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39877959">[-]</label><label class="expand" for="c-39877959">[13 more]</label></div><br/><div class="children"><div class="content">Reference counting does not have lower latency than a tracing GC nor is it more generally predictable. In terms of performance, it is usually worse than a modern tracing GC by most performance metrics. Its benefits are, indeed, lower memory footprint and that it can achieve reasonable latency even using a crude implementation. In other words, you&#x27;d reach for refcounting either if you mostly care about footprint or if you don&#x27;t have a lot of resources to invest in implementing the GC.<p>Modern concurrent tracing has very little impact on latency. First, compared to refcounting, the barriers are rarely invoked. Second, they compact the heap concurrently in the background, and like all mark-compact GCs, their amortized cost drops to zero as the RAM increases (the work is linear with the size of the working set, which is roughly constant for a given program, but it needs to be done less frequently the more RAM you have). That&#x27;s why high-performance languages that rely heavily on a GC -- Java, C#, Go -- prefer tracing.</div><br/><div id="39878668" class="c"><input type="checkbox" id="c-39878668" checked=""/><div class="controls bullet"><span class="by">bluGill</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877959">parent</a><span>|</span><a href="#39878125">next</a><span>|</span><label class="collapse" for="c-39878668">[-]</label><label class="expand" for="c-39878668">[6 more]</label></div><br/><div class="children"><div class="content">when the reference count can only be zero or one reference counts have different performance than when it can be more, and it is much easier to reason about. This is most cases.</div><br/><div id="39879227" class="c"><input type="checkbox" id="c-39879227" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878668">parent</a><span>|</span><a href="#39879128">next</a><span>|</span><label class="collapse" for="c-39879227">[-]</label><label class="expand" for="c-39879227">[1 more]</label></div><br/><div class="children"><div class="content">And yet, the reason tracing GCs are chosen by virtually all high-performance languages that heavily rely on GC is that they&#x27;ve been found to be faster in practice for the common workloads.<p>One of the reasons why your intuition is not so straightforward is that a tracing GC needs to do no work whatsoever when the number of references is zero. One of the common ways to teach the basics of GC is by starting out as looking at tracing and refcounting as duals: refcounting needs to work to free objects, while tracing works to keep them alive. If you thinking in terms of what work needs to be done to promptly determine when an object becomes garbage, then you&#x27;re already not thinking in terms of tracing, because tracing never actually needs to learn about when an object becomes garbage (this isn&#x27;t actually true when they do reference processing, but that&#x27;s another story).<p>Or, if you want to think about it another way, in a tracing collector there are already only two cases no matter how many pointers there are to an object: reachable or not, i.e. the same one and zero as in your case, only there isn&#x27;t even a need to ever set the counter to zero.<p>However, in principle tracing and refcounting can be quite similar (<a href="https:&#x2F;&#x2F;www.cs.cornell.edu&#x2F;courses&#x2F;cs6120&#x2F;2019fa&#x2F;blog&#x2F;unified-theory-gc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cs.cornell.edu&#x2F;courses&#x2F;cs6120&#x2F;2019fa&#x2F;blog&#x2F;unifie...</a>) in their behaviour, but in practice <i>most</i> refcounting GCs in industry use are crude, and don&#x27;t match the performance of tracing GCs in common use, which are quite sophisticated.</div><br/></div></div><div id="39879128" class="c"><input type="checkbox" id="c-39879128" checked=""/><div class="controls bullet"><span class="by">rbehrends</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878668">parent</a><span>|</span><a href="#39879227">prev</a><span>|</span><a href="#39878871">next</a><span>|</span><label class="collapse" for="c-39879128">[-]</label><label class="expand" for="c-39879128">[3 more]</label></div><br/><div class="children"><div class="content">What happens if a large std::unordered_map&lt;std::string, std::string&gt; has its destructor called?<p>The maximum number of references is a red herring. While having a RC capped at 1 allows you to elide the actual reference count and makes pointer assignment cheaper, it does not materially affect the primary source of latency in a reference counting implementation, namely cascading deletions.</div><br/><div id="39879231" class="c"><input type="checkbox" id="c-39879231" checked=""/><div class="controls bullet"><span class="by">bluGill</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39879128">parent</a><span>|</span><a href="#39878871">next</a><span>|</span><label class="collapse" for="c-39879231">[-]</label><label class="expand" for="c-39879231">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t do that. good data design and architecture is always needed.</div><br/><div id="39880844" class="c"><input type="checkbox" id="c-39880844" checked=""/><div class="controls bullet"><span class="by">rbehrends</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39879231">parent</a><span>|</span><a href="#39878871">next</a><span>|</span><label class="collapse" for="c-39880844">[-]</label><label class="expand" for="c-39880844">[1 more]</label></div><br/><div class="children"><div class="content">1. Such data structures (or more generally, std::vector&lt;std::string, std::vector&lt;std::string&gt;&gt; or something like that) are the natural way to represent e.g. dictionaries. So, you absolutely often need to do that and &quot;don&#x27;t do that&quot; doesn&#x27;t help here.<p>2. This general issue extends to virtually all collections. The idea that you should avoid large collections is not a practical solution to real world problems.<p>3. An alternative solution would be lazy destruction, but that comes with its own issues, such as a really bad worst-case memory overhead or making RC sufficiently more complex that it&#x27;s not really a win over tracing GC anymore [1].<p>[1] <a href="https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;doi=3eef7ac270d541eae847a12a7762672c4f2638cd" rel="nofollow">https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;d...</a></div><br/></div></div></div></div></div></div><div id="39878871" class="c"><input type="checkbox" id="c-39878871" checked=""/><div class="controls bullet"><span class="by">dmurray</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878668">parent</a><span>|</span><a href="#39879128">prev</a><span>|</span><a href="#39878125">next</a><span>|</span><label class="collapse" for="c-39878871">[-]</label><label class="expand" for="c-39878871">[1 more]</label></div><br/><div class="children"><div class="content">This sounds intuitively true. So...what if GC languages could introduce an optional annotation for an object to say that only one reference to it can exist, and use that as a hint to the GC?<p>I don&#x27;t see how this could be implemented in a safe and performant way - either you check for existing references at runtime, or you risk some use-after-free bug. But perhaps your project is already in a GC language and you&#x27;re happy with that, but just want to optimise GC for this critical component. And we already have the concept of &quot;unsafe&quot; code blocks in many languages.<p>Does anything like this exist? I Googled &quot;smart pointers in Java&quot; but just got a bunch of mid-quality answers where people explained that I&#x27;m stupid for even asking this and they&#x27;re unnecessary because Java manages its own memory. But hasn&#x27;t someone smarter thought of this?</div><br/></div></div></div></div><div id="39878125" class="c"><input type="checkbox" id="c-39878125" checked=""/><div class="controls bullet"><span class="by">lll-o-lll</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877959">parent</a><span>|</span><a href="#39878668">prev</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39878125">[-]</label><label class="expand" for="c-39878125">[6 more]</label></div><br/><div class="children"><div class="content">&gt; nor is it more generally predictable<p>Can you explain what you mean here? This does not match my experience or intuition.</div><br/><div id="39878240" class="c"><input type="checkbox" id="c-39878240" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878125">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39878240">[-]</label><label class="expand" for="c-39878240">[5 more]</label></div><br/><div class="children"><div class="content">In theory, refcounting and tracing can behave similarly [1], but assuming we&#x27;re speaking about their implementations in the industry (rather elaborate tracing GCs; rather crude refcounting GCs) then a refcounting GC would do some work as soon the refcount for a particular object drops to zero. When exactly that happens and how much work there is to do (and sometimes, what the fragmentation effect on heap is) are local properties that are not very predictable. In contrast, the amount of work a tracing GC needs to do when compacting is directly proportional to the program&#x27;s working set and the frequency in which it needs to do that work is proportional to the allocation rate -- both of which are fairly regular and predictable global properties for a given program. For stop-the-world GCs there was then the matter of the highly unpredictable exact timing of a large STW pause, but modern concurrent GCs don&#x27;t collect anything in STW pauses anymore. They only have very short (sub 1ms) and constant-time pauses and no surprise throttling as long as the allocation rate is within an acceptable range. So all in all, you pay a fairly fixed tax on the CPU (and if you want to pay less, just add more RAM) and virtually no impact on latency.<p>[1]: <a href="https:&#x2F;&#x2F;www.cs.cornell.edu&#x2F;courses&#x2F;cs6120&#x2F;2019fa&#x2F;blog&#x2F;unified-theory-gc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cs.cornell.edu&#x2F;courses&#x2F;cs6120&#x2F;2019fa&#x2F;blog&#x2F;unifie...</a></div><br/><div id="39878465" class="c"><input type="checkbox" id="c-39878465" checked=""/><div class="controls bullet"><span class="by">lll-o-lll</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878240">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39878465">[-]</label><label class="expand" for="c-39878465">[4 more]</label></div><br/><div class="children"><div class="content">Thanks for responding. My experience with tracing GC at scale is exclusively in the realm of .Net, and RC exclusively with C++ smart pointers. That matches your “sophisticated vs crude” contrast.<p>The experience with .Net is that GC impact was difficult to profile and correct, and also “lumpy”, although that may have been before GC tuning. GC would dominate performance profiling in heavy async code, but these days can be corrected by value tasks and other zero alloc methods.<p>For C++ style ref counting, the impact was a continuous % load and simple to profile (and therefore improve). Although here, the ref counting needed to be stripped from the hot paths.<p>The biggest issue I’ve hit between the two modes though, is how they behave when hitting memory limits. Tracing GC appears to have an order of magnitude perf hit when memory becomes scarce, while ref counting does not suffer in this way. This is enough for me to personally dislike tracing GC, as that failure state is particularly problematic.</div><br/><div id="39878548" class="c"><input type="checkbox" id="c-39878548" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878465">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39878548">[-]</label><label class="expand" for="c-39878548">[3 more]</label></div><br/><div class="children"><div class="content">When you hit memory limits, .NETs GC implementation would perform much more frequent, invasive and aggressive collections, including LOH compaction to reduce memory watermark which leads to greater GC pauses, though this is rarely seen in such a bad way on modern versions with e.g. SRV GC.<p>The most scaling way to address this is usually to just allocate less and use valuetasks with pooling where applicable (frequent asynchronous yields), I&#x27;m certain if you built a .NET 8 based solution you would see user-written code dominate heap allocations profile, as most hot internal paths of async utilize said state machine box pooling+ValueTask&lt;T&gt;[0] and may be entirely allocation-free.<p>[0] Example: <a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;blob&#x2F;cc7bf831f02cad241547ebea5c56c82f12a50999&#x2F;src&#x2F;libraries&#x2F;System.Net.Http&#x2F;src&#x2F;System&#x2F;Net&#x2F;Http&#x2F;SocketsHttpHandler&#x2F;RawConnectionStream.cs#L44">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;blob&#x2F;cc7bf831f02cad241547e...</a></div><br/><div id="39879022" class="c"><input type="checkbox" id="c-39879022" checked=""/><div class="controls bullet"><span class="by">lll-o-lll</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878548">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39879022">[-]</label><label class="expand" for="c-39879022">[2 more]</label></div><br/><div class="children"><div class="content">&gt; When you hit memory limits, .NETs GC implementation would perform much more frequent, invasive and aggressive collections, including LOH compaction to reduce memory watermark which leads to greater GC pauses, though this is rarely seen in such a bad way on modern versions with e.g. SRV GC.<p>The trouble with server GC mode is that then there is no natural back pressure. If the processing is not CPU bound, then memory allocation can grow unbounded. This is not something that happens with RC as, again, the GC performance hit is inlined with task processing. The service may not be capable of as much throughput, but it doesn’t take out the entire server either.<p>&gt; The most scaling way to address this is usually to just allocate less and use valuetasks with pooling where applicable  (frequent asynchronous yields), I&#x27;m certain if you built a .NET 8 based solution you would see user-written code dominate heap allocations profile, as most hot internal paths of async utilize said state machine box pooling+ValueTask&lt;T&gt;[0] and may be entirely allocation-free.<p>Absolutely; I think it’s relatively simple to write servers that scale using modern .net; the memory allocation foot-guns when dealing with asynchronous code are now well understood, and tooling is good. I am compressing ~15 years of experiences in that previous post.<p>It’s probably the case that a tracing GC is the better choice for most modern applications, excepting memory constrained devices (like phones), and so long as you design with memory in mind.</div><br/><div id="39879187" class="c"><input type="checkbox" id="c-39879187" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39879022">parent</a><span>|</span><a href="#39880234">next</a><span>|</span><label class="collapse" for="c-39879187">[-]</label><label class="expand" for="c-39879187">[1 more]</label></div><br/><div class="children"><div class="content">Ah, I see where you are coming from.<p>You are correct, sustained load heap size of SRV GC has been a known pain point that had been particularly exacerbated after beefy Windows Server hosts fell out of fashion and got replaced by 512Mi Linux containers.<p>There has been work conducted on this each release throughout Core 2.1, 3.1, and then 5, 6, 7 and 8 versions to make it play nicer with more constrained memory limit systems.<p>The two major features that address this are Regions[0] (.NET 6&#x2F;7) and DATAS[1] (.NET 8). The former is enabled by default everywhere except macOS and the latter is available opt-in either via env var DOTNET_GCDynamicAdaptationMode=1 or msbuild poperty GarbageCollectionAdaptationMode: 1 (see more in [1]).<p>The latter has shown to significantly reduce sustained (or, especially, idling) heap size for some particularly problematic workloads (but not all, sometimes you just have a lot of live objects). I definitely recommend giving it a try if this is something still relevant to you.<p>TLDR of what DATAS does is dynamic heap count scaling and much smarter heap up&#x2F;downsizing depending on allocation rate&#x2F;frequency and anticipated throughput impact of adjusting those.<p>[0] <a href="https:&#x2F;&#x2F;itnext.io&#x2F;how-segments-and-regions-differ-in-decommitting-memory-in-the-net-7-gc-68c58465ab5a" rel="nofollow">https:&#x2F;&#x2F;itnext.io&#x2F;how-segments-and-regions-differ-in-decommi...</a> &#x2F; <a href="https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;dotnet&#x2F;put-a-dpad-on-that-gc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;dotnet&#x2F;put-a-dpad-on-that-gc&#x2F;</a><p>[1] <a href="https:&#x2F;&#x2F;maoni0.medium.com&#x2F;dynamically-adapting-to-application-sizes-2d72fcb6f1ea" rel="nofollow">https:&#x2F;&#x2F;maoni0.medium.com&#x2F;dynamically-adapting-to-applicatio...</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39880234" class="c"><input type="checkbox" id="c-39880234" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877326">parent</a><span>|</span><a href="#39877959">prev</a><span>|</span><a href="#39876110">next</a><span>|</span><label class="collapse" for="c-39880234">[-]</label><label class="expand" for="c-39880234">[3 more]</label></div><br/><div class="children"><div class="content">Reference counting is neither lower latency nor lower memory overhead than basically <i>everything else</i>.<p>Reference counting requires atomics on every single object.  Per object atomics are quite unfriendly to modern microprocessors.<p>There is either very little contention with lots of atomics that you don&#x27;t need or you have high contention with atomics that are blowing out your cache lines repeatedly.<p>In addition, managing reference counts practically requires RAII semantics and all of the baggage that goes along with that.  Doing reference counting in C, for example, is extremely error prone.</div><br/><div id="39880512" class="c"><input type="checkbox" id="c-39880512" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39880234">parent</a><span>|</span><a href="#39876110">next</a><span>|</span><label class="collapse" for="c-39880512">[-]</label><label class="expand" for="c-39880512">[2 more]</label></div><br/><div class="children"><div class="content">The reason Rust has both Arc and Rc types for reference counting is precisely because most of the time when you need reference counting, you do not need thread safety. This is something I think about all the time in C++ when I use std::shared_ptr: it gives me thread safety using atomics but I don&#x27;t need it.<p>More languages should distinguish between thread safe reference counting and single-threaded reference counting.</div><br/><div id="39881266" class="c"><input type="checkbox" id="c-39881266" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39880512">parent</a><span>|</span><a href="#39876110">next</a><span>|</span><label class="collapse" for="c-39881266">[-]</label><label class="expand" for="c-39881266">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The reason Rust has both Arc and Rc types for reference counting is precisely because most of the time when you need reference counting, you do not need thread safety.<p>Hmmm, I&#x27;m curious about your use cases as this is almost precisely opposite my experience.  Normally, I regard Rc as a footgun as I&#x27;ve always found that I&#x27;m shortly going to have to change everything to Arc.</div><br/></div></div></div></div></div></div></div></div><div id="39876110" class="c"><input type="checkbox" id="c-39876110" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39875990">parent</a><span>|</span><a href="#39877326">prev</a><span>|</span><a href="#39876125">next</a><span>|</span><label class="collapse" for="c-39876110">[-]</label><label class="expand" for="c-39876110">[2 more]</label></div><br/><div class="children"><div class="content">In generational GCs there are two or more allocation regions. New objects are put in the &quot;younger&quot; generation, which is garbage collected separated from the other generations. This sort of resolves the issue of tracking individual object lifetimes by having all the short-lived objects subject to rapid GC. This means most of the effort tracking lifetimes is reserved for the fewer long-lived objects.</div><br/><div id="39878145" class="c"><input type="checkbox" id="c-39878145" checked=""/><div class="controls bullet"><span class="by">lll-o-lll</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876110">parent</a><span>|</span><a href="#39876125">next</a><span>|</span><label class="collapse" for="c-39878145">[-]</label><label class="expand" for="c-39878145">[1 more]</label></div><br/><div class="children"><div class="content">It’s “medium term” objects that cause all the trouble. Async operations. That’s why .net invested heavily into zero-alloc tasks, as the gc would kill scaling in async heavy code.</div><br/></div></div></div></div></div></div><div id="39876125" class="c"><input type="checkbox" id="c-39876125" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#39875707">parent</a><span>|</span><a href="#39875990">prev</a><span>|</span><a href="#39876638">next</a><span>|</span><label class="collapse" for="c-39876125">[-]</label><label class="expand" for="c-39876125">[26 more]</label></div><br/><div class="children"><div class="content">Pauses are kind of solved but the CPU usage for the GC is still pretty high.<p>You&#x27;re still at the mercy of unpredictable tail latency and other corner cases.</div><br/><div id="39876151" class="c"><input type="checkbox" id="c-39876151" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876125">parent</a><span>|</span><a href="#39876987">next</a><span>|</span><label class="collapse" for="c-39876151">[-]</label><label class="expand" for="c-39876151">[24 more]</label></div><br/><div class="children"><div class="content">That goes for manual memory management -- and certainly languages with a reference-counting GC, like Rust -- as well. The main difference is by far footprint overhead.</div><br/><div id="39876922" class="c"><input type="checkbox" id="c-39876922" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876151">parent</a><span>|</span><a href="#39876505">next</a><span>|</span><label class="collapse" for="c-39876922">[-]</label><label class="expand" for="c-39876922">[6 more]</label></div><br/><div class="children"><div class="content">&gt; and certainly languages with a reference-counting GC, like Rust<p>It&#x27;s a mistake to say that the Rust <i>language</i> has reference counting. There&#x27;s a pair of reference-counting wrapper types in its standard library (Rc and Arc), or you can roll your own, but there&#x27;s no special support for these types in the language, and their use is optional. Most of the time, you won&#x27;t be using these reference-counting types. Box (the generic heap-allocated or &quot;boxed&quot; type) doesn&#x27;t use reference counting. String (and its several specialized variants) doesn&#x27;t use it. Vec (the generic heap-allocated array type) doesn&#x27;t use it. HashMap, HashSet, BTreeMap, BTreeSet, none of them use reference counting. And so on. You can write a lot of Rust code without using reference counting even once.<p>What the Rust language has is just C++-style RAII: when a value goes out of scope, if it implements Drop, its Drop::drop is called.</div><br/><div id="39877510" class="c"><input type="checkbox" id="c-39877510" checked=""/><div class="controls bullet"><span class="by">cogman10</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876922">parent</a><span>|</span><a href="#39877603">next</a><span>|</span><label class="collapse" for="c-39877510">[-]</label><label class="expand" for="c-39877510">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a mistake to say that the Rust language has reference counting.<p>Having these types in the standard library is the language having those types.<p>Perhaps it&#x27;s not integrated to the level that a language like swift is.  However, I think it&#x27;s reasonable to say the language supports Rc when the standard library  supports it.  I&#x27;d say the same thing about C++ with `shard_ptr`.<p>Otherwise you end up in weird pedantic notions about what a language has or does not have.  Does C have a heap?  Well, technically no since malloc and free are just function calls in the standard library and you can write valid C programs without calling those functions.</div><br/><div id="39877809" class="c"><input type="checkbox" id="c-39877809" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877510">parent</a><span>|</span><a href="#39877603">next</a><span>|</span><label class="collapse" for="c-39877809">[-]</label><label class="expand" for="c-39877809">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Having these types in the standard library is the language having those types.<p>It depends on whether you consider the standard library an indivisible part of the language or not. For Rust, it&#x27;s clearly not the case, since you have the #![no_std] mode in which only a subset of the standard library is available, and this subset does not include these reference counted wrapper types (or any heap-allocated type at all).<p>&gt; Perhaps it&#x27;s not integrated to the level that a language like swift is. However, I think it&#x27;s reasonable to say the language supports Rc when the standard library supports it. I&#x27;d say the same thing about C++ with `shard_ptr`.<p>It&#x27;s one thing to say a language &quot;supports reference counting&quot;, which only means you can use reference counting with it, and another thing to say &quot;[...] languages with a reference-counting GC&quot;, which implies that the language uses a GC for everything, and that GC is a reference-counting GC.<p>&gt; Does C have a heap? Well, technically no since malloc and free are just function calls in the standard library and you can write valid C programs without calling those functions.<p>It&#x27;s actually the same thing: C can run on either a &quot;hosted&quot; environment or a &quot;freestanding&quot; environment, and on the later, most of the standard library is not available, including malloc and free. So C does not necessarily have a heap when running on a freestanding environment.</div><br/><div id="39878402" class="c"><input type="checkbox" id="c-39878402" checked=""/><div class="controls bullet"><span class="by">arcticbull</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877809">parent</a><span>|</span><a href="#39877603">next</a><span>|</span><label class="collapse" for="c-39878402">[-]</label><label class="expand" for="c-39878402">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not part of std exactly, it&#x27;s part of alloc. It&#x27;s re-exported by std.<p>It would still be available in a #![no_std] environment using `extern crate alloc`.<p>This crate generally abstracts over the concept of allocation too, so relying on it doesn&#x27;t require you to also have an allocator - it just requires someone at some point specify one with #[global_allocator]</div><br/></div></div></div></div></div></div><div id="39877603" class="c"><input type="checkbox" id="c-39877603" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876922">parent</a><span>|</span><a href="#39877510">prev</a><span>|</span><a href="#39876505">next</a><span>|</span><label class="collapse" for="c-39877603">[-]</label><label class="expand" for="c-39877603">[2 more]</label></div><br/><div class="children"><div class="content">&gt; and their use is optional<p>It is not, if you have objects with dynamic lifetimes, and allocating them for the whole duration of the program is not an option.<p>Sure, their use can be much less than a managed language that can only do automatic memory management, but RC is objectively a worse from most perspective than tracing GC, except for the fact that they don’t need runtime support, and a slightly lower memory overhead.</div><br/><div id="39879768" class="c"><input type="checkbox" id="c-39879768" checked=""/><div class="controls bullet"><span class="by">arandomusername</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877603">parent</a><span>|</span><a href="#39876505">next</a><span>|</span><label class="collapse" for="c-39879768">[-]</label><label class="expand" for="c-39879768">[1 more]</label></div><br/><div class="children"><div class="content">*shared* objects with dynamic lifetimes.<p>With properly architected code, the times you need to use rc are extremely small.</div><br/></div></div></div></div></div></div><div id="39876505" class="c"><input type="checkbox" id="c-39876505" checked=""/><div class="controls bullet"><span class="by">MForster</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876151">parent</a><span>|</span><a href="#39876922">prev</a><span>|</span><a href="#39876198">next</a><span>|</span><label class="collapse" for="c-39876505">[-]</label><label class="expand" for="c-39876505">[1 more]</label></div><br/><div class="children"><div class="content">Rust by default doesn&#x27;t do reference counting.<p>You can opt into reference counting with `std::rc::Rc`.
(You can even opt into mark-and-sweep GC using the `gc` crate, but this isn&#x27;t done much...).</div><br/></div></div><div id="39876198" class="c"><input type="checkbox" id="c-39876198" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876151">parent</a><span>|</span><a href="#39876505">prev</a><span>|</span><a href="#39876549">next</a><span>|</span><label class="collapse" for="c-39876198">[-]</label><label class="expand" for="c-39876198">[15 more]</label></div><br/><div class="children"><div class="content">I think the important thing to understand is that reference counting isn&#x27;t any better (and often worse) than &quot;regular&quot; garbage collection.<p>The point of manual memory management is to come up with problem-specific strategies to avoid or at least reduce dynamic memory allocation, not to insert manual release&#x2F;free calls for individual objects ;)</div><br/><div id="39876242" class="c"><input type="checkbox" id="c-39876242" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876198">parent</a><span>|</span><a href="#39876243">next</a><span>|</span><label class="collapse" for="c-39876242">[-]</label><label class="expand" for="c-39876242">[13 more]</label></div><br/><div class="children"><div class="content">Reference counting <i>is</i> regular garbage collections. The two broad classes of GC algorithms are tracing and refcounting, and while they can converge to similar behaviour, <i>usually</i> the former optimises for throughput while the latter for memory footprint; latency is similar these days.</div><br/><div id="39876273" class="c"><input type="checkbox" id="c-39876273" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876242">parent</a><span>|</span><a href="#39876243">next</a><span>|</span><label class="collapse" for="c-39876273">[-]</label><label class="expand" for="c-39876273">[12 more]</label></div><br/><div class="children"><div class="content">&gt; Reference counting is regular garbage collection.<p>...while I agree, for many C++ and Rust coders statements like this are pure heresy ;)</div><br/><div id="39877088" class="c"><input type="checkbox" id="c-39877088" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876273">parent</a><span>|</span><a href="#39877190">next</a><span>|</span><label class="collapse" for="c-39877088">[-]</label><label class="expand" for="c-39877088">[9 more]</label></div><br/><div class="children"><div class="content">&gt; ...while I agree, for many C++ and Rust coders statements like this are pure heresy ;)<p>It&#x27;s a matter of definitions. For many people, &quot;garbage collection&quot; refers only to tracing GC, and reference counting is a separate category. In my experience, that&#x27;s the common usage; insisting that &quot;reference counting is formally (in some paper from the last century) also defined as a form of GC&quot; will not magically change the opinions &quot;many C++ and Rust coders&quot; have about tracing GC. In fact, I&#x27;d say that insisting on this nomenclature point only weakens the whole argument; tracing GC should stand on its own merits, and not on depend on some nomenclature equivalence to be accepted (if quibbling about nomenclature is your strongest argument, your arguments are weak).</div><br/><div id="39877383" class="c"><input type="checkbox" id="c-39877383" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877088">parent</a><span>|</span><a href="#39877190">next</a><span>|</span><label class="collapse" for="c-39877383">[-]</label><label class="expand" for="c-39877383">[8 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no need to &quot;change opinions&quot;. People who work on GCs know that reference counting and tracing are the two general GC strategies. The only people who don&#x27;t think of refcounting as a GC are people who simply aren&#x27;t familiar with GCs and how they work. If they also think refcounting has lower latencies (let alone higher throughput) than tracing, then they&#x27;re also just wrong. No one needs to &quot;insist&quot; on the GC nomenclature. You&#x27;re either familiar with it or you&#x27;re not (and since most people are not, they commonly make mistakes on the subject). Also, given that tracing GCs are used by ~90% the market, they hardly require justification anymore; they&#x27;ve won by a large margin over the application space (which constitutes most of software). However, it&#x27;s nice to occasionally educate those unfamiliar with the subject on GC algorithms and nomenclature.</div><br/><div id="39878259" class="c"><input type="checkbox" id="c-39878259" checked=""/><div class="controls bullet"><span class="by">dasyatidprime</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877383">parent</a><span>|</span><a href="#39877646">next</a><span>|</span><label class="collapse" for="c-39878259">[-]</label><label class="expand" for="c-39878259">[3 more]</label></div><br/><div class="children"><div class="content">I have to wonder whether some of this is semantic drift over time or context. My recollection since undergrad (a few decades ago) involves treating “garbage collection” as referring to tracing garbage collection, and “reference counting” as a separate mechanism. There <i>is</i> still a term for the category including both, only that term is not “garbage collection” but “automatic memory management”. But what I see nowadays is closer to what you describe.</div><br/><div id="39878291" class="c"><input type="checkbox" id="c-39878291" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878259">parent</a><span>|</span><a href="#39877646">next</a><span>|</span><label class="collapse" for="c-39878291">[-]</label><label class="expand" for="c-39878291">[2 more]</label></div><br/><div class="children"><div class="content">Automatic memory management is more general than that, it also includes stack allocation.</div><br/><div id="39878438" class="c"><input type="checkbox" id="c-39878438" checked=""/><div class="controls bullet"><span class="by">dasyatidprime</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878291">parent</a><span>|</span><a href="#39877646">next</a><span>|</span><label class="collapse" for="c-39878438">[-]</label><label class="expand" for="c-39878438">[1 more]</label></div><br/><div class="children"><div class="content">I agree; I meant “including” in the non-restrictive sense, not “including only”. Stack allocation is a special case where the lifetimes are arranged in a convenient way—see also escape analysis in languages where stack allocation isn&#x27;t explicitly supported at the language level but can be added by the compiler.</div><br/></div></div></div></div></div></div><div id="39877646" class="c"><input type="checkbox" id="c-39877646" checked=""/><div class="controls bullet"><span class="by">ngrilly</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877383">parent</a><span>|</span><a href="#39878259">prev</a><span>|</span><a href="#39877190">next</a><span>|</span><label class="collapse" for="c-39877646">[-]</label><label class="expand" for="c-39877646">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Also, given that tracing GCs are used by ~90% the market, they hardly require justification anymore; they&#x27;ve won by a large margin over the application space (which constitutes most of software).<p>Tracing GCs have clearly proven themselves and are everywhere (JVM, CLR, Go, Dart, OCaml, etc.) but we can&#x27;t ignore that the Apple ecosystem (Swift) is using ARC. That&#x27;s a significant share of the &quot;market&quot;. Python and Ruby also use reference counting, but I don&#x27;t think anyone is considering them state-of-the-art GC.</div><br/><div id="39877672" class="c"><input type="checkbox" id="c-39877672" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877646">parent</a><span>|</span><a href="#39877742">next</a><span>|</span><label class="collapse" for="c-39877672">[-]</label><label class="expand" for="c-39877672">[1 more]</label></div><br/><div class="children"><div class="content">Except that obligate ARC ala Swift has even lower throughput than obligate tracing GC.  It&#x27;s the worst possible choice unless you <i>really</i> care about low-latency and deterministic freeing of resources (and even then, using RAII for common tree-like allocation patterns like Rust does will perform better).</div><br/></div></div><div id="39877742" class="c"><input type="checkbox" id="c-39877742" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877646">parent</a><span>|</span><a href="#39877672">prev</a><span>|</span><a href="#39877190">next</a><span>|</span><label class="collapse" for="c-39877742">[-]</label><label class="expand" for="c-39877742">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right, I should have said &quot;languages where GC is the primary means of managing heap memory are used by 90% of the market&quot; rather than focused on a specific algorithm.</div><br/><div id="39877792" class="c"><input type="checkbox" id="c-39877792" checked=""/><div class="controls bullet"><span class="by">ngrilly</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877742">parent</a><span>|</span><a href="#39877190">next</a><span>|</span><label class="collapse" for="c-39877792">[-]</label><label class="expand" for="c-39877792">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is quite fascinating how GC replaced manual memory management in most apps over the last 20~30 years.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39877190" class="c"><input type="checkbox" id="c-39877190" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876273">parent</a><span>|</span><a href="#39877088">prev</a><span>|</span><a href="#39876460">next</a><span>|</span><label class="collapse" for="c-39877190">[-]</label><label class="expand" for="c-39877190">[1 more]</label></div><br/><div class="children"><div class="content">From TFA:<p>&gt; Tools to automate the “actually freeing the memory” part, like lifetimes in Rust and RAII in C++, don’t solve these problems. They absolutely aid correctness, something else you should care deeply about, but they do nothing to simplify all this machinery.</div><br/></div></div><div id="39876460" class="c"><input type="checkbox" id="c-39876460" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876273">parent</a><span>|</span><a href="#39877190">prev</a><span>|</span><a href="#39876243">next</a><span>|</span><label class="collapse" for="c-39876460">[-]</label><label class="expand" for="c-39876460">[1 more]</label></div><br/><div class="children"><div class="content">They should read some CS literature, the kind that is used to write the compilers they rely on.  :)</div><br/></div></div></div></div></div></div></div></div><div id="39876549" class="c"><input type="checkbox" id="c-39876549" checked=""/><div class="controls bullet"><span class="by">mdavidn</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876151">parent</a><span>|</span><a href="#39876198">prev</a><span>|</span><a href="#39876987">next</a><span>|</span><label class="collapse" for="c-39876549">[-]</label><label class="expand" for="c-39876549">[1 more]</label></div><br/><div class="children"><div class="content">Rust is more similar to C++, in that the compiler inserts calls to free as variables exit scope. Runtime reference counting is limited to those objects wrapped with Rc or Arc.<p>I agree with pron’s larger point. GC is fine for most applications. It’s just factually inaccurate to compare Rust’s memory management with languages like Python and PHP.</div><br/></div></div></div></div><div id="39876987" class="c"><input type="checkbox" id="c-39876987" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876125">parent</a><span>|</span><a href="#39876151">prev</a><span>|</span><a href="#39876638">next</a><span>|</span><label class="collapse" for="c-39876987">[-]</label><label class="expand" for="c-39876987">[1 more]</label></div><br/><div class="children"><div class="content">the CPU usage of manual memory is also pretty high. it&#x27;s just more evenly distributed throughout the program making it harder to observe.</div><br/></div></div></div></div><div id="39876638" class="c"><input type="checkbox" id="c-39876638" checked=""/><div class="controls bullet"><span class="by">hyperpape</span><span>|</span><a href="#39875707">parent</a><span>|</span><a href="#39876125">prev</a><span>|</span><a href="#39875823">next</a><span>|</span><label class="collapse" for="c-39876638">[-]</label><label class="expand" for="c-39876638">[2 more]</label></div><br/><div class="children"><div class="content">Where are the measurements comparing throughput of tracing GCs and manual memory management? I&#x27;m aware of how incredibly hard this area is to measure, but it&#x27;s a shame that the state of mainstream discussion is &quot;most people just assume GC implies slow, but then again a handful of people say it&#x27;s not.&quot;</div><br/><div id="39876807" class="c"><input type="checkbox" id="c-39876807" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876638">parent</a><span>|</span><a href="#39875823">next</a><span>|</span><label class="collapse" for="c-39876807">[-]</label><label class="expand" for="c-39876807">[1 more]</label></div><br/><div class="children"><div class="content">Given that the no-GC-by-default market is ~10% of the global software market [1] with no signs of shift in either direction over the past couple of decades, which sounds about right to me (considering the percentage of programs that need to run in memory-constrained environment or must have precise control over memory), it seems that the number of those who may benefit significantly from a different choice is small and so it doesn&#x27;t look like anyone wants or needs to be convinced of anything. &quot;GC languages&quot; already command ~90% of the market and have little to gain from such a small market of potential converts, and the others aren&#x27;t trying or succeeding in increasing their market share, so who cares given the small stakes?<p>[1]: <a href="https:&#x2F;&#x2F;www.devjobsscanner.com&#x2F;blog&#x2F;top-8-most-demanded-programming-languages&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.devjobsscanner.com&#x2F;blog&#x2F;top-8-most-demanded-prog...</a></div><br/></div></div></div></div><div id="39875823" class="c"><input type="checkbox" id="c-39875823" checked=""/><div class="controls bullet"><span class="by">znpy</span><span>|</span><a href="#39875707">parent</a><span>|</span><a href="#39876638">prev</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39875823">[-]</label><label class="expand" for="c-39875823">[18 more]</label></div><br/><div class="children"><div class="content">&gt; (OpenJDK&#x27;s ZGC has typical pause times measured in double&#x2F;triple-digit microseconds, and the worst case rarely exceeds 1ms for a reasonable allocation rate -- the pauses are in the same ballpark as OS-induced ones)<p>We&#x27;ve been benchmarking ZGC and Shenandoah at work, and the p100 pause time is usually below 500us (micro-seconds). ZGC seems to be performing a bit better, as it seems to be performing less pauses than Shenandoah (hence doing more work&#x2F;pause).<p>We still have to run tests-in-production, but so far it seems that GC pauses are largely a solved issue when using ZGC (and Generational ZGC since Java21).</div><br/><div id="39876173" class="c"><input type="checkbox" id="c-39876173" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39875823">parent</a><span>|</span><a href="#39875917">next</a><span>|</span><label class="collapse" for="c-39876173">[-]</label><label class="expand" for="c-39876173">[6 more]</label></div><br/><div class="children"><div class="content">FYI, ZGC doesn&#x27;t perform <i>any</i> collection work in the the stop-the-world pauses. They are only required to get all mutator threads to atomically observe the increment of the &quot;GC epoch&quot; for all threads. All actual work, both marking and compaction, is done by GC threads running concurrently with the mutator threads or by the mutator threads themselves as they run. It is only when allocation rate is very, very high that an allocating mutator thread will be paused (&quot;throttled&quot;) for a significant amount of time to allow the GC to catch up by freeing up memory (and if you hit these cases, then you might be better off using a throughput-oriented collector).</div><br/><div id="39877434" class="c"><input type="checkbox" id="c-39877434" checked=""/><div class="controls bullet"><span class="by">hawk_</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876173">parent</a><span>|</span><a href="#39877602">next</a><span>|</span><label class="collapse" for="c-39877434">[-]</label><label class="expand" for="c-39877434">[4 more]</label></div><br/><div class="children"><div class="content">Strangely in our workloads we have noticed generational ZGC latencies are better than G1 at ~99th-99.9th percentile or below but worse at percentiles above that. The allocation rate is moderate.</div><br/><div id="39881273" class="c"><input type="checkbox" id="c-39881273" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877434">parent</a><span>|</span><a href="#39877688">next</a><span>|</span><label class="collapse" for="c-39881273">[-]</label><label class="expand" for="c-39881273">[1 more]</label></div><br/><div class="children"><div class="content">It can be easy to game metrics like this -- trading off p100 for p99.9 or p99. E.g., defer all the expensive work to 1 in every 10,000 operations.</div><br/></div></div><div id="39877688" class="c"><input type="checkbox" id="c-39877688" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877434">parent</a><span>|</span><a href="#39881273">prev</a><span>|</span><a href="#39877602">next</a><span>|</span><label class="collapse" for="c-39877688">[-]</label><label class="expand" for="c-39877688">[2 more]</label></div><br/><div class="children"><div class="content">Above that you might easily get  measuring artifacts, like the OS swapping out your process once, or so.</div><br/><div id="39877970" class="c"><input type="checkbox" id="c-39877970" checked=""/><div class="controls bullet"><span class="by">hawk_</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39877688">parent</a><span>|</span><a href="#39877602">next</a><span>|</span><label class="collapse" for="c-39877970">[-]</label><label class="expand" for="c-39877970">[1 more]</label></div><br/><div class="children"><div class="content">Yes - but it&#x27;s quite consistent. If it was &#x27;noise&#x27; it wouldn&#x27;t be.</div><br/></div></div></div></div></div></div><div id="39877602" class="c"><input type="checkbox" id="c-39877602" checked=""/><div class="controls bullet"><span class="by">znpy</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876173">parent</a><span>|</span><a href="#39877434">prev</a><span>|</span><a href="#39875917">next</a><span>|</span><label class="collapse" for="c-39877602">[-]</label><label class="expand" for="c-39877602">[1 more]</label></div><br/><div class="children"><div class="content">&gt; FYI, ZGC doesn&#x27;t perform any collection work in the the stop-the-world pauses.<p>Yeah i know, but on a certain level I don’t care what it does or does not do.<p>I care about my application not having latency spikes due to stop the world pauses :)</div><br/></div></div></div></div><div id="39876157" class="c"><input type="checkbox" id="c-39876157" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39875823">parent</a><span>|</span><a href="#39875917">prev</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39876157">[-]</label><label class="expand" for="c-39876157">[10 more]</label></div><br/><div class="children"><div class="content">&gt; We&#x27;ve been benchmarking ZGC and Shenandoah at work, and the p100 pause time is usually below 500us<p>&gt; so far it seems that GC pauses are largely a solved issue when using ZGC<p>What? 500us is abysmally slow.<p>Most projects I work on have a latency budget of less than 10us, the average being 2us. That is the budget for the whole wire in&#x2F;wire out for a packet. Even for less latency sensitive workloads, 500us is a no go for most networking application.</div><br/><div id="39876196" class="c"><input type="checkbox" id="c-39876196" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876157">parent</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39876196">[-]</label><label class="expand" for="c-39876196">[9 more]</label></div><br/><div class="children"><div class="content">We&#x27;re talking about occasional hiccups, not an average-case response-latency overhead. You can&#x27;t get <i>worst-case</i> latency of 2-10us with a non-realtime kernel. Even a page fault could take longer than that.</div><br/><div id="39876478" class="c"><input type="checkbox" id="c-39876478" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876196">parent</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39876478">[-]</label><label class="expand" for="c-39876478">[8 more]</label></div><br/><div class="children"><div class="content">&gt; You can&#x27;t get worst-case latency of 2-10us with a non-realtime kernel. Even a page fault could take longer than that.<p>You obviously can, and this has nothing to do with the kernel being real-time or not.<p>There is no situation I can think of where a page fault should occur on a properly setup system running a production networking software, meaning no swap, huge TLB, and proper memory management.</div><br/><div id="39876858" class="c"><input type="checkbox" id="c-39876858" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876478">parent</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39876858">[-]</label><label class="expand" for="c-39876858">[7 more]</label></div><br/><div class="children"><div class="content">If you can think of &quot;no situation&quot; where a server may incur a page fault, forced preemption, or need to perform any I&#x2F;O to a service&#x2F;database, then I hope you at least recognise that your world in no way represents the state of server software at large because <i>none</i> of these things is true for the vast majority of server software.<p>In a former life I worked on some safety-critical onboard  avionics software for an ultrasonic platform, and 2us was around the upper-limit worst-case latency (i.e. you&#x27;ll kill someone if you miss that deadline); still, it&#x27;s not the kind of requirements the vast majority of software finds itself under.<p>When working over the internet, some of the very best services are at &gt;10ms <i>ping</i> latency anyway, where a 500us hiccup is imperceptible.</div><br/><div id="39878210" class="c"><input type="checkbox" id="c-39878210" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39876858">parent</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39878210">[-]</label><label class="expand" for="c-39878210">[6 more]</label></div><br/><div class="children"><div class="content">&gt; If you can think of &quot;no situation&quot; where a server may incur a page fault, forced preemption, or need to perform any I&#x2F;O to a service&#x2F;database, then I hope you at least recognise that your world in no way represents the state of server software at large<p>I won&#x27;t deny that the majority of software out there is not latency sensitive, but the context of this article is specifically targeting those softwares that are _not_ using garbage collection, arguing that it is undeservedly overlooked. OP even adds that GC is a &quot;solved problem&quot; because some GC implementation is 500us worst case latency.<p>My point is that the article author, and OP, are mistaken. Because if you are in the category of &quot;I write server side software without GC&quot; (e. g. C&#x2F;C++), then 500us is horribly wrong.<p>Your point being that 500us is fine for most software out there is surely true, but not relevant, because if that is the case, you&#x27;re probably not using C&#x2F;C++, thus this article is not targeting you.<p>In _my world_ as you phrase it, traffic is unshaped. You need to be able to support line rate, otherwise packets are dropped, and hell breaks loose.</div><br/><div id="39881607" class="c"><input type="checkbox" id="c-39881607" checked=""/><div class="controls bullet"><span class="by">rossjudson</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878210">parent</a><span>|</span><a href="#39881609">next</a><span>|</span><label class="collapse" for="c-39881607">[-]</label><label class="expand" for="c-39881607">[3 more]</label></div><br/><div class="children"><div class="content">Your &quot;properly set up system&quot; is apparently doing nothing other than running your single job. The vast majority of real-world systems have to deal with antagonists.<p>All of the characteristics you mention are true on production systems used in large scale fleets...and yet &quot;bumps&quot; happen...because there&#x27;s never <i>one</i> thing happening. It&#x27;s all the things, and it&#x27;s always changing.<p>I&#x27;m gonna guess you do finance. A six microsecond fiber oneway is a thing of beauty. There are certain technical luxuries associated with that domain, and rarely any requirement to exhibit high utilization rates...or deal with antagonists running on the same hardware.</div><br/><div id="39882392" class="c"><input type="checkbox" id="c-39882392" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39881607">parent</a><span>|</span><a href="#39881609">next</a><span>|</span><label class="collapse" for="c-39882392">[-]</label><label class="expand" for="c-39882392">[2 more]</label></div><br/><div class="children"><div class="content">Finance is one of such use cases, but there&#x27;s a lot more, and that&#x27;s the use case for people not using GC, thus why I find this article (and the comment saying 500us is a solved problem) pedantic.<p>I wrote code profilers for instance, which also need perfectly predictable latency. I worked on L2 and L3 networking applications (bridging, routing, forwarding) that need line rate support. People working on audio sampling, or codecs have the same constraints, etc.<p>There&#x27;s a whole world of applications where 500us is ridiculously slow. The article takes the OS as example, but if my OS has 500us random latency spikes, I would be horrified.</div><br/><div id="39882558" class="c"><input type="checkbox" id="c-39882558" checked=""/><div class="controls bullet"><span class="by">pebal</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39882392">parent</a><span>|</span><a href="#39881609">next</a><span>|</span><label class="collapse" for="c-39882558">[-]</label><label class="expand" for="c-39882558">[1 more]</label></div><br/><div class="children"><div class="content">The article doesn&#x27;t say anything about acceptable pause times. GC can be completely pause-free.</div><br/></div></div></div></div></div></div><div id="39881609" class="c"><input type="checkbox" id="c-39881609" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39878210">parent</a><span>|</span><a href="#39881607">prev</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39881609">[-]</label><label class="expand" for="c-39881609">[2 more]</label></div><br/><div class="children"><div class="content">&gt; because if that is the case, you&#x27;re probably not using C&#x2F;C++<p>The point is that this claim is more wrong than it should be, eg. that C&#x2F;C++ is still used more than it should be partly because these GC myths persist, hence the article.</div><br/><div id="39882171" class="c"><input type="checkbox" id="c-39882171" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#39875707">root</a><span>|</span><a href="#39881609">parent</a><span>|</span><a href="#39875637">next</a><span>|</span><label class="collapse" for="c-39882171">[-]</label><label class="expand" for="c-39882171">[1 more]</label></div><br/><div class="children"><div class="content">I think at the end we&#x27;re debating if the glass is half full or half empty.<p>I claim that people are not ignorant and if they use C&#x2F;C++, they are aware of what a GC implies, and cannot afford it.<p>The article claims that people are somehow wrongly mislead to think they _need_ C&#x2F;C++ while a GC&#x27;ed language would be alright.<p>I don&#x27;t think people are dumb. I think given the choice, any sane person would pick Python or similar to write an application, and that thinking they don&#x27;t because they don&#x27;t know more is pedantic.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39875637" class="c"><input type="checkbox" id="c-39875637" checked=""/><div class="controls bullet"><span class="by">keybored</span><span>|</span><a href="#39875707">prev</a><span>|</span><a href="#39876838">next</a><span>|</span><label class="collapse" for="c-39875637">[-]</label><label class="expand" for="c-39875637">[4 more]</label></div><br/><div class="children"><div class="content">The article motivates RCU and then does a u-turn and starts making a general argument for general-purpose GC. Not quite a trojan horse but a bit whiplash provoking.</div><br/><div id="39876321" class="c"><input type="checkbox" id="c-39876321" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#39875637">parent</a><span>|</span><a href="#39876838">next</a><span>|</span><label class="collapse" for="c-39876321">[-]</label><label class="expand" for="c-39876321">[3 more]</label></div><br/><div class="children"><div class="content">I definitely wouldn&#x27;t call the RCU thing a GC, since at no point is the object garbage. It is in one of 3 states, and changes between them as quickly as possible:<p>* active<p>* obsolete but alive for old readers<p>* deallocated<p>Note that depending on how you write your code, it may be possible to <i>reuse</i> an &quot;obsolete-but-alive&quot; object for a &quot;new&quot; allocation safely, though I haven&#x27;t analyzed performance for this in full.<p>As usual for GC discussions, it is <i>very</i> handwavy about when you have to &quot;fall back to `shared\_ptr&#x2F;Arc`&quot;, when in fact avoiding refcounts (either because you can prove you already have ownership (which does have implications for tail calls, but you shouldn&#x27;t use those anyway), or by avoiding indirection entirely) is the whole point of serious refcount-based systems. Doing nothing at all is obviously better than GC&#x27;s &quot;do something, sometime&quot;.</div><br/><div id="39881692" class="c"><input type="checkbox" id="c-39881692" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#39875637">root</a><span>|</span><a href="#39876321">parent</a><span>|</span><a href="#39880647">next</a><span>|</span><label class="collapse" for="c-39881692">[-]</label><label class="expand" for="c-39881692">[1 more]</label></div><br/><div class="children"><div class="content">RCU objects are garbage when they&#x27;re held by old readers thay will no longer utilize them in the remaining code path before they exit. This code path is virtually always of non-zero length, because ensuring they are deallocated in the absolute shortest path is an NP-class problem for sure. I don&#x27;t see why the fact that this code path might sometimes be longer in GC would preclude RCU from being GC.</div><br/></div></div><div id="39880647" class="c"><input type="checkbox" id="c-39880647" checked=""/><div class="controls bullet"><span class="by">nemetroid</span><span>|</span><a href="#39875637">root</a><span>|</span><a href="#39876321">parent</a><span>|</span><a href="#39881692">prev</a><span>|</span><a href="#39876838">next</a><span>|</span><label class="collapse" for="c-39880647">[-]</label><label class="expand" for="c-39880647">[1 more]</label></div><br/><div class="children"><div class="content">It’s not entirely clear from the article, but the part about rcu_defer() is not just a ”what if?” segue into GC, it’s how RCU is typically used.</div><br/></div></div></div></div></div></div><div id="39876838" class="c"><input type="checkbox" id="c-39876838" checked=""/><div class="controls bullet"><span class="by">mwkaufma</span><span>|</span><a href="#39875637">prev</a><span>|</span><a href="#39877880">next</a><span>|</span><label class="collapse" for="c-39876838">[-]</label><label class="expand" for="c-39876838">[7 more]</label></div><br/><div class="children"><div class="content">(1) the pivot from rcu to general purpose tracing gcs is bait-and-switch.<p>(2) Manual memory management is more than just malloc&#x2F;free calls -- it&#x27;s about layout (e.g. struct-of-arrays, inlining, implicit offsets, packing, etc)</div><br/><div id="39879507" class="c"><input type="checkbox" id="c-39879507" checked=""/><div class="controls bullet"><span class="by">titzer</span><span>|</span><a href="#39876838">parent</a><span>|</span><a href="#39877771">next</a><span>|</span><label class="collapse" for="c-39879507">[-]</label><label class="expand" for="c-39879507">[4 more]</label></div><br/><div class="children"><div class="content">For (2) Virgil has several features that allow you to layout memory with various levels of control. I assume you meaning &quot;array of structs&quot;, and you can do that with arrays of tuples, which will naturally be flattened and normalized based on the target (i.e. will be array-of-structs on native targets). You can define byte-exact layouts[1] (mostly for interfacing with other software and parsing binary formats), unbox ADTs, and soon you can even control the exact encoding of ADTs.<p>Virgil is GC&#x27;d.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;titzer&#x2F;virgil&#x2F;blob&#x2F;master&#x2F;doc&#x2F;tutorial&#x2F;Layouts.md">https:&#x2F;&#x2F;github.com&#x2F;titzer&#x2F;virgil&#x2F;blob&#x2F;master&#x2F;doc&#x2F;tutorial&#x2F;La...</a></div><br/><div id="39879797" class="c"><input type="checkbox" id="c-39879797" checked=""/><div class="controls bullet"><span class="by">mwkaufma</span><span>|</span><a href="#39876838">root</a><span>|</span><a href="#39879507">parent</a><span>|</span><a href="#39882109">next</a><span>|</span><label class="collapse" for="c-39879797">[-]</label><label class="expand" for="c-39879797">[2 more]</label></div><br/><div class="children"><div class="content">Skimming [1], Virgil Layouts resemble ArrayBuffers in JavaScript -- a boxed view of some native span of memory. If I&#x27;m reading that right, it&#x27;s basically an escape-hatch from the GC for &quot;mixed&quot; environments -- the buffer itself is owned by a GC&#x27;d proxy, but it doesn&#x27;t doesn&#x27;t e.g. contain GC references internally.<p>That&#x27;s useful for lots of low-level interfaceing (e.g. communicating with serial interfaces or device drivers), but one couldn&#x27;t, however, build an &quot;allocator&quot; in a Layout for GC&#x27;d objects the way, e.g., in native code you can make a &quot;bump allocator&quot; for arbitrary structs which are &quot;free&quot;ed with just a pointer-reset (pretty important, e.g., in game engines, which is my field).</div><br/><div id="39879858" class="c"><input type="checkbox" id="c-39879858" checked=""/><div class="controls bullet"><span class="by">titzer</span><span>|</span><a href="#39876838">root</a><span>|</span><a href="#39879797">parent</a><span>|</span><a href="#39882109">next</a><span>|</span><label class="collapse" for="c-39879858">[-]</label><label class="expand" for="c-39879858">[1 more]</label></div><br/><div class="children"><div class="content">The last part is correct; layouts are not GC&#x27;d objects. They are views over byte arrays (or mmap&#x27;d memory, or unsafe regions like the execution stack). The first part is partially incorrect; layouts are not &quot;boxed&quot;--they are represented underneath as a pair of a (potentially null) GC object and a pointer-sized offset into that object. So with that representation you can have a reference to an off-heap layout as well.<p>Layouts are a little underpowered right now, owing mostly to the conservatism in that they could always be aliased by a byte array or any other alias, thus their bytes are chaos-bits that cannot be trusted. Adding the ability to have pointers between layouts is another level; for that, I am envisioning reads of pointers requiring a second capability which is the expected region into which the pointers lie.<p>But all of the layout stuff is fundamentally not about performance, it&#x27;s about interfacing with external software and hardware. In Virgil the expectation that you should use the good, type- and memory-safe constructs like classes, arrays, tuples, ADTs, etc. These are plenty efficient and getting new annotations to control their representation in a more fine-grained way.</div><br/></div></div></div></div><div id="39882109" class="c"><input type="checkbox" id="c-39882109" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#39876838">root</a><span>|</span><a href="#39879507">parent</a><span>|</span><a href="#39879797">prev</a><span>|</span><a href="#39877771">next</a><span>|</span><label class="collapse" for="c-39882109">[-]</label><label class="expand" for="c-39882109">[1 more]</label></div><br/><div class="children"><div class="content">I think struct-of-arrays was a quite delibarate wording. It stands out as a strategy that is at odds with object orientation and is sometimes more efficient.</div><br/></div></div></div></div><div id="39877771" class="c"><input type="checkbox" id="c-39877771" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39876838">parent</a><span>|</span><a href="#39879507">prev</a><span>|</span><a href="#39877880">next</a><span>|</span><label class="collapse" for="c-39877771">[-]</label><label class="expand" for="c-39877771">[2 more]</label></div><br/><div class="children"><div class="content">I disagree with 2 being manual memory management. There is definitely a lack of control in contemporary managed languages (though it’s also far from perfect in low-level languages) for memory layout, but there are definitely ways to affect it.</div><br/><div id="39878531" class="c"><input type="checkbox" id="c-39878531" checked=""/><div class="controls bullet"><span class="by">cb321</span><span>|</span><a href="#39876838">root</a><span>|</span><a href="#39877771">parent</a><span>|</span><a href="#39877880">next</a><span>|</span><label class="collapse" for="c-39878531">[-]</label><label class="expand" for="c-39878531">[1 more]</label></div><br/><div class="children"><div class="content">I agree with your disagreement.  As a case in point, Nim has packed bitfields but various choices in automatic memory management.  As a concrete example, a spell-check custom-data store uses them here: <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;suggest&#x2F;blob&#x2F;04e313f8f8d3adf4cb55a8ae0973f815f2b506c6&#x2F;suggest.nim#L102">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;suggest&#x2F;blob&#x2F;04e313f8f8d3adf4cb55...</a> (there the memory is in a memory mapped file and so that code has to manage the space itself.. so, maybe not the perfect example).<p>But I also agree there tends to be a correlation in PLang design in avoiding both low-level memory layout and in manual memory management.  But it&#x27;s just a tendency, not fundamental.</div><br/></div></div></div></div></div></div><div id="39877880" class="c"><input type="checkbox" id="c-39877880" checked=""/><div class="controls bullet"><span class="by">HippoBaro</span><span>|</span><a href="#39876838">prev</a><span>|</span><a href="#39878417">next</a><span>|</span><label class="collapse" for="c-39877880">[-]</label><label class="expand" for="c-39877880">[4 more]</label></div><br/><div class="children"><div class="content">For the kind of software I write there are two cases: (1) the hot path for which I will always have custom allocators and avoid allocations and (2) everything else.<p>For (1) GC or not it doesn’t make a difference, I’ll opt-out. For (2) GC is really convenient and correct.</div><br/><div id="39878864" class="c"><input type="checkbox" id="c-39878864" checked=""/><div class="controls bullet"><span class="by">leapis</span><span>|</span><a href="#39877880">parent</a><span>|</span><a href="#39879105">prev</a><span>|</span><a href="#39878417">next</a><span>|</span><label class="collapse" for="c-39878864">[-]</label><label class="expand" for="c-39878864">[2 more]</label></div><br/><div class="children"><div class="content">Agreed- I come from a Java&#x2F;C++ shop where we tried to tackle this dichotomy with interop but it ended up causing more problems than it solved. A lot of the work that Java has done with modern garbage collectors is impressive, but even they admit (indirectly, via Valhalla) that no&#x2F;low-alloc code has it&#x27;s place.</div><br/><div id="39882389" class="c"><input type="checkbox" id="c-39882389" checked=""/><div class="controls bullet"><span class="by">astrobe_</span><span>|</span><a href="#39877880">root</a><span>|</span><a href="#39878864">parent</a><span>|</span><a href="#39878417">next</a><span>|</span><label class="collapse" for="c-39882389">[-]</label><label class="expand" for="c-39882389">[1 more]</label></div><br/><div class="children"><div class="content">&gt; no&#x2F;low-alloc code has it&#x27;s place<p>... Which is pretty large in the embedded firwmare field. However that&#x27;s not systems programming but system (singular) programming.</div><br/></div></div></div></div></div></div><div id="39878417" class="c"><input type="checkbox" id="c-39878417" checked=""/><div class="controls bullet"><span class="by">musicale</span><span>|</span><a href="#39877880">prev</a><span>|</span><a href="#39879846">next</a><span>|</span><label class="collapse" for="c-39878417">[-]</label><label class="expand" for="c-39878417">[2 more]</label></div><br/><div class="children"><div class="content">The tricky part is identifying which systems programmers can be garbage collected and when.</div><br/><div id="39878455" class="c"><input type="checkbox" id="c-39878455" checked=""/><div class="controls bullet"><span class="by">GeorgeTirebiter</span><span>|</span><a href="#39878417">parent</a><span>|</span><a href="#39879846">next</a><span>|</span><label class="collapse" for="c-39878455">[-]</label><label class="expand" for="c-39878455">[1 more]</label></div><br/><div class="children"><div class="content">Soylent Green was set in 2022&#x2F;2023  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Soylent_Green?useskin=vector" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Soylent_Green?useskin=vector</a></div><br/></div></div></div></div><div id="39879846" class="c"><input type="checkbox" id="c-39879846" checked=""/><div class="controls bullet"><span class="by">SmartHypercube</span><span>|</span><a href="#39878417">prev</a><span>|</span><a href="#39879495">next</a><span>|</span><label class="collapse" for="c-39879846">[-]</label><label class="expand" for="c-39879846">[3 more]</label></div><br/><div class="children"><div class="content">Using RCU as the example to motivate GC is interesting. It is essentially transferring the responsibility of freeing from the writer to the last reader, who cannot be determined when compiling. It makes a lot of sense.<p>But this makes me thinking that, if I want more performance, should I further transfer the freeing from the reader to a dedicated batch process? The readers only update a mark &#x2F; write into a queue or something. Every once in a while, a batch process collects all garbages and compacts. This way the readers don&#x27;t have random additional overheads.<p>&gt; Lies people believe about memory management<p>&gt; The programmer knows the best times to pause for memory management.<p>In my experience, there are many programs in which the programmer does know the best times to pause for memory management. For example, in games and crypto trading programs, I want to classify all computations into two priorities. I need to do an update &#x2F; render a frame &#x2F; compute a trading action in every time period. If it finishes before the deadline, I have nothing to do now and would like to collect some garbages. If the high-priority thing is using all the available time, for example, when the market is very active, I don&#x27;t care too much about collecting garbages and would like to defer everything that is not strictly necessary to as late as possible.</div><br/><div id="39879978" class="c"><input type="checkbox" id="c-39879978" checked=""/><div class="controls bullet"><span class="by">filleduchaos</span><span>|</span><a href="#39879846">parent</a><span>|</span><a href="#39879495">next</a><span>|</span><label class="collapse" for="c-39879978">[-]</label><label class="expand" for="c-39879978">[2 more]</label></div><br/><div class="children"><div class="content">The very next line after the portion of the article you clipped is &quot;Sometimes there are obvious answers—like on the loading screen of a video game.&quot;</div><br/><div id="39880338" class="c"><input type="checkbox" id="c-39880338" checked=""/><div class="controls bullet"><span class="by">SmartHypercube</span><span>|</span><a href="#39879846">root</a><span>|</span><a href="#39879978">parent</a><span>|</span><a href="#39879495">next</a><span>|</span><label class="collapse" for="c-39880338">[-]</label><label class="expand" for="c-39880338">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not talking about the <i>loading screen</i> of a video game.</div><br/></div></div></div></div></div></div><div id="39879495" class="c"><input type="checkbox" id="c-39879495" checked=""/><div class="controls bullet"><span class="by">worik</span><span>|</span><a href="#39879846">prev</a><span>|</span><a href="#39875604">next</a><span>|</span><label class="collapse" for="c-39879495">[-]</label><label class="expand" for="c-39879495">[1 more]</label></div><br/><div class="children"><div class="content">Not mentioned in this article is one thing that goes very well with GC is async&#x2F;await<p>I am a async&#x2F;await hater for personal Idiosyncratic style reasons that I will not bore you with<p>I use it a lot in Type&#x2F;Java script. Have done so in Dart. Works as it should<p>I have used it in Rust. IMO it is a disaster there. Shoehorning the sort of memory management required to use asyc&#x2F;await with a multi threaded runtime is a hellscape<p><a href="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;pin&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;pin&#x2F;index.html</a></div><br/></div></div><div id="39875604" class="c"><input type="checkbox" id="c-39875604" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#39879495">prev</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39875604">[-]</label><label class="expand" for="c-39875604">[28 more]</label></div><br/><div class="children"><div class="content">A point that seems to get lost in many of the pro-GC articles, this one included from what I can see, is that memory is just one kind of resource.<p>Correct code, especially in systems programming, will need to manage external resources as well, be it file handles, sockets or whatnot. GC only solves the application memory part, thus doesn&#x27;t help at all for handling those external resources. In fact it can make it much more complicated, just look at what it takes to correctly implement a non-trivial IDispose in .Net.<p>Other approaches like RAII or reference counting makes it much easier in my experience to handle both memory and external resources in a unified way, thus making it easier to write correct code and reason about it.<p>That said, I&#x27;m not blatantly against GC&#x27;s. It&#x27;s a tool and it has some pros and cons, like everything else. The &quot;manual GC&quot; RCU approach mentioned in the article is interesting for certain tasks.</div><br/><div id="39881349" class="c"><input type="checkbox" id="c-39881349" checked=""/><div class="controls bullet"><span class="by">yawaramin</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39876177">next</a><span>|</span><label class="collapse" for="c-39881349">[-]</label><label class="expand" for="c-39881349">[1 more]</label></div><br/><div class="children"><div class="content">RAII is of course great but any language with a GC and proper exception handling can handle resources safely. Eg look at Java&#x27;s try-with-resources statement which guarantees that the resource will be disposed safely if an exception is raised: <a href="https:&#x2F;&#x2F;docs.oracle.com&#x2F;javase&#x2F;tutorial&#x2F;essential&#x2F;exceptions&#x2F;tryResourceClose.html" rel="nofollow">https:&#x2F;&#x2F;docs.oracle.com&#x2F;javase&#x2F;tutorial&#x2F;essential&#x2F;exceptions...</a><p>You can build up quite resilient and resource-safe systems using these basic building blocks.</div><br/></div></div><div id="39876177" class="c"><input type="checkbox" id="c-39876177" checked=""/><div class="controls bullet"><span class="by">tialaramex</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39881349">prev</a><span>|</span><a href="#39875814">next</a><span>|</span><label class="collapse" for="c-39876177">[-]</label><label class="expand" for="c-39876177">[1 more]</label></div><br/><div class="children"><div class="content">Yes, and the &quot;Memory Safety&quot; arguments apply to the other resources too. For example Rust eventually grew I&#x2F;O safety, so your File Handles (in Unix, OwnedFd) or just straight up Handles (in Windows, OwnedHandle) are owned objects, not just integers like the number 4<p>At the surface this looks like it&#x27;s just about avoiding dumb mistakes like using arithmetic on handles or mistakenly using reserved values as sentinels -- but the ownership model also means anything tricky we&#x27;re doing with handles has explicit ownership, transparent to future maintainers.</div><br/></div></div><div id="39875814" class="c"><input type="checkbox" id="c-39875814" checked=""/><div class="controls bullet"><span class="by">pron</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39876177">prev</a><span>|</span><a href="#39875675">next</a><span>|</span><label class="collapse" for="c-39875814">[-]</label><label class="expand" for="c-39875814">[1 more]</label></div><br/><div class="children"><div class="content">There is a big difference between memory and other resources, and that is that memory -- like processing -- is fundamental for any computation; not for nothing do most theoretical models of computation assume unbounded memory. Very few languages require manual allocation of processing -- even though that is done in some software like OS kernels and hard realtime applications -- and for similar reasons automatic memory management is very useful for abstracting computation, i.e. not leaking their details of memory by a subroutine to its clients just as this is rarely done for CPU use.<p>So while every non-trivial computation involves some non-constant amount of processing and memory, I&#x2F;O is usually done at the edges of the system. Management of I&#x2F;O is very important, of course, but it&#x27;s not as central to the notion of computation (and therefore to abstracting computation) as processing and memory.</div><br/></div></div><div id="39875675" class="c"><input type="checkbox" id="c-39875675" checked=""/><div class="controls bullet"><span class="by">zwieback</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39875814">prev</a><span>|</span><a href="#39880087">next</a><span>|</span><label class="collapse" for="c-39875675">[-]</label><label class="expand" for="c-39875675">[5 more]</label></div><br/><div class="children"><div class="content">So true, moving from C++ to mostly C# I&#x27;m liking memory management by GC but hating tracking file handles, sockets, etc. RAII is something I really appreciated</div><br/><div id="39876578" class="c"><input type="checkbox" id="c-39876578" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39875675">parent</a><span>|</span><a href="#39876060">next</a><span>|</span><label class="collapse" for="c-39876578">[-]</label><label class="expand" for="c-39876578">[3 more]</label></div><br/><div class="children"><div class="content">Use Roslyn analysis that errors when using is forgotten in an IDisposable type, for example.<p>By the way, in modern .NET, using makes use of structural typing. Any class or struct, with a Dispose() method can be referred to, no need to implement the interface, and can also be retrofitted via extension methods.</div><br/><div id="39877625" class="c"><input type="checkbox" id="c-39877625" checked=""/><div class="controls bullet"><span class="by">osigurdson</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876578">parent</a><span>|</span><a href="#39876060">next</a><span>|</span><label class="collapse" for="c-39877625">[-]</label><label class="expand" for="c-39877625">[2 more]</label></div><br/><div class="children"><div class="content">This is strange advice. Why not just implement the IDisposable interface like normal C# code? Using extension methods for this is strange as well. Doing this even somewhat correctly would mean creating another class that implements IDisposable which can only work with public members of the original. In general best not to do weird stuff for no reason imo.</div><br/><div id="39882105" class="c"><input type="checkbox" id="c-39882105" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39877625">parent</a><span>|</span><a href="#39876060">next</a><span>|</span><label class="collapse" for="c-39882105">[-]</label><label class="expand" for="c-39882105">[1 more]</label></div><br/><div class="children"><div class="content">Because you don&#x27;t own the type?<p>Using another class, or struct adds up to memory usage, and turns out some C and C++ folks are itchy with such solutions, not to mention the added issue of passing wrapper classes&#x2F;structs around.</div><br/></div></div></div></div></div></div><div id="39876060" class="c"><input type="checkbox" id="c-39876060" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39875675">parent</a><span>|</span><a href="#39876578">prev</a><span>|</span><a href="#39880087">next</a><span>|</span><label class="collapse" for="c-39876060">[-]</label><label class="expand" for="c-39876060">[1 more]</label></div><br/><div class="children"><div class="content">(SafeFileHandle is internally reference counted, but yes, worst case when you forget to .Dispose it, it waits in the finalizer queue for the GC to trigger the finalizer thread to process the items in it)</div><br/></div></div></div></div><div id="39880087" class="c"><input type="checkbox" id="c-39880087" checked=""/><div class="controls bullet"><span class="by">pebal</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39875675">prev</a><span>|</span><a href="#39876569">next</a><span>|</span><label class="collapse" for="c-39880087">[-]</label><label class="expand" for="c-39880087">[1 more]</label></div><br/><div class="children"><div class="content">Having garbage collection (GC) in your toolkit doesn&#x27;t mean you&#x27;re limited to choosing between GC and deterministic destruction. You can integrate GC, stack allocation, and manual memory management within the same application. It&#x27;s possible to leverage GC in a manner similar to how `shared_ptr` is used, providing both automated cleanup and precise control over object lifetime. For a practical example, consider SGCL: <a href="https:&#x2F;&#x2F;github.com&#x2F;pebal&#x2F;sgcl">https:&#x2F;&#x2F;github.com&#x2F;pebal&#x2F;sgcl</a></div><br/></div></div><div id="39876569" class="c"><input type="checkbox" id="c-39876569" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39880087">prev</a><span>|</span><a href="#39879347">next</a><span>|</span><label class="collapse" for="c-39876569">[-]</label><label class="expand" for="c-39876569">[4 more]</label></div><br/><div class="children"><div class="content">Yet, a point that tends to get lost when criticising GC languages, is that most of them have features for deterministic resource management, that many keep failing to learn.<p>- Some do have RAII<p>- Some do offer keywords<p>- Some do arena like management,  lambdas with implicit management<p>- Some have a little help from the type system<p>- Some do a bit of everything listed above<p>Additionally, just like system developers have to rely on static analysers, the static analysers for those languages can also provide validation when something is forgotten, when the type system alone isn&#x27;t enough.</div><br/><div id="39879122" class="c"><input type="checkbox" id="c-39879122" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876569">parent</a><span>|</span><a href="#39879347">next</a><span>|</span><label class="collapse" for="c-39879122">[-]</label><label class="expand" for="c-39879122">[3 more]</label></div><br/><div class="children"><div class="content">My point though is that by moving memory management into &quot;don&#x27;t care&quot; territory while still, obviously, requiring explicit handling of other resources, it&#x27;s easier to forget or miss when you need to explicitly handle something.<p>When instantiating objects in C# say I need to check the documentation or the source code to see if it implements IDisposable to know if I need to handle it. Lets say that for a given class X in library Y, it does not. So I don&#x27;t worry, I just instantiate and don&#x27;t do anything about the cleanup because GC will handle it.<p>Later, the implementation of X changes and IDisposable is added to it. I now have to change my code, and not doing so could lead to serious production issues. Yet the compiler happily compiles my code without any warning.<p>Sure some static analyzers might catch it, but they&#x27;re not perfect, and you need to run them. A stock Visual Studio 2022 will not complain about the above scenario for example.<p>In my experience it&#x27;s much less error prone to unify memory and external resource management. If instead I had been using a different language which has a more uniform resource handling, the above change in class X would likely not have been a big deal.<p>Also, my code will already be written with resource handling in mind. It can be non-trivial having to change a hierarchy of classes just because a dependency deep down suddenly had IDisposable added to it.<p>I guess what I&#x27;m trying to say is that I think just focusing on memory management, that is to GC or not to GC, is having a myopic view things. I feel it&#x27;s like arguing what kind of pickle to have on your burger without considering the other ingredients. Sure, the pickle is a crucial ingredient, but there&#x27;s a lot more to it.</div><br/><div id="39882146" class="c"><input type="checkbox" id="c-39882146" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39879122">parent</a><span>|</span><a href="#39882461">next</a><span>|</span><label class="collapse" for="c-39882146">[-]</label><label class="expand" for="c-39882146">[1 more]</label></div><br/><div class="children"><div class="content">Just like a stock C or C++ compiler won&#x27;t complain about the endless possibility of getting things wrong.<p>Or to pick on IDisposable, you can repeat exactly everything you said regarding actually providing a destructor, properly implemented, taking into account class hierarchies, multiple inheritance, heap allocation, and being exception safe.<p>Someone has to write those destructors.</div><br/></div></div><div id="39882461" class="c"><input type="checkbox" id="c-39882461" checked=""/><div class="controls bullet"><span class="by">zvrba</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39879122">parent</a><span>|</span><a href="#39882146">prev</a><span>|</span><a href="#39879347">next</a><span>|</span><label class="collapse" for="c-39882461">[-]</label><label class="expand" for="c-39882461">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In my experience it&#x27;s much less error prone to unify memory and external resource management.<p>Until threads and async enter the scene.</div><br/></div></div></div></div></div></div><div id="39879347" class="c"><input type="checkbox" id="c-39879347" checked=""/><div class="controls bullet"><span class="by">worik</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39876569">prev</a><span>|</span><a href="#39881176">next</a><span>|</span><label class="collapse" for="c-39879347">[-]</label><label class="expand" for="c-39879347">[2 more]</label></div><br/><div class="children"><div class="content">Yes. But...<p>&gt; GC only solves the application memory part,<p>Except it does not. &quot;Solve&quot; that is.<p>It helps, yes it does<p>But as I have learnt the hard way (silly way too, to be truthful) GC will not help unless you actually delete all references to the unused memory<p>Perhaps GC have developed magic moo cow properties in the twenty five years since I made that discovery,  but I think the point remains<p>GC is very helpful,  but it does not stop resource leaks</div><br/><div id="39880620" class="c"><input type="checkbox" id="c-39880620" checked=""/><div class="controls bullet"><span class="by">erik_seaberg</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39879347">parent</a><span>|</span><a href="#39881176">next</a><span>|</span><label class="collapse" for="c-39880620">[-]</label><label class="expand" for="c-39880620">[1 more]</label></div><br/><div class="children"><div class="content">If unreachable objects point at each other, that&#x27;s only a problem for refcounting, not for tracing (their pointers aren&#x27;t followed).</div><br/></div></div></div></div><div id="39881176" class="c"><input type="checkbox" id="c-39881176" checked=""/><div class="controls bullet"><span class="by">rbehrends</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39879347">prev</a><span>|</span><a href="#39876031">next</a><span>|</span><label class="collapse" for="c-39881176">[-]</label><label class="expand" for="c-39881176">[1 more]</label></div><br/><div class="children"><div class="content">First, I have no desire to handle both memory and external resources in a unified way, because memory management and resource management have different needs.<p>Memory is not just &quot;one kind of resource&quot;, it&#x27;s a very specific type of resource that if it has to be managed manually, inherently creates crosscutting concerns. And memory allocation is pervasive, often implicit in other language constructs. Garbage collectors get to cheat here, because they have a global view that ignores module boundaries and information hiding.<p>The classical example is that introducing a caching mechanism usually introduces API breaks. Where a function normally returns a pointer&#x2F;reference&#x2F;unique pointer and makes the caller responsible for freeing memory (whether through convention such as in C or enforced&#x2F;automated through language mechanisms such as in Rust), the moment you cache it, you need to return a reference-counted pointer, because now the memory can only be freed if both the caller <i>and</i> the cache don&#x27;t use it anymore. And that change from a non-reference-counted pointer to a reference-counted pointer is a breaking API change.<p>There are plenty more situations where manual memory management interacts poorly with modularity, such as filter() style functions, or the various complications that arise from closures capturing their local environment.<p>Conversely, it is absolutely possible to have pretty straightforward resource management with guaranteed and predictable lifetimes in a GCed language (though, alas, there&#x27;s a lack of direct language support for that).<p>The general approach is as follows: Each resource&#x27;s constructor takes an explicit or implicit owner argument (implicit being the current scope, whether defined through a language construct). You can also transfer a resource to a different owner (reparenting) [1].<p>Owners of resources can be lifetime managers such as scopes (but those do not need to correspond to lexical scopes and are more like transactions), that have more complex lifetime logic (such as a pool of resources) or objects that themselves are owned (e.g. if you have resources dependent on other resources). When the lifetime of the owner finishes, it calls a dispose function in all owned objects.<p>Because an owner is required in order to construct such a resource object (unlike a C# using clause or Java&#x27;s try-with-resources) by virtue of its constructor requiring it, it is impossible to accidentally create such a resource without a controlled lifetime [2].<p>Note that this is not the equivalent to RAII. You can have a number of non-owning references to such resource objects, essentially the equivalent of a weak pointer. In my experience, this is generally a good thing, because you do not want to have a hidden pointer secretly extending the lifetime of a potentially expensive resource. I prefer resource lifetimes to be explicit and to get an error if they are used past their intended lifetime.<p>[1] Note that this is conceptually similar to talloc. <a href="https:&#x2F;&#x2F;talloc.samba.org&#x2F;talloc&#x2F;doc&#x2F;html&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;talloc.samba.org&#x2F;talloc&#x2F;doc&#x2F;html&#x2F;index.html</a><p>[2] Obviously, it is still possible in <i>any</i> language to do the equivalent of a raw fopen() call, but that&#x27;s not something that RAII can fix, either.</div><br/></div></div><div id="39876031" class="c"><input type="checkbox" id="c-39876031" checked=""/><div class="controls bullet"><span class="by">samatman</span><span>|</span><a href="#39875604">parent</a><span>|</span><a href="#39881176">prev</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39876031">[-]</label><label class="expand" for="c-39876031">[11 more]</label></div><br/><div class="children"><div class="content">&gt; <i>GC only solves the application memory part, thus doesn&#x27;t help at all for handling those external resources.</i><p>This is far from entirely true. Most languages with a garbage collector have finalizers, which will clean that sort of thing up. Generally, and unlike memory allocation, one can call those finalizers from within user code, so as not to have to rely on the GC running.<p>The distinction between reference counting and garbage collection is an artificial one. Reference counting is an approach to garbage collection, one with different tradeoffs from more concept-central algorithms for GC. I agree with you that it&#x27;s a more unified approach to resource management, finalizers require user attention in a way which ordinary allocation doesn&#x27;t, so yes, system resources get treated differently. I don&#x27;t see that as a slam-dunk against them, however.</div><br/><div id="39877182" class="c"><input type="checkbox" id="c-39877182" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876031">parent</a><span>|</span><a href="#39877898">next</a><span>|</span><label class="collapse" for="c-39877182">[-]</label><label class="expand" for="c-39877182">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Most languages with a garbage collector have finalizers, which will clean that sort of thing up.<p>Using finalizers for cleanup of non-memory resources is bad because they will only be called when there&#x27;s memory pressure. If you have used all of your non-memory resource, but there&#x27;s still plenty of free memory, the allocation of that resource will fail; if you instead force a garbage collection at that point, not only will you cause a pause, but also you will be collecting memory while there&#x27;s still plenty of it available.</div><br/></div></div><div id="39877898" class="c"><input type="checkbox" id="c-39877898" checked=""/><div class="controls bullet"><span class="by">PhilipRoman</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876031">parent</a><span>|</span><a href="#39877182">prev</a><span>|</span><a href="#39877393">next</a><span>|</span><label class="collapse" for="c-39877898">[-]</label><label class="expand" for="c-39877898">[1 more]</label></div><br/><div class="children"><div class="content">Trusting the GC with freeing externally observable resources will bring you some very painful bugs.<p>On that note, it&#x27;s 2024 and we still cannot unmap a mmapped file from Java in a timely manner. I really hope they do something about it.</div><br/></div></div><div id="39877393" class="c"><input type="checkbox" id="c-39877393" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876031">parent</a><span>|</span><a href="#39877898">prev</a><span>|</span><a href="#39876348">next</a><span>|</span><label class="collapse" for="c-39877393">[-]</label><label class="expand" for="c-39877393">[1 more]</label></div><br/><div class="children"><div class="content">Finalizers will be non-deterministic when called as part of GC. One advantage of reference counting is that it <i>is</i> deterministic (and yes, this means that sometimes freeing the last reference that&#x27;s keeping a bunch of objects around will lead to a spike of extra deallocations.  Guess what, that&#x27;s what determinism is.  It&#x27;s implied by the need to free resources promptly.)</div><br/></div></div><div id="39876348" class="c"><input type="checkbox" id="c-39876348" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876031">parent</a><span>|</span><a href="#39877393">prev</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39876348">[-]</label><label class="expand" for="c-39876348">[7 more]</label></div><br/><div class="children"><div class="content">One problem with finalizers, try-finally, try-with-resources, Python-`with`, etc. is that they don&#x27;t actually guarantee the code will be called even in common cases.<p>In particular, any function that returns a (possibly newly-constructed) open file handle has not yet informed the caller that it&#x27;s actually a thing to keep track of, unlike with destructors which are active <i>immediately</i> once the object&#x27;s lifetime begins, and only rely on `move` being relatively atomic.</div><br/><div id="39878586" class="c"><input type="checkbox" id="c-39878586" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876348">parent</a><span>|</span><a href="#39877872">next</a><span>|</span><label class="collapse" for="c-39878586">[-]</label><label class="expand" for="c-39878586">[1 more]</label></div><br/><div class="children"><div class="content">You use the C and C++ approach to all their design flaws and reach out to a static analysis tool that covers such cases.</div><br/></div></div><div id="39877872" class="c"><input type="checkbox" id="c-39877872" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39876348">parent</a><span>|</span><a href="#39878586">prev</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39877872">[-]</label><label class="expand" for="c-39877872">[5 more]</label></div><br/><div class="children"><div class="content">How is a try-with-resources not guaranteed? At least in Java, it is guaranteed to run - plus, you can get your closing&#x2F;destructor logic wrong in RAII languages as well.</div><br/><div id="39878009" class="c"><input type="checkbox" id="c-39878009" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39877872">parent</a><span>|</span><a href="#39879321">next</a><span>|</span><label class="collapse" for="c-39878009">[-]</label><label class="expand" for="c-39878009">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How is a try-with-resources not guaranteed? At least in Java, it is guaranteed to run<p>There&#x27;s a subtle detail you have to be careful with, however: if you try to allocate memory or call a method between allocating your resource and actually doing the try-with-resources, you might get an OutOfMemoryError or a StackOverflowError, and your resource will leak. That is, if you do something like:<p><pre><code>  try (MyHolder holder = new MyHolder(allocateResource())) { ... }
</code></pre>
You can have a leak if the memory allocation in the &quot;new MyHolder()&quot; fails, or if there&#x27;s not enough space in the stack to call the MyHolder constructor.<p>&gt; plus, you can get your closing&#x2F;destructor logic wrong in RAII languages as well.<p>For instance, in C++ you can accidentally put your resource in a temporary which is immediately destructed at the end of the line, when you wanted it to last until the end of the enclosing scope. Rust makes it harder for this to happen, but it&#x27;s still possible.</div><br/></div></div><div id="39879321" class="c"><input type="checkbox" id="c-39879321" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39877872">parent</a><span>|</span><a href="#39878009">prev</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39879321">[-]</label><label class="expand" for="c-39879321">[3 more]</label></div><br/><div class="children"><div class="content">I mean, it&#x27;s possible to write bad code in C++. But at least it&#x27;s possible to write good code too. C++ makes a careful sequence that&#x27;s hard to get wrong and easily compiler enforced:<p>* if a given subobject (field or base class)&#x27;s constructor runs, its destructor is guaranteed to run.<p>* in particular, in low-level ownership classes, you can arrange for field initializers to be `noexcept`, so you get to run their dtor, regardless of subsequent manipulation of the fields - just be sure to not assume invariants from the fully-constructed main object case. In most classes, deferring <i>all</i> ownership logic to the fields is simpler - rule of zero beats rule of 5. And if you <i>do</i> add manual try-catch during construction it will actually work.<p>Languages other than C++ generally fail in several ways:<p>* Allow exceptions to be thrown by the runtime for reasons unrelated to the code being executed<p>* No support for subobjects, forcing all objects to be allocated separately and thus the runtime not knowing it needs to poke them since finalizers are only applied to objects not pointers. In particular, Python&#x27;s `contextlib.ExitStack` can <i>narrow</i> the window in which case leaks are possible, but not eliminate it.<p>Rust does slightly better than C++ by enforcing trivial moves, at the cost of making many useful programs impossible to write.</div><br/><div id="39879418" class="c"><input type="checkbox" id="c-39879418" checked=""/><div class="controls bullet"><span class="by">worik</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39879321">parent</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39879418">[-]</label><label class="expand" for="c-39879418">[2 more]</label></div><br/><div class="children"><div class="content">Ouch!<p>&gt; Rust does slightly better than C++ by enforcing trivial moves, at the cost of making many useful programs impossible to write.<p>What &quot;useful&quot; programs fit a useful definition of &quot;many&quot;?<p>It makes self referential looped data structures hard to write (double linked lists, trees with pointers to parents).<p>No loss. Great improvement to have fewer of those<p>It makes arbitrary allocation hard.  Enforces behaviors. Makes a programmer think very hard.<p>&quot;useful programs impossible to write. &quot;  No it does not.  It ,ages a lot of bad ideas hard to implement,  makes nothing &quot;impossible &quot;</div><br/><div id="39880002" class="c"><input type="checkbox" id="c-39880002" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#39875604">root</a><span>|</span><a href="#39879418">parent</a><span>|</span><a href="#39877236">next</a><span>|</span><label class="collapse" for="c-39880002">[-]</label><label class="expand" for="c-39880002">[1 more]</label></div><br/><div class="children"><div class="content">Good luck implementing &quot;peer pointers&quot; in Rust. Zero allocation involved, trivial to do safely in C++.<p><pre><code>  class A
  {
    &#x2F;* can be NULL if detached *&#x2F;
    B *peer;
    &#x2F;* other fields generally exist in one of the classes. *&#x2F;

    &#x2F;* useful objects are typically created in pairs, but can be constructed detached if needed *&#x2F;
    &#x2F;* move ctor and swap keep the (value) objects pointing at each other *&#x2F;
    &#x2F;* move assignment and dtor call detach() on the overwritten&#x2F;expiring object *&#x2F;
    &#x2F;* Often separate &quot;detach and cancel&quot; and &quot;detach without canceling&quot; are useful *&#x2F;
    void detach();
    &#x2F;* other functions specific to the peerage *&#x2F;
  };
  class B
  {
    A *peer;
    &#x2F;* same API as `class A`, but usually most of it is only used via one owner. *&#x2F;
    &#x2F;* In my experience, generally one class&#x27;s instance goes in some collection of centralized objects like an event loop, and the other is used as a handle to it. *&#x2F;
  };
</code></pre>
I guess we could always use the usual Rust solution of &quot;screw ownership and efficiency, just shove everything in an `Rc&lt;RefCell&lt;&gt;&gt;`&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39877236" class="c"><input type="checkbox" id="c-39877236" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#39875604">prev</a><span>|</span><a href="#39875767">next</a><span>|</span><label class="collapse" for="c-39877236">[-]</label><label class="expand" for="c-39877236">[1 more]</label></div><br/><div class="children"><div class="content">I quoted this in another comment here, but just to highlight one of the best couple of sentences in TFA:<p>&gt; Tools to automate the “actually freeing the memory” part, like lifetimes in Rust and RAII in C++, don’t solve these problems. They absolutely aid correctness, something else you should care deeply about, but they do nothing to simplify all this machinery.</div><br/></div></div><div id="39875767" class="c"><input type="checkbox" id="c-39875767" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#39877236">prev</a><span>|</span><a href="#39876413">next</a><span>|</span><label class="collapse" for="c-39875767">[-]</label><label class="expand" for="c-39875767">[1 more]</label></div><br/><div class="children"><div class="content">I do a lot of different types of systems programming.<p>Only times I actually use GC is to manage resources other than memory.</div><br/></div></div><div id="39876413" class="c"><input type="checkbox" id="c-39876413" checked=""/><div class="controls bullet"><span class="by">atum47</span><span>|</span><a href="#39875767">prev</a><span>|</span><a href="#39875965">next</a><span>|</span><label class="collapse" for="c-39876413">[-]</label><label class="expand" for="c-39876413">[2 more]</label></div><br/><div class="children"><div class="content">I once enabled garbage collection for this software I was writing and it collected everything.</div><br/><div id="39876443" class="c"><input type="checkbox" id="c-39876443" checked=""/><div class="controls bullet"><span class="by">ervine</span><span>|</span><a href="#39876413">parent</a><span>|</span><a href="#39875965">next</a><span>|</span><label class="collapse" for="c-39876443">[-]</label><label class="expand" for="c-39876443">[1 more]</label></div><br/><div class="children"><div class="content">Sprayed spot remover on my dog. Next day he was gone.</div><br/></div></div></div></div><div id="39875965" class="c"><input type="checkbox" id="c-39875965" checked=""/><div class="controls bullet"><span class="by">netbioserror</span><span>|</span><a href="#39876413">prev</a><span>|</span><a href="#39875936">next</a><span>|</span><label class="collapse" for="c-39875965">[-]</label><label class="expand" for="c-39875965">[9 more]</label></div><br/><div class="children"><div class="content">I use Nim in production. It defaults to RC. The biggest benefit of runtime automatic memory management that rarely gets mentioned: You can easily eliminate almost all memory semantics from a typical server-side program. My code is 99.9% business logic, with the 0.1% being a couple procedures which interface to a C library.<p>Hardcore manual memory people seem to have completely misaligned priorities to real-world concerns. Maintainability, safety, productivity, and iteration speed seem to be bottom-of-list to the egotistic holy grail be being able to say they write their own memory routines. If they&#x27;re not in an embedded context, I&#x27;m really unsure why anyone paying them to write code should care what they have to say. They&#x27;re not talking about increasing robustness and reducing costs, so what the hell are they even rambling about? I&#x27;ve had too many of these debates in-person face-to-face with people who can&#x27;t match my ability to deliver.<p>The vast majority of us are not smarter than the compiler, and are not smarter than automatic MM routines. Those who are write compilers and GCs. They don&#x27;t work on the same programs we all write, just memory managed. It&#x27;s the worst-kept secret that the remaining contexts where manual management is used often have the worst-maintained spaghetti codebases, leading to disasters, whistleblown scandles, and hush-hush covered catastrophes waiting in the wings while people get the hell out of dodge before they blow. It&#x27;s all duct tape and prayers. Having had to inspect and translate procedures from a deliberately obfuscated spaghetti C codebase, my position on this is going to be hard to budge. Experience is an unbeatable Bayesian prior.</div><br/><div id="39877414" class="c"><input type="checkbox" id="c-39877414" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#39875965">parent</a><span>|</span><a href="#39876158">next</a><span>|</span><label class="collapse" for="c-39877414">[-]</label><label class="expand" for="c-39877414">[2 more]</label></div><br/><div class="children"><div class="content">Most systems programming languages don&#x27;t have fully manual memory management these days - they use RAII. Manual deallocation is possible, but not used often.</div><br/><div id="39881375" class="c"><input type="checkbox" id="c-39881375" checked=""/><div class="controls bullet"><span class="by">yawaramin</span><span>|</span><a href="#39875965">root</a><span>|</span><a href="#39877414">parent</a><span>|</span><a href="#39876158">next</a><span>|</span><label class="collapse" for="c-39881375">[-]</label><label class="expand" for="c-39881375">[1 more]</label></div><br/><div class="children"><div class="content">Amusing segfault in 10 lines of Modern C++ with RAII:<p><pre><code>    #include &lt;iostream&gt;
    #include &lt;memory&gt;

    int main(int argc, char* argv[]) {
      auto s = std::make_unique&lt;std::string&gt;(&quot;hello&quot;);
      std::unique_ptr&lt;std::string&gt; s2 = std::move(s);

      std::cout &lt;&lt; *s &lt;&lt; std::endl;
      return 0;
    }</code></pre></div><br/></div></div></div></div><div id="39876158" class="c"><input type="checkbox" id="c-39876158" checked=""/><div class="controls bullet"><span class="by">EatFlamingDeath</span><span>|</span><a href="#39875965">parent</a><span>|</span><a href="#39877414">prev</a><span>|</span><a href="#39878241">next</a><span>|</span><label class="collapse" for="c-39876158">[-]</label><label class="expand" for="c-39876158">[4 more]</label></div><br/><div class="children"><div class="content">How&#x27;s Nim in production? I really enjoyed working with the language and I&#x27;ve been bitten too many times by Python&#x27;s package management. Do you think it&#x27;s suitable for scripting too?</div><br/><div id="39877121" class="c"><input type="checkbox" id="c-39877121" checked=""/><div class="controls bullet"><span class="by">netbioserror</span><span>|</span><a href="#39875965">root</a><span>|</span><a href="#39876158">parent</a><span>|</span><a href="#39876364">next</a><span>|</span><label class="collapse" for="c-39877121">[-]</label><label class="expand" for="c-39877121">[1 more]</label></div><br/><div class="children"><div class="content">I should also mention: Be careful analyzing forum or example Nim code. A LOT of Nim programmers are coming from the C or C++ side of things and trying to use it like C or C++. You can write most Nim programs essentially like Python. Keep it clean, keep it simple. Use iterators, use map(), use universal function call syntax, use the full semantic power of sequences (very comparable to Python lists).</div><br/></div></div><div id="39876364" class="c"><input type="checkbox" id="c-39876364" checked=""/><div class="controls bullet"><span class="by">netbioserror</span><span>|</span><a href="#39875965">root</a><span>|</span><a href="#39876158">parent</a><span>|</span><a href="#39877121">prev</a><span>|</span><a href="#39878241">next</a><span>|</span><label class="collapse" for="c-39876364">[-]</label><label class="expand" for="c-39876364">[2 more]</label></div><br/><div class="children"><div class="content">I use it in a context it&#x27;s extremely well suited for: As a CLI executable invoked by other server-side scripts. It&#x27;s a program that does lots of mathematical and statistical data processing, along with HTML report generation. Like I said, I use the default RC and don&#x27;t even think about memory. The type system is very simple; there is only one nominal string type, for example, instead of the 12 in Rust or C++, and it&#x27;s a fleshed-out string type that can be mutable or immutable. I also take big advantage of its preference for functional-style referential transparency with only local mutations. I have only a single module that could be construed as &quot;OO&quot;. Oh, and the module system works exactly like you probably intuit a module system should, so you probably already know how to use it.<p>If you want to script with Nim, it&#x27;s actually quite nice; it has a &quot;run&quot; command which compiles and runs without depositing artifacts in the run directory, and has an incredibly robust standard library, comparable to that of Python.<p>I have no experience making a live always-running Nim application, so I can&#x27;t speak to that. But in the context I use it, it&#x27;s incredible.</div><br/><div id="39877298" class="c"><input type="checkbox" id="c-39877298" checked=""/><div class="controls bullet"><span class="by">cb321</span><span>|</span><a href="#39875965">root</a><span>|</span><a href="#39876364">parent</a><span>|</span><a href="#39878241">next</a><span>|</span><label class="collapse" for="c-39877298">[-]</label><label class="expand" for="c-39877298">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I have no experience making a live always-running Nim application, so I can&#x27;t speak to that. But in the context I use it, it&#x27;s incredible.<p>I have done this several ways quite successfully. Firstly, instead of &quot;%cpu&quot; I tend to measure &quot;10s..100s of parts per billion&quot; CPU from a like ~100 lines of code &quot;cron library&quot; that I use instead of system cron demons: <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cron">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cron</a>  -- seeing 40 ppb on one box and 73 ppb on another at the moment.<p>Another example might be <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;bu&#x2F;blob&#x2F;main&#x2F;doc&#x2F;dirq.md">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;bu&#x2F;blob&#x2F;main&#x2F;doc&#x2F;dirq.md</a> which is a kind of ad hoc demon to monitor however many directories on Linux with inotify and then launch user-commands against dropped in files.  This can be a sort of Plan 9 &quot;plumb&quot; style thing.  E.g., one of the directories I monitor is a browser download directory.  So, one click to save and them boom - a potential cascade of activity.  (EDTI: This is clocking in at about 9572177ns&#x2F;(48*3600s) =~ 55 parts per billion for me right now.)<p>As a final example, I got annoyed with the unwanted complexity of modern syslog junk.  So, I whipped up <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;kslog">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;kslog</a> which just looking it up for this post, according to &#x2F;proc&#x2F;PID&#x2F;schedstat has only accumulated about 27357590&#x2F;(24*3600+24*60) =~ 311 parts per billion of 1 CPU on a 4-core system since boot about 24h:24m ago. This in about 25% of the lines of Nim code that busybox spends on less useful C code (to your point of &quot;almost all the code is the actual logic, not other junk&quot;).<p>Also, while it is not as full-featured as stdlib `string`, there is a zero-copy `cligen&#x2F;mslice.MSlice` type (<a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cligen&#x2F;blob&#x2F;master&#x2F;cligen&#x2F;mslice.nim">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cligen&#x2F;blob&#x2F;master&#x2F;cligen&#x2F;mslice....</a>) that does have basic features like splitting and number parsing.  There are probably others out in the Nimbleverse.  If view types ever migrate from experimental status to relied-upon that might become less interesting.<p>Since you do a lot of statistics, you might also appreciate the fmtUncertain* subsystem of <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cligen&#x2F;blob&#x2F;master&#x2F;cligen&#x2F;strUt.nim">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;cligen&#x2F;blob&#x2F;master&#x2F;cligen&#x2F;strUt.n...</a> which allows you to retain only meaningful number of digits and also <a href="https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;adix&#x2F;blob&#x2F;master&#x2F;adix&#x2F;mvstat.nim">https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;adix&#x2F;blob&#x2F;master&#x2F;adix&#x2F;mvstat.nim</a> which has efficient moving quantiles via a Fenwick Tree logarithmic histogram.</div><br/></div></div></div></div></div></div><div id="39878241" class="c"><input type="checkbox" id="c-39878241" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#39875965">parent</a><span>|</span><a href="#39876158">prev</a><span>|</span><a href="#39875936">next</a><span>|</span><label class="collapse" for="c-39878241">[-]</label><label class="expand" for="c-39878241">[2 more]</label></div><br/><div class="children"><div class="content"><i>Hardcore manual memory people seem to have completely misaligned priorities to real-world concerns. Maintainability, safety, productivity, and iteration speed seem to be bottom-of-list to the egotistic holy grail be being able to say they write their own memory routines.</i><p>I think you&#x27;ve gotten very worked up over a theoretical boogieman person that doesn&#x27;t exist.  Most natively compiled programs are written in C++ with Rust as a distant second and both put a lot of effort into the selling point that you don&#x27;t have to manually manage memory the same way you do with C and can do with ownership. I&#x27;ve never seen anyone like you&#x27;re describing.</div><br/><div id="39878551" class="c"><input type="checkbox" id="c-39878551" checked=""/><div class="controls bullet"><span class="by">netbioserror</span><span>|</span><a href="#39875965">root</a><span>|</span><a href="#39878241">parent</a><span>|</span><a href="#39875936">next</a><span>|</span><label class="collapse" for="c-39878551">[-]</label><label class="expand" for="c-39878551">[1 more]</label></div><br/><div class="children"><div class="content">I have met people like that. Sorry.</div><br/></div></div></div></div></div></div><div id="39875936" class="c"><input type="checkbox" id="c-39875936" checked=""/><div class="controls bullet"><span class="by">samatman</span><span>|</span><a href="#39875965">prev</a><span>|</span><a href="#39875686">next</a><span>|</span><label class="collapse" for="c-39875936">[-]</label><label class="expand" for="c-39875936">[4 more]</label></div><br/><div class="children"><div class="content">This skirts around the edge of an observation which I want to dive into, which is that modern user OSes (anything which isn&#x27;t a specialized RTOS) has built-in garbage collection. We just don&#x27;t call it that: we just call it memory management. What do we call languages with a built in GC? Memory-managed languages!<p>You see this in a lot of older &quot;top-to-bottom&quot; C programs: they allocate, they clean up system resources (using longjmp to one label), but they don&#x27;t bother with free. When the program exits the OS gets all that memory back anyway, so why bother?<p>There&#x27;s a missed opportunity here, to have an OS with a garbage collector with less isolation from programs, one which handles resources more like a language&#x27;s runtime GC. It will probably stay missed, because in the typical GCed language, the GC is intricately built into practically every line of the runtime, so it&#x27;s not really practical to make a distribution of that language for one OS which hands that control over to the operating system.<p>But it&#x27;s a pity, because there&#x27;s a lot of room to improve some of the chronic problems we see from this artificial isolation of program-level memory management from OS level.</div><br/><div id="39876072" class="c"><input type="checkbox" id="c-39876072" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39875936">parent</a><span>|</span><a href="#39879048">next</a><span>|</span><label class="collapse" for="c-39876072">[-]</label><label class="expand" for="c-39876072">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You see this in a lot of older &quot;top-to-bottom&quot; C programs: they allocate, they clean up system resources (using longjmp to one label), but they don&#x27;t bother with free. When the program exits the OS gets all that memory back anyway, so why bother?<p>You don&#x27;t need to bother with releasing other types of resources either though (files, sockets, threads, ...), since the operating system will take care of that on process exit (unless you are on AmigaOS). The only reason to free memory is to recycle that memory in other allocations in long running applications without grabbing new memory from the OS. For one-shot command line tools it&#x27;s usually not needed.</div><br/></div></div><div id="39879048" class="c"><input type="checkbox" id="c-39879048" checked=""/><div class="controls bullet"><span class="by">ninkendo</span><span>|</span><a href="#39875936">parent</a><span>|</span><a href="#39876072">prev</a><span>|</span><a href="#39877920">next</a><span>|</span><label class="collapse" for="c-39879048">[-]</label><label class="expand" for="c-39879048">[1 more]</label></div><br/><div class="children"><div class="content">The OS only knows it can free memory when your process exits (same as file handles and other resources.) If your process is designed to exit once it&#x27;s done its job, you <i>can</i> use the OS as a garbage collector.<p>Having an operating system know when memory is unused <i>within your running program</i> is not something that has ever existed though (except for perhaps some esoteric research OS&#x27;s.) I wouldn&#x27;t say we&#x27;re missing an opportunity, because the thing we&#x27;re missing doesn&#x27;t exist in any meaningful sense. On the other hand, a programming methodology that uses very simple, short-lived programs is a totally legitimate way to do things... it&#x27;s how CLI tools and the scripting languages that script them work, it&#x27;s how web servers used to work (with CGI&#x2F;etc), and it&#x27;s a perfectly reasonable approach even today.</div><br/></div></div><div id="39877920" class="c"><input type="checkbox" id="c-39877920" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39875936">parent</a><span>|</span><a href="#39879048">prev</a><span>|</span><a href="#39875686">next</a><span>|</span><label class="collapse" for="c-39877920">[-]</label><label class="expand" for="c-39877920">[1 more]</label></div><br/><div class="children"><div class="content">In Java, the Epsilon GC is just that.</div><br/></div></div></div></div><div id="39875686" class="c"><input type="checkbox" id="c-39875686" checked=""/><div class="controls bullet"><span class="by">bckr</span><span>|</span><a href="#39875936">prev</a><span>|</span><a href="#39875411">next</a><span>|</span><label class="collapse" for="c-39875686">[-]</label><label class="expand" for="c-39875686">[5 more]</label></div><br/><div class="children"><div class="content">Off topic but what is going on in the picture of the leaking pipe? I don’t think it’s AI but there’s a third arm in there that I don’t understand. There’s at least two guys in the picture but I can’t assign one of the arms to either of them.</div><br/><div id="39875887" class="c"><input type="checkbox" id="c-39875887" checked=""/><div class="controls bullet"><span class="by">deutschepost</span><span>|</span><a href="#39875686">parent</a><span>|</span><a href="#39875900">next</a><span>|</span><label class="collapse" for="c-39875887">[-]</label><label class="expand" for="c-39875887">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s three people. The guy on the right is leaning over another one under the water. It&#x27;s probably a picture from a flood training simulator.<p>Edit: <a href="https:&#x2F;&#x2F;commons.wikimedia.org&#x2F;wiki&#x2F;File:US_Navy_040308-N-0000P-002_Sailors_practice_repairing_leaks_in_the_%22wet_trainer%22_on_board_the_Submarine_Training_Facility_(SUBTRAFAC)_in_Norfolk,_Va.jpg" rel="nofollow">https:&#x2F;&#x2F;commons.wikimedia.org&#x2F;wiki&#x2F;File:US_Navy_040308-N-000...</a><p>The picture was uploaded in 2009. Downvote if you want, but there is no AI at work here.</div><br/></div></div><div id="39875706" class="c"><input type="checkbox" id="c-39875706" checked=""/><div class="controls bullet"><span class="by">mindv0rtex</span><span>|</span><a href="#39875686">parent</a><span>|</span><a href="#39875900">prev</a><span>|</span><a href="#39875411">next</a><span>|</span><label class="collapse" for="c-39875706">[-]</label><label class="expand" for="c-39875706">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s definitely AI generated, that picture makes no sense.</div><br/></div></div></div></div><div id="39875528" class="c"><input type="checkbox" id="c-39875528" checked=""/><div class="controls bullet"><span class="by">spintin</span><span>|</span><a href="#39878747">prev</a><span>|</span><a href="#39877314">next</a><span>|</span><label class="collapse" for="c-39875528">[-]</label><label class="expand" for="c-39875528">[6 more]</label></div><br/><div class="children"><div class="content">Or you just use static atomic variables no?<p>I mean it wont solve your race conditions but it also wont crash.<p>And it will be VERY fast because parallelism without cache misses!<p>I wish there was a Java with C struct JNI access.</div><br/><div id="39875668" class="c"><input type="checkbox" id="c-39875668" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#39875528">parent</a><span>|</span><a href="#39881810">next</a><span>|</span><label class="collapse" for="c-39875668">[-]</label><label class="expand" for="c-39875668">[1 more]</label></div><br/><div class="children"><div class="content">Saying this as a big hardware atomics enjoyer: Static atomic variables are not fast, are not parallel and definitely are the worst kind of cache misses.<p>Atomics are also atomic only on that one single operation, such as manipulating a single number in a struct or swapping out a pointer from one version of an object to another. To atomically expose a set of changes to a datastructure, you either use a lock or swap the old for the new, which is the driving example in the article.</div><br/></div></div><div id="39881810" class="c"><input type="checkbox" id="c-39881810" checked=""/><div class="controls bullet"><span class="by">gmokki</span><span>|</span><a href="#39875528">parent</a><span>|</span><a href="#39875668">prev</a><span>|</span><a href="#39875595">next</a><span>|</span><label class="collapse" for="c-39881810">[-]</label><label class="expand" for="c-39881810">[1 more]</label></div><br/><div class="children"><div class="content">Modern Java does support directly calling C functions, with structs.
And also upcalls back to java.
All without any JNI style preprocessing or stubs.<p><a href="https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;java&#x2F;javase&#x2F;21&#x2F;core&#x2F;calling-c-library-function-foreign-function-and-memory-api.html" rel="nofollow">https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;java&#x2F;javase&#x2F;21&#x2F;core&#x2F;calling-c-lib...</a></div><br/></div></div><div id="39875595" class="c"><input type="checkbox" id="c-39875595" checked=""/><div class="controls bullet"><span class="by">bugbuddy</span><span>|</span><a href="#39875528">parent</a><span>|</span><a href="#39881810">prev</a><span>|</span><a href="#39876235">next</a><span>|</span><label class="collapse" for="c-39875595">[-]</label><label class="expand" for="c-39875595">[1 more]</label></div><br/><div class="children"><div class="content">This is false. Depending on the CPU Arch, updating a shared static atomic variable may cause cache invalidation. How fast depends on how hot and tight you critical sections are.</div><br/></div></div><div id="39876235" class="c"><input type="checkbox" id="c-39876235" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#39875528">parent</a><span>|</span><a href="#39875595">prev</a><span>|</span><a href="#39877314">next</a><span>|</span><label class="collapse" for="c-39876235">[-]</label><label class="expand" for="c-39876235">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called C# (supporting plain C structs is just a small part of its low-level features)</div><br/><div id="39876673" class="c"><input type="checkbox" id="c-39876673" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39875528">root</a><span>|</span><a href="#39876235">parent</a><span>|</span><a href="#39877314">next</a><span>|</span><label class="collapse" for="c-39876673">[-]</label><label class="expand" for="c-39876673">[1 more]</label></div><br/><div class="children"><div class="content">Or D, available as official fronted language on GCC and LLVM projects, :)</div><br/></div></div></div></div></div></div><div id="39877314" class="c"><input type="checkbox" id="c-39877314" checked=""/><div class="controls bullet"><span class="by">bsdpufferfish</span><span>|</span><a href="#39875528">prev</a><span>|</span><label class="collapse" for="c-39877314">[-]</label><label class="expand" for="c-39877314">[1 more]</label></div><br/><div class="children"><div class="content">Why are they always trying to sell these things to audiences who are not interested?</div><br/></div></div></div></div></div></div></div></body></html>