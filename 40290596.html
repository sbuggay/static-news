<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715158874819" as="style"/><link rel="stylesheet" href="styles.css?v=1715158874819"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://scrapegraph-doc.onrender.com/">ScrapeGraphAI: Web scraping using LLM and direct graph logic</a> <span class="domain">(<a href="https://scrapegraph-doc.onrender.com">scrapegraph-doc.onrender.com</a>)</span></div><div class="subtext"><span>ulrischa</span> | <span>47 comments</span></div><br/><div><div id="40292021" class="c"><input type="checkbox" id="c-40292021" checked=""/><div class="controls bullet"><span class="by">nodoodles</span><span>|</span><a href="#40292086">next</a><span>|</span><label class="collapse" for="c-40292021">[-]</label><label class="expand" for="c-40292021">[14 more]</label></div><br/><div class="children"><div class="content">What I&#x27;d love to see is scraper builder that uses LLMs&#x2F;&#x27;magic&#x27; to generate optimised scraping rules for any page, ie css selectors and processing rules mapped to output keys. So you can run scraping itself at low cost and high performance..</div><br/><div id="40293210" class="c"><input type="checkbox" id="c-40293210" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40293625">next</a><span>|</span><label class="collapse" for="c-40293210">[-]</label><label class="expand" for="c-40293210">[1 more]</label></div><br/><div class="children"><div class="content">Agreed!<p>Apify&#x27;s Website Content Crawler[0] does a decent job of this for most websites in my experience. It allows you to &quot;extract&quot; content via different built-in methods (e.g. Extractus [1]).<p>We currently use this at Magic Loops[2] and it works _most_ of the time.<p>The long-tail is difficult though, and it&#x27;s not uncommon for users to back out to raw HTML, and then have our tool write some custom logic to parse the content they want from the scraped results (fun fact: before GPT-4 Turbo, the HTML page was often too large for the context window... and sometimes it still is!).<p>Would love a dedicated tool for this. I know the folks at Reworkd[3] are working on something similar, but not sure how much is public yet.<p>[0] <a href="https:&#x2F;&#x2F;apify.com&#x2F;apify&#x2F;website-content-crawler" rel="nofollow">https:&#x2F;&#x2F;apify.com&#x2F;apify&#x2F;website-content-crawler</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;extractus&#x2F;article-extractor">https:&#x2F;&#x2F;github.com&#x2F;extractus&#x2F;article-extractor</a><p>[2] <a href="https:&#x2F;&#x2F;magicloops.dev&#x2F;">https:&#x2F;&#x2F;magicloops.dev&#x2F;</a><p>[3] <a href="https:&#x2F;&#x2F;reworkd.ai&#x2F;">https:&#x2F;&#x2F;reworkd.ai&#x2F;</a></div><br/></div></div><div id="40293625" class="c"><input type="checkbox" id="c-40293625" checked=""/><div class="controls bullet"><span class="by">longgui0318</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40293210">prev</a><span>|</span><a href="#40293091">next</a><span>|</span><label class="collapse" for="c-40293625">[-]</label><label class="expand" for="c-40293625">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a project that describes the use of llm to generate crawling rules and then capture them, but it looks like it&#x27;s still in the early stages of research.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;EZ-hwh&#x2F;AutoCrawler">https:&#x2F;&#x2F;github.com&#x2F;EZ-hwh&#x2F;AutoCrawler</a></div><br/></div></div><div id="40293091" class="c"><input type="checkbox" id="c-40293091" checked=""/><div class="controls bullet"><span class="by">KhoomeiK</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40293625">prev</a><span>|</span><a href="#40293114">next</a><span>|</span><label class="collapse" for="c-40293091">[-]</label><label class="expand" for="c-40293091">[3 more]</label></div><br/><div class="children"><div class="content">This is essentially what we&#x27;re building at <a href="https:&#x2F;&#x2F;reworkd.ai">https:&#x2F;&#x2F;reworkd.ai</a> (YC S23). We had thousands of users try using AgentGPT (our previous product) for scraping and we learned that using LLMs for web data extraction fundamentally does not work unless you generate code.</div><br/><div id="40293746" class="c"><input type="checkbox" id="c-40293746" checked=""/><div class="controls bullet"><span class="by">spxneo</span><span>|</span><a href="#40292021">root</a><span>|</span><a href="#40293091">parent</a><span>|</span><a href="#40293114">next</a><span>|</span><label class="collapse" for="c-40293746">[-]</label><label class="expand" for="c-40293746">[2 more]</label></div><br/><div class="children"><div class="content">all around automation sucks with LLM thrown on top of it<p>the statistics are not in its favour</div><br/><div id="40293846" class="c"><input type="checkbox" id="c-40293846" checked=""/><div class="controls bullet"><span class="by">KhoomeiK</span><span>|</span><a href="#40292021">root</a><span>|</span><a href="#40293746">parent</a><span>|</span><a href="#40293114">next</a><span>|</span><label class="collapse" for="c-40293846">[-]</label><label class="expand" for="c-40293846">[1 more]</label></div><br/><div class="children"><div class="content">Yep, until you generate code—it&#x27;s harder from a technical POV but you can get way higher performance &amp; reliability.</div><br/></div></div></div></div></div></div><div id="40293114" class="c"><input type="checkbox" id="c-40293114" checked=""/><div class="controls bullet"><span class="by">nikcub</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40293091">prev</a><span>|</span><a href="#40292900">next</a><span>|</span><label class="collapse" for="c-40293114">[-]</label><label class="expand" for="c-40293114">[2 more]</label></div><br/><div class="children"><div class="content">Most of the top LLM already do this very well. It&#x27;s because they&#x27;ve been trained on web data, and also because they&#x27;re being used for precisely this task internally to grab data.<p>The complicated ops of scraping is running headless browsers, IP ranges, bot bypass, filling captchas, observability and updating selectors, etc. There are a ton of SaaS services that do that part for you.</div><br/><div id="40293851" class="c"><input type="checkbox" id="c-40293851" checked=""/><div class="controls bullet"><span class="by">selimthegrim</span><span>|</span><a href="#40292021">root</a><span>|</span><a href="#40293114">parent</a><span>|</span><a href="#40292900">next</a><span>|</span><label class="collapse" for="c-40293851">[-]</label><label class="expand" for="c-40293851">[1 more]</label></div><br/><div class="children"><div class="content">There was one I remember out of UF&#x2F;FSU called Intoli that seems to have pivoted into consulting.</div><br/></div></div></div></div><div id="40292900" class="c"><input type="checkbox" id="c-40292900" checked=""/><div class="controls bullet"><span class="by">greggsy</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40293114">prev</a><span>|</span><a href="#40295414">next</a><span>|</span><label class="collapse" for="c-40292900">[-]</label><label class="expand" for="c-40292900">[2 more]</label></div><br/><div class="children"><div class="content">It seems also obvious that one would want to simply drag a box around the content you want, and the tool would just provide some examples to help you refine the rule set.<p>Ad blockers have had something very close to this for some time, without any sparkly AI buttons.<p>I’m sure someone would be working on a subscription based model using corporate models in the backend, but it’s something that could easily be implemented with a very small model.</div><br/><div id="40292988" class="c"><input type="checkbox" id="c-40292988" checked=""/><div class="controls bullet"><span class="by">uptown</span><span>|</span><a href="#40292021">root</a><span>|</span><a href="#40292900">parent</a><span>|</span><a href="#40295414">next</a><span>|</span><label class="collapse" for="c-40292988">[-]</label><label class="expand" for="c-40292988">[1 more]</label></div><br/><div class="children"><div class="content">Mozenda does something like that.  I haven&#x27;t used it in many years, so I&#x27;m not up to date on what it currently offers.</div><br/></div></div></div></div><div id="40295414" class="c"><input type="checkbox" id="c-40295414" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40292900">prev</a><span>|</span><a href="#40294807">next</a><span>|</span><label class="collapse" for="c-40295414">[-]</label><label class="expand" for="c-40295414">[1 more]</label></div><br/><div class="children"><div class="content">Parsing html is a solved and frankly not a very interesting problem. Writing up xpath&#x2F;css selectors or JSON parsers (for when data is in script variables) is not much of a  challenge for anyone.<p>More interesting issue is being able to parse data from the whole page content stack which includes XHRs and their triggers. In this case LLM driver would control an indistinguishable web browser to perform all steps to retrieve the data as a full package. Though this is still a low value proposition as the models would get fumbled by harder tasks and easier tasks can be performed by a human being in couple of hours.<p>LLM use in web scraping is still purely educational and assistive as the biggest problem in scraping is not scraping itself but scraper scaling and blocking which is becoming extremely common.</div><br/></div></div><div id="40292551" class="c"><input type="checkbox" id="c-40292551" checked=""/><div class="controls bullet"><span class="by">geuis</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40294807">prev</a><span>|</span><a href="#40292360">next</a><span>|</span><label class="collapse" for="c-40292551">[-]</label><label class="expand" for="c-40292551">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an interesting take. I&#x27;ve been experimenting with reducing the overall rendered html size to just structure and content and using the LLM to extract content from that. It works quite well. But I think your approach might be more efficient and faster.</div><br/></div></div><div id="40292360" class="c"><input type="checkbox" id="c-40292360" checked=""/><div class="controls bullet"><span class="by">cpobuda</span><span>|</span><a href="#40292021">parent</a><span>|</span><a href="#40292551">prev</a><span>|</span><a href="#40292086">next</a><span>|</span><label class="collapse" for="c-40292360">[-]</label><label class="expand" for="c-40292360">[1 more]</label></div><br/><div class="children"><div class="content">I have been working on this. Feel free to DM me.</div><br/></div></div></div></div><div id="40292086" class="c"><input type="checkbox" id="c-40292086" checked=""/><div class="controls bullet"><span class="by">mariopt</span><span>|</span><a href="#40292021">prev</a><span>|</span><a href="#40294623">next</a><span>|</span><label class="collapse" for="c-40292086">[-]</label><label class="expand" for="c-40292086">[8 more]</label></div><br/><div class="children"><div class="content">What is the point of using LLMs for the scrapping itself instead of using them to generate the boring code for mimicking HTTP requests, css&#x2F;xpath selectors, etc?<p>I get it may be interesting for small tasks combined with a browser extension but for real scrapping just seems to be overkill and expensive.</div><br/><div id="40292647" class="c"><input type="checkbox" id="c-40292647" checked=""/><div class="controls bullet"><span class="by">geuis</span><span>|</span><a href="#40292086">parent</a><span>|</span><a href="#40294623">next</a><span>|</span><label class="collapse" for="c-40292647">[-]</label><label class="expand" for="c-40292647">[7 more]</label></div><br/><div class="children"><div class="content">It is potentially expensive, but here&#x27;s a different take.<p>Instead of writing a bunch of selectors that break often, imagine just being able to write a paragraph telling the LLM to fetch the top 10 headlines and their links on a news site. Or to fetch the images, titles, and prices off a store front?<p>It abstracts away a lot of manual fragile work.</div><br/><div id="40292798" class="c"><input type="checkbox" id="c-40292798" checked=""/><div class="controls bullet"><span class="by">mariopt</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40292647">parent</a><span>|</span><a href="#40293977">next</a><span>|</span><label class="collapse" for="c-40292798">[-]</label><label class="expand" for="c-40292798">[4 more]</label></div><br/><div class="children"><div class="content">I get that and LLMs are expected to get better.<p>Today, would you build a scraper with current LLMs that randomly hallucinate? I wouldn&#x27;t.<p>The idea of a LLM powered scraper adapting the selectors every time the website owner updates it, it&#x27;s pretty cool.</div><br/><div id="40294093" class="c"><input type="checkbox" id="c-40294093" checked=""/><div class="controls bullet"><span class="by">ewild</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40292798">parent</a><span>|</span><a href="#40293977">next</a><span>|</span><label class="collapse" for="c-40294093">[-]</label><label class="expand" for="c-40294093">[3 more]</label></div><br/><div class="children"><div class="content">At my job we are scraping using LLMs. For a 10M sector of the company. GPT4 turbo has never not once out of 1.5 million API requests hallucinated. We however use it to parse data and interpret it from webpages, this is something you wouldn&#x27;t be able to do with a regular scraper. Not well atleast.</div><br/><div id="40294262" class="c"><input type="checkbox" id="c-40294262" checked=""/><div class="controls bullet"><span class="by">what</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40294093">parent</a><span>|</span><a href="#40294428">next</a><span>|</span><label class="collapse" for="c-40294262">[-]</label><label class="expand" for="c-40294262">[1 more]</label></div><br/><div class="children"><div class="content">Bold claim, did you review all 1.5 million requests?</div><br/></div></div><div id="40294428" class="c"><input type="checkbox" id="c-40294428" checked=""/><div class="controls bullet"><span class="by">krainboltgreene</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40294093">parent</a><span>|</span><a href="#40294262">prev</a><span>|</span><a href="#40293977">next</a><span>|</span><label class="collapse" for="c-40294428">[-]</label><label class="expand" for="c-40294428">[1 more]</label></div><br/><div class="children"><div class="content">How do you know that&#x27;s true?</div><br/></div></div></div></div></div></div><div id="40293977" class="c"><input type="checkbox" id="c-40293977" checked=""/><div class="controls bullet"><span class="by">is_true</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40292647">parent</a><span>|</span><a href="#40292798">prev</a><span>|</span><a href="#40293673">next</a><span>|</span><label class="collapse" for="c-40293977">[-]</label><label class="expand" for="c-40293977">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve written thousands of scrapers and trust me, they don&#x27;t break often.</div><br/></div></div><div id="40293673" class="c"><input type="checkbox" id="c-40293673" checked=""/><div class="controls bullet"><span class="by">suchintan</span><span>|</span><a href="#40292086">root</a><span>|</span><a href="#40292647">parent</a><span>|</span><a href="#40293977">prev</a><span>|</span><a href="#40294623">next</a><span>|</span><label class="collapse" for="c-40293673">[-]</label><label class="expand" for="c-40293673">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern">https:&#x2F;&#x2F;github.com&#x2F;Skyvern-AI&#x2F;skyvern</a><p>This is pretty much what we&#x27;re building at Skyvern. The only problem is that inference cost is still a little bit too high for scraping, but we expect that to change in the next year</div><br/></div></div></div></div></div></div><div id="40294623" class="c"><input type="checkbox" id="c-40294623" checked=""/><div class="controls bullet"><span class="by">RamblingCTO</span><span>|</span><a href="#40292086">prev</a><span>|</span><a href="#40291195">next</a><span>|</span><label class="collapse" for="c-40294623">[-]</label><label class="expand" for="c-40294623">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see the benefit. I don&#x27;t wanna say what I built 2markdown.com with (converts websites to markdown for LLMs), but it has a pretty decent performance without any high cost (and also sometimes erroneous) LLMs thrown on top of the scraping.</div><br/></div></div><div id="40291195" class="c"><input type="checkbox" id="c-40291195" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#40294623">prev</a><span>|</span><a href="#40290789">next</a><span>|</span><label class="collapse" for="c-40291195">[-]</label><label class="expand" for="c-40291195">[2 more]</label></div><br/><div class="children"><div class="content">Would be nice if docs had a comparison between traditional scraping (e.g. using headless browsers, beautifulsoup, etc) versus this approach. Exactly how is AI used?</div><br/><div id="40292660" class="c"><input type="checkbox" id="c-40292660" checked=""/><div class="controls bullet"><span class="by">geuis</span><span>|</span><a href="#40291195">parent</a><span>|</span><a href="#40290789">next</a><span>|</span><label class="collapse" for="c-40292660">[-]</label><label class="expand" for="c-40292660">[1 more]</label></div><br/><div class="children"><div class="content">A lot of larger LLM&#x27;s have been trained on millions of pages of html. They have the ability to understand raw html structure and extract content from them. I&#x27;ve been having some success with this using Mixtral 8x7B.</div><br/></div></div></div></div><div id="40290789" class="c"><input type="checkbox" id="c-40290789" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40291195">prev</a><span>|</span><a href="#40290996">next</a><span>|</span><label class="collapse" for="c-40290789">[-]</label><label class="expand" for="c-40290789">[1 more]</label></div><br/><div class="children"><div class="content">Typo on your homepage: &quot;You just have to implment just some lines of code and the work is done&quot;</div><br/></div></div><div id="40290996" class="c"><input type="checkbox" id="c-40290996" checked=""/><div class="controls bullet"><span class="by">sethx</span><span>|</span><a href="#40290789">prev</a><span>|</span><a href="#40294618">next</a><span>|</span><label class="collapse" for="c-40290996">[-]</label><label class="expand" for="c-40290996">[2 more]</label></div><br/><div class="children"><div class="content">At jobstash.xyz we have similar tech as part of our generalized scraping infra, and it’s been live for half a year performing optimally.</div><br/></div></div><div id="40294618" class="c"><input type="checkbox" id="c-40294618" checked=""/><div class="controls bullet"><span class="by">nurettin</span><span>|</span><a href="#40290996">prev</a><span>|</span><a href="#40291422">next</a><span>|</span><label class="collapse" for="c-40294618">[-]</label><label class="expand" for="c-40294618">[1 more]</label></div><br/><div class="children"><div class="content">A lot of websites (like online shopping ) won&#x27;t let you scrape for long unless you are logged in. Some (like real estate sites) won&#x27;t tolerate you for long even if you are logged in. Some (like newspapers) won&#x27;t accept a simple request, they will try to detect browser and user behavior. Some will even detect data center ip blocks to get rid of you.<p>I don&#x27;t believe scraping is such a solved problem that you can slap AI and some cute vector spiders on it and claim  that everything works.</div><br/></div></div><div id="40291422" class="c"><input type="checkbox" id="c-40291422" checked=""/><div class="controls bullet"><span class="by">ushakov</span><span>|</span><a href="#40294618">prev</a><span>|</span><a href="#40292200">next</a><span>|</span><label class="collapse" for="c-40291422">[-]</label><label class="expand" for="c-40291422">[3 more]</label></div><br/><div class="children"><div class="content">There’s also llm-scraper in TypeScript<p><a href="https:&#x2F;&#x2F;github.com&#x2F;mishushakov&#x2F;llm-scraper">https:&#x2F;&#x2F;github.com&#x2F;mishushakov&#x2F;llm-scraper</a></div><br/><div id="40291461" class="c"><input type="checkbox" id="c-40291461" checked=""/><div class="controls bullet"><span class="by">lucgagan</span><span>|</span><a href="#40291422">parent</a><span>|</span><a href="#40292200">next</a><span>|</span><label class="collapse" for="c-40291461">[-]</label><label class="expand" for="c-40291461">[2 more]</label></div><br/><div class="children"><div class="content">Something similar I worked on in the past <a href="https:&#x2F;&#x2F;github.com&#x2F;lucgagan&#x2F;auto-playwright&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;lucgagan&#x2F;auto-playwright&#x2F;</a></div><br/><div id="40292369" class="c"><input type="checkbox" id="c-40292369" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#40291422">root</a><span>|</span><a href="#40291461">parent</a><span>|</span><a href="#40292200">next</a><span>|</span><label class="collapse" for="c-40292369">[-]</label><label class="expand" for="c-40292369">[1 more]</label></div><br/><div class="children"><div class="content">Does it use ChatGPT every time you run the test or only when a test fails (to check if the selector has changed)?</div><br/></div></div></div></div></div></div><div id="40292200" class="c"><input type="checkbox" id="c-40292200" checked=""/><div class="controls bullet"><span class="by">spaniard89277</span><span>|</span><a href="#40291422">prev</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292200">[-]</label><label class="expand" for="c-40292200">[13 more]</label></div><br/><div class="children"><div class="content">This is completely unrealistic unless you want to burn money.</div><br/><div id="40292942" class="c"><input type="checkbox" id="c-40292942" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#40292200">parent</a><span>|</span><a href="#40292263">next</a><span>|</span><label class="collapse" for="c-40292942">[-]</label><label class="expand" for="c-40292942">[1 more]</label></div><br/><div class="children"><div class="content">In practice it&#x27;s actually very good for lower volume tasks with non-fixed sources.<p>I haven&#x27;t tried this library but I do use an LLM based scraper in addition to more traditional ones.</div><br/></div></div><div id="40292263" class="c"><input type="checkbox" id="c-40292263" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#40292200">parent</a><span>|</span><a href="#40292942">prev</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292263">[-]</label><label class="expand" for="c-40292263">[11 more]</label></div><br/><div class="children"><div class="content">I have not used this specific library but its far from unrealistic and hardly a money pit. A LLM can fit in nicely with scraping libraries. Sure if you are crawling the web like google, it makes no sense, but if you have a hit list, this can be a cost effective way to not have engineering hours spent maintaining the crawler.</div><br/><div id="40292428" class="c"><input type="checkbox" id="c-40292428" checked=""/><div class="controls bullet"><span class="by">spaniard89277</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292263">parent</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292428">[-]</label><label class="expand" for="c-40292428">[10 more]</label></div><br/><div class="children"><div class="content">Which LLM do you use? Because I can&#x27;t see an scraper running daily without being very expensive.</div><br/><div id="40292516" class="c"><input type="checkbox" id="c-40292516" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292428">parent</a><span>|</span><a href="#40292821">next</a><span>|</span><label class="collapse" for="c-40292516">[-]</label><label class="expand" for="c-40292516">[3 more]</label></div><br/><div class="children"><div class="content">Llama-3 70B on my local MacBook works wonderfully for these tasks.</div><br/><div id="40292819" class="c"><input type="checkbox" id="c-40292819" checked=""/><div class="controls bullet"><span class="by">spaniard89277</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292516">parent</a><span>|</span><a href="#40292821">next</a><span>|</span><label class="collapse" for="c-40292819">[-]</label><label class="expand" for="c-40292819">[2 more]</label></div><br/><div class="children"><div class="content">How&#x27;s the Pipeline? Do you pass all the html to the LLM? Isn&#x27;t the context window a problem?</div><br/><div id="40293417" class="c"><input type="checkbox" id="c-40293417" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292819">parent</a><span>|</span><a href="#40292821">next</a><span>|</span><label class="collapse" for="c-40293417">[-]</label><label class="expand" for="c-40293417">[1 more]</label></div><br/><div class="children"><div class="content">There are phenomenal web scraping tools to crudely &quot;preprocess&quot; the document a bit, slashing outer HTML fluff while preserving the small subset of actual data. From there, 8k tokens (or whatever) goes <i>really</i> far.</div><br/></div></div></div></div></div></div><div id="40292821" class="c"><input type="checkbox" id="c-40292821" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292428">parent</a><span>|</span><a href="#40292516">prev</a><span>|</span><a href="#40292487">next</a><span>|</span><label class="collapse" for="c-40292821">[-]</label><label class="expand" for="c-40292821">[1 more]</label></div><br/><div class="children"><div class="content">Again, depends on the volume of the scraping and the value of the data within it. Even 3.5 can be cost effective for certain workflows and data value.</div><br/></div></div><div id="40292487" class="c"><input type="checkbox" id="c-40292487" checked=""/><div class="controls bullet"><span class="by">mrbungie</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292428">parent</a><span>|</span><a href="#40292821">prev</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292487">[-]</label><label class="expand" for="c-40292487">[5 more]</label></div><br/><div class="children"><div class="content">GPT-3.5&#x2F;GPT-4 ain&#x27;t the only LLMs available. A Flan-T5&#x2F;T5 or Llama2&#x2F;3 8B models may be finetuning for this use case and used for much cheaper.</div><br/><div id="40292808" class="c"><input type="checkbox" id="c-40292808" checked=""/><div class="controls bullet"><span class="by">spaniard89277</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292487">parent</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292808">[-]</label><label class="expand" for="c-40292808">[4 more]</label></div><br/><div class="children"><div class="content">How do you handle the context window limit? If you push the entire Dom to the LLM it will exceed the context window by far in most cases, isn&#x27;t it?</div><br/><div id="40292959" class="c"><input type="checkbox" id="c-40292959" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292808">parent</a><span>|</span><a href="#40292907">next</a><span>|</span><label class="collapse" for="c-40292959">[-]</label><label class="expand" for="c-40292959">[1 more]</label></div><br/><div class="children"><div class="content">Trim unwanted html elements + convert to markdown. Significantly reduces token counts while retaining structure.</div><br/></div></div><div id="40292907" class="c"><input type="checkbox" id="c-40292907" checked=""/><div class="controls bullet"><span class="by">aleksiy123</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292808">parent</a><span>|</span><a href="#40292959">prev</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40292907">[-]</label><label class="expand" for="c-40292907">[2 more]</label></div><br/><div class="children"><div class="content">My guess is you do some preprocessing on the DOM to get it down to text but still retains some structure.<p>Something like <a href="https:&#x2F;&#x2F;github.com&#x2F;Alir3z4&#x2F;html2text">https:&#x2F;&#x2F;github.com&#x2F;Alir3z4&#x2F;html2text</a>.<p>I&#x27;m sure there are other (better?) options as well.</div><br/><div id="40295212" class="c"><input type="checkbox" id="c-40295212" checked=""/><div class="controls bullet"><span class="by">tarasglek</span><span>|</span><a href="#40292200">root</a><span>|</span><a href="#40292907">parent</a><span>|</span><a href="#40290920">next</a><span>|</span><label class="collapse" for="c-40295212">[-]</label><label class="expand" for="c-40295212">[1 more]</label></div><br/><div class="children"><div class="content">I wrote <a href="https:&#x2F;&#x2F;markdown.download" rel="nofollow">https:&#x2F;&#x2F;markdown.download</a> as a general helper for this</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>