<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1691658067940" as="style"/><link rel="stylesheet" href="styles.css?v=1691658067940"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/zknill/sqledge">SQLedge: Replicate Postgres to SQLite on the Edge</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>clessg</span> | <span>66 comments</span></div><br/><div><div id="37063653" class="c"><input type="checkbox" id="c-37063653" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37073287">next</a><span>|</span><label class="collapse" for="c-37063653">[-]</label><label class="expand" for="c-37063653">[23 more]</label></div><br/><div class="children"><div class="content">Following the PostgreSQL logical replication stream to update a local SQLite database copy is definitely a neat trick, and feels very safe to me (especially since you track the Log Sequence Number in a postgres_pos table).<p>The bit that surprised me was that this thing supports writes as well!<p>It does it by acting as a PostgreSQL proxy. You connect to that proxy with a regular PostgreSQL client, then any read queries you issue run against the local SQLite copy and any writes are forwarded on to &quot;real&quot; PostgreSQL.<p>The downside is that now your SELECT statements all need to be in the subset of SQL that is supported by both SQLite and PostgreSQL. This can be pretty limiting, mainly because PostgreSQL SQL is a much, much richer dialect than SQLite.<p>Should work fine for basic SELECT queries though.<p>I&#x27;d find this project useful even without the PostgreSQL connection&#x2F;write support though.<p>I worked with a very high-scale feature flag system a while ago - thousands of flag checks a second. This scaled using a local memcached cache of checks on each machine, despite the check logic itself consulting a MySQL database.<p>I had an idea to improve that system by running a local SQLite cache of the full flag logic on every frontend machine instead. That way flag checks could use full SQL logic, but would still run incredibly fast.<p>The challenge would be keeping that local SQLite database copy synced with the centralized source-of-truth database. A system like SQLedge could make short work of that problem.</div><br/><div id="37070255" class="c"><input type="checkbox" id="c-37070255" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37069343">next</a><span>|</span><label class="collapse" for="c-37070255">[-]</label><label class="expand" for="c-37070255">[1 more]</label></div><br/><div class="children"><div class="content">A simple version of this is to do a very cheap SELECT * [where tenant = ...] of your feature flag table(s) to a dictionary structure in memory on every single edge&#x2F;application server, and do this atomically every few seconds or minutes.<p>Statsig [0] and Transifex [1] both use this pattern to great effect, transmitting not only data but logic on permissions and liveness, and you can roll your own versions of all this for your own domain models.<p>I&#x27;m of the opinion that every agile project should start with a system like this; it opens up entirely new avenues of real-time configuration deployment to satisfy in-the-moment business&#x2F;editorial needs, while providing breathing room to the development team to ensure codebase stability.<p>(As long as all you need is eventual consistency, of course, and are fine with these structures changing in the midst of a request or long-running operation, and are fine with not being able to read your writes if you ever change these values! If any of that sounds necessary, you&#x27;ll need some notion of distributed consensus.)<p>[0] <a href="https:&#x2F;&#x2F;docs.statsig.com&#x2F;server&#x2F;introduction" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.statsig.com&#x2F;server&#x2F;introduction</a><p>[1] <a href="https:&#x2F;&#x2F;developers.transifex.com&#x2F;docs&#x2F;native" rel="nofollow noreferrer">https:&#x2F;&#x2F;developers.transifex.com&#x2F;docs&#x2F;native</a></div><br/></div></div><div id="37069343" class="c"><input type="checkbox" id="c-37069343" checked=""/><div class="controls bullet"><span class="by">Omnipresent</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37070255">prev</a><span>|</span><a href="#37064298">next</a><span>|</span><label class="collapse" for="c-37069343">[-]</label><label class="expand" for="c-37069343">[4 more]</label></div><br/><div class="children"><div class="content">Honest question: why is SQLLite needed for local? Why would you not have PG at edge that replicates data with central PG? That way the SQL dialect problem you mentioned wouldn&#x27;t exist.</div><br/><div id="37069615" class="c"><input type="checkbox" id="c-37069615" checked=""/><div class="controls bullet"><span class="by">joshuahaglund</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37069343">parent</a><span>|</span><a href="#37070431">next</a><span>|</span><label class="collapse" for="c-37069615">[-]</label><label class="expand" for="c-37069615">[1 more]</label></div><br/><div class="children"><div class="content">SQLite is much smaller and self-contained than postgres. It&#x27;s written in ANSI-C and by including one file you have access to a database (which is stored in another single file). It&#x27;s popular in embedded systems like, I imagine, edge devices</div><br/></div></div><div id="37070431" class="c"><input type="checkbox" id="c-37070431" checked=""/><div class="controls bullet"><span class="by">linsomniac</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37069343">parent</a><span>|</span><a href="#37069615">prev</a><span>|</span><a href="#37070666">next</a><span>|</span><label class="collapse" for="c-37070431">[-]</label><label class="expand" for="c-37070431">[1 more]</label></div><br/><div class="children"><div class="content">You know what&#x27;s faster than a local connection to Postgres?  Having the database engine directly embedded in your application.  No context switch.</div><br/></div></div><div id="37070666" class="c"><input type="checkbox" id="c-37070666" checked=""/><div class="controls bullet"><span class="by">yashap</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37069343">parent</a><span>|</span><a href="#37070431">prev</a><span>|</span><a href="#37064298">next</a><span>|</span><label class="collapse" for="c-37070666">[-]</label><label class="expand" for="c-37070666">[1 more]</label></div><br/><div class="children"><div class="content">That is a much safer way to go for most use cases. Well actually, most use cases don&#x27;t need edge compute at all, but for those that do, this setup is indeed common, and fine for most apps:<p>- Say we do edge compute in San Francisco, Montreal, London and Singapore<p>- Set up a PG master in one place (like San Francisco), and read replicas in every place (San Francisco, Montreal, London and Singapore)<p>- Have your app query the read replica when possible, only going to the master for writes<p>In rare cases, maybe any network latency is not OK, you really need an embedded DB for ultimate read performance - then this is pretty interesting. But a backend server truly needing an embedded DB is certainly a rare case. I would imagine this approach would come with some very major downsides, like having to replicate the entire DB to each app instance, as well as the inherent complexity&#x2F;sketchiness of this setup, when you generally want your DB layer to be rock solid.<p>This is probably upvoted so high on HN because it&#x27;s pretty cool&#x2F;wild, and HN loves SQLite, vs. it being something many ppl should use.</div><br/></div></div></div></div><div id="37064298" class="c"><input type="checkbox" id="c-37064298" checked=""/><div class="controls bullet"><span class="by">DaiPlusPlus</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37069343">prev</a><span>|</span><a href="#37066924">next</a><span>|</span><label class="collapse" for="c-37064298">[-]</label><label class="expand" for="c-37064298">[12 more]</label></div><br/><div class="children"><div class="content">&gt; I worked with a very high-scale feature flag system a while ago - thousands of flag checks a second.<p>May I ask why the flags are checked that frequently? Couldn&#x27;t they be cached for at least a minute?<p>&gt; It does it by acting as a PostgreSQL proxy. [...] and any writes are forwarded on to &quot;real&quot; PostgreSQL.<p>What happens if there&#x27;s a multi-statement transaction with a bunch of writes sent-off to the mothership - which then get returned to the client via logical replication, but <i>then</i> there&#x27;s a ROLLBACK - how would that situation be handled such that both the SQLite edge DBs and the mothership DB are able to rollback okay - would this impact other clients?</div><br/><div id="37066036" class="c"><input type="checkbox" id="c-37066036" checked=""/><div class="controls bullet"><span class="by">rockostrich</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37064382">next</a><span>|</span><label class="collapse" for="c-37066036">[-]</label><label class="expand" for="c-37066036">[1 more]</label></div><br/><div class="children"><div class="content">Feature flag systems are usually based on a set of rules that could be serialized and evaluated locally (this is how pretty much every open source feature flag system and feature flag SaaS works). Usually it&#x27;s based on some kind of UUID being hashed with a per-flag seed and bucketed after some set of targeting rules are applied to other properties passed in for that user. There are added features where you can stores large cohorts to do specific targeting and usually there&#x27;s some kind of local cache added to make that look-up faster for recent users.<p>I&#x27;m not sure what the original commenter was doing but it sounds like they had some kind of targeting that was almost entirely based on cohorts or maybe they needed to have stability over time which would require a database. We did something similar recently except we just store a &quot;session ID&quot; with a blob for look-up and the evaluation only happens on the first request for a given session ID.</div><br/></div></div><div id="37064382" class="c"><input type="checkbox" id="c-37064382" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37066036">prev</a><span>|</span><a href="#37064436">next</a><span>|</span><label class="collapse" for="c-37064382">[-]</label><label class="expand" for="c-37064382">[2 more]</label></div><br/><div class="children"><div class="content">&gt; May I ask why the flags are checked that frequently? Couldn&#x27;t they be cached for at least a minute?<p>Not in that project but feature flags don&#x27;t have to be all or nothing. You can apply flags to specific cohorts of your users for example, so if you have a large user base, even if you cache them per-user, it still translates into many checks a second for large systems.</div><br/><div id="37065935" class="c"><input type="checkbox" id="c-37065935" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064382">parent</a><span>|</span><a href="#37064436">next</a><span>|</span><label class="collapse" for="c-37065935">[-]</label><label class="expand" for="c-37065935">[1 more]</label></div><br/><div class="children"><div class="content">I guess the cost of doing it precisely isn&#x27;t terribly high, but if the majority of the flags were &quot;off&quot; (eg, subsets of users being opted into a beta or something), I wonder if you cut a bunch of the queries by sending down a bloom filter.<p>So basically you check the filter first, and if that says the feature is enabled, only then do you actually ask the real DB.</div><br/></div></div></div></div><div id="37064436" class="c"><input type="checkbox" id="c-37064436" checked=""/><div class="controls bullet"><span class="by">jmull</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37064382">prev</a><span>|</span><a href="#37066138">next</a><span>|</span><label class="collapse" for="c-37064436">[-]</label><label class="expand" for="c-37064436">[1 more]</label></div><br/><div class="children"><div class="content">&gt; May I ask why the flags are checked that frequently? Couldn&#x27;t they be cached for at least a minute?<p>Not the previous poster, but it appears in the scenario, the SQLite database <i>is</i> the cache.</div><br/></div></div><div id="37066138" class="c"><input type="checkbox" id="c-37066138" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37064436">prev</a><span>|</span><a href="#37064424">next</a><span>|</span><label class="collapse" for="c-37066138">[-]</label><label class="expand" for="c-37066138">[1 more]</label></div><br/><div class="children"><div class="content">They were being cached for at least a minute (maybe even more than that, I can&#x27;t remember the details) - that&#x27;s what the local memcached instance was for.<p>This was problematic though because changing a feature flag and then waiting for a minute plus to see if the change actually worked can be frustrating, especially if it relates to an outage of some sort.</div><br/></div></div><div id="37064424" class="c"><input type="checkbox" id="c-37064424" checked=""/><div class="controls bullet"><span class="by">zknill</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37066138">prev</a><span>|</span><a href="#37064421">next</a><span>|</span><label class="collapse" for="c-37064424">[-]</label><label class="expand" for="c-37064424">[4 more]</label></div><br/><div class="children"><div class="content">The logical replication protocol sends a series of messages that essentially follow the flow that a database transaction would.<p>i.e. a stream of messages like: &quot;BEGIN&quot;, &quot;[the data]&quot;, [&quot;COMMIT&quot; or &quot;ROLLBACK&quot;].<p>So any application that listens to the Postgres replication protocol can handle the transaction in the same way that Postgres does. Concretely you might choose to open a SQLite transaction on BEGIN, apply the statements, and then COMMIT or ROLLBACK based on the next messages received on the stream replication protocol.<p>The data sent on the replication protocol includes the state of the row after the write query has completed. This means you don&#x27;t need to worry about getting out of sync on queries like &quot;UPDATE field = field + 1&quot; because you have access to the exact resulting value as stored by Postgres.<p>TL;DR - you can follow the same begin&#x2F;change&#x2F;commit flow that the original transaction did on the upstream Postgres server, and you have access to the exact underlying data after the write was committed.<p>It&#x27;s also true (as other commenters have pointed out) that for not-huge transactions (i.e. not streaming transactions, new feature in Postgres 15) the BEGIN message will only be sent if the transaction was committed. It&#x27;s pretty unlikely that you will ever process a ROLLBACK message from the protocol (although possible).</div><br/><div id="37065577" class="c"><input type="checkbox" id="c-37065577" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064424">parent</a><span>|</span><a href="#37064774">next</a><span>|</span><label class="collapse" for="c-37065577">[-]</label><label class="expand" for="c-37065577">[2 more]</label></div><br/><div class="children"><div class="content">Logical replication never includes uncommitted data, unless you have written an custom output plugin.<p>EDIT: <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;52202534&#x2F;postgresql-does-logical-replication-include-rollback-transaction" rel="nofollow noreferrer">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;52202534&#x2F;postgresql-does...</a></div><br/><div id="37065970" class="c"><input type="checkbox" id="c-37065970" checked=""/><div class="controls bullet"><span class="by">zknill</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37065577">parent</a><span>|</span><a href="#37064774">next</a><span>|</span><label class="collapse" for="c-37065970">[-]</label><label class="expand" for="c-37065970">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s true for protocol version 1 that only the committed data is sent on the replication connection.<p>In protocol version 2 (introduced in postgres 14) large in-progress transactions can appear in the new &quot;Stream&quot; messages sent on the replication connection: StreamStart, StreamStop, StreamAbort, StreamCommit, etc. In the case of large in-progress transactions uncommitted data might end up in the replication connection after a StreamStart message. But you would also receive a StreamCommit or StreamAbort message to tell you what happened to that transaction.<p>I&#x27;ve not worked out what qualifies as a &quot;large&quot; transaction though. But it is _possible_ to get uncommitted data in the replication connection, although unlikely.<p><a href="https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;15&#x2F;protocol-logicalrep-message-formats.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;15&#x2F;protocol-logicalrep-messa...</a></div><br/></div></div></div></div></div></div><div id="37064421" class="c"><input type="checkbox" id="c-37064421" checked=""/><div class="controls bullet"><span class="by">runeks</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37064424">prev</a><span>|</span><a href="#37065528">next</a><span>|</span><label class="collapse" for="c-37064421">[-]</label><label class="expand" for="c-37064421">[1 more]</label></div><br/><div class="children"><div class="content">My limited understanding of logical replication is that writes only happen at COMMIT. Ie. nothing is replicated until it&#x27;s committed.</div><br/></div></div><div id="37065528" class="c"><input type="checkbox" id="c-37065528" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#37063653">root</a><span>|</span><a href="#37064298">parent</a><span>|</span><a href="#37064421">prev</a><span>|</span><a href="#37066924">next</a><span>|</span><label class="collapse" for="c-37065528">[-]</label><label class="expand" for="c-37065528">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Couldn&#x27;t they be cached for at least a minute?<p>Only per feature+per user. (Though 1000s per second does seem high unless your scale is gigantic.)<p>&gt; What happens if there&#x27;s a multi-statement transaction with a bunch of writes sent-off to the mothership - which then get returned to the client via logical replication, but then there&#x27;s a ROLLBACK<p>Nothing makes it into the replication stream until it is committed.</div><br/></div></div></div></div><div id="37066924" class="c"><input type="checkbox" id="c-37066924" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37064298">prev</a><span>|</span><a href="#37070764">next</a><span>|</span><label class="collapse" for="c-37066924">[-]</label><label class="expand" for="c-37066924">[1 more]</label></div><br/><div class="children"><div class="content">Does it though? If itâs a proxy it can support the SQLite read and the Postgres write syntax. If reads only ever go to SQLite they donât need to work on Postgres.</div><br/></div></div><div id="37070764" class="c"><input type="checkbox" id="c-37070764" checked=""/><div class="controls bullet"><span class="by">seedless-sensat</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37066924">prev</a><span>|</span><a href="#37066124">next</a><span>|</span><label class="collapse" for="c-37070764">[-]</label><label class="expand" for="c-37070764">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s nice to see another pg proxy using the pgx parser (their src[1]) - I built one using this lib too. However, this implementation is missing a lot of low level features to be considered close to compatible, including: multi-query transactions, auth, TLS, extended query mode, query cancellation.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;zknill&#x2F;sqledge&#x2F;blob&#x2F;main&#x2F;pkg&#x2F;pgwire&#x2F;postgres.go">https:&#x2F;&#x2F;github.com&#x2F;zknill&#x2F;sqledge&#x2F;blob&#x2F;main&#x2F;pkg&#x2F;pgwire&#x2F;postg...</a></div><br/></div></div><div id="37066124" class="c"><input type="checkbox" id="c-37066124" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37070764">prev</a><span>|</span><a href="#37070794">next</a><span>|</span><label class="collapse" for="c-37066124">[-]</label><label class="expand" for="c-37066124">[1 more]</label></div><br/><div class="children"><div class="content">How many flags are we talking here? I implemted a similar system and we just replace the whole sqlite DB file by downloading it from the centralized storage whenever it changes.<p>Even with 1M flags it&#x27;s still only a few 100 kB compressed.<p>I wouldn&#x27;t replicate per user flags to the edge to keep size under control.</div><br/></div></div><div id="37070794" class="c"><input type="checkbox" id="c-37070794" checked=""/><div class="controls bullet"><span class="by">yashap</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37066124">prev</a><span>|</span><a href="#37064214">next</a><span>|</span><label class="collapse" for="c-37070794">[-]</label><label class="expand" for="c-37070794">[1 more]</label></div><br/><div class="children"><div class="content">I wonder, how does this handle a single transaction that contains both reads and writes? Maybe it just says &quot;within a transaction, all reads and writes go through the Postgres proxy, SQLite is ignored&quot;?</div><br/></div></div><div id="37064214" class="c"><input type="checkbox" id="c-37064214" checked=""/><div class="controls bullet"><span class="by">ericraio</span><span>|</span><a href="#37063653">parent</a><span>|</span><a href="#37070794">prev</a><span>|</span><a href="#37073287">next</a><span>|</span><label class="collapse" for="c-37064214">[-]</label><label class="expand" for="c-37064214">[1 more]</label></div><br/><div class="children"><div class="content">One use case I can see this being valuable for is for a client based application and Postgres being a centralized database. The client would just query SQLite and not need to write Postgres SQL.</div><br/></div></div></div></div><div id="37073287" class="c"><input type="checkbox" id="c-37073287" checked=""/><div class="controls bullet"><span class="by">igammarays</span><span>|</span><a href="#37063653">prev</a><span>|</span><a href="#37064419">next</a><span>|</span><label class="collapse" for="c-37073287">[-]</label><label class="expand" for="c-37073287">[1 more]</label></div><br/><div class="children"><div class="content">Iâve been thinking a lot about this problem of distributed databases, and so far the easiest and most innovative solution Iâve seen is PolyScale[1], basically a CDN cache at the SQL layer with smart automatic invalidation. I just donât want to deal with the hairiness of logical replication and now sqlite&lt;&gt;postgres incompatibility.<p>[1] Not associated with PolyScale in any way, just an interested potential customer.</div><br/></div></div><div id="37064419" class="c"><input type="checkbox" id="c-37064419" checked=""/><div class="controls bullet"><span class="by">durkie</span><span>|</span><a href="#37073287">prev</a><span>|</span><a href="#37063455">next</a><span>|</span><label class="collapse" for="c-37064419">[-]</label><label class="expand" for="c-37064419">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m super excited for this -- it seems like it&#x27;s perfect as an app-local cache of things that can be a drop-in replacement for some high-cost queries.<p>Are there any plans to support which tables get copied over? The main postgres database is too big to replicate everywhere, but some key &quot;summary&quot; tables would be really nice to have locally.</div><br/></div></div><div id="37063455" class="c"><input type="checkbox" id="c-37063455" checked=""/><div class="controls bullet"><span class="by">maxfurman</span><span>|</span><a href="#37064419">prev</a><span>|</span><a href="#37064369">next</a><span>|</span><label class="collapse" for="c-37063455">[-]</label><label class="expand" for="c-37063455">[3 more]</label></div><br/><div class="children"><div class="content">This is pretty neat! One question, if all your queries have to be SQLite-compatible, doesn&#x27;t that defeat the purpose of using PG in the first place? Maybe SQLite supports more PG features than I thought, but if for example your app uses pgvector or pgcrypto you might have issues here.</div><br/><div id="37063559" class="c"><input type="checkbox" id="c-37063559" checked=""/><div class="controls bullet"><span class="by">zknill</span><span>|</span><a href="#37063455">parent</a><span>|</span><a href="#37070133">next</a><span>|</span><label class="collapse" for="c-37063559">[-]</label><label class="expand" for="c-37063559">[1 more]</label></div><br/><div class="children"><div class="content">Yes, absolutely, and this is going to be one of the hardest tech challenges to solve. I&#x27;ve thought a little about it, and it&#x27;s probably unrealistic to think that we can translate every single PG statement into a SQLite one, especially when PG has extensions. So we&#x27;re probably destined to use the local SQLite database for queries we can parse and understand, and forwarding all the others (both reads and writes) to the upstream PG server.<p>This slightly breaks model of having a local copy serve data faster, but if only the minority of queries use a format that we don&#x27;t understand in SQLite then only that minority of queries will suffer from the full latency to the main PG server.</div><br/></div></div><div id="37070133" class="c"><input type="checkbox" id="c-37070133" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#37063455">parent</a><span>|</span><a href="#37063559">prev</a><span>|</span><a href="#37064369">next</a><span>|</span><label class="collapse" for="c-37070133">[-]</label><label class="expand" for="c-37070133">[1 more]</label></div><br/><div class="children"><div class="content">&gt; doesn&#x27;t that defeat the purpose of using PG in the first place<p>PG can scale higher than SQLite, especially considering concurrent writers. So even without the PG syntax and extensions, it&#x27;s still useful. Also, maybe you can use PG syntax for complex INSERT (SELECT)s?</div><br/></div></div></div></div><div id="37064369" class="c"><input type="checkbox" id="c-37064369" checked=""/><div class="controls bullet"><span class="by">kiitos</span><span>|</span><a href="#37063455">prev</a><span>|</span><a href="#37069625">next</a><span>|</span><label class="collapse" for="c-37064369">[-]</label><label class="expand" for="c-37064369">[1 more]</label></div><br/><div class="children"><div class="content">And how do you manage conflicts?<p><i>edit</i><p>&gt; The writes via SQLedge are sync, that is we wait for the write to be processed on the upstream Postgres server<p>OK, so, it&#x27;s a SQLite read replica of a Postgres primary DB.<p>Of course, this does mean that it&#x27;s possible for clients to fail the read-your-writes consistency check.</div><br/></div></div><div id="37069625" class="c"><input type="checkbox" id="c-37069625" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#37064369">prev</a><span>|</span><a href="#37072129">next</a><span>|</span><label class="collapse" for="c-37069625">[-]</label><label class="expand" for="c-37069625">[2 more]</label></div><br/><div class="children"><div class="content">How &quot;edgy&quot; can real PostgreSQL be?  Seems to me that this is all in lieu of using real PostgreSQL replication, on the basis that real Postgres is too heavy &#x2F; complex to run on the edge. Can a true PostgreSQL replica be configured in a light weight way to serve a similar purpose?</div><br/><div id="37070147" class="c"><input type="checkbox" id="c-37070147" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#37069625">parent</a><span>|</span><a href="#37072129">next</a><span>|</span><label class="collapse" for="c-37070147">[-]</label><label class="expand" for="c-37070147">[1 more]</label></div><br/><div class="children"><div class="content">I have the same question. There have been demos of local Postgres-on-web using wasm, which would not solve this issue (browser is way heavier than SQLite), but maybe it demonstrates how portable Postgres can be with some effort.</div><br/></div></div></div></div><div id="37072129" class="c"><input type="checkbox" id="c-37072129" checked=""/><div class="controls bullet"><span class="by">jonhohle</span><span>|</span><a href="#37069625">prev</a><span>|</span><a href="#37064423">next</a><span>|</span><label class="collapse" for="c-37072129">[-]</label><label class="expand" for="c-37072129">[1 more]</label></div><br/><div class="children"><div class="content">Somewhat orthogonal, but I was just thinking of looking for or writing a MySQL compatible  frontend for SQLite. Thereâs a third party app that has removed SQLite support in its latest version and I really donât want a MySQL database for something SQLite is more than capable of for my use case.</div><br/></div></div><div id="37064423" class="c"><input type="checkbox" id="c-37064423" checked=""/><div class="controls bullet"><span class="by">rbranson</span><span>|</span><a href="#37072129">prev</a><span>|</span><a href="#37068476">next</a><span>|</span><label class="collapse" for="c-37064423">[-]</label><label class="expand" for="c-37064423">[3 more]</label></div><br/><div class="children"><div class="content">We replicated our MySQL database to a SQLite edge at Segment in ctlstore: <a href="https:&#x2F;&#x2F;github.com&#x2F;segmentio&#x2F;ctlstore">https:&#x2F;&#x2F;github.com&#x2F;segmentio&#x2F;ctlstore</a><p>We considered tailing binlogs directly but there&#x27;s so much cruft and complexity involved trying to translate between types and such at that end, once you even just get passed properly parsing the binlogs and maintaining the replication connection. Then you have to deal with schema management across both systems too. Similar sets of problems using PostgreSQL as a source of truth.<p>In the end we decided just to wrap the whole thing up and abstract away the schema with a common set of types and a limited set of read APIs. Biggest missing piece I regret not getting in was support for secondary indexes.</div><br/><div id="37064466" class="c"><input type="checkbox" id="c-37064466" checked=""/><div class="controls bullet"><span class="by">eddd-ddde</span><span>|</span><a href="#37064423">parent</a><span>|</span><a href="#37068476">next</a><span>|</span><label class="collapse" for="c-37064466">[-]</label><label class="expand" for="c-37064466">[2 more]</label></div><br/><div class="children"><div class="content">Is there a reason you didn&#x27;t add them when making the shared API?</div><br/><div id="37064490" class="c"><input type="checkbox" id="c-37064490" checked=""/><div class="controls bullet"><span class="by">rbranson</span><span>|</span><a href="#37064423">root</a><span>|</span><a href="#37064466">parent</a><span>|</span><a href="#37068476">next</a><span>|</span><label class="collapse" for="c-37064490">[-]</label><label class="expand" for="c-37064490">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re asking about secondary indexes, it was just seen as a &quot;later&quot; feature we&#x27;d implement as a follow-up. It was definitely asked for, just never prioritized before I moved off the project.</div><br/></div></div></div></div></div></div><div id="37068476" class="c"><input type="checkbox" id="c-37068476" checked=""/><div class="controls bullet"><span class="by">singingwolfboy</span><span>|</span><a href="#37064423">prev</a><span>|</span><a href="#37064879">next</a><span>|</span><label class="collapse" for="c-37068476">[-]</label><label class="expand" for="c-37068476">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know of a tool that will export a Postgres database to a SQLite database file? Seems like a handy way of exporting and passing around smallish DBs. I feel like this tool must exist, but I havenât found it yet. (Supporting imports and data transformations would be even better!)</div><br/><div id="37069073" class="c"><input type="checkbox" id="c-37069073" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37068476">parent</a><span>|</span><a href="#37064879">next</a><span>|</span><label class="collapse" for="c-37069073">[-]</label><label class="expand" for="c-37069073">[1 more]</label></div><br/><div class="children"><div class="content">I wrote a tool to do that: <a href="https:&#x2F;&#x2F;datasette.io&#x2F;tools&#x2F;db-to-sqlite" rel="nofollow noreferrer">https:&#x2F;&#x2F;datasette.io&#x2F;tools&#x2F;db-to-sqlite</a><p>You can see an example of it in use here: <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;simonwillisonblog-backup&#x2F;blob&#x2F;main&#x2F;.github&#x2F;workflows&#x2F;backup.yml">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;simonwillisonblog-backup&#x2F;blob&#x2F;main...</a></div><br/></div></div></div></div><div id="37064879" class="c"><input type="checkbox" id="c-37064879" checked=""/><div class="controls bullet"><span class="by">sgt</span><span>|</span><a href="#37068476">prev</a><span>|</span><a href="#37064792">next</a><span>|</span><label class="collapse" for="c-37064879">[-]</label><label class="expand" for="c-37064879">[2 more]</label></div><br/><div class="children"><div class="content">A commercial offering (although also open source): <a href="https:&#x2F;&#x2F;www.powersync.co&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.powersync.co&#x2F;</a></div><br/></div></div><div id="37064792" class="c"><input type="checkbox" id="c-37064792" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#37064879">prev</a><span>|</span><a href="#37070105">next</a><span>|</span><label class="collapse" for="c-37064792">[-]</label><label class="expand" for="c-37064792">[4 more]</label></div><br/><div class="children"><div class="content">Why SQLite instead of a standard hub and spoke replication? What benefit does this provide? Being able to run your database on the client? That seems like it would be risky</div><br/><div id="37066954" class="c"><input type="checkbox" id="c-37066954" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#37064792">parent</a><span>|</span><a href="#37070105">next</a><span>|</span><label class="collapse" for="c-37066954">[-]</label><label class="expand" for="c-37066954">[3 more]</label></div><br/><div class="children"><div class="content">Because itâs running in the appâs address space, SQLite is obscenely fast for reads, so much so that you can often just write N+1 queries with it.</div><br/><div id="37067612" class="c"><input type="checkbox" id="c-37067612" checked=""/><div class="controls bullet"><span class="by">hamandcheese</span><span>|</span><a href="#37064792">root</a><span>|</span><a href="#37066954">parent</a><span>|</span><a href="#37070105">next</a><span>|</span><label class="collapse" for="c-37067612">[-]</label><label class="expand" for="c-37067612">[2 more]</label></div><br/><div class="children"><div class="content">In this case though it appears that SQLEdge is running as its own process, distinct from the app, and the app sends all queries to the SQLEdge proxy.</div><br/><div id="37068734" class="c"><input type="checkbox" id="c-37068734" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#37064792">root</a><span>|</span><a href="#37067612">parent</a><span>|</span><a href="#37070105">next</a><span>|</span><label class="collapse" for="c-37068734">[-]</label><label class="expand" for="c-37068734">[1 more]</label></div><br/><div class="children"><div class="content">That makes less sense to me then, though the IPC cost for those reads is still much lower than a typical n-tier Postgres setup.</div><br/></div></div></div></div></div></div></div></div><div id="37070105" class="c"><input type="checkbox" id="c-37070105" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#37064792">prev</a><span>|</span><a href="#37063599">next</a><span>|</span><label class="collapse" for="c-37070105">[-]</label><label class="expand" for="c-37070105">[1 more]</label></div><br/><div class="children"><div class="content">Very cool. I&#x27;ve always found it hard to write any slightly complex SQL (i.e. not just a simple join) in a way that&#x27;s fast on multiple DBMSes. Even if both support the same syntax you need, subtle things can affect the performance a lot. But there are probably use cases where this isn&#x27;t an issue and you care a lot more about using something compatible with limited edge devices, like SQLite.</div><br/></div></div><div id="37063599" class="c"><input type="checkbox" id="c-37063599" checked=""/><div class="controls bullet"><span class="by">luckystarr</span><span>|</span><a href="#37070105">prev</a><span>|</span><a href="#37066284">next</a><span>|</span><label class="collapse" for="c-37063599">[-]</label><label class="expand" for="c-37063599">[5 more]</label></div><br/><div class="children"><div class="content">How would mutually incompatible upstream changes from multiple SQLite edge instances be resolved? You&#x27;d need user input for that, right?</div><br/><div id="37063705" class="c"><input type="checkbox" id="c-37063705" checked=""/><div class="controls bullet"><span class="by">zknill</span><span>|</span><a href="#37063599">parent</a><span>|</span><a href="#37063669">next</a><span>|</span><label class="collapse" for="c-37063705">[-]</label><label class="expand" for="c-37063705">[2 more]</label></div><br/><div class="children"><div class="content">The writes via SQLedge are sync, that is we wait for the write to be processed on the upstream Postgres server. So it operates as if SQLedge wasn&#x27;t in the request path from application to Postgres. The writes to Postgres are only reflected in SQLite when the data is received back from the Postgres server on the replication slot.<p>This means writes are eventually consistent, currently, but I intend to include a feature that allows waiting for that write to be reflected back in SQLite which would satisfy the &#x27;read your own writes&#x27; property.<p>SQLedge will never be in a situation where the SQLite database thinks it has a write, but that write is yet to be applied to the upstream Postgres server.<p>Basically, the Postgres server &#x27;owns&#x27; the writes, and can handle them just like it would if SQLedge didn&#x27;t exist.</div><br/><div id="37063785" class="c"><input type="checkbox" id="c-37063785" checked=""/><div class="controls bullet"><span class="by">luckystarr</span><span>|</span><a href="#37063599">root</a><span>|</span><a href="#37063705">parent</a><span>|</span><a href="#37063669">next</a><span>|</span><label class="collapse" for="c-37063785">[-]</label><label class="expand" for="c-37063785">[1 more]</label></div><br/><div class="children"><div class="content">So, the advertised performance is just for the read-part, not the write-part?<p>As far as I understand: writing would still exhibit the same characteristics as before, while reads would never be affected by other users.</div><br/></div></div></div></div><div id="37063669" class="c"><input type="checkbox" id="c-37063669" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37063599">parent</a><span>|</span><a href="#37063705">prev</a><span>|</span><a href="#37063666">next</a><span>|</span><label class="collapse" for="c-37063669">[-]</label><label class="expand" for="c-37063669">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s a problem here, because the write queries aren&#x27;t handled by the local SQLite databases - instead, the proxy forwards them directly to the PostgreSQL instance, so presumably the resulting changes show up in SQLite when they are replicated back down again.</div><br/></div></div><div id="37063666" class="c"><input type="checkbox" id="c-37063666" checked=""/><div class="controls bullet"><span class="by">zffr</span><span>|</span><a href="#37063599">parent</a><span>|</span><a href="#37063669">prev</a><span>|</span><a href="#37066284">next</a><span>|</span><label class="collapse" for="c-37063666">[-]</label><label class="expand" for="c-37063666">[1 more]</label></div><br/><div class="children"><div class="content">&gt; SQLedge serves reads from it&#x27;s local sqlite database, and forwards writes to the upstream postgres server that it&#x27;s replicating from.<p>I don&#x27;t think SQLite data is ever written back to the postgres DB so this shouldn&#x27;t be an issue</div><br/></div></div></div></div><div id="37066284" class="c"><input type="checkbox" id="c-37066284" checked=""/><div class="controls bullet"><span class="by">markhalonen</span><span>|</span><a href="#37063599">prev</a><span>|</span><a href="#37066008">next</a><span>|</span><label class="collapse" for="c-37066284">[-]</label><label class="expand" for="c-37066284">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;re currently grappling with trying to build a system similar to <a href="https:&#x2F;&#x2F;stripe.com&#x2F;sigma" rel="nofollow noreferrer">https:&#x2F;&#x2F;stripe.com&#x2F;sigma</a> with a single multi-tenant Postgres db as the source and an SQLite read replica per tenant. Currently we re-generate the world every night. We need fine-grained control over the SQLite schema (it&#x27;s a public api we let users write sql against). Any related projects would be great to point me towards!</div><br/><div id="37066935" class="c"><input type="checkbox" id="c-37066935" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#37066284">parent</a><span>|</span><a href="#37066812">next</a><span>|</span><label class="collapse" for="c-37066935">[-]</label><label class="expand" for="c-37066935">[1 more]</label></div><br/><div class="children"><div class="content">We need a standardized WAL format. Too many people trying to write software to simulate it.</div><br/></div></div></div></div><div id="37066008" class="c"><input type="checkbox" id="c-37066008" checked=""/><div class="controls bullet"><span class="by">maxpert</span><span>|</span><a href="#37066284">prev</a><span>|</span><a href="#37067596">next</a><span>|</span><label class="collapse" for="c-37066008">[-]</label><label class="expand" for="c-37066008">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting! I have question ( out of my experience in <a href="https:&#x2F;&#x2F;github.com&#x2F;maxpert&#x2F;marmot">https:&#x2F;&#x2F;github.com&#x2F;maxpert&#x2F;marmot</a> ) how do get around the boot time, specially when a change log of table is pretty large in Postgres? I&#x27;ve implemented snapshotting mechanism in Marmot as part of quickly getting up to speed. At some level I wonder if we can just feed this PG replication log into NATS cluster and Marmot can just replicate it across the board.</div><br/></div></div><div id="37067596" class="c"><input type="checkbox" id="c-37067596" checked=""/><div class="controls bullet"><span class="by">hamandcheese</span><span>|</span><a href="#37066008">prev</a><span>|</span><a href="#37071987">next</a><span>|</span><label class="collapse" for="c-37067596">[-]</label><label class="expand" for="c-37067596">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit confused by this. Since SQLEdge is a proxy, you lose all the IO benefits of running an embedded in-process DB.<p>At that point, why not replicate to a real Postgres on the edge?<p>Maybe the expectation is that the application also opens the SQLite file directly? (But in that case, what is the point of the SQLEdge proxy?)</div><br/></div></div><div id="37071987" class="c"><input type="checkbox" id="c-37071987" checked=""/><div class="controls bullet"><span class="by">grodes</span><span>|</span><a href="#37067596">prev</a><span>|</span><a href="#37065551">next</a><span>|</span><label class="collapse" for="c-37071987">[-]</label><label class="expand" for="c-37071987">[1 more]</label></div><br/><div class="children"><div class="content">I am sick of reading &quot;on the edge&quot;</div><br/></div></div><div id="37065551" class="c"><input type="checkbox" id="c-37065551" checked=""/><div class="controls bullet"><span class="by">e12e</span><span>|</span><a href="#37071987">prev</a><span>|</span><a href="#37064655">next</a><span>|</span><label class="collapse" for="c-37065551">[-]</label><label class="expand" for="c-37065551">[1 more]</label></div><br/><div class="children"><div class="content">This looks neat. Any support for postgres schemas? Would be cool if this supported each SQLite chard to write to separate schema - giving each &quot;share&quot; a single tenant &quot;view&quot; while giving access to all data in the postgres instance?<p>Or is this only public or all schemas?</div><br/></div></div><div id="37064655" class="c"><input type="checkbox" id="c-37064655" checked=""/><div class="controls bullet"><span class="by">karakanb</span><span>|</span><a href="#37065551">prev</a><span>|</span><a href="#37067555">next</a><span>|</span><label class="collapse" for="c-37064655">[-]</label><label class="expand" for="c-37064655">[2 more]</label></div><br/><div class="children"><div class="content">this seems neat, I&#x27;ll definitely give it a look. this seems like a very suitable trade-off for a lot of applications I have worked on.<p>does anyone know if there is a postgres-postgres version of this that is easy to run in ephemeral environments? ideally I&#x27;d like to be able to run Postgres sidecars along my application containers and eliminate the network roundtrip using the sidecar as a read replica, but haven&#x27;t seen this being done anywhere. maybe it wouldn&#x27;t be fast enough to run in such scenarios?</div><br/><div id="37064790" class="c"><input type="checkbox" id="c-37064790" checked=""/><div class="controls bullet"><span class="by">djbusby</span><span>|</span><a href="#37064655">parent</a><span>|</span><a href="#37067555">next</a><span>|</span><label class="collapse" for="c-37064790">[-]</label><label class="expand" for="c-37064790">[1 more]</label></div><br/><div class="children"><div class="content">In PG only one can use logical or streaming replication. Then all reads to the replica and writes to main.  App needs two connections - one for read, one for write.</div><br/></div></div></div></div><div id="37067555" class="c"><input type="checkbox" id="c-37067555" checked=""/><div class="controls bullet"><span class="by">mvaliente2001</span><span>|</span><a href="#37064655">prev</a><span>|</span><a href="#37064229">next</a><span>|</span><label class="collapse" for="c-37067555">[-]</label><label class="expand" for="c-37067555">[1 more]</label></div><br/><div class="children"><div class="content">For one moment I thought this was the equivalent of SQLite for EdgeDB and the idea made me very happy.</div><br/></div></div><div id="37064229" class="c"><input type="checkbox" id="c-37064229" checked=""/><div class="controls bullet"><span class="by">hrdwdmrbl</span><span>|</span><a href="#37067555">prev</a><span>|</span><a href="#37066689">next</a><span>|</span><label class="collapse" for="c-37064229">[-]</label><label class="expand" for="c-37064229">[5 more]</label></div><br/><div class="children"><div class="content">This space is starting to get crowded. Can anyone compare this with some of the other solutions coming out recently?</div><br/><div id="37064820" class="c"><input type="checkbox" id="c-37064820" checked=""/><div class="controls bullet"><span class="by">DANmode</span><span>|</span><a href="#37064229">parent</a><span>|</span><a href="#37066689">next</a><span>|</span><label class="collapse" for="c-37064820">[-]</label><label class="expand" for="c-37064820">[4 more]</label></div><br/><div class="children"><div class="content">List a couple?</div><br/><div id="37065625" class="c"><input type="checkbox" id="c-37065625" checked=""/><div class="controls bullet"><span class="by">arve0</span><span>|</span><a href="#37064229">root</a><span>|</span><a href="#37064820">parent</a><span>|</span><a href="#37067980">next</a><span>|</span><label class="collapse" for="c-37065625">[-]</label><label class="expand" for="c-37065625">[2 more]</label></div><br/><div class="children"><div class="content">A few I know: rqlite, dqlite, SQLite wasm, litestream.</div><br/><div id="37067353" class="c"><input type="checkbox" id="c-37067353" checked=""/><div class="controls bullet"><span class="by">otoolep</span><span>|</span><a href="#37064229">root</a><span>|</span><a href="#37065625">parent</a><span>|</span><a href="#37067980">next</a><span>|</span><label class="collapse" for="c-37067353">[-]</label><label class="expand" for="c-37067353">[1 more]</label></div><br/><div class="children"><div class="content">rqlite[1] creator here, happy to answer any questions.<p>[1] <a href="https:&#x2F;&#x2F;www.rqlite.io" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rqlite.io</a></div><br/></div></div></div></div><div id="37067980" class="c"><input type="checkbox" id="c-37067980" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#37064229">root</a><span>|</span><a href="#37064820">parent</a><span>|</span><a href="#37065625">prev</a><span>|</span><a href="#37066689">next</a><span>|</span><label class="collapse" for="c-37067980">[-]</label><label class="expand" for="c-37067980">[1 more]</label></div><br/><div class="children"><div class="content">#. SQLite WAL mode<p>From <a href="https:&#x2F;&#x2F;www.sqlite.org&#x2F;isolation.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sqlite.org&#x2F;isolation.html</a> <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32247085">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32247085</a> :<p>&gt; [sqlite] <i>WAL mode permits simultaneous readers and writers. It can do this because changes do not overwrite the original database file, but rather go into the separate write-ahead log file. That means that readers can continue to read the old, original, unaltered content from the original database file at the same time that the writer is appending to the write-ahead log</i><p>#. superfly&#x2F;litefs: a FUSE-based file system for replicating SQLite <a href="https:&#x2F;&#x2F;github.com&#x2F;superfly&#x2F;litefs">https:&#x2F;&#x2F;github.com&#x2F;superfly&#x2F;litefs</a><p>#. sqldiff: <a href="https:&#x2F;&#x2F;www.sqlite.org&#x2F;sqldiff.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sqlite.org&#x2F;sqldiff.html</a> <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31265005">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31265005</a><p>#. dolthub&#x2F;dolt: <a href="https:&#x2F;&#x2F;github.com&#x2F;dolthub&#x2F;dolt">https:&#x2F;&#x2F;github.com&#x2F;dolthub&#x2F;dolt</a> :<p>&gt; <i>Dolt is a SQL database that you can fork, clone, branch, merge, push and pull just like a Git repository.</i> [...]<p>&gt; <i>Dolt can be set up as a replica of your existing MySQL or MariaDB database using standard MySQL binlog replication. Every write becomes a Dolt commit. This is a great way to get the version control benefits of Dolt and keep an existing MySQL or MariaDB database.</i><p>#. github&#x2F;gh-ost: <a href="https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-ost">https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-ost</a> :<p>&gt; <i>Instead, gh-ost uses the binary log stream to capture table changes, and asynchronously applies them onto the ghost table. gh-ost takes upon itself some tasks that other tools leave for the database to perform. As result, gh-ost has greater control over the migration process; can truly suspend it; can truly decouple the migration&#x27;s write load from the master&#x27;s workload.</i><p>#. vlcn-io&#x2F;cr-sqlite: <a href="https:&#x2F;&#x2F;github.com&#x2F;vlcn-io&#x2F;cr-sqlite">https:&#x2F;&#x2F;github.com&#x2F;vlcn-io&#x2F;cr-sqlite</a> :<p>&gt; <i>Convergent, Replicated SQLite. Multi-writer and CRDT support for SQLite</i><p>&gt; <i>CR-SQLite is a run-time loadable extension for SQLite and libSQL. It allows merging different SQLite databases together that have taken independent writes.</i><p>&gt; <i>In other words, you can write to your SQLite database while offline. I can write to mine while offline. We can then both come online and merge our databases together, without conflict.</i><p>&gt; <i>In technical terms: cr-sqlite adds multi-master replication and partition tolerance to SQLite via conflict free replicated data types (CRDTs) and&#x2F;or causally ordered event logs.</i><p>yjs also does CRDTs (Jupyter RTC,)<p>#. pganalyze&#x2F;libpg_query: <a href="https:&#x2F;&#x2F;github.com&#x2F;pganalyze&#x2F;libpg_query">https:&#x2F;&#x2F;github.com&#x2F;pganalyze&#x2F;libpg_query</a> :<p>&gt; <i>C library for accessing the PostgreSQL parser outside of the server environment</i><p>#. Ibis + Substrait [ + DuckDB ] <a href="https:&#x2F;&#x2F;ibis-project.org&#x2F;blog&#x2F;ibis_substrait_to_duckdb&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;ibis-project.org&#x2F;blog&#x2F;ibis_substrait_to_duckdb&#x2F;</a> :<p>&gt; <i>ibis strives to provide a consistent interface for interacting with a multitude of different analytical execution engines, most of which (but not all) speak some dialect of SQL.</i><p>&gt; <i>Today, Ibis accomplishes this with a lot of help from `sqlalchemy` and `sqlglot` to handle differences in dialect, or we interact directly with available Python bindings (for instance with the pandas, datafusion, and polars backends).</i><p>&gt; [...] <i>`Substrait` is a new cross-language serialization format for communicating (among other things) query plans. It&#x27;s still in its early days, but there is already nascent support for Substrait in Apache Arrow, DuckDB, and Velox.</i><p>#. ibis-project&#x2F;ibis-substrait: <a href="https:&#x2F;&#x2F;github.com&#x2F;ibis-project&#x2F;ibis-substrait">https:&#x2F;&#x2F;github.com&#x2F;ibis-project&#x2F;ibis-substrait</a><p>#. tobymao&#x2F;sqlglot: <a href="https:&#x2F;&#x2F;github.com&#x2F;tobymao&#x2F;sqlglot">https:&#x2F;&#x2F;github.com&#x2F;tobymao&#x2F;sqlglot</a> :<p>&gt; <i>SQLGlot is a no-dependency SQL parser, transpiler, optimizer, and engine. It can be used to format SQL or translate between 19 different dialects like DuckDB, Presto, Spark, Snowflake, and BigQuery. It aims to read a wide variety of SQL inputs and output syntactically and semantically correct SQL in the targeted dialects.</i><p>&gt; <i>It is a very comprehensive generic SQL parser with a robust test suite. It is also quite performant, while being written purely in Python.</i><p>&gt; <i>You can easily customize the parser, analyze queries, traverse expression trees, and programmatically build SQL.</i><p>&gt; <i>Syntax errors are highlighted and dialect incompatibilities can warn or raise depending on configurations. However, it should be noted that SQL validation is not SQLGlotâs goal, so some syntax errors may go unnoticed.</i><p>#. benbjohnson&#x2F;postlite: <a href="https:&#x2F;&#x2F;github.com&#x2F;benbjohnson&#x2F;postlite">https:&#x2F;&#x2F;github.com&#x2F;benbjohnson&#x2F;postlite</a> :<p>&gt; <i>postlite is a network proxy to allow access to remote SQLite databases over the Postgres wire protocol. This allows GUI tools to be used on remote SQLite databases which can make administration easier.</i><p>&gt; <i>The proxy works by translating Postgres frontend wire messages into SQLite transactions and converting results back into Postgres response wire messages. Many Postgres clients also inspect the pg_catalog to determine system information so Postlite mirrors this catalog by using an attached in-memory database with virtual tables. The proxy also performs minor rewriting on these system queries to convert them to usable SQLite syntax.</i><p>&gt; <i>Note: This software is in alpha. Please report bugs. Postlite doesn&#x27;t alter your database unless you issue INSERT, UPDATE, DELETE commands so it&#x27;s probably safe. If anything, the Postlite process may die but it shouldn&#x27;t affect your database.</i><p>#. &gt; &quot;Hosting SQLite Databases on GitHub Pages&quot; (2021) re: sql.js-httpvfs, DuckDB <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28021766">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28021766</a><p>#. &gt;&gt; - bittorrent&#x2F;sqltorrent <a href="https:&#x2F;&#x2F;github.com&#x2F;bittorrent&#x2F;sqltorrent">https:&#x2F;&#x2F;github.com&#x2F;bittorrent&#x2F;sqltorrent</a><p>&gt;&gt; <i>Sqltorrent is a custom VFS for sqlite which allows applications to query an sqlite database contained within a torrent. Queries can be processed immediately after the database has been opened, even though the database file is still being downloaded. Pieces of the file which are required to complete a query are prioritized so that queries complete reasonably quickly even if only a small fraction of the whole database has been downloaded.</i><p>#. simonw&#x2F;datasette-lite: <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;datasette-lite">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;datasette-lite</a> datasette, *-to-sqlite, dogsheep<p>&quot;Loading SQLite databases&quot; [w&#x2F; datasette] 
<a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;datasette-lite#loading-sqlite-databases">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;datasette-lite#loading-sqlite-data...</a><p>#. awesome-db-tools: <a href="https:&#x2F;&#x2F;github.com&#x2F;mgramin&#x2F;awesome-db-tools">https:&#x2F;&#x2F;github.com&#x2F;mgramin&#x2F;awesome-db-tools</a><p>Lots of neat SQLite&#x2F;vtable&#x2F;pg&#x2F;replication things</div><br/></div></div></div></div></div></div><div id="37066689" class="c"><input type="checkbox" id="c-37066689" checked=""/><div class="controls bullet"><span class="by">samanator</span><span>|</span><a href="#37064229">prev</a><span>|</span><label class="collapse" for="c-37066689">[-]</label><label class="expand" for="c-37066689">[1 more]</label></div><br/><div class="children"><div class="content">How does this work with custom postgres types?</div><br/></div></div></div></div></div></div></div></body></html>