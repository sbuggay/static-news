<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703926864451" as="style"/><link rel="stylesheet" href="styles.css?v=1703926864451"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.bzero.se/ldapd/btree.html">How the append-only btree works (2010)</a> <span class="domain">(<a href="https://www.bzero.se">www.bzero.se</a>)</span></div><div class="subtext"><span>kevmo314</span> | <span>86 comments</span></div><br/><div><div id="38807532" class="c"><input type="checkbox" id="c-38807532" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38806481">next</a><span>|</span><label class="collapse" for="c-38807532">[-]</label><label class="expand" for="c-38807532">[31 more]</label></div><br/><div class="children"><div class="content">The immutable b+tree is a great idea, except it generates a tremendous amount of garbage pages. Every update of a record generates several new pages along the path of the tree.<p>There are two additional techniques to make  immutable b+tree practical.  One is to reclaim stale unreachable pages after the transactions using them have closed.  Two is to use a pair of oscillating fixed location meta pages.<p>A page is active if it’s in the latest snapshot or it is in use by an open transition; otherwise, it’s unreadable and can be reclaimed. When a transaction closes, it hands its list of in-use pages to the reclaimer.  The reclaimer tracks these pages. When no other open transactions hold on to a page, it can be reclaimed.<p>When the write transaction commits, it hands the list of old pages being overwritten to the reclaimer as candidates for freeing, pending no open transactions using them.<p>The reclaimer can batch a number of reclaimed pages together to update the free page list, by appending to the end of the file a page of the newly freed page pointers. Update the meta page to point to the new head page of the free page list at the end of the file. This can be done as a write transaction to keep things consistent.<p>At a crash all the pending reclaiming pages in memory are lost and the garbage pages in disk linger. This requires periodic garbage collection or compaction.<p>The most frequently updated page in the tree is the meta page. Every write transaction updates it. This creates a lot of garbage pages. The second technique addresses this problem.<p>One insight is that the meta page is only needed when a new transaction begins by finding the tree root of the latest committed snapshot. That means we only need two copies of the meta pages, one for the last committed snapshot and one for the new pending write transaction. When the write transaction commits, the pending meta page becomes the latest committed snapshot. The other page becomes available for the next pending transaction.<p>We can have two fixed location meta pages, oscillating between the latest committed snapshot and the pending new transaction. The fixed location removes the need to search for the meta page from the end of file.</div><br/><div id="38809079" class="c"><input type="checkbox" id="c-38809079" checked=""/><div class="controls bullet"><span class="by">ruuda</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38809034">next</a><span>|</span><label class="collapse" for="c-38809079">[-]</label><label class="expand" for="c-38809079">[4 more]</label></div><br/><div class="children"><div class="content">The Hitchhiker Tree [1] addresses the write amplification at the cost of making lookups and scans slightly more expensive, by keeping a small array of &quot;pending writes&quot; in every non-leaf node. The entire thing is still immutable, but instead of writing a new leaf node + path from root to that leaf, in the majority of cases we only write a new root. When there is no space left in the array, all the pending values get pushed one level down at the same time, so the write amplification is amortized.<p>[1]: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jdn617M3-P4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jdn617M3-P4</a></div><br/><div id="38811790" class="c"><input type="checkbox" id="c-38811790" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809079">parent</a><span>|</span><a href="#38809280">next</a><span>|</span><label class="collapse" for="c-38811790">[-]</label><label class="expand" for="c-38811790">[2 more]</label></div><br/><div class="children"><div class="content">This idea dates to at least 1996: <a href="https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;doi=5353ed87f7ec15c32d66f81a0ad9ba2f695f0855" rel="nofollow">https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;d...</a></div><br/><div id="38813791" class="c"><input type="checkbox" id="c-38813791" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38811790">parent</a><span>|</span><a href="#38809280">next</a><span>|</span><label class="collapse" for="c-38813791">[-]</label><label class="expand" for="c-38813791">[1 more]</label></div><br/><div class="children"><div class="content">can you explain the similarities and differences between arge&#x27;s &#x27;buffer tree&#x27; and the fractal tree and hitchhiker tree?</div><br/></div></div></div></div><div id="38809280" class="c"><input type="checkbox" id="c-38809280" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809079">parent</a><span>|</span><a href="#38811790">prev</a><span>|</span><a href="#38809034">next</a><span>|</span><label class="collapse" for="c-38809280">[-]</label><label class="expand" for="c-38809280">[1 more]</label></div><br/><div class="children"><div class="content">I believe the Bw-tree does the same thing, caching new updates in the intermediate branch nodes and only pushing the updates in batch down to the lower layers when running out of room at the branch node.  These are the newer wave of algorithms to address the write amplification.</div><br/></div></div></div></div><div id="38809034" class="c"><input type="checkbox" id="c-38809034" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38809079">prev</a><span>|</span><a href="#38807717">next</a><span>|</span><label class="collapse" for="c-38809034">[-]</label><label class="expand" for="c-38809034">[7 more]</label></div><br/><div class="children"><div class="content">Yes, CoW trees have tremendous write magnification.  This is well-known.  The fix is to amortize this cost by writing transactions as a log and then doing a b-tree update operation for numerous accumulated transactions.<p>Think of ZFS and it&#x27;s ZIL (ZFS Intent Log).  That&#x27;s exactly what the ZIL is: a CoW tree write magnification amortization mechanism.</div><br/><div id="38809418" class="c"><input type="checkbox" id="c-38809418" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809034">parent</a><span>|</span><a href="#38809399">next</a><span>|</span><label class="collapse" for="c-38809418">[-]</label><label class="expand" for="c-38809418">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not familiar with ZFS internals beyond the deduplication part.  Is that just the traditional transaction log + btree update approach most databases used?  Does ZFS support transactional reading and writing?</div><br/><div id="38809999" class="c"><input type="checkbox" id="c-38809999" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809418">parent</a><span>|</span><a href="#38809399">next</a><span>|</span><label class="collapse" for="c-38809999">[-]</label><label class="expand" for="c-38809999">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Does ZFS support transactional reading and writing?<p>I don&#x27;t know that I understand your question.  ZFS supports POSIX transactional semantics, which is <i>not</i> ACID, though ZFS&#x27;s design <i>could</i> support ACID.<p>&gt; Is that just the traditional transaction log + btree update approach most databases used?<p>Basically, yes.  The idea is to write a sequential log of a) data blocks, b) metadata operations (e.g., renames) to support fast crash recovery.  During normal operation ZFS keeps in-memory data structures up to date but delays writing new tree transactions so as to amortize write magnification.  On unclean shutdown ZFS checks that all transactions recorded in the ZIL have been written to the tree or else it will do it by a) rewinding the ZFS state to the newest fully-written transaction, b) loading the contents of the ZIL from that point forward.<p>Because the ZIL was designed at a time when fast flash devices were expensive, it&#x27;s really a separate thing from the rest of the tree.  If one were to start over one might integrate the ZIL with the rest of the system more tightly so as to further minimize write magnification (e.g., data blocks written to the ZIL need not be re-written to the tree).</div><br/><div id="38811834" class="c"><input type="checkbox" id="c-38811834" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809999">parent</a><span>|</span><a href="#38809399">next</a><span>|</span><label class="collapse" for="c-38811834">[-]</label><label class="expand" for="c-38811834">[1 more]</label></div><br/><div class="children"><div class="content">Good to know.  Thanks for the explanation.<p>Basically ZFS maintains a ZIL based in-memory tree for the recent updates and a on-disk btree for the complete updates, minus the recent updates in ZIL. That&#x27;s consistent with most database transaction log implementation.  Some newer approach adds a Bloom filter to do fast decision between looking in the in-memory tree or in the on-disk btree.</div><br/></div></div></div></div></div></div><div id="38809399" class="c"><input type="checkbox" id="c-38809399" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809034">parent</a><span>|</span><a href="#38809418">prev</a><span>|</span><a href="#38807717">next</a><span>|</span><label class="collapse" for="c-38809399">[-]</label><label class="expand" for="c-38809399">[3 more]</label></div><br/><div class="children"><div class="content">FFS. The fix for absolutely bonkers CoW costs is to stop buying in to this idiotic notion that “immutability is easier to reason about”.<p>If you’re having difficulty reasoning about how to deal with major performance issues <i>then your position is not easier to reason about. Full stop</i>.<p>Stop the madness!</div><br/><div id="38810046" class="c"><input type="checkbox" id="c-38810046" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809399">parent</a><span>|</span><a href="#38812331">next</a><span>|</span><label class="collapse" for="c-38810046">[-]</label><label class="expand" for="c-38810046">[1 more]</label></div><br/><div class="children"><div class="content">It is easy to reason about the performance issues of CoW, and it&#x27;s easy enough to reason about how to work around those issues.  Ease of reasoning is a big deal when you&#x27;re dealing with hundreds of millions of lines of code, as some of us do.  Cognitive load is a big deal in today&#x27;s world.  It&#x27;s why we&#x27;re migrating from C to memory-safe languages.</div><br/></div></div><div id="38812331" class="c"><input type="checkbox" id="c-38812331" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809399">parent</a><span>|</span><a href="#38810046">prev</a><span>|</span><a href="#38807717">next</a><span>|</span><label class="collapse" for="c-38812331">[-]</label><label class="expand" for="c-38812331">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s correct that aliasing makes performance harder to reason about<p>but there are other things you might want to reason about, such as whether a subroutine terminates at all and what it returns, and immutability does make it easier to reason about those things</div><br/></div></div></div></div></div></div><div id="38807717" class="c"><input type="checkbox" id="c-38807717" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38809034">prev</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38807717">[-]</label><label class="expand" for="c-38807717">[8 more]</label></div><br/><div class="children"><div class="content">&gt; except it generates a tremendous amount of garbage pages<p>Note that this is an advantage on say, controller-less NAND Flash (JFFS-like embedded NAND Flash).<p>More modern Flash drives have embedded FTL (flash translation layers) that internalizes that garbage collection process. But *someone* had to write the FTL to begin with, and methinks this append-only btree would work very well for that.<p>-------<p>In NAND Flash, only 10,000ish erase&#x2F;write cycles are allowed before any block becomes unusable. (Depending on tech of course: could be 1000 on QLC could be 100k on SLC). All that garbage helps cycle the write&#x2F;erase cycles across the drive more evenly &#x2F; more consistently. Especially if you combine that garbage with TRIM-like commands.<p>That might be a little bit too low level for a lot of folks though.</div><br/><div id="38808377" class="c"><input type="checkbox" id="c-38808377" checked=""/><div class="controls bullet"><span class="by">epcoa</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38807717">parent</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38808377">[-]</label><label class="expand" for="c-38808377">[7 more]</label></div><br/><div class="children"><div class="content">There are more appropriate and better data structures for an FTL especially with the assumption of some amount of auxiliary RAM (either host or on controller). Much of this literature is open access&#x2F;free.<p>“All that garbage helps cycle the write&#x2F;erase cycles across the drive more evenly”<p>Well no, you still want to minimize garbage production (and related GC overhead). Wear leveling doesn’t mean produce more garbage.</div><br/><div id="38808631" class="c"><input type="checkbox" id="c-38808631" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38808377">parent</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38808631">[-]</label><label class="expand" for="c-38808631">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Well no, you still want to minimize garbage production (and related GC overhead). Wear leveling doesn’t mean produce more garbage.<p>Surely some % of garbage helps as you&#x27;re garbage collecting and reliably trying to shuffle data around to wear-level more evenly?<p>Lets say you have 99% used data and 1% garbage. You have very little room for (static) wear leveling. Ex: If you&#x27;re writing 10MB of new data, and your drive is 99% full of allocated data... you&#x27;d have to move 1000MB of data around to &quot;find&quot; the 10MB of garbage, on the average.<p>In the other extreme case: 0%  data used and 100% garbage (say a TRIM operation just completed), then you simply just write 10MB without having to worry about moving any data around.<p>The 50% data + 50% garbage scales as appropriate. 10MB of written new data will need you to find and coalesce 10MB of garbage to write the new data. This will happen after moving 20MB of overall data around.<p>----------<p>I&#x27;m oversimplifying of course. But even in a real life system, I&#x27;d expect that the more &quot;garbage&quot; you have sitting around, the better the various algorithms work for FTL &#x2F; SSD (static or dynamic) wear leveling.</div><br/><div id="38809242" class="c"><input type="checkbox" id="c-38809242" checked=""/><div class="controls bullet"><span class="by">epcoa</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38808631">parent</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38809242">[-]</label><label class="expand" for="c-38809242">[5 more]</label></div><br/><div class="children"><div class="content">I can’t state any more clearly: minimize the production of garbage.<p>“Surely some % of garbage helps as you&#x27;re garbage collecting ”<p>Garbage that doesn’t exist doesn’t need collecting.<p>The flaw here is confusing free space with garbage. You shouldn’t have written in the first place if you could have avoided it.<p>Every environmentalist knows this: RRR, the first R is reduce not recycle.</div><br/><div id="38809458" class="c"><input type="checkbox" id="c-38809458" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809242">parent</a><span>|</span><a href="#38809400">prev</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38809458">[-]</label><label class="expand" for="c-38809458">[3 more]</label></div><br/><div class="children"><div class="content">Any append-only data-structure will have data that was true (when it was written), but has become false&#x2F;obsolete&#x2F;garbage at a later time. This is unavoidable.<p>I&#x27;m not saying that we write needless garbage to the logs or filesystem or whatever. I&#x27;m saying that the amount of garbage in your stream that you leave behind aids in later steps of (static) wear-leveling. So therefore, its not a big deal. You&#x27;re going to be making plenty of this (initially true data, but later garbage data) as files get updated, moved around filesystems, or whatnot.<p>&quot;Garbage&quot; in this sense is perhaps the wrong word. Its more like &quot;Obsolete data&quot;, or &quot;outdated data&quot;.</div><br/><div id="38809778" class="c"><input type="checkbox" id="c-38809778" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809458">parent</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38809778">[-]</label><label class="expand" for="c-38809778">[2 more]</label></div><br/><div class="children"><div class="content">If you read the article though, many of the updated nodes (which are now garbage) don&#x27;t see any updates to their “data” but to internal tree pointers.<p>So lots of “data” is being copied, and garbage is being generated, only for the benefit of tidying up tree structure, not because the actual “data” in those pages changed.<p>Not generating such garbage in the first place is an obvious benefit.</div><br/><div id="38810598" class="c"><input type="checkbox" id="c-38810598" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809778">parent</a><span>|</span><a href="#38808305">next</a><span>|</span><label class="collapse" for="c-38810598">[-]</label><label class="expand" for="c-38810598">[1 more]</label></div><br/><div class="children"><div class="content">I think I see what you mean now. Thanks.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38808305" class="c"><input type="checkbox" id="c-38808305" checked=""/><div class="controls bullet"><span class="by">thechao</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38807717">prev</a><span>|</span><a href="#38807767">next</a><span>|</span><label class="collapse" for="c-38808305">[-]</label><label class="expand" for="c-38808305">[3 more]</label></div><br/><div class="children"><div class="content">I am <i>immediately</i> nerd-sniped by this. Is there any code out there you know of I can see? The dual meta-data pages sounds <i>precisely</i> like double-buffering (from graphics; my domain of expertise). I am also drawn to append-only-<i>like</i> and persistent data-structures.</div><br/><div id="38808955" class="c"><input type="checkbox" id="c-38808955" checked=""/><div class="controls bullet"><span class="by">hoytech</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38808305">parent</a><span>|</span><a href="#38807767">next</a><span>|</span><label class="collapse" for="c-38808955">[-]</label><label class="expand" for="c-38808955">[2 more]</label></div><br/><div class="children"><div class="content">LMDB works like this. The MDB_env struct keeps pointers to both meta pages:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;LMDB&#x2F;lmdb&#x2F;blob&#x2F;30288c72573ceac719627183f1058cad1dd08b74&#x2F;libraries&#x2F;liblmdb&#x2F;mdb.c#L1520">https:&#x2F;&#x2F;github.com&#x2F;LMDB&#x2F;lmdb&#x2F;blob&#x2F;30288c72573ceac719627183f1...</a><p>Which meta-page used is determined by the transaction ID (even IDs use first, odd IDs second).<p>This is the earliest description I can find of the &quot;shadow paging&quot; concept: <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;320521.320540" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;320521.320540</a><p>And I believe its first implementation was in IBM&#x27;s System R.</div><br/><div id="38811563" class="c"><input type="checkbox" id="c-38811563" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38808955">parent</a><span>|</span><a href="#38807767">next</a><span>|</span><label class="collapse" for="c-38811563">[-]</label><label class="expand" for="c-38811563">[1 more]</label></div><br/><div class="children"><div class="content">LMDB is the poster child of COW btree implementation. That paper is a good find. Thanks.</div><br/></div></div></div></div></div></div><div id="38807767" class="c"><input type="checkbox" id="c-38807767" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38808305">prev</a><span>|</span><a href="#38809374">next</a><span>|</span><label class="collapse" for="c-38807767">[-]</label><label class="expand" for="c-38807767">[2 more]</label></div><br/><div class="children"><div class="content">This description reminds me of a document I read about how ZFS is implemented. In particular, how snapshots work in ZFS, and what happens when you delete a snapshot.</div><br/><div id="38809059" class="c"><input type="checkbox" id="c-38809059" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38807767">parent</a><span>|</span><a href="#38809374">next</a><span>|</span><label class="collapse" for="c-38809059">[-]</label><label class="expand" for="c-38809059">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a very similar idea.<p>Traditional Unix-ish filesystems, with inodes and indirect nodes are a lot like b-trees, but ones where the indices are block numbers and where you can only append indices, trim, or replace indices.<p>The ZIL (ZFS intent log) is a mechanism for amortizing the write magnification of copy on write trees.</div><br/></div></div></div></div><div id="38809374" class="c"><input type="checkbox" id="c-38809374" checked=""/><div class="controls bullet"><span class="by">mamcx</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38807767">prev</a><span>|</span><a href="#38808493">next</a><span>|</span><label class="collapse" for="c-38809374">[-]</label><label class="expand" for="c-38809374">[4 more]</label></div><br/><div class="children"><div class="content">Naively thinking here, how about a 2 immutable b+tree setup:<p>The &quot;hot&quot; tree is the WAL: All the data is there and copies are generated.<p>The &quot;cold&quot; tree is behind: In the background move from WAL and at the same time compact it.</div><br/><div id="38809453" class="c"><input type="checkbox" id="c-38809453" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809374">parent</a><span>|</span><a href="#38808493">next</a><span>|</span><label class="collapse" for="c-38809453">[-]</label><label class="expand" for="c-38809453">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how the traditional transaction log + btree approach work.  The append-only btree removes the need for a separate transaction log.</div><br/><div id="38812035" class="c"><input type="checkbox" id="c-38812035" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38809453">parent</a><span>|</span><a href="#38808493">next</a><span>|</span><label class="collapse" for="c-38812035">[-]</label><label class="expand" for="c-38812035">[2 more]</label></div><br/><div class="children"><div class="content">I think you could view the append-only B-tree as a deamortized version of the traditional update-in-place B-tree + WAL. It&#x27;s true that it eliminates the problem of maintaining a separate WAL, but only by trading it for an arguably harder problem: compacting the B-tree. It&#x27;s easy and cheap to truncate the WAL; it&#x27;s difficult and expensive to compact the B-tree. I guess LMDB solves this problem by only updating at page-level granularity so it can reuse entire pages without compaction, although I haven&#x27;t studied its design in much detail.</div><br/><div id="38812962" class="c"><input type="checkbox" id="c-38812962" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38812035">parent</a><span>|</span><a href="#38808493">next</a><span>|</span><label class="collapse" for="c-38812962">[-]</label><label class="expand" for="c-38812962">[1 more]</label></div><br/><div class="children"><div class="content">If by compacting the tree you meant compacting the space left over by the users deleting the records, it&#x27;s about the same amount of work between the two approaches.  The WAL+btree case needs to merge the near empty pages and copy the remaining records while the append-only btree case needs to allocate new pages to merge in the near empty pages and fix up the parent path which can be done as a batching garbage collection phase.<p>If by compacting you meant cleaning up the garbage pages, while the WAL+btree is simpler in truncating the WAL, the append-only btree is pretty easy.  It&#x27;s just doing upkeep on the free-page list.<p>There&#x27;re only three places to pay attention: 1. any page touched by a transaction (read&#x2F;write) is added to the in-use list.  2. When a transaction closes, removes its touched pages from the in-use list by decrementing their in-use counters.  3. When a write transaction commits, adds all the old overwritten pages to a pending-delete list.  Periodically check the pending-delete list against the in-use list and any page not in use is moved to the deleted-queue.  When the deleted-queue reaches a large enough batch, create a new free-page to contain the pointers of the deleted pages from the queue.  Chain up to the existing free-page list in the meta page by storing the pointer to the existing head of list in the new free-page.  Append the new free-page to the db file.  Update the new free-page as the new head of the free-page list in the meta page.  That&#x27;s it.</div><br/></div></div></div></div></div></div></div></div><div id="38808493" class="c"><input type="checkbox" id="c-38808493" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#38807532">parent</a><span>|</span><a href="#38809374">prev</a><span>|</span><a href="#38806481">next</a><span>|</span><label class="collapse" for="c-38808493">[-]</label><label class="expand" for="c-38808493">[2 more]</label></div><br/><div class="children"><div class="content">Of course, this implies a single-writer design (not necessarily a bad thing!).</div><br/><div id="38808658" class="c"><input type="checkbox" id="c-38808658" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38807532">root</a><span>|</span><a href="#38808493">parent</a><span>|</span><a href="#38806481">next</a><span>|</span><label class="collapse" for="c-38808658">[-]</label><label class="expand" for="c-38808658">[1 more]</label></div><br/><div class="children"><div class="content">Actually immutable btree has a single writer in general since there’s no translation log and the meta page pointing to one latest tree root. Even if two write transactions updating different parts of the tree, they both need to update the same meta page, causing a contention. This is one downside (or upside depending on your need since single writer simplifies things a lot and great for sequential writes).</div><br/></div></div></div></div></div></div><div id="38806481" class="c"><input type="checkbox" id="c-38806481" checked=""/><div class="controls bullet"><span class="by">hoytech</span><span>|</span><a href="#38807532">prev</a><span>|</span><a href="#38806115">next</a><span>|</span><label class="collapse" for="c-38806481">[-]</label><label class="expand" for="c-38806481">[2 more]</label></div><br/><div class="children"><div class="content">LMDB [0] was derived from this project, as mentioned in its copyright notice section [1].<p>[0] <a href="http:&#x2F;&#x2F;www.lmdb.tech&#x2F;doc&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.lmdb.tech&#x2F;doc&#x2F;</a>
[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;LMDB&#x2F;lmdb&#x2F;blob&#x2F;30288c72573ceac719627183f1058cad1dd08b74&#x2F;libraries&#x2F;liblmdb&#x2F;lmdb.h#L150-L152">https:&#x2F;&#x2F;github.com&#x2F;LMDB&#x2F;lmdb&#x2F;blob&#x2F;30288c72573ceac719627183f1...</a></div><br/><div id="38806920" class="c"><input type="checkbox" id="c-38806920" checked=""/><div class="controls bullet"><span class="by">jnwatson</span><span>|</span><a href="#38806481">parent</a><span>|</span><a href="#38806115">next</a><span>|</span><label class="collapse" for="c-38806920">[-]</label><label class="expand" for="c-38806920">[1 more]</label></div><br/><div class="children"><div class="content">Importantly, the LMDB API allows append mode, and it is very fast.</div><br/></div></div></div></div><div id="38806115" class="c"><input type="checkbox" id="c-38806115" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#38806481">prev</a><span>|</span><a href="#38806105">next</a><span>|</span><label class="collapse" for="c-38806115">[-]</label><label class="expand" for="c-38806115">[14 more]</label></div><br/><div class="children"><div class="content">One of the advantages of this kind of architecture is that if one reader is reading the old tree while it is replaced, it just works. Databases are really good at having multiple versions of the same data structure be accessible at the same time.<p>I hand rolled some similar data structures in higher order languages when I couldn&#x27;t find any Python packages that gave me the same capability. But I couldn&#x27;t figure out what a good name would be for, say, a dictionary that could have multiple concurrent versions. So I never went anything where with that.</div><br/><div id="38807998" class="c"><input type="checkbox" id="c-38807998" checked=""/><div class="controls bullet"><span class="by">j-pb</span><span>|</span><a href="#38806115">parent</a><span>|</span><a href="#38806257">next</a><span>|</span><label class="collapse" for="c-38807998">[-]</label><label class="expand" for="c-38807998">[7 more]</label></div><br/><div class="children"><div class="content">These things are usually called &quot;persistent&quot; versions of the thing, e.g. persistent Dictionary. Sometimes &quot;immutably persistent&quot; to distinguish it from the &quot;durable&quot; meaning of persistence i.e. written to disk.</div><br/><div id="38808516" class="c"><input type="checkbox" id="c-38808516" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38807998">parent</a><span>|</span><a href="#38806257">next</a><span>|</span><label class="collapse" for="c-38808516">[-]</label><label class="expand" for="c-38808516">[6 more]</label></div><br/><div class="children"><div class="content">It seems odd to me to call a data structure &quot;persistent&quot; when its purpose is to allow you to cheaply keep many similar transitory copies around until you throw them away.<p>The specific application was using dynamic programming to build up a complex data structure. You wind up with many copies of very similar data structures, and doing a deep copy each time is prohibitively expensive.</div><br/><div id="38809832" class="c"><input type="checkbox" id="c-38809832" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38808516">parent</a><span>|</span><a href="#38806257">next</a><span>|</span><label class="collapse" for="c-38809832">[-]</label><label class="expand" for="c-38809832">[5 more]</label></div><br/><div class="children"><div class="content">Still that&#x27;s what they&#x27;re called:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Persistent_data_structure" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Persistent_data_structure</a><p>Precisely because previous versions remain valid (persist) under modification.</div><br/><div id="38810049" class="c"><input type="checkbox" id="c-38810049" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38809832">parent</a><span>|</span><a href="#38806257">next</a><span>|</span><label class="collapse" for="c-38810049">[-]</label><label class="expand" for="c-38810049">[4 more]</label></div><br/><div class="children"><div class="content">There is a key difference between that, and what I created.<p>The difference is that persistent data structures allow you to traverse the history of the data structure to find past versions. By contrast I only allowed you to see the current version, returning a new version of the root any time you made a modification. As a result, the memory associated with the old version could be freed once nothing would want to access it again. And any version that you had could still be manipulated.<p>For the example that I was dealing with, both made sense. On top of that it made it possible to create a hashable version of the data structure that had a good chance (not a guarantee) of matching hashes when you arrived at the same data structure through different histories.</div><br/><div id="38813752" class="c"><input type="checkbox" id="c-38813752" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38810049">parent</a><span>|</span><a href="#38813420">next</a><span>|</span><label class="collapse" for="c-38813752">[-]</label><label class="expand" for="c-38813752">[1 more]</label></div><br/><div class="children"><div class="content">the data structures people normally call &#x27;persistent&#x27; behave like what you implemented; they&#x27;re ubiquitous in languages like clojure, haskell, and even ocaml that privilege immutability.  the map module in ocaml&#x27;s standard library is an example, and so is almost everything built in to clojure.  &#x27;traverse the history of the data structure to find past versions&#x27; is not how these persistent data structures normally work<p>there is an unfortunate terminology clash with &#x27;persistent&#x27; in the sense of &#x27;not vanishing after a power cycle&#x27;, so i typically use the term &#x27;fp-persistent&#x27;, because this sense of &#x27;persistent&#x27; is associated with functional programming.  this has the disadvantage that it&#x27;s a term i made up, so nobody knows what i mean until i explain it</div><br/></div></div><div id="38813420" class="c"><input type="checkbox" id="c-38813420" checked=""/><div class="controls bullet"><span class="by">j-pb</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38810049">parent</a><span>|</span><a href="#38813752">prev</a><span>|</span><a href="#38810938">next</a><span>|</span><label class="collapse" for="c-38813420">[-]</label><label class="expand" for="c-38813420">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  The difference is that persistent data structures allow you to traverse the history of the data structure to find past versions.
</code></pre>
That capabilities is not a required property of persisten datastructures.
The copy on write and collect the unique parts when a root is freed semantic that you describe is exactly the common behaviour of persistent data-structures in the wild.<p>Libraries like Rusts &quot;im&quot;, even do some nifty optimisations where they combine the borrow checker with reference counting to only perform copy on write when the reference you have is non-unique.<p>So based on your description you build a path-copying persistent data-structure.<p>I&#x27;d recommend this book if you want to compare your work with the state of the art:
<a href="https:&#x2F;&#x2F;books.google.de&#x2F;books&#x2F;about&#x2F;Purely_Functional_Data_Structures.html?id=SxPzSTcTalAC&amp;printsec=frontcover&amp;source=kp_read_button&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;gboemv=1&amp;ovdme=1&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" rel="nofollow">https:&#x2F;&#x2F;books.google.de&#x2F;books&#x2F;about&#x2F;Purely_Functional_Data_S...</a></div><br/></div></div><div id="38810938" class="c"><input type="checkbox" id="c-38810938" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38810049">parent</a><span>|</span><a href="#38813420">prev</a><span>|</span><a href="#38806257">next</a><span>|</span><label class="collapse" for="c-38810938">[-]</label><label class="expand" for="c-38810938">[1 more]</label></div><br/><div class="children"><div class="content">Well, the difference isn&#x27;t that great. You wrote: “the memory associated with the old version could be freed once nothing would want to access it again.” So all it really takes is something wanting.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38806257" class="c"><input type="checkbox" id="c-38806257" checked=""/><div class="controls bullet"><span class="by">Hnrobert42</span><span>|</span><a href="#38806115">parent</a><span>|</span><a href="#38807998">prev</a><span>|</span><a href="#38806105">next</a><span>|</span><label class="collapse" for="c-38806257">[-]</label><label class="expand" for="c-38806257">[6 more]</label></div><br/><div class="children"><div class="content">As Phil Karlton, “There are only two hard things in computer science: cache validation and naming things.”
Seems like you found a way to work on both!<p><a href="https:&#x2F;&#x2F;skeptics.stackexchange.com&#x2F;questions&#x2F;19836&#x2F;has-phil-karlton-ever-said-there-are-only-two-hard-things-in-computer-science#39178" rel="nofollow">https:&#x2F;&#x2F;skeptics.stackexchange.com&#x2F;questions&#x2F;19836&#x2F;has-phil-...</a></div><br/><div id="38806293" class="c"><input type="checkbox" id="c-38806293" checked=""/><div class="controls bullet"><span class="by">timeimp</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38806257">parent</a><span>|</span><a href="#38809322">next</a><span>|</span><label class="collapse" for="c-38806293">[-]</label><label class="expand" for="c-38806293">[4 more]</label></div><br/><div class="children"><div class="content">I always have to add the &quot;and off-by-one&quot; at the end.<p>Nothing like reading memory you don&#x27;t own!</div><br/><div id="38806390" class="c"><input type="checkbox" id="c-38806390" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38806293">parent</a><span>|</span><a href="#38809322">next</a><span>|</span><label class="collapse" for="c-38806390">[-]</label><label class="expand" for="c-38806390">[3 more]</label></div><br/><div class="children"><div class="content">There are actually only two hard problems in computer science:<p>0) Cache invalidation<p>1) Naming things<p>5) Asynchronous callbacks<p>2) Off-by-one errors<p>3) Scope creep<p>6) Bounds checking</div><br/><div id="38808242" class="c"><input type="checkbox" id="c-38808242" checked=""/><div class="controls bullet"><span class="by">Scarblac</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38806390">parent</a><span>|</span><a href="#38807555">next</a><span>|</span><label class="collapse" for="c-38808242">[-]</label><label class="expand" for="c-38808242">[1 more]</label></div><br/><div class="children"><div class="content">There is only one hard problem in software engineering: people.</div><br/></div></div><div id="38807555" class="c"><input type="checkbox" id="c-38807555" checked=""/><div class="controls bullet"><span class="by">alternative_a</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38806390">parent</a><span>|</span><a href="#38808242">prev</a><span>|</span><a href="#38809322">next</a><span>|</span><label class="collapse" for="c-38807555">[-]</label><label class="expand" for="c-38807555">[1 more]</label></div><br/><div class="children"><div class="content">Let’s be pedantic here and get all religious over the words “Science” and “hard”.<p>Computer “science” has a difficult conceptual problem with caching. The optimal cache, this science tells us, is indistinguishable from a fortune teller who is never wrong (oracle). Fortune telling is a “hard” problem for a science based on reasoning. The best we can do is hedge bets (which is what the science of caching focuses on).<p>This same science also has a difficulty with naming things. Now numbering things is easy and science loves maths and maths love sciences, but science and letters have a more difficult history. Science would approve of “factoryfactoryfactoryImpl” btw ... it’s “a rational scheme of naming”. .<p>Here we see a “science” that is facing actual difficulties.<p>The rest of your list are difficult but not “hard”. The science of these matters is clear and the rest is up to the “scientists” struggling with “scope creep” and “bounds checking” ..</div><br/></div></div></div></div></div></div><div id="38809322" class="c"><input type="checkbox" id="c-38809322" checked=""/><div class="controls bullet"><span class="by">pmarreck</span><span>|</span><a href="#38806115">root</a><span>|</span><a href="#38806257">parent</a><span>|</span><a href="#38806293">prev</a><span>|</span><a href="#38806105">next</a><span>|</span><label class="collapse" for="c-38809322">[-]</label><label class="expand" for="c-38809322">[1 more]</label></div><br/><div class="children"><div class="content"><i>in</i>validation?</div><br/></div></div></div></div></div></div><div id="38806105" class="c"><input type="checkbox" id="c-38806105" checked=""/><div class="controls bullet"><span class="by">seunosewa</span><span>|</span><a href="#38806115">prev</a><span>|</span><a href="#38807055">next</a><span>|</span><label class="collapse" for="c-38806105">[-]</label><label class="expand" for="c-38806105">[23 more]</label></div><br/><div class="children"><div class="content">Append-only struxtures are not efficient enough for general use. You&#x27;re paying a steep price for creating a snapshot of the data for every single operation.<p>I saw this when I was playing with Scala&#x27;s immutable and mutable data structures - written by the same team - ages ago. The immutable structures were <i>much</i> slower for common operations.<p>The fastest databases tend to use undo logs to re-construct snapshots when they are needed.</div><br/><div id="38806353" class="c"><input type="checkbox" id="c-38806353" checked=""/><div class="controls bullet"><span class="by">scottlamb</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38807174">next</a><span>|</span><label class="collapse" for="c-38806353">[-]</label><label class="expand" for="c-38806353">[8 more]</label></div><br/><div class="children"><div class="content">You can build real useful systems on them. For example, Gmail used to be implemented on top of GFS as two append-only files per user: the zlog and the index. The zlog held (zlib-compressed) operations such as &quot;add this message&quot; and &quot;delete this message&quot;. The index was an append-only btree as described here. It was a true index in that it didn&#x27;t include the actual message contents. Those were simply pointers into the log. Thus, it was much smaller than the zlog and its efficiency was less of a concern. Also, periodically both files were &quot;compacted&quot; by writing a fresh log (that built the current state in the most efficient way) and matching index. This was primarily for privacy (otherwise your deleted messages would never actually go away) but also improved efficiency.<p>Gmail&#x27;s now built on top of Spanner so uses a log-structured merge tree. Still append-only files but a bit different. Files aren&#x27;t per user but per some arbitrary key range boundary; no more btree; multiple layers with the top ones getting compacted more frequently; etc.</div><br/><div id="38806850" class="c"><input type="checkbox" id="c-38806850" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806353">parent</a><span>|</span><a href="#38808033">next</a><span>|</span><label class="collapse" for="c-38806850">[-]</label><label class="expand" for="c-38806850">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth noting that Google&#x27;s internal scale-out filesystem is append-only (for various distributed systems and operational reasons), so you end up with append-only data structures proliferating in that ecosystem.  That does not necessarily mean that the append-only data structures were chosen for any technical merit other than ability to be implemented on the append-only filesystem.</div><br/><div id="38807278" class="c"><input type="checkbox" id="c-38807278" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806850">parent</a><span>|</span><a href="#38808233">next</a><span>|</span><label class="collapse" for="c-38807278">[-]</label><label class="expand" for="c-38807278">[3 more]</label></div><br/><div class="children"><div class="content">So if we ignore the technical merits based on which append-only data structures were chosen in general, we don&#x27;t necessarily have additional technical merits for any particular time append-only was chosen.<p>The reasons why append-only structures were chosen in general apply surprisingly often to any particular system that scales to large data, which would like to be robust to a wide variety of real world problems. You won&#x27;t see it in looking at the data structure because the hard parts are abstracted away from you. But you&#x27;ll see it if you try to reimplement the same system from scratch, then scale it up to production.</div><br/><div id="38811949" class="c"><input type="checkbox" id="c-38811949" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38807278">parent</a><span>|</span><a href="#38807736">next</a><span>|</span><label class="collapse" for="c-38811949">[-]</label><label class="expand" for="c-38811949">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget the security implications.  If only root can run the compression&#x2F;deletion script, all the compromised user can do is try to write to theirs.  If you get into writing other users&#x27; data, that sucks, but nothing is deleted or exfiltrated, and the log is baked in.  Break into root, well good luck with that on any system.</div><br/></div></div><div id="38807736" class="c"><input type="checkbox" id="c-38807736" checked=""/><div class="controls bullet"><span class="by">alternative_a</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38807278">parent</a><span>|</span><a href="#38811949">prev</a><span>|</span><a href="#38808233">next</a><span>|</span><label class="collapse" for="c-38807736">[-]</label><label class="expand" for="c-38807736">[1 more]</label></div><br/><div class="children"><div class="content">The subtle point I read in GP is the historic correlation between storage systems and data structures. Your point is equally valid in that this correlation is not indicative of non-general applicability.<p>Both points need to be kept in mind imho in design.</div><br/></div></div></div></div><div id="38808233" class="c"><input type="checkbox" id="c-38808233" checked=""/><div class="controls bullet"><span class="by">scottlamb</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806850">parent</a><span>|</span><a href="#38807278">prev</a><span>|</span><a href="#38808033">next</a><span>|</span><label class="collapse" for="c-38808233">[-]</label><label class="expand" for="c-38808233">[2 more]</label></div><br/><div class="children"><div class="content">Good point. It&#x27;s also worth noting that raw flash also is generally treated as roughly append-only for wear leveling. &quot;General-purpose&quot; may be in the eye of the beholder, but I&#x27;d say these append-only data structures are useful in at least two significant environments.</div><br/><div id="38813542" class="c"><input type="checkbox" id="c-38813542" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38808233">parent</a><span>|</span><a href="#38808033">next</a><span>|</span><label class="collapse" for="c-38813542">[-]</label><label class="expand" for="c-38813542">[1 more]</label></div><br/><div class="children"><div class="content">Wear leveling generally happens well below the user-level filesystem (and is quite complicated!), and altering your user-level behavior because you think it helps is a little bit silly. Zoned NVMe is an obvious exception to this, where the FTL takes advantage of the append-only zones (even that is an abstraction only shown to filesystems), but it will frequently remap your blocks if you do a lot of read-modify-writes to keep the wear even.</div><br/></div></div></div></div></div></div><div id="38808033" class="c"><input type="checkbox" id="c-38808033" checked=""/><div class="controls bullet"><span class="by">lloydatkinson</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806353">parent</a><span>|</span><a href="#38806850">prev</a><span>|</span><a href="#38807174">next</a><span>|</span><label class="collapse" for="c-38808033">[-]</label><label class="expand" for="c-38808033">[1 more]</label></div><br/><div class="children"><div class="content">What you described is called event sourcing</div><br/></div></div></div></div><div id="38807174" class="c"><input type="checkbox" id="c-38807174" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38806353">prev</a><span>|</span><a href="#38806263">next</a><span>|</span><label class="collapse" for="c-38807174">[-]</label><label class="expand" for="c-38807174">[1 more]</label></div><br/><div class="children"><div class="content">LMDB is a strong counter-example to your argument. Based on its benchmarks, you&#x27;re wrong. [1]<p>Yes immutable in-memory data structures are slower than their mutable counterpoints, but we&#x27;re not talking about either of those here.<p>Databases are not in-memory data structures.<p>[1] <a href="http:&#x2F;&#x2F;www.lmdb.tech&#x2F;bench&#x2F;microbench&#x2F;july&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.lmdb.tech&#x2F;bench&#x2F;microbench&#x2F;july&#x2F;</a></div><br/></div></div><div id="38806263" class="c"><input type="checkbox" id="c-38806263" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38807174">prev</a><span>|</span><a href="#38810359">next</a><span>|</span><label class="collapse" for="c-38806263">[-]</label><label class="expand" for="c-38806263">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this is generally true.<p>Especially on mediums where sequentially writing large blocks is faster than random writes, you get much better performance to use a log-structured datastructure and put anything new&#x2F;any changes at the end.<p>Due to the design of modern SSD&#x27;s, &#x27;write in place&#x27; is pretty much an illusion.</div><br/></div></div><div id="38810359" class="c"><input type="checkbox" id="c-38810359" checked=""/><div class="controls bullet"><span class="by">joshlemer</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38806263">prev</a><span>|</span><a href="#38806144">next</a><span>|</span><label class="collapse" for="c-38810359">[-]</label><label class="expand" for="c-38810359">[1 more]</label></div><br/><div class="children"><div class="content">Scala&#x27;s immutable data structures, and especially the way they are used idiomatically and most obviously, have a lot of performance issues that are much bigger than the basic cost of persistent data structures. Namely, most commonly I will see developers default to pipelining strict operations like myList.map(...).filter(...).flatMap(...).collect(...).take(2) which forces&#x2F;materializes the whole collection in memory for every operation. Better would be to first transform the list into a lazy view or iterator with myList.view or myList.iterator, and then do the pipeline.<p>They also lack the ability to perform multiple updates in a batch, except for some very limited cases. Other implementations like Clojure&#x27;s support &quot;transients&quot; where you get access to mutate the data structure over and over again (as well as do reads), and then freeze the structure in place as a new persistent collection. JavaScript libraries like immer allow for the same thing. Scala&#x27;s collections don&#x27;t generally support this except in the form of &quot;builders&quot; which don&#x27;t support reads and also don&#x27;t support all the write access patterns (such as updating a vector at a specific index, or removing a key from a map&#x2F;set, etc).</div><br/></div></div><div id="38806144" class="c"><input type="checkbox" id="c-38806144" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38810359">prev</a><span>|</span><a href="#38807208">next</a><span>|</span><label class="collapse" for="c-38806144">[-]</label><label class="expand" for="c-38806144">[5 more]</label></div><br/><div class="children"><div class="content">A mutable approach requires a write ahead log meaning you have to copy the data twice on every write which seems worse.</div><br/><div id="38810278" class="c"><input type="checkbox" id="c-38810278" checked=""/><div class="controls bullet"><span class="by">iambvk</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806144">parent</a><span>|</span><a href="#38806298">next</a><span>|</span><label class="collapse" for="c-38810278">[-]</label><label class="expand" for="c-38810278">[1 more]</label></div><br/><div class="children"><div class="content">It is: two writes for write ahead log vs. log-n (tree-height) writes for CoW</div><br/></div></div><div id="38806298" class="c"><input type="checkbox" id="c-38806298" checked=""/><div class="controls bullet"><span class="by">vajrabum</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806144">parent</a><span>|</span><a href="#38810278">prev</a><span>|</span><a href="#38807208">next</a><span>|</span><label class="collapse" for="c-38806298">[-]</label><label class="expand" for="c-38806298">[3 more]</label></div><br/><div class="children"><div class="content">In a well designed database system (hardware!) you aren&#x27;t going to use the same CPU, disk or controller to write the log and the data structure. So the performance penalty if any is going to be low.</div><br/><div id="38808235" class="c"><input type="checkbox" id="c-38808235" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806298">parent</a><span>|</span><a href="#38806591">next</a><span>|</span><label class="collapse" for="c-38808235">[-]</label><label class="expand" for="c-38808235">[1 more]</label></div><br/><div class="children"><div class="content">Low but non 0 and you’re still duplicating the values written to disk. So your SSD lifetime is decreased and this is effectively a RAID0 layout which means data loss is risky too.</div><br/></div></div><div id="38806591" class="c"><input type="checkbox" id="c-38806591" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38806298">parent</a><span>|</span><a href="#38808235">prev</a><span>|</span><a href="#38807208">next</a><span>|</span><label class="collapse" for="c-38806591">[-]</label><label class="expand" for="c-38806591">[1 more]</label></div><br/><div class="children"><div class="content">Now you’re paying for double the hardware.</div><br/></div></div></div></div></div></div><div id="38807208" class="c"><input type="checkbox" id="c-38807208" checked=""/><div class="controls bullet"><span class="by">halayli</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38806144">prev</a><span>|</span><a href="#38809120">next</a><span>|</span><label class="collapse" for="c-38807208">[-]</label><label class="expand" for="c-38807208">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re comparing apples and oranges. Anytime you write&#x2F;modify on an SSD you&#x27;re writing on a new page. So you might as well leverage this behavior to your advantage. It has several benefits when it comes to implementing transactions.</div><br/></div></div><div id="38809120" class="c"><input type="checkbox" id="c-38809120" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38807208">prev</a><span>|</span><a href="#38808920">next</a><span>|</span><label class="collapse" for="c-38809120">[-]</label><label class="expand" for="c-38809120">[1 more]</label></div><br/><div class="children"><div class="content">The biggest cost to copy-on-write data structures is write magnification.  Adding a log to amortize that cost helps a lot.  That&#x27;s what the ZFS intent log does.  Any CoW b-tree scheme can benefit from that approach.<p>The benefits of CoW data structures are tremendous:<p><pre><code>  - easy to reason about
  - easy to multi-thread for reading
  - O(1) snashopts (and clones)
</code></pre>
The downsides of CoW data structures are mainly:<p><pre><code>  - the need to amortize write magnification
  - difficulty in multi-threading writes</code></pre></div><br/></div></div><div id="38808920" class="c"><input type="checkbox" id="c-38808920" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38809120">prev</a><span>|</span><a href="#38806811">next</a><span>|</span><label class="collapse" for="c-38808920">[-]</label><label class="expand" for="c-38808920">[2 more]</label></div><br/><div class="children"><div class="content">You probably need something special for batch operations. Adding five records in one transaction shouldn’t pay &gt;= 5 times as much as a single one.<p>You need a different API for something like that however.</div><br/><div id="38810389" class="c"><input type="checkbox" id="c-38810389" checked=""/><div class="controls bullet"><span class="by">joshlemer</span><span>|</span><a href="#38806105">root</a><span>|</span><a href="#38808920">parent</a><span>|</span><a href="#38806811">next</a><span>|</span><label class="collapse" for="c-38810389">[-]</label><label class="expand" for="c-38810389">[1 more]</label></div><br/><div class="children"><div class="content">Yes, for instance Clojure&#x27;s &quot;transients&quot; as well as the JavaScript &quot;immer&quot; library</div><br/></div></div></div></div><div id="38806811" class="c"><input type="checkbox" id="c-38806811" checked=""/><div class="controls bullet"><span class="by">valenterry</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38808920">prev</a><span>|</span><a href="#38808046">next</a><span>|</span><label class="collapse" for="c-38806811">[-]</label><label class="expand" for="c-38806811">[1 more]</label></div><br/><div class="children"><div class="content">That usually happens when you try to work with immutable data structures like you are used to with mutable datastructures.<p>For example, if you append to a mutable list then it&#x27;s going to be fast. But prepending to it is much slower. With immutable lists, it&#x27;s the other way around. Not knowing that will make you think that immutable datastructures are generally slow, but they are not.<p>That being said, I would say they are generally more tricky, so it&#x27;s good to understand in which cases it&#x27;s worth to sacrifize safety and readability and switch to mutable datastructures for performance reasons.</div><br/></div></div><div id="38808046" class="c"><input type="checkbox" id="c-38808046" checked=""/><div class="controls bullet"><span class="by">teo_zero</span><span>|</span><a href="#38806105">parent</a><span>|</span><a href="#38806811">prev</a><span>|</span><a href="#38807055">next</a><span>|</span><label class="collapse" for="c-38808046">[-]</label><label class="expand" for="c-38808046">[1 more]</label></div><br/><div class="children"><div class="content">IF reads dominate writes, and multiple threads read the data concurrently, this approach may win by eliminating the need for locks.</div><br/></div></div></div></div><div id="38807055" class="c"><input type="checkbox" id="c-38807055" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#38806105">prev</a><span>|</span><a href="#38810232">next</a><span>|</span><label class="collapse" for="c-38807055">[-]</label><label class="expand" for="c-38807055">[1 more]</label></div><br/><div class="children"><div class="content">Some years ago I was playing around with the idea of an append-only splay tree for storing a database file. The thinking was that the algorithm would keep recently-<i>accessed</i> items at the business end of the log (in addition to any new&#x2F;updated&#x2F;deleted items).<p>This concept is clearly quite heavy on writes, but the tradeoff is that you would then have the ability to expire unused entries simply by picking an offset in the log and chopping everything that precedes it. Any record accessed more recently than that cutoff point would be guaranteed to have been written one or more times later on in the log.<p><i>Any</i> access would result in a new modified tree &amp; root node being written, but the prototype did batch IO using an MPSC queue abstraction which meant that I could amortize things a bit. Multiple transactions could fit in a single IO command if they are issued from different threads, occur within a small slice of time and are smaller than the block size.</div><br/></div></div><div id="38810232" class="c"><input type="checkbox" id="c-38810232" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#38807055">prev</a><span>|</span><a href="#38809402">next</a><span>|</span><label class="collapse" for="c-38810232">[-]</label><label class="expand" for="c-38810232">[1 more]</label></div><br/><div class="children"><div class="content">One thing that&#x27;s not explicitly mentioned: append-only trees necessarily lack `parent` pointers.<p>This means that your &quot;iterator&quot; can&#x27;t be a lightweight type, it has to contain an array of parent nodes to visit (again) later. You can use a fixed-size array if you can reason about the maximum height of the tree (for a balanced binary tree, this means around `2*POINTER_BITS`, which is 1024 bytes on a 64-bit platform; it will be less for a B-tree (`2*log(POINTER_MAX, CHILDREN_PER_NODE)`) but you now have to either track or re-scan for the index of the child you just returned from). Beware buffer overflow logic bugs if your tree isn&#x27;t as balanced as you thought!</div><br/></div></div><div id="38809402" class="c"><input type="checkbox" id="c-38809402" checked=""/><div class="controls bullet"><span class="by">hlship</span><span>|</span><a href="#38810232">prev</a><span>|</span><a href="#38807384">next</a><span>|</span><label class="collapse" for="c-38809402">[-]</label><label class="expand" for="c-38809402">[3 more]</label></div><br/><div class="children"><div class="content">In such a system, how does a reader find the root node?  I&#x27;d be concerned about a) readers seeing a partial write to disk (or page buffer) during an update or b) a crash while the writer writes to disk.<p>I could imagine using two files, one containing the actual b-tree, the second containing the offset to the latest root note; the second file gets overwritten only after a successful write is verifiably written to disk.<p>Datomic&#x27;s (<a href="https:&#x2F;&#x2F;www.datomic.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.datomic.com&#x2F;</a>) architecture is similar to this, but uses many write-once &quot;segments&quot; (which could be files in EFS or S3, or rows in DynamoDB or other stores).</div><br/><div id="38809530" class="c"><input type="checkbox" id="c-38809530" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38809402">parent</a><span>|</span><a href="#38809492">next</a><span>|</span><label class="collapse" for="c-38809530">[-]</label><label class="expand" for="c-38809530">[1 more]</label></div><br/><div class="children"><div class="content">The pointer to the root tree node is stored in the last committed metadata page.  A read transaction starts with the reading of the metadata page.  Reaching the partial written pages is impossible as the writer has not committed the latest metadata page yet.  The transaction is committed when the latest metadata page is written as the last step.</div><br/></div></div><div id="38809492" class="c"><input type="checkbox" id="c-38809492" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#38809402">parent</a><span>|</span><a href="#38809530">prev</a><span>|</span><a href="#38807384">next</a><span>|</span><label class="collapse" for="c-38809492">[-]</label><label class="expand" for="c-38809492">[1 more]</label></div><br/><div class="children"><div class="content">There’s a “canonical” pointer to the root node which is updated atomically on every append.<p>For an in-memory database, a CAS is  adequate. Persistent stores ultimately need some kind of file-level locking.<p>If you look at the Apache Iceberg spec, you get a good idea of how this works: The only “mutability” in that universe is the root table pointer in the catalog.</div><br/></div></div></div></div><div id="38807384" class="c"><input type="checkbox" id="c-38807384" checked=""/><div class="controls bullet"><span class="by">paulsutter</span><span>|</span><a href="#38809402">prev</a><span>|</span><a href="#38806450">next</a><span>|</span><label class="collapse" for="c-38807384">[-]</label><label class="expand" for="c-38807384">[1 more]</label></div><br/><div class="children"><div class="content">Every historical version of the database is available as a snapshot. The metadata block should point back to previous meta block(s), not just the new root<p>And of course emphasizing the closing statement:<p>&gt; there is no need for a transaction log, because the database file is the transaction log</div><br/></div></div><div id="38806450" class="c"><input type="checkbox" id="c-38806450" checked=""/><div class="controls bullet"><span class="by">zogomoox</span><span>|</span><a href="#38807384">prev</a><span>|</span><a href="#38807721">next</a><span>|</span><label class="collapse" for="c-38806450">[-]</label><label class="expand" for="c-38806450">[4 more]</label></div><br/><div class="children"><div class="content">Instead of cloning the branches all the way up to root, wouldn&#x27;t it be more efficient to just write delta-records, so a structure per inner node that says &quot;it&#x27;s like this original node, but with the following modifications x,y,z&quot;</div><br/><div id="38807190" class="c"><input type="checkbox" id="c-38807190" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#38806450">parent</a><span>|</span><a href="#38806832">next</a><span>|</span><label class="collapse" for="c-38807190">[-]</label><label class="expand" for="c-38807190">[1 more]</label></div><br/><div class="children"><div class="content">Efficient in what way?<p>Yes, a delta record would be smaller. But now you have to fetch both the new and the old, plus do computation to figure out what you have. This is trading off space and time.<p>I&#x27;m going to go to a reasonably low level to explain this.<p>Databases have generally found that the right tradeoff between space and time is to always work in terms of pages of fixed size. Now all reads are memory aligned, of known size. All writes are as well. And inside the CPU, processing a page in the most straightforward and predictable way possible is very fast. In particular you want to avoid complex logic that introduces too many pipeline stalls.<p>If you&#x27;re going to work with pages anyways, you want to find ways to fetch as few pages as possible. Only have this page point to that page where you really need to. And put as much as reasonable on each page. The name of the game is to fetch as few pages as you need, and get everything you need from a page when you fetch it. Because when you&#x27;re getting a new page, often you have to wait for a disk read. That&#x27;s slow. It used to be really slow, you needed to wait for the right part of the disk to rotate around. Those disks went at something like 7200 rpm, but that means 120 revolutions per second, which means you&#x27;re waiting for anywhere from 0 to 8.333... milliseconds for the read. Now consider reading through a million record database...<p>That&#x27;s where a BTree comes in. It is a tree structure built around a page layout. When a page gets too full, it is split and one record is promoted to the level above. When the top page gets too full, a new level is created at top. That keeps it perfectly balanced at all times. So you can get to any record in very few reads. And if you&#x27;re walking the whole data structure, a single page generally has many records.</div><br/></div></div><div id="38806832" class="c"><input type="checkbox" id="c-38806832" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#38806450">parent</a><span>|</span><a href="#38807190">prev</a><span>|</span><a href="#38807721">next</a><span>|</span><label class="collapse" for="c-38806832">[-]</label><label class="expand" for="c-38806832">[2 more]</label></div><br/><div class="children"><div class="content">You may want to rebalance a tree, or you may want to have multiple readers while a writer exists without relying on mutexes or locking.</div><br/><div id="38806880" class="c"><input type="checkbox" id="c-38806880" checked=""/><div class="controls bullet"><span class="by">zogomoox</span><span>|</span><a href="#38806450">root</a><span>|</span><a href="#38806832">parent</a><span>|</span><a href="#38807721">next</a><span>|</span><label class="collapse" for="c-38806880">[-]</label><label class="expand" for="c-38806880">[1 more]</label></div><br/><div class="children"><div class="content">as long as you don&#x27;t modify the original nodes that would still work, no locks needed.</div><br/></div></div></div></div></div></div><div id="38807721" class="c"><input type="checkbox" id="c-38807721" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#38806450">prev</a><span>|</span><a href="#38809825">next</a><span>|</span><label class="collapse" for="c-38807721">[-]</label><label class="expand" for="c-38807721">[1 more]</label></div><br/><div class="children"><div class="content">One enhancement I&#x27;ve toyed with in the past is to have subtrees beneath each leaf node for the historical data for each record. You switch the indexing value to the timestamp of record insertion time or a TX number and keep inserting in append-only fashion. There&#x27;s some enhancements you can make because the common case is for the key to be a monotonically increasing number, but nothing is strictly necessary. I&#x27;d love to build a datalog system on top of something like that at some point, even if it&#x27;s just for fun.</div><br/></div></div><div id="38809825" class="c"><input type="checkbox" id="c-38809825" checked=""/><div class="controls bullet"><span class="by">toolslive</span><span>|</span><a href="#38807721">prev</a><span>|</span><a href="#38809687">next</a><span>|</span><label class="collapse" for="c-38809825">[-]</label><label class="expand" for="c-38809825">[2 more]</label></div><br/><div class="children"><div class="content">with append-only data structures, you could turn the fact that you rewrite the path from the node to the root to your advantage and rebalance. This means you abandon the &quot;balanced&quot; property and use update statistics to get an optimal shape. Who cares about the length of paths to parts of the tree you never visit?</div><br/><div id="38813769" class="c"><input type="checkbox" id="c-38813769" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38809825">parent</a><span>|</span><a href="#38809687">next</a><span>|</span><label class="collapse" for="c-38813769">[-]</label><label class="expand" for="c-38813769">[1 more]</label></div><br/><div class="children"><div class="content">this is how splay trees work, but you might actually care about the lengths of paths to parts of the tree you rarely visit; for many real systems, worst-case response time is more important than throughput</div><br/></div></div></div></div><div id="38809687" class="c"><input type="checkbox" id="c-38809687" checked=""/><div class="controls bullet"><span class="by">JensRantil</span><span>|</span><a href="#38809825">prev</a><span>|</span><label class="collapse" for="c-38809687">[-]</label><label class="expand" for="c-38809687">[2 more]</label></div><br/><div class="children"><div class="content">IIRC, this is how CouchDB was implemented. The benefit is that it was resilient to crash without needing a write-ahead log. The downside was that it required running background compaction of the B+tree regularly.</div><br/><div id="38809735" class="c"><input type="checkbox" id="c-38809735" checked=""/><div class="controls bullet"><span class="by">josephg</span><span>|</span><a href="#38809687">parent</a><span>|</span><label class="collapse" for="c-38809735">[-]</label><label class="expand" for="c-38809735">[1 more]</label></div><br/><div class="children"><div class="content">LMDB works the same way. But it also stores a second data structure on disk listing all free blocks. Writes preferentially take free blocks when they’re available. The result is it doesn’t need any special compaction step. It sort of automatically compacts constantly.</div><br/></div></div></div></div></div></div></div></div></div></body></html>