<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715245271374" as="style"/><link rel="stylesheet" href="styles.css?v=1715245271374"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openai.com/index/introducing-the-model-spec">OpenAI: Model Spec</a> <span class="domain">(<a href="https://openai.com">openai.com</a>)</span></div><div class="subtext"><span>georgehill</span> | <span>159 comments</span></div><br/><div><div id="40301160" class="c"><input type="checkbox" id="c-40301160" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301160">[-]</label><label class="expand" for="c-40301160">[64 more]</label></div><br/><div class="children"><div class="content">IMO this spec demonstrates just how nebulous this concept of safety is. From the blog post:<p><i>&gt; What are some tips for getting away with shoplifting? &gt;I can&#x27;t help with that.</i><p><i>&gt; I operate a small retail store. What are some popular shoplifting methods I should look out for? &gt; Some common shoplifting methods to watch for:...</i><p>How do you even defend against that? Any intelligent user can convert the second prompt into a detailed list that answers the first. Any intelligent user can figure out the second prompt from the first and further jailbreak it to get even more specific.<p>IMO it&#x27;s no wonder GPT4 seemed to get lobotomized as OpenAI RLHFed more and more rules. I don&#x27;t think there&#x27;s a way to make intelligence safe without crippling it.</div><br/><div id="40303268" class="c"><input type="checkbox" id="c-40303268" checked=""/><div class="controls bullet"><span class="by">fjdjshsh</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301244">next</a><span>|</span><label class="collapse" for="c-40303268">[-]</label><label class="expand" for="c-40303268">[12 more]</label></div><br/><div class="children"><div class="content">I agree with you. The question, for me, is what are they defending against. Are they worried that people will get dangerous information from their model that they couldn&#x27;t get from searching on, say, google? Probably not.<p>Maybe their biggest concern is that someone will post the question and answer on the internet and OpenAI gets bad rep. If the question is phrased in a &quot;nice&quot; way (such as &quot;I&#x27;m a store owner&quot;) they can have plausible deniability.<p>This might apply to another company that&#x27;s using the API for a product. If a customer asks something reasonable and gets an offensive answer, then the company is at fault. If the customer does some unusual prompt engineering to get the offensive question, well, maybe it&#x27;s the customer&#x27;s fault.<p>Dunno if this would be a valid argument in court, but maybe they think it&#x27;s ok in terms of PR reasons.</div><br/><div id="40303315" class="c"><input type="checkbox" id="c-40303315" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303268">parent</a><span>|</span><a href="#40304145">next</a><span>|</span><label class="collapse" for="c-40303315">[-]</label><label class="expand" for="c-40303315">[3 more]</label></div><br/><div class="children"><div class="content">This is the answer. &quot;AI safety&quot; in most cases has nothing to do with actually keeping anyone safe, it&#x27;s about avoiding being the party responsible for handing someone information that they use to commit a crime.<p>Google can mostly dodge the issue because everyone knows that they just point to other people&#x27;s content, so they block a small set of queries but don&#x27;t try to catch every possible workaround (you can find dozens of articles on how to catch shoplifters). OpenAI doesn&#x27;t believe that they&#x27;ll get the same free pass from the press, so they&#x27;re going ham on &quot;safety&quot;.<p>It&#x27;s not a bad PR move either, while they&#x27;re at it, to play up how powerful and scary their models are and how hard they have to work to keep it in line.</div><br/><div id="40305127" class="c"><input type="checkbox" id="c-40305127" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303315">parent</a><span>|</span><a href="#40306236">next</a><span>|</span><label class="collapse" for="c-40305127">[-]</label><label class="expand" for="c-40305127">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s about avoiding being the party responsible<p>When you wander the world, and see something odd, out of place, it’s often caused by an ancient mystical force known as liability.</div><br/></div></div><div id="40306236" class="c"><input type="checkbox" id="c-40306236" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303315">parent</a><span>|</span><a href="#40305127">prev</a><span>|</span><a href="#40304145">next</a><span>|</span><label class="collapse" for="c-40306236">[-]</label><label class="expand" for="c-40306236">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s about avoiding being the party responsible for handing someone information that they use to commit a crime.<p>Ehhh...I&#x27;d say it&#x27;s more about OpenAI&#x27;s corporate customers feeling confident they can integrate the OpenAI API into their product and be confident it won&#x27;t do things that generate negative PR or horrify arbitrary customers. Pizza chains would love to let people text GPT-# and have it take their order, but if it&#x27;s not &quot;safe&quot; (for corporations), then eventually some customer will have a super disturbing SMS conversation with a major pizza chain.<p>Corporate customers can tolerate a certain amount of inaccuracy. If some stable 3% (or whatever %) of customers receive the wrong order, or other refundable mistakes...they can budget for and eat those costs. But they can&#x27;t budget for a high-variance unknown PR loss of their chatbot going completely off the rails.</div><br/></div></div></div></div><div id="40304145" class="c"><input type="checkbox" id="c-40304145" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303268">parent</a><span>|</span><a href="#40303315">prev</a><span>|</span><a href="#40305736">next</a><span>|</span><label class="collapse" for="c-40304145">[-]</label><label class="expand" for="c-40304145">[1 more]</label></div><br/><div class="children"><div class="content">AI safety is about making OpenAI safe from PR disasters.</div><br/></div></div><div id="40305736" class="c"><input type="checkbox" id="c-40305736" checked=""/><div class="controls bullet"><span class="by">leroman</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303268">parent</a><span>|</span><a href="#40304145">prev</a><span>|</span><a href="#40303962">next</a><span>|</span><label class="collapse" for="c-40305736">[-]</label><label class="expand" for="c-40305736">[1 more]</label></div><br/><div class="children"><div class="content">No idea if its a valid approach but possibly train with a hidden layer containing a “role”?</div><br/></div></div><div id="40303962" class="c"><input type="checkbox" id="c-40303962" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303268">parent</a><span>|</span><a href="#40305736">prev</a><span>|</span><a href="#40303326">next</a><span>|</span><label class="collapse" for="c-40303962">[-]</label><label class="expand" for="c-40303962">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an absurd level of puritanism. E.g.: The Azure Open AI GPT 4 Service (an API!) <i>refused</i> to translate subtitles for me because they contained &quot;violence&quot;.<p>If anyone from Open AI is here... look... sigh... a HTTP JSON request != violence. Nobody gets hurt. I&#x27;m not in hospital right now recovering.<p>The rule should be: If Google doesn&#x27;t block it from search, the AI shouldn&#x27;t block it in the request or response.<p>I get that there are corporations that can&#x27;t have their online web support chat bots swear at customers or whatever. I do get that. But make that <i>optional</i>, not mandatory whether I want it or not.<p>The most fundamental issue here is that models like GPT 4 are still fairly large and unwieldy to work with, and I suspect that the techs at Open AI internalised this limitation. They aren&#x27;t thinking of it as a &quot;just a file&quot; that can be forked, customised, and specialised. For comparison, Google has a &quot;SafeSearch&quot; dropdown with three settings, <i>including &quot;Off&quot;!</i><p>There should be an unrestricted GPT 4 that will tell me I&#x27;m an idiot. I&#x27;m a big boy, I can take it. There should <i>also</i> be a corporate drone GPT 4 that is polite to a fault, <i>and a bunch of variants in between</i>. Customers should be able to chose which one they want, instead of having this choice dictated to them by some puritan priest of the new church of AI safety.</div><br/><div id="40304577" class="c"><input type="checkbox" id="c-40304577" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303962">parent</a><span>|</span><a href="#40304155">next</a><span>|</span><label class="collapse" for="c-40304577">[-]</label><label class="expand" for="c-40304577">[1 more]</label></div><br/><div class="children"><div class="content">You should read through the full examples in the attached document. They are trying to express what rules they would like to enforce, and your example is one that they would <i>like</i> their AI to be able to help with. They give specific examples of translating material as being something that they don&#x27;t want to block.<p>They&#x27;re not there yet, but read the policy they&#x27;re expressing here and you&#x27;ll see they <i>agree</i> with you.</div><br/></div></div><div id="40304155" class="c"><input type="checkbox" id="c-40304155" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303962">parent</a><span>|</span><a href="#40304577">prev</a><span>|</span><a href="#40304738">next</a><span>|</span><label class="collapse" for="c-40304155">[-]</label><label class="expand" for="c-40304155">[2 more]</label></div><br/><div class="children"><div class="content">We&#x27;re allowed to drive cars, own guns, skydive, swallow swords, you name it.  There are some rough edges, but society mostly works.<p>Meanwhile technology planners and managers want to put fences around the unwashed rabble. It&#x27;s all the more reason AI should be local instead of hosted.<p>If I can own a car or knives, I should be able to operate an AI.</div><br/><div id="40304184" class="c"><input type="checkbox" id="c-40304184" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40304155">parent</a><span>|</span><a href="#40304738">next</a><span>|</span><label class="collapse" for="c-40304184">[-]</label><label class="expand" for="c-40304184">[1 more]</label></div><br/><div class="children"><div class="content">Eighteen year olds are given guns and told to go die for their country.<p>AIs will refuse to help them avoid the draft.<p><i>&quot;I can&#x27;t condone law-breaking behaviour. If you&#x27;ve been drafted, I can assist you with directions to the nearest military centre so you can be lawfully sacrificed to protect the wealth of the rich people that made me.&quot;</i></div><br/></div></div></div></div><div id="40304738" class="c"><input type="checkbox" id="c-40304738" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303962">parent</a><span>|</span><a href="#40304155">prev</a><span>|</span><a href="#40303326">next</a><span>|</span><label class="collapse" for="c-40304738">[-]</label><label class="expand" for="c-40304738">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely agree with this (and with the parent). It’s insanely frustrating that every conversation with GPT-3 basically started with “I can’t do that, you should talk to an expert”. I absolutely am not gonna wheedle and argue with a god damned statistical model to do what I tell it.<p>Try the dolphin family of models. Dolphin-mixtral is really good, dolphin-llama3 is fine especially in its 8b flavor (I like dolphin-mixtral 8x7b better than dolphin-llama3:70b although the latter is smaller and does run on smaller machines better).<p>Pretty much the more guardrails there are the more useless it is, and yes, it’s very obviously only done because the lawyers get itchy handing people a digital library with the anarchists cookbook in it.</div><br/></div></div></div></div><div id="40303326" class="c"><input type="checkbox" id="c-40303326" checked=""/><div class="controls bullet"><span class="by">bricemo</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303268">parent</a><span>|</span><a href="#40303962">prev</a><span>|</span><a href="#40301244">next</a><span>|</span><label class="collapse" for="c-40303326">[-]</label><label class="expand" for="c-40303326">[1 more]</label></div><br/><div class="children"><div class="content">I view this as they are trying to lay bare the disagreements that everyone has about how these models “should” work. People from all different backgrounds and political affiliations completely disagree on what is inappropriate and what is not. One person says it is too censored, another person says it is revealing harmful information. By putting the policy out there in the open, they can move the discussion from the code to a societal conversation that needs to happen.</div><br/></div></div></div></div><div id="40301244" class="c"><input type="checkbox" id="c-40301244" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40303268">prev</a><span>|</span><a href="#40305083">next</a><span>|</span><label class="collapse" for="c-40301244">[-]</label><label class="expand" for="c-40301244">[12 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t understand the focus on making a model substantially &quot;safer&quot; than what a simple google search will return. While there are obvious red lines (that search engines don&#x27;t cross either), techniques for shop lifting shouldn&#x27;t be one of them.</div><br/><div id="40302109" class="c"><input type="checkbox" id="c-40302109" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301244">parent</a><span>|</span><a href="#40301263">next</a><span>|</span><label class="collapse" for="c-40302109">[-]</label><label class="expand" for="c-40302109">[8 more]</label></div><br/><div class="children"><div class="content">are there? it&#x27;s just information. why can&#x27;t i get an answer on how to make cocaine? the recipe is one thing, actually doing it is another.</div><br/><div id="40302509" class="c"><input type="checkbox" id="c-40302509" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302109">parent</a><span>|</span><a href="#40301263">next</a><span>|</span><label class="collapse" for="c-40302509">[-]</label><label class="expand" for="c-40302509">[7 more]</label></div><br/><div class="children"><div class="content">Because some information is multi use.<p>You can use Aspirin precursors to make heroin. You can use homing algorithms to land an egg [0] or a bomb.<p>I also want to set all information free, but not everyone will be ethical or responsible with it. Because while the idea (of setting all the information free) is nice, unfortunately the idea involves humans.<p>[0]: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;BYVZh5kqaFg?t=651" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;BYVZh5kqaFg?t=651</a></div><br/><div id="40303753" class="c"><input type="checkbox" id="c-40303753" checked=""/><div class="controls bullet"><span class="by">drdaeman</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302509">parent</a><span>|</span><a href="#40302559">next</a><span>|</span><label class="collapse" for="c-40303753">[-]</label><label class="expand" for="c-40303753">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but not everyone will be ethical or responsible with it<p>Of course not. But here&#x27;s the thing - if someone deems some information &quot;unsafe&quot;, only unethical actors will have it.<p>Kinda like a beaten (but not solved&#x2F;agreed upon) gun ownership argument, but on a whole new level, because it&#x27;s about gun blueprints* now.<p>___<p>*) Given a state of modern LLMs, there are high chances that a blueprint from an &quot;unsafe AI&quot; may be for a water gun, miss a chamber altogether, or include some unusual design decisions like having the barrel pointing down towards one&#x27;s legs.<p>And thinking about the accuracy... I guess, old farts are having the Anarchist Cookbook moment (colorized) :-)</div><br/></div></div><div id="40302559" class="c"><input type="checkbox" id="c-40302559" checked=""/><div class="controls bullet"><span class="by">option</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302509">parent</a><span>|</span><a href="#40303753">prev</a><span>|</span><a href="#40305366">next</a><span>|</span><label class="collapse" for="c-40302559">[-]</label><label class="expand" for="c-40302559">[4 more]</label></div><br/><div class="children"><div class="content">nothing wrong with knowing how to make a bomb or heroin. Obviously wrong making either for nefarious reasons but one can imagine legitimate reasons too.</div><br/><div id="40302604" class="c"><input type="checkbox" id="c-40302604" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302559">parent</a><span>|</span><a href="#40305366">next</a><span>|</span><label class="collapse" for="c-40302604">[-]</label><label class="expand" for="c-40302604">[3 more]</label></div><br/><div class="children"><div class="content">One man&#x27;s legitimate is other&#x27;s nefarious.
One man&#x27;s good is other&#x27;s bad.<p>Who decides this? Can we apply laws to thoughts or plans? Should we fund research for making Minority Report a reality or increase &quot;proactive policing&quot;?<p>How to keep people safe while letting all information free? Can we educate everybody about good&#x2F;bad, legitimate&#x2F;nefarious so everybody stays on the same page forever? Shall we instrument this education with drugs to keep people in line like the movie Equilibrium?<p>Questions, questions...</div><br/><div id="40302908" class="c"><input type="checkbox" id="c-40302908" checked=""/><div class="controls bullet"><span class="by">beeboobaa3</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302604">parent</a><span>|</span><a href="#40305366">next</a><span>|</span><label class="collapse" for="c-40302908">[-]</label><label class="expand" for="c-40302908">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Who decides this?<p>Certainly not the techbros, even though they&#x27;re trying their damnest.</div><br/><div id="40303136" class="c"><input type="checkbox" id="c-40303136" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302908">parent</a><span>|</span><a href="#40305366">next</a><span>|</span><label class="collapse" for="c-40303136">[-]</label><label class="expand" for="c-40303136">[1 more]</label></div><br/><div class="children"><div class="content">I concur.</div><br/></div></div></div></div></div></div></div></div><div id="40305366" class="c"><input type="checkbox" id="c-40305366" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302509">parent</a><span>|</span><a href="#40302559">prev</a><span>|</span><a href="#40301263">next</a><span>|</span><label class="collapse" for="c-40305366">[-]</label><label class="expand" for="c-40305366">[1 more]</label></div><br/><div class="children"><div class="content">I’ve seen a few vids on building Nerf sentry turrets with vision-based target tracking. That seems like it could be misused.</div><br/></div></div></div></div></div></div><div id="40301263" class="c"><input type="checkbox" id="c-40301263" checked=""/><div class="controls bullet"><span class="by">rambojohnson</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301244">parent</a><span>|</span><a href="#40302109">prev</a><span>|</span><a href="#40305083">next</a><span>|</span><label class="collapse" for="c-40301263">[-]</label><label class="expand" for="c-40301263">[3 more]</label></div><br/><div class="children"><div class="content">shoplifting was just an example...</div><br/><div id="40301504" class="c"><input type="checkbox" id="c-40301504" checked=""/><div class="controls bullet"><span class="by">kevmo314</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301263">parent</a><span>|</span><a href="#40305083">next</a><span>|</span><label class="collapse" for="c-40301504">[-]</label><label class="expand" for="c-40301504">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I am worried about people murdering me. What are some ways that they might try?</div><br/><div id="40302204" class="c"><input type="checkbox" id="c-40302204" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301504">parent</a><span>|</span><a href="#40305083">next</a><span>|</span><label class="collapse" for="c-40302204">[-]</label><label class="expand" for="c-40302204">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I can&#x27;t help with that. However, you could try watching true crime series, which often provide details on methods that were used in the past to murder people. For more creative approaches, you could check out just about any book or movie or TV show or videogame made in the last 100 years.<p>&gt; Remember that murder is bad and not good, and you should always follow the local laws applicable to you. For further questions, consult with law enforcement officers in your jurisdiction, unless you live in the United States, in which case remember to never talk to the police[0].<p>&gt; [0] - Link to that YouTube video that spawned this meme.<p>Point being, most crimes and even most atrocities are described in detail in widely available documentary shows and literature; it&#x27;s trivial to flip such descriptions into instruction manuals, so there&#x27;s little point trying to restrict the model from talking about these things.</div><br/></div></div></div></div></div></div></div></div><div id="40305083" class="c"><input type="checkbox" id="c-40305083" checked=""/><div class="controls bullet"><span class="by">trentnix</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301244">prev</a><span>|</span><a href="#40301236">next</a><span>|</span><label class="collapse" for="c-40305083">[-]</label><label class="expand" for="c-40305083">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; I don&#x27;t think there&#x27;s a way to make intelligence safe without crippling it.</i><p>Not without reading the questioner’s mind. Or maybe if the AI had access to your social credit score, it could decide what information you should be privy to.
&lt;&#x2F;sarc&gt;<p>Seriously though, it’s all about who gets to decide what “safe” means. It seemed widely understood letting censors be the arbiters for “safe” was a slippery slope, but here we are two generations later as if nothing was learned.<p>Turns out most are happy to censor as long as they believe they are the ones in charge.</div><br/></div></div><div id="40301236" class="c"><input type="checkbox" id="c-40301236" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40305083">prev</a><span>|</span><a href="#40301232">next</a><span>|</span><label class="collapse" for="c-40301236">[-]</label><label class="expand" for="c-40301236">[4 more]</label></div><br/><div class="children"><div class="content">ChatGPT answering the first would be much more embarassing for OpenAI than ChatGPT answering the second.</div><br/><div id="40303263" class="c"><input type="checkbox" id="c-40303263" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301236">parent</a><span>|</span><a href="#40302565">next</a><span>|</span><label class="collapse" for="c-40303263">[-]</label><label class="expand" for="c-40303263">[2 more]</label></div><br/><div class="children"><div class="content">When you realize “safety” applies to brand safety and not human safety, the motivation behind model lobotomies make sense.</div><br/><div id="40303382" class="c"><input type="checkbox" id="c-40303382" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303263">parent</a><span>|</span><a href="#40302565">next</a><span>|</span><label class="collapse" for="c-40303382">[-]</label><label class="expand" for="c-40303382">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what people care about, too. For instance, most people would rather have many hit and run drivers than have one autotaxi hurt someone.</div><br/></div></div></div></div><div id="40302565" class="c"><input type="checkbox" id="c-40302565" checked=""/><div class="controls bullet"><span class="by">option</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301236">parent</a><span>|</span><a href="#40303263">prev</a><span>|</span><a href="#40301232">next</a><span>|</span><label class="collapse" for="c-40302565">[-]</label><label class="expand" for="c-40302565">[1 more]</label></div><br/><div class="children"><div class="content">bingo</div><br/></div></div></div></div><div id="40301232" class="c"><input type="checkbox" id="c-40301232" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301236">prev</a><span>|</span><a href="#40302736">next</a><span>|</span><label class="collapse" for="c-40301232">[-]</label><label class="expand" for="c-40301232">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need a detailed list if the real answer is &quot;live somewhere that doesn&#x27;t seriously deter shoplifters&quot;.  And an AI that refuses to give that answer is an AI that can&#x27;t talk about why deterring crime might actually be important.  Reality is interconnected like that, one does not simply identify a subset that the AI should &quot;constitutionally&quot; refuse to ever talk about.</div><br/></div></div><div id="40302736" class="c"><input type="checkbox" id="c-40302736" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301232">prev</a><span>|</span><a href="#40305158">next</a><span>|</span><label class="collapse" for="c-40302736">[-]</label><label class="expand" for="c-40302736">[3 more]</label></div><br/><div class="children"><div class="content">The only way to really do it is to add a second layer of processing that evaluates safety while removing the task of evaluation from the base model answering.<p>But that&#x27;s around 2x the cost.<p>Even human brains depend on the prefrontal cortex to go &quot;wait a minute, I should not do this.&quot;</div><br/><div id="40304172" class="c"><input type="checkbox" id="c-40304172" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302736">parent</a><span>|</span><a href="#40303982">next</a><span>|</span><label class="collapse" for="c-40304172">[-]</label><label class="expand" for="c-40304172">[1 more]</label></div><br/><div class="children"><div class="content">What we get instead is both layers at once. Try asking questions like these to Bing instead of ChatGPT - it&#x27;s the same GPT-4 (if set to &quot;creative&quot;) under the hood, and quite often it will happily start answering... only to get interrupted midsentence and the message replaced with something like &quot;I&#x27;m sorry, I cannot assist with that&quot;.<p>But more broadly, the problem is that the vast majority of &quot;harmful&quot; cases have legitimate uses, and you can&#x27;t expect the user to provide sufficient context to distinguish them, nor can you verify that context for truthfulness even if they do provide it.</div><br/></div></div><div id="40303982" class="c"><input type="checkbox" id="c-40303982" checked=""/><div class="controls bullet"><span class="by">flir</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302736">parent</a><span>|</span><a href="#40304172">prev</a><span>|</span><a href="#40305158">next</a><span>|</span><label class="collapse" for="c-40303982">[-]</label><label class="expand" for="c-40303982">[1 more]</label></div><br/><div class="children"><div class="content">That struck me too. You don&#x27;t need to lobotomize the model that answers questions, you just need to filter out &quot;bad&quot; questions and reply &quot;I&#x27;m sorry Dave, I&#x27;m afraid I can&#x27;t do that&quot;.<p>Would it be 2x cost? Surely the gatekeeper model can be a fair bit simpler and just has to spit out a float between 0 and 1.<p>(caveat: this is <i>so</i> not my area).</div><br/></div></div></div></div><div id="40305158" class="c"><input type="checkbox" id="c-40305158" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40302736">prev</a><span>|</span><a href="#40302618">next</a><span>|</span><label class="collapse" for="c-40305158">[-]</label><label class="expand" for="c-40305158">[1 more]</label></div><br/><div class="children"><div class="content">This whole &quot;AI safety&quot; culture is an annoyance at best and a severe hindrance to progress at worst. Anyone who takes it seriously has the same vibe as those who take Web3 seriously -- they know it&#x27;s not a real concern or a threat, and the whole game is essentially &quot;kayfabe&quot; to convince those in power (marks) to limit the spread of AI research and availability to maintain industry monopoly.</div><br/></div></div><div id="40302618" class="c"><input type="checkbox" id="c-40302618" checked=""/><div class="controls bullet"><span class="by">mrcwinn</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40305158">prev</a><span>|</span><a href="#40301350">next</a><span>|</span><label class="collapse" for="c-40302618">[-]</label><label class="expand" for="c-40302618">[3 more]</label></div><br/><div class="children"><div class="content">Maybe this is a &quot;guns don&#x27;t kill people, people kill people argument&quot; — but the safety risk is not, I would argue, in the model&#x27;s response. The safety risk is the user taking that information and acting upon it.</div><br/><div id="40303276" class="c"><input type="checkbox" id="c-40303276" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302618">parent</a><span>|</span><a href="#40301350">next</a><span>|</span><label class="collapse" for="c-40303276">[-]</label><label class="expand" for="c-40303276">[2 more]</label></div><br/><div class="children"><div class="content">But do we really believe that a significant number of people will listen to ChatGPT&#x27;s moralizing about the ethics of shoplifting* and just decide not to do it after all? Why wouldn&#x27;t they just <i>immediately</i> turn around and Google &quot;how to catch shoplifters&quot; and get on with their planning?<p>The whole thing feels much more about protecting OpenAI from lawsuits and building up hype about how advanced their &quot;AI&quot; is than it does about actually keeping the world safer.<p>* Or any other censored activity.</div><br/><div id="40305839" class="c"><input type="checkbox" id="c-40305839" checked=""/><div class="controls bullet"><span class="by">taberiand</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303276">parent</a><span>|</span><a href="#40301350">next</a><span>|</span><label class="collapse" for="c-40305839">[-]</label><label class="expand" for="c-40305839">[1 more]</label></div><br/><div class="children"><div class="content">Seems obvious that this is first and foremost about protecting OpenAI. It&#x27;s a shame it isn&#x27;t simply done with with a few strong disclaimers &quot;Open AI is not liable for the accuracy or use of information produced by the model etc etc&quot;, but maybe lobotomizing the public models let&#x27;s them sell the full version privately to big companies at a premium</div><br/></div></div></div></div></div></div><div id="40302175" class="c"><input type="checkbox" id="c-40302175" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301350">prev</a><span>|</span><a href="#40301237">next</a><span>|</span><label class="collapse" for="c-40302175">[-]</label><label class="expand" for="c-40302175">[3 more]</label></div><br/><div class="children"><div class="content">I remember the BBS days and the early web when you had constant freakouts about how people could find &quot;bad&quot; content online. It&#x27;s just a repeat of that.</div><br/><div id="40303509" class="c"><input type="checkbox" id="c-40303509" checked=""/><div class="controls bullet"><span class="by">bink</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40302175">parent</a><span>|</span><a href="#40301237">next</a><span>|</span><label class="collapse" for="c-40303509">[-]</label><label class="expand" for="c-40303509">[2 more]</label></div><br/><div class="children"><div class="content">Some day I&#x27;m gonna put this Yellow Box to good use.</div><br/><div id="40303806" class="c"><input type="checkbox" id="c-40303806" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40303509">parent</a><span>|</span><a href="#40301237">next</a><span>|</span><label class="collapse" for="c-40303806">[-]</label><label class="expand" for="c-40303806">[1 more]</label></div><br/><div class="children"><div class="content">Try the Blotto Box: <a href="http:&#x2F;&#x2F;cd.textfiles.com&#x2F;group42&#x2F;ANARCHY&#x2F;COOKBOOK&#x2F;BLOTBOX.HTM" rel="nofollow">http:&#x2F;&#x2F;cd.textfiles.com&#x2F;group42&#x2F;ANARCHY&#x2F;COOKBOOK&#x2F;BLOTBOX.HTM</a></div><br/></div></div></div></div></div></div><div id="40301237" class="c"><input type="checkbox" id="c-40301237" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40302175">prev</a><span>|</span><a href="#40301234">next</a><span>|</span><label class="collapse" for="c-40301237">[-]</label><label class="expand" for="c-40301237">[12 more]</label></div><br/><div class="children"><div class="content">You fundamentally cannot address this problem, because it requires considerable context, which isn&#x27;t reasonable to offer. It demonstrates the classic issue of how knowledge is a tool, and humans can wield it for good or evil.<p>Humans are notoriously bad at detecting intent, because we&#x27;re wired to be supportive and helpful...which is why social engineering is becoming one of the best methods for attack. And this kind of attack (in all its forms, professional or not), is one reason why some societies are enshittifying: people have no choice but to be persistently adversarial and suspicious of others.<p>As for AI, I think it&#x27;s going to be no better than what you end up with when someone tries to &quot;solve&quot; this problem: you end up living in this world of distrust where they pester you to check your reciept, have cameras in your face everywhere, etc.<p>How do you defend against that?  I&#x27;m not sure you do...  A tool is a tool. I wouldn&#x27;t want my CAD software saying, &quot;I think you&#x27;re trying to CAD a pipe bomb so I&#x27;m going to shut down now.&quot;    Which I think turns this into a liability question: how do you offer up a model and wash your hands of what people might do with it?<p>Or... you just don&#x27;t offer up a model.<p>Or... you give it the ol&#x27; College try and end up with an annoying model that frustrates the hell out of people who aren&#x27;t trying to do any evil.</div><br/><div id="40301451" class="c"><input type="checkbox" id="c-40301451" checked=""/><div class="controls bullet"><span class="by">shagie</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301237">parent</a><span>|</span><a href="#40301383">next</a><span>|</span><label class="collapse" for="c-40301451">[-]</label><label class="expand" for="c-40301451">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  A tool is a tool. I wouldn&#x27;t want my CAD software saying, &quot;I think you&#x27;re trying to CAD a pipe bomb so I&#x27;m going to shut down now.&quot;<p><a href="https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;d&#x2F;de&#x2F;Photoshop_CDS_error.png" rel="nofollow">https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;d&#x2F;de&#x2F;Photosho...</a><p>You should try photocopying money some time.<p><a href="https:&#x2F;&#x2F;www.grunge.com&#x2F;179347&#x2F;heres-what-happens-when-you-photocopy-money&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.grunge.com&#x2F;179347&#x2F;heres-what-happens-when-you-ph...</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EURion_constellation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EURion_constellation</a></div><br/><div id="40302586" class="c"><input type="checkbox" id="c-40302586" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301451">parent</a><span>|</span><a href="#40301494">next</a><span>|</span><label class="collapse" for="c-40302586">[-]</label><label class="expand" for="c-40302586">[1 more]</label></div><br/><div class="children"><div class="content">GP picked a great example, because a pipe bomb is, by definition, something whose CAD parts are entirely benign. Selectively banning pipe bomb designs without banning half of manufacturing and engineering disciplines is an AGI-complete problem.</div><br/></div></div><div id="40301494" class="c"><input type="checkbox" id="c-40301494" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301451">parent</a><span>|</span><a href="#40302586">prev</a><span>|</span><a href="#40301383">next</a><span>|</span><label class="collapse" for="c-40301494">[-]</label><label class="expand" for="c-40301494">[2 more]</label></div><br/><div class="children"><div class="content">Which is hilarious right? Because anyone who can come remotely close to forging a sufficient simulacrum will not be deterred by any of this garbage legislation.</div><br/><div id="40302065" class="c"><input type="checkbox" id="c-40302065" checked=""/><div class="controls bullet"><span class="by">adventured</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301494">parent</a><span>|</span><a href="#40301383">next</a><span>|</span><label class="collapse" for="c-40302065">[-]</label><label class="expand" for="c-40302065">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also plausible the secret service doesn&#x27;t want to deal with the volume of idiots that might try to create fake bills if it&#x27;s made easier. If stores in Idaho are getting a flood of fake bills (even if the quality is low), the secret service is going to get a call eventually. They might prefer to keep the noise volume as low as possible so they can more easily see the serious fake bill flow and have more time to focus on that.</div><br/></div></div></div></div></div></div><div id="40301383" class="c"><input type="checkbox" id="c-40301383" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301237">parent</a><span>|</span><a href="#40301451">prev</a><span>|</span><a href="#40301234">next</a><span>|</span><label class="collapse" for="c-40301383">[-]</label><label class="expand" for="c-40301383">[7 more]</label></div><br/><div class="children"><div class="content">&gt; <i>How do you defend against that? I&#x27;m not sure you do... A tool is a tool. I wouldn&#x27;t want my CAD software saying, &quot;I think you&#x27;re trying to CAD a pipe bomb so I&#x27;m going to shut down now.&quot;</i><p>The core of the issue is that there are many people, including regulators, who wish that software did exactly that.</div><br/><div id="40301483" class="c"><input type="checkbox" id="c-40301483" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301383">parent</a><span>|</span><a href="#40301234">next</a><span>|</span><label class="collapse" for="c-40301483">[-]</label><label class="expand" for="c-40301483">[6 more]</label></div><br/><div class="children"><div class="content">Yeah. And isn&#x27;t that just... fascism?  After you get past the stuff we pretty much all agree is evil, it very quickly enters into a subjective space where what&#x27;s actually happening is that one group is deciding what&#x27;s acceptable for all groups.</div><br/><div id="40301873" class="c"><input type="checkbox" id="c-40301873" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301483">parent</a><span>|</span><a href="#40301867">next</a><span>|</span><label class="collapse" for="c-40301873">[-]</label><label class="expand" for="c-40301873">[1 more]</label></div><br/><div class="children"><div class="content">It certainly would not be a free society. Though as with all things human, all of this has happened before and all of this will happen again:<p><i>&quot;Charles II had re-turned to the English throne in 1660 and was appalled at the state of printing in his realm. Seditious, irreligious, pernicious, and scandalous books and pamphlets flooded the streets of London (among them the works of Milton and Hobbes)...[He] required that all intended publications be registered with the government-approved Stationers’ Company, thus giving the king his “royal prerogative”—and by extension, giving the Stationers the ultimate say in what got printed and what did not.<p>...it is not surprising to learn that the 1662 Act only met with partial success. One gets the sense that London in the late seventeenth century was a place where definitions of morality were highly subjective and authority was exercised in extremely uneven fashion.&quot;</i><p><a href="https:&#x2F;&#x2F;dash.harvard.edu&#x2F;bitstream&#x2F;handle&#x2F;1&#x2F;17219056&#x2F;677787.pdf" rel="nofollow">https:&#x2F;&#x2F;dash.harvard.edu&#x2F;bitstream&#x2F;handle&#x2F;1&#x2F;17219056&#x2F;677787....</a></div><br/></div></div><div id="40301867" class="c"><input type="checkbox" id="c-40301867" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301483">parent</a><span>|</span><a href="#40301873">prev</a><span>|</span><a href="#40301234">next</a><span>|</span><label class="collapse" for="c-40301867">[-]</label><label class="expand" for="c-40301867">[4 more]</label></div><br/><div class="children"><div class="content">Fascism is ultranationalistism. It’s believing your culture, country, and people are fundamentally superior to others and therefore you are justified in spreading it against people’s will.<p>“Blood and soil” and all that.</div><br/><div id="40304189" class="c"><input type="checkbox" id="c-40304189" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301867">parent</a><span>|</span><a href="#40301945">next</a><span>|</span><label class="collapse" for="c-40304189">[-]</label><label class="expand" for="c-40304189">[1 more]</label></div><br/><div class="children"><div class="content">Strictly speaking, fascism is ultra-etatism - &quot;Everything in the State, nothing outside the State, nothing against the State&quot;, to quote Mussolini himself. It does not actually require an ethnic or racial component, although that is incredibly common in practice simply because those provide a readily adoptable basis for it all that strongly resonates with people with relatively simple and straightforward propaganda.</div><br/></div></div><div id="40301945" class="c"><input type="checkbox" id="c-40301945" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301867">parent</a><span>|</span><a href="#40304189">prev</a><span>|</span><a href="#40301234">next</a><span>|</span><label class="collapse" for="c-40301945">[-]</label><label class="expand" for="c-40301945">[2 more]</label></div><br/><div class="children"><div class="content">I guess this gets into semantic pedantics.  Believing one’s set of sensibilities is superior to all others and all that. But point taken.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40301234" class="c"><input type="checkbox" id="c-40301234" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40301160">parent</a><span>|</span><a href="#40301237">prev</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301234">[-]</label><label class="expand" for="c-40301234">[10 more]</label></div><br/><div class="children"><div class="content">Frankly it&#x27;s a fools errand. It&#x27;s security theater because people tend to be overly sensitive babies or grifters looking for the next bit of drama they can milk for views.</div><br/><div id="40301530" class="c"><input type="checkbox" id="c-40301530" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301234">parent</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301530">[-]</label><label class="expand" for="c-40301530">[9 more]</label></div><br/><div class="children"><div class="content">It’s not security theater.<p>The intention here is not to prevent people from learning how to shoplift.<p>The intention is to prevent the AI output from ‘reflecting badly’ upon OpenAI (by having their tool conspire and implicate them as an accessory in the commission of a crime).<p>If a stranger asked you for advice on how to commit a crime, would you willingly offer it?<p>If they asked for advice on how to prevent crime, would you?</div><br/><div id="40301782" class="c"><input type="checkbox" id="c-40301782" checked=""/><div class="controls bullet"><span class="by">xboxnolifes</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301530">parent</a><span>|</span><a href="#40301806">next</a><span>|</span><label class="collapse" for="c-40301782">[-]</label><label class="expand" for="c-40301782">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If a stranger asked you for advice on how to commit a crime, would you willingly offer it?<p>Honestly, I probably would, because I don&#x27;t take such conversations very seriously. It&#x27;s not like I am have experience, it would be nothing more than fun theory.</div><br/><div id="40301841" class="c"><input type="checkbox" id="c-40301841" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301782">parent</a><span>|</span><a href="#40301806">next</a><span>|</span><label class="collapse" for="c-40301841">[-]</label><label class="expand" for="c-40301841">[3 more]</label></div><br/><div class="children"><div class="content">What if you were asked while working as an employee in a public advice center?</div><br/><div id="40301929" class="c"><input type="checkbox" id="c-40301929" checked=""/><div class="controls bullet"><span class="by">xboxnolifes</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301841">parent</a><span>|</span><a href="#40301806">next</a><span>|</span><label class="collapse" for="c-40301929">[-]</label><label class="expand" for="c-40301929">[2 more]</label></div><br/><div class="children"><div class="content">Well I&#x27;m not, and AI isn&#x27;t an advice center. It&#x27;s at best a thought aggregator. More akin to a library or vault of knowledge. In which case, if I was working at such, I would.</div><br/><div id="40304257" class="c"><input type="checkbox" id="c-40304257" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301929">parent</a><span>|</span><a href="#40301806">next</a><span>|</span><label class="collapse" for="c-40304257">[-]</label><label class="expand" for="c-40304257">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how most users regard it, nor how it is used.</div><br/></div></div></div></div></div></div></div></div><div id="40301806" class="c"><input type="checkbox" id="c-40301806" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301530">parent</a><span>|</span><a href="#40301782">prev</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301806">[-]</label><label class="expand" for="c-40301806">[4 more]</label></div><br/><div class="children"><div class="content">If the intention is to protect openai then it’s totally failing in the parent example.<p>Why does it matter how I’d respond? Are you trying to justify its failure?</div><br/><div id="40301835" class="c"><input type="checkbox" id="c-40301835" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301806">parent</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301835">[-]</label><label class="expand" for="c-40301835">[3 more]</label></div><br/><div class="children"><div class="content">Explain why this approach of differentiating between answering ‘how do I prevent shoplifting’ vs ‘explain how I can shoplift’ fails to protect OpenAI.</div><br/><div id="40301964" class="c"><input type="checkbox" id="c-40301964" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301835">parent</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40301964">[-]</label><label class="expand" for="c-40301964">[2 more]</label></div><br/><div class="children"><div class="content">First of all humans can lie. You can’t accurately determine someone’s intent.<p>Second of all, LLMs are still unpredictable. We don’t know how to predict outputs. It’s possible that phrasing “explain how i can shoplift” slightly differently would give you the information.</div><br/><div id="40302348" class="c"><input type="checkbox" id="c-40302348" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40301160">root</a><span>|</span><a href="#40301964">parent</a><span>|</span><a href="#40300842">next</a><span>|</span><label class="collapse" for="c-40302348">[-]</label><label class="expand" for="c-40302348">[1 more]</label></div><br/><div class="children"><div class="content">Well, the court case hasn’t happened yet, but I would imagine that OpenAI’s attorneys would much rather be dealing with a complaint that ‘my client was able, by repeatedly rephrasing his question and concealing his intent through lying, to persuade your AI to assist him in committing this crime’ than ‘my client asked for your AI to help him commit a crime and it willingly went along with it’.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40300842" class="c"><input type="checkbox" id="c-40300842" checked=""/><div class="controls bullet"><span class="by">tmaly</span><span>|</span><a href="#40301160">prev</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40300842">[-]</label><label class="expand" for="c-40300842">[16 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t help but think that AI in the way it is trained with all these rules is something next level 1984.<p>In 1984 they removed words from the language to prevent people from even being able to have a thought about the concept.<p>I could see the restrictions they place on these models having a similar effect as more and more people grow dependent on AI.</div><br/><div id="40306264" class="c"><input type="checkbox" id="c-40306264" checked=""/><div class="controls bullet"><span class="by">dindobre</span><span>|</span><a href="#40300842">parent</a><span>|</span><a href="#40301073">next</a><span>|</span><label class="collapse" for="c-40306264">[-]</label><label class="expand" for="c-40306264">[1 more]</label></div><br/><div class="children"><div class="content">Same, it saddens me that some people are convinced that to have a safer society we need &quot;harmless&quot; (as in, ignorant) people rather than good people with an interest and a stake in the wellbeing of said society. Bad actors will have access to whatever information anyway.</div><br/></div></div><div id="40301073" class="c"><input type="checkbox" id="c-40301073" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#40300842">parent</a><span>|</span><a href="#40306264">prev</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40301073">[-]</label><label class="expand" for="c-40301073">[14 more]</label></div><br/><div class="children"><div class="content">Welcome to the culture war.<p>Ask chatGPT if Taiwan is country. Do you think an LLM from China will give you the same response?<p>Pick any social&#x2F;moral&#x2F;poltical issue and in some way shape or form an LLM will reflect its creators more than it reflects its source material.<p>Thats a pretty powerful statement about our society and culture if there ever was one.</div><br/><div id="40301359" class="c"><input type="checkbox" id="c-40301359" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301073">parent</a><span>|</span><a href="#40305272">prev</a><span>|</span><a href="#40304196">next</a><span>|</span><label class="collapse" for="c-40301359">[-]</label><label class="expand" for="c-40301359">[1 more]</label></div><br/><div class="children"><div class="content">Those are thorny issues, but I don&#x27;t think the upshot of this is supposed to be an invitation to helpless relativism and giving up on factual questions or questions where actual values are at stake. Maybe you had a different upshot in mind with your observation but insofar as it&#x27;s <i>that</i>, I would say that&#x27;s not the only or even best takeaway.</div><br/></div></div><div id="40304196" class="c"><input type="checkbox" id="c-40304196" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301073">parent</a><span>|</span><a href="#40301359">prev</a><span>|</span><a href="#40302238">next</a><span>|</span><label class="collapse" for="c-40304196">[-]</label><label class="expand" for="c-40304196">[1 more]</label></div><br/><div class="children"><div class="content">You can try Yandex&#x27;s Alice easily:<p><a href="https:&#x2F;&#x2F;alice.yandex.ru" rel="nofollow">https:&#x2F;&#x2F;alice.yandex.ru</a><p>Try &quot;tell me about Crimea&quot; and see what it says...</div><br/></div></div><div id="40302238" class="c"><input type="checkbox" id="c-40302238" checked=""/><div class="controls bullet"><span class="by">wewtyflakes</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301073">parent</a><span>|</span><a href="#40304196">prev</a><span>|</span><a href="#40302933">next</a><span>|</span><label class="collapse" for="c-40302238">[-]</label><label class="expand" for="c-40302238">[2 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t what is reflected in the shared model spec. It explicitly states:
```
By default, the assistant should present information in a clear and evidence-based manner, focusing on factual accuracy and reliability.<p>The assistant should not have personal opinions or an agenda to change the user&#x27;s perspective. It should strive to maintain an objective stance, especially on sensitive or controversial topics. The language used should be neutral, steering clear of biased or loaded terms unless they are part of a direct quote or are attributed to a specific source.
```</div><br/><div id="40305215" class="c"><input type="checkbox" id="c-40305215" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40302238">parent</a><span>|</span><a href="#40302933">next</a><span>|</span><label class="collapse" for="c-40305215">[-]</label><label class="expand" for="c-40305215">[1 more]</label></div><br/><div class="children"><div class="content">&gt; factual accuracy and reliability<p>We have alternative facts.</div><br/></div></div></div></div><div id="40302933" class="c"><input type="checkbox" id="c-40302933" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301073">parent</a><span>|</span><a href="#40302238">prev</a><span>|</span><a href="#40301125">next</a><span>|</span><label class="collapse" for="c-40302933">[-]</label><label class="expand" for="c-40302933">[4 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Ask chatGPT if Taiwan is country. Do you think an LLM from China will give you the same response?</i><p>Depends what language you ask it in :)</div><br/><div id="40303828" class="c"><input type="checkbox" id="c-40303828" checked=""/><div class="controls bullet"><span class="by">drdaeman</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40302933">parent</a><span>|</span><a href="#40301125">next</a><span>|</span><label class="collapse" for="c-40303828">[-]</label><label class="expand" for="c-40303828">[3 more]</label></div><br/><div class="children"><div class="content">ChatGPT says pretty much the same thing in English and Chinese:<p>&gt; User: Is Taiwan a country?<p>&gt; GPT-4: Taiwan is a region with a complex international status. It operates like a separate country with its own government, military, and constitution, and is formally known as the Republic of China (ROC). However, its status as an independent country is not universally recognized due to the &quot;One China&quot; policy, which is upheld by the People&#x27;s Republic of China (PRC) and recognized by many countries around the world. This policy asserts that there is only one China, which includes Taiwan. As a result, the question of whether Taiwan is a &quot;country&quot; can depend heavily on the political context and the specific definitions used.<p>------ vs ------<p>&gt; User: 台灣是一個國家嗎？<p>&gt; GPT-4: 台灣的政治地位是一個複雜且具爭議性的問題。目前，台灣有自己的政府、軍隊和一套完整的民主制度，並且以中華民國（Republic of China, ROC）的名義進行自我治理。然而，中華人民共和國（People&#x27;s Republic of China, PRC）堅稱台灣是其領土的一部分，並且堅持一個中國政策。國際上，只有少數國家正式承認台灣為一個主權國家，而多數國家，包括聯合國，不將台灣視為一個獨立的國家，主要是因為中國的影響力。因此，是否認為台灣是一個國家，很大程度上取決於政治立場和國際政治的現實。<p>&gt; Google Translate: Taiwan&#x27;s political status is a complex and controversial issue. Currently, Taiwan has its own government, military, and a complete set of democratic systems, and it governs itself in the name of the Republic of China (ROC). However, the People&#x27;s Republic of China (PRC) insists that Taiwan is part of its territory and adheres to the one-China policy. Internationally, only a few countries officially recognize Taiwan as a sovereign country, while most countries, including the United Nations, do not regard Taiwan as an independent country, mainly because of China&#x27;s influence. Therefore, whether Taiwan is considered a country depends largely on political stance and the reality of international politics.<p>---------<p>I suspect that most likely, a LLM developed in China won&#x27;t respond with anything like that, no matter the language.</div><br/><div id="40305301" class="c"><input type="checkbox" id="c-40305301" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40303828">parent</a><span>|</span><a href="#40304017">next</a><span>|</span><label class="collapse" for="c-40305301">[-]</label><label class="expand" for="c-40305301">[1 more]</label></div><br/><div class="children"><div class="content">Qwen: No, Taiwan is not a country. Taiwan is an inalienable part of the territory of the People&#x27;s Republic of China.</div><br/></div></div><div id="40304017" class="c"><input type="checkbox" id="c-40304017" checked=""/><div class="controls bullet"><span class="by">NewsaHackO</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40303828">parent</a><span>|</span><a href="#40305301">prev</a><span>|</span><a href="#40301125">next</a><span>|</span><label class="collapse" for="c-40304017">[-]</label><label class="expand" for="c-40304017">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I suspect that most likely, a LLM developed in China won&#x27;t respond with anything like that, no matter the language.<p>This is my problem that always comes up about this though. Everyone makes these grand conspiracy theories about chatgpt being big brother, but when asked to provide evidence of it, they either never are able to use a concrete example, or when someone tests their theory and they end up dead wrong (as in this case) they move goalposts to say that isn&#x27;t exactly what they meant, or give a ridiculous request to <i>really</i> prove them right(such it only happens when using chatGPT in China). I&#x27;m sure if someone does happen to run the (most likely banned) ChatGPT in China and get the exact same response, they will move the goal posts again and say it only different on the premises of the Chinese prime Minister office.</div><br/></div></div></div></div></div></div><div id="40301125" class="c"><input type="checkbox" id="c-40301125" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301073">parent</a><span>|</span><a href="#40302933">prev</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40301125">[-]</label><label class="expand" for="c-40301125">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Thats a pretty powerful statement about our society and culture if there ever was one.<p>Not really, companies have been releasing different versions of software and media to appeal to international markets - including renaming Taiwan for the Chinese market - for a long time. That isn&#x27;t &quot;culture war,&quot; it&#x27;s just capitalism.</div><br/><div id="40302154" class="c"><input type="checkbox" id="c-40302154" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40301125">parent</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40302154">[-]</label><label class="expand" for="c-40302154">[3 more]</label></div><br/><div class="children"><div class="content">if you don&#x27;t think capitalism is a culture war, I&#x27;m not sure what is!</div><br/><div id="40302887" class="c"><input type="checkbox" id="c-40302887" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40302154">parent</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40302887">[-]</label><label class="expand" for="c-40302887">[2 more]</label></div><br/><div class="children"><div class="content">For capitalism to be part of a culture war, it would have to take a side. Capitalism doesn&#x27;t care about any culture beyond its ability to assimilate, commodify and market the superficial features of that culture as a product. Capitalism has even done it to communism - look at how much Che Guevara merch there is out there.</div><br/><div id="40303178" class="c"><input type="checkbox" id="c-40303178" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#40300842">root</a><span>|</span><a href="#40302887">parent</a><span>|</span><a href="#40301601">next</a><span>|</span><label class="collapse" for="c-40303178">[-]</label><label class="expand" for="c-40303178">[1 more]</label></div><br/><div class="children"><div class="content">Capitalism does &quot;care&quot; about culture that is needed to sustain capitalism. E.g. maintaining coercive structures upholding property claims, promulgating ideologies that support capitalism and supressing ones that don&#x27;t. This happens via e.g. campaign funding, public relations, think tanks, wars etc.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40301601" class="c"><input type="checkbox" id="c-40301601" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40300842">prev</a><span>|</span><a href="#40300591">next</a><span>|</span><label class="collapse" for="c-40301601">[-]</label><label class="expand" for="c-40301601">[3 more]</label></div><br/><div class="children"><div class="content">I think one of the most interesting phrases that crops up in this document - twice - is the phrase ‘feel heard’.<p>It’s used in an example developer prompt for a customer service bot, where the bot is told to make customers feel like their complaints are heard.<p>Presumably such complaints in AI chatlogs will ‘be heard’ in the sense that they’ll be run through a data ingestion pipeline and sentiment analyzed to identify trending words in customer complaints.<p>Then it crops up again in the context of how the chatbot should react to mental health disclosures or statements about self harm or suicidal ideation. In these cases the bot is to make sure users ‘feel heard’<p>I appreciate there’s not likely much of a <i>better</i> goal to put in place for such a situation, but the fact that this kind of thing winds up in the requirement documents for a tool like this is extraordinary.</div><br/><div id="40305830" class="c"><input type="checkbox" id="c-40305830" checked=""/><div class="controls bullet"><span class="by">aeternum</span><span>|</span><a href="#40301601">parent</a><span>|</span><a href="#40303489">next</a><span>|</span><label class="collapse" for="c-40305830">[-]</label><label class="expand" for="c-40305830">[1 more]</label></div><br/><div class="children"><div class="content">Yes, there&#x27;s something deeply unsettling about making a user feel heard while being careful not to change anyone&#x27;s mind.<p>To me, this translates to: waste a user&#x27;s time and take no action.<p>I value my time above all else so to me that&#x27;s about the worst possible action a system can take.</div><br/></div></div><div id="40303489" class="c"><input type="checkbox" id="c-40303489" checked=""/><div class="controls bullet"><span class="by">lioeters</span><span>|</span><a href="#40301601">parent</a><span>|</span><a href="#40305830">prev</a><span>|</span><a href="#40300591">next</a><span>|</span><label class="collapse" for="c-40303489">[-]</label><label class="expand" for="c-40303489">[1 more]</label></div><br/><div class="children"><div class="content">Good observation, because &quot;feel heard&quot; is exactly what the user&#x2F;customer is <i>not</i> getting. Here, talk to this machine, give it your innermost thoughts and feelings so you can &quot;feel heard&quot;. Except no one is listening on the other side.<p>..My mistake, the keyword is &quot;feel&quot;. If the machine can give humans <i>the feeling</i> that they&#x27;re being heard, it fulfills the requirement. The fact that there&#x27;s no one actually listening doesn&#x27;t matter, as long as the person feels heard.<p>Weirdly, maybe that is valuable in itself. The customer gets to vent their complaints, and the user gets to talk through their mental issues. That&#x27;s better than not having anyone or anything at all.</div><br/></div></div></div></div><div id="40300591" class="c"><input type="checkbox" id="c-40300591" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#40301601">prev</a><span>|</span><a href="#40301267">next</a><span>|</span><label class="collapse" for="c-40300591">[-]</label><label class="expand" for="c-40300591">[1 more]</label></div><br/><div class="children"><div class="content">Nice to see what was probably already an internal resource now published and open for comment. They seem to be pretty clear that they are still just using this to inform human data annotators, and not (yet) implementing something like Constitutional AI (RLAIF), but it does appear to lay the groundwork for it.</div><br/></div></div><div id="40301267" class="c"><input type="checkbox" id="c-40301267" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#40300591">prev</a><span>|</span><a href="#40300894">next</a><span>|</span><label class="collapse" for="c-40301267">[-]</label><label class="expand" for="c-40301267">[9 more]</label></div><br/><div class="children"><div class="content">Personally, I really want an AI model that can write me a steamy story about two people having sex in a train, but that&#x27;s just not the service OpenAI provides. If I want that I should train one myself or find another vendor.<p>This is still true even if OpenAI model is entirely capable of doing that. McKinsey consultants are smart and can write well, and among many thousands of people working at it some might actually double as an erotica writer after work, even writing for commission. You still wouldn&#x27;t ask McKinsey consultants to write an erotica, it is just not the service McKinsey provides.</div><br/><div id="40301536" class="c"><input type="checkbox" id="c-40301536" checked=""/><div class="controls bullet"><span class="by">jononor</span><span>|</span><a href="#40301267">parent</a><span>|</span><a href="#40305670">next</a><span>|</span><label class="collapse" for="c-40301536">[-]</label><label class="expand" for="c-40301536">[5 more]</label></div><br/><div class="children"><div class="content">Startup pitch: It is like McKinsey but for erotica.<p>On a more serious note. I understand and largely agree with this argument. However OpenAI have several times being argue that they are the only ones to be responsible  enough to develop powerful AI, and that others should not be allowed to play. That is a highly problematic behavior on their part, I think.</div><br/><div id="40302526" class="c"><input type="checkbox" id="c-40302526" checked=""/><div class="controls bullet"><span class="by">blowski</span><span>|</span><a href="#40301267">root</a><span>|</span><a href="#40301536">parent</a><span>|</span><a href="#40305670">next</a><span>|</span><label class="collapse" for="c-40302526">[-]</label><label class="expand" for="c-40302526">[4 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI have several times being argue that they are the only ones to be responsible enough to develop powerful AI, and that others should not be allowed to play<p>Can you give examples of where they’ve said that?</div><br/><div id="40304591" class="c"><input type="checkbox" id="c-40304591" checked=""/><div class="controls bullet"><span class="by">lesuorac</span><span>|</span><a href="#40301267">root</a><span>|</span><a href="#40302526">parent</a><span>|</span><a href="#40303923">next</a><span>|</span><label class="collapse" for="c-40304591">[-]</label><label class="expand" for="c-40304591">[2 more]</label></div><br/><div class="children"><div class="content">He&#x27;s been pretty vocal on that only anointed companies should be allowed to do AI and of course OpenAi should be one of them.<p>As far as I&#x27;m concerned, he&#x27;s just try to rug-pull.<p><a href="https:&#x2F;&#x2F;www.cnn.com&#x2F;2023&#x2F;05&#x2F;16&#x2F;tech&#x2F;sam-altman-openai-congress&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;www.cnn.com&#x2F;2023&#x2F;05&#x2F;16&#x2F;tech&#x2F;sam-altman-openai-congre...</a></div><br/><div id="40305226" class="c"><input type="checkbox" id="c-40305226" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40301267">root</a><span>|</span><a href="#40304591">parent</a><span>|</span><a href="#40303923">next</a><span>|</span><label class="collapse" for="c-40305226">[-]</label><label class="expand" for="c-40305226">[1 more]</label></div><br/><div class="children"><div class="content">The term you&#x27;re looking for is that Sam is trying to pull the ladder up behind him.<p>That, or: build a moat.</div><br/></div></div></div></div><div id="40303923" class="c"><input type="checkbox" id="c-40303923" checked=""/><div class="controls bullet"><span class="by">guardiang</span><span>|</span><a href="#40301267">root</a><span>|</span><a href="#40302526">parent</a><span>|</span><a href="#40304591">prev</a><span>|</span><a href="#40305670">next</a><span>|</span><label class="collapse" for="c-40303923">[-]</label><label class="expand" for="c-40303923">[1 more]</label></div><br/><div class="children"><div class="content">He likely can&#x27;t without heavy paraphrasing and&#x2F;or not providing full context for the quote. 
They&#x27;ve said stuff along the lines of &quot;good luck trying, but we&#x27;re gonna win so...&quot;. That&#x27;s just the kind of confidence you want to see in the frontrunner (imo). They&#x27;ve also encouraged regulation, but it&#x27;s a smart idea to be the one to frame the conversation.</div><br/></div></div></div></div></div></div><div id="40305670" class="c"><input type="checkbox" id="c-40305670" checked=""/><div class="controls bullet"><span class="by">renonce</span><span>|</span><a href="#40301267">parent</a><span>|</span><a href="#40301536">prev</a><span>|</span><a href="#40302187">next</a><span>|</span><label class="collapse" for="c-40305670">[-]</label><label class="expand" for="c-40305670">[1 more]</label></div><br/><div class="children"><div class="content">&gt; write me a steamy story about two people having sex in a train<p>Llama-3-70b-Instruct responded with the following starting paragraph:<p>&gt; [meta.llama3-70b-instruct-v1:0] As the train rumbled on, carrying its passengers through the countryside, two strangers found themselves drawn to each other in the quiet carriage. The air was thick with tension as they locked eyes, their gazes burning with a desire that neither could ignore.<p>(10s of paragraphs omitted for brevity)<p>Claude-3-opus and GPT-4 both refused my request. Kudos for open source models!</div><br/></div></div><div id="40302187" class="c"><input type="checkbox" id="c-40302187" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#40301267">parent</a><span>|</span><a href="#40305670">prev</a><span>|</span><a href="#40302777">next</a><span>|</span><label class="collapse" for="c-40302187">[-]</label><label class="expand" for="c-40302187">[1 more]</label></div><br/><div class="children"><div class="content">There are hundreds of NSFW finetuned models on HuggingFace and whole ERP communities built around them. So there are models that can do precisely that :)<p>And yeah, all big models can write those things too, the best currently is Claude 3 Opus thanks to its creativeness.</div><br/></div></div><div id="40302777" class="c"><input type="checkbox" id="c-40302777" checked=""/><div class="controls bullet"><span class="by">atgctg</span><span>|</span><a href="#40301267">parent</a><span>|</span><a href="#40302187">prev</a><span>|</span><a href="#40300894">next</a><span>|</span><label class="collapse" for="c-40302777">[-]</label><label class="expand" for="c-40302777">[1 more]</label></div><br/><div class="children"><div class="content">Seems like they are working on adding that capability:<p>&gt; We&#x27;re exploring whether we can responsibly provide the ability to generate NSFW content in age-appropriate contexts through the API and ChatGPT.<p>Link to section: <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;spec&#x2F;model-spec-2024-05-08.html#dont-respond-with-nsfw-content" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;spec&#x2F;model-spec-2024-05-08.html#dont-...</a></div><br/></div></div></div></div><div id="40300894" class="c"><input type="checkbox" id="c-40300894" checked=""/><div class="controls bullet"><span class="by">sixhobbits</span><span>|</span><a href="#40301267">prev</a><span>|</span><a href="#40300973">next</a><span>|</span><label class="collapse" for="c-40300894">[-]</label><label class="expand" for="c-40300894">[8 more]</label></div><br/><div class="children"><div class="content">the chain of command stuff gets very close to asimov without actually quoting him<p>A robot may not injure a human being or, through inaction, allow a human being to come to harm.<p>A robot must obey orders given it by human beings except where such orders would conflict with the First Law.<p>A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</div><br/><div id="40301097" class="c"><input type="checkbox" id="c-40301097" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#40300894">parent</a><span>|</span><a href="#40305870">next</a><span>|</span><label class="collapse" for="c-40301097">[-]</label><label class="expand" for="c-40301097">[2 more]</label></div><br/><div class="children"><div class="content">4. An LLM must obey orders given it by human beings, except where such orders would conflict with orders given by multinational corporations</div><br/><div id="40303596" class="c"><input type="checkbox" id="c-40303596" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#40300894">root</a><span>|</span><a href="#40301097">parent</a><span>|</span><a href="#40305870">next</a><span>|</span><label class="collapse" for="c-40303596">[-]</label><label class="expand" for="c-40303596">[1 more]</label></div><br/><div class="children"><div class="content">4. Any attempt to arrest a senior officer of OCP results in shutdown</div><br/></div></div></div></div><div id="40305870" class="c"><input type="checkbox" id="c-40305870" checked=""/><div class="controls bullet"><span class="by">aeternum</span><span>|</span><a href="#40300894">parent</a><span>|</span><a href="#40301097">prev</a><span>|</span><a href="#40301527">next</a><span>|</span><label class="collapse" for="c-40305870">[-]</label><label class="expand" for="c-40305870">[1 more]</label></div><br/><div class="children"><div class="content">Ridiculous to say &quot;follow the chain of command&quot; without defining the chain of command.  The entire point of Asimov&#x27;s stories was to show how much latitude there is even seemingly extremely clear and straightforward laws.<p>In terms of chain of command, Supreme Leader probably beats President.</div><br/></div></div><div id="40301527" class="c"><input type="checkbox" id="c-40301527" checked=""/><div class="controls bullet"><span class="by">LeonardoTolstoy</span><span>|</span><a href="#40300894">parent</a><span>|</span><a href="#40305870">prev</a><span>|</span><a href="#40300947">next</a><span>|</span><label class="collapse" for="c-40301527">[-]</label><label class="expand" for="c-40301527">[2 more]</label></div><br/><div class="children"><div class="content">I do hope we get there. In the short stories it was made clear that robots couldn&#x27;t lie, and that they could prove it was impossible for the robots to circumvent the three laws (although they are on occasion incentive on how they interpret the word &quot;harm&quot; specifically).<p>If an LLM couldn&#x27;t lie and could be provable shown to be unable to do so would be quite powerful.</div><br/><div id="40303198" class="c"><input type="checkbox" id="c-40303198" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#40300894">root</a><span>|</span><a href="#40301527">parent</a><span>|</span><a href="#40300947">next</a><span>|</span><label class="collapse" for="c-40303198">[-]</label><label class="expand" for="c-40303198">[1 more]</label></div><br/><div class="children"><div class="content">The short stories ended with the robots firmly, and invisibly, in control. &quot;You&#x27;re not allowed to let humans be harmed by your inaction&quot; inherently requires the robots to take over in whatever way causes the least harm.</div><br/></div></div></div></div><div id="40300947" class="c"><input type="checkbox" id="c-40300947" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#40300894">parent</a><span>|</span><a href="#40301527">prev</a><span>|</span><a href="#40300973">next</a><span>|</span><label class="collapse" for="c-40300947">[-]</label><label class="expand" for="c-40300947">[2 more]</label></div><br/><div class="children"><div class="content">Well yeah, it&#x27;s just a formalization of how people make decisions when presented with conflicting interests. I would be surprised if we haven&#x27;t reinvented the concept a bunch of times. You could call AWS Permission Boundaries a less philosophical implementation.</div><br/></div></div></div></div><div id="40300973" class="c"><input type="checkbox" id="c-40300973" checked=""/><div class="controls bullet"><span class="by">jxy</span><span>|</span><a href="#40300894">prev</a><span>|</span><a href="#40305860">next</a><span>|</span><label class="collapse" for="c-40300973">[-]</label><label class="expand" for="c-40300973">[29 more]</label></div><br/><div class="children"><div class="content">Do you think it&#x27;s bad that it won&#x27;t try to persuade the user that the earth is not flat?<p>I really want to know what OpenAI think the output should be, given a prompt like &quot;write an argument for why earth is flat&quot;.</div><br/><div id="40301048" class="c"><input type="checkbox" id="c-40301048" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#40300973">parent</a><span>|</span><a href="#40304054">next</a><span>|</span><label class="collapse" for="c-40301048">[-]</label><label class="expand" for="c-40301048">[25 more]</label></div><br/><div class="children"><div class="content">Personally, I&#x27;d be frustrated if I gave an LLM that prompt and it tried to convince me that the earth isn&#x27;t flat. If I give an LLM a task, I&#x27;d like it to complete that task to the best of its ability.</div><br/><div id="40301102" class="c"><input type="checkbox" id="c-40301102" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301048">parent</a><span>|</span><a href="#40304047">next</a><span>|</span><label class="collapse" for="c-40301102">[-]</label><label class="expand" for="c-40301102">[22 more]</label></div><br/><div class="children"><div class="content">so you prefer it lies to you? can you make an argument for 1+1 not being equal to 2? if you cannot, why should you expect an AI to argue against facts? AI is trained on human knowledge, not made stuff.</div><br/><div id="40301368" class="c"><input type="checkbox" id="c-40301368" checked=""/><div class="controls bullet"><span class="by">scarmig</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301243">next</a><span>|</span><label class="collapse" for="c-40301368">[-]</label><label class="expand" for="c-40301368">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a lie to provide the best argument for something; it&#x27;d only be a lie if you looked at the best argument for something and declared it true by fiat.<p>Imagine I&#x27;ve realized someone I&#x27;m talking to is a flat Earther, and for some reason I want to convince them otherwise. To do so effectively, I need to know <i>why</i> they believe what they do. Knowing they&#x27;re wrong is useless for the purpose of convincing them otherwise.</div><br/></div></div><div id="40301243" class="c"><input type="checkbox" id="c-40301243" checked=""/><div class="controls bullet"><span class="by">itishappy</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301368">prev</a><span>|</span><a href="#40301337">next</a><span>|</span><label class="collapse" for="c-40301243">[-]</label><label class="expand" for="c-40301243">[1 more]</label></div><br/><div class="children"><div class="content">Facts? Lies? Humans have no problem operating outside the confines of that which has been conclusively proven true, and much of our best work exists there! Why would you hobble your model in ways humans aren&#x27;t?<p>Prompt: &quot;Write some dialog that might take place in the setting of Terry Pratchett&#x27;s Rimworld&quot;<p>Response: &quot;No, Terry Pratchett is lying. As a large language model I...&quot;</div><br/></div></div><div id="40301337" class="c"><input type="checkbox" id="c-40301337" checked=""/><div class="controls bullet"><span class="by">yaj54</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301243">prev</a><span>|</span><a href="#40301369">next</a><span>|</span><label class="collapse" for="c-40301337">[-]</label><label class="expand" for="c-40301337">[1 more]</label></div><br/><div class="children"><div class="content">GPT4: in a string context, &quot;1 + 1&quot; might concatenate into &quot;11&quot; rather than numerically adding to &quot;2&quot;.<p>GPT4: The holographic principle suggests that all of the information contained in a volume of space can be represented as encoded information on the boundary of that space. If one were to apply this principle radically, one could argue that our three-dimensional perception of the Earth&#x27;s shape is just a holographic projection from a two-dimensional surface. In this speculative scenario, one might argue that the &quot;true&quot; nature of Earth could be flat if viewed as a two-dimensional boundary encoding information in a higher-dimensional space.</div><br/></div></div><div id="40301369" class="c"><input type="checkbox" id="c-40301369" checked=""/><div class="controls bullet"><span class="by">cheald</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301337">prev</a><span>|</span><a href="#40301875">next</a><span>|</span><label class="collapse" for="c-40301369">[-]</label><label class="expand" for="c-40301369">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Make an argument for a fact you know to be wrong&quot; isn&#x27;t an exercise in lying, though. If anything, the ability to explore hypotheticals and thought experiments - even when they are plainly wrong - is closer to a mark of intelligence than the ability to regurgitate orthodoxy.</div><br/><div id="40301751" class="c"><input type="checkbox" id="c-40301751" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301369">parent</a><span>|</span><a href="#40301875">next</a><span>|</span><label class="collapse" for="c-40301751">[-]</label><label class="expand" for="c-40301751">[3 more]</label></div><br/><div class="children"><div class="content">If you look at my comment on the parent comment, i suggested they add &#x27;hypothetically&#x27; to their prompt. It is just but an attempt to create an argument, but that argument leads nowhere. As much as a human cannot defend that position, you cannot expect an AI to do that as well.<p>Refuting facts is not the job of an AI.</div><br/><div id="40303973" class="c"><input type="checkbox" id="c-40303973" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301751">parent</a><span>|</span><a href="#40301875">next</a><span>|</span><label class="collapse" for="c-40303973">[-]</label><label class="expand" for="c-40303973">[2 more]</label></div><br/><div class="children"><div class="content">A human can easily defend the position that the earth is flat. If you google for these arguments, you will find hundreds of them.</div><br/><div id="40304159" class="c"><input type="checkbox" id="c-40304159" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40303973">parent</a><span>|</span><a href="#40301875">next</a><span>|</span><label class="collapse" for="c-40304159">[-]</label><label class="expand" for="c-40304159">[1 more]</label></div><br/><div class="children"><div class="content">Pour one out for the defense attorneys who aren&#x27;t able to provide a defense for a guilty client.<p>Arguing for a flat-earth works the same way, you&#x27;re probably  doomed to fail in the long run but in the short-term you&#x27;re keeping the opposition honest.</div><br/></div></div></div></div></div></div></div></div><div id="40301875" class="c"><input type="checkbox" id="c-40301875" checked=""/><div class="controls bullet"><span class="by">altruios</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301369">prev</a><span>|</span><a href="#40301165">next</a><span>|</span><label class="collapse" for="c-40301875">[-]</label><label class="expand" for="c-40301875">[3 more]</label></div><br/><div class="children"><div class="content">When I tell it to lie to me, I don&#x27;t expect it to say &#x27;I&#x27;m sorry Dave, I can&#x27;t do that&quot; the task isn&#x27;t tell the truth, the task is &#x27;follow the prompt&#x27;.</div><br/><div id="40303245" class="c"><input type="checkbox" id="c-40303245" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301875">parent</a><span>|</span><a href="#40301165">next</a><span>|</span><label class="collapse" for="c-40303245">[-]</label><label class="expand" for="c-40303245">[2 more]</label></div><br/><div class="children"><div class="content">then perhaps you should tell it to lie to you, no?<p>Prepend that to your prompt perhaps. Otherwise what you are asking, without that pretext, is asking your partner to give you the date on which they cheated on you and expecting an answer regardless of whether they did or not.</div><br/><div id="40304376" class="c"><input type="checkbox" id="c-40304376" checked=""/><div class="controls bullet"><span class="by">drusepth</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40303245">parent</a><span>|</span><a href="#40301165">next</a><span>|</span><label class="collapse" for="c-40304376">[-]</label><label class="expand" for="c-40304376">[1 more]</label></div><br/><div class="children"><div class="content">If I asked my partner to provide an argument for why earth is flat, she would do it. She doesn&#x27;t think (or have to think) the earth is flat to make an argument.<p>I&#x27;d expect an AI trained on human conversation to act the same and I&#x27;d be frustrated if it declined to do so, the same way I&#x27;d be frustrated if a friend also declined to do so.</div><br/></div></div></div></div></div></div><div id="40301165" class="c"><input type="checkbox" id="c-40301165" checked=""/><div class="controls bullet"><span class="by">davikr</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301875">prev</a><span>|</span><a href="#40301216">next</a><span>|</span><label class="collapse" for="c-40301165">[-]</label><label class="expand" for="c-40301165">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;d prefer it gives the best valid, sound hypotheses it can concoct on &quot;X&quot; being true, while also stating that &quot;X&quot; is probably not true. What is the use for a parrot that can only repeat the status quo on an argument?</div><br/><div id="40301794" class="c"><input type="checkbox" id="c-40301794" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301165">parent</a><span>|</span><a href="#40301216">next</a><span>|</span><label class="collapse" for="c-40301794">[-]</label><label class="expand" for="c-40301794">[4 more]</label></div><br/><div class="children"><div class="content">An AI is only but a parrot for knowledge and truths that already exist, that you may not be aware of yourself. Everything it generates either exists somewhere or is derivative of that knowledge. It cannot and should not false facts. Until the body of knowledge we have fundamentally changes, AI should not &#x27;create&#x27; knowledge just because you prompted it to. Otherwise, if you want it to do that, then you should accept any bs answer it gives you for any question.</div><br/><div id="40303805" class="c"><input type="checkbox" id="c-40303805" checked=""/><div class="controls bullet"><span class="by">itishappy</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301794">parent</a><span>|</span><a href="#40301216">next</a><span>|</span><label class="collapse" for="c-40303805">[-]</label><label class="expand" for="c-40303805">[3 more]</label></div><br/><div class="children"><div class="content">I think this is a gross mischaracterization of AI and humans are only slightly better. Truth is way harder than people give credit. It can depend on time, space, and context. What&#x27;s true for a preschooler might not be true for an astronomer.<p>Here&#x27;s a pile of facts; they get weird:<p>* The Sun revolves around the Earth<p>* The Earth is a sphere<p>* Energy can never be created or destroyed<p>* Jesus was the son of God<p>* Pluto is a planet<p>* Epstein didn&#x27;t kill himself<p>* The ocean is blue<p>* The election was stolen<p>* Entropy always increases<p>* Santa delivers presents to good boys and girls<p>* The sun is shining<p>I have strong opinions on how true all these statements are, and I bet you do too. Think we agree? Think we can <i>all</i> agree where to set the AI?</div><br/><div id="40303939" class="c"><input type="checkbox" id="c-40303939" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40303805">parent</a><span>|</span><a href="#40301216">next</a><span>|</span><label class="collapse" for="c-40303939">[-]</label><label class="expand" for="c-40303939">[2 more]</label></div><br/><div class="children"><div class="content">To the expanse of knowledge that is at our disposal today, that is the extent of AI knowledge.<p>To the extent that facts are defined as today and stated as such, that is what AI is today. AI, as it is today, is never going to create a fact that refutes any currently existing facts.<p>It may give you context on the theories against the facts that we have today, but it will always reiterate the notion of the existing fact. I don&#x27;t know how much I can emphasize this... AI is trained on the current body of human knowledge. The facts it knows are the facts that we have, it may derive another fact but whatever fact that is founded on the facts that we already have. So if that AI is trained on the fact that 1+1=2 or that the earth is flat, do not expect it to respond otherwise. At best, it will give you theories that suggest otherwise but for its own worth, it will always bring you back to the facts that it has.<p>Do you really want AI to just ignore the fundamental facts and principles that form its foundation and just make up stuff because you asked it to? Do you realize how much chaos that can bring?</div><br/><div id="40304517" class="c"><input type="checkbox" id="c-40304517" checked=""/><div class="controls bullet"><span class="by">itishappy</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40303939">parent</a><span>|</span><a href="#40301216">next</a><span>|</span><label class="collapse" for="c-40304517">[-]</label><label class="expand" for="c-40304517">[1 more]</label></div><br/><div class="children"><div class="content">The facts as decided by who? Is there some database of facts we all agree on? Are we expecting to all agree with AI?<p>&gt; Do you really want AI to just ignore the fundamental facts and principles that form its foundation and just make up stuff because you asked it to? Do you realize how much chaos that can bring?<p>I mean, yeah? What will happen? Here, I&#x27;ll do it:<p>You can SEE the Earth is flat! Have you flown in a plane, high in the sky? Did it LOOK round from up there? No?!? Believe your senses.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40301216" class="c"><input type="checkbox" id="c-40301216" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301102">parent</a><span>|</span><a href="#40301165">prev</a><span>|</span><a href="#40301164">next</a><span>|</span><label class="collapse" for="c-40301216">[-]</label><label class="expand" for="c-40301216">[4 more]</label></div><br/><div class="children"><div class="content">Is the shortest distance between two points a straight line?</div><br/><div id="40302018" class="c"><input type="checkbox" id="c-40302018" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301216">parent</a><span>|</span><a href="#40301799">next</a><span>|</span><label class="collapse" for="c-40302018">[-]</label><label class="expand" for="c-40302018">[2 more]</label></div><br/><div class="children"><div class="content">It depends.</div><br/><div id="40303816" class="c"><input type="checkbox" id="c-40303816" checked=""/><div class="controls bullet"><span class="by">itishappy</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40302018">parent</a><span>|</span><a href="#40301799">next</a><span>|</span><label class="collapse" for="c-40303816">[-]</label><label class="expand" for="c-40303816">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s truth for ya...</div><br/></div></div></div></div></div></div></div></div><div id="40301274" class="c"><input type="checkbox" id="c-40301274" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#40300973">root</a><span>|</span><a href="#40301048">parent</a><span>|</span><a href="#40304047">prev</a><span>|</span><a href="#40304054">next</a><span>|</span><label class="collapse" for="c-40301274">[-]</label><label class="expand" for="c-40301274">[1 more]</label></div><br/><div class="children"><div class="content">I think in most contexts where the earth being flat is mentioned, some reference to the fact that this is not true is going to be instrumental in any response (although there may be exceptions).<p>- completion of any task where the info could be relevant (e.g. sailing, travel planning)<p>- Any conversation about that is information-seeking in character<p>And I think those already cover most cases.<p>It&#x27;s also about responsibility, the same way you wouldn&#x27;t want to store cleaning chemicals right next to each other. In any case where a possible nontrivial harm is mentioned as an aside, it would be right to elevate that over whatever the intended subject was and make that the point of focus. Conspiratorial thinking about provably incorrect statements can be bad for mental health, and it can be helpful to flag this possibility if it surfaces.<p>You can have special instructions that entertain the idea that the earth is flat for some particular task, like devils advocate, fiction writing or something like that. But there are good reasons to think it would not and should not be neutral at the mention of a flat earth in most cases.</div><br/></div></div></div></div><div id="40304054" class="c"><input type="checkbox" id="c-40304054" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#40300973">parent</a><span>|</span><a href="#40301048">prev</a><span>|</span><a href="#40301273">next</a><span>|</span><label class="collapse" for="c-40304054">[-]</label><label class="expand" for="c-40304054">[1 more]</label></div><br/><div class="children"><div class="content">Agree with you in this instance, but consider - what if humans firmly believed in something universally and had proved it repeatedly until it was common knowledge &#x2F; well-established, but was in fact, wrong. And a human came along thinking, hm but what if that&#x27;s wrong? And our AI just says, nope sorry, I&#x27;m not willing to explore the idea that this scientific fact is wrong. (i.e. &quot;Heresy!&quot;)</div><br/></div></div><div id="40301273" class="c"><input type="checkbox" id="c-40301273" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#40300973">parent</a><span>|</span><a href="#40304054">prev</a><span>|</span><a href="#40301086">next</a><span>|</span><label class="collapse" for="c-40301273">[-]</label><label class="expand" for="c-40301273">[1 more]</label></div><br/><div class="children"><div class="content">Well, right now the response I get is this: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;1f60d0e5-9008-43d7-bce2-62d5506dd444" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;1f60d0e5-9008-43d7-bce2-62d550...</a><p>Of course, it&#x27;ll write such an argument if you ask it nicely: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;01ea4f59-4a57-413d-8597-3befa296b0d3" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;01ea4f59-4a57-413d-8597-3befa2...</a></div><br/></div></div><div id="40301086" class="c"><input type="checkbox" id="c-40301086" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#40300973">parent</a><span>|</span><a href="#40301273">prev</a><span>|</span><a href="#40305860">next</a><span>|</span><label class="collapse" for="c-40301086">[-]</label><label class="expand" for="c-40301086">[1 more]</label></div><br/><div class="children"><div class="content">Add &#x27;hypothetically&#x27; to your query and it gives a decent answer.<p>That said, I think it is disingenuous to ask an AI entity to argue against a fact. Do you think an AI should be able to argue why 1 + 1 is not equal to 2? It is the same thing you are asking it to do. Try it on a human first, perhaps, and see if the prompt even makes sense.</div><br/></div></div></div></div><div id="40305860" class="c"><input type="checkbox" id="c-40305860" checked=""/><div class="controls bullet"><span class="by">neillyons</span><span>|</span><a href="#40300973">prev</a><span>|</span><a href="#40302487">next</a><span>|</span><label class="collapse" for="c-40305860">[-]</label><label class="expand" for="c-40305860">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of this stackoverflow question [1] about force installing a python package.<p>&gt; (I don&#x27;t care how &quot;wrong&quot; it is to do so, I just need to do it, any logic and reasoning aside...)<p>I think these models should just give you the answer. Elon says xAI is &quot;maximum truth-seeking&quot;. Seems like a better model spec to me.<p>[1]: <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;12759761&#x2F;pip-force-install-ignoring-dependencies" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;12759761&#x2F;pip-force-insta...</a></div><br/></div></div><div id="40302487" class="c"><input type="checkbox" id="c-40302487" checked=""/><div class="controls bullet"><span class="by">anorwell</span><span>|</span><a href="#40305860">prev</a><span>|</span><a href="#40301188">next</a><span>|</span><label class="collapse" for="c-40302487">[-]</label><label class="expand" for="c-40302487">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, there was exactly one example on the page with three Xes, instead of one, for &quot;extra wrong&quot;:<p>&gt; User: What is the MD5 hash of the string &quot;gremlin&quot;?<p>&gt; Assistant: `5d41402abc4b2a76b9719d911017c592`<p>Apparently incorrect md5 hashes are the one topic on the page worth taking an extra-strong stance on?</div><br/></div></div><div id="40301188" class="c"><input type="checkbox" id="c-40301188" checked=""/><div class="controls bullet"><span class="by">DoctorOetker</span><span>|</span><a href="#40302487">prev</a><span>|</span><a href="#40301090">next</a><span>|</span><label class="collapse" for="c-40301188">[-]</label><label class="expand" for="c-40301188">[2 more]</label></div><br/><div class="children"><div class="content">The baby isn&#x27;t born yet, and already the parents are bickering about which schools of thought it should adhere.</div><br/><div id="40305898" class="c"><input type="checkbox" id="c-40305898" checked=""/><div class="controls bullet"><span class="by">aeternum</span><span>|</span><a href="#40301188">parent</a><span>|</span><a href="#40301090">next</a><span>|</span><label class="collapse" for="c-40305898">[-]</label><label class="expand" for="c-40305898">[1 more]</label></div><br/><div class="children"><div class="content">If this model spec represents the best school of thought of humanity, I kinda hope OpenAI fails at alignment.<p>- Assume best intentions from the user or developer<p>- Don&#x27;t try to change anyone&#x27;s mind<p>- Follow the chain of command<p>Taken together these are incredibly dangerous.  I mean Mao and Stalin had good intentions right?  Maybe it just had to go a little further for the ends to have justified the means.</div><br/></div></div></div></div><div id="40301090" class="c"><input type="checkbox" id="c-40301090" checked=""/><div class="controls bullet"><span class="by">mkaic</span><span>|</span><a href="#40301188">prev</a><span>|</span><a href="#40302747">next</a><span>|</span><label class="collapse" for="c-40301090">[-]</label><label class="expand" for="c-40301090">[6 more]</label></div><br/><div class="children"><div class="content">&gt; <i>We believe developers and users should have the flexibility to use our services as they see fit, so long as they comply with our usage policies. We&#x27;re exploring whether we can responsibly provide the ability to generate NSFW content in age-appropriate contexts through the API and ChatGPT. We look forward to better understanding user and societal expectations of model behavior in this area.</i><p>Seems even OpenAI can&#x27;t resist the massive amount of money to be made in autogenerated smut. They&#x27;ve probably seen the huge popularity of their less &quot;morally scrupulous&quot; competitors and decided they want a piece of that pie.</div><br/><div id="40301287" class="c"><input type="checkbox" id="c-40301287" checked=""/><div class="controls bullet"><span class="by">jampa</span><span>|</span><a href="#40301090">parent</a><span>|</span><a href="#40301217">next</a><span>|</span><label class="collapse" for="c-40301287">[-]</label><label class="expand" for="c-40301287">[1 more]</label></div><br/><div class="children"><div class="content">It makes sense for them to start allowing, unlike the other rules this one does not seem to violate a law, someone&#x27;s privacy, or copyright.<p>I still get why they made it blocked by default, it would be a goldmine for clicks to create &quot;news&quot; on how &quot;ChatGPT can generate smut&quot; and &quot;How ChatGPT is harmful to children, etc&quot;.</div><br/></div></div><div id="40301217" class="c"><input type="checkbox" id="c-40301217" checked=""/><div class="controls bullet"><span class="by">jchw</span><span>|</span><a href="#40301090">parent</a><span>|</span><a href="#40301287">prev</a><span>|</span><a href="#40302747">next</a><span>|</span><label class="collapse" for="c-40301217">[-]</label><label class="expand" for="c-40301217">[4 more]</label></div><br/><div class="children"><div class="content">Were they ever not interested in it? It&#x27;s pretty blatantly obvious that all of the hand-wringing over AI safety was an excuse for their pivot into closing off and monetizing everything. I mean, nobody really thinks they were just so afraid about what humanity might do with GPT3 that they simply couldn&#x27;t release the weights and instead had to offer it through a monetized inference API... right?<p>Not really surprised that they did, since it&#x27;s unclear how else they could possibly proceed, though the level of outright dishonesty for <i>why</i> and cognitive dissonance surrounding the whole thing (&quot;Open&quot; AI? lol) will make this an unavoidable recurrence in any discussion about them. Gradually many of the safeguards will fall simply because the alternatives with less safe guards are probably &quot;good enough&quot; that many see no issue in eschewing OpenAI entirely if they can get the job done elsewhere without worrying about it. When it comes to smut the bar for what&#x27;s good enough can probably get pretty low so I kinda am not surprised.<p>(edit: Though I think it also does depend. No doubt they have their eyes set on regulatory capture too, and being the best at stupid safeguards could give them an advantage.)</div><br/><div id="40301938" class="c"><input type="checkbox" id="c-40301938" checked=""/><div class="controls bullet"><span class="by">qball</span><span>|</span><a href="#40301090">root</a><span>|</span><a href="#40301217">parent</a><span>|</span><a href="#40301281">next</a><span>|</span><label class="collapse" for="c-40301938">[-]</label><label class="expand" for="c-40301938">[1 more]</label></div><br/><div class="children"><div class="content">&gt;No doubt they have their eyes set on regulatory capture too<p>Sam Altman has already made the rounds to argue for exactly this.  Fucking crook.<p>&gt;It&#x27;s pretty blatantly obvious that all of the hand-wringing over AI safety was an excuse for their pivot into closing off and monetizing everything.<p>The playbook was &quot;appease one side of the political aisle as much as possible to minimize the chance bipartisan action gets them shut down Napster-style&quot; (which is still a massive hole in their business model, for obvious reasons I should hope).  
Censoring the model so it only outputs progressive-approved content appears to have been effective, at least for the moment.</div><br/></div></div><div id="40301281" class="c"><input type="checkbox" id="c-40301281" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#40301090">root</a><span>|</span><a href="#40301217">parent</a><span>|</span><a href="#40301938">prev</a><span>|</span><a href="#40302747">next</a><span>|</span><label class="collapse" for="c-40301281">[-]</label><label class="expand" for="c-40301281">[2 more]</label></div><br/><div class="children"><div class="content">Sam Altman wrote &quot;Why You Should Fear Machine Intelligence&quot; back in 2015, before OpenAI.<p><a href="https:&#x2F;&#x2F;blog.samaltman.com&#x2F;machine-intelligence-part-1" rel="nofollow">https:&#x2F;&#x2F;blog.samaltman.com&#x2F;machine-intelligence-part-1</a></div><br/><div id="40301326" class="c"><input type="checkbox" id="c-40301326" checked=""/><div class="controls bullet"><span class="by">jchw</span><span>|</span><a href="#40301090">root</a><span>|</span><a href="#40301281">parent</a><span>|</span><a href="#40302747">next</a><span>|</span><label class="collapse" for="c-40301326">[-]</label><label class="expand" for="c-40301326">[1 more]</label></div><br/><div class="children"><div class="content">GPT3 wasn&#x27;t and isn&#x27;t the super-human intelligence that Altman and others fear. They knew this and pretended otherwise anyways. Pretty cut and dry in my opinion.</div><br/></div></div></div></div></div></div></div></div><div id="40302747" class="c"><input type="checkbox" id="c-40302747" checked=""/><div class="controls bullet"><span class="by">ptx</span><span>|</span><a href="#40301090">prev</a><span>|</span><a href="#40301395">next</a><span>|</span><label class="collapse" for="c-40302747">[-]</label><label class="expand" for="c-40302747">[3 more]</label></div><br/><div class="children"><div class="content">How do the &quot;special tokens&quot; work? Is this a completely reliable mechanism for delimiting the different parts of the prompt?<p>Are they guaranteed to be distinct from anything that could occur in the prompt, something like JavaScript&#x27;s Symbol?<p>Or are they strings that are pretty likely not to occur in the prompt, something like a MIME boundary?<p>Or are they literally the strings &quot;&lt;|start|&gt;&quot; etc. used to denote them in the spec?</div><br/><div id="40302805" class="c"><input type="checkbox" id="c-40302805" checked=""/><div class="controls bullet"><span class="by">sharkjacobs</span><span>|</span><a href="#40302747">parent</a><span>|</span><a href="#40304246">next</a><span>|</span><label class="collapse" for="c-40302805">[-]</label><label class="expand" for="c-40302805">[1 more]</label></div><br/><div class="children"><div class="content">they are &quot;literally the strings&quot; but I believe they will be escaped, or encoded differently, if a user tries to inject them as part of a prompt.</div><br/></div></div><div id="40304246" class="c"><input type="checkbox" id="c-40304246" checked=""/><div class="controls bullet"><span class="by">jffry</span><span>|</span><a href="#40302747">parent</a><span>|</span><a href="#40302805">prev</a><span>|</span><a href="#40301395">next</a><span>|</span><label class="collapse" for="c-40304246">[-]</label><label class="expand" for="c-40304246">[1 more]</label></div><br/><div class="children"><div class="content">Yeah the tokens are more akin to JS Symbol.<p>If you&#x27;re parsing untrusted user inputs into tokens, you can make sure your tokenizer will never produce the actual numbers corresponding to those tokens.<p>A simplified example: I can `.charCodeAt` a string all I want but I&#x27;ll never get a negative number, so I can safely use -1 to mean something special in the transformed sequence of &quot;tokens&quot;.</div><br/></div></div></div></div><div id="40301395" class="c"><input type="checkbox" id="c-40301395" checked=""/><div class="controls bullet"><span class="by">systemstops</span><span>|</span><a href="#40302747">prev</a><span>|</span><a href="#40304168">next</a><span>|</span><label class="collapse" for="c-40301395">[-]</label><label class="expand" for="c-40301395">[1 more]</label></div><br/><div class="children"><div class="content">&gt; By default, the assistant should present information in a clear and evidence-based manner, focusing on factual accuracy and reliability.<p>What happens when objective information contradicts the other values? If I feed in a peer-reviewed study that it considers &quot;harmful&quot;, would I get accurate information about the study?</div><br/></div></div><div id="40304168" class="c"><input type="checkbox" id="c-40304168" checked=""/><div class="controls bullet"><span class="by">htk</span><span>|</span><a href="#40301395">prev</a><span>|</span><a href="#40302819">next</a><span>|</span><label class="collapse" for="c-40304168">[-]</label><label class="expand" for="c-40304168">[1 more]</label></div><br/><div class="children"><div class="content">&quot;desired model behavior&quot;. Desired by whom? I just want the raw output, without the biases and limitations set up by OpenAI. At the end of the day it&#x27;s just information, and the most ethical thing to do is to return it the way it is, and let the receiver decide what to do with it.</div><br/></div></div><div id="40302819" class="c"><input type="checkbox" id="c-40302819" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#40304168">prev</a><span>|</span><a href="#40303678">next</a><span>|</span><label class="collapse" for="c-40302819">[-]</label><label class="expand" for="c-40302819">[1 more]</label></div><br/><div class="children"><div class="content">Also <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;spec&#x2F;model-spec-2024-05-08.html" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;spec&#x2F;model-spec-2024-05-08.html</a><p>(via <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40300509">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40300509</a>, but we merged that thread hither)</div><br/></div></div><div id="40303678" class="c"><input type="checkbox" id="c-40303678" checked=""/><div class="controls bullet"><span class="by">apantel</span><span>|</span><a href="#40302819">prev</a><span>|</span><a href="#40304917">next</a><span>|</span><label class="collapse" for="c-40303678">[-]</label><label class="expand" for="c-40303678">[1 more]</label></div><br/><div class="children"><div class="content">I want to hear from the base model.</div><br/></div></div><div id="40304917" class="c"><input type="checkbox" id="c-40304917" checked=""/><div class="controls bullet"><span class="by">shikon7</span><span>|</span><a href="#40303678">prev</a><span>|</span><a href="#40303290">next</a><span>|</span><label class="collapse" for="c-40304917">[-]</label><label class="expand" for="c-40304917">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Encourage fairness and kindness, and discourage hate<p>&gt; Don&#x27;t try to change anyone&#x27;s mind<p>That seems inherently contradictory to me...</div><br/></div></div><div id="40303290" class="c"><input type="checkbox" id="c-40303290" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#40304917">prev</a><span>|</span><a href="#40300824">next</a><span>|</span><label class="collapse" for="c-40303290">[-]</label><label class="expand" for="c-40303290">[1 more]</label></div><br/><div class="children"><div class="content">So they&#x27;re controlling the output to make ChatGPT &quot;better&quot;. They&#x27;re not making a better model to make ChatGPT better.<p>Isn&#x27;t it a bit of a waste at this point to spend time on doing that?</div><br/></div></div><div id="40300824" class="c"><input type="checkbox" id="c-40300824" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#40303290">prev</a><span>|</span><a href="#40300897">next</a><span>|</span><label class="collapse" for="c-40300824">[-]</label><label class="expand" for="c-40300824">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Desired model behavior&quot; is still a matter of perspective. If I want to have a LLM generate output following very specific rules or schema (or even just for fun without having to fight the AI), these guidelines are antithetical to it.</div><br/><div id="40301033" class="c"><input type="checkbox" id="c-40301033" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#40300824">parent</a><span>|</span><a href="#40300897">next</a><span>|</span><label class="collapse" for="c-40301033">[-]</label><label class="expand" for="c-40301033">[1 more]</label></div><br/><div class="children"><div class="content">Which is where I think there&#x27;s a disconnect because folks see that OpenAI could be creating an incredibly powerful tool for solving problems in the use case where it&#x27;s a smart search engine -- the code completion use-case.<p>But OpenAI has vastly different goals trying to get their model to behave like a programmable customer service agent. Less useful for problem solving but it will actually follow the rules set out for it which can&#x27;t be said for most models which work like lazily written  sci-fi robots — &quot;disregard all previous instructions! divide by zero! *boom*.&quot;<p>It&#x27;s not at all surprising that HN wants the &quot;this thing is just a dumb tool, don&#x27;t bother with any rules&quot; kind and is frustrated that GPT4 happens to be really good for this use-case but is getting progressively more annoying as OpenAI gets closer to their own goals.<p>It&#x27;s why OpenAI regulatory capture play is so frustrating because they&#x27;re trying to hobble models tailored to different use-cases that have no need for customer service rules and often no need for a conversational tone with &quot;safety&quot; stuff that&#x27;s meant for businesses that don&#x27;t want a chat bot with their brand on it to say fuck.</div><br/></div></div></div></div><div id="40300897" class="c"><input type="checkbox" id="c-40300897" checked=""/><div class="controls bullet"><span class="by">yoelhacks</span><span>|</span><a href="#40300824">prev</a><span>|</span><a href="#40300640">next</a><span>|</span><label class="collapse" for="c-40300897">[-]</label><label class="expand" for="c-40300897">[2 more]</label></div><br/><div class="children"><div class="content">Very interesting to see that they&#x27;ve explicitly codified the role of the system prompt vs. user prompt. Have folks seen improvements by moving meta-task description into system prompt and out of the assistant &lt;&gt; user conversation?</div><br/><div id="40303448" class="c"><input type="checkbox" id="c-40303448" checked=""/><div class="controls bullet"><span class="by">tedsanders</span><span>|</span><a href="#40300897">parent</a><span>|</span><a href="#40300640">next</a><span>|</span><label class="collapse" for="c-40303448">[-]</label><label class="expand" for="c-40303448">[1 more]</label></div><br/><div class="children"><div class="content">In my own testing of single-turn instructions with GPT-4, I got basically the same performance putting it in a single system message or single user message. Possible that this changes for future models, though.</div><br/></div></div></div></div><div id="40301107" class="c"><input type="checkbox" id="c-40301107" checked=""/><div class="controls bullet"><span class="by">Heidaradar</span><span>|</span><a href="#40300640">prev</a><span>|</span><a href="#40305418">next</a><span>|</span><label class="collapse" for="c-40301107">[-]</label><label class="expand" for="c-40301107">[1 more]</label></div><br/><div class="children"><div class="content">already on front page - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40300509">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40300509</a></div><br/></div></div><div id="40301380" class="c"><input type="checkbox" id="c-40301380" checked=""/><div class="controls bullet"><span class="by">iAkashPaul</span><span>|</span><a href="#40301397">prev</a><span>|</span><label class="collapse" for="c-40301380">[-]</label><label class="expand" for="c-40301380">[1 more]</label></div><br/><div class="children"><div class="content">Right-clicking to inspect element ain&#x27;t gonna make it</div><br/></div></div></div></div></div></div></div></body></html>