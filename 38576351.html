<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702112456277" as="style"/><link rel="stylesheet" href="styles.css?v=1702112456277"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://cornell-relaxml.github.io/quip-sharp/">QuIP#: 2-bit Quantization for LLMs</a>Â <span class="domain">(<a href="https://cornell-relaxml.github.io">cornell-relaxml.github.io</a>)</span></div><div class="subtext"><span>jasondavies</span> | <span>28 comments</span></div><br/><div><div id="38578281" class="c"><input type="checkbox" id="c-38578281" checked=""/><div class="controls bullet"><span class="by">SeanAnderson</span><span>|</span><a href="#38579240">next</a><span>|</span><label class="collapse" for="c-38578281">[-]</label><label class="expand" for="c-38578281">[2 more]</label></div><br/><div class="children"><div class="content">Just to make sure I&#x27;m understanding this correctly.<p>This paper signals that the authors have found a way to run Llama 2 70B, but with 1&#x2F;8th the VRAM requirements as compared to the original model, right?<p>And the output is on-par with the original along some metrics (ArcE&#x2F;PiQA), within 25% on others (Wiki&#x2F;C4), and the trajectory of their progress hints that there&#x27;s even more ground to gain in the future?</div><br/><div id="38579946" class="c"><input type="checkbox" id="c-38579946" checked=""/><div class="controls bullet"><span class="by">samus</span><span>|</span><a href="#38578281">parent</a><span>|</span><a href="#38579240">next</a><span>|</span><label class="collapse" for="c-38579946">[-]</label><label class="expand" for="c-38579946">[1 more]</label></div><br/><div class="children"><div class="content">Your last paragraph is the key. Without their improvements, the quality tradeoff would have been hard to stomach.</div><br/></div></div></div></div><div id="38579240" class="c"><input type="checkbox" id="c-38579240" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38578281">prev</a><span>|</span><a href="#38577760">next</a><span>|</span><label class="collapse" for="c-38579240">[-]</label><label class="expand" for="c-38579240">[1 more]</label></div><br/><div class="children"><div class="content">If this quantization method works with smaller models, it would enable running up to 33B models with only 12GB VRAM.<p>Especially important for democratizing access to Mistral MoE new model.</div><br/></div></div><div id="38577760" class="c"><input type="checkbox" id="c-38577760" checked=""/><div class="controls bullet"><span class="by">bongwater_OS</span><span>|</span><a href="#38579240">prev</a><span>|</span><a href="#38578473">next</a><span>|</span><label class="collapse" for="c-38577760">[-]</label><label class="expand" for="c-38577760">[1 more]</label></div><br/><div class="children"><div class="content">One of the best papers I&#x27;ve read in a long time. This could be huge.</div><br/></div></div><div id="38578473" class="c"><input type="checkbox" id="c-38578473" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#38577760">prev</a><span>|</span><a href="#38577303">next</a><span>|</span><label class="collapse" for="c-38578473">[-]</label><label class="expand" for="c-38578473">[1 more]</label></div><br/><div class="children"><div class="content">Already works on oobabooga as of a few days ago: <a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;issues&#x2F;4799">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;issues&#x2F;47...</a><p>Need a few extra steps: <a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;pull&#x2F;4803">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;pull&#x2F;4803</a></div><br/></div></div><div id="38577303" class="c"><input type="checkbox" id="c-38577303" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#38578473">prev</a><span>|</span><a href="#38577818">next</a><span>|</span><label class="collapse" for="c-38577303">[-]</label><label class="expand" for="c-38577303">[17 more]</label></div><br/><div class="children"><div class="content">can anyone comment on running the 2b quantized llama 70b on consumer cards like the 4090?</div><br/><div id="38577443" class="c"><input type="checkbox" id="c-38577443" checked=""/><div class="controls bullet"><span class="by">beacon294</span><span>|</span><a href="#38577303">parent</a><span>|</span><a href="#38578081">next</a><span>|</span><label class="collapse" for="c-38577443">[-]</label><label class="expand" for="c-38577443">[10 more]</label></div><br/><div class="children"><div class="content">I have quantized Llama-2-chat-70b to 2q_k with llama.cpp then run on a 4090 for 50&#x2F;83 layers.  I was able to get 1.3 tokens per second. It answers this question, which smaller models have trouble with:<p>&lt;s&gt;[INST]Hello. The functions addition, multiplication, and exponentiation can be considered each as a higher order of the previous. For example, 2+2+2 = 2*3 which is significant because there are three twos, which is the multiplication factor. Likewise 2*2*2=2^3, again, the power number represents the count of the numbers being multiplied. What is this concept and what is the next higher order function?[&#x2F;INST]
The concept you are referring to is called the &quot;iterative&quot; or &quot;recursive&quot; nature of arithmetic operations. Each operation can be seen as a repeated application of the previous operation, with the multiplication factor representing the number of times the operation is applied.<p>For example, the addition of two numbers, 2+2, can be seen as a repeated application of the multiplication operation, where the multiplicand is 2 and the multiplier is 3 (i.e., 2*3 = 6, which is the result of the addition). Similarly, the multiplication of two numbers, 
2*2, can be seen as a repeated application of the exponentiation operation, where the base is 2 and the power is 3 (i.e., 2^3 = 8, which is the result of the multiplication).<p>The next higher order function would be the &quot;tetration&quot; operation, which is the iterative application of the exponential function. In other words, tetration(n,x) = x^(x^(x^(...(x^n)...))), where n is the number of times the exponential function is applied.<p>For example, tetration(2,2) = 2^(2^(2^(2))), which can be simplified to 2^16, or 65536.<p>It&#x27;s worth noting that this concept can be extended even further to higher levels of abstraction, such as &quot;hyper-operations&quot; and &quot;super
-operations&quot;, but these are more advanced and less commonly used concepts in mathematics.*</div><br/><div id="38577915" class="c"><input type="checkbox" id="c-38577915" checked=""/><div class="controls bullet"><span class="by">skykooler</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577443">parent</a><span>|</span><a href="#38577792">next</a><span>|</span><label class="collapse" for="c-38577915">[-]</label><label class="expand" for="c-38577915">[1 more]</label></div><br/><div class="children"><div class="content">Note that it got all the math wrong. 2+2 is a repetition of the succession operator, not multiplication; 2+2 equals 4, not 6; multiplication of two numbers is repeated addition, not exponentiation; 2*2 equals 4, not 8; and tetration(2,2) is 4, not 65536. This is actually the invariant in that n-ation(2,2) equals 4 for all natural numbers n.</div><br/></div></div><div id="38577792" class="c"><input type="checkbox" id="c-38577792" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577443">parent</a><span>|</span><a href="#38577915">prev</a><span>|</span><a href="#38577468">next</a><span>|</span><label class="collapse" for="c-38577792">[-]</label><label class="expand" for="c-38577792">[3 more]</label></div><br/><div class="children"><div class="content">to clarify, is that with <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;relaxml&#x2F;Llama-2-70b-chat-E8P-2Bit" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;relaxml&#x2F;Llama-2-70b-chat-E8P-2Bit</a></div><br/><div id="38578171" class="c"><input type="checkbox" id="c-38578171" checked=""/><div class="controls bullet"><span class="by">beacon294</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577792">parent</a><span>|</span><a href="#38577468">next</a><span>|</span><label class="collapse" for="c-38578171">[-]</label><label class="expand" for="c-38578171">[2 more]</label></div><br/><div class="children"><div class="content">It is Llama-2-70b-chat. I quantized it to 2q_k using `quantize` with llama.cpp.</div><br/><div id="38579482" class="c"><input type="checkbox" id="c-38579482" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578171">parent</a><span>|</span><a href="#38577468">next</a><span>|</span><label class="collapse" for="c-38579482">[-]</label><label class="expand" for="c-38579482">[1 more]</label></div><br/><div class="children"><div class="content">So your experience isnât representative of the work presented by this post? Or does llama.cpp use the same technique for quantization?</div><br/></div></div></div></div></div></div><div id="38577468" class="c"><input type="checkbox" id="c-38577468" checked=""/><div class="controls bullet"><span class="by">beacon294</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577443">parent</a><span>|</span><a href="#38577792">prev</a><span>|</span><a href="#38578081">next</a><span>|</span><label class="collapse" for="c-38577468">[-]</label><label class="expand" for="c-38577468">[5 more]</label></div><br/><div class="children"><div class="content">The answer seems kind of low quality, but it got further than others. It could probably self correct.</div><br/><div id="38577598" class="c"><input type="checkbox" id="c-38577598" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577468">parent</a><span>|</span><a href="#38578081">next</a><span>|</span><label class="collapse" for="c-38577598">[-]</label><label class="expand" for="c-38577598">[4 more]</label></div><br/><div class="children"><div class="content">I donât know too many humans who could answer that half as well.</div><br/><div id="38578671" class="c"><input type="checkbox" id="c-38578671" checked=""/><div class="controls bullet"><span class="by">epcoa</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577598">parent</a><span>|</span><a href="#38577682">next</a><span>|</span><label class="collapse" for="c-38578671">[-]</label><label class="expand" for="c-38578671">[2 more]</label></div><br/><div class="children"><div class="content">&quot;For example, the addition of two numbers, 2+2, can be seen as a repeated application of the multiplication operation,&quot;<p>I bet most humans ever born did not know what the word &quot;multiplication&quot; meant. Not sure how your metric is useful.</div><br/><div id="38579311" class="c"><input type="checkbox" id="c-38579311" checked=""/><div class="controls bullet"><span class="by">philipswood</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578671">parent</a><span>|</span><a href="#38577682">next</a><span>|</span><label class="collapse" for="c-38579311">[-]</label><label class="expand" for="c-38579311">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes, to achieve some perspective, I also zoom out and declare normal over the estimated +-120,000,000,000 people who have ever lived.</div><br/></div></div></div></div><div id="38577682" class="c"><input type="checkbox" id="c-38577682" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38577598">parent</a><span>|</span><a href="#38578671">prev</a><span>|</span><a href="#38578081">next</a><span>|</span><label class="collapse" for="c-38577682">[-]</label><label class="expand" for="c-38577682">[1 more]</label></div><br/><div class="children"><div class="content">To be fair it is a memory&#x2F;recite test mostly. âDefine thisâ</div><br/></div></div></div></div></div></div></div></div><div id="38578081" class="c"><input type="checkbox" id="c-38578081" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#38577303">parent</a><span>|</span><a href="#38577443">prev</a><span>|</span><a href="#38577818">next</a><span>|</span><label class="collapse" for="c-38578081">[-]</label><label class="expand" for="c-38578081">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s been on my list to do a proper shootout of all the various new quant formats floating around (my list here: <a href="https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;quantization-overview" rel="nofollow noreferrer">https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;quantization-overvi...</a>) but a lot of them don&#x27;t have very good production code yet (eg, a few months ago, when I tried OmniQuant, some of the important bits of code wasn&#x27;t even included and had to be gotten directly from the authors: <a href="https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;omniquant" rel="nofollow noreferrer">https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;omniquant</a>).<p>If you&#x27;re looking for the best widely deployed quant format atm, it&#x27;s probably ExLlamaV2&#x27;s EXL2 - it supports arbitrary bpw w&#x2F; a calibration file, and also 8-bit kvcache support. I haven&#x27;t tested EXL2 much at lower bpws though.<p>Note, both llama.cpp and AirLLM allow layer offloading to system memory (or in AirLLM&#x27;s case, even to disk?!).<p>r&#x2F;LocalLlama probably is the best place to search for if you&#x27;re looking for people&#x27;s experiences w&#x2F; quants. I know some people have been testing, like: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;17klaa5&#x2F;tested_exllamav2s_max_context_on_24gb_with_70b&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;17klaa5&#x2F;tested_...</a></div><br/><div id="38579533" class="c"><input type="checkbox" id="c-38579533" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578081">parent</a><span>|</span><a href="#38578701">next</a><span>|</span><label class="collapse" for="c-38579533">[-]</label><label class="expand" for="c-38579533">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <a href="https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;quantization-overview" rel="nofollow noreferrer">https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;llms&#x2F;page&#x2F;quantization-overvi...</a><p>This is a very cool resource, thanks!<p>Gems like this, even in areas I follow pretty closely, are why I keep coming back to HN.</div><br/></div></div><div id="38578701" class="c"><input type="checkbox" id="c-38578701" checked=""/><div class="controls bullet"><span class="by">0xDEADFED5</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578081">parent</a><span>|</span><a href="#38579533">prev</a><span>|</span><a href="#38577818">next</a><span>|</span><label class="collapse" for="c-38578701">[-]</label><label class="expand" for="c-38578701">[4 more]</label></div><br/><div class="children"><div class="content">i humbly request you to add mlc-llm to your quant test when&#x2F;if you get around to doing it</div><br/><div id="38578984" class="c"><input type="checkbox" id="c-38578984" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578701">parent</a><span>|</span><a href="#38579039">next</a><span>|</span><label class="collapse" for="c-38578984">[-]</label><label class="expand" for="c-38578984">[1 more]</label></div><br/><div class="children"><div class="content">Sure, I think their quant format is pretty basic, something similar to bnb q4 - my plan will to be scripting a framework for testing, so should do that as well since the omniquant implementation is in mlc-llm anyways.</div><br/></div></div><div id="38579039" class="c"><input type="checkbox" id="c-38579039" checked=""/><div class="controls bullet"><span class="by">acosmism</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578701">parent</a><span>|</span><a href="#38578984">prev</a><span>|</span><a href="#38579050">next</a><span>|</span><label class="collapse" for="c-38579039">[-]</label><label class="expand" for="c-38579039">[1 more]</label></div><br/><div class="children"><div class="content">i was trying to get this to work with mlc-llm. i&#x27;d appreciate any pointers</div><br/></div></div><div id="38579050" class="c"><input type="checkbox" id="c-38579050" checked=""/><div class="controls bullet"><span class="by">acosmism</span><span>|</span><a href="#38577303">root</a><span>|</span><a href="#38578701">parent</a><span>|</span><a href="#38579039">prev</a><span>|</span><a href="#38577818">next</a><span>|</span><label class="collapse" for="c-38579050">[-]</label><label class="expand" for="c-38579050">[1 more]</label></div><br/><div class="children"><div class="content">more specifically on a non-cuda gpu - mali on orangepi via opencl</div><br/></div></div></div></div></div></div></div></div><div id="38577818" class="c"><input type="checkbox" id="c-38577818" checked=""/><div class="controls bullet"><span class="by">skykooler</span><span>|</span><a href="#38577303">prev</a><span>|</span><label class="collapse" for="c-38577818">[-]</label><label class="expand" for="c-38577818">[5 more]</label></div><br/><div class="children"><div class="content">I wonder whether quantization to 1-bit would be functional?</div><br/><div id="38580044" class="c"><input type="checkbox" id="c-38580044" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#38577818">parent</a><span>|</span><a href="#38578187">next</a><span>|</span><label class="collapse" for="c-38580044">[-]</label><label class="expand" for="c-38580044">[1 more]</label></div><br/><div class="children"><div class="content">If we get 1-bit quantization, wouldn&#x27;t it be basically a bunch of nested if&#x27;s and else&#x27;s?</div><br/></div></div><div id="38578187" class="c"><input type="checkbox" id="c-38578187" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#38577818">parent</a><span>|</span><a href="#38580044">prev</a><span>|</span><a href="#38579194">next</a><span>|</span><label class="collapse" for="c-38578187">[-]</label><label class="expand" for="c-38578187">[1 more]</label></div><br/><div class="children"><div class="content">There was a paper from the Allen institute from around 2017 successfully using 1 bit quantization but I canât find it right now.  We started using it where I was working at the time but Iâm no longer there so I donât know how it all turned out.</div><br/></div></div><div id="38579194" class="c"><input type="checkbox" id="c-38579194" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#38577818">parent</a><span>|</span><a href="#38578187">prev</a><span>|</span><a href="#38577892">next</a><span>|</span><label class="collapse" for="c-38579194">[-]</label><label class="expand" for="c-38579194">[1 more]</label></div><br/><div class="children"><div class="content">Functional? Sure, it will work. Useful? Unlikely. It would be surprising to see quantization of pretrained models to surpass the existing research around binary NNs (trained from scratch as 1-bit while using full precision for the most critical parts)</div><br/></div></div></div></div></div></div></div></div></div></body></html>