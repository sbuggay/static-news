<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1682672452493" as="style"/><link rel="stylesheet" href="styles.css?v=1682672452493"/><link rel="apple-touch-startup-image" href="https://png.pngtree.com/png-clipart/20210309/original/pngtree-a-squatting-tabby-cat-png-image_5803660.jpg"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://pytorch.org/blog/introducing-hidet/">Hidet: A Deep Learning Compiler for Efficient Model Serving</a> <span class="domain">(<a href="https://pytorch.org">pytorch.org</a>)</span></div><div class="subtext"><span>ashvardanian</span> | <span>13 comments</span></div><br/><div><div id="35738900" class="c"><input type="checkbox" id="c-35738900" checked=""/><div class="controls bullet"><span class="by">lamchob</span><span>|</span><a href="#35738396">next</a><span>|</span><label class="collapse" for="c-35738900">[-]</label><label class="expand" for="c-35738900">[1 more]</label></div><br/><div class="children"><div class="content">If you read into the paper (<a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3575693.3575702" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3575693.3575702</a>), one can find more performance comparisons. 
There, from a latency&#x2F;throughput PoV they are en par with existing tools like TVM&#x2F;Ansor. Sometimes faster, sometimes slower.<p>What is more interesting is this: They have very GPU-specific auto-tuning routine that drastically reduces the optimzation space, compared to TVM&#x2F;Ansor. They go from ~10^6 possible implementations for an operator to a &quot;few hundred&quot;, which enabled much faster time-to-solution. This is achieved with a GPU-centric problem formulation and search space.  In essence, they trade how widely applicable their approach is (from &quot;any&quot; kind of hardware to only GPU-style architectures) for retrieval speed.</div><br/></div></div><div id="35738396" class="c"><input type="checkbox" id="c-35738396" checked=""/><div class="controls bullet"><span class="by">junrushao1994</span><span>|</span><a href="#35738900">prev</a><span>|</span><a href="#35738019">next</a><span>|</span><label class="collapse" for="c-35738396">[-]</label><label class="expand" for="c-35738396">[1 more]</label></div><br/><div class="children"><div class="content">Nice work! This is interesting to read the comparison between Hidet and Triton in this blog:<p>&gt; Hidet Script vs. Triton: Triton greatly simplifies the CUDA programming by introducing the tile-based programming model where the parallel execution unit is thread blocks instead of threads. However, this simplification also prevents the tensor program developers from manipulating the fine-grained computation and memory resources (e.g., warps, shared memory) in their preferred ways. It would be challenging to implement an optimization that requires fine-grained control of these resources using Triton if it has not been implemented by the Triton compiler itself. Hidet Script, on the other hand, simplifies tensor programming while still enabling users to implement their own optimizations with extensive flexibility. It’s worth noting that the more granular control of Hidet Script also brings added complexity compared to Triton.</div><br/></div></div><div id="35738019" class="c"><input type="checkbox" id="c-35738019" checked=""/><div class="controls bullet"><span class="by">kookamamie</span><span>|</span><a href="#35738396">prev</a><span>|</span><a href="#35737331">next</a><span>|</span><label class="collapse" for="c-35738019">[-]</label><label class="expand" for="c-35738019">[2 more]</label></div><br/><div class="children"><div class="content">I more relevant benchmark would be against TensorRT, the current kind of model serving performance on NVIDIA GPUs.</div><br/><div id="35738936" class="c"><input type="checkbox" id="c-35738936" checked=""/><div class="controls bullet"><span class="by">lamchob</span><span>|</span><a href="#35738019">parent</a><span>|</span><a href="#35737331">next</a><span>|</span><label class="collapse" for="c-35738936">[-]</label><label class="expand" for="c-35738936">[1 more]</label></div><br/><div class="children"><div class="content">In the paper (<a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3575693.3575702" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3575693.3575702</a>) there is also a TensorRT comparison. There, they are pretty much neck and neck. Sometimes faster, sometimes slower.</div><br/></div></div></div></div><div id="35737331" class="c"><input type="checkbox" id="c-35737331" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#35738019">prev</a><span>|</span><a href="#35738358">next</a><span>|</span><label class="collapse" for="c-35737331">[-]</label><label class="expand" for="c-35737331">[5 more]</label></div><br/><div class="children"><div class="content">Hmm, does not work for Stable Diffusion yet :(<p>But inductor&#x2F;triton didn&#x27;t work in the 2.0 nightlies either, and now it works fine for SD.</div><br/><div id="35737696" class="c"><input type="checkbox" id="c-35737696" checked=""/><div class="controls bullet"><span class="by">mlazos</span><span>|</span><a href="#35737331">parent</a><span>|</span><a href="#35738358">next</a><span>|</span><label class="collapse" for="c-35737696">[-]</label><label class="expand" for="c-35737696">[4 more]</label></div><br/><div class="children"><div class="content">This bug was in the front end (dynamo) so I’m not surprised it happens with hidet too. I fixed this for the 2.0.1 release.</div><br/><div id="35737817" class="c"><input type="checkbox" id="c-35737817" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#35737331">root</a><span>|</span><a href="#35737696">parent</a><span>|</span><a href="#35738358">next</a><span>|</span><label class="collapse" for="c-35737817">[-]</label><label class="expand" for="c-35737817">[3 more]</label></div><br/><div class="children"><div class="content">On 2.1, I am getting backend errors atm. For instance, with the unet:<p>&gt; torch._dynamo.exc.BackendCompilerFailed: backend=&#x27;hidet_backend&#x27; raised:
NotImplementedError: hidet: Tensor.to(..., device=...) is not supported for symbolic tensors...<p>Early torch 2.0 was full of backend unimplemented&#x2F;unsupported errors too, but I can&#x27;t even remember when that was all implemented and the dynamo issues popped up (or even when everything started working) since I stayed on torch nightly.</div><br/><div id="35737921" class="c"><input type="checkbox" id="c-35737921" checked=""/><div class="controls bullet"><span class="by">mlazos</span><span>|</span><a href="#35737331">root</a><span>|</span><a href="#35737817">parent</a><span>|</span><a href="#35738075">next</a><span>|</span><label class="collapse" for="c-35737921">[-]</label><label class="expand" for="c-35737921">[1 more]</label></div><br/><div class="children"><div class="content">Ah ok this wasn’t what I thought then. I haven’t taken a look at Hidet yet so I won’t be much help here :( I thought you were talking about 2.0.0</div><br/></div></div><div id="35738075" class="c"><input type="checkbox" id="c-35738075" checked=""/><div class="controls bullet"><span class="by">yyding</span><span>|</span><a href="#35737331">root</a><span>|</span><a href="#35737817">parent</a><span>|</span><a href="#35737921">prev</a><span>|</span><a href="#35738358">next</a><span>|</span><label class="collapse" for="c-35738075">[-]</label><label class="expand" for="c-35738075">[1 more]</label></div><br/><div class="children"><div class="content">Hi, do you mind submitting an issue to the hidet github repo so we can have a look? Thank you!</div><br/></div></div></div></div></div></div></div></div><div id="35738358" class="c"><input type="checkbox" id="c-35738358" checked=""/><div class="controls bullet"><span class="by">psuedo_uuh</span><span>|</span><a href="#35737331">prev</a><span>|</span><a href="#35738035">next</a><span>|</span><label class="collapse" for="c-35738358">[-]</label><label class="expand" for="c-35738358">[1 more]</label></div><br/><div class="children"><div class="content">Hidet: a deep learning model to detect when you’re ready for your bidet to activate</div><br/></div></div></div></div></div></div></div></body></html>