<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697533267604" as="style"/><link rel="stylesheet" href="styles.css?v=1697533267604"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://news.err.ee/1609120697/finland-s-chatgpt-equivalent-begins-to-think-in-estonian-as-well">Finland&#x27;s ChatGPT equivalent begins to think in Estonian as well</a> <span class="domain">(<a href="https://news.err.ee">news.err.ee</a>)</span></div><div class="subtext"><span>jruohonen</span> | <span>66 comments</span></div><br/><div><div id="37912076" class="c"><input type="checkbox" id="c-37912076" checked=""/><div class="controls bullet"><span class="by">anileated</span><span>|</span><a href="#37911965">next</a><span>|</span><label class="collapse" for="c-37912076">[-]</label><label class="expand" for="c-37912076">[5 more]</label></div><br/><div class="children"><div class="content">Describing a glorified autocomplete as “thinking” is wrong on many levels; it devalues human consciousness, it attributes to a software tool qualities that it does not possess, and has implications for the entire AI industry.<p>If we are to  believe an LLM is <i>at least</i> sentient and intelligent on par with an octopus, much less a human, then we have a moral imperative to fight for LLMs to be recognized as protected sentient thinking beings with awareness and agency and admit that AI industry is built on systematic abuse of those beings.<p>Of course, no one does it, because it would be ridiculous. It’s time to admit that people who insist that LLMs “think” are simply trying to make ML seem mysterious and magical in an ill thought through (because see above) attempt to attract more VC money.</div><br/><div id="37912217" class="c"><input type="checkbox" id="c-37912217" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#37912076">parent</a><span>|</span><a href="#37912121">next</a><span>|</span><label class="collapse" for="c-37912217">[-]</label><label class="expand" for="c-37912217">[1 more]</label></div><br/><div class="children"><div class="content">We agree the word is an open window to flawed analogy extension.<p>On the other hand we do use analogy all the time, because it makes such a good fit with the way we infer our models of the world. The key point is to always remain sufficiently aware of the fact we use analogies to not fall in the trap where we push it too far.</div><br/></div></div><div id="37912121" class="c"><input type="checkbox" id="c-37912121" checked=""/><div class="controls bullet"><span class="by">looping8</span><span>|</span><a href="#37912076">parent</a><span>|</span><a href="#37912217">prev</a><span>|</span><a href="#37912173">next</a><span>|</span><label class="collapse" for="c-37912121">[-]</label><label class="expand" for="c-37912121">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that admitting an AI is in some way sentient would create a push to protect it. Animal testing is still very popular, despite there being no arguments about them being sentient. The tech industry isn&#x27;t a moral leader and, based on some things major companies do, isn&#x27;t even moral.</div><br/></div></div><div id="37912173" class="c"><input type="checkbox" id="c-37912173" checked=""/><div class="controls bullet"><span class="by">nercury</span><span>|</span><a href="#37912076">parent</a><span>|</span><a href="#37912121">prev</a><span>|</span><a href="#37912184">next</a><span>|</span><label class="collapse" for="c-37912173">[-]</label><label class="expand" for="c-37912173">[1 more]</label></div><br/><div class="children"><div class="content">Have we forgot that we have attributed &quot;thinking&quot; to all the machines since the beginning?</div><br/></div></div><div id="37912184" class="c"><input type="checkbox" id="c-37912184" checked=""/><div class="controls bullet"><span class="by">GolDDranks</span><span>|</span><a href="#37912076">parent</a><span>|</span><a href="#37912173">prev</a><span>|</span><a href="#37911965">next</a><span>|</span><label class="collapse" for="c-37912184">[-]</label><label class="expand" for="c-37912184">[1 more]</label></div><br/><div class="children"><div class="content">I bet you think that aeroplanes don&#x27;t fly either. &#x2F;s</div><br/></div></div></div></div><div id="37911965" class="c"><input type="checkbox" id="c-37911965" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#37912076">prev</a><span>|</span><a href="#37911794">next</a><span>|</span><label class="collapse" for="c-37911965">[-]</label><label class="expand" for="c-37911965">[1 more]</label></div><br/><div class="children"><div class="content">Slightly off-topic, but figured this might be the best place to connect with like minded people: I’ve been working on tooling for low resource languages, and  had quite the success developing an LLM that speaks Moroccan natively [0], started from a super tiny dataset I manually annotated and scaling it to find anything written in Moroccan on the whole web.<p>Currently helping out a research group to extend the same approaches from my project to Indic languages and writing scripts.<p>If anyone here is working on NLP for low resource languages, hit me up! I’d love to exchange ideas, techniques and possibly to collaborate.<p>[0]: <a href="https:&#x2F;&#x2F;sawalni.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;sawalni.com</a></div><br/></div></div><div id="37911794" class="c"><input type="checkbox" id="c-37911794" checked=""/><div class="controls bullet"><span class="by">dstala</span><span>|</span><a href="#37911965">prev</a><span>|</span><a href="#37912215">next</a><span>|</span><label class="collapse" for="c-37911794">[-]</label><label class="expand" for="c-37911794">[1 more]</label></div><br/><div class="children"><div class="content">Very much applicable to South Asian languages too, but the problem remains same. Not enough content being available to train. And unlike Finland, Government or private funding is a distant dream for many states in India.</div><br/></div></div><div id="37912215" class="c"><input type="checkbox" id="c-37912215" checked=""/><div class="controls bullet"><span class="by">nodoodles</span><span>|</span><a href="#37911794">prev</a><span>|</span><a href="#37912080">next</a><span>|</span><label class="collapse" for="c-37912215">[-]</label><label class="expand" for="c-37912215">[1 more]</label></div><br/><div class="children"><div class="content">The real question is, will it pick up and emulate national archetypes in communication - I expect this model to be introverted and avoid talking to strangers</div><br/></div></div><div id="37912080" class="c"><input type="checkbox" id="c-37912080" checked=""/><div class="controls bullet"><span class="by">paulhalla</span><span>|</span><a href="#37912215">prev</a><span>|</span><a href="#37911581">next</a><span>|</span><label class="collapse" for="c-37912080">[-]</label><label class="expand" for="c-37912080">[1 more]</label></div><br/><div class="children"><div class="content">I use ChatGPT audio to get answers in a few languages, including Estonian. I find it really amusing that Estonian ChatGPT audio has a thick American accent. Generally the content is solid and the speech is fluid, not halting or robotic or anything, so it legit sounds like an American person that is super fluent in Estonian.</div><br/></div></div><div id="37911581" class="c"><input type="checkbox" id="c-37911581" checked=""/><div class="controls bullet"><span class="by">v4dok</span><span>|</span><a href="#37912080">prev</a><span>|</span><a href="#37912044">next</a><span>|</span><label class="collapse" for="c-37911581">[-]</label><label class="expand" for="c-37911581">[20 more]</label></div><br/><div class="children"><div class="content">This is important work. And think about African or southeast Asian languages, they are even more screwed. We need to make sure that AI multilingual to avoid total English domination of culture.</div><br/><div id="37911689" class="c"><input type="checkbox" id="c-37911689" checked=""/><div class="controls bullet"><span class="by">tellarin</span><span>|</span><a href="#37911581">parent</a><span>|</span><a href="#37911866">next</a><span>|</span><label class="collapse" for="c-37911689">[-]</label><label class="expand" for="c-37911689">[1 more]</label></div><br/><div class="children"><div class="content">Project Aya is one such attempt at a multi-lingual model (targeting 101 languages):<p>- <a href="https:&#x2F;&#x2F;txt.cohere.com&#x2F;aya-multilingual&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;txt.cohere.com&#x2F;aya-multilingual&#x2F;</a><p>- <a href="https:&#x2F;&#x2F;aya.for.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;aya.for.ai</a><p>I&#x27;m a contributor to the project and all data and model will be open-sourced.<p>We&#x27;re looking for contributors in many languages!</div><br/></div></div><div id="37911866" class="c"><input type="checkbox" id="c-37911866" checked=""/><div class="controls bullet"><span class="by">c7DJTLrn</span><span>|</span><a href="#37911581">parent</a><span>|</span><a href="#37911689">prev</a><span>|</span><a href="#37911758">next</a><span>|</span><label class="collapse" for="c-37911866">[-]</label><label class="expand" for="c-37911866">[12 more]</label></div><br/><div class="children"><div class="content">&gt;We need to make sure that AI multilingual to avoid total English domination of culture.<p>Not saying English is an ideal language, but I&#x27;m interested in why you think it shouldn&#x27;t dominate. Wouldn&#x27;t a universal language be a good thing?</div><br/><div id="37912057" class="c"><input type="checkbox" id="c-37912057" checked=""/><div class="controls bullet"><span class="by">pjc50</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911866">parent</a><span>|</span><a href="#37911892">next</a><span>|</span><label class="collapse" for="c-37912057">[-]</label><label class="expand" for="c-37912057">[3 more]</label></div><br/><div class="children"><div class="content">A <i>lingua franca</i> is useful and probably inevitable. The downside is language and cultural loss. Works in translation are rarely quite as good, especially humor and wordplay. This is why various countries have &quot;local language quota&quot; rules for media; although derided by English speakers and HN, they&#x27;re a way to keep the local language, culture and identity alive.</div><br/><div id="37912236" class="c"><input type="checkbox" id="c-37912236" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37912057">parent</a><span>|</span><a href="#37911892">next</a><span>|</span><label class="collapse" for="c-37912236">[-]</label><label class="expand" for="c-37912236">[2 more]</label></div><br/><div class="children"><div class="content">Apriori assuming that those things are somehow intrinsically valuable. These decisions (eg. language quotas) are made by armchair intellectuals with career&#x2F;identity investments in the said language. Language evolution ignores them, but they can be annoying in the interim.</div><br/><div id="37912293" class="c"><input type="checkbox" id="c-37912293" checked=""/><div class="controls bullet"><span class="by">tuukkah</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37912236">parent</a><span>|</span><a href="#37911892">next</a><span>|</span><label class="collapse" for="c-37912293">[-]</label><label class="expand" for="c-37912293">[1 more]</label></div><br/><div class="children"><div class="content">Ehh, are you as a non-intellectual ready to throw away your first language? Also, think of people whose first language is their only language.</div><br/></div></div></div></div></div></div><div id="37911892" class="c"><input type="checkbox" id="c-37911892" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911866">parent</a><span>|</span><a href="#37912057">prev</a><span>|</span><a href="#37911898">next</a><span>|</span><label class="collapse" for="c-37911892">[-]</label><label class="expand" for="c-37911892">[1 more]</label></div><br/><div class="children"><div class="content">Not from an aesthetic sense. I think it&#x27;s really cool that we have a lot of languages. I&#x27;m personally willing to pay a high price in inconvenience to keep that coolness around, although not everyone would.<p>However I also don&#x27;t think we will <i>have</i> to. Machine translation and language learning are substitute goods -- the better the former gets, the fewer people who will feel any desire to pursue the latter, because it just won&#x27;t be that big of a deal to translate between X and Y anyway.<p>A universal second language for commerce is a fine middle ground, though.</div><br/></div></div><div id="37911898" class="c"><input type="checkbox" id="c-37911898" checked=""/><div class="controls bullet"><span class="by">aziaziazi</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911866">parent</a><span>|</span><a href="#37911892">prev</a><span>|</span><a href="#37911968">next</a><span>|</span><label class="collapse" for="c-37911898">[-]</label><label class="expand" for="c-37911898">[6 more]</label></div><br/><div class="children"><div class="content">Languages are like frameworks, they (slightly) guide your thinking. Think about the same stuff in different languages and you’ll probably get more ideas about it than in one language only.</div><br/><div id="37911970" class="c"><input type="checkbox" id="c-37911970" checked=""/><div class="controls bullet"><span class="by">FL33TW00D</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911898">parent</a><span>|</span><a href="#37912048">next</a><span>|</span><label class="collapse" for="c-37911970">[-]</label><label class="expand" for="c-37911970">[1 more]</label></div><br/><div class="children"><div class="content">Orwell demonstrates this concept very powerfully in 1984.</div><br/></div></div><div id="37912048" class="c"><input type="checkbox" id="c-37912048" checked=""/><div class="controls bullet"><span class="by">anonylizard</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911898">parent</a><span>|</span><a href="#37911970">prev</a><span>|</span><a href="#37911945">next</a><span>|</span><label class="collapse" for="c-37912048">[-]</label><label class="expand" for="c-37912048">[1 more]</label></div><br/><div class="children"><div class="content">Moreover, censorship does not cross languages. Its very hard to make a multi-lingual censor system.<p>Being fluent in two major language systems, its very, very glaringly obvious, what are the taboos, politically correct untruths in both languages, that seem completely invisible to the monolingual speakers.</div><br/></div></div><div id="37911945" class="c"><input type="checkbox" id="c-37911945" checked=""/><div class="controls bullet"><span class="by">himinlomax</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911898">parent</a><span>|</span><a href="#37912048">prev</a><span>|</span><a href="#37911968">next</a><span>|</span><label class="collapse" for="c-37911945">[-]</label><label class="expand" for="c-37911945">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the Sapir-Worth hypothesis. It&#x27;s decidedly pre-Chomsky, and as Pinker calls it,  it is both the most well known and accepted linguistic hypothesis and also almost certainly completely wrong.</div><br/><div id="37912132" class="c"><input type="checkbox" id="c-37912132" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911945">parent</a><span>|</span><a href="#37911968">next</a><span>|</span><label class="collapse" for="c-37912132">[-]</label><label class="expand" for="c-37912132">[2 more]</label></div><br/><div class="children"><div class="content">It’s something you just know if you’re bilingual or more. It would sound threatening to monolingual speakers but this is just how it works. Languages are our thought construction algorithms.<p>It’s not a “Turing Completeness isn’t real” hypothesis, more like just “Rust != C”. I think this is where software nerd types predict wrong, as it sounds as if it is trying to disprove TC, which shall be futile attempt. It’s not(the former one at least).</div><br/><div id="37912287" class="c"><input type="checkbox" id="c-37912287" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37912132">parent</a><span>|</span><a href="#37911968">next</a><span>|</span><label class="collapse" for="c-37912287">[-]</label><label class="expand" for="c-37912287">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think this is where software nerd types predict wrong<p>Pinker isn&#x27;t a software nerd, he&#x27;s an evolutionary psychologist and psycholinguist.</div><br/></div></div></div></div></div></div></div></div><div id="37911968" class="c"><input type="checkbox" id="c-37911968" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911866">parent</a><span>|</span><a href="#37911898">prev</a><span>|</span><a href="#37911758">next</a><span>|</span><label class="collapse" for="c-37911968">[-]</label><label class="expand" for="c-37911968">[1 more]</label></div><br/><div class="children"><div class="content">The languages you think in affect your decision making, your creativity, how you perceive the world. If the were were restricted to a single language, we’d lose as individuals and as a species.<p><a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;science&#x2F;2023&#x2F;sep&#x2F;17&#x2F;how-learning-thinking-in-a-foreign-language-improves-decision-making" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theguardian.com&#x2F;science&#x2F;2023&#x2F;sep&#x2F;17&#x2F;how-learning...</a></div><br/></div></div></div></div><div id="37911758" class="c"><input type="checkbox" id="c-37911758" checked=""/><div class="controls bullet"><span class="by">mchaver</span><span>|</span><a href="#37911581">parent</a><span>|</span><a href="#37911866">prev</a><span>|</span><a href="#37911746">next</a><span>|</span><label class="collapse" for="c-37911758">[-]</label><label class="expand" for="c-37911758">[1 more]</label></div><br/><div class="children"><div class="content">It is a concern because presumably most people in office jobs are going to need to be able to use these tools, but I am somewhat comforted to know one language that AI systems do not understand well yet because of lack of texts. However, I think that will be short lived.</div><br/></div></div><div id="37911746" class="c"><input type="checkbox" id="c-37911746" checked=""/><div class="controls bullet"><span class="by">loxdalen</span><span>|</span><a href="#37911581">parent</a><span>|</span><a href="#37911758">prev</a><span>|</span><a href="#37911613">next</a><span>|</span><label class="collapse" for="c-37911746">[-]</label><label class="expand" for="c-37911746">[3 more]</label></div><br/><div class="children"><div class="content">I can speak in my own language with chat gpt without much issue</div><br/><div id="37911776" class="c"><input type="checkbox" id="c-37911776" checked=""/><div class="controls bullet"><span class="by">rjtavares</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911746">parent</a><span>|</span><a href="#37911894">next</a><span>|</span><label class="collapse" for="c-37911776">[-]</label><label class="expand" for="c-37911776">[1 more]</label></div><br/><div class="children"><div class="content">While I can speak in Portuguese without much issues (except being hard for them to stick to European Portuguese), I&#x27;ve nooticed that sometimes it uses a clear translation of an English expression that does not feel natural in Portuguese at all.</div><br/></div></div><div id="37911894" class="c"><input type="checkbox" id="c-37911894" checked=""/><div class="controls bullet"><span class="by">asutekku</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911746">parent</a><span>|</span><a href="#37911776">prev</a><span>|</span><a href="#37911613">next</a><span>|</span><label class="collapse" for="c-37911894">[-]</label><label class="expand" for="c-37911894">[1 more]</label></div><br/><div class="children"><div class="content">You can, but it will get facts more likely wrong than if you converse with it in english</div><br/></div></div></div></div><div id="37911613" class="c"><input type="checkbox" id="c-37911613" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#37911581">parent</a><span>|</span><a href="#37911746">prev</a><span>|</span><a href="#37912044">next</a><span>|</span><label class="collapse" for="c-37911613">[-]</label><label class="expand" for="c-37911613">[2 more]</label></div><br/><div class="children"><div class="content">This will be easy, it will go from mostly English to hyperpolyglot quickly.</div><br/><div id="37911713" class="c"><input type="checkbox" id="c-37911713" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911581">root</a><span>|</span><a href="#37911613">parent</a><span>|</span><a href="#37912044">next</a><span>|</span><label class="collapse" for="c-37911713">[-]</label><label class="expand" for="c-37911713">[1 more]</label></div><br/><div class="children"><div class="content">The issue raised in the article is that there may not be enough training material in many languages to do this.<p>I find this very plausible.</div><br/></div></div></div></div></div></div><div id="37912044" class="c"><input type="checkbox" id="c-37912044" checked=""/><div class="controls bullet"><span class="by">helsinkiandrew</span><span>|</span><a href="#37911581">prev</a><span>|</span><a href="#37911916">next</a><span>|</span><label class="collapse" for="c-37912044">[-]</label><label class="expand" for="c-37912044">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly it&#x27;s using the LUMI supercomputer to do this:
HPE Cray EX supercomputer, 2560 nodes comprised of a 64 core AMD Trento CPU and four AMD MI250X GPUs (128 GB).  With a combined Linpack performance of 375 Pflop&#x2F;s<p><a href="https:&#x2F;&#x2F;www.lumi-supercomputer.eu&#x2F;lumis-full-system-architecture-revealed&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.lumi-supercomputer.eu&#x2F;lumis-full-system-architec...</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LUMI" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LUMI</a></div><br/></div></div><div id="37911916" class="c"><input type="checkbox" id="c-37911916" checked=""/><div class="controls bullet"><span class="by">qwerty456127</span><span>|</span><a href="#37912044">prev</a><span>|</span><a href="#37911842">next</a><span>|</span><label class="collapse" for="c-37911916">[-]</label><label class="expand" for="c-37911916">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if a GPT or something alike could possibly produce a good conlang easy to understand and learn for people of a specific linguistic group by optimally interpolating between their languages and filtering out idiosyncrasies.</div><br/><div id="37911998" class="c"><input type="checkbox" id="c-37911998" checked=""/><div class="controls bullet"><span class="by">pmontra</span><span>|</span><a href="#37911916">parent</a><span>|</span><a href="#37911842">next</a><span>|</span><label class="collapse" for="c-37911998">[-]</label><label class="expand" for="c-37911998">[2 more]</label></div><br/><div class="children"><div class="content">Maybe, but it would take some real effort. This naive attempt of mine is an obvious non starter (it&#x27;s ChatGPT 3.5). Transcript with some minimal editing to fit it into HN:<p>User: Would you be able to develop an artificial language easy to learn and use for speakers of English and romance languages? Extremely simple grammar.<p>ChatGPT: Sure, I&#x27;d focus on minimal grammar, consistent rules, and common vocabulary. It&#x27;s doable.<p>User: Good. Give a name to that language<p>ChatGPT: How about &quot;LinguaEase&quot;?<p>User: OK. Give me some examples starting with translations of the sentences in this chat so far.<p>ChatGPT &quot;LinguaEase Exempla:<p>&gt; &#x27;Sure, I&#x27;d focus on minimal grammar, consistent rules, and common vocabulary.&#x27; becomes &#x27;Yep, keep grammar simple, rules steady, vocab shared.&#x27;<p>&gt; &#x27;How about &quot;LinguaEase&quot;?&#x27; becomes &#x27;What about &quot;LinguaEase&quot;?&#x27;<p>&gt; &#x27;OK. Give me some examples starting with translations of the sentences in this chat so far.&#x27; becomes &#x27;Alright, show me samples, begin with translations of this chat&#x27;s sentences.&#x27;&quot;<p>I went with English and romance languages because they are the languages I know. It looks all English to me.<p>I would probably have had to be more specific. For example: only present tense. No plural. No gender. Only one set of pronouns. Aim to sentences like Beer two me drink yesterday. Beer ten me buy tomorrow. Then work on vocabulary.</div><br/><div id="37912284" class="c"><input type="checkbox" id="c-37912284" checked=""/><div class="controls bullet"><span class="by">d1sxeyes</span><span>|</span><a href="#37911916">root</a><span>|</span><a href="#37911998">parent</a><span>|</span><a href="#37911842">next</a><span>|</span><label class="collapse" for="c-37912284">[-]</label><label class="expand" for="c-37912284">[1 more]</label></div><br/><div class="children"><div class="content">I agree it would be very difficult. I think that current LLMs would fail here because I don&#x27;t think they would be able to make a value judgement about what is &#x27;harder&#x27; between &#x27;I drank two beers yesterday&#x27; and &#x27;Beer two me drink yesterday&#x27;. In fact, I&#x27;m not sure most linguists would agree.<p>All languages are something of a compromise between accuracy and simplicity. An LLM is currently not equipped to make decisions about the correct balance between accuracy and simplicity.<p>For example, English eschews cases (in most situations) in favour of fixed word order. &#x27;Beer two me drink yesterday&#x27; violates that rule (and in fact, manages to use case incorrectly in one of the few places the vestiges of a case system still exist in English).<p>However, a sentence constructed using the same structure as yours highlights a problem.<p>&#x27;Me two dog bite yesterday&#x27;<p>Did you bite two dogs or were you bitten by two dogs? How can you tell? English has the subject of the sentence (the thing&#x2F;person doing the verb) first, then the verb, then the object (the thing having the verb done to it). In languages with more fluid word order, normally a case marker is added to either the determiner or the noun itself:<p>&#x27;Me-o two dog bite yesterday&#x27;. Let&#x27;s choose &#x27;-o&#x27; as our accusative case ending.  Now we can tell that it was you who was bitten by the dog.<p>Next problem: what if instead of &#x27;me&#x27; it&#x27;s &#x27;man&#x27;.<p>&#x27;Man-o two dog bite yesterday&#x27;. How do we know whether it&#x27;s two men, or two dogs? Again, English keeps the number with the noun it refers to. Most languages do, but some also put a marker on the number to make it clear.<p>&#x27;Man-o two-o dog bite yesterday&#x27;. Now we can tell that two men were bitten by some number of dogs. Next problem is that we don&#x27;t know how many dogs bit the men. Were two men bitten by the same dog, or different dogs? Were two men surrounded by a pack of dogs? Is it important? Most languages care about this enough to at least mark the plural.<p>What if we don&#x27;t know exactly when the men were bitten? We could have some generic word like &#x27;past&#x27;, to make &#x27;man-o two-o dog bite past&#x27;.<p>But at that point, is your conlang <i>really</i> any easier than English, or just different?</div><br/></div></div></div></div></div></div><div id="37911842" class="c"><input type="checkbox" id="c-37911842" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#37911916">prev</a><span>|</span><a href="#37911825">next</a><span>|</span><label class="collapse" for="c-37911842">[-]</label><label class="expand" for="c-37911842">[4 more]</label></div><br/><div class="children"><div class="content">ChatGPT is a single pass for each character. It can&#x27;t &quot;think&quot; in English then translate it.  
It will often respond in English instead of the language you are using.  
Yes, it&#x27;s better in English than any other languages, because the English dataset is bigger, and that&#x27;s why an English AI will always be slightly better with the same technology.</div><br/><div id="37912214" class="c"><input type="checkbox" id="c-37912214" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#37911842">parent</a><span>|</span><a href="#37911905">next</a><span>|</span><label class="collapse" for="c-37912214">[-]</label><label class="expand" for="c-37912214">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT does not think and we’re anthropomorphizing it. Having said that, it does “sound” like they are thinking in en-US or as if they are machine-translating English boilerplates.<p>e.g. wouldn’t say “cake may be cutted by a knife” and instead would say “knives can cut cakes”, <i>always</i>. In languages which the first example would be more correct and the latter would be borderline incorrect, GPTs tend to prioritize the second pattern. And this isn’t ideal.</div><br/></div></div><div id="37911905" class="c"><input type="checkbox" id="c-37911905" checked=""/><div class="controls bullet"><span class="by">xico</span><span>|</span><a href="#37911842">parent</a><span>|</span><a href="#37912214">prev</a><span>|</span><a href="#37911877">next</a><span>|</span><label class="collapse" for="c-37911905">[-]</label><label class="expand" for="c-37911905">[1 more]</label></div><br/><div class="children"><div class="content">That’s indeed its interface, but there is still a huge training phase during which the model was taught using mostly English, and it explains why some other languages interactions feel like they are some direct translation of English expressions (not to mention higher ways of thinking). Most of the thinking indeed is done during training, and then encoded in the weights which act like a huge cache of thoughts, but there is still a lot of learning on how to use the context when you emit this character (token), the attention layers, which is also a form of thinking that uses whatever new input you are giving to the model and applies a series of transformations (granted, finite in current models) to it.</div><br/></div></div><div id="37911877" class="c"><input type="checkbox" id="c-37911877" checked=""/><div class="controls bullet"><span class="by">dustypotato</span><span>|</span><a href="#37911842">parent</a><span>|</span><a href="#37911905">prev</a><span>|</span><a href="#37911825">next</a><span>|</span><label class="collapse" for="c-37911877">[-]</label><label class="expand" for="c-37911877">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ChatGPT is a single pass for each character.<p>Not for each token?</div><br/></div></div></div></div><div id="37911825" class="c"><input type="checkbox" id="c-37911825" checked=""/><div class="controls bullet"><span class="by">kunley</span><span>|</span><a href="#37911842">prev</a><span>|</span><a href="#37911572">next</a><span>|</span><label class="collapse" for="c-37911825">[-]</label><label class="expand" for="c-37911825">[5 more]</label></div><br/><div class="children"><div class="content">ChatGPT does not think.</div><br/><div id="37911873" class="c"><input type="checkbox" id="c-37911873" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#37911825">parent</a><span>|</span><a href="#37911572">next</a><span>|</span><label class="collapse" for="c-37911873">[-]</label><label class="expand" for="c-37911873">[4 more]</label></div><br/><div class="children"><div class="content">Are you <i>sure?</i> How would you even know!?<p>This is like a machine intelligence casually dismissing a brain as not being able to properly think, since meat can&#x27;t compute.[1]<p>Don&#x27;t confuse the substrate or the training method with the result.<p>[1] Obligatory reference: <a href="https:&#x2F;&#x2F;www.mit.edu&#x2F;people&#x2F;dpolicar&#x2F;writing&#x2F;prose&#x2F;text&#x2F;thinkingMeat.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.mit.edu&#x2F;people&#x2F;dpolicar&#x2F;writing&#x2F;prose&#x2F;text&#x2F;think...</a></div><br/><div id="37912123" class="c"><input type="checkbox" id="c-37912123" checked=""/><div class="controls bullet"><span class="by">kunley</span><span>|</span><a href="#37911825">root</a><span>|</span><a href="#37911873">parent</a><span>|</span><a href="#37911942">next</a><span>|</span><label class="collapse" for="c-37912123">[-]</label><label class="expand" for="c-37912123">[1 more]</label></div><br/><div class="children"><div class="content">I will wait until machine intelligence will have any symptoms of being conscious, then it will be able to &quot;dismiss&quot; anything. Until then, it&#x27;s just another mathematical model, used recently for several new hyped schemas of making money.</div><br/></div></div><div id="37911888" class="c"><input type="checkbox" id="c-37911888" checked=""/><div class="controls bullet"><span class="by">diogenes4</span><span>|</span><a href="#37911825">root</a><span>|</span><a href="#37911873">parent</a><span>|</span><a href="#37911942">prev</a><span>|</span><a href="#37911572">next</a><span>|</span><label class="collapse" for="c-37911888">[-]</label><label class="expand" for="c-37911888">[1 more]</label></div><br/><div class="children"><div class="content">Hell i&#x27;m not even sure you or I think. This is the problem with referring to subjective perception when we can&#x27;t be sure we&#x27;re even referring to the same thing. A &quot;thought&quot; might just be a linguistic quirk of two meats exchanging information.</div><br/></div></div></div></div></div></div><div id="37911572" class="c"><input type="checkbox" id="c-37911572" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#37911825">prev</a><span>|</span><label class="collapse" for="c-37911572">[-]</label><label class="expand" for="c-37911572">[23 more]</label></div><br/><div class="children"><div class="content">“think”. Think of the average person and then think that half of the world is less smart than that. Those people are the target audience for news articles and products that use terms such as “think” and fear mongering when it comes to a”i”.</div><br/><div id="37911649" class="c"><input type="checkbox" id="c-37911649" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#37911572">parent</a><span>|</span><label class="collapse" for="c-37911649">[-]</label><label class="expand" for="c-37911649">[22 more]</label></div><br/><div class="children"><div class="content">This is pointless and frankly baseless pedantry. There&#x27;s no reason to artificially restrict the word &quot;think&quot; to squashy brains.</div><br/><div id="37911698" class="c"><input type="checkbox" id="c-37911698" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911649">parent</a><span>|</span><a href="#37911738">next</a><span>|</span><label class="collapse" for="c-37911698">[-]</label><label class="expand" for="c-37911698">[13 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t like your parent comment but there&#x27;s merit in avoiding people believing those things actually think and are actually intelligent. In &quot;thinking&quot;, there&#x27;s reasoning, which those things currently don&#x27;t. They output text statistically and that&#x27;s what mass media should tell their audience.</div><br/><div id="37911870" class="c"><input type="checkbox" id="c-37911870" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911698">parent</a><span>|</span><a href="#37911780">next</a><span>|</span><label class="collapse" for="c-37911870">[-]</label><label class="expand" for="c-37911870">[5 more]</label></div><br/><div class="children"><div class="content">What is, then, the qualitative difference between a GOFAI automated reasoning system [1], like Coq, and an LLM? Why does Coq do reasoning but GPT-4 doesn&#x27;t? Does it only count as reasoning if hand-coded by a human? Or did you have another definition of &quot;reasoning&quot; in mind?<p>Statistical or probabilistic reasoning is still reasoning, and indeed essentially mandatory to make sense of the real world, and is what humans do. Indeed the failure of painstakingly hand-trained symbolic reasoning engines to model reality (as opposed to just simple toy worlds) was the entire reason for the rise of neural networks.<p>The entire point of a neural network is to efficiently compress large amounts of statistical data into a model with as much predictive power as possible. Somewhere within GPT-4&#x27;s many layers there has to exist something like Bayes networks and other ultra-efficient representations of the vast network of correlations present in the training corpus – otherwise there&#x27;s no way it could do what it does.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Automated_reasoning" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Automated_reasoning</a></div><br/><div id="37911979" class="c"><input type="checkbox" id="c-37911979" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911870">parent</a><span>|</span><a href="#37911780">next</a><span>|</span><label class="collapse" for="c-37911979">[-]</label><label class="expand" for="c-37911979">[4 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t know &quot;automated reasoning&quot; was an actual technical term.<p>I didn&#x27;t mean this by &quot;reasoning&quot;. To me, Coq does not reason (in the meaning I intended). It checks proofs are well-formed and assists proof writing.<p>But yes, there&#x27;s some implementation of logic in Coq. It applies (a specific form of) logic. Again, LLMs output probable text. They don&#x27;t do logic. They do statistics on language.<p>Coq works on the actual objects themselves directly, not on the text that presents them.<p>LLMs usually fail to answer to riddles correctly for this reason. We saw plenty of occurrences of this in recent times. Each time LLMs are benchmarked, people think of trying riddles and it works to some extent because something that looks like these riddles are in the training set but it eventually fails. Humans also make mistakes when solving riddles, but not for the same reasons (the process is not the same, they are not &quot;processing text&quot;, the are really processing logic, even if the process is fallible).</div><br/><div id="37912054" class="c"><input type="checkbox" id="c-37912054" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911979">parent</a><span>|</span><a href="#37912071">next</a><span>|</span><label class="collapse" for="c-37912054">[-]</label><label class="expand" for="c-37912054">[1 more]</label></div><br/><div class="children"><div class="content">So you just replaced the nebulously defined word &quot;think&quot; with an equally nebulously defined word, &quot;reason&quot;? Not a very convincing argument.<p>You do not <i>know</i> what humans do, no human does, as we don&#x27;t have such an access to our internal representations. You neither know what LLMs do, no human does, as even though we have full access to their internals, we have little to no idea how to interpret said internals.<p>The most interesting thing about LLMs is the degree that they have learned to model the real world while only being exposed to <i>words</i>. Because those words are highly correlated not just with each other, but with an external entity unknown to the LLM, it&#x27;s very likely that by learning to model that external entity, the LLM&#x27;s word-predicting power will increase. LLMs are likely to have converged on a world-model simply because it makes the most sense given the available evidence.<p>This is no different from how human scientists create models of things they cannot directly see based on what they <i>can</i> see. And of course, &quot;seeing&quot; is not directly perceiving the external reality either! Sensory data merely <i>correlates</i> with what&#x27;s really going on, and the brain has learned to model the world – an unknown external entity – based on the correlations that exist in the sensory <i>language</i>.</div><br/></div></div><div id="37912071" class="c"><input type="checkbox" id="c-37912071" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911979">parent</a><span>|</span><a href="#37912054">prev</a><span>|</span><a href="#37911780">next</a><span>|</span><label class="collapse" for="c-37912071">[-]</label><label class="expand" for="c-37912071">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Coq works on the actual objects themselves directly, not on the text that presents them.<p>Coq parses the text to an abstract representation and so do LLMs.</div><br/><div id="37912265" class="c"><input type="checkbox" id="c-37912265" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37912071">parent</a><span>|</span><a href="#37911780">next</a><span>|</span><label class="collapse" for="c-37912265">[-]</label><label class="expand" for="c-37912265">[1 more]</label></div><br/><div class="children"><div class="content">This does not say much. What&#x27;s interesting is what do they do with this abstract representation, and what is represented in this representation and how.<p>Compilers translate their abstract interpretation to another programming language, usually native assembly code or bytecode. Coq applies &#x2F; verifies logical (inductive) inferences on logical objects (rules, proofs, axioms, predicates) (not a Coq expert, details should be checked).
LLMs predict next words.</div><br/></div></div></div></div></div></div></div></div><div id="37911780" class="c"><input type="checkbox" id="c-37911780" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911698">parent</a><span>|</span><a href="#37911870">prev</a><span>|</span><a href="#37911738">next</a><span>|</span><label class="collapse" for="c-37911780">[-]</label><label class="expand" for="c-37911780">[7 more]</label></div><br/><div class="children"><div class="content">What is &quot;reasoning&quot;? Wikipedia surprised me with this opening paragraph:<p>&gt; Reason is the capacity of applying logic consciously by drawing conclusions from new or existing information, with the aim of seeking the truth, with more than 10 or more than 3 evidence, 99.9% reliability or 87.5% reliability.<p>Apart from the words &quot;consciously&quot; (which has 100 or so different definitions, some of which do and some of which do not apply to AI), and &quot;aim&quot; which can be contentious depending upon if you feel that requires consciousness or can include training rewards… I think the best of them is at the lower of those two mysterious percentages I&#x27;ve never seen discussed before.<p>And that&#x27;s despite LLMs being wildly bad at, specifically, logic. Though even this specific weakness in general seems like a very easy thing to get around by hybridising it with the computer it has to run on e.g. by telling it how to use a compiler, as logic is the foundation of the arithmetic that the transformers use to do natural language comprehension in the first place.</div><br/><div id="37911835" class="c"><input type="checkbox" id="c-37911835" checked=""/><div class="controls bullet"><span class="by">vikramkr</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911780">parent</a><span>|</span><a href="#37911887">next</a><span>|</span><label class="collapse" for="c-37911835">[-]</label><label class="expand" for="c-37911835">[4 more]</label></div><br/><div class="children"><div class="content">That opening for the Wikipedia article looks problematic - it&#x27;s grammatically nonsense and has random numbers in it - someone should probably open a talk discussion on what happened<p>Edit: yeah that looks like a recent edit. I thought Wikipedia was supposed to be pretty good about flagging this sort of stuff? Does anyone know how to raise the problem to those super editors that run the site? I assume they won&#x27;t appreciate a random person undoing an edit<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=Reason&amp;diff=prev&amp;oldid=1179925542" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=Reason&amp;diff=prev&amp;...</a></div><br/><div id="37911885" class="c"><input type="checkbox" id="c-37911885" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911835">parent</a><span>|</span><a href="#37911887">next</a><span>|</span><label class="collapse" for="c-37911885">[-]</label><label class="expand" for="c-37911885">[3 more]</label></div><br/><div class="children"><div class="content">If I was on desktop right now, I&#x27;d put the new bit after the existing citation and add a new {{citation needed}} for the addition.<p>Don&#x27;t worry too much about diving in, so long as you comment your changes appropriately when committing, that&#x27;s the point of the place and how it does the quality control in the first place :)</div><br/><div id="37911909" class="c"><input type="checkbox" id="c-37911909" checked=""/><div class="controls bullet"><span class="by">vikramkr</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911885">parent</a><span>|</span><a href="#37911887">next</a><span>|</span><label class="collapse" for="c-37911909">[-]</label><label class="expand" for="c-37911909">[2 more]</label></div><br/><div class="children"><div class="content">Leaving a citation needed doesn&#x27;t sound like the right thing to do for the definition of something as big as reason - esp with the grammatical confusion idk what you&#x27;d even edit it to to make sense. Like what is a three evidence or a reliability and what do those reliability numbers mean. And the sentence describing those numbers doesn&#x27;t make sense - is it 10 or 3 or which of those percentages? Idk maybe it should just be undone</div><br/><div id="37911980" class="c"><input type="checkbox" id="c-37911980" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911909">parent</a><span>|</span><a href="#37911887">next</a><span>|</span><label class="collapse" for="c-37911980">[-]</label><label class="expand" for="c-37911980">[1 more]</label></div><br/><div class="children"><div class="content">Then be bold with the edits and delete it, just say why in the comment box. The deletion itself is as easy to undo as to perform, and if you say why you&#x27;re doing it, someone bringing that part back can do a better job next time. :)</div><br/></div></div></div></div></div></div></div></div><div id="37911887" class="c"><input type="checkbox" id="c-37911887" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911780">parent</a><span>|</span><a href="#37911835">prev</a><span>|</span><a href="#37911738">next</a><span>|</span><label class="collapse" for="c-37911887">[-]</label><label class="expand" for="c-37911887">[2 more]</label></div><br/><div class="children"><div class="content">&gt; And that&#x27;s despite LLMs being wildly bad at, specifically, logic.<p>I&#x27;d say &quot;wildly bad&quot; is wildly exaggerated given that GPT-4 exists, even if you define &quot;logic&quot; as &quot;logical puzzles encoded in natural language&quot; and not &quot;the thing that allows an LLM to reason highly efficiently about what token comes next&quot;.</div><br/><div id="37912020" class="c"><input type="checkbox" id="c-37912020" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911887">parent</a><span>|</span><a href="#37911738">next</a><span>|</span><label class="collapse" for="c-37912020">[-]</label><label class="expand" for="c-37912020">[1 more]</label></div><br/><div class="children"><div class="content">The numbers in Table 1 of this paper are mostly worse than I remembered, but I would also note that humans would fail the &quot;can they reason?&quot; standard I quoted, given the grades the species gets on several of the tests:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2304.03439.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2304.03439.pdf</a><p>Table 2 likewise shows significant weaknesses in GPT-4, worse than I remember, except on MED which was better than I remember it being capable of.<p>&gt; even if you define &quot;logic&quot; as &quot;logical puzzles encoded in natural language&quot; and not &quot;the thing that allows an LLM to reason highly efficiently about what token comes next&quot;.<p>I think this is a reasonable thing to say of LLMs specifically[0], given I think most people would agree with the sentence &quot;humans are bad at quantum mechanics&quot; even though that&#x27;s what our cell chemistry is implemented on.<p>[0] Though not AI in general! One of my recently-developed bug-bears is the conflation of the limits of LLMs with AI even in technical circles. Human brains aren&#x27;t just a language cortex, there&#x27;s no reason to look at an isolated language model and assume an AI can&#x27;t be wired into other things, yet this assumption is baked into quite a lot of talking points even on HN.</div><br/></div></div></div></div></div></div></div></div><div id="37911738" class="c"><input type="checkbox" id="c-37911738" checked=""/><div class="controls bullet"><span class="by">s_dev</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911649">parent</a><span>|</span><a href="#37911698">prev</a><span>|</span><a href="#37911737">next</a><span>|</span><label class="collapse" for="c-37911738">[-]</label><label class="expand" for="c-37911738">[5 more]</label></div><br/><div class="children"><div class="content">Google doesn&#x27;t &#x27;think&#x27; and neither does ChatGPT. I will give you a hard limit on what a machine can&#x27;t compute -- it will never figure out given a programming script and an input when that program will stop. A human can do it by thinking through the problem -- whatever that process&#x2F;phenomena of thought actually is it can think outside of itself and that fundamentally seperates it from a program even one as sophisticated as ChatGPT.</div><br/><div id="37911901" class="c"><input type="checkbox" id="c-37911901" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911738">parent</a><span>|</span><a href="#37911861">next</a><span>|</span><label class="collapse" for="c-37911901">[-]</label><label class="expand" for="c-37911901">[1 more]</label></div><br/><div class="children"><div class="content">Have you verified this hypothesis of yours? In my experience GPT4 especially can definitely &quot;think through&quot; what a program does and arrive at the result.<p>Even the significantly dumber ChatGPT can do this: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;3ee29c5e-6cb4-485f-b0b4-29e982463687" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;3ee29c5e-6cb4-485f-b0b4-29e982...</a><p>People mistakenly think that it&#x27;s just regurgitating what it has seen on the web, but even if you don&#x27;t prompt it in English it&#x27;ll still a) solve the problem correctly, and b) do it in the target language: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;5b4e6e99-3fd8-4316-811c-2a9dec776f63" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;5b4e6e99-3fd8-4316-811c-2a9dec...</a><p>If that&#x27;s not impressive enough, the ability to round-trip from script-to-poem and then poem-to-script should <i>blow your mind:</i><p><pre><code>    What might have been the original PowerShell script snippet that inspired this poem?
    Be as terse as possible, using aliases where possible.    
        
    In the realm of numbers, a tale begins,      
    Where $x is a 7, with a smile it grins.      
    From one to ten, the journey we thread,      
    Adding 7 to $x, step by step we tread.      
           
    $x grows and grows, like a tree so tall,      
    With every step, it doesn&#x27;t fall.      
    Once the journey ends, not a moment we relax,      
    Triple the fun, we do with $x.      
           
    In this dance of digits and the arithmetic song,      
    With $x as our guide, we whirl along.      
    From start to finish, through each complex,      
    This is the tale of our friend, $x.

    Here&#x27;s a terse PowerShell script snippet that inspired the poem:  
       
    ```powershell  
    $x = 7  
    1..10 | % {$x += 7}  
    $x *= 3  
    ```
</code></pre>
Disclaimer: the above required GPT4 with careful prompting. Notably ChatGPT 3.5 couldn&#x27;t solve it, and asking for just a &quot;script&quot; resulted in pseudocode instead of PowerShell.</div><br/></div></div><div id="37911861" class="c"><input type="checkbox" id="c-37911861" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911738">parent</a><span>|</span><a href="#37911901">prev</a><span>|</span><a href="#37911883">next</a><span>|</span><label class="collapse" for="c-37911861">[-]</label><label class="expand" for="c-37911861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A human can do it by thinking through the problem<p>No, we cannot.<p>Imagine a program that looks for the smallest counterexample to the Collatz conjecture.<p><i>Nobody knows if it will ever terminate</i>.</div><br/></div></div><div id="37911883" class="c"><input type="checkbox" id="c-37911883" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911738">parent</a><span>|</span><a href="#37911861">prev</a><span>|</span><a href="#37911837">next</a><span>|</span><label class="collapse" for="c-37911883">[-]</label><label class="expand" for="c-37911883">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A human can do it by thinking through the problem<p>No. Humans cannot solve the halting problem. It is unsolvable. Cannot be solved manually or automatically.<p>&gt; It will never figure out given a programming script and an input when that program will stop<p>It can for some programs. Just like humans can for some programs but not all.</div><br/></div></div><div id="37911837" class="c"><input type="checkbox" id="c-37911837" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911738">parent</a><span>|</span><a href="#37911883">prev</a><span>|</span><a href="#37911737">next</a><span>|</span><label class="collapse" for="c-37911837">[-]</label><label class="expand" for="c-37911837">[1 more]</label></div><br/><div class="children"><div class="content">The limits on the halting problem are the same for a human and a computer. People aren&#x27;t hypercomputers.</div><br/></div></div></div></div><div id="37911737" class="c"><input type="checkbox" id="c-37911737" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911649">parent</a><span>|</span><a href="#37911738">prev</a><span>|</span><a href="#37911806">next</a><span>|</span><label class="collapse" for="c-37911737">[-]</label><label class="expand" for="c-37911737">[1 more]</label></div><br/><div class="children"><div class="content">Is it really baseless? I&#x27;d say it depends on your theory of mind and is a serious question which generates interesting discussion.<p>Myself I don&#x27;t consider &quot;think&quot; an appropriate term, since the super-Markov-chain types of LLM right now seem to miss out on important aspects of cognition, particularly synthesis of two disparate ideas. It&#x27;s hard to test this since you need to ask it about things which aren&#x27;t already discussed in its corpus, but even GPT-4 tends to disappoint me when I ask it weird questions that have straightforward answers but probably aren&#x27;t written about much.<p>As an example, I asked how I could go about obtaining a large quantity of animal skulls cheaply. It directed me to taxidermists and specialists dealing in bones of exotic animals, whereas it could be much easier to go to an abbatoir, or even buy whole animals (since the exotic ones are so expensive).</div><br/></div></div><div id="37911806" class="c"><input type="checkbox" id="c-37911806" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911649">parent</a><span>|</span><a href="#37911737">prev</a><span>|</span><label class="collapse" for="c-37911806">[-]</label><label class="expand" for="c-37911806">[2 more]</label></div><br/><div class="children"><div class="content">No. You&#x27;re wrong. It&#x27;s important and we need to stomp on random use of language like this, which has consequences.<p>It&#x27;s not thinking and you are dangerously wrong if you don&#x27;t understand why. The danger isn&#x27;t AGI it&#x27;s misplaced belief in the state of AI. Call this thinking and you skew perceptions.</div><br/><div id="37911855" class="c"><input type="checkbox" id="c-37911855" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#37911572">root</a><span>|</span><a href="#37911806">parent</a><span>|</span><label class="collapse" for="c-37911855">[-]</label><label class="expand" for="c-37911855">[1 more]</label></div><br/><div class="children"><div class="content">All they need to do is put the word in quotes. ChatGPT Equivalent begins to &quot;think&quot; in Estonian.<p>Any better suggestions? Thinking itself isn&#x27;t exactly a rigorously-defined word. Do animals think?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>