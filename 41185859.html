<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723107666744" as="style"/><link rel="stylesheet" href="styles.css?v=1723107666744"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/gazette">Gazette: Cloud-native millisecond-latency streaming</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>danthelion</span> | <span>30 comments</span></div><br/><div><div id="41188424" class="c"><input type="checkbox" id="c-41188424" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41186384">next</a><span>|</span><label class="collapse" for="c-41188424">[-]</label><label class="expand" for="c-41188424">[1 more]</label></div><br/><div class="children"><div class="content">From reading the docs, this has an IMO surprising design decision: the “journal” is a stream of <i>bytes</i>, where each append (of a byte string) is atomic and occurs in a global order.  The bytes are grouped into fragments, and no write spans a fragment boundary.<p>This seems sort of okay if writes are self-delimiting and never corrupt, and synchronization can always be recovered at a fragment boundary.<p>I suppose it’s neat that one can write JSONL and get actual JSONL in the blobs. But this seems quite brittle if multiple writers write to one journal and one malfunctions (aside from possibly failing to write a delimiter, there’s no way to tell who wrote a record, and using only a single writer per journal seems to defeat the purpose).  And getting, say, Parquet output doesn’t seem like it will happen in any sensible way.</div><br/></div></div><div id="41186384" class="c"><input type="checkbox" id="c-41186384" checked=""/><div class="controls bullet"><span class="by">danthelion</span><span>|</span><a href="#41188424">prev</a><span>|</span><a href="#41187440">next</a><span>|</span><label class="collapse" for="c-41186384">[-]</label><label class="expand" for="c-41186384">[2 more]</label></div><br/><div class="children"><div class="content">Gazette is at the core of Estuary Flow (<a href="https:&#x2F;&#x2F;estuary.dev" rel="nofollow">https:&#x2F;&#x2F;estuary.dev</a>), a real-time data platform. Unlike Kafka, Gazette’s architecture is simpler to reason about and operate. It plays well with k8s and is backed by S3 (or any object storage).</div><br/><div id="41188737" class="c"><input type="checkbox" id="c-41188737" checked=""/><div class="controls bullet"><span class="by">Onavo</span><span>|</span><a href="#41186384">parent</a><span>|</span><a href="#41187440">next</a><span>|</span><label class="collapse" for="c-41188737">[-]</label><label class="expand" for="c-41188737">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, are there any open source alternatives to tinybird?<p><a href="https:&#x2F;&#x2F;www.tinybird.co&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.tinybird.co&#x2F;</a></div><br/></div></div></div></div><div id="41187440" class="c"><input type="checkbox" id="c-41187440" checked=""/><div class="controls bullet"><span class="by">abrookewood</span><span>|</span><a href="#41186384">prev</a><span>|</span><a href="#41187898">next</a><span>|</span><label class="collapse" for="c-41187440">[-]</label><label class="expand" for="c-41187440">[1 more]</label></div><br/><div class="children"><div class="content">More details viewable here: <a href="https:&#x2F;&#x2F;gazette.readthedocs.io&#x2F;en&#x2F;latest&#x2F;" rel="nofollow">https:&#x2F;&#x2F;gazette.readthedocs.io&#x2F;en&#x2F;latest&#x2F;</a></div><br/></div></div><div id="41187898" class="c"><input type="checkbox" id="c-41187898" checked=""/><div class="controls bullet"><span class="by">oatmeal_croc</span><span>|</span><a href="#41187440">prev</a><span>|</span><a href="#41187560">next</a><span>|</span><label class="collapse" for="c-41187898">[-]</label><label class="expand" for="c-41187898">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the use case for millisecond-latency streaming? HFT? Remotely driving heavy machinery? Anything else?</div><br/><div id="41188001" class="c"><input type="checkbox" id="c-41188001" checked=""/><div class="controls bullet"><span class="by">mbrock</span><span>|</span><a href="#41187898">parent</a><span>|</span><a href="#41187915">next</a><span>|</span><label class="collapse" for="c-41188001">[-]</label><label class="expand" for="c-41188001">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s less about guaranteed 1ms real time transactions and more about, like, it&#x27;s just fast enough that you most likely don&#x27;t have to worry about it introducing perceptible lag?<p>I&#x27;m working on a streaming audio thing and keeping latency low is a priority. I actually think I&#x27;ll try Gazette, I just saw it now and it was one of those moments where it&#x27;s like wait I go to Hacker News to waste time but this is quite exactly what I&#x27;ve been wanting in so many ways.<p>I&#x27;ll use it for Ogg&#x2F;Opus media streams, transcription results, chat events, LLM inferences...<p>I really like the byte-indexed append-only blob paradigm backed by object storage. It feels kind of like Unix as a distributed streaming system.<p>Other streaming data gadgets like Kafka always feel a bit uncomfortable and annoying to me with their idiosyncratic record formats and topic hierarchies and whatnot... I always wanted something more low level and obvious...</div><br/><div id="41189419" class="c"><input type="checkbox" id="c-41189419" checked=""/><div class="controls bullet"><span class="by">rswail</span><span>|</span><a href="#41187898">root</a><span>|</span><a href="#41188001">parent</a><span>|</span><a href="#41187915">next</a><span>|</span><label class="collapse" for="c-41189419">[-]</label><label class="expand" for="c-41189419">[1 more]</label></div><br/><div class="children"><div class="content">&gt; wait I go to Hacker News to waste time but this is quite exactly what I&#x27;ve been wanting in so many ways.<p>This has happened so many times for me that I don&#x27;t consider the time &quot;wasted&quot;. I try to make sure I separate the a) &quot;this is interesting personally&quot;, and b) &quot;this is interesting professionally&quot; threads and have a bunch of open tabs for a) that I can &quot;read later&quot;.<p>But the items in (b) I read &quot;now&quot; and consider that to be work, not pleasure.</div><br/></div></div></div></div><div id="41187915" class="c"><input type="checkbox" id="c-41187915" checked=""/><div class="controls bullet"><span class="by">freeqaz</span><span>|</span><a href="#41187898">parent</a><span>|</span><a href="#41188001">prev</a><span>|</span><a href="#41187560">next</a><span>|</span><label class="collapse" for="c-41187915">[-]</label><label class="expand" for="c-41187915">[1 more]</label></div><br/><div class="children"><div class="content">Collaborative systems come to mind. If you edit a document and want to subscribe to changes from other nodes it is valuable to have very low latency.</div><br/></div></div></div></div><div id="41187560" class="c"><input type="checkbox" id="c-41187560" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#41187898">prev</a><span>|</span><a href="#41186772">next</a><span>|</span><label class="collapse" for="c-41187560">[-]</label><label class="expand" for="c-41187560">[7 more]</label></div><br/><div class="children"><div class="content">Where can I get nanosecond latency streaming?</div><br/><div id="41187730" class="c"><input type="checkbox" id="c-41187730" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#41187560">parent</a><span>|</span><a href="#41187639">next</a><span>|</span><label class="collapse" for="c-41187730">[-]</label><label class="expand" for="c-41187730">[5 more]</label></div><br/><div class="children"><div class="content">The screen in front of your face. That&#x27;ll give you like 3ns latency.</div><br/><div id="41188267" class="c"><input type="checkbox" id="c-41188267" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41187560">root</a><span>|</span><a href="#41187730">parent</a><span>|</span><a href="#41187639">next</a><span>|</span><label class="collapse" for="c-41188267">[-]</label><label class="expand" for="c-41188267">[4 more]</label></div><br/><div class="children"><div class="content">It is frequently faster to send an IP packet to another continent than to change a pixel on the screen.</div><br/><div id="41188357" class="c"><input type="checkbox" id="c-41188357" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#41187560">root</a><span>|</span><a href="#41188267">parent</a><span>|</span><a href="#41187639">next</a><span>|</span><label class="collapse" for="c-41188357">[-]</label><label class="expand" for="c-41188357">[3 more]</label></div><br/><div class="children"><div class="content">No it isn&#x27;t. John Carmack found a tv ten years ago that had 200-300ms of latency due to all its post processing and wrote an essay about it.<p>That doesn&#x27;t mean that it is &quot;frequently&quot; faster to send packets to other continents than change pixels on screens. It doesn&#x27;t even apply to modern tvs set up for latency, let alone computer monitors.</div><br/><div id="41188646" class="c"><input type="checkbox" id="c-41188646" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41187560">root</a><span>|</span><a href="#41188357">parent</a><span>|</span><a href="#41187639">next</a><span>|</span><label class="collapse" for="c-41188646">[-]</label><label class="expand" for="c-41188646">[2 more]</label></div><br/><div class="children"><div class="content">Yes, it really is. The problem is it takes a lot more than one frame for most modern software to change a pixel on the screen. I&#x27;m sitting in Hawaii on wifi right now and the first random US mainland server I pinged responded in 120ms, which means sending only took 60ms. Now say you&#x27;re running a 30 Hz game with 2 frames of input lag, and you&#x27;ve already lost before even considering the input lag of the monitor itself.<p>There are just so many ways to accidentally get many frames of input lag. OS window compositors generally add a whole frame of input lag globally to every windowed app. Anything running in a browser has a second compositor in between it and the display that can add more frames. GPU APIs typically buffer one or two frames by default. And all of that is on top of whatever the app itself does, and whatever the monitor does (and whatever the input device does if you want to count that too).</div><br/><div id="41188687" class="c"><input type="checkbox" id="c-41188687" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#41187560">root</a><span>|</span><a href="#41188646">parent</a><span>|</span><a href="#41187639">next</a><span>|</span><label class="collapse" for="c-41188687">[-]</label><label class="expand" for="c-41188687">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OS window compositors generally add a whole frame of input lag globally to every windowed app.<p>Is there a way to verify this is the case? In X11 Linux specifically.<p>Also does variable refresh rate like freesync help with this?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41187639" class="c"><input type="checkbox" id="c-41187639" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41187560">parent</a><span>|</span><a href="#41187730">prev</a><span>|</span><a href="#41186772">next</a><span>|</span><label class="collapse" for="c-41187639">[-]</label><label class="expand" for="c-41187639">[1 more]</label></div><br/><div class="children"><div class="content">A wire</div><br/></div></div></div></div><div id="41186772" class="c"><input type="checkbox" id="c-41186772" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41187560">prev</a><span>|</span><label class="collapse" for="c-41186772">[-]</label><label class="expand" for="c-41186772">[14 more]</label></div><br/><div class="children"><div class="content">I feel a bit paralyzed by Fear Of Missing Io_Uring. There&#x27;s so much awesome streaming stuff about (RisingWave, Materialize, NATS, DataFusion, Velox, neat upstarts like Iggy, many more), but it all feels built on slower legacy system libraries.<p>It&#x27;s not heavily used yet, but Rust has a bunch of fairly high visibility efforts. Situation sort of feels similar with http3, where the problem is figuring out what to pick. <a href="https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;tokio-uring">https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;tokio-uring</a> <a href="https:&#x2F;&#x2F;github.com&#x2F;bytedance&#x2F;monoio">https:&#x2F;&#x2F;github.com&#x2F;bytedance&#x2F;monoio</a> <a href="https:&#x2F;&#x2F;github.com&#x2F;DataDog&#x2F;glommio">https:&#x2F;&#x2F;github.com&#x2F;DataDog&#x2F;glommio</a><p>Alas libuv (powering Node.js) shipped io_uring but disabled it latter. Seems to have significantly worn out the original author on the topic to boot. <a href="https:&#x2F;&#x2F;github.com&#x2F;libuv&#x2F;libuv&#x2F;pull&#x2F;4421#issuecomment-2225860128">https:&#x2F;&#x2F;github.com&#x2F;libuv&#x2F;libuv&#x2F;pull&#x2F;4421#issuecomment-222586...</a></div><br/><div id="41187679" class="c"><input type="checkbox" id="c-41187679" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41186772">parent</a><span>|</span><a href="#41187109">next</a><span>|</span><label class="collapse" for="c-41187679">[-]</label><label class="expand" for="c-41187679">[5 more]</label></div><br/><div class="children"><div class="content">I seem to be missing context for this reply. Why do you need io_uring?</div><br/><div id="41188223" class="c"><input type="checkbox" id="c-41188223" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187679">parent</a><span>|</span><a href="#41187109">next</a><span>|</span><label class="collapse" for="c-41188223">[-]</label><label class="expand" for="c-41188223">[4 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t <i>need</i> io_uring. For many workloads being slow &amp; inefficient is acceptable, isn&#x27;t awful. But gee I&#x27;d rather start from a modern baseline that has high levels of <i>mechanistic sympathy</i> with the hardware, where things like network &amp; io work can be done in an efficient async manner.<p>Why do I need io_uring? Because it sounds awful and unhackerly to suffer living in a much lesser worse world.</div><br/><div id="41188321" class="c"><input type="checkbox" id="c-41188321" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41188223">parent</a><span>|</span><a href="#41188935">next</a><span>|</span><label class="collapse" for="c-41188321">[-]</label><label class="expand" for="c-41188321">[2 more]</label></div><br/><div class="children"><div class="content">Mechanical sympathy is understanding the system, not using the shiniest thing. If you want low latency processing of one event at a time, you are either going to burn an entire core spinning or you are going to do a syscall for each operation. The io_uring syscalls are not especially fast — they get their awesomeness by doing, potentially, a whole lot of work per operation.  And, for some use cases, by having a superior async IO model.<p>But if you actually just want read(), then call read().</div><br/><div id="41188531" class="c"><input type="checkbox" id="c-41188531" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41188321">parent</a><span>|</span><a href="#41188935">next</a><span>|</span><label class="collapse" for="c-41188531">[-]</label><label class="expand" for="c-41188531">[1 more]</label></div><br/><div class="children"><div class="content">Low latency for a single event is never going to have mechanistic sympathy, will be a colossal waste of most of your system.<p>Highly concurrent system usage is what it takes. EPOLLEXCLUSIVE (2016) finally sort of gets epoll vaguely capable of what OSes were doing decades ago but is still difficult to use &amp; a rats nest of complexity. Who here feels good reading <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;41582560&#x2F;how-does-epolls-epollexclusive-mode-interact-with-level-triggering" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;41582560&#x2F;how-does-epolls...</a> ?<p>The submission&#x2F;completion queue model of io_uring makes sense. It lets work be added or resolved without crossing that painful slow kernel barrier. It&#x27;s been expanded to offer a lot more operations than what could be done in epoll.<p>The &quot;shiniest thing&quot; is a vast leap in capabilities, systems legibility, and overall (not single operation) throughout. You cannot remotely get the numbers io_uring was bringing three years ago any other way. And it&#x27;s only gotten further and further ahead while everyone else has sat still.</div><br/></div></div></div></div><div id="41188935" class="c"><input type="checkbox" id="c-41188935" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41188223">parent</a><span>|</span><a href="#41188321">prev</a><span>|</span><a href="#41187109">next</a><span>|</span><label class="collapse" for="c-41188935">[-]</label><label class="expand" for="c-41188935">[1 more]</label></div><br/><div class="children"><div class="content">if you want mechanistic sympathy and low latency then you can&#x27;t really do much better than dpdk; uring is still going through the very generic and abstracted kernel networking stack.</div><br/></div></div></div></div></div></div><div id="41187109" class="c"><input type="checkbox" id="c-41187109" checked=""/><div class="controls bullet"><span class="by">hnav</span><span>|</span><a href="#41186772">parent</a><span>|</span><a href="#41187679">prev</a><span>|</span><label class="collapse" for="c-41187109">[-]</label><label class="expand" for="c-41187109">[8 more]</label></div><br/><div class="children"><div class="content">io_uring is a low level abstraction and is generally a wash against epoll. Really won&#x27;t make a difference for these kinds of applications, especially not for client nodes.</div><br/><div id="41187238" class="c"><input type="checkbox" id="c-41187238" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187109">parent</a><span>|</span><label class="collapse" for="c-41187238">[-]</label><label class="expand" for="c-41187238">[7 more]</label></div><br/><div class="children"><div class="content">io_uring allows for async reads and writes to disk without forcing a thread pool or direct I&#x2F;O. That alone makes it much more scalable for workloads that touch both the network and disk.</div><br/><div id="41187643" class="c"><input type="checkbox" id="c-41187643" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187238">parent</a><span>|</span><label class="collapse" for="c-41187643">[-]</label><label class="expand" for="c-41187643">[6 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t the kernel use a thread pool to process the requests in the ring, because the kernel is still designed around blocking disk I&#x2F;O?</div><br/><div id="41187840" class="c"><input type="checkbox" id="c-41187840" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187643">parent</a><span>|</span><label class="collapse" for="c-41187840">[-]</label><label class="expand" for="c-41187840">[5 more]</label></div><br/><div class="children"><div class="content">No, most operations in the ring directly work asynchronously. The thread mechanism only exists as a fallback for combinations of operations and system configurations (e.g. filesystems) that don&#x27;t support asynchronous operation.</div><br/><div id="41187951" class="c"><input type="checkbox" id="c-41187951" checked=""/><div class="controls bullet"><span class="by">mightyham</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187840">parent</a><span>|</span><label class="collapse" for="c-41187951">[-]</label><label class="expand" for="c-41187951">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know anything about the internals of io_uring and am genuinely curious how it works. Saying it &quot;directly works asynchronously&quot; doesn&#x27;t mean anything though. When circular buffer requests are processed what thread is processing the request, how is that thread managed, and how does it manage blocking&#x2F;unblocking when communicating with the storage device?</div><br/><div id="41188043" class="c"><input type="checkbox" id="c-41188043" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41187951">parent</a><span>|</span><label class="collapse" for="c-41188043">[-]</label><label class="expand" for="c-41188043">[3 more]</label></div><br/><div class="children"><div class="content">Internally, many parts of the Linux kernel operate asynchronously: they queue up a request with some subsystem (e.g. a hardware device), and get an event delivered when the request is completed. In such cases, io_uring can enqueue such a request, and complete it when receiving the event, without needing to use a thread to block waiting for it.<p>See, for instance, <a href="https:&#x2F;&#x2F;lpc.events&#x2F;event&#x2F;11&#x2F;contributions&#x2F;901&#x2F;attachments&#x2F;786&#x2F;1661&#x2F;io_uring-BPF.pdf" rel="nofollow">https:&#x2F;&#x2F;lpc.events&#x2F;event&#x2F;11&#x2F;contributions&#x2F;901&#x2F;attachments&#x2F;78...</a> slide 5 (though more has happened since then). io_uring will first see if it has everything needed to do the operation <i>immediately</i>, if not it&#x27;ll queue a request in some cases (e.g. direct I&#x2F;O, or buffered I&#x2F;O in <i>some</i> cases). The thread pool is the last fallback, which always works if nothing else does.<p><a href="https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;821274&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;821274&#x2F;</a> talks about making async buffered reads work, for instance.</div><br/><div id="41188488" class="c"><input type="checkbox" id="c-41188488" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41188043">parent</a><span>|</span><label class="collapse" for="c-41188488">[-]</label><label class="expand" for="c-41188488">[2 more]</label></div><br/><div class="children"><div class="content">Is it safe to say that a single thread using io_uring should be as fast or faster than N threads performing the same set of I&#x2F;O tasks in a blocking manner?<p>In other words, can you count on the kernel to use its own threads internally whenever an I&#x2F;O task might actually need to use a lot of CPU?</div><br/><div id="41189149" class="c"><input type="checkbox" id="c-41189149" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#41186772">root</a><span>|</span><a href="#41188488">parent</a><span>|</span><label class="collapse" for="c-41189149">[-]</label><label class="expand" for="c-41189149">[1 more]</label></div><br/><div class="children"><div class="content">If you saturate the submission queue with CPU-bottlenecked tasks, it defeats the value-add of io_uring - at that point, you might as well replace your kernel-space thread pool with a user-space one.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>