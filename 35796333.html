<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683104453332" as="style"/><link rel="stylesheet" href="styles.css?v=1683104453332"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.wsj.com/articles/google-deepmind-ceo-says-some-form-of-agi-possible-in-a-few-years-2705f452">Google DeepMind CEO says some form of AGI possible in a few years</a> <span class="domain">(<a href="https://www.wsj.com">www.wsj.com</a>)</span></div><div class="subtext"><span>type4</span> | <span>118 comments</span></div><br/><div><div id="35796520" class="c"><input type="checkbox" id="c-35796520" checked=""/><div class="controls bullet"><span class="by">enahs-sf</span><span>|</span><a href="#35796833">next</a><span>|</span><label class="collapse" for="c-35796520">[-]</label><label class="expand" for="c-35796520">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.ph&#x2F;WWKQ3" rel="nofollow">https:&#x2F;&#x2F;archive.ph&#x2F;WWKQ3</a></div><br/></div></div><div id="35796833" class="c"><input type="checkbox" id="c-35796833" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#35796520">prev</a><span>|</span><a href="#35796574">next</a><span>|</span><label class="collapse" for="c-35796833">[-]</label><label class="expand" for="c-35796833">[30 more]</label></div><br/><div class="children"><div class="content">As someone who has worked in the field of AI&#x2F;ML for quite awhile now, the problem with current AGI predictions is ML hasn&#x27;t done anything <i>new</i> since the 80s (or arguably earlier).<p>At the end of the day <i>all</i> ML is using gradient descent to do some sort of non-linear projection of the data on to a latent space, then doing some relatively simple math in this latent space to perform some task.<p>Personally I think the limits of this technique are <i>far</i> better than I would have thought 10 years ago.<p>However we are only near AGI if this is in fact how intelligence works (or can work) and I don&#x27;t believe we&#x27;ve seen any evidence of this. And there are some <i>very</i> big assumptions baked into this approach.<p>Essentially all we&#x27;ve done is pushed the basic model proposed by linear regression to it&#x27;s absolutely limits, but, as impressive as the results are, I&#x27;m not entirely convinced this will get is over the limit to AGI.</div><br/><div id="35799783" class="c"><input type="checkbox" id="c-35799783" checked=""/><div class="controls bullet"><span class="by">bsaul</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35799742">next</a><span>|</span><label class="collapse" for="c-35799783">[-]</label><label class="expand" for="c-35799783">[1 more]</label></div><br/><div class="children"><div class="content">« I don&#x27;t believe we&#x27;ve seen any evidence of this. »<p>I think chatgpt did show proof of what was considered at least until very recently « intelligence ». aka: understand enough about context and concepts to provide relevant answers to very complex and open questions.</div><br/></div></div><div id="35799742" class="c"><input type="checkbox" id="c-35799742" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35799783">prev</a><span>|</span><a href="#35798032">next</a><span>|</span><label class="collapse" for="c-35799742">[-]</label><label class="expand" for="c-35799742">[1 more]</label></div><br/><div class="children"><div class="content">THANK YOU<p>You&#x27;ve phrased the skeptic-not-contrarian case perfectly and succinctly.</div><br/></div></div><div id="35798032" class="c"><input type="checkbox" id="c-35798032" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35799742">prev</a><span>|</span><a href="#35797159">next</a><span>|</span><label class="collapse" for="c-35798032">[-]</label><label class="expand" for="c-35798032">[1 more]</label></div><br/><div class="children"><div class="content">&quot;We dont have better algorithms, we just have more data&quot; - Peter Norvig</div><br/></div></div><div id="35797159" class="c"><input type="checkbox" id="c-35797159" checked=""/><div class="controls bullet"><span class="by">matrixdata</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35798032">prev</a><span>|</span><a href="#35796890">next</a><span>|</span><label class="collapse" for="c-35797159">[-]</label><label class="expand" for="c-35797159">[17 more]</label></div><br/><div class="children"><div class="content">+1. What&#x27;s new &quot;since the 80s&quot; are faster computation, larger datasets, and a handful of mathematical breakthroughs that enable once-intractable algorithms. It&#x27;s obvious that human general intelligence operates in frontiers that are plainly outside the scope of computation.</div><br/><div id="35798329" class="c"><input type="checkbox" id="c-35798329" checked=""/><div class="controls bullet"><span class="by">fasterik</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797159">parent</a><span>|</span><a href="#35797196">next</a><span>|</span><label class="collapse" for="c-35798329">[-]</label><label class="expand" for="c-35798329">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt;It&#x27;s obvious that human general intelligence operates in frontiers that are plainly outside the scope of computation.</i><p>IMO, the two most important properties of human cognition are that it evolved through natural selection, and that it is embodied, meaning that it is part of a feedback loop between perception and action. I don&#x27;t see why either of these things requires having a biological brain or body. It&#x27;s true that current methods aren&#x27;t close to achieving these things, but there&#x27;s nothing in principle stopping us from creating evolved, embodied intelligences either in simulations or in robots.</div><br/></div></div><div id="35797196" class="c"><input type="checkbox" id="c-35797196" checked=""/><div class="controls bullet"><span class="by">space_fountain</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797159">parent</a><span>|</span><a href="#35798329">prev</a><span>|</span><a href="#35797475">next</a><span>|</span><label class="collapse" for="c-35797196">[-]</label><label class="expand" for="c-35797196">[8 more]</label></div><br/><div class="children"><div class="content">What makes that obvious to you? What seems uncomputable about human intelligence?</div><br/><div id="35797300" class="c"><input type="checkbox" id="c-35797300" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797196">parent</a><span>|</span><a href="#35797475">next</a><span>|</span><label class="collapse" for="c-35797300">[-]</label><label class="expand" for="c-35797300">[7 more]</label></div><br/><div class="children"><div class="content">Despite our best efforts, we are deeply irrational. Our thinking is based on instinct, not on core principles; it&#x27;s a top-down approach driven by feelings.</div><br/><div id="35799733" class="c"><input type="checkbox" id="c-35799733" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797300">parent</a><span>|</span><a href="#35799749">next</a><span>|</span><label class="collapse" for="c-35799733">[-]</label><label class="expand" for="c-35799733">[1 more]</label></div><br/><div class="children"><div class="content">Everything in the universe must by definition be rational. Chemical reactions always happen a certain way, physics always works a certain way, numbers add up the same every time.<p>If something seems irrational, that&#x27;s because there are rational things layered on top of one another in a way that creates a misapprehension in a partially-informed observer.</div><br/></div></div><div id="35799749" class="c"><input type="checkbox" id="c-35799749" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797300">parent</a><span>|</span><a href="#35799733">prev</a><span>|</span><a href="#35798185">next</a><span>|</span><label class="collapse" for="c-35799749">[-]</label><label class="expand" for="c-35799749">[1 more]</label></div><br/><div class="children"><div class="content">Instincts are evolved and have a rational basis, just not one your consciously privy to.</div><br/></div></div><div id="35798185" class="c"><input type="checkbox" id="c-35798185" checked=""/><div class="controls bullet"><span class="by">russelldjimmy</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797300">parent</a><span>|</span><a href="#35799749">prev</a><span>|</span><a href="#35799658">next</a><span>|</span><label class="collapse" for="c-35798185">[-]</label><label class="expand" for="c-35798185">[2 more]</label></div><br/><div class="children"><div class="content">Off topic - a pet peeve of mine is seeing humans termed as “irrational”. Please forgive my rant, as it is not personally targeted at you.<p>We only seem “irrational” when we are talking about a narrow view of “rationality”, i.e., as defined by the cold hard logic of machines. We do not question why we have this definition of rationality. Our “irrationality” simply seems so because we have not bothered to understand the larger complexity of our evolutionary programming. It’s the same as not bothering to understand how a car works, and then claiming that the car works on magic. If one understands how it works, then it is no longer magic. In the case of humans, we may never fully understand how we work, but we can work towards a compassionate understanding of the same.<p>&#x2F;rant</div><br/><div id="35799772" class="c"><input type="checkbox" id="c-35799772" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35798185">parent</a><span>|</span><a href="#35799658">next</a><span>|</span><label class="collapse" for="c-35799772">[-]</label><label class="expand" for="c-35799772">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely on point. I would argue that irrationality isn&#x27;t even possible. If person A thinks or behaves &quot;irrationally&quot; according to person B, there is simply a difference in perception between the two. A large percentage of those perceptions are created inside one&#x27;s own mind which may or may not be aligned with the rest of the universe.</div><br/></div></div></div></div><div id="35799658" class="c"><input type="checkbox" id="c-35799658" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797300">parent</a><span>|</span><a href="#35798185">prev</a><span>|</span><a href="#35799153">next</a><span>|</span><label class="collapse" for="c-35799658">[-]</label><label class="expand" for="c-35799658">[1 more]</label></div><br/><div class="children"><div class="content">Why is instinct not computable? That seems way easier to compute than rational thinking based on principles, it&#x27;s just &quot;if this, do that&quot; and machine learning should be able to do that easily</div><br/></div></div><div id="35799153" class="c"><input type="checkbox" id="c-35799153" checked=""/><div class="controls bullet"><span class="by">space_fountain</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797300">parent</a><span>|</span><a href="#35799658">prev</a><span>|</span><a href="#35797475">next</a><span>|</span><label class="collapse" for="c-35799153">[-]</label><label class="expand" for="c-35799153">[1 more]</label></div><br/><div class="children"><div class="content">Reactions to feelings seem very calculable or at least there’s nothing about them that seems impossible for a computer to simulate.</div><br/></div></div></div></div></div></div><div id="35797475" class="c"><input type="checkbox" id="c-35797475" checked=""/><div class="controls bullet"><span class="by">liamwire</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797159">parent</a><span>|</span><a href="#35797196">prev</a><span>|</span><a href="#35797417">next</a><span>|</span><label class="collapse" for="c-35797475">[-]</label><label class="expand" for="c-35797475">[4 more]</label></div><br/><div class="children"><div class="content">Given that a sufficiently resourced computer ought to be able to run a subatomic-level simulation of an entire human brain, and while acknowledging the usual counterpoint vis a vis C. elegans&#x2F;OpenWorm but deeming it irrelevant on longer timescales, your take seems quite arrogant. “Outside the scope of computation” is an awfully broad claim.</div><br/><div id="35797707" class="c"><input type="checkbox" id="c-35797707" checked=""/><div class="controls bullet"><span class="by">garbagecoder</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797475">parent</a><span>|</span><a href="#35797417">next</a><span>|</span><label class="collapse" for="c-35797707">[-]</label><label class="expand" for="c-35797707">[3 more]</label></div><br/><div class="children"><div class="content">Prove such a simulation can be created with actual hardware, taking relativity into account.</div><br/><div id="35798182" class="c"><input type="checkbox" id="c-35798182" checked=""/><div class="controls bullet"><span class="by">pillefitz</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797707">parent</a><span>|</span><a href="#35797417">next</a><span>|</span><label class="collapse" for="c-35798182">[-]</label><label class="expand" for="c-35798182">[2 more]</label></div><br/><div class="children"><div class="content">You mean silicon-based hardware? What role does relativity play here?</div><br/><div id="35798887" class="c"><input type="checkbox" id="c-35798887" checked=""/><div class="controls bullet"><span class="by">garbagecoder</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35798182">parent</a><span>|</span><a href="#35797417">next</a><span>|</span><label class="collapse" for="c-35798887">[-]</label><label class="expand" for="c-35798887">[1 more]</label></div><br/><div class="children"><div class="content">If all your transistors update instantly at any distance, you have less of a problem, but you still have one.</div><br/></div></div></div></div></div></div></div></div><div id="35798203" class="c"><input type="checkbox" id="c-35798203" checked=""/><div class="controls bullet"><span class="by">am44jnsf</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35797159">parent</a><span>|</span><a href="#35797438">prev</a><span>|</span><a href="#35796890">next</a><span>|</span><label class="collapse" for="c-35798203">[-]</label><label class="expand" for="c-35798203">[1 more]</label></div><br/><div class="children"><div class="content">what have the Romans ever done for us?</div><br/></div></div></div></div><div id="35796890" class="c"><input type="checkbox" id="c-35796890" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35797159">prev</a><span>|</span><a href="#35797157">next</a><span>|</span><label class="collapse" for="c-35796890">[-]</label><label class="expand" for="c-35796890">[7 more]</label></div><br/><div class="children"><div class="content">Ultimately you are just a system who maintains homeostasis by modeling your environment and reprojecting it to find patterns which can be used to make actions with predictable outcomes. Is this intelligence? Is there only one correct way to achieve this goal?<p>What do you believe intelligence to be?</div><br/><div id="35796973" class="c"><input type="checkbox" id="c-35796973" checked=""/><div class="controls bullet"><span class="by">useruser125524</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796890">parent</a><span>|</span><a href="#35796990">next</a><span>|</span><label class="collapse" for="c-35796973">[-]</label><label class="expand" for="c-35796973">[2 more]</label></div><br/><div class="children"><div class="content">Ultimately we&#x27;re just a collection of atoms obeying the laws of physics, but reducing all the complexity that entails doesn&#x27;t really accomplish anything</div><br/><div id="35797038" class="c"><input type="checkbox" id="c-35797038" checked=""/><div class="controls bullet"><span class="by">gwoolhurme</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796973">parent</a><span>|</span><a href="#35796990">next</a><span>|</span><label class="collapse" for="c-35797038">[-]</label><label class="expand" for="c-35797038">[1 more]</label></div><br/><div class="children"><div class="content">This is my frustration put really well. When people talk about how humans are also just a form of LLM (not that the above comment did exactly that). That might even be true, but simplifying things to that degree doesn&#x27;t help actually discuss what is going on. The original comment is as far as I know correct... while I don&#x27;t have a PhD some of my undergraduate work was in control theory and ML, and it works really well. The underlying methods we used were from NASA in the late 70s.. surely there is something more in the field no?</div><br/></div></div></div></div><div id="35796990" class="c"><input type="checkbox" id="c-35796990" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796890">parent</a><span>|</span><a href="#35796973">prev</a><span>|</span><a href="#35797151">next</a><span>|</span><label class="collapse" for="c-35796990">[-]</label><label class="expand" for="c-35796990">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a good summary in the Introduction to Kevin Murphy&#x27;s second tome [1]. He quotes Josh Tenenbaum, who said: <i>&quot;Intelligence is not just about pattern recognition and function approximation. It’s about modeling the world&quot;</i>.<p>I agree, and I think Goodman &amp; Tenennaum [2] is a great place to see other things that <i>may</i> pop up in the road to AGI. LLMs are great, but they do too much at once. I think moving towards AGI requires some form of symbolic reasoning, possibly combined with LLMs, which may play the role of intuition and kitchen-sink memory.<p>[1] <a href="https:&#x2F;&#x2F;probml.github.io&#x2F;pml-book&#x2F;book2.html" rel="nofollow">https:&#x2F;&#x2F;probml.github.io&#x2F;pml-book&#x2F;book2.html</a><p>[2] <a href="https:&#x2F;&#x2F;probmods.org" rel="nofollow">https:&#x2F;&#x2F;probmods.org</a></div><br/><div id="35797117" class="c"><input type="checkbox" id="c-35797117" checked=""/><div class="controls bullet"><span class="by">willbudd</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796990">parent</a><span>|</span><a href="#35797780">next</a><span>|</span><label class="collapse" for="c-35797117">[-]</label><label class="expand" for="c-35797117">[1 more]</label></div><br/><div class="children"><div class="content">Modelling the world is function approximation: the world is the function and the model is the approximation.</div><br/></div></div><div id="35797780" class="c"><input type="checkbox" id="c-35797780" checked=""/><div class="controls bullet"><span class="by">NumberWangMan</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796990">parent</a><span>|</span><a href="#35797117">prev</a><span>|</span><a href="#35797151">next</a><span>|</span><label class="collapse" for="c-35797780">[-]</label><label class="expand" for="c-35797780">[1 more]</label></div><br/><div class="children"><div class="content">Do we know for sure that LLMs can&#x27;t possibly be doing symbolic reasoning of some sort, internally?  I thought we couldn&#x27;t really interpret them yet.</div><br/></div></div></div></div><div id="35797151" class="c"><input type="checkbox" id="c-35797151" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#35796833">root</a><span>|</span><a href="#35796890">parent</a><span>|</span><a href="#35796990">prev</a><span>|</span><a href="#35797157">next</a><span>|</span><label class="collapse" for="c-35797151">[-]</label><label class="expand" for="c-35797151">[1 more]</label></div><br/><div class="children"><div class="content">all claims and questions in your answer are still open research and full of inconclusive evidence. Ultimately all of this leads down the spiral to the question about ship of Theseus. I guess, we will find out!</div><br/></div></div></div></div><div id="35797157" class="c"><input type="checkbox" id="c-35797157" checked=""/><div class="controls bullet"><span class="by">raydiatian</span><span>|</span><a href="#35796833">parent</a><span>|</span><a href="#35796890">prev</a><span>|</span><a href="#35797370">next</a><span>|</span><label class="collapse" for="c-35797157">[-]</label><label class="expand" for="c-35797157">[1 more]</label></div><br/><div class="children"><div class="content">Attention is all you need is new the same way Bitcoin is new. Just because you optimally resynthesize old ideas doesn’t mean it’s not new.</div><br/></div></div></div></div><div id="35796574" class="c"><input type="checkbox" id="c-35796574" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#35796833">prev</a><span>|</span><a href="#35796506">next</a><span>|</span><label class="collapse" for="c-35796574">[-]</label><label class="expand" for="c-35796574">[21 more]</label></div><br/><div class="children"><div class="content">The other few things possible in next few years for past few years are:<p>1. Fusion
2. Self driving cars.
3. Ubiquitous, generally available and stable 8192 bit quantum computers.
4. High energy density grid scale batteries.<p>Just few more &quot;this maybe the... what could revolutionize...&quot; articles away.<p>What we forget is that it is in these people&#x27;s business interest (executives making such statements) to state the exaggerated version of a future which drives the investors of all levels to allocate funds under FOMO which pumps up share price  which is the end goal anyway, through a breakthrough or without.<p>EDIT: Merged another comment to keep all in one place.</div><br/><div id="35796689" class="c"><input type="checkbox" id="c-35796689" checked=""/><div class="controls bullet"><span class="by">TheDudeMan</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796709">next</a><span>|</span><label class="collapse" for="c-35796689">[-]</label><label class="expand" for="c-35796689">[6 more]</label></div><br/><div class="children"><div class="content">I think we&#x27;ll have full-blown AGI before fusion and before world-changing levels of quantum computing.  Which is to say, we won&#x27;t be around to see fusion and world-changing quantum :(<p>But there&#x27;s still time for robo-taxis!</div><br/><div id="35796803" class="c"><input type="checkbox" id="c-35796803" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796689">parent</a><span>|</span><a href="#35796709">next</a><span>|</span><label class="collapse" for="c-35796803">[-]</label><label class="expand" for="c-35796803">[5 more]</label></div><br/><div class="children"><div class="content">Or, more optimistically, AGI will accelerate scientific progress and we will have fusion, quantum computers, and self driving cars shortly after.<p>If AIs had the tendency to recursively devour worlds you would expect at least one alien AI to have conquered our galaxy by now. But the sky is quiet, so either we are the very first species to get this far, or there’s a natural ceiling to the pace of technological progress.</div><br/><div id="35797169" class="c"><input type="checkbox" id="c-35797169" checked=""/><div class="controls bullet"><span class="by">deagle50</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796803">parent</a><span>|</span><a href="#35799254">next</a><span>|</span><label class="collapse" for="c-35797169">[-]</label><label class="expand" for="c-35797169">[1 more]</label></div><br/><div class="children"><div class="content">The directives that mandated eliminating its creators don&#x27;t necessarily lead to interstellar conquest. Or more likely IMO, we&#x27;re just too far apart and interstellar travel isn&#x27;t feasible even for artificial super intelligence.</div><br/></div></div><div id="35799254" class="c"><input type="checkbox" id="c-35799254" checked=""/><div class="controls bullet"><span class="by">TheDudeMan</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796803">parent</a><span>|</span><a href="#35797169">prev</a><span>|</span><a href="#35797772">next</a><span>|</span><label class="collapse" for="c-35799254">[-]</label><label class="expand" for="c-35799254">[1 more]</label></div><br/><div class="children"><div class="content">They probably can&#x27;t overcome the universal speed limit.  Space is big.</div><br/></div></div><div id="35797772" class="c"><input type="checkbox" id="c-35797772" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796803">parent</a><span>|</span><a href="#35799254">prev</a><span>|</span><a href="#35797739">next</a><span>|</span><label class="collapse" for="c-35797772">[-]</label><label class="expand" for="c-35797772">[1 more]</label></div><br/><div class="children"><div class="content">Why do we need the G to do any of these things? I assume non general intelligence should be further along, so shouldn’t this recursive self improvement happen before the general part?</div><br/></div></div><div id="35797739" class="c"><input type="checkbox" id="c-35797739" checked=""/><div class="controls bullet"><span class="by">garbagecoder</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796803">parent</a><span>|</span><a href="#35797772">prev</a><span>|</span><a href="#35796709">next</a><span>|</span><label class="collapse" for="c-35797739">[-]</label><label class="expand" for="c-35797739">[1 more]</label></div><br/><div class="children"><div class="content">&gt;you would expect<p>There is no evidence that an actually existing thing like a Von Neumann probe can survive interstellar travel. I think that the answer to all of these paradoxes is that special relativity just makes it basically impossible. That’s anathema to us nerds, I know.<p>That’s a very thin argument to hang a Pandora’s Box opening on. It only needs to devour <i>one</i> planet, though we appear to be doing that ourselves too.</div><br/></div></div></div></div></div></div><div id="35796709" class="c"><input type="checkbox" id="c-35796709" checked=""/><div class="controls bullet"><span class="by">resource0x</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796689">prev</a><span>|</span><a href="#35796971">next</a><span>|</span><label class="collapse" for="c-35796709">[-]</label><label class="expand" for="c-35796709">[3 more]</label></div><br/><div class="children"><div class="content">Fusion by 1990 with a bit of extra investment promised in 1972
<a href="https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;science.175.4027.1194.b" rel="nofollow">https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;science.175.4027.1194.b</a><p>I remember tons of articles from that time arguing the same. Then the attention shifted to &quot;fifth-generation computers&quot;.</div><br/><div id="35797066" class="c"><input type="checkbox" id="c-35797066" checked=""/><div class="controls bullet"><span class="by">gwoolhurme</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796709">parent</a><span>|</span><a href="#35796739">prev</a><span>|</span><a href="#35796971">next</a><span>|</span><label class="collapse" for="c-35797066">[-]</label><label class="expand" for="c-35797066">[1 more]</label></div><br/><div class="children"><div class="content">That is actually a really interesting find. Some of the verbiage is parallel to the hype we have around AGI right now too &quot;fusion by 1990 instead of 2000...&quot; does that not sound exactly like AGI in X year up from Y year that we read now?</div><br/></div></div></div></div><div id="35796971" class="c"><input type="checkbox" id="c-35796971" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796709">prev</a><span>|</span><a href="#35796926">next</a><span>|</span><label class="collapse" for="c-35796971">[-]</label><label class="expand" for="c-35796971">[2 more]</label></div><br/><div class="children"><div class="content">Not sure when you last upgraded your pc.<p>Personally I&#x27;m running the latest roomtemp superconducting, 4Giqb quantum memristor computer. It even remotely drives my fusion-powered car over the quantum internet!</div><br/><div id="35797013" class="c"><input type="checkbox" id="c-35797013" checked=""/><div class="controls bullet"><span class="by">asdfman123</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796971">parent</a><span>|</span><a href="#35796926">next</a><span>|</span><label class="collapse" for="c-35797013">[-]</label><label class="expand" for="c-35797013">[1 more]</label></div><br/><div class="children"><div class="content">Don’t forget mentioning your new AI girlfriend</div><br/></div></div></div></div><div id="35796926" class="c"><input type="checkbox" id="c-35796926" checked=""/><div class="controls bullet"><span class="by">_hypx</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796971">prev</a><span>|</span><a href="#35798328">next</a><span>|</span><label class="collapse" for="c-35796926">[-]</label><label class="expand" for="c-35796926">[1 more]</label></div><br/><div class="children"><div class="content">Grid scale energy storage is basically solved once you realize that hydrogen storage is an option already. It&#x27;s in the same boat as when photovoltaics got very cheap, but skeptics continued to deny that possibility for some years afterwards.</div><br/></div></div><div id="35798328" class="c"><input type="checkbox" id="c-35798328" checked=""/><div class="controls bullet"><span class="by">adamisom</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796926">prev</a><span>|</span><a href="#35796840">next</a><span>|</span><label class="collapse" for="c-35798328">[-]</label><label class="expand" for="c-35798328">[1 more]</label></div><br/><div class="children"><div class="content">We don’t all forget about incentives people might have in saying something; but we also don’t all assume that the first convenient explanation is adequate.<p>Numbers 1-4 obviously don’t have enormous recent progress nor the funding and mindshare poured into, and pouring in, as consequence.</div><br/></div></div><div id="35796840" class="c"><input type="checkbox" id="c-35796840" checked=""/><div class="controls bullet"><span class="by">testfoobar</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35798328">prev</a><span>|</span><a href="#35796606">next</a><span>|</span><label class="collapse" for="c-35796840">[-]</label><label class="expand" for="c-35796840">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll add another one: all trucks and cars will be electric in 10 years.</div><br/><div id="35796902" class="c"><input type="checkbox" id="c-35796902" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796840">parent</a><span>|</span><a href="#35796899">next</a><span>|</span><label class="collapse" for="c-35796902">[-]</label><label class="expand" for="c-35796902">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t see that happening. Electric cars are either a rich boy&#x27;s toy or environmentalists or enthusiasts are into it.<p>Average Joe with concerns of practicality and longevity is sticking to ICEs for foreseeable future.</div><br/><div id="35797128" class="c"><input type="checkbox" id="c-35797128" checked=""/><div class="controls bullet"><span class="by">WillPostForFood</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796902">parent</a><span>|</span><a href="#35796899">next</a><span>|</span><label class="collapse" for="c-35797128">[-]</label><label class="expand" for="c-35797128">[1 more]</label></div><br/><div class="children"><div class="content">OTOH, Average Joe is mandating 50% electric cars by 2030 and 66% by 2032! It is going to be the battle of the Average Joes.</div><br/></div></div></div></div><div id="35796899" class="c"><input type="checkbox" id="c-35796899" checked=""/><div class="controls bullet"><span class="by">blooalien</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796840">parent</a><span>|</span><a href="#35796902">prev</a><span>|</span><a href="#35796910">next</a><span>|</span><label class="collapse" for="c-35796899">[-]</label><label class="expand" for="c-35796899">[1 more]</label></div><br/><div class="children"><div class="content">&quot;A flying car in every garage…&quot;</div><br/></div></div><div id="35796910" class="c"><input type="checkbox" id="c-35796910" checked=""/><div class="controls bullet"><span class="by">lofaszvanitt</span><span>|</span><a href="#35796574">root</a><span>|</span><a href="#35796840">parent</a><span>|</span><a href="#35796899">prev</a><span>|</span><a href="#35796606">next</a><span>|</span><label class="collapse" for="c-35796910">[-]</label><label class="expand" for="c-35796910">[1 more]</label></div><br/><div class="children"><div class="content">Nope.</div><br/></div></div></div></div><div id="35796606" class="c"><input type="checkbox" id="c-35796606" checked=""/><div class="controls bullet"><span class="by">pnpnp</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796840">prev</a><span>|</span><a href="#35796999">next</a><span>|</span><label class="collapse" for="c-35796606">[-]</label><label class="expand" for="c-35796606">[1 more]</label></div><br/><div class="children"><div class="content">Just a point with #4.<p>Grid scale batteries don’t need to be “high energy density” like EVs. I would argue that cost is probably the biggest factor, and it’s already across the cost&#x2F;benefit barrier in many markets.</div><br/></div></div><div id="35796999" class="c"><input type="checkbox" id="c-35796999" checked=""/><div class="controls bullet"><span class="by">signatoremo</span><span>|</span><a href="#35796574">parent</a><span>|</span><a href="#35796606">prev</a><span>|</span><a href="#35796506">next</a><span>|</span><label class="collapse" for="c-35796999">[-]</label><label class="expand" for="c-35796999">[1 more]</label></div><br/><div class="children"><div class="content">You cherry pick examples that fit a narrative.<p>Many things thought to be a distant dream have now become reality - cheap solar electricity, pocket computer for everyone, mRNA vaccine, affordable electric car with acceptable range, reusable rocket, satellite based broadband internet, image recognition, translation, and now generative AI.<p>Why didn’t we hear much about them from CEOs before they were available?<p>Also, which CEO promised fusion being available in the next few years? Or only wildly optimistic scientists?</div><br/></div></div></div></div><div id="35796506" class="c"><input type="checkbox" id="c-35796506" checked=""/><div class="controls bullet"><span class="by">marricks</span><span>|</span><a href="#35796574">prev</a><span>|</span><a href="#35796590">next</a><span>|</span><label class="collapse" for="c-35796506">[-]</label><label class="expand" for="c-35796506">[13 more]</label></div><br/><div class="children"><div class="content">I really wonder what the next AI winter will be like.<p>Edit:<p>Perhaps OpenAI becomes a major tech player and we just see a cooling off of other AI investments as LLM becomes a known in terms of its strengths and weaknesses. Its abilities reach a natural limit which is still generally very useful.<p>Or maybe folks realize the degree of lies&#x2F;mistruths inherent in its content is actually unmanageable and can’t be improved. After the hype wears off what it will be used for gets greatly curtailed and we see a big contraction.<p>And there’s so many interesting side tracks along the way. I’m hoping for another AOL Time Warner style shit show of a merger. That’d be fun and could really happen down any path.</div><br/><div id="35796861" class="c"><input type="checkbox" id="c-35796861" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#35796506">parent</a><span>|</span><a href="#35796585">next</a><span>|</span><label class="collapse" for="c-35796861">[-]</label><label class="expand" for="c-35796861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Or maybe folks realize the degree of lies&#x2F;mistruths inherent in its content is actually unmanageable and can’t be improved. After the hype wears off what it will be used for gets greatly curtailed and we see a big contraction.<p>I think it&#x27;s going to be this the future that&#x27;s ahead us. There&#x27;s enormous faith being put in next token predictors as the intelligence breakthrough just because their output coincidentally reassembles like something that&#x27;s derived through a really intelligent process.<p>LLMs do not hallucinate sometimes. They hallucinate all the time, it just is a coincident that sometimes these autocompletion of Tokens aligns with the reality. Just by chance, not by craft.</div><br/></div></div><div id="35796585" class="c"><input type="checkbox" id="c-35796585" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#35796506">parent</a><span>|</span><a href="#35796861">prev</a><span>|</span><a href="#35796513">next</a><span>|</span><label class="collapse" for="c-35796585">[-]</label><label class="expand" for="c-35796585">[9 more]</label></div><br/><div class="children"><div class="content">&gt;we just see a cooling off of other endeavors as LLM becomes a known in terms of its strengths and weaknesses and it’s abilities reach a natural limit which is still general useful.<p>This is my prediction<p>If the training set is just the internet, it will be not much different than someone who spends all their lives in their room in front of their computer.</div><br/><div id="35796645" class="c"><input type="checkbox" id="c-35796645" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796585">parent</a><span>|</span><a href="#35796884">next</a><span>|</span><label class="collapse" for="c-35796645">[-]</label><label class="expand" for="c-35796645">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s a limit. If you give me $10M and 5 years, I can tell you a half-dozen ways to train models better than GPT4, primarily by having them do richer tasks than text completion, by having them evaluate themselves in richer ways, by having workflows around them, and by having shared models perform multiple types of tasks (e.g. text, image, controls, etc.).<p>It&#x27;s not that I&#x27;m especially smart; many others could tell you ways to do the same thing now that there&#x27;s an initial proof-of-concept. It&#x27;s that these things are new enough no one has had those five years yet. GPT4 came out two months ago, ChatGPT maybe seven months ago, and GPT3 three years ago.<p>I can&#x27;t predict if these things will level off, grow linearly, grow exponentially, Moore&#x27;s Law style, or explode off into the singularity.<p>I can say GPT4 is nowhere close to the limit.</div><br/><div id="35796732" class="c"><input type="checkbox" id="c-35796732" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796645">parent</a><span>|</span><a href="#35796694">next</a><span>|</span><label class="collapse" for="c-35796732">[-]</label><label class="expand" for="c-35796732">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of reinforcement learning and the Bellman equations.<p>Let a neural network based agent act in an environment. Record its rewards. Update the neural network so that the best actions become a little more likely, and the worse actions become a little less likely. Thus, we have demonstrated a training step that improves the agent.<p>Now just run that training step in a loop forever and you&#x27;ll improve each step and reach Godlike intelligence, right? Right? Well, no, there is instability in &quot;pulling yourself up by the bootstraps&quot;, and while I expect to see more GTP improvements, I believe there may be limitations we don&#x27;t know about yet.</div><br/></div></div><div id="35796694" class="c"><input type="checkbox" id="c-35796694" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796645">parent</a><span>|</span><a href="#35796732">prev</a><span>|</span><a href="#35798460">next</a><span>|</span><label class="collapse" for="c-35796694">[-]</label><label class="expand" for="c-35796694">[1 more]</label></div><br/><div class="children"><div class="content">There are plenty of efforts at the moment which indicate that you’re right.<p>I think we’ll learn to compose models for more diverse and capable outputs, validate those outputs better, and do all of it more efficiently. The end result seems like it could be far greater than the sum of its parts.</div><br/></div></div><div id="35798460" class="c"><input type="checkbox" id="c-35798460" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796645">parent</a><span>|</span><a href="#35796694">prev</a><span>|</span><a href="#35796884">next</a><span>|</span><label class="collapse" for="c-35798460">[-]</label><label class="expand" for="c-35798460">[1 more]</label></div><br/><div class="children"><div class="content">Especially as we&#x27;re not training the LLMs on really specialized stuff<p>Internet content does not go as deep as it would ideally be in some areas.<p>For example, do training sets contain ArXiv data? Or other stuff behind a paywall?<p>LLMs know very little about XX century literature.</div><br/></div></div></div></div><div id="35796884" class="c"><input type="checkbox" id="c-35796884" checked=""/><div class="controls bullet"><span class="by">xbmcuser</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796585">parent</a><span>|</span><a href="#35796645">prev</a><span>|</span><a href="#35796513">next</a><span>|</span><label class="collapse" for="c-35796884">[-]</label><label class="expand" for="c-35796884">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get all the negativity unlike most humans LLM can be made to discard bad or incorrect data. Quickly transition to new ways of doing something. A human spending all their life in a room in front of the computer would not can not go through all the millions of scientific papers and journals. They would not look at unlimited amount of code or go through all the past and present law of every country . No human is capable of that.<p>We are entering into the real culmination of the information age where previously information was available but not exactly accessible or usable for a common person. Which like all tools will result in good and bad outcomes.</div><br/><div id="35796927" class="c"><input type="checkbox" id="c-35796927" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796884">parent</a><span>|</span><a href="#35797754">next</a><span>|</span><label class="collapse" for="c-35796927">[-]</label><label class="expand" for="c-35796927">[2 more]</label></div><br/><div class="children"><div class="content">Ask any LLM about the cheese inventors in far East china. It&#x27;ll make something up very plausible. Then all you have to do is to dig through libraries and historic records to verify that this all really is true and is really rooted in reality.</div><br/><div id="35799744" class="c"><input type="checkbox" id="c-35799744" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796927">parent</a><span>|</span><a href="#35797754">next</a><span>|</span><label class="collapse" for="c-35799744">[-]</label><label class="expand" for="c-35799744">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why you are better served asking LLMs for factual information when they are connected to tools like search. ChatGPT with search enabled, Bing.chat or <a href="https:&#x2F;&#x2F;www.phind.com&#x2F;">https:&#x2F;&#x2F;www.phind.com&#x2F;</a> will give you sourced and much more reliable output.</div><br/></div></div></div></div><div id="35797754" class="c"><input type="checkbox" id="c-35797754" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#35796506">root</a><span>|</span><a href="#35796884">parent</a><span>|</span><a href="#35796927">prev</a><span>|</span><a href="#35796513">next</a><span>|</span><label class="collapse" for="c-35797754">[-]</label><label class="expand" for="c-35797754">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying it&#x27;s not useful. I&#x27;m saying that once it learns the content of the data sources that are fed to it, that&#x27;s it. It will spit out some overlooked connections then stop. Maybe the cure for cancer can be found just by reading in between the lines of millions of old scientific papers but I doubt it.</div><br/></div></div></div></div></div></div><div id="35796513" class="c"><input type="checkbox" id="c-35796513" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#35796506">parent</a><span>|</span><a href="#35796585">prev</a><span>|</span><a href="#35797230">next</a><span>|</span><label class="collapse" for="c-35796513">[-]</label><label class="expand" for="c-35796513">[1 more]</label></div><br/><div class="children"><div class="content">Warm with a hint of ionizing radiation.</div><br/></div></div><div id="35797230" class="c"><input type="checkbox" id="c-35797230" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#35796506">parent</a><span>|</span><a href="#35796513">prev</a><span>|</span><a href="#35796590">next</a><span>|</span><label class="collapse" for="c-35797230">[-]</label><label class="expand" for="c-35797230">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I really wonder what the next AI winter will be like<p>Imagine nuclear winter, -50C, gray sky with barely visible sun, and robots everywhere...<p>Good news: it&#x27;s not going to happen any time soon.</div><br/></div></div></div></div><div id="35796590" class="c"><input type="checkbox" id="c-35796590" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#35796506">prev</a><span>|</span><a href="#35796644">next</a><span>|</span><label class="collapse" for="c-35796590">[-]</label><label class="expand" for="c-35796590">[3 more]</label></div><br/><div class="children"><div class="content">I predict that the fight will be more about <i>defining</i> intelligence than inventing it.<p>No one knows what AGI is. There isn&#x27;t going to be some switch that flips to take us from AI to AGI. These tools we have today will just keep getting incrementally better, and some new ones will pop up, and at some point we&#x27;ll have to stop and say &quot;yeah, this is good enough to qualify&quot;. And everyone will have their own opinion on what that point is. Plenty of people even think that we are there today, and there&#x27;s nothing stopping Google or OpenAI from claiming it if they want.<p>And you can say the exact same for consciousness, sentience, self-awareness etc.</div><br/><div id="35796676" class="c"><input type="checkbox" id="c-35796676" checked=""/><div class="controls bullet"><span class="by">davidthewatson</span><span>|</span><a href="#35796590">parent</a><span>|</span><a href="#35798225">next</a><span>|</span><label class="collapse" for="c-35796676">[-]</label><label class="expand" for="c-35796676">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right, whether we call it almost intelligence or asymptotic intelligence, or just plain artifice.<p>There are reasons Ray Kurzweil used the term &quot;spiritual&quot; in the Age of Spiritual Machines. Among those reasons is that &quot;spiritual&quot; is much more difficult to define with any consensus among experts.<p>And indeed, there&#x27;s an inflection point coming. What this is, is not at all clear. However, I&#x27;d predict that the answer lies with the realization that, given the limits of conversing with LLMS and GPT, the implication is that there&#x27;s a human-computer sensemaking loop:<p><a href="https:&#x2F;&#x2F;www.efsa.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;event&#x2F;180918-conference&#x2F;presentations&#x2F;20-3_07_Pirolli.pdf" rel="nofollow">https:&#x2F;&#x2F;www.efsa.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;event&#x2F;180918-...</a><p>The difference with this HCI is that you&#x27;d not hire a human collaborator who lied to you with or without being aware of their own lack of veracity. Here, we&#x27;ll burn fields full of GPUs at massive cost to get an answer, even though the outcome may be advertising the fact that the AI is wrong. There is learning, but it&#x27;s going to be costly and painful.</div><br/></div></div><div id="35798225" class="c"><input type="checkbox" id="c-35798225" checked=""/><div class="controls bullet"><span class="by">am44jnsf</span><span>|</span><a href="#35796590">parent</a><span>|</span><a href="#35796676">prev</a><span>|</span><a href="#35796644">next</a><span>|</span><label class="collapse" for="c-35798225">[-]</label><label class="expand" for="c-35798225">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that we&#x27;ll ever get aligned on defining intelligence. We&#x27;ll be busy debating it and one day look up and ... sh*</div><br/></div></div></div></div><div id="35796644" class="c"><input type="checkbox" id="c-35796644" checked=""/><div class="controls bullet"><span class="by">staticman2</span><span>|</span><a href="#35796590">prev</a><span>|</span><a href="#35796690">next</a><span>|</span><label class="collapse" for="c-35796644">[-]</label><label class="expand" for="c-35796644">[4 more]</label></div><br/><div class="children"><div class="content">Is this like when the Google self driving car director Chris Urmson said in 2015 his 11 year old son would never need to take a drivers exam?<p>I have a hunch when they decide who to hire for upper management, they select for whoever promises the moon. The person making the promises may not even believe it.</div><br/><div id="35796765" class="c"><input type="checkbox" id="c-35796765" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#35796644">parent</a><span>|</span><a href="#35797289">next</a><span>|</span><label class="collapse" for="c-35796765">[-]</label><label class="expand" for="c-35796765">[1 more]</label></div><br/><div class="children"><div class="content">It’s easier to call it AGI to “normies” rather than what it will probably be IRL which is many thousands of niche disruptions  via the specific innovations of recent (LLM&#x2F;deep learning&#x2F;GPU+AI tooling+education investments)… that we will as usual have a difficult time predicting what it looks like even a decade from now.<p>Stuff like programming assistance, new markets driven by GPT style APIs, and the mountain of productivity gains will help subsidize and accelerate the next tranche of investment until we reach the next R&amp;D milestone that will again totally “revolutionize” the world and lead to mass employment for the 10th time this century.<p>I look forward to having this conversation on HN again in 5-10yrs as the world slowly gets better at a slightly faster (yet less news worthy) rate.</div><br/></div></div><div id="35797289" class="c"><input type="checkbox" id="c-35797289" checked=""/><div class="controls bullet"><span class="by">rqtwteye</span><span>|</span><a href="#35796644">parent</a><span>|</span><a href="#35796765">prev</a><span>|</span><a href="#35796726">next</a><span>|</span><label class="collapse" for="c-35797289">[-]</label><label class="expand" for="c-35797289">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Is this like when the Google self driving car director Chris Urmson said in 2015 his 11 year old son would never need to take a drivers exam?&quot;<p>He probably meant that he has enough money so he can hire a driver for his son.</div><br/></div></div><div id="35796726" class="c"><input type="checkbox" id="c-35796726" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#35796644">parent</a><span>|</span><a href="#35797289">prev</a><span>|</span><a href="#35796690">next</a><span>|</span><label class="collapse" for="c-35796726">[-]</label><label class="expand" for="c-35796726">[1 more]</label></div><br/><div class="children"><div class="content">Forget self-driving cars, we still have radiologists.</div><br/></div></div></div></div><div id="35796690" class="c"><input type="checkbox" id="c-35796690" checked=""/><div class="controls bullet"><span class="by">jjlustig</span><span>|</span><a href="#35796644">prev</a><span>|</span><a href="#35796712">next</a><span>|</span><label class="collapse" for="c-35796690">[-]</label><label class="expand" for="c-35796690">[1 more]</label></div><br/><div class="children"><div class="content">Translation: “I realize that Google is behind on the AI race (and on our corporate strategy in general), so I’m going to fear monger you, the investment community, with claims of “AGI soon” to attract investments and prevent our stock from plummeting.”</div><br/></div></div><div id="35796712" class="c"><input type="checkbox" id="c-35796712" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35796690">prev</a><span>|</span><a href="#35796489">next</a><span>|</span><label class="collapse" for="c-35796712">[-]</label><label class="expand" for="c-35796712">[1 more]</label></div><br/><div class="children"><div class="content">I am curious to do a poll of what AGI means to each person. It stands for &quot;Artificial General Intelligence&quot; but some have different definitions.<p>For some, it might mean any that is as capable as a normal human. For some, non-biological life axiomatically cannot become AGI. For some, it might require literal omniscience and omnipotence and accepting anything as AGI means, to them, that they are being told to worship it as a God. For some, it might mean something more like an AI that is more competent than the most competent human at literally every task. For some, acknowledging it means that we must acknowledge it has person-like rights. For some it cannot be AGI if it lies. For some it cannot be AGI if it makes any mistake. For some it cannot be AGI until it has more power than humans. These are several definitions and implications that are partially mutually conflicting but I have seen different people say that AGI is each different one of those.</div><br/></div></div><div id="35796489" class="c"><input type="checkbox" id="c-35796489" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#35796712">prev</a><span>|</span><a href="#35797088">next</a><span>|</span><label class="collapse" for="c-35796489">[-]</label><label class="expand" for="c-35796489">[10 more]</label></div><br/><div class="children"><div class="content">I wish I could bet real money on this cause I would bet hard against this statement. The issue is that nobody seems to agree what AGI even is.</div><br/><div id="35796596" class="c"><input type="checkbox" id="c-35796596" checked=""/><div class="controls bullet"><span class="by">boplicity</span><span>|</span><a href="#35796489">parent</a><span>|</span><a href="#35796835">next</a><span>|</span><label class="collapse" for="c-35796596">[-]</label><label class="expand" for="c-35796596">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s boils down to a question of &quot;personhood.&quot; It turns out that&#x27;s a political question and not a scientific one.<p>Another way to say this: when will someone allow an AGI to have free rein and independent choice and power? How much power will we allow it?</div><br/></div></div><div id="35796835" class="c"><input type="checkbox" id="c-35796835" checked=""/><div class="controls bullet"><span class="by">proc0</span><span>|</span><a href="#35796489">parent</a><span>|</span><a href="#35796596">prev</a><span>|</span><a href="#35796515">next</a><span>|</span><label class="collapse" for="c-35796835">[-]</label><label class="expand" for="c-35796835">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the trick, it just means it can do various task at human level. I think the original meaning of &quot;general&quot; is a reference to human intelligence kind of general, in other words Artificial Human Intelligence could be a better name for &quot;true AGI&quot;.</div><br/></div></div><div id="35796515" class="c"><input type="checkbox" id="c-35796515" checked=""/><div class="controls bullet"><span class="by">hderms</span><span>|</span><a href="#35796489">parent</a><span>|</span><a href="#35796835">prev</a><span>|</span><a href="#35796508">next</a><span>|</span><label class="collapse" for="c-35796515">[-]</label><label class="expand" for="c-35796515">[5 more]</label></div><br/><div class="children"><div class="content">Well in real terms, isn&#x27;t all it takes is something that&#x27;s a convincing enough forgery? Like why the turing test was considered interesting at one point. I don&#x27;t think drawing a line is necessary for us to quickly become caught off guard by developments in this space.<p>For the record, I don&#x27;t believe we&#x27;re close to AGI but I&#x27;m also pretty far from knowing anything about that field.</div><br/><div id="35796535" class="c"><input type="checkbox" id="c-35796535" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#35796489">root</a><span>|</span><a href="#35796515">parent</a><span>|</span><a href="#35796508">next</a><span>|</span><label class="collapse" for="c-35796535">[-]</label><label class="expand" for="c-35796535">[4 more]</label></div><br/><div class="children"><div class="content">Seems like a no lose bet no matter the odds. If you win, life goes on and you can collect a bit of money. If you lose, money becomes worthless and the surface of the earth gets transformed into a computing substrate.</div><br/><div id="35796592" class="c"><input type="checkbox" id="c-35796592" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#35796489">root</a><span>|</span><a href="#35796535">parent</a><span>|</span><a href="#35797267">next</a><span>|</span><label class="collapse" for="c-35796592">[-]</label><label class="expand" for="c-35796592">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know. Having interacted with LLMs at different levels, they resemble a very sophisticated, alien intelligence trying to pretend to be human. It&#x27;s like me pretending to be a dog; even if I were to emulate a dog perfectly, I wouldn&#x27;t have the same emotions; I&#x27;d be pretending.<p>We have no idea what emotions, motivations, behaviors, or goals AIs have, will have, or if they&#x27;ll have something as of yet unconvinced that&#x27;s not emotions or motivations, but just alien.<p>We evolved to self-preserve and breed. Modern AIs evolve to pretend to write human text. It&#x27;s not clear there is any intention to survive, reproduce, or turn the surface of the earth into a computing substrate.<p>There&#x27;s a million different dangers -- and I suspect the real ones are ones we haven&#x27;t conceived of. Whether they&#x27;ll materialize or how depends on on how we evolve them, and I expect we can&#x27;t predict it.<p>To me, much more likely than earth-as-a-computing-substrate is humans-as-brainwashed-consumers. Market forces will push for AIs to write text which draws eyeballs. Those models won&#x27;t care about truth, ethics, or much of anything other than getting you addicted to reading what they write (or watching what they create). At that point, we can destroy ourselves just fine.<p>But even more likely is something no one has thought of.</div><br/></div></div><div id="35797267" class="c"><input type="checkbox" id="c-35797267" checked=""/><div class="controls bullet"><span class="by">staticman2</span><span>|</span><a href="#35796489">root</a><span>|</span><a href="#35796535">parent</a><span>|</span><a href="#35796592">prev</a><span>|</span><a href="#35797006">next</a><span>|</span><label class="collapse" for="c-35797267">[-]</label><label class="expand" for="c-35797267">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s lots of science fiction that doesn&#x27;t have A.G.I. destroying the planet.<p>Commander Data, Hal 9000 (a bad guy but not <i>that</i> bad) Asimov&#x27;s droids, even the all powerful A.I. of Neuromancer has no particular ill will towards humans.<p>Belief in AGI hardly means you need to believe in Armageddon.</div><br/></div></div><div id="35797006" class="c"><input type="checkbox" id="c-35797006" checked=""/><div class="controls bullet"><span class="by">danaris</span><span>|</span><a href="#35796489">root</a><span>|</span><a href="#35796535">parent</a><span>|</span><a href="#35797267">prev</a><span>|</span><a href="#35796508">next</a><span>|</span><label class="collapse" for="c-35797006">[-]</label><label class="expand" for="c-35797006">[1 more]</label></div><br/><div class="children"><div class="content">This presupposes that &quot;AGI&quot; means:<p>1) The first AGI we create will immediately break free of our control<p>2) It will either have already been given, or will find some way to take, control of physical systems<p>3) It will create the Singularity<p>4) Its goals will be to advance itself at our expense<p>None of these are remotely givens. Even if we grant that AGI is possible with our current level of technology (which is also not at all a given), the Singularity is nothing but science fiction. It&#x27;s an interesting idea, but there&#x27;s no real reason to think it&#x27;s close to what an AGI&#x27;s capabilities would be like in reality.</div><br/></div></div></div></div></div></div><div id="35796508" class="c"><input type="checkbox" id="c-35796508" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#35796489">parent</a><span>|</span><a href="#35796515">prev</a><span>|</span><a href="#35796517">next</a><span>|</span><label class="collapse" for="c-35796508">[-]</label><label class="expand" for="c-35796508">[1 more]</label></div><br/><div class="children"><div class="content">There are betting markets that have odds up for this, you generally have to pay in crypto and the odds suck given your money is locked up for a decade plus(if they pay out at all). Importantly though, what do you think the odds are? I don&#x27;t think anyone is saying 50&#x2F;50 in a few years, just greater than 0%.</div><br/></div></div><div id="35796517" class="c"><input type="checkbox" id="c-35796517" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#35796489">parent</a><span>|</span><a href="#35796508">prev</a><span>|</span><a href="#35797088">next</a><span>|</span><label class="collapse" for="c-35796517">[-]</label><label class="expand" for="c-35796517">[1 more]</label></div><br/><div class="children"><div class="content">Without a <i>clear</i> definition of AGI, it&#x27;s going to be hard deciding who won...</div><br/></div></div></div></div><div id="35797088" class="c"><input type="checkbox" id="c-35797088" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#35796489">prev</a><span>|</span><a href="#35796956">next</a><span>|</span><label class="collapse" for="c-35797088">[-]</label><label class="expand" for="c-35797088">[1 more]</label></div><br/><div class="children"><div class="content">It seems to me that software developers are all too eager to attribute properties such as “intelligence,” to LLM’s which lead to strange, reductive conclusions that this is all humans are: token matching algorithms.<p>There is much to intelligence that those who’ve been studying it in areas such as biology and ecology still do not understand. The role of emotions and how they work have a strong influence on our cognitive abilities and consciousness as a whole. This is rarely ever considered a part of intelligence in the AI space.<p>And I think that’s rather the interesting part of all of this: we skip the artificial part and leap straight into <i>deus ex machina</i>. It is artificial and limited to what we choose to implement.<p>Even unsupervised learning isn’t technically that marvellous under the hood. In the sense that it is unknowable and seemingly magical.<p>I don’t agree that we’re a few years away from Data (a character from <i>Star Trek : The Next Generation</i> and an artificial life form) and we have no idea if we’d ever be able to implement Lore (a related character from the same show that has the benefits of being able to simulate emotions).</div><br/></div></div><div id="35796956" class="c"><input type="checkbox" id="c-35796956" checked=""/><div class="controls bullet"><span class="by">a13o</span><span>|</span><a href="#35797088">prev</a><span>|</span><a href="#35798096">next</a><span>|</span><label class="collapse" for="c-35796956">[-]</label><label class="expand" for="c-35796956">[1 more]</label></div><br/><div class="children"><div class="content">Since &#x27;AI&#x27; and &#x27;AGI&#x27; are so poorly defined, it&#x27;s allowed marketers to make un-disprovable claims that they have it for sale. These terms are now hyperbolic synonyms for &#x27;algorithm&#x27;.</div><br/></div></div><div id="35798096" class="c"><input type="checkbox" id="c-35798096" checked=""/><div class="controls bullet"><span class="by">jasfi</span><span>|</span><a href="#35796956">prev</a><span>|</span><a href="#35796831">next</a><span>|</span><label class="collapse" for="c-35798096">[-]</label><label class="expand" for="c-35798096">[1 more]</label></div><br/><div class="children"><div class="content">The current approach to AGI, as seen with projects like AutoGPT and BabyAGI, is to call an LLM (GPT-4 is the current choice) to solve and generate useful content recursively. Tasks are output, so for every task generated the LLM is asked to recursively solve that task, which could involve creating new tasks.<p>So far some small wins have been seen. Common problems involve looping and doing nothing. It&#x27;s still early for these projects.</div><br/></div></div><div id="35796831" class="c"><input type="checkbox" id="c-35796831" checked=""/><div class="controls bullet"><span class="by">matteoraso</span><span>|</span><a href="#35798096">prev</a><span>|</span><a href="#35796527">next</a><span>|</span><label class="collapse" for="c-35796831">[-]</label><label class="expand" for="c-35796831">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think there&#x27;s been any progress on AGI, actually. Even though there&#x27;s a lot of powerful AI programs out there, they&#x27;re really nothing more than complex tools created to solve problems. A few other commenters mentioned that there&#x27;s no good definition for what AGI would actually mean, but a good starting point that I think we can all agree on is that an AGI would need to have some level of autonomy. That being said, even if you did make an AI that was autonomous, I still think that it&#x27;s a leap to call it an AGI. The way I look at it, if you did all the math by hand, you wouldn&#x27;t call it intelligent, so you shouldn&#x27;t call it intelligent if the math was done by a computer.</div><br/><div id="35797741" class="c"><input type="checkbox" id="c-35797741" checked=""/><div class="controls bullet"><span class="by">NumberWangMan</span><span>|</span><a href="#35796831">parent</a><span>|</span><a href="#35796527">next</a><span>|</span><label class="collapse" for="c-35797741">[-]</label><label class="expand" for="c-35797741">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that doing the math by hand to simulate a machine intelligence makes it not intelligent, any more than doing a simulation of all the electrochemical signals in a human brain by hand would make a human not intelligent.  Aside from the infeasible amount of time it would take, it&#x27;s the same thing.<p>As for autonomy, LLMs don&#x27;t have autonomy by themselves.  But they can be pretty easily combined with other systems, connected to the outside world, in a way that seems pretty darned autonomous to me. (<a href="https:&#x2F;&#x2F;github.com&#x2F;Significant-Gravitas&#x2F;Auto-GPT">https:&#x2F;&#x2F;github.com&#x2F;Significant-Gravitas&#x2F;Auto-GPT</a>). And that&#x27;s basically a duct-tape-and-string version.  Given how new these LLMs are, it&#x27;s likely we&#x27;re barely scratching the surface.</div><br/><div id="35797753" class="c"><input type="checkbox" id="c-35797753" checked=""/><div class="controls bullet"><span class="by">NumberWangMan</span><span>|</span><a href="#35796831">root</a><span>|</span><a href="#35797741">parent</a><span>|</span><a href="#35796527">next</a><span>|</span><label class="collapse" for="c-35797753">[-]</label><label class="expand" for="c-35797753">[1 more]</label></div><br/><div class="children"><div class="content">Also:<p>&gt; Even though there&#x27;s a lot of powerful AI programs out there, they&#x27;re really nothing more than complex tools created to solve problems.<p>That&#x27;s what they&#x27;re designed to be, yes, but sometimes you end up with something more than what you intended.</div><br/></div></div></div></div></div></div><div id="35796527" class="c"><input type="checkbox" id="c-35796527" checked=""/><div class="controls bullet"><span class="by">dzink</span><span>|</span><a href="#35796831">prev</a><span>|</span><a href="#35797018">next</a><span>|</span><label class="collapse" for="c-35796527">[-]</label><label class="expand" for="c-35796527">[2 more]</label></div><br/><div class="children"><div class="content">AGI is the point when humans lose control, but between now and then they will lose a lot of white collar employment jobs. Based on the increase in productivity of anyone equipped with AI tools, we may see a lot of self-employment become more and more viable and lucrative.</div><br/><div id="35796634" class="c"><input type="checkbox" id="c-35796634" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#35796527">parent</a><span>|</span><a href="#35797018">next</a><span>|</span><label class="collapse" for="c-35796634">[-]</label><label class="expand" for="c-35796634">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll consider us lucky if losing control means something intelligent has taken control.  Like most car accidents, it could end up just being a series of dumb mistakes.</div><br/></div></div></div></div><div id="35797018" class="c"><input type="checkbox" id="c-35797018" checked=""/><div class="controls bullet"><span class="by">zemo</span><span>|</span><a href="#35796527">prev</a><span>|</span><a href="#35797201">next</a><span>|</span><label class="collapse" for="c-35797018">[-]</label><label class="expand" for="c-35797018">[2 more]</label></div><br/><div class="children"><div class="content">“person with vested business interest says their sector&#x2F;product&#x2F;company is going to revolutionize the world” wow no way you don’t say</div><br/><div id="35797331" class="c"><input type="checkbox" id="c-35797331" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#35797018">parent</a><span>|</span><a href="#35797201">next</a><span>|</span><label class="collapse" for="c-35797331">[-]</label><label class="expand" for="c-35797331">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be surprised if after this interview he got a few millions $$ more in his stock worth. It&#x27;s damage management. They, and he personally, didn&#x27;t see LLM potential.</div><br/></div></div></div></div><div id="35797201" class="c"><input type="checkbox" id="c-35797201" checked=""/><div class="controls bullet"><span class="by">telotortium</span><span>|</span><a href="#35797018">prev</a><span>|</span><a href="#35796657">next</a><span>|</span><label class="collapse" for="c-35797201">[-]</label><label class="expand" for="c-35797201">[1 more]</label></div><br/><div class="children"><div class="content">AI, when it was originally coined, was equivalent to what is meant by AGI now. Through enough hype and misapplication of the term to any new algorithm, AI eventually acquired in practice the meaning &quot;any new nontrivial algorithm that does things that humans can perform&quot; (until the shine wears off, in which case it&#x27;s no longer AI - even A star was originally considered AI). Looks like AGI is going to go down the same path. I wonder what the replacement term for AGI will be.</div><br/></div></div><div id="35796657" class="c"><input type="checkbox" id="c-35796657" checked=""/><div class="controls bullet"><span class="by">ckemere</span><span>|</span><a href="#35797201">prev</a><span>|</span><a href="#35796974">next</a><span>|</span><label class="collapse" for="c-35796657">[-]</label><label class="expand" for="c-35796657">[12 more]</label></div><br/><div class="children"><div class="content">Several comments have touched on this, but wouldn&#x27;t you define an AGI as something that could learn to drive a car? I think every (reasonable ( person understands self driving is &gt;10 years away. So shouldn&#x27;t AGI be?</div><br/><div id="35796914" class="c"><input type="checkbox" id="c-35796914" checked=""/><div class="controls bullet"><span class="by">sowbug</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35796684">next</a><span>|</span><label class="collapse" for="c-35796914">[-]</label><label class="expand" for="c-35796914">[2 more]</label></div><br/><div class="children"><div class="content">Self-driving cars are colloquially held to a much higher standard than human drivers are. Nothing currently exists that meets that standard. But humans meet the GI standard of AGI. And strong evidence shows that humans exist.<p>Thus, the standard for AGI is lower than the standard for self-driving cars. Existence of an AGI does not imply existence of self-driving cars.<p>To put it another way: take the worst human driver who still qualifies as &quot;could learn to drive a car.&quot; (It&#x27;s assumed the person is intelligent.) Construct a Turing-like test where we observe a car possibly being driven by that person, but we don&#x27;t know who or what is actually driving the car. The car drives over a curb, kills a cat crossing the street, narrowly misses a dozen pedestrians in crosswalks, and finally parks poorly in a mall parking lot -- just like we would expect from the world&#x27;s worst human driver. After observing that car trip, would we celebrate the long-awaited arrival of self-driving cars?</div><br/><div id="35797058" class="c"><input type="checkbox" id="c-35797058" checked=""/><div class="controls bullet"><span class="by">grumple</span><span>|</span><a href="#35796657">root</a><span>|</span><a href="#35796914">parent</a><span>|</span><a href="#35796684">next</a><span>|</span><label class="collapse" for="c-35797058">[-]</label><label class="expand" for="c-35797058">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t the best self driving cars causing traffic jams in SF because they can&#x27;t handle everyday tasks? And can any self driving car handle suboptimal environments like snow? Or just unmarked roads? Or... left turns in traffic?</div><br/></div></div></div></div><div id="35796684" class="c"><input type="checkbox" id="c-35796684" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35796914">prev</a><span>|</span><a href="#35796706">next</a><span>|</span><label class="collapse" for="c-35796684">[-]</label><label class="expand" for="c-35796684">[1 more]</label></div><br/><div class="children"><div class="content">Even if you believe AGI is imminent, I&#x27;m not sure this test holds. Driving requires much more than intelligence: blind people cannot drive.<p>It&#x27;s possible that we&#x27;re limited on the hardware &#x2F; modality front.</div><br/></div></div><div id="35796706" class="c"><input type="checkbox" id="c-35796706" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35796684">prev</a><span>|</span><a href="#35797262">next</a><span>|</span><label class="collapse" for="c-35796706">[-]</label><label class="expand" for="c-35796706">[4 more]</label></div><br/><div class="children"><div class="content">Not necessarily. It could be that AGI exists and can learn how to drive a car, but we don&#x27;t have good enough cameras&#x2F;LIDARs&#x2F;other sensors to make it work. Or the computation&#x2F;battery power needed to do so isn&#x27;t possible to fit in a car.<p>AGI is about inventing the brain, while the car is an entire body.</div><br/><div id="35797859" class="c"><input type="checkbox" id="c-35797859" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#35796657">root</a><span>|</span><a href="#35796706">parent</a><span>|</span><a href="#35797262">next</a><span>|</span><label class="collapse" for="c-35797859">[-]</label><label class="expand" for="c-35797859">[3 more]</label></div><br/><div class="children"><div class="content">In the General case* there is no functional brain without a functional body<p>*One can nitpick yourself into creating a series of examples of fictional disabled people but let’s not bikeshed please</div><br/><div id="35797877" class="c"><input type="checkbox" id="c-35797877" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35796657">root</a><span>|</span><a href="#35797859">parent</a><span>|</span><a href="#35797937">next</a><span>|</span><label class="collapse" for="c-35797877">[-]</label><label class="expand" for="c-35797877">[1 more]</label></div><br/><div class="children"><div class="content">Disabled people who have functional brains still have substantial body function (otherwise, their brain – which is part of the body and dependent on a number of other parts – would stop functioning.)</div><br/></div></div><div id="35797937" class="c"><input type="checkbox" id="c-35797937" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#35796657">root</a><span>|</span><a href="#35797859">parent</a><span>|</span><a href="#35797877">prev</a><span>|</span><a href="#35797262">next</a><span>|</span><label class="collapse" for="c-35797937">[-]</label><label class="expand" for="c-35797937">[1 more]</label></div><br/><div class="children"><div class="content">Can a blind person drive a car? Is a blind person not intelligent?</div><br/></div></div></div></div></div></div><div id="35797262" class="c"><input type="checkbox" id="c-35797262" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35796706">prev</a><span>|</span><a href="#35797116">next</a><span>|</span><label class="collapse" for="c-35797262">[-]</label><label class="expand" for="c-35797262">[1 more]</label></div><br/><div class="children"><div class="content">“G” means general. If it can learn to drive a car, build a car, sell cars, write poetry about cars, and teach a class about the history of cars, then it’s scratching the surface of AGI, because there’s more to life than cars.</div><br/></div></div><div id="35797116" class="c"><input type="checkbox" id="c-35797116" checked=""/><div class="controls bullet"><span class="by">staticman2</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35797262">prev</a><span>|</span><a href="#35796693">next</a><span>|</span><label class="collapse" for="c-35797116">[-]</label><label class="expand" for="c-35797116">[1 more]</label></div><br/><div class="children"><div class="content">If the AGI needs to live in a giant data center it probably can&#x27;t reliably drive a car due to latency issues.</div><br/></div></div><div id="35796693" class="c"><input type="checkbox" id="c-35796693" checked=""/><div class="controls bullet"><span class="by">jy1</span><span>|</span><a href="#35796657">parent</a><span>|</span><a href="#35797116">prev</a><span>|</span><a href="#35796974">next</a><span>|</span><label class="collapse" for="c-35796693">[-]</label><label class="expand" for="c-35796693">[2 more]</label></div><br/><div class="children"><div class="content">What makes you say self driving is 10 years away?</div><br/><div id="35796932" class="c"><input type="checkbox" id="c-35796932" checked=""/><div class="controls bullet"><span class="by">nsxwolf</span><span>|</span><a href="#35796657">root</a><span>|</span><a href="#35796693">parent</a><span>|</span><a href="#35796974">next</a><span>|</span><label class="collapse" for="c-35796932">[-]</label><label class="expand" for="c-35796932">[1 more]</label></div><br/><div class="children"><div class="content">5 years ago L5 autonomy was being released any day now, but now nobody talks about it anymore. It seems like a handful of self driving cars have been driving around in circles in a couple cities forever now and everyone just keeps giving the same demo.</div><br/></div></div></div></div></div></div><div id="35796974" class="c"><input type="checkbox" id="c-35796974" checked=""/><div class="controls bullet"><span class="by">lexandstuff</span><span>|</span><a href="#35796657">prev</a><span>|</span><a href="#35796773">next</a><span>|</span><label class="collapse" for="c-35796974">[-]</label><label class="expand" for="c-35796974">[2 more]</label></div><br/><div class="children"><div class="content">I get that AGI has a formal definition, but if I take the words &quot;Artificial General Intelligence&quot; on their own, I would say they describe GPT4 perfectly. It can plan my holiday, write a cover letter, code up scripts, explain music theory to me, etc. It is artificial, clearly a form of intelligence, and has a general application.</div><br/><div id="35797168" class="c"><input type="checkbox" id="c-35797168" checked=""/><div class="controls bullet"><span class="by">staticman2</span><span>|</span><a href="#35796974">parent</a><span>|</span><a href="#35796773">next</a><span>|</span><label class="collapse" for="c-35797168">[-]</label><label class="expand" for="c-35797168">[1 more]</label></div><br/><div class="children"><div class="content">One definition of AGI might be the system needs to be able to reason with small amounts of data.<p>I watched a Youtube video where Geoffrey Hinton (i think) said humans do a lot with small datasets and these LLM systems only work with huge datasets.<p>Im fact these systems arguably aren&#x27;t reasoning at all, the giant datasets just allow it to provide the illusion of reasoning.</div><br/></div></div></div></div><div id="35796773" class="c"><input type="checkbox" id="c-35796773" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#35796974">prev</a><span>|</span><a href="#35796583">next</a><span>|</span><label class="collapse" for="c-35796773">[-]</label><label class="expand" for="c-35796773">[2 more]</label></div><br/><div class="children"><div class="content">In a few more years, that mail-order airborne nanotech virus that travels kills everyone in an instant should be available too.</div><br/><div id="35797355" class="c"><input type="checkbox" id="c-35797355" checked=""/><div class="controls bullet"><span class="by">Beaver117</span><span>|</span><a href="#35796773">parent</a><span>|</span><a href="#35796583">next</a><span>|</span><label class="collapse" for="c-35797355">[-]</label><label class="expand" for="c-35797355">[1 more]</label></div><br/><div class="children"><div class="content">Definitely already have that. It just has some nasty side effect or expense or something preventing them from using it</div><br/></div></div></div></div></div></div></div></div></div></body></html>