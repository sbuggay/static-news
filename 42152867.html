<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731834066719" as="style"/><link rel="stylesheet" href="styles.css?v=1731834066719"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://rccchoudhury.github.io/rlt/">Don&#x27;t Look Twice: Faster Video Transformers with Run-Length Tokenization</a>Â <span class="domain">(<a href="https://rccchoudhury.github.io">rccchoudhury.github.io</a>)</span></div><div class="subtext"><span>jasondavies</span> | <span>10 comments</span></div><br/><div><div id="42161947" class="c"><input type="checkbox" id="c-42161947" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#42155927">next</a><span>|</span><label class="collapse" for="c-42161947">[-]</label><label class="expand" for="c-42161947">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, biological vision for reptiles (and probably other species) works largely on the same principle. It tends to filter out static background.</div><br/></div></div><div id="42155927" class="c"><input type="checkbox" id="c-42155927" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#42161947">prev</a><span>|</span><a href="#42156746">next</a><span>|</span><label class="collapse" for="c-42155927">[-]</label><label class="expand" for="c-42155927">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this like Differential Transformers that worked based on differences?</div><br/><div id="42159517" class="c"><input type="checkbox" id="c-42159517" checked=""/><div class="controls bullet"><span class="by">ImageXav</span><span>|</span><a href="#42155927">parent</a><span>|</span><a href="#42159461">next</a><span>|</span><label class="collapse" for="c-42159517">[-]</label><label class="expand" for="c-42159517">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can can tell though the core idea is the same, to focus on the differences, the implementation is different. Differential transformers &#x27;calculates attention scores as the difference between two separate softmax attention maps&#x27;. So they must process the redundant areas. This removes them altogether, which would significantly reduce compute. Very neat idea.<p>However, I do think that background information can sometimes be important. I reckon a mild improvement on this model would be to leave the background in the first frame, and perhaps every x frames, so that the model gets better context cues. This would also more accurately replicate video compression.</div><br/></div></div><div id="42159461" class="c"><input type="checkbox" id="c-42159461" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#42155927">parent</a><span>|</span><a href="#42159517">prev</a><span>|</span><a href="#42156746">next</a><span>|</span><label class="collapse" for="c-42159461">[-]</label><label class="expand" for="c-42159461">[1 more]</label></div><br/><div class="children"><div class="content">That was my feeling too for the most part, but The run length is a significant source of information and if it enables tokens to be skipped it is essentially gaining performance by working with a smaller but more dense form of the same information.  My instinct is that run-length would be just the most basic case of a more generalized method for storing token information to encompass time and area and for the density of information in tokens to be more even,  The area and duration being variable but the token stream containing a series of tokens containing similar quantities of semantic data.<p>I feel like this is very much like the early days of data compression where a few logical but kind of ad-hoc principles are being investigated in advance of a  more sophisticated theory that integrates the ideas of what is being attempted, how to identify success, and recognizing pathways that move towards the optimal solution.<p>These papers are the foundations of that work.</div><br/></div></div></div></div><div id="42156746" class="c"><input type="checkbox" id="c-42156746" checked=""/><div class="controls bullet"><span class="by">robbiemitchell</span><span>|</span><a href="#42155927">prev</a><span>|</span><a href="#42160269">next</a><span>|</span><label class="collapse" for="c-42156746">[-]</label><label class="expand" for="c-42156746">[4 more]</label></div><br/><div class="children"><div class="content">For training, would it be useful to stabilize the footage first?</div><br/><div id="42159541" class="c"><input type="checkbox" id="c-42159541" checked=""/><div class="controls bullet"><span class="by">FatalLogic</span><span>|</span><a href="#42156746">parent</a><span>|</span><a href="#42157247">next</a><span>|</span><label class="collapse" for="c-42159541">[-]</label><label class="expand" for="c-42159541">[2 more]</label></div><br/><div class="children"><div class="content">Stabilization appears to be a subset of a literally wider, but more rewarding, challenge: reconstructing the whole area that is scanned by the camera. It could be better to work on that challenge, not on simple stabilization.<p>That&#x27;s similar to how the human visual system &#x27;paints&#x27; a coherent scene from a quite narrow field of high-resolution view, with educated guesses and assumptions</div><br/><div id="42161163" class="c"><input type="checkbox" id="c-42161163" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#42156746">root</a><span>|</span><a href="#42159541">parent</a><span>|</span><a href="#42157247">next</a><span>|</span><label class="collapse" for="c-42161163">[-]</label><label class="expand" for="c-42161163">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;vidpanos.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vidpanos.github.io&#x2F;</a><p>There are other recent ones that do a new camera from any vantage point, not just rotation+fov changes like the above as well.  But they still might want stabilized video as the baseline input if they don&#x27;t already use it.<p>Besides saccades and tracking, your eyes also do a lot of stabilization, even counter rotating on the roll axis as you lean your head to the side.  I&#x27;m not sure if they roll when tracking a subject that rolls, I would think not common enough to need to be a thing.</div><br/></div></div></div></div><div id="42157247" class="c"><input type="checkbox" id="c-42157247" checked=""/><div class="controls bullet"><span class="by">nairoz</span><span>|</span><a href="#42156746">parent</a><span>|</span><a href="#42159541">prev</a><span>|</span><a href="#42160269">next</a><span>|</span><label class="collapse" for="c-42157247">[-]</label><label class="expand" for="c-42157247">[1 more]</label></div><br/><div class="children"><div class="content">I guess yes. Having worked on video processing, it&#x27;s always better if you can stabilize because it significantly reduces the number of unique tokens, which would be even more useful for the present method.
However, you probably lose in generalization performance and not all videos can be stabilized.</div><br/></div></div></div></div><div id="42160269" class="c"><input type="checkbox" id="c-42160269" checked=""/><div class="controls bullet"><span class="by">trash_cat</span><span>|</span><a href="#42156746">prev</a><span>|</span><label class="collapse" for="c-42160269">[-]</label><label class="expand" for="c-42160269">[1 more]</label></div><br/><div class="children"><div class="content">What would be the applications of this that is different from regular transformers? Perhaps stupid question.</div><br/></div></div></div></div></div></div></div></body></html>