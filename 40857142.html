<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720342856172" as="style"/><link rel="stylesheet" href="styles.css?v=1720342856172"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.tomshardware.com/pc-components/gpus/gpus-get-a-boost-from-pcie-attached-memory-that-boosts-capacity-and-delivers-double-digit-nanosecond-latency-ssds-can-also-be-used-to-expand-gpu-memory-capacity-via-panmnesias-cxl-ip">GPUs can now use PCIe-attached memory or SSDs to boost VRAM capacity</a>Â <span class="domain">(<a href="https://www.tomshardware.com">www.tomshardware.com</a>)</span></div><div class="subtext"><span>ohmyblock</span> | <span>15 comments</span></div><br/><div><div id="40857486" class="c"><input type="checkbox" id="c-40857486" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#40857637">next</a><span>|</span><label class="collapse" for="c-40857486">[-]</label><label class="expand" for="c-40857486">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s CXL not PCIe. The latency is much more like NUMA hop or so with CXL, which makes this much more likely to be useful than trying to use host memory over PCIe.<p>CXL 3.1 was the first spec where they added any way to have a host CPU also be able to share memory (host to host), itself be part of RDMA. It seems like it&#x27;s not exactly going to look like any other CXL memory device, so it&#x27;ll take some effort to make other hosts or even the local host be able to take advantage of CXL. <a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;cxl-3-1-specification-aims-for-big-topologies&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.servethehome.com&#x2F;cxl-3-1-specification-aims-for-...</a></div><br/></div></div><div id="40858711" class="c"><input type="checkbox" id="c-40858711" checked=""/><div class="controls bullet"><span class="by">RecycledEle</span><span>|</span><a href="#40857637">prev</a><span>|</span><a href="#40860033">next</a><span>|</span><label class="collapse" for="c-40858711">[-]</label><label class="expand" for="c-40858711">[2 more]</label></div><br/><div class="children"><div class="content">Good job decreasing latency.<p>Now work on the bandwidth.<p>A single HBM3 module has the bandwidth of half-a-dozen data center grade PCIe 5.0 x16 NVME drives.<p>A single DDR5 DIMM has the bandwidth of a pair of PCIe 5.0 x4 NVME drives.</div><br/><div id="40867687" class="c"><input type="checkbox" id="c-40867687" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#40858711">parent</a><span>|</span><a href="#40860033">next</a><span>|</span><label class="collapse" for="c-40867687">[-]</label><label class="expand" for="c-40867687">[1 more]</label></div><br/><div class="children"><div class="content">&quot;New RISC-V microprocessor can run CPU, GPU, and NPU workloads simultaneously&quot; <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39938538">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39938538</a></div><br/></div></div></div></div><div id="40860033" class="c"><input type="checkbox" id="c-40860033" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#40858711">prev</a><span>|</span><a href="#40857223">next</a><span>|</span><label class="collapse" for="c-40860033">[-]</label><label class="expand" for="c-40860033">[6 more]</label></div><br/><div class="children"><div class="content">Perhaps this would be a good application for 3D XPoint memory that was seemingly discontinued due to lack of a compelling use case.</div><br/><div id="40861004" class="c"><input type="checkbox" id="c-40861004" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#40860033">parent</a><span>|</span><a href="#40896079">next</a><span>|</span><label class="collapse" for="c-40861004">[-]</label><label class="expand" for="c-40861004">[2 more]</label></div><br/><div class="children"><div class="content">Optane definitely had many great uses. It had stunningly good iops with very low latency, it had fantastic endurance, and no write amplification concerns. Optane was excellent for datases, just pricey! Far more pricey than Intel had promised initially, which was a disappointment, but still somewhat in league with enterprise SSDs of the time.<p>If you really wanted very low latency you needed Optane DIMMs. And that was problematic because typically you wanted motherboards loaded with ram. And it made it complex to figure out how to use those DIMMs, those parts of memory that would be slower but persistent. Using the DIMMs was hard.<p>But Optane existed as a damned fine NVMe product too! Latency wasn&#x27;t as good because it was PCIe, was the main downside. CXL could remove this penalty, make it look more like ram that is a NUMA hop away, potentially, which would be grand. This ain&#x27;t really required to use Optane well, one can still get epic iops at incredibly consistently low latency &amp; proposer, but if you do have a latency sensitive demand it certainly can help!<p>Poor Optane. I have a hard time understanding how something of such excellent value floundered so. In truth there&#x27;s not that many people who need many drive-writes-per-day but even if you didn&#x27;t, the promise was this drive should last you a very very long time because it had such endurance. That long term sustainability seemed like an incredible value we simply failed to recognize &amp; tap.</div><br/><div id="40896163" class="c"><input type="checkbox" id="c-40896163" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#40860033">root</a><span>|</span><a href="#40861004">parent</a><span>|</span><a href="#40896079">next</a><span>|</span><label class="collapse" for="c-40896163">[-]</label><label class="expand" for="c-40896163">[1 more]</label></div><br/><div class="children"><div class="content">Every time I go through old NVME&#x2F;m2 drives in the bins in our IT cage, I sigh and think what could have been.</div><br/></div></div></div></div><div id="40896079" class="c"><input type="checkbox" id="c-40896079" checked=""/><div class="controls bullet"><span class="by">pbalcer</span><span>|</span><a href="#40860033">parent</a><span>|</span><a href="#40861004">prev</a><span>|</span><a href="#40861305">next</a><span>|</span><label class="collapse" for="c-40896079">[-]</label><label class="expand" for="c-40896079">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll just leave this here:
<a href="https:&#x2F;&#x2F;computeexpresslink.org&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;12&#x2F;CXL-2.0-Presentation-Persistent-Memory-20210615_FINAL.pdf" rel="nofollow">https:&#x2F;&#x2F;computeexpresslink.org&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;12&#x2F;CX...</a><p>Combined with the fact that Intel created both CXL and Optane, it stands to reason that the plan was to combine them eventually. Unfortunately, that was never came to pass :(</div><br/></div></div><div id="40861305" class="c"><input type="checkbox" id="c-40861305" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40860033">parent</a><span>|</span><a href="#40896079">prev</a><span>|</span><a href="#40857223">next</a><span>|</span><label class="collapse" for="c-40861305">[-]</label><label class="expand" for="c-40861305">[2 more]</label></div><br/><div class="children"><div class="content">It was discontinued because it was too expensive to be viable.</div><br/><div id="40866175" class="c"><input type="checkbox" id="c-40866175" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#40860033">root</a><span>|</span><a href="#40861305">parent</a><span>|</span><a href="#40857223">next</a><span>|</span><label class="collapse" for="c-40866175">[-]</label><label class="expand" for="c-40866175">[1 more]</label></div><br/><div class="children"><div class="content">Usually cost comes down with volume so that is also tied to lack of uses. If a significant use case was known it could have been scaled to offset investments. Things were already developed for SSD and memory access tiers with no substantial demand&#x2F;application for something in-between.</div><br/></div></div></div></div></div></div><div id="40857223" class="c"><input type="checkbox" id="c-40857223" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#40860033">prev</a><span>|</span><a href="#40857436">next</a><span>|</span><label class="collapse" for="c-40857223">[-]</label><label class="expand" for="c-40857223">[3 more]</label></div><br/><div class="children"><div class="content">Using CPU memory to extend GPU memory seems like a more straightforward approach. Does this method provide any benefits over it?</div><br/><div id="40857682" class="c"><input type="checkbox" id="c-40857682" checked=""/><div class="controls bullet"><span class="by">Zandikar</span><span>|</span><a href="#40857223">parent</a><span>|</span><a href="#40857449">next</a><span>|</span><label class="collapse" for="c-40857682">[-]</label><label class="expand" for="c-40857682">[1 more]</label></div><br/><div class="children"><div class="content">Depends on the PCIe&#x2F;DMA topology of the system, but in short, in an ideal system you can avoid the bottleneck of the CPU interconnect (eg, AMD&#x27;s Infinity Fabric) and reduce overall CPU load by (un)loading data directly from your NVMe storage to your PCIe accelerator [0]. You can also combine this with RDMA&#x2F;RoCE (provided everything in the chain supports it) to make a clustered network with NVMeoF to serve data from a high speed NVMe flash array(s) to clusters of GPU&#x27;s; even potentially using this to reduce cost&#x2F;space&#x2F;power by reducing the nead for high cost&#x2F;high power CPU&#x27;s. Prior to CXL&#x27;s proliferation (which realistically we haven&#x27;t achieved yet), this is mostly limited to bespoke HPC systems; most consumer systems lack the PCIe lanes&#x2F;topology to really make use of this in a practical  way.<p>On the consumer side, you&#x27;re right, using the System ram is probably a better approach as most consumer motherboards would have the NVMe storage routing up to the CPU Interconnect then back &quot;Down&quot; to the GPU (or worse through the &quot;southbridge&quot; chipset(s) like on X570) so you take that hit anyway.<p>However if you have a PCIe switch on board that allows data to flow direct from storage to GPU without a round trip across the CPU, then NVMe&#x2F;CXL&#x2F;SCM modules would theoretically be better than system RAM. Depends on the switch, retimers, muxing, topology etc.<p>Regardless of what you&#x27;re using for direct storage and how ideal your topology is, the MTps and GBps over PCIe is <i>significantly</i> slower than onboard VRAM (be it GDDR or especially HBM) and bandwidth limited to boot. Doesn&#x27;t mean it&#x27;s useless by any means, but important to point out that this doesn&#x27;t turn a 20GB VRAM card into a 2.02TB VRAM card just because you DirectStorage&#x27;d a 2TB Drive to it, no matter how ideal the setup is. However, as PCIe increases in bandwidth and Storage-Class-Memory type devices and just storage tech in general continues to improve, it&#x27;s rapidly becoming more viable. On PCIe gen 3, you&#x27;re probably shooting yourself in the foot. on PCIe Gen 6, you can realistically see a very real benefit. But again, there&#x27;s a lot of &quot;depends&quot; here and for now, you&#x27;re probably better off buying a bigger or multiple GPUs if you&#x27;re not on the cutting edge with the corporate credit line.<p>0: <a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;gpudirect-storage&#x2F;" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;gpudirect-storage&#x2F;</a></div><br/></div></div><div id="40857449" class="c"><input type="checkbox" id="c-40857449" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#40857223">parent</a><span>|</span><a href="#40857682">prev</a><span>|</span><a href="#40857436">next</a><span>|</span><label class="collapse" for="c-40857449">[-]</label><label class="expand" for="c-40857449">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if fighting with the CPU for allocation would be a bottleneck. Seems to me the only way to dedicate full bandwidth would be to have a separate PCI-e (as theyve done)</div><br/></div></div></div></div></div></div></div></div></div></body></html>