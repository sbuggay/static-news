<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700643667669" as="style"/><link rel="stylesheet" href="styles.css?v=1700643667669"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/PKU-YuanGroup/Video-LLaVA">Video-LLaVA</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>tosh</span> | <span>35 comments</span></div><br/><div><div id="38367897" class="c"><input type="checkbox" id="c-38367897" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#38367387">next</a><span>|</span><label class="collapse" for="c-38367897">[-]</label><label class="expand" for="c-38367897">[14 more]</label></div><br/><div class="children"><div class="content">Researchers seem very comfortable sticking &quot;Apache 2.0&quot; licenses all over their foundation model finetunes.<p>This model is absolutely not Apache 2.0 in reality (it&#x27;s a Vicuna finetune nevermind the sourcing of the finetune dataset) and I would use it for business at your peril.</div><br/><div id="38374679" class="c"><input type="checkbox" id="c-38374679" checked=""/><div class="controls bullet"><span class="by">cosmojg</span><span>|</span><a href="#38367897">parent</a><span>|</span><a href="#38368064">next</a><span>|</span><label class="collapse" for="c-38374679">[-]</label><label class="expand" for="c-38374679">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s unlikely that model weights are even copyrightable in the first place, at least based on what the US Copyright Office has said in the past. In fact, it seems that even the outputs of such models are excluded from copyright protection, regardless of the skill involved in their production[1]. IANAL, but it&#x27;s likely that the license documents attached to these large language models amount to little more than somewhat weak ToS agreements, allowing the distributor a bit more leeway in managing their legal&#x2F;commercial relationship with users of said models.<p>At the end of the day, though, this is all mere speculation. We won&#x27;t know the truth until someone decides to burn the cash necessary to test it in court.<p>[1] <a href="https:&#x2F;&#x2F;fingfx.thomsonreuters.com&#x2F;gfx&#x2F;legaldocs&#x2F;klpygnkyrpg&#x2F;AI%20COPYRIGHT%20decision.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;fingfx.thomsonreuters.com&#x2F;gfx&#x2F;legaldocs&#x2F;klpygnkyrpg&#x2F;...</a></div><br/></div></div><div id="38368064" class="c"><input type="checkbox" id="c-38368064" checked=""/><div class="controls bullet"><span class="by">yeldarb</span><span>|</span><a href="#38367897">parent</a><span>|</span><a href="#38374679">prev</a><span>|</span><a href="#38371219">next</a><span>|</span><label class="collapse" for="c-38368064">[-]</label><label class="expand" for="c-38368064">[4 more]</label></div><br/><div class="children"><div class="content">Looks like the Vicuna repo is Apache 2.0 also[1].<p>What&#x27;s the interpretation of copyright law that would prevent the code being Apache 2.0 based on the source of the fine-tuning dataset?<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;lm-sys&#x2F;FastChat">https:&#x2F;&#x2F;github.com&#x2F;lm-sys&#x2F;FastChat</a></div><br/><div id="38369591" class="c"><input type="checkbox" id="c-38369591" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38368064">parent</a><span>|</span><a href="#38371219">next</a><span>|</span><label class="collapse" for="c-38369591">[-]</label><label class="expand" for="c-38369591">[3 more]</label></div><br/><div class="children"><div class="content">Not quite: fastchat is the inference code which is Apache 2.0 but distinct from the model artifact. If you look at the model [0] it is licensed as non-commercial.<p>But why?<p>Well for one, Vicuna is a Llama finetune, which already excludes it from being Apache 2.0. It&#x27;s also finetuned on OAI data which is... questionable in terms of license (don&#x27;t think you can really legally license a model trained on OAI output as Apache 2.0 - although OAI doesn&#x27;t really play by its own rules so who knows)<p>[0]: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;lmsys&#x2F;vicuna-13b-v1.3" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;lmsys&#x2F;vicuna-13b-v1.3</a></div><br/><div id="38370219" class="c"><input type="checkbox" id="c-38370219" checked=""/><div class="controls bullet"><span class="by">yeldarb</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38369591">parent</a><span>|</span><a href="#38371219">next</a><span>|</span><label class="collapse" for="c-38370219">[-]</label><label class="expand" for="c-38370219">[2 more]</label></div><br/><div class="children"><div class="content">Which part of copyright law are model weights governed by? (Or, if not by copyright law, what&#x27;s the legal basis that would let you choose a &quot;license&quot; for model weights?)</div><br/><div id="38371877" class="c"><input type="checkbox" id="c-38371877" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38370219">parent</a><span>|</span><a href="#38371219">next</a><span>|</span><label class="collapse" for="c-38371877">[-]</label><label class="expand" for="c-38371877">[1 more]</label></div><br/><div class="children"><div class="content">Weights may or may not be subject to copyright law.<p>Are they a mere aggregation of facts -- some uncopyrightable, and some from other sources--, or is there a creative component to them?<p><a href="https:&#x2F;&#x2F;libraries.emory.edu&#x2F;research&#x2F;copyright&#x2F;copyright-data" rel="nofollow noreferrer">https:&#x2F;&#x2F;libraries.emory.edu&#x2F;research&#x2F;copyright&#x2F;copyright-dat...</a></div><br/></div></div></div></div></div></div></div></div><div id="38371219" class="c"><input type="checkbox" id="c-38371219" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38367897">parent</a><span>|</span><a href="#38368064">prev</a><span>|</span><a href="#38368011">next</a><span>|</span><label class="collapse" for="c-38371219">[-]</label><label class="expand" for="c-38371219">[2 more]</label></div><br/><div class="children"><div class="content">Tbf the llama license allows for small businesses usage.<p>But also these models aren’t watermarked or anything (not that watermarking really works) so it’s kind of the wild west</div><br/><div id="38374059" class="c"><input type="checkbox" id="c-38374059" checked=""/><div class="controls bullet"><span class="by">pilotneko</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38371219">parent</a><span>|</span><a href="#38368011">next</a><span>|</span><label class="collapse" for="c-38374059">[-]</label><label class="expand" for="c-38374059">[1 more]</label></div><br/><div class="children"><div class="content">Llama 2 does, but Llama does not. Vicuna is based on Llama.</div><br/></div></div></div></div><div id="38368011" class="c"><input type="checkbox" id="c-38368011" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#38367897">parent</a><span>|</span><a href="#38371219">prev</a><span>|</span><a href="#38367387">next</a><span>|</span><label class="collapse" for="c-38368011">[-]</label><label class="expand" for="c-38368011">[6 more]</label></div><br/><div class="children"><div class="content">Fine-tuning the weights scrambles the original representations (sometimes more than others depending on training settings, but if you train the text encoder it certainly will). All authors have to do is not be honest about the original model it was fine-tuned on in a world where lawyers start to come down on this.<p>I see no issue for businesses using it.</div><br/><div id="38369610" class="c"><input type="checkbox" id="c-38369610" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38368011">parent</a><span>|</span><a href="#38372025">next</a><span>|</span><label class="collapse" for="c-38369610">[-]</label><label class="expand" for="c-38369610">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know - it sounds like your default assumption is that there is no issue because businesses can commit copyright infringement&#x2F;fraud and not be caught, I am not a lawyer so I can&#x27;t comment on the merits of the approach.<p>Generally I think it is difficult for businesses to break the law given that any one of the members might defect on you.<p>Also I suspect that the logprobs for various sequences would reveal which foundation model you used.</div><br/><div id="38372081" class="c"><input type="checkbox" id="c-38372081" checked=""/><div class="controls bullet"><span class="by">theferalrobot</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38369610">parent</a><span>|</span><a href="#38372025">next</a><span>|</span><label class="collapse" for="c-38372081">[-]</label><label class="expand" for="c-38372081">[3 more]</label></div><br/><div class="children"><div class="content">I do not think it has been determined that weights are copyrightable</div><br/><div id="38373878" class="c"><input type="checkbox" id="c-38373878" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38372081">parent</a><span>|</span><a href="#38372025">next</a><span>|</span><label class="collapse" for="c-38373878">[-]</label><label class="expand" for="c-38373878">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the issue here, regardless of if it&#x27;s true or not.<p>The issue here is that if you have some upstream with license XXX on it, you can most certainly slap some YYY license on your repo, but <i>that doesn&#x27;t make it true</i>.<p>This is like when someone pushes up a corporate private repo and puts an MIT license file on the repo.<p>Releasing code as GPL when you <i>dont have the authority to do so</i>, does <i>not make the code GPL</i>.<p>Certainly, as a consumer you can say that you &#x27;didn&#x27;t know&#x27; it was not actually MIT, but that <i>doesn&#x27;t absolve you from liability</i>; as a consumer, you are required to do your due diligence, and if upon finding that you were mislead &#x2F; mistaken &#x2F; whatever, take steps to remediate it.<p>...otherwise you&#x27;re liable.<p>It&#x27;s that simple.</div><br/><div id="38374701" class="c"><input type="checkbox" id="c-38374701" checked=""/><div class="controls bullet"><span class="by">cosmojg</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38373878">parent</a><span>|</span><a href="#38372025">next</a><span>|</span><label class="collapse" for="c-38374701">[-]</label><label class="expand" for="c-38374701">[1 more]</label></div><br/><div class="children"><div class="content">I think the parent comment is implying that they don&#x27;t believe they are liable for infringement since, based on their understanding of the law, model weights are not copyrightable in the first place, and until a court actually rules on the issue, there&#x27;s nothing to remediate.</div><br/></div></div></div></div></div></div></div></div><div id="38372025" class="c"><input type="checkbox" id="c-38372025" checked=""/><div class="controls bullet"><span class="by">theferalrobot</span><span>|</span><a href="#38367897">root</a><span>|</span><a href="#38368011">parent</a><span>|</span><a href="#38369610">prev</a><span>|</span><a href="#38367387">next</a><span>|</span><label class="collapse" for="c-38372025">[-]</label><label class="expand" for="c-38372025">[1 more]</label></div><br/><div class="children"><div class="content">It is my understanding that you can compare weights and with a high degree of confidence determine what the parent of a model is unless the fine tuning destroyed all the original information in which case there isn’t a huge reason to have fine tuned to begin with. There are other ways to scramble weights which make the comparisons a lot harder to do though which will matter if weights ever are considered copyrightable</div><br/></div></div></div></div></div></div><div id="38367387" class="c"><input type="checkbox" id="c-38367387" checked=""/><div class="controls bullet"><span class="by">bobosha</span><span>|</span><a href="#38367897">prev</a><span>|</span><a href="#38370603">next</a><span>|</span><label class="collapse" for="c-38367387">[-]</label><label class="expand" for="c-38367387">[2 more]</label></div><br/><div class="children"><div class="content">This is a very cool project! Kudos to the authors for being on top and keeping the features coming. Appears to be feature-competitive with OpenAI&#x27;s GPT-4V `vision` endpoint.</div><br/><div id="38372968" class="c"><input type="checkbox" id="c-38372968" checked=""/><div class="controls bullet"><span class="by">zwily</span><span>|</span><a href="#38367387">parent</a><span>|</span><a href="#38370603">next</a><span>|</span><label class="collapse" for="c-38372968">[-]</label><label class="expand" for="c-38372968">[1 more]</label></div><br/><div class="children"><div class="content">It has more features actually - cause it does video. But quality is far, far behind gpt4-vision. (Just tried a bunch of images on it and compared to the gpt4 output). This feels more gpt3 level. I’m glad someone is working on it though!</div><br/></div></div></div></div><div id="38370603" class="c"><input type="checkbox" id="c-38370603" checked=""/><div class="controls bullet"><span class="by">rajamaka</span><span>|</span><a href="#38367387">prev</a><span>|</span><a href="#38368058">next</a><span>|</span><label class="collapse" for="c-38370603">[-]</label><label class="expand" for="c-38370603">[1 more]</label></div><br/><div class="children"><div class="content">Demo just errors out unfortunately</div><br/></div></div><div id="38368058" class="c"><input type="checkbox" id="c-38368058" checked=""/><div class="controls bullet"><span class="by">kyriakos</span><span>|</span><a href="#38370603">prev</a><span>|</span><a href="#38368481">next</a><span>|</span><label class="collapse" for="c-38368058">[-]</label><label class="expand" for="c-38368058">[7 more]</label></div><br/><div class="children"><div class="content">I honestly have no idea what this project is about. It may be because I&#x27;m completely out of the loop regarding LLMs but still...</div><br/><div id="38375647" class="c"><input type="checkbox" id="c-38375647" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#38368058">parent</a><span>|</span><a href="#38368584">next</a><span>|</span><label class="collapse" for="c-38375647">[-]</label><label class="expand" for="c-38375647">[1 more]</label></div><br/><div class="children"><div class="content">It will answer questions about images and&#x2F;or videos; it&#x27;s open-source and would compete with some of Chat-GPT 4&#x27;s advanced features. It&#x27;s extremely poorly explained on the Github page because it&#x27;s trying to get interest from other AI researchers with ~256 buzzwords. Great if you already know what it is, extremely unhelpful if you don&#x27;t.<p>It seems quite good, ironic that the Github landing page communicates the idea so poorly.</div><br/></div></div><div id="38368584" class="c"><input type="checkbox" id="c-38368584" checked=""/><div class="controls bullet"><span class="by">abrichr</span><span>|</span><a href="#38368058">parent</a><span>|</span><a href="#38375647">prev</a><span>|</span><a href="#38368541">next</a><span>|</span><label class="collapse" for="c-38368584">[-]</label><label class="expand" for="c-38368584">[2 more]</label></div><br/><div class="children"><div class="content">Open source question answering over videos:<p>&gt; With the binding of unified visual representations to the language feature space, we enable an LLM to perform visual reasoning capabilities on both images and videos simultaneously.</div><br/><div id="38368995" class="c"><input type="checkbox" id="c-38368995" checked=""/><div class="controls bullet"><span class="by">kyriakos</span><span>|</span><a href="#38368058">root</a><span>|</span><a href="#38368584">parent</a><span>|</span><a href="#38368541">next</a><span>|</span><label class="collapse" for="c-38368995">[-]</label><label class="expand" for="c-38368995">[1 more]</label></div><br/><div class="children"><div class="content">Thanks</div><br/></div></div></div></div><div id="38368541" class="c"><input type="checkbox" id="c-38368541" checked=""/><div class="controls bullet"><span class="by">fkyoureadthedoc</span><span>|</span><a href="#38368058">parent</a><span>|</span><a href="#38368584">prev</a><span>|</span><a href="#38368753">next</a><span>|</span><label class="collapse" for="c-38368541">[-]</label><label class="expand" for="c-38368541">[2 more]</label></div><br/><div class="children"><div class="content">I had no idea from the name, but the README does a good job of explaining what it&#x27;s about. Even has a nice video demo.</div><br/><div id="38375095" class="c"><input type="checkbox" id="c-38375095" checked=""/><div class="controls bullet"><span class="by">dcchambers</span><span>|</span><a href="#38368058">root</a><span>|</span><a href="#38368541">parent</a><span>|</span><a href="#38368753">next</a><span>|</span><label class="collapse" for="c-38375095">[-]</label><label class="expand" for="c-38375095">[1 more]</label></div><br/><div class="children"><div class="content">Does it? I have tried to read the README and I still can&#x27;t figure out what it does. There&#x27;s also so much random stuff smashed into the README that just trying to figure out where to get started...reading...is an exercise in frustration.<p>The Title:<p>&gt; &quot;Video-LLaVA: Learning United Visual Representation by Alignment Before Projection&quot;<p>I know all of those words, but I don&#x27;t understand what they mean in that order or context. Let&#x27;s move on.<p>Next up is a bunch of links to other pages, other projects, and news about the project. Let&#x27;s skip all that.<p>Finally we get to something called &quot; Highlights&quot;:<p>&gt; &quot;Video-LLaVA exhibits remarkable interactive capabilities between images and videos, despite the absence of image-video pairs in the dataset.&quot;<p>OK, so now I know that it does <i>something</i> with images and videos, although I am not sure what that something is. I still don&#x27;t know what it <i>IS</i> though. Is it an application? A LLM?<p>Continuing on...<p>&gt;  Simple baseline, learning united visual representation by alignment before projection<p>&gt; With the binding of unified visual representations to the language feature space, we enable an LLM to perform visual reasoning capabilities on both images and videos simultaneously.<p>&gt;  High performance, complementary learning with video and image<p>&gt; Extensive experiments demonstrate the complementarity of modalities, showcasing significant superiority when compared to models specifically designed for either images or videos.<p>Seriously...what? Did a (bad) LLM write those sentences or am I just an idiot?<p>Then there&#x27;s a picture, demo video, some installation and basic CLI usage commands (hey, now I finally know it&#x27;s a python tool!), API info, and more random stuff.<p>Honestly I have attempted to read through this README several times and I still don&#x27;t really know what I&#x27;m looking at.</div><br/></div></div></div></div><div id="38368753" class="c"><input type="checkbox" id="c-38368753" checked=""/><div class="controls bullet"><span class="by">btbuildem</span><span>|</span><a href="#38368058">parent</a><span>|</span><a href="#38368541">prev</a><span>|</span><a href="#38368481">next</a><span>|</span><label class="collapse" for="c-38368753">[-]</label><label class="expand" for="c-38368753">[1 more]</label></div><br/><div class="children"><div class="content">The related paper is here: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.10122.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.10122.pdf</a><p>I think the TL;DR is &quot;it can tell what&#x27;s in the video and &#x27;reason&#x27; about it&quot;</div><br/></div></div></div></div><div id="38368481" class="c"><input type="checkbox" id="c-38368481" checked=""/><div class="controls bullet"><span class="by">astrea</span><span>|</span><a href="#38368058">prev</a><span>|</span><label class="collapse" for="c-38368481">[-]</label><label class="expand" for="c-38368481">[10 more]</label></div><br/><div class="children"><div class="content">Side note: Why does every GitHub readme look like a children’s book these days? Emojis, big colorful graphics, gifs, cute project logo, etc. Makes me feel awkward trying to read about a serious topic with the “:o” emoji staring in my face. I’m just waiting for the air horns to start blaring and a dancing cat to slide across my screen.</div><br/><div id="38368661" class="c"><input type="checkbox" id="c-38368661" checked=""/><div class="controls bullet"><span class="by">chankstein38</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38368692">next</a><span>|</span><label class="collapse" for="c-38368661">[-]</label><label class="expand" for="c-38368661">[1 more]</label></div><br/><div class="children"><div class="content">Because you&#x27;re dealing with humans and sometimes humans don&#x27;t behave in the same way you apparently expect everyone to?  These aren&#x27;t massive billion dollar corps they&#x27;re some engineer or group of engineers doing something interesting to them.<p>In this case it seems related to a university, so these are students and researchers at a university.  Some of them are very likely qualifiable as kids to us old people.<p>Not sure why it&#x27;s such a bother to you, does a topic need to be cold and black and white for it to further our technological research?  (That&#x27;s hypothetical because this repo, for instance, absolutely furthers our tech abilities while also being in a more friendly non-academic format.)</div><br/></div></div><div id="38368692" class="c"><input type="checkbox" id="c-38368692" checked=""/><div class="controls bullet"><span class="by">Implicated</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38368661">prev</a><span>|</span><a href="#38370595">next</a><span>|</span><label class="collapse" for="c-38368692">[-]</label><label class="expand" for="c-38368692">[1 more]</label></div><br/><div class="children"><div class="content">The closer to discord a community is the more things look this way, at least that&#x27;s my interpretation.</div><br/></div></div><div id="38370595" class="c"><input type="checkbox" id="c-38370595" checked=""/><div class="controls bullet"><span class="by">dvngnt_</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38368692">prev</a><span>|</span><a href="#38370253">next</a><span>|</span><label class="collapse" for="c-38370595">[-]</label><label class="expand" for="c-38370595">[1 more]</label></div><br/><div class="children"><div class="content">you could also ask why does serious writing often avoid adding big colorful graphics if it looks better.</div><br/></div></div><div id="38370253" class="c"><input type="checkbox" id="c-38370253" checked=""/><div class="controls bullet"><span class="by">dymk</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38370595">prev</a><span>|</span><a href="#38369404">next</a><span>|</span><label class="collapse" for="c-38370253">[-]</label><label class="expand" for="c-38370253">[1 more]</label></div><br/><div class="children"><div class="content">Do you use syntax highlighting?</div><br/></div></div><div id="38369404" class="c"><input type="checkbox" id="c-38369404" checked=""/><div class="controls bullet"><span class="by">devmor</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38370253">prev</a><span>|</span><a href="#38369458">next</a><span>|</span><label class="collapse" for="c-38369404">[-]</label><label class="expand" for="c-38369404">[1 more]</label></div><br/><div class="children"><div class="content">Emojis are part of the common vernacular now, and software development is a mainstream career instead of a siloed off nerd-haven.</div><br/></div></div><div id="38369458" class="c"><input type="checkbox" id="c-38369458" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38369404">prev</a><span>|</span><a href="#38369659">next</a><span>|</span><label class="collapse" for="c-38369458">[-]</label><label class="expand" for="c-38369458">[3 more]</label></div><br/><div class="children"><div class="content">Because it&#x27;s more inviting than to just people who like text alone.<p><a href="https:&#x2F;&#x2F;shuiblue.github.io&#x2F;forcolab-uoft&#x2F;paper&#x2F;IST2022-emoji.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;shuiblue.github.io&#x2F;forcolab-uoft&#x2F;paper&#x2F;IST2022-emoji...</a></div><br/><div id="38371239" class="c"><input type="checkbox" id="c-38371239" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38368481">root</a><span>|</span><a href="#38369458">parent</a><span>|</span><a href="#38369659">next</a><span>|</span><label class="collapse" for="c-38371239">[-]</label><label class="expand" for="c-38371239">[2 more]</label></div><br/><div class="children"><div class="content">I love that this exists</div><br/><div id="38371445" class="c"><input type="checkbox" id="c-38371445" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#38368481">root</a><span>|</span><a href="#38371239">parent</a><span>|</span><a href="#38369659">next</a><span>|</span><label class="collapse" for="c-38371445">[-]</label><label class="expand" for="c-38371445">[1 more]</label></div><br/><div class="children"><div class="content">Me too.<p>Not to say a study can’t often be found for most viewpoints.</div><br/></div></div></div></div></div></div><div id="38369659" class="c"><input type="checkbox" id="c-38369659" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#38368481">parent</a><span>|</span><a href="#38369458">prev</a><span>|</span><label class="collapse" for="c-38369659">[-]</label><label class="expand" for="c-38369659">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t agree more!</div><br/></div></div></div></div></div></div></div></div></div></body></html>