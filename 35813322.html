<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683363668492" as="style"/><link rel="stylesheet" href="styles.css?v=1683363668492"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">Google “We have no moat, and neither does OpenAI”</a> <span class="domain">(<a href="https://www.semianalysis.com">www.semianalysis.com</a>)</span></div><div class="subtext"><span>klelatti</span> | <span>498 comments</span></div><br/><div><div id="35821576" class="c"><input type="checkbox" id="c-35821576" checked=""/><div class="controls bullet"><span class="by">dahwolf</span><span>|</span><a href="#35818774">next</a><span>|</span><label class="collapse" for="c-35821576">[-]</label><label class="expand" for="c-35821576">[137 more]</label></div><br/><div class="children"><div class="content">The current paradigm is that AI is a destination. A product you go to and interact with.<p>That&#x27;s not at all how the masses are going to interact with AI in the near future. It&#x27;s going to be seamlessly integrated into every-day software. In Office&#x2F;Google docs, at the operating system level (Android), in your graphics editor (Adobe), on major web platforms: search, image search, Youtube, the like.<p>Since Google and other Big Tech continue to control these billion-user platforms, they have AI reach, even if they are temporarily behind in capability. They&#x27;ll also find a way to integrate this in a way where you don&#x27;t have to directly pay for the capability, as it&#x27;s paid in other ways: ads.<p>OpenAI faces the existential risk, not Google. They&#x27;ll catch up and will have the reach&#x2F;subsidy advantage.<p>And it doesn&#x27;t end there. This so-called &quot;competition&quot; from open source is going to be free labor. Any winning idea ported into Google&#x27;s products on short notice. Thanks open source!</div><br/><div id="35825767" class="c"><input type="checkbox" id="c-35825767" checked=""/><div class="controls bullet"><span class="by">safety1st</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35821671">next</a><span>|</span><label class="collapse" for="c-35825767">[-]</label><label class="expand" for="c-35825767">[28 more]</label></div><br/><div class="children"><div class="content">There are no guarantees about who will or won&#x27;t own the future, just the observation that disruptive technology makes everyone&#x27;s fate more volatile. Big tech companies like Google have a lot of in-built advantages, but they&#x27;re notoriously bad at executing on pivots which fundamentally alter or commoditize their core business. If that wasn&#x27;t true we&#x27;d all be using Microsoft phones (or heck, IBM PCs AND phones).<p>In Google&#x27;s case they are still really focused on search whereas LLMs arguably move the focus to answers. I don&#x27;t use an LLM to search for stuff, it just gives me an answer. Whether this is a huge shift for how Google&#x27;s business works and whether they will be able to execute it quickly and effectively remains to be seen.<p>Bill Gates&#x27; &quot;Internet Tidal Wave&quot; memo from 1995 is a great piece of relevant historical reading. You can see that he was amazingly prescient about the potential of the Internet at a time when barely anyone was using it. Despite Microsoft having more resources than anyone, totally understanding what a big deal the Internet was going to be, and even coming out of the gate pretty strong by dominating the browser market, they lost a lot of relevancy in the long run because their business was just too tied up in the idea of a box sitting on a desktop in an office as the center of value. (When Windows was dethroned as the company&#x27;s center of gravity and they put Satya and DevDiv with its Azure offerings in charge, things started to turn around!)<p>[1] <a href="https:&#x2F;&#x2F;lettersofnote.com&#x2F;2011&#x2F;07&#x2F;22&#x2F;the-internet-tidal-wave&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lettersofnote.com&#x2F;2011&#x2F;07&#x2F;22&#x2F;the-internet-tidal-wave...</a></div><br/><div id="35829259" class="c"><input type="checkbox" id="c-35829259" checked=""/><div class="controls bullet"><span class="by">kmmlng</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35828875">next</a><span>|</span><label class="collapse" for="c-35829259">[-]</label><label class="expand" for="c-35829259">[5 more]</label></div><br/><div class="children"><div class="content">I feel like search still has its place. New information is being generated all the time. I want to be able to access it without having to retrain my LLM. It&#x27;s also easier to validate that my search results are real. With LLMs, you never know if the answers are hallucinated or real. Where LLMs really shine is in understanding what I actually want. Where search still gives me many irrelevant answers, LLMs just get my question. Combining the two in some way might just get us the best of both worlds.</div><br/><div id="35834437" class="c"><input type="checkbox" id="c-35834437" checked=""/><div class="controls bullet"><span class="by">midnitewarrior</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829259">parent</a><span>|</span><a href="#35835857">next</a><span>|</span><label class="collapse" for="c-35834437">[-]</label><label class="expand" for="c-35834437">[1 more]</label></div><br/><div class="children"><div class="content">Bing Chat searches then summarizes for you. It gets all the latest information, reads the top results and gives you a summary of what you are looking for. It&#x27;s here today. Also, Bing Chat makes search by humans irrelevant for many things.<p>&quot;You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete.&quot; ― Buckminster Fuller<p>Google needs to move fast.</div><br/></div></div><div id="35835857" class="c"><input type="checkbox" id="c-35835857" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829259">parent</a><span>|</span><a href="#35834437">prev</a><span>|</span><a href="#35834164">next</a><span>|</span><label class="collapse" for="c-35835857">[-]</label><label class="expand" for="c-35835857">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I feel like search still has its place.<p>I sure hope so. Unlike (apparently) the majority here, when I&#x27;m searching the web I&#x27;m rarely just looking for an answer. I&#x27;m researching. What I want is a list of possible resources to investigate. What I don&#x27;t want is for someone or something to determine an &quot;answer&quot; or to summarize everything for me.<p>I hope my use case isn&#x27;t tossed aside.</div><br/></div></div><div id="35834164" class="c"><input type="checkbox" id="c-35834164" checked=""/><div class="controls bullet"><span class="by">rounakdatta</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829259">parent</a><span>|</span><a href="#35835857">prev</a><span>|</span><a href="#35832647">next</a><span>|</span><label class="collapse" for="c-35834164">[-]</label><label class="expand" for="c-35834164">[1 more]</label></div><br/><div class="children"><div class="content">Phind shines here.</div><br/></div></div><div id="35832647" class="c"><input type="checkbox" id="c-35832647" checked=""/><div class="controls bullet"><span class="by">nicehill</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829259">parent</a><span>|</span><a href="#35834164">prev</a><span>|</span><a href="#35828875">next</a><span>|</span><label class="collapse" for="c-35832647">[-]</label><label class="expand" for="c-35832647">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why I turn almost all of my personal notes into blog posts, so I can use Google to search my notes.</div><br/></div></div></div></div><div id="35828875" class="c"><input type="checkbox" id="c-35828875" checked=""/><div class="controls bullet"><span class="by">hyperthesis</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35829259">prev</a><span>|</span><a href="#35826708">next</a><span>|</span><label class="collapse" for="c-35828875">[-]</label><label class="expand" for="c-35828875">[2 more]</label></div><br/><div class="children"><div class="content">Christensen&#x27;s <i>disruptive</i> vs <i>sustaining</i> innovations is more descriptive than predictive. But if it&#x27;s the same customers, solving the same problem, in the same way (from their point of view), then it&#x27;s probably &quot;sustaining&quot; and incumbents win.<p>Different customers, problems, ways - and all bets are off. Worse, incumbents are dependent on their customers, having optimized the company around them. Even if they know the opportunity and could grasp it, if it means losing customers <i>they simply can&#x27;t do it.</i><p>Larry is thinking <i>people will still search... right?</i></div><br/><div id="35839430" class="c"><input type="checkbox" id="c-35839430" checked=""/><div class="controls bullet"><span class="by">afpx</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35828875">parent</a><span>|</span><a href="#35826708">next</a><span>|</span><label class="collapse" for="c-35839430">[-]</label><label class="expand" for="c-35839430">[1 more]</label></div><br/><div class="children"><div class="content">The innovator&#x27;s dilemma posits that innovations often eats away at current revenues. Systematically, large organizations structure themselves into silos. Owners of silos resist change. Large organizations are unable to innovate unless there&#x27;s pressure (and support) at the top level to slowly abandon existing revenue streams.</div><br/></div></div></div></div><div id="35826708" class="c"><input type="checkbox" id="c-35826708" checked=""/><div class="controls bullet"><span class="by">midasuni</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35828875">prev</a><span>|</span><a href="#35826580">next</a><span>|</span><label class="collapse" for="c-35826708">[-]</label><label class="expand" for="c-35826708">[2 more]</label></div><br/><div class="children"><div class="content">From memory Bill Gates barely mentioned the internet in his first edition of road ahead in early 95. By late 95 the second edition entire book was revolving around the internet as if he had an epiphany.</div><br/><div id="35827463" class="c"><input type="checkbox" id="c-35827463" checked=""/><div class="controls bullet"><span class="by">Hydraulix989</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826708">parent</a><span>|</span><a href="#35826580">next</a><span>|</span><label class="collapse" for="c-35827463">[-]</label><label class="expand" for="c-35827463">[1 more]</label></div><br/><div class="children"><div class="content">In the first edition, he did describe something very much like the Internet, except he called it the &quot;Information Superhighway&quot;</div><br/></div></div></div></div><div id="35826580" class="c"><input type="checkbox" id="c-35826580" checked=""/><div class="controls bullet"><span class="by">bsaul</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35826708">prev</a><span>|</span><a href="#35829676">next</a><span>|</span><label class="collapse" for="c-35826580">[-]</label><label class="expand" for="c-35826580">[7 more]</label></div><br/><div class="children"><div class="content">in 1995 people understood <i>very well</i> what internet was going to become. The technology just wasn&#x27;t there yet, but every kid and parents remember very well the sound of that modem and the phone lines beeing busy.<p>That memo would have been prescient if made 5 years before.</div><br/><div id="35826743" class="c"><input type="checkbox" id="c-35826743" checked=""/><div class="controls bullet"><span class="by">pcthrowaway</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826580">parent</a><span>|</span><a href="#35839442">next</a><span>|</span><label class="collapse" for="c-35826743">[-]</label><label class="expand" for="c-35826743">[1 more]</label></div><br/><div class="children"><div class="content">The infamous Bill Gates and David Letterman interview was in 1995: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tgODUgHeT5Y">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tgODUgHeT5Y</a> Lots of people definitely <i>didn&#x27;t</i> understand what a big deal it was going to be then.<p>In October 1994 a Wired journalist registered mcdonalds.com and then tried to <i>give</i> it to Mcdonalds, but couldn&#x27;t reach anyone who understood the importance of domain name registration: <a href="https:&#x2F;&#x2F;archive.is&#x2F;tHaea" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;tHaea</a><p>In my recollection it really wasn&#x27;t til 1998-2001 or so that people (where I lived in the southern U.S. anyway) really started to take notice.</div><br/></div></div><div id="35839442" class="c"><input type="checkbox" id="c-35839442" checked=""/><div class="controls bullet"><span class="by">afpx</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826580">parent</a><span>|</span><a href="#35826743">prev</a><span>|</span><a href="#35826672">next</a><span>|</span><label class="collapse" for="c-35839442">[-]</label><label class="expand" for="c-35839442">[1 more]</label></div><br/><div class="children"><div class="content">In 1995, I was working for a tech company that literally sent memos in paper folders. It took them until 1999 to adopt email.</div><br/></div></div><div id="35826672" class="c"><input type="checkbox" id="c-35826672" checked=""/><div class="controls bullet"><span class="by">mads_ravn</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826580">parent</a><span>|</span><a href="#35839442">prev</a><span>|</span><a href="#35826664">next</a><span>|</span><label class="collapse" for="c-35826672">[-]</label><label class="expand" for="c-35826672">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I also thought of Eternal September [1] in 1993, when I saw the claim to prescience.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eternal_September" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eternal_September</a></div><br/></div></div><div id="35826664" class="c"><input type="checkbox" id="c-35826664" checked=""/><div class="controls bullet"><span class="by">adalacelove</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826580">parent</a><span>|</span><a href="#35826672">prev</a><span>|</span><a href="#35835909">next</a><span>|</span><label class="collapse" for="c-35826664">[-]</label><label class="expand" for="c-35826664">[1 more]</label></div><br/><div class="children"><div class="content">True but the remaining of the comment is still valid: Microsoft had time in advance to prepare.<p>But just &quot;internet&quot; doesn&#x27;t mean a lot. Prescient would have been predicting search, ads and social media. We now are in a similar position maybe, with some tech that looks cool, trying to build geocities with AI</div><br/></div></div><div id="35832884" class="c"><input type="checkbox" id="c-35832884" checked=""/><div class="controls bullet"><span class="by">greedo</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826580">parent</a><span>|</span><a href="#35835909">prev</a><span>|</span><a href="#35829676">next</a><span>|</span><label class="collapse" for="c-35832884">[-]</label><label class="expand" for="c-35832884">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re conflating the Internet with the walled gardens that were dominant at the time; AOL, Compuserve, Prodigy etc.</div><br/></div></div></div></div><div id="35829676" class="c"><input type="checkbox" id="c-35829676" checked=""/><div class="controls bullet"><span class="by">kweingar</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35826580">prev</a><span>|</span><a href="#35829552">next</a><span>|</span><label class="collapse" for="c-35829676">[-]</label><label class="expand" for="c-35829676">[5 more]</label></div><br/><div class="children"><div class="content">&gt; In Google&#x27;s case they are still really focused on search whereas LLMs arguably move the focus to answers.<p>I would love to see what proportion of searches are questions that would benefit from natural language answers. The huge majority of my searches would not be improved by LLMs and in fact would probably be made worse. “Thai food near me”, “IRS phone number”, “golang cmp documentation”</div><br/><div id="35832387" class="c"><input type="checkbox" id="c-35832387" checked=""/><div class="controls bullet"><span class="by">sdwr</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829676">parent</a><span>|</span><a href="#35834673">next</a><span>|</span><label class="collapse" for="c-35832387">[-]</label><label class="expand" for="c-35832387">[1 more]</label></div><br/><div class="children"><div class="content">That kind of myopic thinking is exactly why google might be in trouble.<p>Think about the problem, not your current solution.<p>&quot;I&#x27;m hungry&quot;<p>&quot;I need to do my taxes&quot;<p>&quot;My code dont work right&quot;<p>Searching for info is <i>a</i> solution to those problems, not <i>the</i> solution. The promise of AI (might take a while to get there) is having an agent that you trust to solve those problems for you.<p>Or learning your preferences over time.<p>Or folding the question into part of a longer dialogue.</div><br/></div></div><div id="35834673" class="c"><input type="checkbox" id="c-35834673" checked=""/><div class="controls bullet"><span class="by">agitator</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829676">parent</a><span>|</span><a href="#35832387">prev</a><span>|</span><a href="#35829827">next</a><span>|</span><label class="collapse" for="c-35834673">[-]</label><label class="expand" for="c-35834673">[1 more]</label></div><br/><div class="children"><div class="content">And isn’t that the problem?<p>Why do I need to translate my question into an optimal set of keywords that will give me what I want while minimizing unwanted results? Google search was a great stepping stone and connects you with the web, but it’s broken in many ways when it comes to what value we are really trying to extract.<p>A machine that can hone in on what I’m getting at in an intuitive sense while having all of human data available to generate a response is so much more powerful.</div><br/></div></div><div id="35829827" class="c"><input type="checkbox" id="c-35829827" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829676">parent</a><span>|</span><a href="#35834673">prev</a><span>|</span><a href="#35829754">next</a><span>|</span><label class="collapse" for="c-35829827">[-]</label><label class="expand" for="c-35829827">[1 more]</label></div><br/><div class="children"><div class="content">Frankly, it’s more about the number of ads and low relevance.<p>Old google was simply faster to use.<p>GPT for search is google without ads</div><br/></div></div><div id="35829754" class="c"><input type="checkbox" id="c-35829754" checked=""/><div class="controls bullet"><span class="by">throwaway1777</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35829676">parent</a><span>|</span><a href="#35829827">prev</a><span>|</span><a href="#35829552">next</a><span>|</span><label class="collapse" for="c-35829754">[-]</label><label class="expand" for="c-35829754">[1 more]</label></div><br/><div class="children"><div class="content">Thai food near me- chatgpt can give you a list of thai restaurants near you. IRS phone number has a definitive answer. Chatgpt can also spit out the golang documentation for cmp or even give you sample code.</div><br/></div></div></div></div><div id="35829552" class="c"><input type="checkbox" id="c-35829552" checked=""/><div class="controls bullet"><span class="by">lallysingh</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35829676">prev</a><span>|</span><a href="#35826679">next</a><span>|</span><label class="collapse" for="c-35829552">[-]</label><label class="expand" for="c-35829552">[1 more]</label></div><br/><div class="children"><div class="content">For Google, LLMs for search responses, ad ranking, and page ranking are all quite useful.  They can directly eat up the first page or so of filler responses they normally have now for queries.  It&#x27;s a great opportunity to clean out all the spam pages on the result pages at once, leaving high quality results <i>and</i> capturing that advertising&#x2F;referral money back to Google.<p>Top 10 best reviewed android phones?  Just put up a list generated by the LLM.  Have a conversation with a product recommender that then collects fees from whoever it recommends.<p>Not that I think Google&#x27;s got the executive capacity to do any of this anymore.</div><br/></div></div><div id="35826679" class="c"><input type="checkbox" id="c-35826679" checked=""/><div class="controls bullet"><span class="by">nivenkos</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35829552">prev</a><span>|</span><a href="#35826649">next</a><span>|</span><label class="collapse" for="c-35826679">[-]</label><label class="expand" for="c-35826679">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft wanted to control it all with Blackbird and ActivePlatform.<p>Their greed ended up with them losing out (thankfully).</div><br/></div></div><div id="35826649" class="c"><input type="checkbox" id="c-35826649" checked=""/><div class="controls bullet"><span class="by">graycat</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35826679">prev</a><span>|</span><a href="#35826419">next</a><span>|</span><label class="collapse" for="c-35826649">[-]</label><label class="expand" for="c-35826649">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If that wasn&#x27;t true we&#x27;d all be using Microsoft phones (or heck, IBM PCs AND phones).<p>Once an IBM Office Manager was offering me a job and explained<p>&quot;IBM is a marketing organization.&quot;<p>So, the focus was not really on computers or phones but on the central, crucial, bet your business <i>data processing</i> of the larger and largest companies -- banking, insurance, manufacturing, ..., and <i>marketing</i> to them.<p>So, the focus of IBM was really on their target customers.  So, if some target customers needed something, then IBM would design, build, and deliver it.<p>That may still be their focus.</div><br/><div id="35826765" class="c"><input type="checkbox" id="c-35826765" checked=""/><div class="controls bullet"><span class="by">killjoywashere</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826649">parent</a><span>|</span><a href="#35826419">next</a><span>|</span><label class="collapse" for="c-35826765">[-]</label><label class="expand" for="c-35826765">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, as a government buyer, IBM is indistinguishable from the other big integrator&#x2F;consulting firms (BAH, Deloitte, Lockheed, Mitre to an extent). Literally, whatever we want, they will swear they can build. The challenge is getting the spec right.</div><br/></div></div></div></div><div id="35826419" class="c"><input type="checkbox" id="c-35826419" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825767">parent</a><span>|</span><a href="#35826649">prev</a><span>|</span><a href="#35821671">next</a><span>|</span><label class="collapse" for="c-35826419">[-]</label><label class="expand" for="c-35826419">[2 more]</label></div><br/><div class="children"><div class="content">&gt; even coming out of the gate pretty strong by dominating the browser market<p>They were out of the gate about as weak as could be, Windows didn&#x27;t have a native tcp&#x2F;ip stack for the longest time (remember Trumpet Winsock?) and they only dominated the browser market through grossly uncompetitive behavior after they had lost the initial 5 rounds of the battle.</div><br/><div id="35829631" class="c"><input type="checkbox" id="c-35829631" checked=""/><div class="controls bullet"><span class="by">ChrisLTD</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35826419">parent</a><span>|</span><a href="#35821671">next</a><span>|</span><label class="collapse" for="c-35829631">[-]</label><label class="expand" for="c-35829631">[1 more]</label></div><br/><div class="children"><div class="content">They definitely used uncompetitive behavior, but it’s also true that IE was also a better browser than Netscape by the time version 4 rolled out.</div><br/></div></div></div></div></div></div><div id="35821671" class="c"><input type="checkbox" id="c-35821671" checked=""/><div class="controls bullet"><span class="by">narrator</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35825767">prev</a><span>|</span><a href="#35822087">next</a><span>|</span><label class="collapse" for="c-35821671">[-]</label><label class="expand" for="c-35821671">[37 more]</label></div><br/><div class="children"><div class="content">I think the problem with AI being everywhere and ubiquitous is that AI is the first technology in a very long time that requires non-trivial compute power.  That compute power costs money. This is why you only get a limited number of messages every few hours from GPT4.  It simply costs too much to be a ubiquitous technology.<p>For example, the biggest LLama model only runs on an A100 that costs about $15,000 on ebay.  The new H100 that is 3x faster goes for about $40,000 and both of these cards can only support a limited number of users, not the tens of thousands of users who can run off a high-end webserver.<p>I&#x27;d imagine Google would lose a lot of money if they put GPT4 level AI into every search, and they are obsessed with cost per search.  Multiply that by the billions and it&#x27;s the kind of thing that will not be cheap enough to be ad supported.</div><br/><div id="35823522" class="c"><input type="checkbox" id="c-35823522" checked=""/><div class="controls bullet"><span class="by">Taek</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35821763">next</a><span>|</span><label class="collapse" for="c-35823522">[-]</label><label class="expand" for="c-35823522">[6 more]</label></div><br/><div class="children"><div class="content">The biggest llama model has near 100% fidelity (its like 99.3%) at 4 bit quantization, which allows it to fit on any 40GB or 48GB GPU, which you can get for $3500.<p>Or at about a 10x speed reduction you can run it on 128 GB of RAM for only around $250.<p>The story is not anywhere near as bleak as you paint.</div><br/><div id="35824892" class="c"><input type="checkbox" id="c-35824892" checked=""/><div class="controls bullet"><span class="by">opisthenar84</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823522">parent</a><span>|</span><a href="#35823931">next</a><span>|</span><label class="collapse" for="c-35824892">[-]</label><label class="expand" for="c-35824892">[1 more]</label></div><br/><div class="children"><div class="content">A $3500 GPU requirement is far from democratization of AI.</div><br/></div></div><div id="35823931" class="c"><input type="checkbox" id="c-35823931" checked=""/><div class="controls bullet"><span class="by">brimwats</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823522">parent</a><span>|</span><a href="#35824892">prev</a><span>|</span><a href="#35835947">next</a><span>|</span><label class="collapse" for="c-35823931">[-]</label><label class="expand" for="c-35823931">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen any repos or guides to using llama on that level of RAM, which is something I do have. any pointers?</div><br/></div></div><div id="35826753" class="c"><input type="checkbox" id="c-35826753" checked=""/><div class="controls bullet"><span class="by">botanical</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823522">parent</a><span>|</span><a href="#35835947">prev</a><span>|</span><a href="#35824282">next</a><span>|</span><label class="collapse" for="c-35826753">[-]</label><label class="expand" for="c-35826753">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s just to run a model already trained by a multi-billion dollar company. And we are &quot;lucky&quot; a corporation gave it to the public. Training such a model requires tons of compute power and electricity.</div><br/></div></div><div id="35824282" class="c"><input type="checkbox" id="c-35824282" checked=""/><div class="controls bullet"><span class="by">spiffytech</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823522">parent</a><span>|</span><a href="#35826753">prev</a><span>|</span><a href="#35821763">next</a><span>|</span><label class="collapse" for="c-35824282">[-]</label><label class="expand" for="c-35824282">[1 more]</label></div><br/><div class="children"><div class="content">Something I haven&#x27;t figured out: should I think about these memory requirements as comparable to the baseline memory an app uses, or like per-request overhead? If I needed to process 10 prompts at once, do I need 10x those memory figures?</div><br/></div></div></div></div><div id="35821763" class="c"><input type="checkbox" id="c-35821763" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35823522">prev</a><span>|</span><a href="#35823636">next</a><span>|</span><label class="collapse" for="c-35821763">[-]</label><label class="expand" for="c-35821763">[4 more]</label></div><br/><div class="children"><div class="content">Time for a dedicated &quot;AI box&quot; at home with hotswapping compute boards? Maybe put it inside a humanoid or animal-like robot with TTS capabilities?<p>Sign me up for that kickstarter!<p>EDIT: based on some quick googling (should I have asked ChatGPT instead?), Nvidia sells the Jetson Xavier Nx dev kit for ~$610 <a href="https:&#x2F;&#x2F;www.electromaker.io&#x2F;shop&#x2F;product&#x2F;nvidia-jetson-xavier-nx-developer-kitpre-order" rel="nofollow">https:&#x2F;&#x2F;www.electromaker.io&#x2F;shop&#x2F;product&#x2F;nvidia-jetson-xavie...</a><p>Just need the robot toy dog enclosure<p>(See <a href="https:&#x2F;&#x2F;www.electromaker.io&#x2F;blog&#x2F;article&#x2F;best-sbc-for-ai-single-board-computer-for-artificial-intelligence" rel="nofollow">https:&#x2F;&#x2F;www.electromaker.io&#x2F;blog&#x2F;article&#x2F;best-sbc-for-ai-sin...</a> for a list of alternatives if that one is too expensive)</div><br/><div id="35827101" class="c"><input type="checkbox" id="c-35827101" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821763">parent</a><span>|</span><a href="#35821992">next</a><span>|</span><label class="collapse" for="c-35827101">[-]</label><label class="expand" for="c-35827101">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more likely that you want a lot of compute for a very little amount of time each day - which makes centralised&#x2F;cloud processing the most obvious answer.<p>If I want a response within 100ms, and have 1000 AI-queries per day, that would only be about 2 minutes of aggregated processing time for your AI box per day. It&#x27;s less than 1% utilised. If the same box is multiuser and on the internet, it can probably serve 50-100 peoples queries concurrently.<p>The converse is that if you put something onto the cloud, for the same cost you might be able to effectively get 50x the hardware per user for the same cost (i.e. rather than have 1 AI box locally with 1 GPU for each of the 50 users, you could have 1 AI box with 50 GPU&#x27;s which is usable by all 50 users).</div><br/></div></div><div id="35821992" class="c"><input type="checkbox" id="c-35821992" checked=""/><div class="controls bullet"><span class="by">yayr</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821763">parent</a><span>|</span><a href="#35827101">prev</a><span>|</span><a href="#35824535">next</a><span>|</span><label class="collapse" for="c-35821992">[-]</label><label class="expand" for="c-35821992">[1 more]</label></div><br/><div class="children"><div class="content">each billion parameters using 16 bit floats requires around 2 GB of GPU or TPU RAM. ChatGPT is expected to have around 1000 billion. Good open source LLMs have around 7-20 billion currently. Consumer GPUs currently max out at 24 GB. You can now quantize the model to e.g. 4 bits instead of 32 per parameter and do other compressions, but still there is quite a limit what you can do with 24 GB of RAM. The Apple unified memory approach may be a path forward to increase that... so one box gives you access to the small models, for a GPT4 like model you&#x27;d need (for inference and if you had the model and tools) probably 100 of those 4090s or 25 of H100 with 96 GBs I guess to fit in 2 TB of model data.</div><br/></div></div><div id="35824535" class="c"><input type="checkbox" id="c-35824535" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821763">parent</a><span>|</span><a href="#35821992">prev</a><span>|</span><a href="#35823636">next</a><span>|</span><label class="collapse" for="c-35824535">[-]</label><label class="expand" for="c-35824535">[1 more]</label></div><br/><div class="children"><div class="content">Benchmarks for what you can do on CPU alone.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;issues&#x2F;34">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;issues&#x2F;34</a><p>An M1 Max does 100ms per token. A 64 core threadripper about 33ms per token.</div><br/></div></div></div></div><div id="35823636" class="c"><input type="checkbox" id="c-35823636" checked=""/><div class="controls bullet"><span class="by">deegles</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35821763">prev</a><span>|</span><a href="#35822107">next</a><span>|</span><label class="collapse" for="c-35823636">[-]</label><label class="expand" for="c-35823636">[3 more]</label></div><br/><div class="children"><div class="content">I was in Japan recently and they sell these pocket size translator devices with a microphone, camera and screen. You can speak to it or take pictures and it will translate on the fly. Maybe $100 usd range for a nice one.<p>It&#x27;s only a matter of time before someone makes a similar device with a decent LLM on it, and premium ones will have more memory&#x2F;cpu power.</div><br/><div id="35824095" class="c"><input type="checkbox" id="c-35824095" checked=""/><div class="controls bullet"><span class="by">nmfisher</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823636">parent</a><span>|</span><a href="#35823661">next</a><span>|</span><label class="collapse" for="c-35824095">[-]</label><label class="expand" for="c-35824095">[1 more]</label></div><br/><div class="children"><div class="content">I mean...isn&#x27;t that just a smartphone?<p>I know exactly what you&#x27;re talking about because my father-in-law had the same thing. I&#x27;m just very skeptical that specialist hardware will overtake general commoditized computing devices for mass-market usage. The economics alone make it unlikely.</div><br/></div></div><div id="35823661" class="c"><input type="checkbox" id="c-35823661" checked=""/><div class="controls bullet"><span class="by">tyree731</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823636">parent</a><span>|</span><a href="#35824095">prev</a><span>|</span><a href="#35822107">next</a><span>|</span><label class="collapse" for="c-35823661">[-]</label><label class="expand" for="c-35823661">[1 more]</label></div><br/><div class="children"><div class="content">I think we as humans have a tendency to extrapolate from our present position to a position we can imagine that we’d like, even if there isn’t a foreseeable path from here to there. I believe this may end up being one of those cases.</div><br/></div></div></div></div><div id="35822107" class="c"><input type="checkbox" id="c-35822107" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35823636">prev</a><span>|</span><a href="#35822865">next</a><span>|</span><label class="collapse" for="c-35822107">[-]</label><label class="expand" for="c-35822107">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a win for Google that LLMs are getting cheaper to run. OpenAI&#x27;s service is too expensive to be ad-funded. Google needs a technology that&#x27;s cheaper to provide to maintain their ad-supported business model.</div><br/><div id="35822675" class="c"><input type="checkbox" id="c-35822675" checked=""/><div class="controls bullet"><span class="by">patrickk</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822107">parent</a><span>|</span><a href="#35822865">next</a><span>|</span><label class="collapse" for="c-35822675">[-]</label><label class="expand" for="c-35822675">[1 more]</label></div><br/><div class="children"><div class="content">Google could make a bet like they did with YouTube.<p>At the time, operating YouTube was eye wateringly expensive and lost billions. But google could see where things were going: a triple trend of falling storage costs, falling bandwidth and transmission costs (I’m trying to dig up a link I read years ago about this but google search has gotten so shit that I can’t find it).<p>It was similar for Asic miners for Bitcoin. Given enough demand, specialised, lower cost hardware specially for LLMs will emerge.</div><br/></div></div></div></div><div id="35822865" class="c"><input type="checkbox" id="c-35822865" checked=""/><div class="controls bullet"><span class="by">rileyphone</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35822107">prev</a><span>|</span><a href="#35824792">next</a><span>|</span><label class="collapse" for="c-35822865">[-]</label><label class="expand" for="c-35822865">[2 more]</label></div><br/><div class="children"><div class="content">You can run it (quantified at least) on a $4000 Mac thanks to Apple&#x27;s unified memory. Surely other manufacturers are looking for how to expand VRAM, hopefully Intel or AMD.</div><br/><div id="35824467" class="c"><input type="checkbox" id="c-35824467" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822865">parent</a><span>|</span><a href="#35824792">next</a><span>|</span><label class="collapse" for="c-35824467">[-]</label><label class="expand" for="c-35824467">[1 more]</label></div><br/><div class="children"><div class="content">Not to mention Apple chips have a bunch of very nice accelerators and also (!!!) macOS contains system frameworks that <i>actually use them</i>.</div><br/></div></div></div></div><div id="35824792" class="c"><input type="checkbox" id="c-35824792" checked=""/><div class="controls bullet"><span class="by">pavelstoev</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35822865">prev</a><span>|</span><a href="#35821894">next</a><span>|</span><label class="collapse" for="c-35824792">[-]</label><label class="expand" for="c-35824792">[1 more]</label></div><br/><div class="children"><div class="content">Or you can apply GPU optimizations for such ML workloads. By optimizing the way these models run on GPUs, significantly improve efficiency and slash costs by a factor of 10 or even more. These techniques include kernel fusion, memory access optimization, and efficient use of GPU resources, which can lead to substantial improvements in both training and inference speed. This allows AI models to run on more affordable hardware and still deliver exceptional performance. For example, LLMs running on A100 can also run on 3090s with no change in accuracy and comparable inference latency.</div><br/></div></div><div id="35821894" class="c"><input type="checkbox" id="c-35821894" checked=""/><div class="controls bullet"><span class="by">Certhas</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35824792">prev</a><span>|</span><a href="#35826227">next</a><span>|</span><label class="collapse" for="c-35821894">[-]</label><label class="expand" for="c-35821894">[2 more]</label></div><br/><div class="children"><div class="content">The article talks about this explicitly though. Reasonably good models are running on raspberry Pis now.</div><br/><div id="35823877" class="c"><input type="checkbox" id="c-35823877" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821894">parent</a><span>|</span><a href="#35826227">next</a><span>|</span><label class="collapse" for="c-35823877">[-]</label><label class="expand" for="c-35823877">[1 more]</label></div><br/><div class="children"><div class="content">Is a reasonably good model what people get value out of though?<p>Maybe this is why Sam Altman talked about &quot;the end of the large LLMs is here&quot;? He understands anything bigger than ChatGPT-4 isn&#x27;t viable to run at scale and be profitable?</div><br/></div></div></div></div><div id="35826227" class="c"><input type="checkbox" id="c-35826227" checked=""/><div class="controls bullet"><span class="by">hsbauauvhabzb</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35821894">prev</a><span>|</span><a href="#35822935">next</a><span>|</span><label class="collapse" for="c-35826227">[-]</label><label class="expand" for="c-35826227">[1 more]</label></div><br/><div class="children"><div class="content">Would google even care about integrating LLMs into search? They don’t even prune all the spam entries, presumably because they increase advertising revenue and analytics profit.</div><br/></div></div><div id="35822935" class="c"><input type="checkbox" id="c-35822935" checked=""/><div class="controls bullet"><span class="by">james-revisoai</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35826227">prev</a><span>|</span><a href="#35827024">next</a><span>|</span><label class="collapse" for="c-35822935">[-]</label><label class="expand" for="c-35822935">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right and this is why they didn&#x27;t heavily use BERT(in the full sense), arguably the game-changing NLP model of the 10s. They couldn&#x27;t justify bringing the cost per search up.</div><br/></div></div><div id="35827024" class="c"><input type="checkbox" id="c-35827024" checked=""/><div class="controls bullet"><span class="by">greenfield1</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35822935">prev</a><span>|</span><a href="#35822491">next</a><span>|</span><label class="collapse" for="c-35827024">[-]</label><label class="expand" for="c-35827024">[2 more]</label></div><br/><div class="children"><div class="content">The thing you have in your pocket would have meant an enormous investment for equivalent compute power just decades ago and filled a whole basement with server racks.</div><br/><div id="35828404" class="c"><input type="checkbox" id="c-35828404" checked=""/><div class="controls bullet"><span class="by">isp</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35827024">parent</a><span>|</span><a href="#35822491">next</a><span>|</span><label class="collapse" for="c-35828404">[-]</label><label class="expand" for="c-35828404">[1 more]</label></div><br/><div class="children"><div class="content">The legendary Cray-2 was the fastest supercomputer in the world in 1985, with peak 1.9 GFLOPS. Less than four decades ago.<p>By comparison, the Cray is outperformed by my smartphone.<p>Actually, it is outperformed by my <i>previous</i> smartphone, which I purchased in 2016 and replaced in 2018.<p>Actually, it is outperformed by a <i>single core</i> on my <i>previous</i> smartphone, of which it has eight cores.</div><br/></div></div></div></div><div id="35822491" class="c"><input type="checkbox" id="c-35822491" checked=""/><div class="controls bullet"><span class="by">ok123456</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35827024">prev</a><span>|</span><a href="#35833078">next</a><span>|</span><label class="collapse" for="c-35822491">[-]</label><label class="expand" for="c-35822491">[4 more]</label></div><br/><div class="children"><div class="content">Within a decade mid-level consumer cards will be just as powerful as those $40k cards.</div><br/><div id="35822580" class="c"><input type="checkbox" id="c-35822580" checked=""/><div class="controls bullet"><span class="by">bcrosby95</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822491">parent</a><span>|</span><a href="#35824591">next</a><span>|</span><label class="collapse" for="c-35822580">[-]</label><label class="expand" for="c-35822580">[1 more]</label></div><br/><div class="children"><div class="content">Considering how long it took mid level consumer cards to beat my $600 1080,  you&#x27;re way more optimistic than I am.</div><br/></div></div><div id="35824591" class="c"><input type="checkbox" id="c-35824591" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822491">parent</a><span>|</span><a href="#35822580">prev</a><span>|</span><a href="#35822574">next</a><span>|</span><label class="collapse" for="c-35824591">[-]</label><label class="expand" for="c-35824591">[1 more]</label></div><br/><div class="children"><div class="content">Given how nvidia has almost no competition, it just seems unlikely that nvidia decides to stop milking the enterprise and they will continue to lock 40GB+ cards behind ludicrous price points</div><br/></div></div></div></div><div id="35833078" class="c"><input type="checkbox" id="c-35833078" checked=""/><div class="controls bullet"><span class="by">lerchmo</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35822491">prev</a><span>|</span><a href="#35823778">next</a><span>|</span><label class="collapse" for="c-35833078">[-]</label><label class="expand" for="c-35833078">[1 more]</label></div><br/><div class="children"><div class="content">caching + simpler models for classification &#x2F; triage should reduce the load on the big model.</div><br/></div></div><div id="35823778" class="c"><input type="checkbox" id="c-35823778" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35833078">prev</a><span>|</span><a href="#35823417">next</a><span>|</span><label class="collapse" for="c-35823778">[-]</label><label class="expand" for="c-35823778">[1 more]</label></div><br/><div class="children"><div class="content">Or you can quantize the model and run it on your laptop.</div><br/></div></div><div id="35823417" class="c"><input type="checkbox" id="c-35823417" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35823778">prev</a><span>|</span><a href="#35824370">next</a><span>|</span><label class="collapse" for="c-35823417">[-]</label><label class="expand" for="c-35823417">[2 more]</label></div><br/><div class="children"><div class="content">nah, Lora quantized LLM’s are going to be at the OS level in 2 years and consumer architecture refreshes are just going to extend more RAM to already existing dedicated chips like Neural Engine<p>client side tokens per second will be through the roof and the models will be smaller</div><br/><div id="35823793" class="c"><input type="checkbox" id="c-35823793" checked=""/><div class="controls bullet"><span class="by">computerex</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823417">parent</a><span>|</span><a href="#35824370">next</a><span>|</span><label class="collapse" for="c-35823793">[-]</label><label class="expand" for="c-35823793">[1 more]</label></div><br/><div class="children"><div class="content">LoRa is not a quantization method, it&#x27;s a fine tuning method.</div><br/></div></div></div></div><div id="35824370" class="c"><input type="checkbox" id="c-35824370" checked=""/><div class="controls bullet"><span class="by">cush</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35823417">prev</a><span>|</span><a href="#35824069">next</a><span>|</span><label class="collapse" for="c-35824370">[-]</label><label class="expand" for="c-35824370">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, today.</div><br/></div></div><div id="35824069" class="c"><input type="checkbox" id="c-35824069" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35824370">prev</a><span>|</span><a href="#35822452">next</a><span>|</span><label class="collapse" for="c-35824069">[-]</label><label class="expand" for="c-35824069">[1 more]</label></div><br/><div class="children"><div class="content">Is the assumption that GPU power and advancements in AI will not get to a reasonable price point in the near future? Because it seems to me that advances in computation have not slowed down at all since it started.</div><br/></div></div><div id="35822452" class="c"><input type="checkbox" id="c-35822452" checked=""/><div class="controls bullet"><span class="by">unicornmama</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821671">parent</a><span>|</span><a href="#35824069">prev</a><span>|</span><a href="#35831676">next</a><span>|</span><label class="collapse" for="c-35822452">[-]</label><label class="expand" for="c-35822452">[1 more]</label></div><br/><div class="children"><div class="content">This cost argument is being overblown. While it&#x27;s a limitation for today&#x27;s product, enginners are very good at optimization. Therefore the costs will drop in the medium to long term from efforts on both the software and hardware side.</div><br/></div></div></div></div><div id="35822087" class="c"><input type="checkbox" id="c-35822087" checked=""/><div class="controls bullet"><span class="by">titzer</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35821671">prev</a><span>|</span><a href="#35825860">next</a><span>|</span><label class="collapse" for="c-35822087">[-]</label><label class="expand" for="c-35822087">[17 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s going to be seamlessly integrated into every-day software.<p>I...kinda don&#x27;t want this? UIs have already changed in so many different fits, starts, waves, and cycles. I used to have skills. But I have no skills now. Nothing works like it used to. Yeah they were tricky to use but I cannot imagine that a murky AI interface is going to be any easier to use, and certainly impossible to master.<p>Even if it <i>is</i> easier to use, I am not sure I want that either. I don&#x27;t know where the buttons are. I don&#x27;t know what I can do and what I can&#x27;t. And it won&#x27;t stay the same, dodging my feckless attempts to commit to memory how it works and get better at it...?</div><br/><div id="35824976" class="c"><input type="checkbox" id="c-35824976" checked=""/><div class="controls bullet"><span class="by">zztop44</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822087">parent</a><span>|</span><a href="#35822692">next</a><span>|</span><label class="collapse" for="c-35824976">[-]</label><label class="expand" for="c-35824976">[4 more]</label></div><br/><div class="children"><div class="content">I once volunteered with a older woman. She’d been a computer programmer in the 70s, using punch cards and, later, Pascal.<p>Then she had kids and stopped working for a while and the technology moved on without her. Now she’s like any other old person, doesn’t know how to use a computer and gets flustered when eg: trying to switch from the browser back to Word. Her kids and grandkids clown on her for being hopeless with computers.<p>I asked her what it was she found difficult about modern computers compared to what she worked with 50 years ago. She said it’s the multitasking. The computers she had worked with just did one thing at once.</div><br/><div id="35825526" class="c"><input type="checkbox" id="c-35825526" checked=""/><div class="controls bullet"><span class="by">yantrams</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824976">parent</a><span>|</span><a href="#35833931">next</a><span>|</span><label class="collapse" for="c-35825526">[-]</label><label class="expand" for="c-35825526">[1 more]</label></div><br/><div class="children"><div class="content">Interesting story. Thanks for sharing this. I have a somewhat similar story with my failure to transition from paltformers &#x2F; sidescrollers to 3D games. I just couldn&#x27;t do it.</div><br/></div></div><div id="35833931" class="c"><input type="checkbox" id="c-35833931" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824976">parent</a><span>|</span><a href="#35825526">prev</a><span>|</span><a href="#35834182">next</a><span>|</span><label class="collapse" for="c-35833931">[-]</label><label class="expand" for="c-35833931">[1 more]</label></div><br/><div class="children"><div class="content">I worked with somebody who developed MULTICS but struggled constantly to do even the most basic tasks on a Mac even after using Macs for a decade.  It was painful to watch them slowly move a mouse across the screen to the apple, take about ten seconds to click it, and then get confused about how to see system info.</div><br/></div></div><div id="35834182" class="c"><input type="checkbox" id="c-35834182" checked=""/><div class="controls bullet"><span class="by">titzer</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824976">parent</a><span>|</span><a href="#35833931">prev</a><span>|</span><a href="#35822692">next</a><span>|</span><label class="collapse" for="c-35834182">[-]</label><label class="expand" for="c-35834182">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. I like the fact that my stove has only the knobs and buttons on it (other than a 7-segment LED display). I am master of my stove because I am pretty sure I have explored the complete state space of it by now.</div><br/></div></div></div></div><div id="35822692" class="c"><input type="checkbox" id="c-35822692" checked=""/><div class="controls bullet"><span class="by">jjoonathan</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822087">parent</a><span>|</span><a href="#35824976">prev</a><span>|</span><a href="#35823817">next</a><span>|</span><label class="collapse" for="c-35822692">[-]</label><label class="expand" for="c-35822692">[5 more]</label></div><br/><div class="children"><div class="content">It was a sad day when I realized I was systematically overinvesting in skills on churning technology and that my investments would never amortize. Suddenly my parents&#x27; stubborn unwillingness to bother learning anything technological made complete sense and I had to adjust my own patience threshold sharply downwards.</div><br/><div id="35822886" class="c"><input type="checkbox" id="c-35822886" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822692">parent</a><span>|</span><a href="#35825625">next</a><span>|</span><label class="collapse" for="c-35822886">[-]</label><label class="expand" for="c-35822886">[1 more]</label></div><br/><div class="children"><div class="content">There are some software tools where the investment pays back, and has been over decades. Microsoft Office (in part because it&#x27;s not reinventing itself, but rather accrues new features; in part because everyone else copies its UI patterns). Photoshop. Emacs.<p>With modern software, I find it that there isn&#x27;t much to learn at all - in the past decade, seems to only be <i>removing</i> features and interaction modes, never adding anything new.<p>Still, I don&#x27;t regret having learned so much all those years ago. It gives me an idea what the software <i>could</i> do. What it was <i>supposed to</i> do. This means I often think of multi-step solutions for problems most people around me can&#x27;t solve unless there&#x27;s a dedicated SaaS for it. As frustrating as it often is to not be able to do something you could 10 years ago, sometimes I discover that some of the more advanced features still remain in modern toy-like software.</div><br/></div></div><div id="35825625" class="c"><input type="checkbox" id="c-35825625" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822692">parent</a><span>|</span><a href="#35822886">prev</a><span>|</span><a href="#35825606">next</a><span>|</span><label class="collapse" for="c-35825625">[-]</label><label class="expand" for="c-35825625">[1 more]</label></div><br/><div class="children"><div class="content">I find focusing on fundamental tools and concepts like terminals and text mode editors like vi and emacs will pay off handsomely.<p>All the fancy dialogs will switch around every few years.<p>This mindset extends to stuff like Word. Whenever you do something think hard about the essence of what you’re doing. Realize this should have been a script, but due to constraints in reality you are forced to use some wanky GUI.<p>If you look at it like this, you won’t care the pixels move around. Your mental model will be solid and building that is 90% of the work.</div><br/></div></div><div id="35825606" class="c"><input type="checkbox" id="c-35825606" checked=""/><div class="controls bullet"><span class="by">CapsAdmin</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822692">parent</a><span>|</span><a href="#35825625">prev</a><span>|</span><a href="#35829663">next</a><span>|</span><label class="collapse" for="c-35825606">[-]</label><label class="expand" for="c-35825606">[1 more]</label></div><br/><div class="children"><div class="content">Maybe my time will come some day (I&#x27;m 32 years old), but I always tell myself that learning how to learn and being interested in new&#x2F;different technology is how I keep myself updated. The latter is probably difficult to maintain, but this whole AI thing has given me a new pastime hobby I could never imagine.<p>Maybe I&#x27;ll reject instead of embrace the next big thing once I&#x27;m old enough?</div><br/></div></div><div id="35829663" class="c"><input type="checkbox" id="c-35829663" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822692">parent</a><span>|</span><a href="#35825606">prev</a><span>|</span><a href="#35823817">next</a><span>|</span><label class="collapse" for="c-35829663">[-]</label><label class="expand" for="c-35829663">[1 more]</label></div><br/><div class="children"><div class="content">i&#x27;m using a web browser broadly similar to mosaic (01994) on a site that works similarly to early reddit (02005).  in another window i&#x27;m running irssi (01999) to chat on irc (01988, but i&#x27;ve only been using it since 01994) inside screen (01987, but i&#x27;ve only been using it since 01994), to which i&#x27;m connected with ssh (01996) and mosh (02011, but i didn&#x27;t start using it until last month).  in my unix shell window (mate-terminal, but a thin wrapper around libvte (02002), mostly emulating a vt100 from 01978) i&#x27;m running a bourne shell (01979, but really it&#x27;s brian fox&#x27;s better reimplementation which he started in 01989) in which i just ran yt-dlp (which has to be updated every couple of months to keep working, but mostly has the same command-line flags as youtube-dl, first released in 02006) to download a video encoded in h.264 (02003) in an mpeg-4 container (01998), and then play it with mpv (02013, but forked from and sharing command-line flags with mplayer (02000)).  mpv displays the video with a gpu renderer (new) on a display server running x11 (01987).<p>in another browser tab i&#x27;m running jupyter (the renamed ipython notebook from 02011) to graph some dsp calculations with matplotlib (02003, but mostly providing the plotting functions from matlab (01984)) which i made with python (01991, but i&#x27;ve only been using it since 02000) and numpy (02006, but a mostly compatible reimplementation of numeric from 01995, which i&#x27;ve been using since 02003).  in jupyter i can format my equations in latex (01984, but for equations basically the same as plain tex82 from 01982, but i&#x27;ve only been using them since 01999) and my text in markdown (02004, though jupyter&#x27;s implementation supports many extensions).  i keep the jupyter notebook in git (02005, but i&#x27;ve only been using it since 02009, when i switched from cvs (01986, but i&#x27;ve only been using it since about 01998)).  the dsp stuff is largely applications of the convolution theorem (01822 or 01912) and hogenauer filters  (01981).<p>i do most of my programming that isn&#x27;t in jupyter in gnu emacs (01984, but i didn&#x27;t start using it until 01994) except that i prefer to do java stuff in intellij idea, which i first used in 02006<p>earlier this year, my wife and i wrote our wedding invitation rsvp site in html (01990, but using a lot of stuff added up to 02000) and css2 (01998) plus a few things like corner-radius (dunno, 02006?) and a little bit of js (01995, but in practical terms 02004), with the backend done in django (02005) backed by sqlite (02000, but this was sqlite3 (02004), but sqlite mostly just implements sql (01974, first publicly available in 01979, but mostly the 01992 ansi standard) which in turn mostly just implements codd&#x27;s relational data model (01970) and acid transactions (01983), all of which i&#x27;ve been using since 01996).  and of course python, emacs, and git.  most of the css debugging was done with chromium&#x27;s web inspector (present from the first chrome release in 02008, a clone of firebug (02006)).<p>for looking up these dates just now, i used google&#x27;s newish structured search results, which mostly pull information from wikipedia (02001); i also used stack overflow (02008) and its related sites.<p>the median of the years above is 01998, with 25% and 75% quartiles of 01987 and 02004, which i calculated using r (01997, but a reimplementation of s (01976)).  if we assume that each new introduction listed above displaced some existing skill, then we can vaguely handwave at a half-life of about 25 years for these churning technology skills, which to me seems like enough time for a lot of them to amortize; but it seems like it&#x27;s slowing down a lot, because the 25% quartile is in 01987 and not 01973<p>it&#x27;s true that all the time i spent configuring twm, olvwm, fvwm, and afterstep, and working around bugs in netscape 4&#x27;s javascript implementation, and maintaining csh scripts and informix ace database applications, and logging into anonymous ftp sites running tops-20, and debugging irq conflicts, isn&#x27;t really serving me today.  but you could kind of tell that those things weren&#x27;t the future.  the surprising thing is really how <i>slowly</i> things change: that we&#x27;re still running variants of the bourne shell in emulators of the vt100<p>other still-relevant technological skills for me today include building a fire, qwerty typing, ansi c (my wife is taking a class), bittorrent, operating a gas stove, and making instant coffee.  still beyond me, though, is how to turn this tv on</div><br/></div></div></div></div><div id="35823817" class="c"><input type="checkbox" id="c-35823817" checked=""/><div class="controls bullet"><span class="by">duderific</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822087">parent</a><span>|</span><a href="#35822692">prev</a><span>|</span><a href="#35822302">next</a><span>|</span><label class="collapse" for="c-35823817">[-]</label><label class="expand" for="c-35823817">[2 more]</label></div><br/><div class="children"><div class="content">If it is seamlessly integrated, the AI won&#x27;t even surface in a UI. You will just be presented with different options in the UI, which theoretically would be more precisely curated by the AI that you don&#x27;t even see.</div><br/><div id="35824565" class="c"><input type="checkbox" id="c-35824565" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823817">parent</a><span>|</span><a href="#35822302">next</a><span>|</span><label class="collapse" for="c-35824565">[-]</label><label class="expand" for="c-35824565">[1 more]</label></div><br/><div class="children"><div class="content">That runs counter to some very well established UI principles.  People get confused when their interface changes except as a result of direct interaction.  Open up a menu in response to a click, yes; reorganize menus to &quot;optimize&quot; them based on what a model predicts a person is going to do, no.<p>The killer is being able to tell a program what you want it to do, then not having to fuddle with buttons or menus at all (unless you want to tweak things).</div><br/></div></div></div></div><div id="35822302" class="c"><input type="checkbox" id="c-35822302" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822087">parent</a><span>|</span><a href="#35823817">prev</a><span>|</span><a href="#35823906">next</a><span>|</span><label class="collapse" for="c-35822302">[-]</label><label class="expand" for="c-35822302">[4 more]</label></div><br/><div class="children"><div class="content">An AI interface in Office brings back memories of Clippy.</div><br/><div id="35824645" class="c"><input type="checkbox" id="c-35824645" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822302">parent</a><span>|</span><a href="#35823648">next</a><span>|</span><label class="collapse" for="c-35824645">[-]</label><label class="expand" for="c-35824645">[1 more]</label></div><br/><div class="children"><div class="content">XR will solve the AI UI problem<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;jasminezroberts&#x2F;status&#x2F;1605611451674025989?t=d3aeSAHcY5CcRvQNlgo0mg&amp;s=19" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;jasminezroberts&#x2F;status&#x2F;16056114516740259...</a></div><br/></div></div><div id="35823648" class="c"><input type="checkbox" id="c-35823648" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822302">parent</a><span>|</span><a href="#35824645">prev</a><span>|</span><a href="#35823438">next</a><span>|</span><label class="collapse" for="c-35823648">[-]</label><label class="expand" for="c-35823648">[1 more]</label></div><br/><div class="children"><div class="content">Now imagine Clippy on a car touchscreen.</div><br/></div></div><div id="35823438" class="c"><input type="checkbox" id="c-35823438" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822302">parent</a><span>|</span><a href="#35823648">prev</a><span>|</span><a href="#35823906">next</a><span>|</span><label class="collapse" for="c-35823438">[-]</label><label class="expand" for="c-35823438">[1 more]</label></div><br/><div class="children"><div class="content">We may not have seen the last of Clippy yet… <a href="https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy" rel="nofollow">https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy</a></div><br/></div></div></div></div><div id="35823906" class="c"><input type="checkbox" id="c-35823906" checked=""/><div class="controls bullet"><span class="by">bombolo</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822087">parent</a><span>|</span><a href="#35822302">prev</a><span>|</span><a href="#35825860">next</a><span>|</span><label class="collapse" for="c-35823906">[-]</label><label class="expand" for="c-35823906">[1 more]</label></div><br/><div class="children"><div class="content">shell is the same</div><br/></div></div></div></div><div id="35825860" class="c"><input type="checkbox" id="c-35825860" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35822087">prev</a><span>|</span><a href="#35821696">next</a><span>|</span><label class="collapse" for="c-35825860">[-]</label><label class="expand" for="c-35825860">[3 more]</label></div><br/><div class="children"><div class="content">I think Satya Nadella put it pretty well in an interview: ad revenue, especially from search, is incremental to Microsoft; to Google, it&#x27;s everything. So while Microsoft is willing to have worse margins on search ads in order to win marketshare from Google, Google has to defend all of their margins — or else they become significantly less profitable in their core business. LLMs cost a lot more than traditional search, and Google can&#x27;t just drop-in replace its existing product lines with LLMs: that hikes their bottom line, literally. Microsoft is willing to swap out the existing Bing with the &quot;new Bing&quot; based on OpenAI&#x27;s technology, because they make very little money comparatively on search, and winning marketshare will more than make up for having smaller margins on that marketshare. Google is, IMO, in between a rock and a hard place on this one: either they dramatically increase their cost of revenue to defend marketshare, or they risk losing marketshare to Microsoft in their core business.<p>Meanwhile, OpenAI gets paid by MS. Not that MS minds! They own a 49% stake in OpenAI, so what&#x27;s good for OpenAI is what&#x27;s good for MS.<p>If Google had decades to figure it out, I think your analysis might be right — although I&#x27;m not certain that it is, since I&#x27;m not certain that the calculus of &quot;free product, for ad revenue&quot; makes as much sense when the products are much more expensive to run than they were previously. But even if it&#x27;s correct in the  long run, if Google starts slipping now it turns into a death spiral: their share prices slip, meaning the cost of compensation for key employees goes up, meaning they lose critical people (or cut even further into their bottom line, hurting their shares more, until they&#x27;re forced to make staffing cuts), and they fall even further behind. Just as Google once ate Yahoo! via PageRank, it could get eaten by a disruptive technology like LLMs in the future.</div><br/><div id="35830515" class="c"><input type="checkbox" id="c-35830515" checked=""/><div class="controls bullet"><span class="by">DannyBee</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35825860">parent</a><span>|</span><a href="#35821696">next</a><span>|</span><label class="collapse" for="c-35830515">[-]</label><label class="expand" for="c-35830515">[2 more]</label></div><br/><div class="children"><div class="content">&quot;OpenAI gets paid by MS&quot;<p>Actually, MS gets paid by OpenAI at 70% of profits until they make back their investment (according to articles on the terms)</div><br/><div id="35833968" class="c"><input type="checkbox" id="c-35833968" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35830515">parent</a><span>|</span><a href="#35821696">next</a><span>|</span><label class="collapse" for="c-35833968">[-]</label><label class="expand" for="c-35833968">[1 more]</label></div><br/><div class="children"><div class="content">Note that MS cost-offsets much OpenAI infrastructure including their top-5 TOP500 class supercomputer (similar to a full TPUv4 pod)</div><br/></div></div></div></div></div></div><div id="35821696" class="c"><input type="checkbox" id="c-35821696" checked=""/><div class="controls bullet"><span class="by">kelipso</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35825860">prev</a><span>|</span><a href="#35838785">next</a><span>|</span><label class="collapse" for="c-35821696">[-]</label><label class="expand" for="c-35821696">[7 more]</label></div><br/><div class="children"><div class="content">To be fair, the open source model has been what&#x27;s been working for the last few decades. The concern with LLMs was that open source (and academia) couldn&#x27;t do what the big companies are doing because they couldn&#x27;t get access to enough computing resources. The article is arguing (and I guess open source ML groups are showing) you don&#x27;t need those computing resources to pave the way. It&#x27;s still an open question whether OpenAI or the other big companies can find a most in AI via either some model, dataset, computing resources, whatever. But then you could ask that question about any field.</div><br/><div id="35822036" class="c"><input type="checkbox" id="c-35822036" checked=""/><div class="controls bullet"><span class="by">not2b</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821696">parent</a><span>|</span><a href="#35821838">next</a><span>|</span><label class="collapse" for="c-35822036">[-]</label><label class="expand" for="c-35822036">[5 more]</label></div><br/><div class="children"><div class="content">But none of the &quot;open source&quot; AI models are open source in the classic sense. They are free but they aren&#x27;t the source code; they are closer to a freely distributable compiled binary where the compiler and the original input hasn&#x27;t been released. A true open source AI model would need to specify the training data and the code to go from the training data to the model. Certainly it would be very expensive for someone else to take this information, build the model again, and verify that the same result is obtained, and maybe we don&#x27;t really need that. But if we don&#x27;t have it, then I think we need some other term than &quot;open source&quot; to describe these things. You can get it, you can share it, but you don&#x27;t know what&#x27;s in it.</div><br/><div id="35822257" class="c"><input type="checkbox" id="c-35822257" checked=""/><div class="controls bullet"><span class="by">kbrkbr</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822036">parent</a><span>|</span><a href="#35823298">next</a><span>|</span><label class="collapse" for="c-35822257">[-]</label><label class="expand" for="c-35822257">[1 more]</label></div><br/><div class="children"><div class="content">RWKV does: <a href="https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;RWKV-LM">https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;RWKV-LM</a>
It uses „the Pile“: <a href="https:&#x2F;&#x2F;pile.eleuther.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pile.eleuther.ai&#x2F;</a>
And I’ve seen some more in the last weeks.</div><br/></div></div><div id="35823298" class="c"><input type="checkbox" id="c-35823298" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822036">parent</a><span>|</span><a href="#35822257">prev</a><span>|</span><a href="#35822959">next</a><span>|</span><label class="collapse" for="c-35823298">[-]</label><label class="expand" for="c-35823298">[1 more]</label></div><br/><div class="children"><div class="content">Keep an eye on the RedPajama project for a model where the training data and code should both be freely available: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;redpajama&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;redpajama&#x2F;</a></div><br/></div></div><div id="35822959" class="c"><input type="checkbox" id="c-35822959" checked=""/><div class="controls bullet"><span class="by">kelipso</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822036">parent</a><span>|</span><a href="#35823298">prev</a><span>|</span><a href="#35823441">next</a><span>|</span><label class="collapse" for="c-35822959">[-]</label><label class="expand" for="c-35822959">[1 more]</label></div><br/><div class="children"><div class="content">I agree with you to the extent that yeah technically it&#x27;s not open source because the data is not known. But for these foundation models like Llama, the model structure is obviously known, pretty sure (didn&#x27;t check) the hyperparameters used to train the model is known, the remaining unknown of data, it&#x27;s pretty much the same for all foundation models, CommonCrawl etc. So replicating Llama once you know all that is a mechanical step and so isn&#x27;t really closed source in a sense. Though probably some new term open something is more appropriate.<p>The real sauce is the data you fine tune these foundation models on, so RLHF, specific proprietary data for your subfield, etc. The model definition, basically Transformer architecture and a bunch of tricks to get it to scale are mostly all published material, hyper parameters to train the model are less accessible but also part of published literature; then the data and (probably) niche field you apply it to becomes the key. Gonna be fun times!</div><br/></div></div><div id="35823441" class="c"><input type="checkbox" id="c-35823441" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822036">parent</a><span>|</span><a href="#35822959">prev</a><span>|</span><a href="#35821838">next</a><span>|</span><label class="collapse" for="c-35823441">[-]</label><label class="expand" for="c-35823441">[1 more]</label></div><br/><div class="children"><div class="content">These &quot;open source&quot; ai models are more like Obtainable models. You can obtain them. The source is not open, hence open-source. Somewhere open-source got lumped in with free or accessible. Obtainable makes sense to me.</div><br/></div></div></div></div><div id="35821838" class="c"><input type="checkbox" id="c-35821838" checked=""/><div class="controls bullet"><span class="by">dahwolf</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821696">parent</a><span>|</span><a href="#35822036">prev</a><span>|</span><a href="#35838785">next</a><span>|</span><label class="collapse" for="c-35821838">[-]</label><label class="expand" for="c-35821838">[1 more]</label></div><br/><div class="children"><div class="content">That makes sense. But I would argue to smaller&#x2F;cheaper models are not a threat to Google, they are a solution. They will still have the reach advantage and can more cheaply integrate small&#x2F;low costs models at every touch point.</div><br/></div></div></div></div><div id="35838785" class="c"><input type="checkbox" id="c-35838785" checked=""/><div class="controls bullet"><span class="by">ArthurAardvark</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35821696">prev</a><span>|</span><a href="#35822171">next</a><span>|</span><label class="collapse" for="c-35838785">[-]</label><label class="expand" for="c-35838785">[1 more]</label></div><br/><div class="children"><div class="content">Stupid, silly me who knows little-to-nothing about the lore of OS. Why can&#x27;t OS devs simply write out in the OS licensing that their wonderful work is usable by anyone and everybody unless you belong to Alphabet&#x2F;Meta&#x2F;Oracle&#x2F;Adobe&#x2F;Twitter&#x2F;Microsoftpen– McCorps &amp; their subsidiaries?<p>I imagine it comes down to ol&#x27; Googly &amp; the boys taking advantage of the OS work -&gt; OS devs backed by weak NFOs sue X corp. -&gt; X corp. manages to delay the courts and carries on litigation so the bill is astronomical aka ain&#x27;t nobody footing that -&gt; ???<p>I imagine 90% end up taking some sort of $ and handover the goods like Chromium, though.<p>So back to square one, guess we kowtow and pray for us prey?</div><br/></div></div><div id="35822171" class="c"><input type="checkbox" id="c-35822171" checked=""/><div class="controls bullet"><span class="by">aero-deck</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35838785">prev</a><span>|</span><a href="#35821899">next</a><span>|</span><label class="collapse" for="c-35822171">[-]</label><label class="expand" for="c-35822171">[4 more]</label></div><br/><div class="children"><div class="content">Disagree. What you have in mind is already how the masses interact AI. There is little value-add for making machine translation, auto-correct and video recommendations better.<p>I can think of a myriad of use-cases for AI that involve custom-tuning foundation models to user-specific environments. Think of an app that can detect bad dog behavior, or an app that gives you pointers on your golf swing. The moat for AI is going to be around building user-friendly tools for fine-tuning models to domain-specific applications, and getting users to spend enough time fine-tuning those tools to where the switch-cost to another tool becomes too high.<p>When google complains that there is no moat, they&#x27;re complaining that there is no moat big enough to sustain companies as large as Google.</div><br/><div id="35823814" class="c"><input type="checkbox" id="c-35823814" checked=""/><div class="controls bullet"><span class="by">computerex</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822171">parent</a><span>|</span><a href="#35823460">next</a><span>|</span><label class="collapse" for="c-35823814">[-]</label><label class="expand" for="c-35823814">[2 more]</label></div><br/><div class="children"><div class="content">Fine tuning isn&#x27;t a thing for foundational models though, it&#x27;s all about in context learning.</div><br/><div id="35829993" class="c"><input type="checkbox" id="c-35829993" checked=""/><div class="controls bullet"><span class="by">aero-deck</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823814">parent</a><span>|</span><a href="#35823460">next</a><span>|</span><label class="collapse" for="c-35829993">[-]</label><label class="expand" for="c-35829993">[1 more]</label></div><br/><div class="children"><div class="content">that means there&#x27;s no money in making foundation models - the economics are broken.</div><br/></div></div></div></div><div id="35823460" class="c"><input type="checkbox" id="c-35823460" checked=""/><div class="controls bullet"><span class="by">jimsimmons</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822171">parent</a><span>|</span><a href="#35823814">prev</a><span>|</span><a href="#35821899">next</a><span>|</span><label class="collapse" for="c-35823460">[-]</label><label class="expand" for="c-35823460">[1 more]</label></div><br/><div class="children"><div class="content">Making video recs better translates to direct $$$<p>There’s a reason YT or TikTok recommendation is so revered</div><br/></div></div></div></div><div id="35821899" class="c"><input type="checkbox" id="c-35821899" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35822171">prev</a><span>|</span><a href="#35823231">next</a><span>|</span><label class="collapse" for="c-35821899">[-]</label><label class="expand" for="c-35821899">[9 more]</label></div><br/><div class="children"><div class="content">Honestly, I can&#x27;t see Google failing here. Like other tech giants, they&#x27;re sitting on a ridiculously large war chest. Worst case, they can wait for the space to settle a bit and spend a few billion to buy the market leader. If AI really is an existential threat to their business prospects, spending their reserves on this is a no-brainer.</div><br/><div id="35823642" class="c"><input type="checkbox" id="c-35823642" checked=""/><div class="controls bullet"><span class="by">jldugger</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821899">parent</a><span>|</span><a href="#35822140">next</a><span>|</span><label class="collapse" for="c-35823642">[-]</label><label class="expand" for="c-35823642">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Honestly, I can&#x27;t see Google failing here. Like other tech giants, they&#x27;re sitting on a ridiculously large war chest. Worst case, they can wait for the space to settle a bit and spend a few billion to buy the market leader.<p>It seems incredibly likely that the FTC will block that. New leadership seems to be of the opinion that consumer harm is the wrong standard. Buying the competition with profits from a search monopoly leaves all parties impoverished.<p>Anyways, I don&#x27;t think the risk is failure, but of non-success. The article claims meta won but it seems like nvidia is the winner: everyone uses their chipsets for training, fine tuning and inference. And the more entrants and niche applications show up the more demand there is for their product. TPUs theoretically play into this, but the &quot;leak&quot; doesn&#x27;t mention them at all.</div><br/><div id="35824361" class="c"><input type="checkbox" id="c-35824361" checked=""/><div class="controls bullet"><span class="by">yellowapple</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823642">parent</a><span>|</span><a href="#35822140">next</a><span>|</span><label class="collapse" for="c-35824361">[-]</label><label class="expand" for="c-35824361">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The article claims meta won but it seems like nvidia is the winner: everyone uses their chipsets for training, fine tuning and inference. And the more entrants and niche applications show up the more demand there is for their product.<p>Like the saying goes: during a gold rush, sell shovels.</div><br/></div></div></div></div><div id="35822140" class="c"><input type="checkbox" id="c-35822140" checked=""/><div class="controls bullet"><span class="by">blowski</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821899">parent</a><span>|</span><a href="#35823642">prev</a><span>|</span><a href="#35824597">next</a><span>|</span><label class="collapse" for="c-35822140">[-]</label><label class="expand" for="c-35822140">[2 more]</label></div><br/><div class="children"><div class="content">That was true for IBM in the 1970s and Microsoft in the 90s. Despite holding a royal flush, they managed to lose the game through a combination of arrogance, internal fighting, innovator&#x27;s dilemma, concern over anti-trust, and bureaucratic inertia. It will be hard for Google to pull this off.</div><br/><div id="35823041" class="c"><input type="checkbox" id="c-35823041" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822140">parent</a><span>|</span><a href="#35824597">next</a><span>|</span><label class="collapse" for="c-35823041">[-]</label><label class="expand" for="c-35823041">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft aint doing so bad now</div><br/></div></div></div></div><div id="35824597" class="c"><input type="checkbox" id="c-35824597" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821899">parent</a><span>|</span><a href="#35822140">prev</a><span>|</span><a href="#35823466">next</a><span>|</span><label class="collapse" for="c-35824597">[-]</label><label class="expand" for="c-35824597">[2 more]</label></div><br/><div class="children"><div class="content">They won&#x27;t fail, they&#x27;ll just provide compute infrastructure for people building AI products.  Google is mostly bad at building products these days.</div><br/><div id="35828300" class="c"><input type="checkbox" id="c-35828300" checked=""/><div class="controls bullet"><span class="by">acdha</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824597">parent</a><span>|</span><a href="#35823466">next</a><span>|</span><label class="collapse" for="c-35828300">[-]</label><label class="expand" for="c-35828300">[1 more]</label></div><br/><div class="children"><div class="content">GCP is a product, too, but it’s not as good as either of the top two, that’s a low margin market, and a key theme in this article is that people have made model tuning less expensive.<p>There’s no path forward for Google which doesn’t involve firing a lot of managers and replacing them with people who think their income depends on being a lot better at building and especially maintaining products.</div><br/></div></div></div></div><div id="35823466" class="c"><input type="checkbox" id="c-35823466" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821899">parent</a><span>|</span><a href="#35824597">prev</a><span>|</span><a href="#35823231">next</a><span>|</span><label class="collapse" for="c-35823466">[-]</label><label class="expand" for="c-35823466">[2 more]</label></div><br/><div class="children"><div class="content">The threat isn’t that another company has AI, it’s that they don’t (yet) have a good way to sell ads with a chat bot. Buying the chat bot doesn’t change that.</div><br/><div id="35823783" class="c"><input type="checkbox" id="c-35823783" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35823466">parent</a><span>|</span><a href="#35823231">next</a><span>|</span><label class="collapse" for="c-35823783">[-]</label><label class="expand" for="c-35823783">[1 more]</label></div><br/><div class="children"><div class="content">What I mean is, if they can&#x27;t figure out the ad angle and end up facing an existential threat, they have enough money to just drop their existing ad business almost entirely, and buy out the leading AI company to integrate as a replacement business model. It would be bloody (in the business sense, at least), but Google would likely survive such drastic move.</div><br/></div></div></div></div></div></div><div id="35823231" class="c"><input type="checkbox" id="c-35823231" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35821899">prev</a><span>|</span><a href="#35822582">next</a><span>|</span><label class="collapse" for="c-35823231">[-]</label><label class="expand" for="c-35823231">[1 more]</label></div><br/><div class="children"><div class="content">I think this won&#x27;t work out: AI is so popular now because it&#x27;s a destination. It&#x27;s been rebranded as a cool thing to play with, that anyone can immediately see the potential in. That all collapses when it&#x27;s integrated into Word or other &quot;productivity&quot; tools and it just becomes another annoying feature that gives you some irrelevant suggestions.<p>OpenAI has no moat, but at least they have first mover advantage on a cool product, and may be able to get some chumps (microsoft) to think this will translate into a lasting feature inside of office or bing.</div><br/></div></div><div id="35822582" class="c"><input type="checkbox" id="c-35822582" checked=""/><div class="controls bullet"><span class="by">irrational</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35823231">prev</a><span>|</span><a href="#35824374">next</a><span>|</span><label class="collapse" for="c-35822582">[-]</label><label class="expand" for="c-35822582">[7 more]</label></div><br/><div class="children"><div class="content">It being everywhere worries me a lot. It outputs a lot of false information and the typical person doesn’t have the time or inclination to vet the output. Maybe this is a problem that will be solved. I’m not optimistic on that front.</div><br/><div id="35822671" class="c"><input type="checkbox" id="c-35822671" checked=""/><div class="controls bullet"><span class="by">mattferderer</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822582">parent</a><span>|</span><a href="#35823524">next</a><span>|</span><label class="collapse" for="c-35822671">[-]</label><label class="expand" for="c-35822671">[5 more]</label></div><br/><div class="children"><div class="content">Same can be said about the results that pop up on your favorite search engine or asking other people questions.<p>If anything advances in AI &amp; search tech will do a better job at providing citations that agree &amp; disagree with the results given. But this can be a turtles all the way down problem.</div><br/><div id="35828272" class="c"><input type="checkbox" id="c-35828272" checked=""/><div class="controls bullet"><span class="by">acdha</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822671">parent</a><span>|</span><a href="#35826713">next</a><span>|</span><label class="collapse" for="c-35828272">[-]</label><label class="expand" for="c-35828272">[1 more]</label></div><br/><div class="children"><div class="content">There’s a real difference in scale and perceived authority: false search results already cause problems but many people have also been learning not to blindly trust the first hit and to check things like the site hosting it.<p>That’s not perfect but I think it’s a lot better than building things into Word will be. There’s almost no chance that people won’t trust suggestions there more than random web searches and the quality of the writing will make people more inclined to think it’s authoritative.<p>Consider what happened earlier this year when professor Tyler Cowen wrote an entire blog post on a fake citation. He certainly knows better but it’s so convenient to use the LLM emission rather than do more research…<p><a href="https:&#x2F;&#x2F;www.thenation.com&#x2F;article&#x2F;culture&#x2F;internet-archive-publishers-lawsuit-chatbot&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.thenation.com&#x2F;article&#x2F;culture&#x2F;internet-archive-p...</a></div><br/></div></div><div id="35826713" class="c"><input type="checkbox" id="c-35826713" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822671">parent</a><span>|</span><a href="#35828272">prev</a><span>|</span><a href="#35835281">next</a><span>|</span><label class="collapse" for="c-35826713">[-]</label><label class="expand" for="c-35826713">[1 more]</label></div><br/><div class="children"><div class="content">No it won&#x27;t and random search popup results are already a massive societal problem (and they&#x27;re not even used like people are attempting to use AI - to make decisions over other peoples lives in insurance, banking, law enforcement and other areas where abuse is common when unchecked).</div><br/></div></div><div id="35835281" class="c"><input type="checkbox" id="c-35835281" checked=""/><div class="controls bullet"><span class="by">jabradoodle</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822671">parent</a><span>|</span><a href="#35826713">prev</a><span>|</span><a href="#35823506">next</a><span>|</span><label class="collapse" for="c-35835281">[-]</label><label class="expand" for="c-35835281">[1 more]</label></div><br/><div class="children"><div class="content">Low quality blogs etc stand out as low quality, LLMs can eloquently state truths with convincing sounding nonsense sprinkled through out. It&#x27;s a different problem and many people already take low quality propaganda at face value.</div><br/></div></div></div></div><div id="35823524" class="c"><input type="checkbox" id="c-35823524" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822582">parent</a><span>|</span><a href="#35822671">prev</a><span>|</span><a href="#35824374">next</a><span>|</span><label class="collapse" for="c-35823524">[-]</label><label class="expand" for="c-35823524">[1 more]</label></div><br/><div class="children"><div class="content">I think this is a failure in how we fine-tuned and evaluated them in RLHF.<p>&quot;In theory, the human labeler can include all the context they know with each prompt to teach the model to use only the existing knowledge. However, this is impossible in practice.&quot; [1] Therefore causing and forcing some connections that are not all there for the LLM. Extrapolate that across various subjects and types of queries and there you go.<p>1:<a href="https:&#x2F;&#x2F;huyenchip.com&#x2F;2023&#x2F;05&#x2F;02&#x2F;rlhf.html" rel="nofollow">https:&#x2F;&#x2F;huyenchip.com&#x2F;2023&#x2F;05&#x2F;02&#x2F;rlhf.html</a></div><br/></div></div></div></div><div id="35824374" class="c"><input type="checkbox" id="c-35824374" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35822582">prev</a><span>|</span><a href="#35823645">next</a><span>|</span><label class="collapse" for="c-35824374">[-]</label><label class="expand" for="c-35824374">[4 more]</label></div><br/><div class="children"><div class="content">&gt; This so-called &quot;competition&quot; from open source is going to be free labor. Any winning idea ported into Google&#x27;s products on short notice. Thanks open source!<p>How else, exactly, is open source supposed to work? Nobody wants to make their code GPL but everybody complains when companies use their code. I get that open source projects will like companies to contribute back, but shouldn&#x27;t that go for everyone using this code? Like, I don&#x27;t get what the proposed way of working is here.</div><br/><div id="35824450" class="c"><input type="checkbox" id="c-35824450" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824374">parent</a><span>|</span><a href="#35823645">next</a><span>|</span><label class="collapse" for="c-35824450">[-]</label><label class="expand" for="c-35824450">[3 more]</label></div><br/><div class="children"><div class="content">Developers nowadays want to have their cake and eat it too. They want to develop FOSS code because capitalism is evil and proprietary software is immoral and Micro$oft is the <i>devil, man</i>, and so give their work away for free... but whenever a company makes money on it and gives nothing back, completely in line with the letter <i>and spirit</i> of FOSS (because requiring compensation would violate user freedom,) they also want to get paid.<p>Like the entire premise of FOSS is that money doesn&#x27;t matter, only freedom matters. You&#x27;re not supposed to <i>care</i> that Google made a billion dollars off your library as long as they keep it open.</div><br/><div id="35838227" class="c"><input type="checkbox" id="c-35838227" checked=""/><div class="controls bullet"><span class="by">melagonster</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824450">parent</a><span>|</span><a href="#35824781">next</a><span>|</span><label class="collapse" for="c-35838227">[-]</label><label class="expand" for="c-35838227">[1 more]</label></div><br/><div class="children"><div class="content">free as freedom, but not free as beer?</div><br/></div></div><div id="35824781" class="c"><input type="checkbox" id="c-35824781" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824450">parent</a><span>|</span><a href="#35838227">prev</a><span>|</span><a href="#35823645">next</a><span>|</span><label class="collapse" for="c-35824781">[-]</label><label class="expand" for="c-35824781">[1 more]</label></div><br/><div class="children"><div class="content">I see this as part of the decline of hacker culture and rise of brogrammers. I see very few people programming for fun, everyone seems to be looking for a monetization opportunity for every breath they take.</div><br/></div></div></div></div></div></div><div id="35823645" class="c"><input type="checkbox" id="c-35823645" checked=""/><div class="controls bullet"><span class="by">bburnett44</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35824374">prev</a><span>|</span><a href="#35822285">next</a><span>|</span><label class="collapse" for="c-35823645">[-]</label><label class="expand" for="c-35823645">[1 more]</label></div><br/><div class="children"><div class="content">The problem is that the llms are better at search (for an open ended question) than Google is and that’s where most of googles revenue comes from. So it actually gives a new company like openai the opportunity to change consumers destinations from google</div><br/></div></div><div id="35822285" class="c"><input type="checkbox" id="c-35822285" checked=""/><div class="controls bullet"><span class="by">bhl</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35823645">prev</a><span>|</span><a href="#35836021">next</a><span>|</span><label class="collapse" for="c-35822285">[-]</label><label class="expand" for="c-35822285">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s going to be seamlessly integrated into every-day software. In Office&#x2F;Google docs, at the operating system level (Android), in your graphics editor (Adobe), on major web platforms: search, image search, Youtube, the like<p>Agreed but I don’t think the products that’ll gain market share from this wave of AI will be legacy web 2 apps; rather it’ll be AI-native or first apps that are build from ground up to collect user data and fulfill user intent. Prime example is TikTok.</div><br/><div id="35823607" class="c"><input type="checkbox" id="c-35823607" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822285">parent</a><span>|</span><a href="#35836021">next</a><span>|</span><label class="collapse" for="c-35823607">[-]</label><label class="expand" for="c-35823607">[1 more]</label></div><br/><div class="children"><div class="content">You bottled up exactly my disappointment with some large companies&#x27; legacy AI offerings. They don&#x27;t do both: iterate off of telemetry data and fulfill user&#x27;s needs.</div><br/></div></div></div></div><div id="35836021" class="c"><input type="checkbox" id="c-35836021" checked=""/><div class="controls bullet"><span class="by">scyzoryk_xyz</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35822285">prev</a><span>|</span><a href="#35822062">next</a><span>|</span><label class="collapse" for="c-35836021">[-]</label><label class="expand" for="c-35836021">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is more of a lab than a company though, no?<p>Aren’t they, in some sense, kind of like that lab division that invented the computer mouse? Or for that matter, any other laboratory that made significant breakthroughs but left the commercialization to others?<p>It would make sense to me what you’re describing. Only, we will probably be laughing from the future the extent of our current imagination with this stuff is still limited to GUI’s, excels and docs.</div><br/></div></div><div id="35822062" class="c"><input type="checkbox" id="c-35822062" checked=""/><div class="controls bullet"><span class="by">vosper</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35836021">prev</a><span>|</span><a href="#35821702">next</a><span>|</span><label class="collapse" for="c-35822062">[-]</label><label class="expand" for="c-35822062">[3 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI faces the existential risk, not Google.<p>Yes, but the quickest way for anyone to get themselves to state-of-the-art is to buy OpenAI. Their existential risk is whether they continue to be (semi)independent, not whether they shutdown or not. Presumably Microsoft is the obvious acquirer, but there must be a bunch of others who could also be in the running.</div><br/><div id="35822164" class="c"><input type="checkbox" id="c-35822164" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822062">parent</a><span>|</span><a href="#35821702">next</a><span>|</span><label class="collapse" for="c-35822164">[-]</label><label class="expand" for="c-35822164">[2 more]</label></div><br/><div class="children"><div class="content">But if you wait a month you can get that model for free...</div><br/><div id="35823327" class="c"><input type="checkbox" id="c-35823327" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35822164">parent</a><span>|</span><a href="#35821702">next</a><span>|</span><label class="collapse" for="c-35823327">[-]</label><label class="expand" for="c-35823327">[1 more]</label></div><br/><div class="children"><div class="content">Where?</div><br/></div></div></div></div></div></div><div id="35821702" class="c"><input type="checkbox" id="c-35821702" checked=""/><div class="controls bullet"><span class="by">4ndrewl</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35822062">prev</a><span>|</span><a href="#35824051">next</a><span>|</span><label class="collapse" for="c-35821702">[-]</label><label class="expand" for="c-35821702">[2 more]</label></div><br/><div class="children"><div class="content">This is 100% correct - products evolve to become features. Not sure OpenAI faces the existential risk as MS need them to compete with Google in this space.</div><br/><div id="35821781" class="c"><input type="checkbox" id="c-35821781" checked=""/><div class="controls bullet"><span class="by">chabons</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35821702">parent</a><span>|</span><a href="#35824051">next</a><span>|</span><label class="collapse" for="c-35821781">[-]</label><label class="expand" for="c-35821781">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Not sure OpenAI faces the existential risk as MS need them to compete with Google in this space.<p>I think OP is arguing that in that partnership Microsoft holds the power, as they have the existing platforms. The linked article argues that AI technology itself is not as much of a moat as previously thought, and the argument therefore is that Microsoft likely doesn&#x27;t need OpenAI in the long term.</div><br/></div></div></div></div><div id="35824051" class="c"><input type="checkbox" id="c-35824051" checked=""/><div class="controls bullet"><span class="by">1vuio0pswjnm7</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35821702">prev</a><span>|</span><a href="#35827037">next</a><span>|</span><label class="collapse" for="c-35824051">[-]</label><label class="expand" for="c-35824051">[5 more]</label></div><br/><div class="children"><div class="content">&quot;Any winning idea ported into Google&#x27;s products on short notice.&quot;<p>Imagine for a moment, in a different universe, in a different galaxy, another planet is ostensibly a mirror image of Earth, evolving along the same trajectory.  However on this hypothetical planet, <i>anything is possible</i>.  This has resulted in some interesting differences.<p>The No Google License<p>Neither Google, its subsidiaries, business partners nor its academic collaborators may use this software.  Under no circumstance may this software be directly or indirectly used to further Google&#x27;s business or other objectives.<p>If 100s or 1000s or more people on planet X started adopting this license for their open source projects, then of course it won&#x27;t stop Google from copying them or even using the code as is.  But it would muddy the waters with 100s or 1000s or more potential lawsuits.  Why would any company risk it.<p>There is nothing stopping anyone writing software for which they have no intention of charging license fees.  It&#x27;s done all the time these days.  There is also nothing stopping anyone from prohibiting certain companies from using it, or prohibiting certain uses.<p>I recall in the early days of the web when &quot;shareware&quot; licenses often tried to distinguish commercial from non-commercial use.  Commercial use would presumably incur higher fees.  Non-commercial use was either free or low cost.  I always wondered, &quot;How is the author going to discover if XYZ, LLC is using his software?&quot;  (This is before telemetry was common.) The license seemed unworkable, but that did not stop me from using the software.  I was never afraid that I would be mistaken for a commercial user and the author would come knocking asking me to agree to a commercial license.  I doubt I was the only one bold enough to use software with licenses prohibiting commercial use.<p>Even a &quot;No Microsoft License&quot; would make Github more interesting.  One could pick some random usage.  Microsoft may not this software for X.  Would this make MSFT&#x27;s plans more complicated.  Try it and see what happens.  Only way to know for sure.<p>Instead, MSFT is currently trying to out the plaintiffs in the Doe v Github case, over MSFT&#x27;s usage of other peoples&#x27; code who put their stuff on Github, and as the Court gets ready to decide the issue, it&#x27;s becoming clear IMO that if these individual are named, these brave individuals will lose their jobs and be blackballed from ever working in software again.<p>The No Internet Advertising License<p>This software may not be used to create or support internet advertising services for commercial gain.</div><br/><div id="35824744" class="c"><input type="checkbox" id="c-35824744" checked=""/><div class="controls bullet"><span class="by">kistaro</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824051">parent</a><span>|</span><a href="#35836558">next</a><span>|</span><label class="collapse" for="c-35824744">[-]</label><label class="expand" for="c-35824744">[1 more]</label></div><br/><div class="children"><div class="content">The No Google License functionally exists: it&#x27;s the AGPL. <a href="https:&#x2F;&#x2F;opensource.google&#x2F;documentation&#x2F;reference&#x2F;using&#x2F;agpl-policy" rel="nofollow">https:&#x2F;&#x2F;opensource.google&#x2F;documentation&#x2F;reference&#x2F;using&#x2F;agpl...</a></div><br/></div></div><div id="35836558" class="c"><input type="checkbox" id="c-35836558" checked=""/><div class="controls bullet"><span class="by">1vuio0pswjnm7</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824051">parent</a><span>|</span><a href="#35824744">prev</a><span>|</span><a href="#35824582">next</a><span>|</span><label class="collapse" for="c-35836558">[-]</label><label class="expand" for="c-35836558">[1 more]</label></div><br/><div class="children"><div class="content">Neither Alphabet, Google nor their successors, subsidiaries, affiliates, business partners, academic collaborators or parent companies may use this software; all of the foregoing are specifically prohibited from any use of this software.</div><br/></div></div><div id="35824582" class="c"><input type="checkbox" id="c-35824582" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824051">parent</a><span>|</span><a href="#35836558">prev</a><span>|</span><a href="#35834477">next</a><span>|</span><label class="collapse" for="c-35824582">[-]</label><label class="expand" for="c-35824582">[1 more]</label></div><br/><div class="children"><div class="content">The license that prevents use by a particular list of corporations can likely be easily crafted.<p>But because any particular invention about LLMs is not a specific product but an approach, it would just be re-implemented.<p>One could imagine <i>patenting</i> an approach, if it ends up being patentable, and then giving everyone but some excluded entities a grant of royalty-free use. But, unless the use if that particular approach is inevitably very obvious (which is really unlikely with ML models), you would have hard time detecting violations and especially enforcing your patent.</div><br/></div></div><div id="35834477" class="c"><input type="checkbox" id="c-35834477" checked=""/><div class="controls bullet"><span class="by">codethief</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824051">parent</a><span>|</span><a href="#35824582">prev</a><span>|</span><a href="#35827037">next</a><span>|</span><label class="collapse" for="c-35834477">[-]</label><label class="expand" for="c-35834477">[1 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s call it the Underdog License. It must not be used by any of the top N tech companies in terms of market share and&#x2F;or market capitalization.</div><br/></div></div></div></div><div id="35827037" class="c"><input type="checkbox" id="c-35827037" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35824051">prev</a><span>|</span><a href="#35836718">next</a><span>|</span><label class="collapse" for="c-35827037">[-]</label><label class="expand" for="c-35827037">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI faces the existential risk, not Google. They&#x27;ll catch up and will have the reach&#x2F;subsidy advantage.<p>Doesn&#x27;t Microsoft products get used more times in a day by more paying customers than Google products?<p>OpenAI won&#x27;t have a problem because they reach more paying customers via Microsoft than Google can.</div><br/></div></div><div id="35836718" class="c"><input type="checkbox" id="c-35836718" checked=""/><div class="controls bullet"><span class="by">htss2013</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35827037">prev</a><span>|</span><a href="#35824128">next</a><span>|</span><label class="collapse" for="c-35836718">[-]</label><label class="expand" for="c-35836718">[1 more]</label></div><br/><div class="children"><div class="content">Thats like saying in 1995 search is going to be integrated into everything, not a destination. That&#x27;d be true but also very wrong. Google.com ended up as the main destination.</div><br/></div></div><div id="35824128" class="c"><input type="checkbox" id="c-35824128" checked=""/><div class="controls bullet"><span class="by">zelon88</span><span>|</span><a href="#35821576">parent</a><span>|</span><a href="#35836718">prev</a><span>|</span><a href="#35818774">next</a><span>|</span><label class="collapse" for="c-35824128">[-]</label><label class="expand" for="c-35824128">[2 more]</label></div><br/><div class="children"><div class="content">&gt; And we should not expect to be able to catch up. The modern internet runs on open source for a reason. Open source has some significant advantages that we cannot replicate.<p>I don&#x27;t have faith in OpenAI as a company, but I have faith in Open-Source. What you&#x27;re trying to say, if I understand correctly, is that Google will absorb the open-source and simply be back on top. But who will maintain this newly acquired status quo for Google? Google cannot EEE their own developer base. They said that much in the article;<p>&gt; We cannot hope to both drive innovation and control it.<p>History as an example, Android did not kill *nix. Chrome did not kill Firefox. Google Docs has not killed Open Office. For the simple fact that Google needs all of these organizations to push Google forward. Whether that means Google gets access to code, or whether that means Google becomes incentivized to improve in some way.<p>If Google wants to eat another free lunch tomorrow they have no choice but to leave some of that free labor standing, if not prop it up a little. The real question becomes, how much market share can we realistically expect without eating tomorrow&#x27;s lunch?</div><br/><div id="35824190" class="c"><input type="checkbox" id="c-35824190" checked=""/><div class="controls bullet"><span class="by">spyckie2</span><span>|</span><a href="#35821576">root</a><span>|</span><a href="#35824128">parent</a><span>|</span><a href="#35818774">next</a><span>|</span><label class="collapse" for="c-35824190">[-]</label><label class="expand" for="c-35824190">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re not saying that they should absorb open-source. They&#x27;re arguing towards a strategy&#x2F;direction for how to approach AI models from a business perspective, laying down the facts that open-source has a superior positional advantage in terms of development costs.<p>Probably, internally Googlers are arguing that the &quot;AI explosion&quot; is short lived and people will be stop paying for AI as soon as open source PC models become cost and quality competitive. So they shouldn&#x27;t chase the next big revenue stream that OpenAI is currently enjoying because it&#x27;s short lived.</div><br/></div></div></div></div></div></div><div id="35818774" class="c"><input type="checkbox" id="c-35818774" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#35821576">prev</a><span>|</span><a href="#35819312">next</a><span>|</span><label class="collapse" for="c-35818774">[-]</label><label class="expand" for="c-35818774">[118 more]</label></div><br/><div class="children"><div class="content">The part of the post that resonates for me is that working with the open source community may allow a model to improve faster. And, whichever model improves faster, will win - if it can continue that pace of improvement.<p>The author talks about Koala but notes that ChatGPT is better. GPT-4 is then significantly better than GPT-3.5. If you&#x27;ve used all the models and can afford to spend money, you&#x27;d be insane to not use GPT-4 over all the other models.<p>Midjourney is more popular (from what I&#x27;m seeing) than Stable Diffusion at the moment because it&#x27;s better at the moment. Midjourney is closed-source.<p>The point I&#x27;m wanting to make is that users will go to whoever has the best model. So, the winning strategy is whatever strategy allows your model to compound in quality faster and to continue to compound that growth in quality for longer.<p>Open source doesn&#x27;t always win in producing better quality products.<p>Linux won in servers and supercomputing, but not in end user computing.<p>Open-source databases mostly won.<p>Chromium sorta won, but really Chrome.<p>Then in most other areas, closed-source has won.<p>So one takeaway might be that open-source will win in areas where the users are often software developers that can make improvements to the product they&#x27;re using, and closed-source will win in other areas.</div><br/><div id="35821308" class="c"><input type="checkbox" id="c-35821308" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819021">next</a><span>|</span><label class="collapse" for="c-35821308">[-]</label><label class="expand" for="c-35821308">[27 more]</label></div><br/><div class="children"><div class="content">GPT-4 is so much better for complex tasks that I wouldn&#x27;t use anything else. Trying to get 3.5 to do anything complicated is like pulling teeth, and using something worse than 3.5... Oof.<p>TBH this feels like cope from Google; Bard is embarrassingly bad and they expected to be able to compete with OpenAI. In my experience, despite their graph in the article that puts them ahead of Vicuna-13B, they&#x27;re actually behind... And you can&#x27;t even use Bard as a developer, there&#x27;s no API!<p>But GPT-4 is so, so much better. It&#x27;s not clear to me that individual people doing LoRa at home is going to meaningfully close the gap in terms of generalized capability — at least, not faster than OpenAI itself improves its models. Similarly, StableDiffusion&#x27;s image quality progress has in my experience stalled out, whereas Midjourney continues to dramatically improve every couple months, and easily beats SD. Open source isn&#x27;t a magic bullet for quality.<p>Edit: re: the complaints about Midjourney&#x27;s UI being Discord — sure, that definitely constrains what you can do with it, but OpenAI&#x27;s interface isn&#x27;t Discord, it has an API. And you can fine-tune the GPT-3 models programmatically too, and although they haven&#x27;t opened that up to GPT-4 yet, IME you can&#x27;t fine-tune your way to GPT-4 quality anyway with anything.<p>&quot;There&#x27;s no moat&quot; and &quot;OpenAI is irrelevant&quot; feel like the cries of the company that&#x27;s losing to OpenAI and wants to save face on the way out. Getting repeated generational improvements without the dataset size and compute scale of a dedicated, well-capitalized company is going to be very tough. As a somewhat similar data+compute problem, I can&#x27;t think of an open-source project that effectively dethroned Google Search, for example... At least, not by <i>being better at search</i> (you can argue that maybe LLMs are dethroning Google, but on the other hand, it&#x27;s not the open source models that are the best at that, it&#x27;s closed-source GPT-4).</div><br/><div id="35821512" class="c"><input type="checkbox" id="c-35821512" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35825822">next</a><span>|</span><label class="collapse" for="c-35821512">[-]</label><label class="expand" for="c-35821512">[17 more]</label></div><br/><div class="children"><div class="content">Yes, I&#x27;d readily pay for GPT-4 access, though not the limited 25 requests per 3 hours version. I ponied up $20 for a month of usage to check it out, and it performs head &amp; shoulders above 3.5 in its ability to comprehensively address more complex prompts and provide output that is more nuanced than ChatGPT.<p>I&#x27;ll also point out that paid api access to 3.5 (davinci-03) is frequently better than ChatGPT&#x27;s use of 3.5. You get many fewer restrictions, and none the &quot;awe shucks, I&#x27;m just a little &#x27;ol LLM and so I couldn&#x27;t possibly answer that&quot;.<p>If you&#x27;re frustrated by having to go to great lengths to prompt engineer and ask  ChatGPT to &quot;pretend&quot; then it&#x27;s worth it to pay for API access. I&#x27;m just frustrated that I can&#x27;t use the GPT-4 API the same way yet (waitlist)</div><br/><div id="35821635" class="c"><input type="checkbox" id="c-35821635" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821512">parent</a><span>|</span><a href="#35821858">next</a><span>|</span><label class="collapse" for="c-35821635">[-]</label><label class="expand" for="c-35821635">[4 more]</label></div><br/><div class="children"><div class="content">I hear ya! I&#x27;m out here dying on the GPT-4 API waitlist too. I use gpt-3.5-turbo&#x27;s API extensively, and occasionally copy my prompts into GPT-4&#x27;s web UI and watch as it just flawlessly does all the things 3.5 struggles with. Very frustrating since I don&#x27;t have GPT-4 API access, but also very, very impressive. It&#x27;s not even remotely close.<p>I pay the $20 for ChatGPT Plus (aka, GPT-4 web interface access); personally I find it useful enough to be worth paying for, even in its 
rate-limited state. It already replaces Google for anything complex for me. I wish I could pay for the API too, and use it in my projects.</div><br/><div id="35822682" class="c"><input type="checkbox" id="c-35822682" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821635">parent</a><span>|</span><a href="#35823930">next</a><span>|</span><label class="collapse" for="c-35822682">[-]</label><label class="expand" for="c-35822682">[1 more]</label></div><br/><div class="children"><div class="content">GPT 4 really shows how absolutely terrible regular web search is at finding anything these days. Another complete embarrassment for Google.<p>Often times it can just recite things from memory that Google can&#x27;t even properly link to, and they&#x27;ve got a proper index to work from for fucks sake.</div><br/></div></div><div id="35823930" class="c"><input type="checkbox" id="c-35823930" checked=""/><div class="controls bullet"><span class="by">tominous</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821635">parent</a><span>|</span><a href="#35822682">prev</a><span>|</span><a href="#35828810">next</a><span>|</span><label class="collapse" for="c-35823930">[-]</label><label class="expand" for="c-35823930">[1 more]</label></div><br/><div class="children"><div class="content">I was dying on the GPT-4 API waitlist too. I built a proof-of-concept with GPT-3.5, got some ada embeddings, played around with some common patterns for a couple of weeks, spent less than $20. I then applied to the waitlist again with a few short sentences about what I&#x27;d done, how GPT-4 would make it better, and how it would enable something new and valuable for a particular market. Approved that day.<p>It&#x27;s not exactly a shortcut, and maybe it was just luck, but I suspect the key is just to start building with what you have and show a trajectory. The best part is that coding with ChatGPT-4 as a &quot;colleague&quot; has made the whole thing super fun.</div><br/></div></div><div id="35828810" class="c"><input type="checkbox" id="c-35828810" checked=""/><div class="controls bullet"><span class="by">irthomasthomas</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821635">parent</a><span>|</span><a href="#35823930">prev</a><span>|</span><a href="#35821858">next</a><span>|</span><label class="collapse" for="c-35828810">[-]</label><label class="expand" for="c-35828810">[1 more]</label></div><br/><div class="children"><div class="content">I just got access. If you want, you can email me some prompts to test, ^ @gmail.</div><br/></div></div></div></div><div id="35821858" class="c"><input type="checkbox" id="c-35821858" checked=""/><div class="controls bullet"><span class="by">obiefernandez</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821512">parent</a><span>|</span><a href="#35821635">prev</a><span>|</span><a href="#35824691">next</a><span>|</span><label class="collapse" for="c-35821858">[-]</label><label class="expand" for="c-35821858">[7 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re technical just get yourself OpenAI API access which is super cheap and hook it up to your own self-hosted ChatGPT clone like <a href="https:&#x2F;&#x2F;github.com&#x2F;magma-labs&#x2F;magma-chat">https:&#x2F;&#x2F;github.com&#x2F;magma-labs&#x2F;magma-chat</a><p>The wait for GPT-4 is not as long as it used to be, and when you&#x27;re using the API directly there&#x27;s no censorship.</div><br/><div id="35822537" class="c"><input type="checkbox" id="c-35822537" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35823959">next</a><span>|</span><label class="collapse" for="c-35822537">[-]</label><label class="expand" for="c-35822537">[1 more]</label></div><br/><div class="children"><div class="content">Yep, I use the paid API, and it’s a lot more flexible than ChatGPT. I’d didn’t know about the self-hosted interface though: that will be my project for tomorrow morning, thanks!<p>I’ve been on the GPT-4 waitlist for about 6 weeks, but I’m not sure what the typical wait is.</div><br/></div></div><div id="35823959" class="c"><input type="checkbox" id="c-35823959" checked=""/><div class="controls bullet"><span class="by">chillfox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35822537">prev</a><span>|</span><a href="#35823868">next</a><span>|</span><label class="collapse" for="c-35823959">[-]</label><label class="expand" for="c-35823959">[1 more]</label></div><br/><div class="children"><div class="content">&quot;just get yourself OpenAI API access&quot;<p>Could you please describe how one &quot;just&quot; do that?
I have been on the GPT-4 API waitlist since it was announced and I still don&#x27;t have access to the GPT-4 API.</div><br/></div></div><div id="35823868" class="c"><input type="checkbox" id="c-35823868" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35823959">prev</a><span>|</span><a href="#35823556">next</a><span>|</span><label class="collapse" for="c-35823868">[-]</label><label class="expand" for="c-35823868">[1 more]</label></div><br/><div class="children"><div class="content">Magma wants me to use my google credentials to login. I’ll pass on that, it shouldn’t be required in anything self hosted which makes me distrust it a bit right off the bat.</div><br/></div></div><div id="35823556" class="c"><input type="checkbox" id="c-35823556" checked=""/><div class="controls bullet"><span class="by">rcpt</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35823868">prev</a><span>|</span><a href="#35826421">next</a><span>|</span><label class="collapse" for="c-35823556">[-]</label><label class="expand" for="c-35823556">[1 more]</label></div><br/><div class="children"><div class="content">&gt; when you&#x27;re using the API directly there&#x27;s no censorship.<p>Wait seriously?</div><br/></div></div><div id="35826421" class="c"><input type="checkbox" id="c-35826421" checked=""/><div class="controls bullet"><span class="by">QkPrsMizkYvt</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35823556">prev</a><span>|</span><a href="#35822902">next</a><span>|</span><label class="collapse" for="c-35826421">[-]</label><label class="expand" for="c-35826421">[1 more]</label></div><br/><div class="children"><div class="content">Did you come across some other self-hosted ChatGPT clones that you can recommend?</div><br/></div></div><div id="35822902" class="c"><input type="checkbox" id="c-35822902" checked=""/><div class="controls bullet"><span class="by">DesiLurker</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821858">parent</a><span>|</span><a href="#35826421">prev</a><span>|</span><a href="#35824691">next</a><span>|</span><label class="collapse" for="c-35822902">[-]</label><label class="expand" for="c-35822902">[1 more]</label></div><br/><div class="children"><div class="content">.</div><br/></div></div></div></div><div id="35824691" class="c"><input type="checkbox" id="c-35824691" checked=""/><div class="controls bullet"><span class="by">artdigital</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821512">parent</a><span>|</span><a href="#35821858">prev</a><span>|</span><a href="#35828779">next</a><span>|</span><label class="collapse" for="c-35824691">[-]</label><label class="expand" for="c-35824691">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ll also point out that paid api access to 3.5 (davinci-03) is frequently better than ChatGPT&#x27;s use of 3.5. You get many fewer restrictions, and none the &quot;awe shucks, I&#x27;m just a little &#x27;ol LLM and so I couldn&#x27;t possibly answer that&quot;.<p>Little correction - 3.5 is not davinci. davinci is 3.0, 3.5-turbo (chatgpt) is a davinci variant that has been tuned and adjusted for chatting and conversation, including all those restrictions. It is much faster than davinci, way cheaper but as you know, results are… ok<p>davinci (3.0) is more untuned, slower, more expensive to use, not conversational, but can yield much better quality</div><br/><div id="35827198" class="c"><input type="checkbox" id="c-35827198" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35824691">parent</a><span>|</span><a href="#35825304">next</a><span>|</span><label class="collapse" for="c-35827198">[-]</label><label class="expand" for="c-35827198">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Little correction - 3.5 is not davinci. davinci is 3.0, 3.5-turbo (chatgpt) is a davinci variant that has been tuned and adjusted for chatting and conversation, including all those restrictions.<p>Little correction of the correction. The base models are:<p>davinci = GPT-3<p>code-davinci-002 = GPT-3.5<p>They do only text completion and do not natively answer to instructions. There are also instruction tuned versions of the latter, e.g. text-davinci-003 and gpt-3.5-turbo-0301 (used in ChatGPT). See<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;model-index-for-researchers" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;model-index-for-researchers</a><p>Note that code-davinci-002 is no longer available via the OpenAI API, but it is still on Azure. The GPT-4 base model is generally unavailable. Too powerful perhaps.</div><br/></div></div><div id="35825304" class="c"><input type="checkbox" id="c-35825304" checked=""/><div class="controls bullet"><span class="by">user_named</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35824691">parent</a><span>|</span><a href="#35827198">prev</a><span>|</span><a href="#35828779">next</a><span>|</span><label class="collapse" for="c-35825304">[-]</label><label class="expand" for="c-35825304">[1 more]</label></div><br/><div class="children"><div class="content">Turbo and davinci should be equally non-conversational. When you use GhatGPT it also has InstructGPT on top of turbo which is what makes it conversational, together with RLHF.</div><br/></div></div></div></div><div id="35828779" class="c"><input type="checkbox" id="c-35828779" checked=""/><div class="controls bullet"><span class="by">irthomasthomas</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821512">parent</a><span>|</span><a href="#35824691">prev</a><span>|</span><a href="#35825822">next</a><span>|</span><label class="collapse" for="c-35828779">[-]</label><label class="expand" for="c-35828779">[2 more]</label></div><br/><div class="children"><div class="content">I have access. If you want to collaborate, or just test a few prompt ideas, you can email me @gmail</div><br/><div id="35838937" class="c"><input type="checkbox" id="c-35838937" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35828779">parent</a><span>|</span><a href="#35825822">next</a><span>|</span><label class="collapse" for="c-35838937">[-]</label><label class="expand" for="c-35838937">[1 more]</label></div><br/><div class="children"><div class="content">I’m pasting my response to someone else who made the same kind offer:<p>Thanks you for the offer, but I’m extremely conscious of avoiding a direct link from my comments here to who I am.
Maybe it’s a bit too paranoid, I don’t know, but I’ve also been open here about my workplace experiences, if someone who knew my irl connection to them and decided to comb through my comments, in a way that my HR dept among others might not quite appreciate. Maybe I should setup a separate HN account connected to me Professionally for that sort of thing.
Also my use case for GPT-4 is data analysis. Using the paid “plus” version shows a lot of promise for quickly bootstrapping data exploration and consumption as a jumping off point for more detailed digging. Via the chat interface it can ingest very small aggregate datasets and spit out observations that only myself and my boss have the domain name expertise to produce in my organization. but the Chat interface is highly limited and often truncates even small (faked but plausible) data, so I really want API access, because it involves sensitive info I couldn’t put into the chat site or responsibly share with someone outside my org.
But really, thanks for the offer. What are you working on with it?</div><br/></div></div></div></div></div></div><div id="35825822" class="c"><input type="checkbox" id="c-35825822" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35821512">prev</a><span>|</span><a href="#35821376">next</a><span>|</span><label class="collapse" for="c-35825822">[-]</label><label class="expand" for="c-35825822">[1 more]</label></div><br/><div class="children"><div class="content">SD and its configurability is miles and miles ahead of MJ. Sure if you want a fancy picture <i>now</i> it’s OK. How are you going to generate that same picture in another pose? Inpainting, outpainting.. I don’t even know where to begin. MJ is a toy compared to SD’s ecosystem.</div><br/></div></div><div id="35821376" class="c"><input type="checkbox" id="c-35821376" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35825822">prev</a><span>|</span><a href="#35824515">next</a><span>|</span><label class="collapse" for="c-35821376">[-]</label><label class="expand" for="c-35821376">[3 more]</label></div><br/><div class="children"><div class="content">GPT-4 is a must if tool using is your goal.<p>GPT-3.5, I think it is mostly suitable for:<p>1. Quick documentation lookup for non-essential facts<p>2. Lightweight documents writing and rewriting<p>3. Translation<p>Other use cases should go straightly to GPT-4</div><br/><div id="35821582" class="c"><input type="checkbox" id="c-35821582" checked=""/><div class="controls bullet"><span class="by">biesnecker</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821376">parent</a><span>|</span><a href="#35821749">next</a><span>|</span><label class="collapse" for="c-35821582">[-]</label><label class="expand" for="c-35821582">[1 more]</label></div><br/><div class="children"><div class="content">I use GPT-3.5 for a lot of terminology lookup, and it&#x27;s generally pretty great.<p>&quot;In the context of [field I&#x27;m ramping up in], what does X mean, and how is it different than Y&quot; -- it&#x27;s not as good as GPT4 but it emits so much quicker and it normally gets me where I needed to go.</div><br/></div></div></div></div><div id="35824515" class="c"><input type="checkbox" id="c-35824515" checked=""/><div class="controls bullet"><span class="by">spyckie2</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35821376">prev</a><span>|</span><a href="#35829892">next</a><span>|</span><label class="collapse" for="c-35824515">[-]</label><label class="expand" for="c-35824515">[2 more]</label></div><br/><div class="children"><div class="content">The question is how long will it take for open source to become just as good as GPT 4? If it is 3 years, then yes, this is copium. But if it is 1 year or less, then how much is google really missing out on?<p>OpenAI spent 600m to improve GPT and made 200m from it and if costs dramatically fall for model development, it might be OpenAI that is shooting itself in the foot.</div><br/><div id="35827971" class="c"><input type="checkbox" id="c-35827971" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35824515">parent</a><span>|</span><a href="#35829892">next</a><span>|</span><label class="collapse" for="c-35827971">[-]</label><label class="expand" for="c-35827971">[1 more]</label></div><br/><div class="children"><div class="content"><i>OpenAI spent 600m to improve GPT and made 200m from it</i><p>How do you know?</div><br/></div></div></div></div><div id="35829892" class="c"><input type="checkbox" id="c-35829892" checked=""/><div class="controls bullet"><span class="by">whywhywhywhy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35824515">prev</a><span>|</span><a href="#35821502">next</a><span>|</span><label class="collapse" for="c-35829892">[-]</label><label class="expand" for="c-35829892">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Similarly, StableDiffusion&#x27;s image quality progress has in my experience stalled out, whereas Midjourney continues to dramatically improve every couple months, and easily beats SD. Open source isn&#x27;t a magic bullet for quality.<p>MJ only does one style, and you can emulate that just fine in SD if thats what you want.</div><br/></div></div><div id="35821502" class="c"><input type="checkbox" id="c-35821502" checked=""/><div class="controls bullet"><span class="by">joshbert</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35829892">prev</a><span>|</span><a href="#35825496">next</a><span>|</span><label class="collapse" for="c-35821502">[-]</label><label class="expand" for="c-35821502">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t feel sorry for Google, nor the big amounts of PR nonsense they&#x27;re putting out there in order to try to spin their being too slow to move LLM tech to the side of the consumer. Get better or get out.</div><br/></div></div><div id="35825496" class="c"><input type="checkbox" id="c-35825496" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821308">parent</a><span>|</span><a href="#35821502">prev</a><span>|</span><a href="#35819021">next</a><span>|</span><label class="collapse" for="c-35825496">[-]</label><label class="expand" for="c-35825496">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And you can&#x27;t even use Bard as a developer, there&#x27;s no API!<p>There is an API for the underlying model, it&#x27;s just in alpha&#x2F;beta&#x2F;whatever they call limited invite-only release and you have to ask your devrel team to get access. I&#x27;m guessing we&#x27;ll see better models very soon.<p>Google is, as usual, playing catch-up, but I have no doubt once the machine gets cranking they&#x27;ll be fully competitive, at least similar to how GCP is now a totally viable AWS alternative. They never lead the pack because they can&#x27;t (lawyers, regulation, monopoly, etc), but they know how to commit and execute.</div><br/></div></div></div></div><div id="35819021" class="c"><input type="checkbox" id="c-35819021" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35821308">prev</a><span>|</span><a href="#35819287">next</a><span>|</span><label class="collapse" for="c-35819021">[-]</label><label class="expand" for="c-35819021">[48 more]</label></div><br/><div class="children"><div class="content">&gt;Midjourney is more popular (from what I&#x27;m seeing) than Stable Diffusion at the moment because it&#x27;s better at the moment. Midjourney is closed-source.<p>Midjourney is easier, its not better. The low barrier to entry has it popular, but it isnt as realistic, doesnt follow the prompt as well, and has almost no customization.<p>SD is the holy grail of AI art, if you can afford a computer or server to run SD + have the ability to figure out how to install python, clone Automatic1111 from git, and run the installer, its the best. Those 3 steps are too much for most people, so they default to something more like an app. Maybe it is too soon, but it seems SD has already won. MJ is like using MS paint, where SD is like photoshop.</div><br/><div id="35821209" class="c"><input type="checkbox" id="c-35821209" checked=""/><div class="controls bullet"><span class="by">contravert</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35820718">next</a><span>|</span><label class="collapse" for="c-35821209">[-]</label><label class="expand" for="c-35821209">[7 more]</label></div><br/><div class="children"><div class="content">I just want to add my $0.02 currently working at a games studio that is integrating AI generated art into our art pipelines.<p>Midjourney definitely generates really high quality art based on simple prompts, but the inability to really customize the output basically kills its utility.<p>We heavily use Stable Diffusion with specific models and ControlNet to get customizable and consistent results. Our artists also need to extensively tweak and post-process the output, and re-run it again in Stable Diffusion.<p>This entire workflow is definitely beyond a Discord-based interface to say the least.</div><br/><div id="35821479" class="c"><input type="checkbox" id="c-35821479" checked=""/><div class="controls bullet"><span class="by">jononor</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821209">parent</a><span>|</span><a href="#35821903">next</a><span>|</span><label class="collapse" for="c-35821479">[-]</label><label class="expand" for="c-35821479">[2 more]</label></div><br/><div class="children"><div class="content">If you would give a talk about this, I would watch it - despite being out of the graphics for almost 10 years now. Really want to hear from the trenches about the workflows, benefits and challenges you have.</div><br/><div id="35823704" class="c"><input type="checkbox" id="c-35823704" checked=""/><div class="controls bullet"><span class="by">pjgalbraith</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821479">parent</a><span>|</span><a href="#35821903">next</a><span>|</span><label class="collapse" for="c-35823704">[-]</label><label class="expand" for="c-35823704">[1 more]</label></div><br/><div class="children"><div class="content">Here is a test I did the other day of rough sketch (hand drawn) -&gt; clean line work (AI) -&gt; coloured (AI). This workflow gives 100% control over the output because you can easily adjust the linework in the intermediary step.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;P_Galbraith&#x2F;status&#x2F;1649317290926825473?cxt=HHwWgoDT-c3VxuMtAAAA" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;P_Galbraith&#x2F;status&#x2F;1649317290926825473?c...</a><p>This is using Stable Diffusion and the Control Net Lineart Model. The coloured version is pretty rough but it was a quick test.<p>In my opinion Stable Diffusion is vastly superior to Midjourney if you have the skill to provide input to img2img&#x2F;ControlNet.<p>I have some other earlier workflow experiments on Youtube if you&#x27;re interested in this kind of thing <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;pjgalbraith">https:&#x2F;&#x2F;www.youtube.com&#x2F;pjgalbraith</a></div><br/></div></div></div></div><div id="35821903" class="c"><input type="checkbox" id="c-35821903" checked=""/><div class="controls bullet"><span class="by">netdur</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821209">parent</a><span>|</span><a href="#35821479">prev</a><span>|</span><a href="#35824844">next</a><span>|</span><label class="collapse" for="c-35821903">[-]</label><label class="expand" for="c-35821903">[3 more]</label></div><br/><div class="children"><div class="content">use <a href="https:&#x2F;&#x2F;github.com&#x2F;deep-floyd&#x2F;IF">https:&#x2F;&#x2F;github.com&#x2F;deep-floyd&#x2F;IF</a>, it uses LLM to generate exact art you need.</div><br/><div id="35823406" class="c"><input type="checkbox" id="c-35823406" checked=""/><div class="controls bullet"><span class="by">jelling</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821903">parent</a><span>|</span><a href="#35822449">next</a><span>|</span><label class="collapse" for="c-35823406">[-]</label><label class="expand" for="c-35823406">[1 more]</label></div><br/><div class="children"><div class="content">Deep Floyd doesn&#x27;t allow commercial usage, such as a game studio using it.</div><br/></div></div><div id="35822449" class="c"><input type="checkbox" id="c-35822449" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821903">parent</a><span>|</span><a href="#35823406">prev</a><span>|</span><a href="#35824844">next</a><span>|</span><label class="collapse" for="c-35822449">[-]</label><label class="expand" for="c-35822449">[1 more]</label></div><br/><div class="children"><div class="content">The image quality of DeepFloyd is much lower than Stable Diffusion 1.5 though, it&#x27;s a pretty major tradeoff. Can definitely be part of the workflow since it really is good at composition, but right now it&#x27;s not a replacement.</div><br/></div></div></div></div><div id="35824844" class="c"><input type="checkbox" id="c-35824844" checked=""/><div class="controls bullet"><span class="by">exodust</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821209">parent</a><span>|</span><a href="#35821903">prev</a><span>|</span><a href="#35820718">next</a><span>|</span><label class="collapse" for="c-35824844">[-]</label><label class="expand" for="c-35824844">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AI generated art into our art pipelines<p>I&#x27;d be interested to know where the art ends up in the game? Do you mean 2D backgrounds and billboards in-game? Or are we talking cut-scenes and menu screen art?</div><br/></div></div></div></div><div id="35820718" class="c"><input type="checkbox" id="c-35820718" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35821209">prev</a><span>|</span><a href="#35819760">next</a><span>|</span><label class="collapse" for="c-35820718">[-]</label><label class="expand" for="c-35820718">[9 more]</label></div><br/><div class="children"><div class="content">That seems to depend on your use case. Frankly, I don&#x27;t have much use for either of them but Midjourney was much closer.<p>I&#x27;ve twice spent a couple of hours unsuccessfully trying to generate a simple background image that would be blurred out when rendering 3D models. SD out-of-the-box was far worse, but Midjourney still was not up to the task. It&#x27;s incredible how well they can generate images of nearly any subject&#x2F;object and make some changes to the style and placement, but trying to precisely achieve critical broad-stroke things like like perspective, sizing, lighting direction&#x2F;amount&#x2F;temperature, etc. was far too cumbersome. Prompt refining is just like having a program with a bunch of nebulous undocumented menu entries that you just have to click on to see what they do rather than just giving you the tools to make what you need to make. Was that the right entry or the wrong entry? Who knows! Maybe just try it again to see if it works better!<p>There&#x27;s a fundamental disconnect between professional-level and consumer-level tools. Consumer tools must be approachable, easy to use, quickly yield appealing results, affordable, and require little maintenance. Professional tools need to be precise, reliable, capable of repeated results with the most demanding tasks, and easily serviceable into perfect working order.<p>These are consumer-level tools. If you merely need a cool picture of a space ship done in such and such style with such and such guns blah blah blah (that for some reason always looks 10%-50% Thomas Kinkaid,) these tools are great, but they abstract away the controls that really matter in professional work. Novices who get overwhelmed by all of those factors love it because they don&#x27;t understand, and probably don&#x27;t care about what they&#x27;re giving up. For serious work, aside from getting inspo images or maybe generating deliberately weird bits of whatever, they&#x27;re hit-or-miss at best. Without exception, doing a rough mock-up in a modelling program took FAR less time than trying to wrangle exactly what I needed from one of those generators.<p>I&#x27;m sure they&#x27;ll get there someday but right now they&#x27;re miles away from being professional-quality image generation tools.</div><br/><div id="35821130" class="c"><input type="checkbox" id="c-35821130" checked=""/><div class="controls bullet"><span class="by">jstarfish</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820718">parent</a><span>|</span><a href="#35822557">next</a><span>|</span><label class="collapse" for="c-35821130">[-]</label><label class="expand" for="c-35821130">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Without exception, doing a rough mock-up in a modelling program took FAR less time than trying to wrangle exactly what I needed from one of those generators.<p>I think a lot of people have unrealistic expectations of the tech-- they think they can get <i>exactly</i> what they want if they are articulate enough in describing it with words.<p>Feed your rough mock-up to img2img (or use inpaint sketch) and you&#x27;ll land much closer to where you&#x27;re trying to go.<p>It&#x27;s a power tool. It will do tedious manual work (producing art) very quickly. The difference between professionals and consumers in how they use it is that the professional asks the machine to &quot;finish what I started,&quot; whereas the consumer tells the machine to &quot;do all of the work for me.&quot;</div><br/><div id="35821738" class="c"><input type="checkbox" id="c-35821738" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821130">parent</a><span>|</span><a href="#35824038">next</a><span>|</span><label class="collapse" for="c-35821738">[-]</label><label class="expand" for="c-35821738">[1 more]</label></div><br/><div class="children"><div class="content">I tried img2img. It will do rough finishing work but it won&#x27;t take some lighting vectors and match my lighting. It won&#x27;t shift the viewpoint by 18 degrees. It puts a smooth sheen on rough work with broad stroke needs and that&#x27;s valuable in some cases, but it is not a general-purpose professional tool.<p>Canva competently satisfies most non-professional needs but it only satisfies a narrow slice of professional needs. Trying to use it for most professional work takes vastly <i>more</i> time and effort than using a proper professional tool. LaTeX fits academic paper publisher&#x27;s needs and can pump out formatted and laid-out text far quicker than someone using InDesign but you&#x27;d go crazy trying to assemble a modern magazine or high-end book. It doesn&#x27;t need polish or sheen. It needs something fundamentally structurally different.<p>I&#x27;m both a professional digital artists and a long time back-end software developer. This slice of time has really opened my eyes to what it must be like for most non-developers to speak to developers: constantly oversimplifying your use case and assuming some algorithmic approximation will do without really understanding the problem.</div><br/></div></div><div id="35824038" class="c"><input type="checkbox" id="c-35824038" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821130">parent</a><span>|</span><a href="#35821738">prev</a><span>|</span><a href="#35822557">next</a><span>|</span><label class="collapse" for="c-35824038">[-]</label><label class="expand" for="c-35824038">[1 more]</label></div><br/><div class="children"><div class="content"><i>I think a lot of people have unrealistic expectations of the tech-- they think they can get exactly what they want if they are articulate enough in describing it with words</i><p>Who&#x27;s fault is this though? The hype is absolutely hysterical.</div><br/></div></div></div></div><div id="35822557" class="c"><input type="checkbox" id="c-35822557" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820718">parent</a><span>|</span><a href="#35821130">prev</a><span>|</span><a href="#35820902">next</a><span>|</span><label class="collapse" for="c-35822557">[-]</label><label class="expand" for="c-35822557">[2 more]</label></div><br/><div class="children"><div class="content">ControlNet helps a lot with composition and lighting (<a href="https:&#x2F;&#x2F;sandner.art&#x2F;create-atmospheric-effects-in-stable-diffusion&#x2F;" rel="nofollow">https:&#x2F;&#x2F;sandner.art&#x2F;create-atmospheric-effects-in-stable-dif...</a>). It requires more work than just entering a prompt, but probably less work than doing it manually once you get used to it. I think there&#x27;s a number of StableDiffusion clients in development that are trying to make this easier.</div><br/><div id="35833541" class="c"><input type="checkbox" id="c-35833541" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35822557">parent</a><span>|</span><a href="#35820902">next</a><span>|</span><label class="collapse" for="c-35833541">[-]</label><label class="expand" for="c-35833541">[1 more]</label></div><br/><div class="children"><div class="content">Ha... I accidentally replied to the wrong comment. Anyway, thanks! That&#x27;s pretty neat. The sample images look a bit overwrought like a lot of other AI images do but I&#x27;ll bet they&#x27;re doing that to follow the trend rather than it being a technical limitation.</div><br/></div></div></div></div><div id="35820902" class="c"><input type="checkbox" id="c-35820902" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820718">parent</a><span>|</span><a href="#35822557">prev</a><span>|</span><a href="#35828220">next</a><span>|</span><label class="collapse" for="c-35820902">[-]</label><label class="expand" for="c-35820902">[1 more]</label></div><br/><div class="children"><div class="content">I will say though that low-effort higher-volume professionals (e.g. mobile game mills, Fiverrrr designers) will likely profit from these tools once they can out-compete cheap online assets from stock images&#x2F;models&#x2F;etc. but they&#x27;re so not there yet.</div><br/></div></div><div id="35828220" class="c"><input type="checkbox" id="c-35828220" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820718">parent</a><span>|</span><a href="#35820902">prev</a><span>|</span><a href="#35819760">next</a><span>|</span><label class="collapse" for="c-35828220">[-]</label><label class="expand" for="c-35828220">[2 more]</label></div><br/><div class="children"><div class="content">Classical professional tools like Photoshop have a lot less potential though. They are very precise, but (I assume) they have barely advanced in the past decade. Tools based on generative AI will probably improve massively over the next few years. Most such tools seem currently based on Stable Diffusion, and apparently OpenAI&#x2F;Midjourney&#x2F;Google have zero interest in supporting such tools. But this could change soon, e.g. when Adobe tries to compete with the SD ecosystem.<p>We already now see deepfakes (e.g. of Trump or the Pope, recently even videos) that a far beyond what we saw in the years before, indicating that the old professional tools weren&#x27;t so powerful after all. Now if we extrapolate this a few years into the future...</div><br/><div id="35836582" class="c"><input type="checkbox" id="c-35836582" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35828220">parent</a><span>|</span><a href="#35819760">next</a><span>|</span><label class="collapse" for="c-35836582">[-]</label><label class="expand" for="c-35836582">[1 more]</label></div><br/><div class="children"><div class="content">You assume wrong. What these tools offer is <i>constantly</i> churning. Far faster than ever before and Photoshop has been around for over 30 years. They release updates constantly. Photoshop got AI filters like detail enhancement for zooming a few years ago. Automatic object detection, content-aware delete, etc. etc etc. a few years before that. That&#x27;s only what I can recall off the top of my head for Photoshop alone, but it&#x27;s such a giant environment that even most of their own product people probably couldn&#x27;t tell you off the cuff. In areas like video compositing, tools like Nuke are developing tools with these capabilities even more quickly... and they better when the cheap license costs $3500&#x2F;yr.<p>As I mentioned in another comment, so much of this hype is based on developers assuming they understand something that they don&#x27;t. I&#x27;ve indulged in this hubris as a developer but straddling both sides of this line has been illuminating.</div><br/></div></div></div></div></div></div><div id="35819760" class="c"><input type="checkbox" id="c-35819760" checked=""/><div class="controls bullet"><span class="by">mdorazio</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35820718">prev</a><span>|</span><a href="#35819472">next</a><span>|</span><label class="collapse" for="c-35819760">[-]</label><label class="expand" for="c-35819760">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Midjourney is easier, its not better.<p>By what measure? Midjourney v5 is massively better with every prompt topic I&#x27;ve thrown at it than SD. It&#x27;s not even close. SD, however, is much better if you want an actual customizable toolchain or to do things like train it on your own face&#x2F;character.</div><br/><div id="35822744" class="c"><input type="checkbox" id="c-35822744" checked=""/><div class="controls bullet"><span class="by">throwaway675309</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819760">parent</a><span>|</span><a href="#35821421">next</a><span>|</span><label class="collapse" for="c-35822744">[-]</label><label class="expand" for="c-35822744">[2 more]</label></div><br/><div class="children"><div class="content">Generate the following picture in mid journey:
&quot;A school of dolphins spanking a mermaid with their flukes.&quot;<p>A 1000 V-rolls won&#x27;t get you there. For something like this control net combined with inpainting is indispensable. Not to mention the excessively heavy handed censorship in MJ.<p>Midjourney excels in overall quality, but it completely falls down if you have an actual complex vision.</div><br/><div id="35827813" class="c"><input type="checkbox" id="c-35827813" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35822744">parent</a><span>|</span><a href="#35821421">next</a><span>|</span><label class="collapse" for="c-35827813">[-]</label><label class="expand" for="c-35827813">[1 more]</label></div><br/><div class="children"><div class="content">It seems Midjourney is great at generating non-pornographic pictures.</div><br/></div></div></div></div><div id="35821421" class="c"><input type="checkbox" id="c-35821421" checked=""/><div class="controls bullet"><span class="by">fumar</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819760">parent</a><span>|</span><a href="#35822744">prev</a><span>|</span><a href="#35820614">next</a><span>|</span><label class="collapse" for="c-35821421">[-]</label><label class="expand" for="c-35821421">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. I pay for MJ and have several SD versions running on my PC. I like the ability to fine tune the SD models and my Pc with a 4090 is plenty fast, but I can&#x27;t match MJ&#x27;s output on artistic quality. SD allows for 4k sized outputs which is great but I can&#x27;t use the art like I would like. FWIW the SD NSFW community is large but that is not where I invest my time with AI art.</div><br/></div></div><div id="35820614" class="c"><input type="checkbox" id="c-35820614" checked=""/><div class="controls bullet"><span class="by">ZephyrBlu</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819760">parent</a><span>|</span><a href="#35821421">prev</a><span>|</span><a href="#35819472">next</a><span>|</span><label class="collapse" for="c-35820614">[-]</label><label class="expand" for="c-35820614">[2 more]</label></div><br/><div class="children"><div class="content">They also just released v5.1, which seems to be quite a bit better than v5.</div><br/><div id="35827901" class="c"><input type="checkbox" id="c-35827901" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820614">parent</a><span>|</span><a href="#35819472">next</a><span>|</span><label class="collapse" for="c-35827901">[-]</label><label class="expand" for="c-35827901">[1 more]</label></div><br/><div class="children"><div class="content">Is there a comparison? It is interesting that there do not seem to be any Midjourney benchmarks. E.g.<p><a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;text-to-image-generation-on-coco?tag_filter=188" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;text-to-image-generation-on-...</a><p>Parti and Imagen are still on top, followed by Dall-E 2.<p>If their model is so great, why are they afraid of benchmarks?</div><br/></div></div></div></div></div></div><div id="35819472" class="c"><input type="checkbox" id="c-35819472" checked=""/><div class="controls bullet"><span class="by">tysam_and</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819760">prev</a><span>|</span><a href="#35819421">next</a><span>|</span><label class="collapse" for="c-35819472">[-]</label><label class="expand" for="c-35819472">[8 more]</label></div><br/><div class="children"><div class="content">Midjourney is higher quality by a fair bit, from my personal experience and from being near a few of the top early AI artists for a good little while.</div><br/><div id="35819899" class="c"><input type="checkbox" id="c-35819899" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819472">parent</a><span>|</span><a href="#35820938">next</a><span>|</span><label class="collapse" for="c-35819899">[-]</label><label class="expand" for="c-35819899">[3 more]</label></div><br/><div class="children"><div class="content">Is midjourneys model actually better?<p>I was under the impression that midjourney was just running a form of SD and it&#x27;s real secret sauce are the peripheral prompts it injects on the backend along with your prompts.<p>I could be totally off the mark here.</div><br/><div id="35822211" class="c"><input type="checkbox" id="c-35822211" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819899">parent</a><span>|</span><a href="#35821972">next</a><span>|</span><label class="collapse" for="c-35822211">[-]</label><label class="expand" for="c-35822211">[1 more]</label></div><br/><div class="children"><div class="content">The model is obviously massively better. and they haven&#x27;t been using SD in any form since the test mode of v3. the models are trained from scratch.</div><br/></div></div><div id="35821972" class="c"><input type="checkbox" id="c-35821972" checked=""/><div class="controls bullet"><span class="by">jaxboxer</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819899">parent</a><span>|</span><a href="#35822211">prev</a><span>|</span><a href="#35820938">next</a><span>|</span><label class="collapse" for="c-35821972">[-]</label><label class="expand" for="c-35821972">[1 more]</label></div><br/><div class="children"><div class="content">To me it is like saying oil is better than acrylics. These statements have no meaning when it comes to art.</div><br/></div></div></div></div><div id="35820938" class="c"><input type="checkbox" id="c-35820938" checked=""/><div class="controls bullet"><span class="by">lukebitts</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819472">parent</a><span>|</span><a href="#35819899">prev</a><span>|</span><a href="#35819904">next</a><span>|</span><label class="collapse" for="c-35820938">[-]</label><label class="expand" for="c-35820938">[2 more]</label></div><br/><div class="children"><div class="content">MJ edits your prompts, you can achieve the same level of quality if you use the same prompts they do (which can be found on the internet)</div><br/><div id="35827987" class="c"><input type="checkbox" id="c-35827987" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820938">parent</a><span>|</span><a href="#35819904">next</a><span>|</span><label class="collapse" for="c-35827987">[-]</label><label class="expand" for="c-35827987">[1 more]</label></div><br/><div class="children"><div class="content">They edit your prompt ... how?</div><br/></div></div></div></div><div id="35819904" class="c"><input type="checkbox" id="c-35819904" checked=""/><div class="controls bullet"><span class="by">sixothree</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819472">parent</a><span>|</span><a href="#35820938">prev</a><span>|</span><a href="#35819421">next</a><span>|</span><label class="collapse" for="c-35819904">[-]</label><label class="expand" for="c-35819904">[2 more]</label></div><br/><div class="children"><div class="content">Is midjourney still using discord as its primary user interface? That really turned me off.</div><br/><div id="35820255" class="c"><input type="checkbox" id="c-35820255" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819904">parent</a><span>|</span><a href="#35819421">next</a><span>|</span><label class="collapse" for="c-35820255">[-]</label><label class="expand" for="c-35820255">[1 more]</label></div><br/><div class="children"><div class="content">Yes-- a classmate uses it. They do @everyone announces in their server every day, and while you can mute actual notifications, it still adds one to your badge count. My attention is too valuable-- that would get me to cancel my subscription.</div><br/></div></div></div></div></div></div><div id="35819421" class="c"><input type="checkbox" id="c-35819421" checked=""/><div class="controls bullet"><span class="by">lrem</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819472">prev</a><span>|</span><a href="#35819237">next</a><span>|</span><label class="collapse" for="c-35819421">[-]</label><label class="expand" for="c-35819421">[2 more]</label></div><br/><div class="children"><div class="content">Are you sure about this? For the couple things I tried, a colleague with Midjourney managed to outperform my attempts with SD by leaps and bounds.</div><br/><div id="35822620" class="c"><input type="checkbox" id="c-35822620" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819421">parent</a><span>|</span><a href="#35819237">next</a><span>|</span><label class="collapse" for="c-35822620">[-]</label><label class="expand" for="c-35822620">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a higher &quot;skill ceiling&quot; with SD. You can install different models for different styles or subjects, use ControlNet for composition, and use plugins to do things you can&#x27;t easily do with MJ.</div><br/></div></div></div></div><div id="35819237" class="c"><input type="checkbox" id="c-35819237" checked=""/><div class="controls bullet"><span class="by">HelloMcFly</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819421">prev</a><span>|</span><a href="#35819303">next</a><span>|</span><label class="collapse" for="c-35819237">[-]</label><label class="expand" for="c-35819237">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Midjourney is easier, its not better<p>Does being easier not influence whether it&#x27;s better? I mean this in that for many of the ways AI art would be used, MJ already seems to be &quot;good enough&quot; at a lot of it.<p>Secondarily: doesn&#x27;t Midjourney&#x27;s increased user base and increased ratings they get from users help it refine its model, thus meaning that &quot;ease of use&quot; creates a feedback loop with &quot;quality of output&quot; because more users are engaged?<p>I&#x27;m asking real questions, not making a statement I believe in and just adding a question mark.</div><br/><div id="35819331" class="c"><input type="checkbox" id="c-35819331" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819237">parent</a><span>|</span><a href="#35819355">next</a><span>|</span><label class="collapse" for="c-35819331">[-]</label><label class="expand" for="c-35819331">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Does being easier not influence whether it&#x27;s better?<p>As mentioned, what is better, MS Paint or photoshop? If MJ ignores your prompt and spits out a half related picture, are you going to continue using it?<p>If anything MJ is a stepping stone to SD. You get a taste of AI art, but want to do something specific that MJ cannot do. You learn about control-net, alternative models, inpainting, etc... and you decide you need to move on from MS Paint to Photoshop.<p>I personally used free AI art(cant remember which), it was super cool, but quickly I wanted to use different models and generate thousands of pictures at a time. I wanted to make gifs, img2img, etc... and the only people doing that were on SD.</div><br/></div></div><div id="35819355" class="c"><input type="checkbox" id="c-35819355" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819237">parent</a><span>|</span><a href="#35819331">prev</a><span>|</span><a href="#35819303">next</a><span>|</span><label class="collapse" for="c-35819355">[-]</label><label class="expand" for="c-35819355">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Does being easier not influence whether it&#x27;s better<p>Midjourney let&#x27;s you type in a thing and get a result that will look great, which is no small accomplishment. If you want &quot;incidental art&quot; like blog post heros there is no competition. But it&#x27;s really hard to use if you want to get exactly what you want.</div><br/></div></div></div></div><div id="35819303" class="c"><input type="checkbox" id="c-35819303" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819237">prev</a><span>|</span><a href="#35819162">next</a><span>|</span><label class="collapse" for="c-35819303">[-]</label><label class="expand" for="c-35819303">[3 more]</label></div><br/><div class="children"><div class="content">&gt; SD is the holy grail of AI art, if you can afford a computer or server to run SD + have the ability to figure out how to install python, clone Automatic1111 from git, and run the installer, its the best.<p>If you can afford Colab (which is free if you don’t want to use it too much), you can just click one of the existing A1111 colabs and run that, you don’t need to figure out python, git, or A1111 installs.</div><br/><div id="35819574" class="c"><input type="checkbox" id="c-35819574" checked=""/><div class="controls bullet"><span class="by">kyleyeats</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819303">parent</a><span>|</span><a href="#35819498">next</a><span>|</span><label class="collapse" for="c-35819574">[-]</label><label class="expand" for="c-35819574">[1 more]</label></div><br/><div class="children"><div class="content">Google is cracking down on this recently.</div><br/></div></div><div id="35819498" class="c"><input type="checkbox" id="c-35819498" checked=""/><div class="controls bullet"><span class="by">LordDragonfang</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819303">parent</a><span>|</span><a href="#35819574">prev</a><span>|</span><a href="#35819162">next</a><span>|</span><label class="collapse" for="c-35819498">[-]</label><label class="expand" for="c-35819498">[1 more]</label></div><br/><div class="children"><div class="content">Free Colabs have started blocking any SD web-ui it detects (presumably because it&#x27;s meant as a community service for ML researchers, not for people who want to play hentai gacha, and they&#x27;re running out of server time)</div><br/></div></div></div></div><div id="35819162" class="c"><input type="checkbox" id="c-35819162" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819303">prev</a><span>|</span><a href="#35823335">next</a><span>|</span><label class="collapse" for="c-35819162">[-]</label><label class="expand" for="c-35819162">[5 more]</label></div><br/><div class="children"><div class="content">Do you have a link to a decent tutorial for someone to do what you&#x27;re describing in the last paragraph?</div><br/><div id="35819270" class="c"><input type="checkbox" id="c-35819270" checked=""/><div class="controls bullet"><span class="by">xhrpost</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819162">parent</a><span>|</span><a href="#35819247">next</a><span>|</span><label class="collapse" for="c-35819270">[-]</label><label class="expand" for="c-35819270">[1 more]</label></div><br/><div class="children"><div class="content">It took me a little hunting, but thanks to Reddit I eventually found a cloud-gpu host that provides a working Stable Diffusion image. So you basically don&#x27;t have to do anything that GP said. Everything is installed and you just rent the hardware.<p><a href="https:&#x2F;&#x2F;www.runpod.io&#x2F;console&#x2F;templates" rel="nofollow">https:&#x2F;&#x2F;www.runpod.io&#x2F;console&#x2F;templates</a><p>Look for &quot;RunPod Stable Diffusion&quot;. I spent a whole $0.35&#x2F;hr playing around with my own SD instance that I had running in minutes.</div><br/></div></div><div id="35819247" class="c"><input type="checkbox" id="c-35819247" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819162">parent</a><span>|</span><a href="#35819270">prev</a><span>|</span><a href="#35819380">next</a><span>|</span><label class="collapse" for="c-35819247">[-]</label><label class="expand" for="c-35819247">[1 more]</label></div><br/><div class="children"><div class="content">Do you need additional detail that cannot be found here?<p><a href="https:&#x2F;&#x2F;github.com&#x2F;AUTOMATIC1111&#x2F;stable-diffusion-webui">https:&#x2F;&#x2F;github.com&#x2F;AUTOMATIC1111&#x2F;stable-diffusion-webui</a><p>Or are you looking for the cutting edge stuff like control net?<p>If you want to use colab instead, I used this a month or two ago.<p><a href="https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;TheLastBen&#x2F;fast-stable-diffusion&#x2F;blob&#x2F;main&#x2F;fast_stable_diffusion_AUTOMATIC1111.ipynb" rel="nofollow">https:&#x2F;&#x2F;colab.research.google.com&#x2F;github&#x2F;TheLastBen&#x2F;fast-sta...</a><p>I hope other people can give you further reading.</div><br/></div></div><div id="35819380" class="c"><input type="checkbox" id="c-35819380" checked=""/><div class="controls bullet"><span class="by">enlyth</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819162">parent</a><span>|</span><a href="#35819247">prev</a><span>|</span><a href="#35819261">next</a><span>|</span><label class="collapse" for="c-35819380">[-]</label><label class="expand" for="c-35819380">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;rentry.org&#x2F;sdg-link" rel="nofollow">https:&#x2F;&#x2F;rentry.org&#x2F;sdg-link</a></div><br/></div></div><div id="35819261" class="c"><input type="checkbox" id="c-35819261" checked=""/><div class="controls bullet"><span class="by">erichocean</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819162">parent</a><span>|</span><a href="#35819380">prev</a><span>|</span><a href="#35823335">next</a><span>|</span><label class="collapse" for="c-35819261">[-]</label><label class="expand" for="c-35819261">[1 more]</label></div><br/><div class="children"><div class="content">There are dozens on YouTube. My kids did it, and they don&#x27;t even program and had never touched Python in their life.<p>Even trained their own models using a cloud GPU.<p>The SD ecosystem is wild.</div><br/></div></div></div></div><div id="35823335" class="c"><input type="checkbox" id="c-35823335" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819162">prev</a><span>|</span><a href="#35819786">next</a><span>|</span><label class="collapse" for="c-35823335">[-]</label><label class="expand" for="c-35823335">[1 more]</label></div><br/><div class="children"><div class="content">Midjourney is more niche. It’s great at photographs, digital art, concept art, game art and everything in that sphere. Because that’s what it was trained on. So it has a specific style. Dall-E in comparison produces kind of garbage looking pictures of many more styles</div><br/></div></div><div id="35819786" class="c"><input type="checkbox" id="c-35819786" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35823335">prev</a><span>|</span><a href="#35821841">next</a><span>|</span><label class="collapse" for="c-35819786">[-]</label><label class="expand" for="c-35819786">[1 more]</label></div><br/><div class="children"><div class="content">I have SD up on a machine with a 3090 and it can&#x27;t produce output half as good as MJ without a ton of work.<p>I use SD to augment MJ, like fixing hands with specific LORAs for example, so I definitely appreciate that it exists. But for actually creating a full image in one shot, they&#x27;re not even comparable.</div><br/></div></div><div id="35821841" class="c"><input type="checkbox" id="c-35821841" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819021">parent</a><span>|</span><a href="#35819786">prev</a><span>|</span><a href="#35819368">next</a><span>|</span><label class="collapse" for="c-35821841">[-]</label><label class="expand" for="c-35821841">[1 more]</label></div><br/><div class="children"><div class="content">Midjourney retrains itself, I have one click installer apps for SD, Midjourney and the live prompt community is very good<p>None of this stuff is copyrightable so I dont care that its not private</div><br/></div></div></div></div><div id="35819287" class="c"><input type="checkbox" id="c-35819287" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819021">prev</a><span>|</span><a href="#35820046">next</a><span>|</span><label class="collapse" for="c-35819287">[-]</label><label class="expand" for="c-35819287">[1 more]</label></div><br/><div class="children"><div class="content">&gt; users will go to whoever has the best model<p>Depends. You might want privacy, need low price in order to process big volumes, need no commercial restrictions, need a different tuning, or the task is easy enough and can be done by the smaller free model - why not? Why pay money, leak information, and get subjected to their rules?<p>You will only use GPT-4 or 5 for that 10% of tasks that really require it. The future spells bad for OpenAI, there is less profit in the large and seldom used big models. For 90% of the tasks there is a &quot;good enough&quot; level, and we&#x27;re approaching it, we don&#x27;t need smarter models except rarely.<p>Another concern for big model developers is data leaks - you can exfiltrate the skills of a large model by batch solving tasks. This works pretty well, you can make smaller models that are just as good as GPT-4 but on a single task. So you can do that if you need to call the API too many times - make your own free and libre model.<p>I think the logical response in this situation would be to start working on AI-anti-malware, like filters for fake news and deceptive sites. It&#x27;s gonna be a cat and mouse game from now on. Better to accept this situation and move on, we can&#x27;t stop AI misuse completely, we&#x27;ll have to manage it, and learn quickly.</div><br/></div></div><div id="35820046" class="c"><input type="checkbox" id="c-35820046" checked=""/><div class="controls bullet"><span class="by">MetaWhirledPeas</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819287">prev</a><span>|</span><a href="#35819301">next</a><span>|</span><label class="collapse" for="c-35820046">[-]</label><label class="expand" for="c-35820046">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Linux won in servers and supercomputing, but not in end user computing.<p>Pardon the side discussion, but I think this is because of a few things.<p>1. OS-exclusive &quot;killer apps&quot; (Office, anything that integrates with an iPhone)<p>2. Games<p>The killer apps have better alternatives now, and games are starting to work better on Linux. Microsoft&#x27;s business model no longer requires everyone to use Windows. (Mac is another story.) So I think that, at least for non-Macolytes, Linux end user dominance is certainly on the horizon.</div><br/><div id="35821218" class="c"><input type="checkbox" id="c-35821218" checked=""/><div class="controls bullet"><span class="by">importantbrian</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820046">parent</a><span>|</span><a href="#35820875">next</a><span>|</span><label class="collapse" for="c-35821218">[-]</label><label class="expand" for="c-35821218">[1 more]</label></div><br/><div class="children"><div class="content">Linux did kind of win for end user computing. Android is based on a modified linux kernel.</div><br/></div></div><div id="35820875" class="c"><input type="checkbox" id="c-35820875" checked=""/><div class="controls bullet"><span class="by">flerchin</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820046">parent</a><span>|</span><a href="#35821218">prev</a><span>|</span><a href="#35819301">next</a><span>|</span><label class="collapse" for="c-35820875">[-]</label><label class="expand" for="c-35820875">[1 more]</label></div><br/><div class="children"><div class="content">This year is the year of the Linux Desktop!<p>I kid. I&#x27;ve been primarily a Linux Desktop user for 20 years.</div><br/></div></div></div></div><div id="35819301" class="c"><input type="checkbox" id="c-35819301" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35820046">prev</a><span>|</span><a href="#35819039">next</a><span>|</span><label class="collapse" for="c-35819301">[-]</label><label class="expand" for="c-35819301">[7 more]</label></div><br/><div class="children"><div class="content">If you think you can use GPT-4 then you don&#x27;t know what you&#x27;re talking about.<p>API access is on waitlist.<p>UI has limit of 25 messages in 3 hours.<p>If you think big, known companies can get ahead of the waitlist and use it - short answer is no, they can&#x27;t because of their IP. Nobody is going to sign off leaking out all internal knowledge to play with something.<p>ClosedAI seems to have big problem with capacity.<p>Those poems about your colleague&#x27;s upcoming birthday do burn a lot of GPU cycles.</div><br/><div id="35820103" class="c"><input type="checkbox" id="c-35820103" checked=""/><div class="controls bullet"><span class="by">realusername</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819301">parent</a><span>|</span><a href="#35821509">next</a><span>|</span><label class="collapse" for="c-35820103">[-]</label><label class="expand" for="c-35820103">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s also why I think OpenAI is in a tough spot in the long run. They just threw as much expensive hardware as they could to build this moat. There&#x27;s basically two things which can happen from now on:<p>- Some scalability breakthrough will appear, if that&#x27;s the case their moat disappears pretty much instantly and the cost of LLMs will plunge close to zero being a commodity. That&#x27;s the future I&#x27;m betting on from what&#x27;s happening now.<p>- No scalability breakthrough will appear and then it means that they will have a hard time to expand further as seen as the gpt4 limited access.<p>Either way, they are in a tough spot.</div><br/></div></div><div id="35821509" class="c"><input type="checkbox" id="c-35821509" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819301">parent</a><span>|</span><a href="#35820103">prev</a><span>|</span><a href="#35823826">next</a><span>|</span><label class="collapse" for="c-35821509">[-]</label><label class="expand" for="c-35821509">[1 more]</label></div><br/><div class="children"><div class="content">Big, known companies are <i>already</i> getting their GPT-4 fix via Azure OpenAI Service, where they can get meaningful guarantees for their data, and even on-prem if they really want it.</div><br/></div></div><div id="35823826" class="c"><input type="checkbox" id="c-35823826" checked=""/><div class="controls bullet"><span class="by">computerex</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819301">parent</a><span>|</span><a href="#35821509">prev</a><span>|</span><a href="#35820011">next</a><span>|</span><label class="collapse" for="c-35823826">[-]</label><label class="expand" for="c-35823826">[1 more]</label></div><br/><div class="children"><div class="content">We have gpt-4 deployed to production being used by fortune 100 labels.</div><br/></div></div><div id="35820011" class="c"><input type="checkbox" id="c-35820011" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819301">parent</a><span>|</span><a href="#35823826">prev</a><span>|</span><a href="#35819039">next</a><span>|</span><label class="collapse" for="c-35820011">[-]</label><label class="expand" for="c-35820011">[3 more]</label></div><br/><div class="children"><div class="content">Pretty easy to get API access, I got it within a few days. Aware this is a sample of one, but also can’t believe they fast tracked me.</div><br/><div id="35820187" class="c"><input type="checkbox" id="c-35820187" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820011">parent</a><span>|</span><a href="#35819039">next</a><span>|</span><label class="collapse" for="c-35820187">[-]</label><label class="expand" for="c-35820187">[2 more]</label></div><br/><div class="children"><div class="content">It took me several weeks to get access. I just got it today.</div><br/><div id="35821098" class="c"><input type="checkbox" id="c-35821098" checked=""/><div class="controls bullet"><span class="by">dwringer</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35820187">parent</a><span>|</span><a href="#35819039">next</a><span>|</span><label class="collapse" for="c-35821098">[-]</label><label class="expand" for="c-35821098">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been waiting a little over a month with no update so far, but I don&#x27;t expect any sort of fast track since I&#x27;m not currently a paying customer.</div><br/></div></div></div></div></div></div></div></div><div id="35819039" class="c"><input type="checkbox" id="c-35819039" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819301">prev</a><span>|</span><a href="#35822514">next</a><span>|</span><label class="collapse" for="c-35819039">[-]</label><label class="expand" for="c-35819039">[3 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Linux won in servers and supercomputing, but not in end user computing</i><p>&quot;End user computing&quot; these days means mobile, and mobile is dominated by Linux (in Apple&#x27;s case BSD, but we&#x27;re splitting hair) and Chrome&#x2F;WebKit - which began as KHTML.<p>The only area where opensource failed is the desktop, and that&#x27;s also because of Microsoft&#x27;s skill in defending their moats.</div><br/><div id="35819197" class="c"><input type="checkbox" id="c-35819197" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819039">parent</a><span>|</span><a href="#35822514">next</a><span>|</span><label class="collapse" for="c-35819197">[-]</label><label class="expand" for="c-35819197">[2 more]</label></div><br/><div class="children"><div class="content">The kernel isn&#x27;t the OS&#x2F;environment.  Distiling iOS to BSD is just not useful in the context of this discussion.</div><br/><div id="35821901" class="c"><input type="checkbox" id="c-35821901" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819197">parent</a><span>|</span><a href="#35822514">next</a><span>|</span><label class="collapse" for="c-35821901">[-]</label><label class="expand" for="c-35821901">[1 more]</label></div><br/><div class="children"><div class="content">The kernel is absolutely the OS, the desktop environment is an interface to it.</div><br/></div></div></div></div></div></div><div id="35822514" class="c"><input type="checkbox" id="c-35822514" checked=""/><div class="controls bullet"><span class="by">alfor</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819039">prev</a><span>|</span><a href="#35822395">next</a><span>|</span><label class="collapse" for="c-35822514">[-]</label><label class="expand" for="c-35822514">[3 more]</label></div><br/><div class="children"><div class="content">How can a company keep up with the speed of what is happening in the open?<p>Open AI had years of advanced that almost vanished in a few months.<p>And we will see the rise of specialized models, smaller but targeted, working in team, delegating (Hugging GPT)<p>I would use a small and fast model that only speak english, is expert at coding an science and not much more. Then you fire up an question to another model if yours is out of it’s area.</div><br/><div id="35824918" class="c"><input type="checkbox" id="c-35824918" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35822514">parent</a><span>|</span><a href="#35822395">next</a><span>|</span><label class="collapse" for="c-35824918">[-]</label><label class="expand" for="c-35824918">[2 more]</label></div><br/><div class="children"><div class="content">Will the average use know or want to use different models when they can just go to ChatGPT?</div><br/><div id="35829574" class="c"><input type="checkbox" id="c-35829574" checked=""/><div class="controls bullet"><span class="by">usrbinbash</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35824918">parent</a><span>|</span><a href="#35822395">next</a><span>|</span><label class="collapse" for="c-35829574">[-]</label><label class="expand" for="c-35829574">[1 more]</label></div><br/><div class="children"><div class="content">The average user won&#x27;t have to care when these models run as part of whatever app he is using on his device, or on the server his app uses as a backend.<p>Look at the first uses of StableDiffusion. It was either &quot;you know python or you use Dall-E&quot;. Now we have one-click installers setting everything up, and nice user interfaces on top of it.</div><br/></div></div></div></div></div></div><div id="35822395" class="c"><input type="checkbox" id="c-35822395" checked=""/><div class="controls bullet"><span class="by">amon22</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35822514">prev</a><span>|</span><a href="#35819531">next</a><span>|</span><label class="collapse" for="c-35822395">[-]</label><label class="expand" for="c-35822395">[1 more]</label></div><br/><div class="children"><div class="content">&gt; users will go to whoever has the best model<p>Not me, I refuse to use OpenAI products but I do sometimes use vicuna 13b when I&#x27;m coding C. It&#x27;s pretty good and I&#x27;m happy to see the rapid advancement of open source LLMs. It gives me hope for the future.<p>&gt; Linux won in servers and supercomputing, but not in end user computing.<p>I use linux on all of my computers and I love it, many of us do (obviously). I&#x27;m aware that I&#x27;m a small minority even among other developers but I think looking at just statistics misses the point. Even if the majority will just use the most approachable tool (and there is nothing wrong with that), it&#x27;s important to have an alternative. For me this is the point of open software, not market domination or whatever.</div><br/></div></div><div id="35819531" class="c"><input type="checkbox" id="c-35819531" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35822395">prev</a><span>|</span><a href="#35819343">next</a><span>|</span><label class="collapse" for="c-35819531">[-]</label><label class="expand" for="c-35819531">[1 more]</label></div><br/><div class="children"><div class="content">None of the models will &quot;win&quot; because it is just a foundation. Google won because they leveeraged the linux ecosystem to build a monetizable business with a moat on top of it. The real moat will be some specific application on top of LLMs</div><br/></div></div><div id="35819343" class="c"><input type="checkbox" id="c-35819343" checked=""/><div class="controls bullet"><span class="by">ilyt</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819531">prev</a><span>|</span><a href="#35822961">next</a><span>|</span><label class="collapse" for="c-35819343">[-]</label><label class="expand" for="c-35819343">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The point I&#x27;m wanting to make is that users will go to whoever has the best model. So, the winning strategy is whatever strategy allows your model to compound in quality faster and to continue to compound that growth in quality for longer.<p>Best only works till second best is &quot;close enough&quot; and cheaper&#x2F;free</div><br/><div id="35819661" class="c"><input type="checkbox" id="c-35819661" checked=""/><div class="controls bullet"><span class="by">bilbo0s</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819343">parent</a><span>|</span><a href="#35822961">next</a><span>|</span><label class="collapse" for="c-35819661">[-]</label><label class="expand" for="c-35819661">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s likely they will all be free in time. That&#x27;s kind of the problem underlying the consternation here.<p>It&#x27;s the internet all over again. How do you win the race to the bottom?<p>Once there<p>How do you compete effectively with free? Microsoft and Amazon will have billions on billions coming in to float their free offerings for what is effectively eternity in business terms. Probably Google and Meta will as well. What happens to everyone else?<p>I think you have to be in some niche market where you can charge. Because for everyone else, free is unsustainable.<p>Porn maybe? But there will be way too many competitors there. So something more like medical. Or semiconductors. Or construction or something.</div><br/><div id="35821274" class="c"><input type="checkbox" id="c-35821274" checked=""/><div class="controls bullet"><span class="by">ilyt</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819661">parent</a><span>|</span><a href="#35822961">next</a><span>|</span><label class="collapse" for="c-35821274">[-]</label><label class="expand" for="c-35821274">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s likely they will all be free in time. That&#x27;s kind of the problem underlying the consternation here.<p>That what I was getting to. Paid only makes sense if you&#x27;re willing to provide stuff that OSS lacks, which is either &quot;super specialized things not many people want to OSS&quot; or, well good looking UI... (there seem to be massive lack of any UI&#x2F;UX people vs developers in near anything OSS).<p>AI is neither so it will be commoditized and mostly run in few OSS projects, and <i>probably</i> for the best, the only thing worse than anyone having access to &quot;near free copywriter bot that will write about anything you tell it to&quot; is only people with money having access and control over it.</div><br/></div></div></div></div></div></div><div id="35822961" class="c"><input type="checkbox" id="c-35822961" checked=""/><div class="controls bullet"><span class="by">mesh</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819343">prev</a><span>|</span><a href="#35821316">next</a><span>|</span><label class="collapse" for="c-35822961">[-]</label><label class="expand" for="c-35822961">[2 more]</label></div><br/><div class="children"><div class="content">&gt;The point I&#x27;m wanting to make is that users will go to whoever has the best model.<p>Best isn&#x27;t defined just by quality though. In some instances for some groups, things like whether the model is trained on licensed content (with permission) and &#x2F; or is safe for commercial use is more important.<p>This is one reason why Adobe&#x27;s Firefly has been received relatively well. (I work for Adobe).</div><br/><div id="35827828" class="c"><input type="checkbox" id="c-35827828" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35822961">parent</a><span>|</span><a href="#35821316">next</a><span>|</span><label class="collapse" for="c-35827828">[-]</label><label class="expand" for="c-35827828">[1 more]</label></div><br/><div class="children"><div class="content">Adobe Firefly can&#x27;t be run locally and Adobe knows everything that their users generate. I can&#x27;t train my own LoRAs or checkpoints. Adobe also has proven that they can&#x27;t keep the data of their users secure. Which is why it&#x27;s better to use something else.</div><br/></div></div></div></div><div id="35821316" class="c"><input type="checkbox" id="c-35821316" checked=""/><div class="controls bullet"><span class="by">randomdata</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35822961">prev</a><span>|</span><a href="#35828836">next</a><span>|</span><label class="collapse" for="c-35821316">[-]</label><label class="expand" for="c-35821316">[3 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Linux won in servers and supercomputing, but not in end user computing.</i><p>It seems just about every computing appliance in my home runs Linux. Then you have Android, ChromeOS, etc. which are also quite popular with end users, the first one especially. It may not have won, but I think it is safe to say that it is dominating.</div><br/><div id="35821570" class="c"><input type="checkbox" id="c-35821570" checked=""/><div class="controls bullet"><span class="by">jononor</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821316">parent</a><span>|</span><a href="#35828836">next</a><span>|</span><label class="collapse" for="c-35821570">[-]</label><label class="expand" for="c-35821570">[2 more]</label></div><br/><div class="children"><div class="content">Appliances are not end user computing, but embedded computing - the OS is incidental and under full control of the manufacturer.
Some might argue that even mobile phones are not sufficiently under the control of end users to qualify.</div><br/><div id="35821937" class="c"><input type="checkbox" id="c-35821937" checked=""/><div class="controls bullet"><span class="by">randomdata</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821570">parent</a><span>|</span><a href="#35828836">next</a><span>|</span><label class="collapse" for="c-35821937">[-]</label><label class="expand" for="c-35821937">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Appliances are not end user computing</i><p>They are when the end user is using them. Think things like TVs or even thermostats.<p><i>&gt; the OS is incidental and under full control of the manufacturer.</i><p>For all intents and purposes Linux <i>has</i> won where those conditions aren’t met.</div><br/></div></div></div></div></div></div><div id="35828836" class="c"><input type="checkbox" id="c-35828836" checked=""/><div class="controls bullet"><span class="by">aws_ls</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35821316">prev</a><span>|</span><a href="#35820910">next</a><span>|</span><label class="collapse" for="c-35828836">[-]</label><label class="expand" for="c-35828836">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Linux won in servers and supercomputing, but not in end user computing<p>Android is based on Linux.</div><br/></div></div><div id="35820910" class="c"><input type="checkbox" id="c-35820910" checked=""/><div class="controls bullet"><span class="by">tontomath</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35828836">prev</a><span>|</span><a href="#35819339">next</a><span>|</span><label class="collapse" for="c-35820910">[-]</label><label class="expand" for="c-35820910">[1 more]</label></div><br/><div class="children"><div class="content">I think that pouring a lot of money in open source, by bounties or crowdfunding can accelerate open source alternatives to closed LLMs. Perhaps a middle way in which software will be declared open source six month from now can give enough compensation to those institutions contributing big money for developing LLM technology. That is a crowdfunding in which the great contributors have a limited time to be compensated, but capping the total prize just like that of chatgpt 3.5 or 4 depending of the model.</div><br/></div></div><div id="35819339" class="c"><input type="checkbox" id="c-35819339" checked=""/><div class="controls bullet"><span class="by">nabakin</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35820910">prev</a><span>|</span><a href="#35821600">next</a><span>|</span><label class="collapse" for="c-35819339">[-]</label><label class="expand" for="c-35819339">[1 more]</label></div><br/><div class="children"><div class="content">I think the best situation is when a company will perform an expensive but high value task that the open source community can&#x27;t and then give it back to them for further iterations and development. If the community isn&#x27;t able to perform a high value task again, a company steps in, does it, and gives it back to the community to restart the process.<p>In this way, everyone&#x27;s skills are being leveraged to innovate at a rapid pace.</div><br/></div></div><div id="35821600" class="c"><input type="checkbox" id="c-35821600" checked=""/><div class="controls bullet"><span class="by">kashkhan</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35819339">prev</a><span>|</span><a href="#35821397">next</a><span>|</span><label class="collapse" for="c-35821600">[-]</label><label class="expand" for="c-35821600">[1 more]</label></div><br/><div class="children"><div class="content">aren&#x27;t androids linux? thats the biggest by far end user platform.<p>of course google doesnt want to acknowledge it too much.<p><a href="https:&#x2F;&#x2F;source.android.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;source.android.com&#x2F;</a></div><br/></div></div><div id="35821397" class="c"><input type="checkbox" id="c-35821397" checked=""/><div class="controls bullet"><span class="by">quijoteuniv</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35821600">prev</a><span>|</span><a href="#35824590">next</a><span>|</span><label class="collapse" for="c-35821397">[-]</label><label class="expand" for="c-35821397">[3 more]</label></div><br/><div class="children"><div class="content">This is what happened with kubernetes no? Open source was about to take over so google release the code not to loose out.</div><br/><div id="35823934" class="c"><input type="checkbox" id="c-35823934" checked=""/><div class="controls bullet"><span class="by">rektide</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35821397">parent</a><span>|</span><a href="#35824590">next</a><span>|</span><label class="collapse" for="c-35823934">[-]</label><label class="expand" for="c-35823934">[2 more]</label></div><br/><div class="children"><div class="content">Worthy to note, it seems like there were some incredibly dedicated hardworking engineers that drove extremely hard for a really long time to make this happen.<p>They did manage to get large buy in from the company after quite a significant journey. But it seems so much like a kind of outside event, something begat &amp; pushed for not because it was a smart top down move, but because a couple super driven engineers made it their cause.</div><br/><div id="35824796" class="c"><input type="checkbox" id="c-35824796" checked=""/><div class="controls bullet"><span class="by">asadotzler</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35823934">parent</a><span>|</span><a href="#35824590">next</a><span>|</span><label class="collapse" for="c-35824796">[-]</label><label class="expand" for="c-35824796">[1 more]</label></div><br/><div class="children"><div class="content">I see this often. We didn&#x27;t document our efforts well at <i>creating</i> the OSS ecosystem that youngsters take for granted today.  They attribute the efforts of some thousands of advocates that made all this happen to &quot;market forces&quot; or some other nonsense. OSS exists because some really dedicated hackers and their allies spent years of mostly unrewarded effort making it happen.</div><br/></div></div></div></div></div></div><div id="35824590" class="c"><input type="checkbox" id="c-35824590" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35821397">prev</a><span>|</span><a href="#35819058">next</a><span>|</span><label class="collapse" for="c-35824590">[-]</label><label class="expand" for="c-35824590">[1 more]</label></div><br/><div class="children"><div class="content">What?<p>No, what the article <i>said</i> was:<p>&gt; At that pace, it doesn’t take long before the cumulative effect of all of these fine-tunings overcomes starting off at a size disadvantage.<p>&gt;Indeed, in terms of engineer-hours, the pace of improvement from these models vastly outstrips what we can do with our largest variants, and<p>&gt; the best are already largely indistinguishable from ChatGPT.<p>^ The author did not note chat gpt is better, the author claims that the 7B koala model is &#x27;largely indistinguishable from ChatGPT&#x27;.<p>and:<p>&gt; While ChatGPT still holds a slight edge, more than 50% of the time users either prefer Koala or have no preference.<p>Which is highly misleading.<p>The <i>koala authors</i> rated their model by passing it to 100 people using the mechanical turk, noting:<p>&gt; To mitigate possible test-set leakage, we filtered out queries that have a BLEU score greater than 20% with any example from our training set. Additionally, we removed non-English and coding-related prompts, since responses to these queries cannot be reliably reviewed by our pool of raters (crowd workers).<p>So.<p>What you have is a model that performs pretty well for some trivial conversational prompting tasks.<p>What you DO NOT have, is something that is: &quot;largely indistinguishable from ChatGPT&quot;.<p>Anyway, regardless of the creative interpretation of the authors writing, the point that I&#x27;m making is that your point:<p>&gt; So, the winning strategy is whatever strategy allows your model to compound in quality faster and to continue to compound that growth in quality for longer.<p>Is founded on the assumption from the post that:<p>&gt; While the individual fine tunings are low rank, their sum need not be, allowing full-rank updates to the model to accumulate over time.<p>ie. If you fine tune it enough, it&#x27;ll get better and better <i>in an unlimited</i> fashion.<p>Which is provably false.<p>If I have a 10-parameter model, there is <i>no possible way</i> that the accumulation of low rank fine tunings will make it the equivalent of a 7B, 13B of 135B model.<p>It is simply not complex enough to do some tasks.<p><i>Similarly</i>, smaller models like 3B or 7B model, appear to have an upper bound on what is possible to achieve with them <i>regardless of the number of fine tunings applied to them</i>, for the direct and obvious same reason.<p>There is an <i>upper bound</i> on what is possible, based on the model size.<p>The &#x27;best&#x27; size for a model hasn&#x27;t really been figured out, but... I&#x27;m getting pretty sick of people saying these 7B models are as good as &#x27;ChatGPT&#x27;.<p>They. Are. Not.<p>People <i>will</i> go to the best models, with the best licenses, but... those models are, it seems, unlikely to be fine tuned smallish models.</div><br/></div></div><div id="35819058" class="c"><input type="checkbox" id="c-35819058" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#35818774">parent</a><span>|</span><a href="#35824590">prev</a><span>|</span><a href="#35820873">next</a><span>|</span><label class="collapse" for="c-35819058">[-]</label><label class="expand" for="c-35819058">[6 more]</label></div><br/><div class="children"><div class="content">GPT4 sucks for many use cases because it&#x27;s SLOW. It will co-exist with ChatGPT variants.</div><br/><div id="35819632" class="c"><input type="checkbox" id="c-35819632" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819058">parent</a><span>|</span><a href="#35820990">next</a><span>|</span><label class="collapse" for="c-35819632">[-]</label><label class="expand" for="c-35819632">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s quite fast if you use it at ~4 AM in the US.  There&#x27;s definitely a cycle in time.  Putting things in a queue to run while you sleep is a good work around.</div><br/></div></div><div id="35820990" class="c"><input type="checkbox" id="c-35820990" checked=""/><div class="controls bullet"><span class="by">yesimahuman</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819058">parent</a><span>|</span><a href="#35819632">prev</a><span>|</span><a href="#35819349">next</a><span>|</span><label class="collapse" for="c-35820990">[-]</label><label class="expand" for="c-35820990">[1 more]</label></div><br/><div class="children"><div class="content">Yea 3.5 is more than good enough for a whole slew of tasks (especially code), and it&#x27;s ridiculously fast. I rarely find the need to use 4 but certainly if there was a usecase it was significantly better at that mattered to me, I would.</div><br/></div></div><div id="35819349" class="c"><input type="checkbox" id="c-35819349" checked=""/><div class="controls bullet"><span class="by">happycube</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819058">parent</a><span>|</span><a href="#35820990">prev</a><span>|</span><a href="#35819326">next</a><span>|</span><label class="collapse" for="c-35819349">[-]</label><label class="expand" for="c-35819349">[1 more]</label></div><br/><div class="children"><div class="content">And far more expensive than ChatGPT via API, so it makes sense to use ChatGPT3.5, or the locally run equivalents once they get as good, as much as possible.</div><br/></div></div><div id="35819326" class="c"><input type="checkbox" id="c-35819326" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819058">parent</a><span>|</span><a href="#35819349">prev</a><span>|</span><a href="#35820873">next</a><span>|</span><label class="collapse" for="c-35819326">[-]</label><label class="expand" for="c-35819326">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s about using the right tool for the right job. GPT-4 is an incredibly versatile generalist tool and a fantastic jack of all trades. However, this comes with some drawbacks. While saying it &#x27;sucks&#x27; might be an exaggeration, I generally concur with the point you&#x27;re making.</div><br/><div id="35821075" class="c"><input type="checkbox" id="c-35821075" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#35818774">root</a><span>|</span><a href="#35819326">parent</a><span>|</span><a href="#35820873">next</a><span>|</span><label class="collapse" for="c-35821075">[-]</label><label class="expand" for="c-35821075">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s no exaggeration that it sucks for certain use cases where you would expect and can achieve near-realtime response, and that&#x27;s fine because it&#x27;s not built for that use case. I&#x27;m responding to someone saying it&#x27;s always best if you can afford it</div><br/></div></div></div></div></div></div></div></div><div id="35819312" class="c"><input type="checkbox" id="c-35819312" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#35818774">prev</a><span>|</span><a href="#35827160">next</a><span>|</span><label class="collapse" for="c-35819312">[-]</label><label class="expand" for="c-35819312">[19 more]</label></div><br/><div class="children"><div class="content">Fantastic article if you are quick to just go to the comments like I usually do, don&#x27;t. Read it.<p>One of my favorites: 
LoRA works by representing model updates as low-rank factorizations, which reduces the size of the update matrices by a factor of up to several thousand. This allows model fine-tuning at a fraction of the cost and time. Being able to personalize a language model in a few hours on consumer hardware is a big deal, particularly for aspirations that involve incorporating new and diverse knowledge in near real-time. The fact that this technology exists is underexploited inside Google, even though it directly impacts some of our most ambitious projects.<p>Anyone has worked with LoRa ? Sounds super interesting.</div><br/><div id="35820872" class="c"><input type="checkbox" id="c-35820872" checked=""/><div class="controls bullet"><span class="by">eulers_secret</span><span>|</span><a href="#35819312">parent</a><span>|</span><a href="#35819999">next</a><span>|</span><label class="collapse" for="c-35820872">[-]</label><label class="expand" for="c-35820872">[12 more]</label></div><br/><div class="children"><div class="content">If you use the web interface (oobabooga), then training a LoRa is as easy as clicking the &quot;training&quot; tab, keeping all the defaults, and giving it a flat text file of your data. The defaults are sane enough to not begin undermining any instruction tuning too much. Takes 3-5 hours on a 3080 for 7B, 4bit model (and ~1KWh).<p>So far I&#x27;ve trained 3: 2 on the entire text of ASOIAF (converted from e-books) and 1 on the Harry Potter series. I can ask questions like &quot;tell me a story about a long winter in Westeros&quot; and get something in the &quot;voice&quot; of GRRM and with real references to the text. It can write HP fanfics all day long. My favorite so far was the assistant self-inserting into a story with Jon Snow, complete with &quot;The Assistant has much data for you. Please wait while it fetches it.&quot; and actually having a conversation with Jon.<p>Asking specific questions is way more of a miss (e.x. &quot;Who are Jon Snow&#x27;s real parents?&quot; returns total BS), but that may be because my 3080 is too weak to train anything other than 7B models in 4bit (which is only supported with hacked patches). I used Koala as my base model.<p>I&#x27;m getting close to dropping $1600 on a 4090, but I should find employment first... but then I&#x27;ll have less time to mess with it.</div><br/><div id="35823665" class="c"><input type="checkbox" id="c-35823665" checked=""/><div class="controls bullet"><span class="by">se4u</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820872">parent</a><span>|</span><a href="#35821238">next</a><span>|</span><label class="collapse" for="c-35823665">[-]</label><label class="expand" for="c-35823665">[2 more]</label></div><br/><div class="children"><div class="content">I am surprised that people aren&#x27;t using google colab pro&#x2F;pro+ in this context. You basically get access to multiple A100 for $10&#x2F;month and with some simple javascript tricks, you can get a session to last for 24hrs at least.<p>Pro+ is more expensive at $50&#x2F;mo but it allows for more simplified background execution. if you are only just getting started and don&#x27;t expect to be training for multiple months, then colab or other cloud-notebook providers are really great to start.</div><br/><div id="35824256" class="c"><input type="checkbox" id="c-35824256" checked=""/><div class="controls bullet"><span class="by">addandsubtract</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35823665">parent</a><span>|</span><a href="#35821238">next</a><span>|</span><label class="collapse" for="c-35824256">[-]</label><label class="expand" for="c-35824256">[1 more]</label></div><br/><div class="children"><div class="content">Google has recently limited the pro plan to 100 compute units per month. Using an A100 on colab burns 13 units an hour. So you could be out of units within 8 hours. Not really the $10&#x2F;month deal you&#x27;re looking for.</div><br/></div></div></div></div><div id="35821238" class="c"><input type="checkbox" id="c-35821238" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820872">parent</a><span>|</span><a href="#35823665">prev</a><span>|</span><a href="#35821156">next</a><span>|</span><label class="collapse" for="c-35821238">[-]</label><label class="expand" for="c-35821238">[3 more]</label></div><br/><div class="children"><div class="content">Used 3090 are getting really cheaps on the second hand market.  
Then if you only need VRAM, the Tesla M40 are even cheaper at 100€ per unit, which has 24GB of VRAM.</div><br/><div id="35822848" class="c"><input type="checkbox" id="c-35822848" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35821238">parent</a><span>|</span><a href="#35821156">next</a><span>|</span><label class="collapse" for="c-35822848">[-]</label><label class="expand" for="c-35822848">[2 more]</label></div><br/><div class="children"><div class="content">The M40 does not support 4bit, so it&#x27;s basically useless for LLMs.<p>The P40 24GB is only $200, supports 4bit, and is about 80% the speed of a 3090 (surprisingly) for LLM purposes.</div><br/><div id="35826696" class="c"><input type="checkbox" id="c-35826696" checked=""/><div class="controls bullet"><span class="by">awestroke</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35822848">parent</a><span>|</span><a href="#35821156">next</a><span>|</span><label class="collapse" for="c-35826696">[-]</label><label class="expand" for="c-35826696">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the catch?</div><br/></div></div></div></div></div></div><div id="35821156" class="c"><input type="checkbox" id="c-35821156" checked=""/><div class="controls bullet"><span class="by">Tiktaalik</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820872">parent</a><span>|</span><a href="#35821238">prev</a><span>|</span><a href="#35821609">next</a><span>|</span><label class="collapse" for="c-35821156">[-]</label><label class="expand" for="c-35821156">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s really interesting.<p>I guess it would do really well with world building lore type stuff, being able to go into great depth about the Brackens vs the Blackwoods but would struggle at the sort of subtext that even human readers may have missed (eg. who poisoned Tywin? and as you said, who are Jon Snow&#x27;s parents?)</div><br/></div></div><div id="35821609" class="c"><input type="checkbox" id="c-35821609" checked=""/><div class="controls bullet"><span class="by">sbrother</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820872">parent</a><span>|</span><a href="#35821156">prev</a><span>|</span><a href="#35821071">next</a><span>|</span><label class="collapse" for="c-35821609">[-]</label><label class="expand" for="c-35821609">[2 more]</label></div><br/><div class="children"><div class="content">Will it distribute training across multiple GFX cards? I have a 4x 2080Ti box I would love to be able to use for this sort of thing.</div><br/><div id="35821919" class="c"><input type="checkbox" id="c-35821919" checked=""/><div class="controls bullet"><span class="by">eulers_secret</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35821609">parent</a><span>|</span><a href="#35821071">next</a><span>|</span><label class="collapse" for="c-35821919">[-]</label><label class="expand" for="c-35821919">[1 more]</label></div><br/><div class="children"><div class="content">Not for training with the webui: <a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;issues&#x2F;1107">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;issues&#x2F;11...</a><p>It does seem to work using alpca-lora directly, though.</div><br/></div></div></div></div><div id="35821071" class="c"><input type="checkbox" id="c-35821071" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820872">parent</a><span>|</span><a href="#35821609">prev</a><span>|</span><a href="#35819999">next</a><span>|</span><label class="collapse" for="c-35821071">[-]</label><label class="expand" for="c-35821071">[3 more]</label></div><br/><div class="children"><div class="content">how much memory does the 7B training need?</div><br/><div id="35821158" class="c"><input type="checkbox" id="c-35821158" checked=""/><div class="controls bullet"><span class="by">eulers_secret</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35821071">parent</a><span>|</span><a href="#35819999">next</a><span>|</span><label class="collapse" for="c-35821158">[-]</label><label class="expand" for="c-35821158">[2 more]</label></div><br/><div class="children"><div class="content">~7.5GB - it&#x27;ll be the same as running inference with a full context. That&#x27;s for 4-bit quantization, the 8-bit quantization uses more RAM than my 3080 has...</div><br/><div id="35821187" class="c"><input type="checkbox" id="c-35821187" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35821158">parent</a><span>|</span><a href="#35819999">next</a><span>|</span><label class="collapse" for="c-35821187">[-]</label><label class="expand" for="c-35821187">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how much it would take to train the 4b 13B</div><br/></div></div></div></div></div></div></div></div><div id="35819999" class="c"><input type="checkbox" id="c-35819999" checked=""/><div class="controls bullet"><span class="by">adroitboss</span><span>|</span><a href="#35819312">parent</a><span>|</span><a href="#35820872">prev</a><span>|</span><a href="#35820590">next</a><span>|</span><label class="collapse" for="c-35819999">[-]</label><label class="expand" for="c-35819999">[1 more]</label></div><br/><div class="children"><div class="content">You can find the guy who created it on reddit u&#x2F;edwardjhu. I remember because he showed up in the Stable Diffusion Subreddit.  <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1223y27&#x2F;im_the_creator_of_lora_how_can_i_make_it_better&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1223y27&#x2F;im...</a></div><br/></div></div><div id="35820590" class="c"><input type="checkbox" id="c-35820590" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35819312">parent</a><span>|</span><a href="#35819999">prev</a><span>|</span><a href="#35822680">next</a><span>|</span><label class="collapse" for="c-35820590">[-]</label><label class="expand" for="c-35820590">[4 more]</label></div><br/><div class="children"><div class="content">If i understand correctly it is also shockingly simple, basically just the first figure in the paper: <a href="https:&#x2F;&#x2F;miro.medium.com&#x2F;v2&#x2F;resize:fit:730&#x2F;1*D_i25E9dTd_5HMa45zITSg.png" rel="nofollow">https:&#x2F;&#x2F;miro.medium.com&#x2F;v2&#x2F;resize:fit:730&#x2F;1*D_i25E9dTd_5HMa4...</a><p>train 2 matrices, add their product to the pretrained weights, and voila! Someone correct me if i m wrong</div><br/><div id="35824150" class="c"><input type="checkbox" id="c-35824150" checked=""/><div class="controls bullet"><span class="by">xkgt</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35820590">parent</a><span>|</span><a href="#35822680">next</a><span>|</span><label class="collapse" for="c-35824150">[-]</label><label class="expand" for="c-35824150">[3 more]</label></div><br/><div class="children"><div class="content">Correct me if I am wrong, to use LORA fine-tuned model in inference you would still need the original model + trained additional layers, right?<p>If we can perfect methods to fine-tune large models for specific task while reducing the overall model size, then it can fit into more consumer grade hardware for inference and can be broadly used. The objective is to prune unnecessary trivia and memorization artifacts from the model and leverage LLMs purely for interpreting natural language inputs.</div><br/><div id="35826557" class="c"><input type="checkbox" id="c-35826557" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35824150">parent</a><span>|</span><a href="#35824882">next</a><span>|</span><label class="collapse" for="c-35826557">[-]</label><label class="expand" for="c-35826557">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  to use LORA fine-tuned model in inference you would still need the original model + trained additional layers, right?<p>You don&#x27;t need additional layers. After training, the product of the two matrices is added to the original weights matrix, so the model size remains the same as the original during inference.</div><br/></div></div><div id="35824882" class="c"><input type="checkbox" id="c-35824882" checked=""/><div class="controls bullet"><span class="by">pavo-etc</span><span>|</span><a href="#35819312">root</a><span>|</span><a href="#35824150">parent</a><span>|</span><a href="#35826557">prev</a><span>|</span><a href="#35822680">next</a><span>|</span><label class="collapse" for="c-35824882">[-]</label><label class="expand" for="c-35824882">[1 more]</label></div><br/><div class="children"><div class="content">Yes you still require the original model weights to use LoRA layers. For many LLaMA based models you need to find the original weight yourself and then apply the LoRA diff on top of that.</div><br/></div></div></div></div></div></div><div id="35822680" class="c"><input type="checkbox" id="c-35822680" checked=""/><div class="controls bullet"><span class="by">Levitz</span><span>|</span><a href="#35819312">parent</a><span>|</span><a href="#35820590">prev</a><span>|</span><a href="#35827160">next</a><span>|</span><label class="collapse" for="c-35822680">[-]</label><label class="expand" for="c-35822680">[1 more]</label></div><br/><div class="children"><div class="content">I wholeheartedly second this. This article seems to me to be one important, small piece of text to read. It might very well end up somewhere in a history book someday.</div><br/></div></div></div></div><div id="35827160" class="c"><input type="checkbox" id="c-35827160" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35819312">prev</a><span>|</span><a href="#35819672">next</a><span>|</span><label class="collapse" for="c-35827160">[-]</label><label class="expand" for="c-35827160">[7 more]</label></div><br/><div class="children"><div class="content">Investors are obsessed with moats, but people have to realize that the entire world runs on business that have no moats.<p>There are no moats to being a plumber, a baker, a restaurant...<p>The moat concept is predominant because the idea that everything must make billions have infected the debate about businesses.<p>It&#x27;s all about being a unicorn, a giant, a monopoly, making every body at the top billionaires, and it&#x27;s like there is no other way to live.<p>Except that&#x27;s not how most people do live, even entrepreneurs.<p>Even Apple, which today is the typical example of a business with a moat, didn&#x27;t start with &quot;we can&#x27;t get into this computer business, we&#x27;d have no moat&quot;.<p>They have a moat now, but it&#x27;s a consequence of all the business decisions and the thing they built after many decades.<p>They didn&#x27;t start their project by the moat. The started their project by providing value and marketing it.</div><br/><div id="35828737" class="c"><input type="checkbox" id="c-35828737" checked=""/><div class="controls bullet"><span class="by">nologic01</span><span>|</span><a href="#35827160">parent</a><span>|</span><a href="#35828908">next</a><span>|</span><label class="collapse" for="c-35828737">[-]</label><label class="expand" for="c-35828737">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Investors are obsessed with moats<p>You can&#x27;t blame them: gratuitous moats (like those provided by winner-takes-all dynamics) are not common in a functioning (competitive) economy so they get to be revered.<p>It feels unlikely that the recent period of big tech can keep the same benefits going forward. It was basically a political moat: counting on the ongoing lack of antitrust and consumer protection regulation. Even if the political dysfunction that allows that continues (quite likely), the wheels of the universe are turning.<p>The &quot;leaked&quot; report focuses on open source - a mode of producing software that is bound to become a major disruptor. We tend to discount open source because of its humble beginnings, long incubation, many false dawns and difficult business models. But if you objectively take a look at what is possible today with open source software, its quite breathtaking. I would not discount some tectonic shifts in adoption. The long running joke is &quot;the year of the linux desktop&quot;, but keep adding open source AI and other related functionality and at some point the value proposition of open source computing (both for individuals and enterprises) will be crushingly large to ignore.<p>Don&#x27;t forget too, that other force of human nature: geopolitics (e.g., think TikTok and friends). The current &quot;moats&quot; were established during an earlier, more innocent era. Now digitization is a top priority &#x2F; concern for many countries. The idea that somebody can build a long-lived AI moat given the stakes is strange to say the least.</div><br/></div></div><div id="35828908" class="c"><input type="checkbox" id="c-35828908" checked=""/><div class="controls bullet"><span class="by">moberemk</span><span>|</span><a href="#35827160">parent</a><span>|</span><a href="#35828737">prev</a><span>|</span><a href="#35827705">next</a><span>|</span><label class="collapse" for="c-35828908">[-]</label><label class="expand" for="c-35828908">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There are no moats to being a plumber, a baker, a restaurant...<p>This line is interesting to me, because actually I think there _is_ a major moat there: locality. I don&#x27;t disagree with the rest of your comment, but for those examples specifically a lot of the value of specific instances of those business comes from their being in your neighborhood. If I live in Toronto, I&#x27;m not going to fly a plumber from Manhattan to fix my pipes; if I want a loaf of sourdough, I&#x27;m not going to get it from San Francisco, I&#x27;m going to get it from the bakery around the corner; I might travel out of town for a particularly unique and amazing restaurant, but not every week, I&#x27;ve got solid enough options within a ten minute drive. Software is different because that physical accessibility hurdle doesn&#x27;t exist.<p>Rest of this is spot-on though</div><br/><div id="35829622" class="c"><input type="checkbox" id="c-35829622" checked=""/><div class="controls bullet"><span class="by">hudon</span><span>|</span><a href="#35827160">root</a><span>|</span><a href="#35828908">parent</a><span>|</span><a href="#35827705">next</a><span>|</span><label class="collapse" for="c-35829622">[-]</label><label class="expand" for="c-35829622">[1 more]</label></div><br/><div class="children"><div class="content">What you&#x27;re describing is less a statement on moats and more a statement on markets. Plumbers in one location share the market (the potential clients in that area), and as the parent comment states, there is no moat in that given market. A moat is a barrier to compete within a given market. So if something made it really difficult for a new plumber to serve an already-served clientele, that would be a moat. But individuals on the other side of the planet are by physical encumbrance not actually clientele... they&#x27;re not even in the market.</div><br/></div></div></div></div><div id="35827705" class="c"><input type="checkbox" id="c-35827705" checked=""/><div class="controls bullet"><span class="by">nashashmi</span><span>|</span><a href="#35827160">parent</a><span>|</span><a href="#35828908">prev</a><span>|</span><a href="#35829079">next</a><span>|</span><label class="collapse" for="c-35827705">[-]</label><label class="expand" for="c-35827705">[1 more]</label></div><br/><div class="children"><div class="content">Shareholders gain pennies with moats, pennies that someone else does not earn. Without moats they benefit much more, but it&#x27;s not more than someone else.  And that&#x27;s the contentious issue. How would I benefit more than my neighbor?</div><br/></div></div><div id="35829079" class="c"><input type="checkbox" id="c-35829079" checked=""/><div class="controls bullet"><span class="by">mastax</span><span>|</span><a href="#35827160">parent</a><span>|</span><a href="#35827705">prev</a><span>|</span><a href="#35819672">next</a><span>|</span><label class="collapse" for="c-35829079">[-]</label><label class="expand" for="c-35829079">[2 more]</label></div><br/><div class="children"><div class="content">No reason to invest loads of capital unless you&#x27;re building a moat.</div><br/><div id="35838627" class="c"><input type="checkbox" id="c-35838627" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35827160">root</a><span>|</span><a href="#35829079">parent</a><span>|</span><a href="#35819672">next</a><span>|</span><label class="collapse" for="c-35838627">[-]</label><label class="expand" for="c-35838627">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but open ai is not an investor, it&#x27;s the company. They don&#x27;t have to follow this logic, they can build something without thinking of the moat, and succeed anyway.<p>The moat is a priority for rent seekers, but most successful builders didn&#x27;t start by that.<p>Coca cola, Mac Donald, Gillet and all the Buffet favorite children didn&#x27;t grow by thinking moat first. The moat was built on the way, sometimes very late.</div><br/></div></div></div></div></div></div><div id="35819672" class="c"><input type="checkbox" id="c-35819672" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#35827160">prev</a><span>|</span><a href="#35818328">next</a><span>|</span><label class="collapse" for="c-35819672">[-]</label><label class="expand" for="c-35819672">[6 more]</label></div><br/><div class="children"><div class="content">This gets attention due to being a leak, but it’s still just one Googler’s opinion and it has signs of being overstated for rhetorical effect.<p>In particular, demos aren’t the same as products. Running a demo on one person’s phone is an important milestone, but if the device overheats and&#x2F;or gets throttled then it’s not really something you’d want to run on your phone.<p>It’s easy to claim that a problem is “solved” with a link to a demo when actually there’s more to do. People can link to projects they didn’t actually investigate. They can claim “parity” because they tried one thing and were impressed. Figuring out if something works well takes more effort. Could you write a product review, or did you just hear about it, or try it once?<p>I haven’t investigated most projects either so I don’t know, but consider that things may not be moving quite as fast as demo-based hype indicates.</div><br/><div id="35820548" class="c"><input type="checkbox" id="c-35820548" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#35819672">parent</a><span>|</span><a href="#35818328">next</a><span>|</span><label class="collapse" for="c-35820548">[-]</label><label class="expand" for="c-35820548">[5 more]</label></div><br/><div class="children"><div class="content">It comes across as something from an open source enthusiast outside Google. Note the complete lack of references to monetization. Also, there&#x27;s no sense of how this fits with other Google products. Given a chat engine, what do you do with it? Integrate it with search? With Gmail? With Google Docs? LLMs by themselves are fun, but their use will be as components of larger systems.</div><br/><div id="35820624" class="c"><input type="checkbox" id="c-35820624" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#35819672">root</a><span>|</span><a href="#35820548">parent</a><span>|</span><a href="#35829953">next</a><span>|</span><label class="collapse" for="c-35820624">[-]</label><label class="expand" for="c-35820624">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but there are open source enthusiasts inside Google, too. People don’t necessarily change their opinions much when they start working at Google.</div><br/></div></div><div id="35829953" class="c"><input type="checkbox" id="c-35829953" checked=""/><div class="controls bullet"><span class="by">generalizations</span><span>|</span><a href="#35819672">root</a><span>|</span><a href="#35820548">parent</a><span>|</span><a href="#35820624">prev</a><span>|</span><a href="#35823592">next</a><span>|</span><label class="collapse" for="c-35829953">[-]</label><label class="expand" for="c-35829953">[1 more]</label></div><br/><div class="children"><div class="content">Honestly, it kinda fits my perception of Google, which is that they don&#x27;t really have good business sense for creating new products - they invent first, find applications after. This &#x27;leak&#x27; feels like it has that same kind of perspective.</div><br/></div></div><div id="35823592" class="c"><input type="checkbox" id="c-35823592" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#35819672">root</a><span>|</span><a href="#35820548">parent</a><span>|</span><a href="#35829953">prev</a><span>|</span><a href="#35826818">next</a><span>|</span><label class="collapse" for="c-35823592">[-]</label><label class="expand" for="c-35823592">[1 more]</label></div><br/><div class="children"><div class="content">Inside or out, it sounds like someone with an agenda to convince Google to release its model in the wild. I feel that all the more so because it is never stated explicitly but it&#x27;s the obvious conclusion from reading between the lines. Things like hinting that Meta is a huge winner from LLaMa getting released (this isn&#x27;t obvious to me at all).<p>The pitch being that if Google makes its models public it can race back to the forefront of &quot;owning&quot; the AI space and then capture the value of owning the underlying platform, like Android and Chrome.<p>The kind of scenario I imagine is that this is an insider who wants out but a huge amount of their work &#x2F; investment &#x2F; value is tied up with models they can&#x27;t take with them.</div><br/></div></div><div id="35826818" class="c"><input type="checkbox" id="c-35826818" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#35819672">root</a><span>|</span><a href="#35820548">parent</a><span>|</span><a href="#35823592">prev</a><span>|</span><a href="#35818328">next</a><span>|</span><label class="collapse" for="c-35826818">[-]</label><label class="expand" for="c-35826818">[1 more]</label></div><br/><div class="children"><div class="content">I mean, all this talk about &quot;moats&quot; is directly tied to monetization. The leaker is saying &quot;no matter what product we build with AI, equivalent open-source products will pop up free of charge, so we won&#x27;t be able to charge for our product&quot;.<p>And while integrating a LLM into, say, Google Docs can be a selling point, it&#x27;s not going to be a moat if OSS developers have access to their own LLMs; end users are going to choose Google Docs over FoobarOffice Online™ because Google Docs has a slightly better auto-complete or whatever.<p>So even if Google decides to integrates their LLM into Doc, it&#x27;s not clear that it wouldn&#x27;t benefit from open-sourcing that LLM and encouraging people to experiment on it.</div><br/></div></div></div></div></div></div><div id="35818328" class="c"><input type="checkbox" id="c-35818328" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#35819672">prev</a><span>|</span><a href="#35823543">next</a><span>|</span><label class="collapse" for="c-35818328">[-]</label><label class="expand" for="c-35818328">[33 more]</label></div><br/><div class="children"><div class="content">Having enough scale to perpetually offer free&#x2F;low-cost compute is a moat.
The primary reason ChatGPT went viral in the first place was because it was free, with no restrictions. Back in 2019, GPT-2 1.5B was made freely accessible by a single developer via the TalkToTransformers website, which was the very first time many people talking about AI text generation...then the owner got hit with sticker shock from the GPU compute needed to scale.<p>AI text generation competitors like Cohere and Anthropic will never be able to compete with Microsoft&#x2F;Google&#x2F;Amazon on marginal cost.</div><br/><div id="35820126" class="c"><input type="checkbox" id="c-35820126" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35819065">next</a><span>|</span><label class="collapse" for="c-35820126">[-]</label><label class="expand" for="c-35820126">[1 more]</label></div><br/><div class="children"><div class="content">And ChatGPT has a super low barrier to entry while open source alternatives have a high one.<p>Creating a service that can compete with it on that regard implies you can scale GPU farms in a cost effective way.<p>It&#x27;s not as easy as it sounds.<p>Meanwhile, openai still improves their product very fast, and unlike google, it&#x27;s their only one. It&#x27;s their baby. It has their entire focus.<p>Since for most consumers, AI == ChatGPT, they have the best market share right now, which mean the most user feedback to improve their product. Which they do at a fast pace.<p>They also understand that to get mass adoption, they need to censor the AI, like MacDonald and Disney craft their family friendly image. Which irritate every geeks, including me, but make commercially sense.<p>Plus, despite the fact you can torrent music and watch it with VLC, and that Amazon+Disney are competitors, netflix exists. Having a quality service has value in itself.<p>I would not count open ai as dead as a lot of people seem to desperately want it to be. Just because Google missed the AI train doesn&#x27;t mean wishful thinking the market to be killed by FOSS is going to make it so.<p>As usual with those things it&#x27;s impossible to know in advance what&#x27;s going to happen, but odds are not disfavoring chatgpt as much as this article says.</div><br/></div></div><div id="35819065" class="c"><input type="checkbox" id="c-35819065" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35820126">prev</a><span>|</span><a href="#35819582">next</a><span>|</span><label class="collapse" for="c-35819065">[-]</label><label class="expand" for="c-35819065">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Having enough scale to perpetually offer free&#x2F;low-cost compute is a moat.<p>Its a moat for services, not models, and its only a moat for AI services as long as that compute isn’t hobbled by being used for models which are so inefficient compared to SOTA as to waste the advantage, which underlines why leaning into open source the way this piece urges is in Google’s interests, the same way open source has worked to Google and Amazon’s benefits as service providers in other domains.<p>(Not so much “the ability to offer free&#x2F;low-cost compute” but “the advantages of scale and existing need for widely geographically dispersed compute on the cost of both marginal compute and having marginal compute close to the customer where that is relevant”, but those are pretty close to differenly-focussed rephrasings of the same underlying reality.)</div><br/></div></div><div id="35819582" class="c"><input type="checkbox" id="c-35819582" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35819065">prev</a><span>|</span><a href="#35818374">next</a><span>|</span><label class="collapse" for="c-35819582">[-]</label><label class="expand" for="c-35819582">[10 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what a lot of people think until they run Vicuna 13B or equivalent. We&#x27;re just 5 months in this, there will be many leaps.</div><br/><div id="35820420" class="c"><input type="checkbox" id="c-35820420" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35819582">parent</a><span>|</span><a href="#35819808">next</a><span>|</span><label class="collapse" for="c-35820420">[-]</label><label class="expand" for="c-35820420">[6 more]</label></div><br/><div class="children"><div class="content">What makes you think open ai won&#x27;t look at the FOSS improvements, include them in their tech, and make their GPU farm way cheaper, rendering their service even more competitive?<p>Not to mention it&#x27;s easy to run stable diffusion, but midjourney is still a good business. I can run sd on my laptop, I still pay for midjourney because it&#x27;s convenient, the out of the box experience is better than any competition, and it keeps improving.</div><br/><div id="35821356" class="c"><input type="checkbox" id="c-35821356" checked=""/><div class="controls bullet"><span class="by">syntheweave</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35820420">parent</a><span>|</span><a href="#35820630">next</a><span>|</span><label class="collapse" for="c-35821356">[-]</label><label class="expand" for="c-35821356">[2 more]</label></div><br/><div class="children"><div class="content">The reason why proprietary software ever had a moat simply comes down to: software startups could dump investment capital onto the development process and achieve results much faster, with better user interfaces, allowing them to achieve path dependence in their customer base. Thus we had a few big application verticals that were ultimately won by MS Office, Adobe Photoshop, etc.<p>If the result here is as marginal as it seems - a few months of advantage in output quality and a slightly more sleek UI - the capital-intensive play doesn&#x27;t work. The featuresets that industrial users want the most depend on having more control over the stack, not on UI or output quality. The open source models are stepping up to this goal of &quot;cheap and custom&quot;. Casual users can play with the open models without much difficulty either, provided they take a few hours to work through an installation tutorial - UI isn&#x27;t a major advantage when the whole point is that it&#x27;s a magic black box.</div><br/><div id="35823836" class="c"><input type="checkbox" id="c-35823836" checked=""/><div class="controls bullet"><span class="by">oldsecondhand</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35821356">parent</a><span>|</span><a href="#35820630">next</a><span>|</span><label class="collapse" for="c-35823836">[-]</label><label class="expand" for="c-35823836">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Casual users can play with the open models without much difficulty either, provided they take a few hours to work through an installation tutorial<p>That can be quite a barrier for entry for non-powerusers. I wouldn&#x27;t underestimate serving casual users, considering that the alternative is OSS i.e. giving your shit away for free.</div><br/></div></div></div></div><div id="35820630" class="c"><input type="checkbox" id="c-35820630" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35820420">parent</a><span>|</span><a href="#35821356">prev</a><span>|</span><a href="#35821253">next</a><span>|</span><label class="collapse" for="c-35820630">[-]</label><label class="expand" for="c-35820630">[2 more]</label></div><br/><div class="children"><div class="content">that&#x27;s like saying that apple and MS can look into linux and steal ideas. Yes they can do that but it doesnt make linux any less useful. If anything they learned to contribute back to the common pile, because everyone benefits from it. It would be a problem if this was a one-way relationship , which it doesnt seem to be. If Open source is making them more money, why kill it</div><br/><div id="35821197" class="c"><input type="checkbox" id="c-35821197" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35820630">parent</a><span>|</span><a href="#35821253">next</a><span>|</span><label class="collapse" for="c-35821197">[-]</label><label class="expand" for="c-35821197">[1 more]</label></div><br/><div class="children"><div class="content">You are making my point: linux, mac and windows coexist, despite the overwhelming strength of open source, and the proprietary platforms are quite profitable.</div><br/></div></div></div></div><div id="35821253" class="c"><input type="checkbox" id="c-35821253" checked=""/><div class="controls bullet"><span class="by">Tyr42</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35820420">parent</a><span>|</span><a href="#35820630">prev</a><span>|</span><a href="#35819808">next</a><span>|</span><label class="collapse" for="c-35821253">[-]</label><label class="expand" for="c-35821253">[1 more]</label></div><br/><div class="children"><div class="content">I mean, read the article, the author is concerned about that, and wants Google to open source more so it&#x27;s not just Facebook&#x27;s lama that gets open source building on it.</div><br/></div></div></div></div><div id="35819808" class="c"><input type="checkbox" id="c-35819808" checked=""/><div class="controls bullet"><span class="by">bilbo0s</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35819582">parent</a><span>|</span><a href="#35820420">prev</a><span>|</span><a href="#35818374">next</a><span>|</span><label class="collapse" for="c-35819808">[-]</label><label class="expand" for="c-35819808">[3 more]</label></div><br/><div class="children"><div class="content">Yes there will, that&#x27;s the problem HN User Minimaxir is talking about.<p>It will only get less and less expensive for Microsoft in terms of cost. And more and more effective for Microsoft in terms of results delivered.<p>How do you compete with free? That&#x27;s the question. The previous internet experience has already shown us that &quot;also be free&quot; is not really a sustainable or even effective answer. You have to be better in some fundamental dimension.</div><br/></div></div></div></div><div id="35818374" class="c"><input type="checkbox" id="c-35818374" checked=""/><div class="controls bullet"><span class="by">FemmeAndroid</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35819582">prev</a><span>|</span><a href="#35820890">next</a><span>|</span><label class="collapse" for="c-35818374">[-]</label><label class="expand" for="c-35818374">[18 more]</label></div><br/><div class="children"><div class="content">Charity is only a moat if it’s not profitable.</div><br/><div id="35818884" class="c"><input type="checkbox" id="c-35818884" checked=""/><div class="controls bullet"><span class="by">sharemywin</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818374">parent</a><span>|</span><a href="#35818569">next</a><span>|</span><label class="collapse" for="c-35818884">[-]</label><label class="expand" for="c-35818884">[7 more]</label></div><br/><div class="children"><div class="content">This is the timeline that&#x27;s scaring the shit out of them:<p>Feb 24, 2023: Meta launches LLaMA, a relatively small, open-source AI model.<p>March 3, 2023: LLaMA is leaked to the public, spurring rapid innovation.<p>March 12, 2023: Artem Andreenko runs LLaMA on a Raspberry Pi, inspiring minification efforts.<p>March 13, 2023: Stanford&#x27;s Alpaca adds instruction tuning to LLaMA, enabling low-budget fine-tuning.<p>March 18, 2023: Georgi Gerganov&#x27;s 4-bit quantization enables LLaMA to run on a MacBook CPU.<p>March 19, 2023: Vicuna, a 13B model, achieves &quot;parity&quot; with Bard at a $300 training cost.<p>March 25, 2023: Nomic introduces GPT4All, an ecosystem gathering models like Vicuna at a $100 training cost.<p>March 28, 2023: Cerebras trains an open-source GPT-3 architecture, making the community independent of LLaMA.<p>March 28, 2023: LLaMA-Adapter achieves SOTA multimodal ScienceQA with 1.2M learnable parameters.<p>April 3, 2023: Berkeley&#x27;s Koala dialogue model rivals ChatGPT in user preference at a $100 training cost.<p>April 15, 2023: Open Assistant releases an open-source RLHF model and dataset, making alignment more accessible.</div><br/><div id="35821607" class="c"><input type="checkbox" id="c-35821607" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818884">parent</a><span>|</span><a href="#35819111">next</a><span>|</span><label class="collapse" for="c-35821607">[-]</label><label class="expand" for="c-35821607">[1 more]</label></div><br/><div class="children"><div class="content">This really ought to mention <a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui</a>, which was the first popular UI for LLaMA, and remains one for anyone who runs it on GPU. It is also where GPTQ 4-bit quantization was first enabled in a LLaMA-based chatbot; llama.cpp picked it up later.</div><br/></div></div><div id="35819111" class="c"><input type="checkbox" id="c-35819111" checked=""/><div class="controls bullet"><span class="by">sharemywin</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818884">parent</a><span>|</span><a href="#35821607">prev</a><span>|</span><a href="#35821032">next</a><span>|</span><label class="collapse" for="c-35819111">[-]</label><label class="expand" for="c-35819111">[2 more]</label></div><br/><div class="children"><div class="content">this doesn&#x27;t even include the stuff around agents and&#x2F;or langchain</div><br/><div id="35819888" class="c"><input type="checkbox" id="c-35819888" checked=""/><div class="controls bullet"><span class="by">politician</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35819111">parent</a><span>|</span><a href="#35821032">next</a><span>|</span><label class="collapse" for="c-35819888">[-]</label><label class="expand" for="c-35819888">[1 more]</label></div><br/><div class="children"><div class="content">The post mentions that they consider &quot;Responsible Release&quot; to be an unsolved hard problem internally. It&#x27;s possible that they are culturally blind to agents.</div><br/></div></div></div></div><div id="35821032" class="c"><input type="checkbox" id="c-35821032" checked=""/><div class="controls bullet"><span class="by">ByThyGrace</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818884">parent</a><span>|</span><a href="#35819111">prev</a><span>|</span><a href="#35818569">next</a><span>|</span><label class="collapse" for="c-35821032">[-]</label><label class="expand" for="c-35821032">[3 more]</label></div><br/><div class="children"><div class="content">Interesting! It&#x27;s like nothing has happened on the field for the last three weeks heh</div><br/><div id="35821174" class="c"><input type="checkbox" id="c-35821174" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35821032">parent</a><span>|</span><a href="#35821268">next</a><span>|</span><label class="collapse" for="c-35821174">[-]</label><label class="expand" for="c-35821174">[1 more]</label></div><br/><div class="children"><div class="content">OpenLlaMa came out last week I think.</div><br/></div></div><div id="35821268" class="c"><input type="checkbox" id="c-35821268" checked=""/><div class="controls bullet"><span class="by">Tyr42</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35821032">parent</a><span>|</span><a href="#35821174">prev</a><span>|</span><a href="#35818569">next</a><span>|</span><label class="collapse" for="c-35821268">[-]</label><label class="expand" for="c-35821268">[1 more]</label></div><br/><div class="children"><div class="content">The doc was written a bit ago.</div><br/></div></div></div></div></div></div><div id="35818569" class="c"><input type="checkbox" id="c-35818569" checked=""/><div class="controls bullet"><span class="by">r00fus</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818374">parent</a><span>|</span><a href="#35818884">prev</a><span>|</span><a href="#35818777">next</a><span>|</span><label class="collapse" for="c-35818569">[-]</label><label class="expand" for="c-35818569">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s &quot;immediately profitable&quot; and &quot;eventually profitable&quot;.  Vast compute scale allows collection of customer generated data so the latter is possible, AI as of yet is not the former.<p>So GP point still stands.  FAAMG can run much larger immediate deficits in order to corner the market on the eventual profitability of AI.</div><br/><div id="35818734" class="c"><input type="checkbox" id="c-35818734" checked=""/><div class="controls bullet"><span class="by">cushpush</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818569">parent</a><span>|</span><a href="#35818662">next</a><span>|</span><label class="collapse" for="c-35818734">[-]</label><label class="expand" for="c-35818734">[1 more]</label></div><br/><div class="children"><div class="content">All this talk that every investment pays off in the end is faulty and dangerous.  Many investments don&#x27;t pan out,  95% of the firms you see in the ticker this decade might be gone, and yet everyone is very confident is underwriting these &quot;losses for future gains&quot; but really it&#x27;s economies of scale.  It doesn&#x27;t cost MSFT much more to run the GPU than to turn it on in the first place.</div><br/></div></div><div id="35818662" class="c"><input type="checkbox" id="c-35818662" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818569">parent</a><span>|</span><a href="#35818734">prev</a><span>|</span><a href="#35821339">next</a><span>|</span><label class="collapse" for="c-35818662">[-]</label><label class="expand" for="c-35818662">[1 more]</label></div><br/><div class="children"><div class="content">The amount of valuable data generated from professionals using these services to work through their problems and find solutions to industry problems is immense. It essentially gives these companies the keys to automating many industries by just...letting people try and make their jobs easier and collecting all data.</div><br/></div></div><div id="35821339" class="c"><input type="checkbox" id="c-35821339" checked=""/><div class="controls bullet"><span class="by">indymike</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818569">parent</a><span>|</span><a href="#35818662">prev</a><span>|</span><a href="#35818777">next</a><span>|</span><label class="collapse" for="c-35821339">[-]</label><label class="expand" for="c-35821339">[1 more]</label></div><br/><div class="children"><div class="content">&gt; . FAAMG can run much larger immediate deficits in order to corner the market on the eventual profitability of AI.<p>This assumes that there is a corner-able market. Previously, the cost of training was the moat. That appears to have been more of a puddle under the gate than an actual moat.</div><br/></div></div></div></div><div id="35818777" class="c"><input type="checkbox" id="c-35818777" checked=""/><div class="controls bullet"><span class="by">moron4hire</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818374">parent</a><span>|</span><a href="#35818569">prev</a><span>|</span><a href="#35818648">next</a><span>|</span><label class="collapse" for="c-35818777">[-]</label><label class="expand" for="c-35818777">[1 more]</label></div><br/><div class="children"><div class="content">In other words, engage in anti-competitive behavior.</div><br/></div></div><div id="35818648" class="c"><input type="checkbox" id="c-35818648" checked=""/><div class="controls bullet"><span class="by">deelowe</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818374">parent</a><span>|</span><a href="#35818777">prev</a><span>|</span><a href="#35820890">next</a><span>|</span><label class="collapse" for="c-35818648">[-]</label><label class="expand" for="c-35818648">[5 more]</label></div><br/><div class="children"><div class="content">It seems the plan is to be a loss leader until scale is sufficient to reach near AGI levels of capability.</div><br/><div id="35818787" class="c"><input type="checkbox" id="c-35818787" checked=""/><div class="controls bullet"><span class="by">nirav72</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818648">parent</a><span>|</span><a href="#35820890">next</a><span>|</span><label class="collapse" for="c-35818787">[-]</label><label class="expand" for="c-35818787">[4 more]</label></div><br/><div class="children"><div class="content">There was some indication recently that OpenAI was spending over $500k&#x2F;day to keep it running.  Not sure how long thats going to last. AGI is still a pipe dream. Sooner or later , they’re going to have to make money.</div><br/><div id="35819091" class="c"><input type="checkbox" id="c-35819091" checked=""/><div class="controls bullet"><span class="by">blihp</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818787">parent</a><span>|</span><a href="#35819012">next</a><span>|</span><label class="collapse" for="c-35819091">[-]</label><label class="expand" for="c-35819091">[1 more]</label></div><br/><div class="children"><div class="content">Oh no, they&#x27;re going belly up in 20,000 days! (i.e. $10B &#x2F; 500k)  Compute is going to keep getting cheaper and they&#x27;re going to keep optimizing it to reduce how much compute it needs.  I&#x27;m more curious about their next steps rather than how they&#x27;re going to keep the lights on for ChatGPT.</div><br/></div></div><div id="35819012" class="c"><input type="checkbox" id="c-35819012" checked=""/><div class="controls bullet"><span class="by">cmelbye</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818787">parent</a><span>|</span><a href="#35819091">prev</a><span>|</span><a href="#35819967">next</a><span>|</span><label class="collapse" for="c-35819012">[-]</label><label class="expand" for="c-35819012">[1 more]</label></div><br/><div class="children"><div class="content">Assuming you&#x27;re talking about the free ChatGPT product, it&#x27;s important to consider the value of the training data that users are giving them.<p>Beyond that, they are making a lot of money from their enterprise offerings (API products, custom partnerships, etc.) with more to come soon, like ChatGPT for Business.</div><br/></div></div><div id="35819967" class="c"><input type="checkbox" id="c-35819967" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#35818328">root</a><span>|</span><a href="#35818787">parent</a><span>|</span><a href="#35819012">prev</a><span>|</span><a href="#35820890">next</a><span>|</span><label class="collapse" for="c-35819967">[-]</label><label class="expand" for="c-35819967">[1 more]</label></div><br/><div class="children"><div class="content">$500k&#x2F;day for a large tech company is absolutely peanuts. Open.AI could probably even get away with justifying $5M&#x2F;day right now.</div><br/></div></div></div></div></div></div></div></div><div id="35820890" class="c"><input type="checkbox" id="c-35820890" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35818374">prev</a><span>|</span><a href="#35820786">next</a><span>|</span><label class="collapse" for="c-35820890">[-]</label><label class="expand" for="c-35820890">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AI text generation competitors like Cohere and Anthropic will never be able to compete with Microsoft&#x2F;Google&#x2F;Amazon on marginal cost.<p>Anthropic already does, with its models. They are same price or cheaper than OpenAI, with comparable quality.<p>&gt; Having enough scale to perpetually offer free&#x2F;low-cost compute is a moat.<p>Rather than a moat it is a growth strategy. At one point in time you need to start to monetize and this is the moment when rubber hits the road. If you can survive monetization and continue to grow, now you have a moat.</div><br/></div></div><div id="35820786" class="c"><input type="checkbox" id="c-35820786" checked=""/><div class="controls bullet"><span class="by">bickfordb</span><span>|</span><a href="#35818328">parent</a><span>|</span><a href="#35820890">prev</a><span>|</span><a href="#35823543">next</a><span>|</span><label class="collapse" for="c-35820786">[-]</label><label class="expand" for="c-35820786">[1 more]</label></div><br/><div class="children"><div class="content">A good example of this is Youtube</div><br/></div></div></div></div><div id="35823543" class="c"><input type="checkbox" id="c-35823543" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#35818328">prev</a><span>|</span><a href="#35815363">next</a><span>|</span><label class="collapse" for="c-35823543">[-]</label><label class="expand" for="c-35823543">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit sceptical of the &quot;no moat&quot; proposition because (a) ChatGPT 4.0 really does seem in a different league and (b) it&#x27;s clearly very hard to run. I haven&#x27;t seen anything from the explosion of open source &#x2F; community efforts that comes close for general applications.<p>The take in the post rings of the classic trademark Google arrogance where they assume that if somebody else can do it they can do it better if they just try - where the challenge of &quot;just trying&quot; is discounted to zero. In reality, &quot;Just trying&quot; is massively important and sometimes all that is important. The gap between unrefined model output and the level of polish and refinement that is apparent with ChatGPT 4 may appear technically small but it&#x27;s the whole difference between a widely applicable and usable product and something that can&#x27;t be more than a toy. I&#x27;m not sure Google has it in it any more to really fight for something they want to achieve that level of polish.</div><br/><div id="35828005" class="c"><input type="checkbox" id="c-35828005" checked=""/><div class="controls bullet"><span class="by">bionhoward</span><span>|</span><a href="#35823543">parent</a><span>|</span><a href="#35828496">next</a><span>|</span><label class="collapse" for="c-35828005">[-]</label><label class="expand" for="c-35828005">[2 more]</label></div><br/><div class="children"><div class="content">Version 4 also now supports 32k tokens, good luck handling that on even awesome gaming local dev rig machines, although perhaps with linformer ideas, block-wise algorithms to handle larger than GPU memory, universal memory &#x2F; RDMA it’s entirely doable. I got 50,000 atoms simulation back in 2018 on 11gb vram, at 32bit floats, the software stack has come a long way and now we have the 24gb 4090 with bfloat16, and vector DBs, and the infinite-context transformer paper just came out, so models all ought to be retrained on that if the method is truly superior anyway, not sure how atoms translate to pages of text but it’s almost surely possible to make a pretty useful LLM.<p>Although, OpenAI has a massive moat named “data”</div><br/><div id="35831539" class="c"><input type="checkbox" id="c-35831539" checked=""/><div class="controls bullet"><span class="by">sealeck</span><span>|</span><a href="#35823543">root</a><span>|</span><a href="#35828005">parent</a><span>|</span><a href="#35828496">next</a><span>|</span><label class="collapse" for="c-35831539">[-]</label><label class="expand" for="c-35831539">[1 more]</label></div><br/><div class="children"><div class="content">Except that the models have been trained on publicly available data sources.</div><br/></div></div></div></div><div id="35828496" class="c"><input type="checkbox" id="c-35828496" checked=""/><div class="controls bullet"><span class="by">mda</span><span>|</span><a href="#35823543">parent</a><span>|</span><a href="#35828005">prev</a><span>|</span><a href="#35815363">next</a><span>|</span><label class="collapse" for="c-35828496">[-]</label><label class="expand" for="c-35828496">[1 more]</label></div><br/><div class="children"><div class="content">Just wait a few months. You are underestimating thousands of researches and engineers only working on this with enormous compute budgets in several companies.</div><br/></div></div></div></div><div id="35815363" class="c"><input type="checkbox" id="c-35815363" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#35823543">prev</a><span>|</span><a href="#35818049">next</a><span>|</span><label class="collapse" for="c-35815363">[-]</label><label class="expand" for="c-35815363">[8 more]</label></div><br/><div class="children"><div class="content">Great read, but I don&#x27;t agree with all of these points. OpenAI&#x27;s technological moat is not necessarily meaningful in a context where the average consumer is starting to recognize ChatGPT as a brand name.<p>Furthermore, models which fine-tune LLMs are still dependent on the base model&#x27;s quality. Having a much higher quality base model is still a competitive advantage in scenarios where generalizability is an important aspect of the use case.<p>Thus far, Google has failed to integrate LLMs into their products in a way that adds value. But they do have advantages which could be used to gain a competitive lead:
- Their crawling infrastructure could allow their to generate better training datasets, and update models more quickly.
- Their TPU hardware could allow them to train and fine-tune models more quickly.
- Their excellent research divisions could give them a head start with novel architectures.<p>If Google utilizes those advantages, they could develop a moat in the future. OpenAI has access to great researchers, and good crawl data through Bing, but it seems plausible to me that 2 or 3 companies in this space could develop sizeable moats which smaller competitors can&#x27;t overcome.</div><br/><div id="35818272" class="c"><input type="checkbox" id="c-35818272" checked=""/><div class="controls bullet"><span class="by">ealexhudson</span><span>|</span><a href="#35815363">parent</a><span>|</span><a href="#35818501">next</a><span>|</span><label class="collapse" for="c-35818272">[-]</label><label class="expand" for="c-35818272">[4 more]</label></div><br/><div class="children"><div class="content">Consumers recognizing ChatGPT might just end up like vacuum cleaners; at least in the UK, people will often just call it a &quot;hoover&quot; but the likelihood of it being a Hoover is low.<p>It is difficult to see where the moat might exist if it&#x27;s not data and the majority of the workings are published &#x2F; discoverable. I don&#x27;t think the document identifies a readily working strategy to defend against the threats it recognises.</div><br/><div id="35818513" class="c"><input type="checkbox" id="c-35818513" checked=""/><div class="controls bullet"><span class="by">dmoy</span><span>|</span><a href="#35815363">root</a><span>|</span><a href="#35818272">parent</a><span>|</span><a href="#35818501">next</a><span>|</span><label class="collapse" for="c-35818513">[-]</label><label class="expand" for="c-35818513">[3 more]</label></div><br/><div class="children"><div class="content">&gt; end up like vacuum cleaners<p>The term of art is Generic Trademark<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Generic_trademark" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Generic_trademark</a><p>In US common law (and I&#x27;d imagine UK too), it&#x27;s usually something companies want to avoid if at all possible.<p>Relevant case for Google itself: <a href="https:&#x2F;&#x2F;www.intepat.com&#x2F;blog&#x2F;is-google-a-generic-trademark&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.intepat.com&#x2F;blog&#x2F;is-google-a-generic-trademark&#x2F;</a></div><br/><div id="35818795" class="c"><input type="checkbox" id="c-35818795" checked=""/><div class="controls bullet"><span class="by">akiselev</span><span>|</span><a href="#35815363">root</a><span>|</span><a href="#35818513">parent</a><span>|</span><a href="#35820105">next</a><span>|</span><label class="collapse" for="c-35818795">[-]</label><label class="expand" for="c-35818795">[1 more]</label></div><br/><div class="children"><div class="content">See also the “Don’t Say Velcro” [1] campaign from the eponymous hook and loop fastener company.<p>[1] <a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=rRi8LptvFZY">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=rRi8LptvFZY</a></div><br/></div></div><div id="35820105" class="c"><input type="checkbox" id="c-35820105" checked=""/><div class="controls bullet"><span class="by">ealexhudson</span><span>|</span><a href="#35815363">root</a><span>|</span><a href="#35818513">parent</a><span>|</span><a href="#35818795">prev</a><span>|</span><a href="#35818501">next</a><span>|</span><label class="collapse" for="c-35820105">[-]</label><label class="expand" for="c-35820105">[1 more]</label></div><br/><div class="children"><div class="content">Well, except that there&#x27;s no evidence that OpenAI are using the name in a trademark sense, let alone registered it?<p>Can&#x27;t really genericise that which was never made specific...</div><br/></div></div></div></div></div></div><div id="35818501" class="c"><input type="checkbox" id="c-35818501" checked=""/><div class="controls bullet"><span class="by">kevinmchugh</span><span>|</span><a href="#35815363">parent</a><span>|</span><a href="#35818272">prev</a><span>|</span><a href="#35818661">next</a><span>|</span><label class="collapse" for="c-35818501">[-]</label><label class="expand" for="c-35818501">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll also mark myself as skeptical of the brand-as-moat. I think AskJeeves and especially Yahoo probably had more brand recognition just before Google took over than ChatGPT or openai has today.</div><br/></div></div><div id="35818661" class="c"><input type="checkbox" id="c-35818661" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#35815363">parent</a><span>|</span><a href="#35818501">prev</a><span>|</span><a href="#35820676">next</a><span>|</span><label class="collapse" for="c-35818661">[-]</label><label class="expand" for="c-35818661">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  in a context where the average consumer is starting to recognize ChatGPT as a brand name.<p>That brand recognition could hurt them, though. If the widespread use of LLMs results in severe economic disruption due to unemployment, ChatGPT (and therefore OpenAI) will get the majority of the ire even for the effects of their competition.</div><br/></div></div><div id="35820676" class="c"><input type="checkbox" id="c-35820676" checked=""/><div class="controls bullet"><span class="by">russellbeattie</span><span>|</span><a href="#35815363">parent</a><span>|</span><a href="#35818661">prev</a><span>|</span><a href="#35818049">next</a><span>|</span><label class="collapse" for="c-35820676">[-]</label><label class="expand" for="c-35820676">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>ChatGPT as a brand name</i><p>You&#x27;re forgetting the phenomenon of the fast follower or second to market effect. Hydrox and Oreos, Newton and Palm, MySpace and Facebook, etc. Just because you created the market doesn&#x27;t necessarily mean you will own it long term. Competitors often respond better to customer demand and are more willing to innovate since they have nothing to lose.</div><br/></div></div></div></div><div id="35818049" class="c"><input type="checkbox" id="c-35818049" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#35815363">prev</a><span>|</span><a href="#35818514">next</a><span>|</span><label class="collapse" for="c-35818049">[-]</label><label class="expand" for="c-35818049">[5 more]</label></div><br/><div class="children"><div class="content">FWIW I posted Simon&#x27;s summary because it&#x27;s what I encountered first, but here&#x27;s the leaked document itself[0].<p>Some snippets for folks who came just for the comments:<p>&gt; While our models still hold a slight edge in terms of quality, the gap is closing astonishingly quickly. Open-source models are faster, more customizable, more private, and pound-for-pound more capable. They are doing things with $100 and 13B params that we struggle with at $10M and 540B. And they are doing so in weeks, not months.<p>&gt; A tremendous outpouring of innovation followed, with just days between major developments (see The Timeline for the full breakdown). Here we are, barely a month later, and there are variants with instruction tuning, quantization, quality improvements, human evals, multimodality, RLHF, etc. etc. many of which build on each other.<p>&gt; This recent progress has direct, immediate implications for our business strategy. Who would pay for a Google product with usage restrictions if there is a free, high quality alternative without them?<p>&gt; Paradoxically, the one clear winner in all of this is Meta. Because the leaked model was theirs, they have effectively garnered an entire planet’s worth of free labor. Since most open source innovation is happening on top of their architecture, there is nothing stopping them from directly incorporating it into their products.<p>&gt; And in the end, OpenAI doesn’t matter. They are making the same mistakes we are in their posture relative to open source, and their ability to maintain an edge is necessarily in question. Open source alternatives can and will eventually eclipse them unless they change their stance. In this respect, at least, we can make the first move.<p>[0]: <a href="https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;google-we-have-no-moat-and-neither" rel="nofollow">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;google-we-have-no-moat-and-ne...</a></div><br/><div id="35818816" class="c"><input type="checkbox" id="c-35818816" checked=""/><div class="controls bullet"><span class="by">davidguetta</span><span>|</span><a href="#35818049">parent</a><span>|</span><a href="#35818514">next</a><span>|</span><label class="collapse" for="c-35818816">[-]</label><label class="expand" for="c-35818816">[4 more]</label></div><br/><div class="children"><div class="content">Seems to be the Open Source who is the real winner overall.. After OpenAI became basically ClosedAI it&#x27;s an excellent news</div><br/><div id="35822819" class="c"><input type="checkbox" id="c-35822819" checked=""/><div class="controls bullet"><span class="by">Levitz</span><span>|</span><a href="#35818049">root</a><span>|</span><a href="#35818816">parent</a><span>|</span><a href="#35818514">next</a><span>|</span><label class="collapse" for="c-35822819">[-]</label><label class="expand" for="c-35822819">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure? Placing ethics constraints on a company under a capitalist system is hard. Placing them on open source is impossible.</div><br/><div id="35827205" class="c"><input type="checkbox" id="c-35827205" checked=""/><div class="controls bullet"><span class="by">davidguetta</span><span>|</span><a href="#35818049">root</a><span>|</span><a href="#35822819">parent</a><span>|</span><a href="#35825461">next</a><span>|</span><label class="collapse" for="c-35827205">[-]</label><label class="expand" for="c-35827205">[1 more]</label></div><br/><div class="children"><div class="content">I have real troubles taking with &quot;AI&quot; ethics when the biggest danger seems to be offending people at a mass scale... Sounds like a win as well</div><br/></div></div><div id="35825461" class="c"><input type="checkbox" id="c-35825461" checked=""/><div class="controls bullet"><span class="by">carapace</span><span>|</span><a href="#35818049">root</a><span>|</span><a href="#35822819">parent</a><span>|</span><a href="#35827205">prev</a><span>|</span><a href="#35818514">next</a><span>|</span><label class="collapse" for="c-35825461">[-]</label><label class="expand" for="c-35825461">[1 more]</label></div><br/><div class="children"><div class="content">Whose ethics?</div><br/></div></div></div></div></div></div></div></div><div id="35818514" class="c"><input type="checkbox" id="c-35818514" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35818049">prev</a><span>|</span><a href="#35825437">next</a><span>|</span><label class="collapse" for="c-35818514">[-]</label><label class="expand" for="c-35818514">[4 more]</label></div><br/><div class="children"><div class="content">I have been toying around with Stable Diffusion for a while now and becoming comfortable with the enormous community filled with <i>textual inversions</i>, <i>LoRAs</i>, <i>hyper networks</i> and <i>checkpoints</i>. You can get things with names like “chill blend”, a fine-tuned model on top of the SD with the author’s personal style.<p>There is something called automatic1111 which is a pretty comprehensive web UI for managing all these moving parts. Filled to the brim with extensions to handle AI upscaling, inpainting, outpainting, etc.<p>One of these is ControlNet where you can generate new images based on pose info extracted from an existing image or edited by yourself in the web based 3d editor (integrated, of course). Not just pose but depth maps, etc. All with a few clicks.<p>The level of detail and sheer amount of <i>stuff</i> is ridiculous and it all has meaning and substantial impact on the end result. I have not even talked about the prompting. You can do stuff like [cow:dog:.25] where the generator will start with a cow and then switch over at 25% of the process to a dog. You can use parens like ((sunglasses)) to focus extra hard on that concept.<p>There are so called LoRAs trained on specific styles and&#x2F;or characters. These are usually like 5-100MB and work unreasonably well.<p>You can switch over to the base model easily and the original SD results are 80s arcade game vs GTA5. This stuff has been around for like a year. This is ridiculous.<p>LLMs are enormously “undertooled”. Give it a year or so.<p>My point by the way is that any quality issues in the open source models will be fixed and then some.</div><br/><div id="35822131" class="c"><input type="checkbox" id="c-35822131" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#35818514">parent</a><span>|</span><a href="#35821288">next</a><span>|</span><label class="collapse" for="c-35822131">[-]</label><label class="expand" for="c-35822131">[2 more]</label></div><br/><div class="children"><div class="content">Local LLMs already have a UI intentionally similar to AUTOMATIC1111, including LoRAs, training with checkpoints, various extensions including multimodal and experimental long-term memory etc.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui</a></div><br/><div id="35825493" class="c"><input type="checkbox" id="c-35825493" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35818514">root</a><span>|</span><a href="#35822131">parent</a><span>|</span><a href="#35821288">next</a><span>|</span><label class="collapse" for="c-35825493">[-]</label><label class="expand" for="c-35825493">[1 more]</label></div><br/><div class="children"><div class="content">Excellent! Impossible to keep up.</div><br/></div></div></div></div><div id="35821288" class="c"><input type="checkbox" id="c-35821288" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#35818514">parent</a><span>|</span><a href="#35822131">prev</a><span>|</span><a href="#35825437">next</a><span>|</span><label class="collapse" for="c-35821288">[-]</label><label class="expand" for="c-35821288">[1 more]</label></div><br/><div class="children"><div class="content">I wrote a whole gist about this exact thing!!!!<p><a href="https:&#x2F;&#x2F;gist.github.com&#x2F;Hellisotherpeople&#x2F;45c619ee22aac6865ca4bb328eb58faf" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;Hellisotherpeople&#x2F;45c619ee22aac6865c...</a></div><br/></div></div></div></div><div id="35825437" class="c"><input type="checkbox" id="c-35825437" checked=""/><div class="controls bullet"><span class="by">keenon</span><span>|</span><a href="#35818514">prev</a><span>|</span><a href="#35818806">next</a><span>|</span><label class="collapse" for="c-35825437">[-]</label><label class="expand" for="c-35825437">[3 more]</label></div><br/><div class="children"><div class="content">This is so indicative of Google culture missing the point. The idea of spending $10M training a single model is treated as a casual reality. But “tHaNk GoOdNeSs those generous open source people published their HiGh QuAlItY datasets of ten thousand examples each. Otherwise we’d have no way of creating datasets like that…” :| the sustainable competitive advantage has been and will continue to be HUGE PROPRIETARY DATASETS. (Duh - this is as true for new AI as it was for old AI = ad targeting). It was the _query+click pairs_ that kept Google dominant all these years, not the brilliant engineers. They had all of humanity labeling the entire internet with “when I click on this page&#x2F;ad for this query I do&#x2F;don’t search again” a billion+ times a day for a decade. For good measure they’ve also been collecting your email, your calendar, and your browsing habits for nearly as long. The fact that they’ve managed to erase that historic advantage from their collective consciousness (presumably because AI researchers would rather not spend time debugging data labeling UI) is strange to me. It at least deserves a mention in a strategy memo like this. Not vague platitudes about “influence through innovation.” Spend that $10M you were going to spend on a training run as $9.9999M on a private dataset, then the remaining $100 on training. Better still, build products that gets user behavior to train your models for you. Obviously.<p>We’re going to watch the biggest face plant in recent economic history if they can’t get this one together. I can’t decide if that makes me happy about an overdue changing of the guard in the Valley or sad about the fall of a once great company.<p>It’s not about the models! Model training is a commodity! It’s about the data! Come on guys.</div><br/><div id="35828041" class="c"><input type="checkbox" id="c-35828041" checked=""/><div class="controls bullet"><span class="by">bionhoward</span><span>|</span><a href="#35825437">parent</a><span>|</span><a href="#35818806">next</a><span>|</span><label class="collapse" for="c-35828041">[-]</label><label class="expand" for="c-35828041">[2 more]</label></div><br/><div class="children"><div class="content">One way to push back on the data argument is to consider the progress DeepMind made with self play. Perhaps Bard can self-dialogue and achieve superhuman results. I won’t be surprised. Plus the underlying architecture is dense. Sparse transformers are a major upgrade. That’s only one of many upgrades you can make. There is still a lot of headroom and IMHO GPT-4 already implements AGI if you give it the right context</div><br/><div id="35836573" class="c"><input type="checkbox" id="c-35836573" checked=""/><div class="controls bullet"><span class="by">jxmorris12</span><span>|</span><a href="#35825437">root</a><span>|</span><a href="#35828041">parent</a><span>|</span><a href="#35818806">next</a><span>|</span><label class="collapse" for="c-35836573">[-]</label><label class="expand" for="c-35836573">[1 more]</label></div><br/><div class="children"><div class="content">Self-play works for eg Go because there’s a perfect simulator of the game – which gives at least one very clear training signal, <i>winning</i>. There’s no simulator for conversation, no winning, and no training signal. Self-dialog doesn’t make any sense</div><br/></div></div></div></div></div></div><div id="35818806" class="c"><input type="checkbox" id="c-35818806" checked=""/><div class="controls bullet"><span class="by">ChaitanyaSai</span><span>|</span><a href="#35825437">prev</a><span>|</span><a href="#35817862">next</a><span>|</span><label class="collapse" for="c-35818806">[-]</label><label class="expand" for="c-35818806">[34 more]</label></div><br/><div class="children"><div class="content">This is easily among the rare highest quality articles&#x2F;comments I&#x27;ve read in the past weeks, perhaps months (on LLMs&#x2F;AI since that&#x27;s what I am particularly interested in). And this was for internal consumption before it was made public. Reinforces my recent impression that so much that&#x27;s being made for public consumption now is shallow and it is hard to find the good stuff. And sadly, increasing so even on HN. As I write this, I acknowledge I discovered this on HN :) Wish we had ways to incentivize the public sharing of such high-quality content that don&#x27;t die at the altar of micro rewards.</div><br/><div id="35818999" class="c"><input type="checkbox" id="c-35818999" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35820169">next</a><span>|</span><label class="collapse" for="c-35818999">[-]</label><label class="expand" for="c-35818999">[14 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been saying the same things for weeks, right here and in the usual places. Basically - OpenAI will not be able to continue to commercialise chatGPT-3.5, they will have to move to GPT-4 because the open source alternatives will catch up. Their island of exclusivity is shrinking fast. In a few months nobody will want to pay for GPT-4 either when they can have private, cheap equivalents. So GPT-5 it is for OpenAI.<p>But the bulk of the tasks can probably be solved at 3.5 level, another more difficult chunk with 4, I&#x27;m wondering how many of the requests will be so complex as to require GPT-5. Probably less than 1%.<p>There&#x27;s a significant distinction between web search and generative AI. You can&#x27;t download &quot;a Google&quot; but you can download &quot;a LLaMA&quot;. This marks the end of the centralisation era and increased user freedom. Engaging in chat and image generation without being tracked is now possible while searching, browsing the web or torrenting are still tracked.</div><br/><div id="35819282" class="c"><input type="checkbox" id="c-35819282" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35818999">parent</a><span>|</span><a href="#35826436">next</a><span>|</span><label class="collapse" for="c-35819282">[-]</label><label class="expand" for="c-35819282">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve been saying the same things for weeks, right here and in the usual places. Basically - OpenAI will not be able to continue to commercialise chatGPT-3.5, they will have to move to GPT-4 because the open source alternatives will catch up. Their island of exclusivity is shrinking fast. In a few months nobody will want to pay for GPT-4 either when they can have private, cheap equivalents. So GPT-5 it is for OpenAI.<p>It is worth $20 a month to have one UI on one service that does everything.<p>Unless specialized models can far exceed what GPT4 can do, being general purpose is amazing.<p>IMHO the future is APIs written for consumption by LLMs, and then natural language interfaces and just telling an AI literally anything you want done.</div><br/><div id="35820211" class="c"><input type="checkbox" id="c-35820211" checked=""/><div class="controls bullet"><span class="by">xiphias2</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819282">parent</a><span>|</span><a href="#35820894">next</a><span>|</span><label class="collapse" for="c-35820211">[-]</label><label class="expand" for="c-35820211">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m paying but hate the UI. I had to add labels myself as a Tampermonkey extension,  but it would be much better if they would give API access to what I&#x27;m paying for and let UIs compete.</div><br/></div></div><div id="35820894" class="c"><input type="checkbox" id="c-35820894" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819282">parent</a><span>|</span><a href="#35820211">prev</a><span>|</span><a href="#35828443">next</a><span>|</span><label class="collapse" for="c-35820894">[-]</label><label class="expand" for="c-35820894">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It is worth $20 a month to have one UI on one service that does everything.<p>Today it is. When there is an open source, capable “one UI for everything” that runs locally and can consume external services as needed (but keeps your data locally otherwise), will it still be?</div><br/></div></div><div id="35828443" class="c"><input type="checkbox" id="c-35828443" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819282">parent</a><span>|</span><a href="#35820894">prev</a><span>|</span><a href="#35819589">next</a><span>|</span><label class="collapse" for="c-35828443">[-]</label><label class="expand" for="c-35828443">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t train ChatGPT with your own data and it has the infamous &quot;As a language model...&quot; problem. This is why an alternative that can be run locally is a better option for many people.</div><br/></div></div><div id="35819589" class="c"><input type="checkbox" id="c-35819589" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819282">parent</a><span>|</span><a href="#35828443">prev</a><span>|</span><a href="#35826436">next</a><span>|</span><label class="collapse" for="c-35819589">[-]</label><label class="expand" for="c-35819589">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It is worth $20 a month to have one UI on one service that does everything.<p>competition will drive profit margins and prices down to nothing because the number of companies that can spin up an UI is unlimited. Markets don&#x27;t pay you what something is worth, they pay what the cheapest participant is willing to sell it for.</div><br/></div></div></div></div><div id="35826436" class="c"><input type="checkbox" id="c-35826436" checked=""/><div class="controls bullet"><span class="by">tlonny</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35818999">parent</a><span>|</span><a href="#35819282">prev</a><span>|</span><a href="#35820471">next</a><span>|</span><label class="collapse" for="c-35826436">[-]</label><label class="expand" for="c-35826436">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve been saying the same things for weeks, right here and in the usual places. Basically - OpenAI will not be able to continue to commercialise chatGPT-3.5, they will have to move to GPT-4 because the open source alternatives will catch up. Their island of exclusivity is shrinking fast. In a few months nobody will want to pay for GPT-4 either when they can have private, cheap equivalents. So GPT-5 it is for OpenAI.<p>I wonder if this effect will be compounded by regulatory pressure that seems poised to slow down progress at the bleeding edge of LLMs.<p>Open source closing the gap at the bottom, and governments restricting further movement at the top...</div><br/></div></div><div id="35820471" class="c"><input type="checkbox" id="c-35820471" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35818999">parent</a><span>|</span><a href="#35826436">prev</a><span>|</span><a href="#35820386">next</a><span>|</span><label class="collapse" for="c-35820471">[-]</label><label class="expand" for="c-35820471">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m wondering how many of the requests will be so complex as to require GPT-5<p>I am not sure the pessimism is warranted. True that few people have the need to upgrade from GPT-3.5 to GPT-4 now, but if GPT-5 is another serious leap in capabilities, it might have an effect closer to the difference between old chatbots (useless, interesting) and ChatGPT (immediate economic impact, transforming some jobs). Or at any rate, we should expect such a leap to occur soon, even if it&#x27;s not GPT-5.</div><br/><div id="35820599" class="c"><input type="checkbox" id="c-35820599" checked=""/><div class="controls bullet"><span class="by">ngngngng</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35820471">parent</a><span>|</span><a href="#35820386">next</a><span>|</span><label class="collapse" for="c-35820599">[-]</label><label class="expand" for="c-35820599">[1 more]</label></div><br/><div class="children"><div class="content">Also significant to note that much of this AI boom was due to the UI of ChatGPT that gave everyone easy access to the model. Perhaps much of the improvements to be had in GPT-5 will also be found in the UI. I mean UI in the broadest possible sense, I&#x27;m sure we&#x27;ll come up with very creative ways to interact with this over the coming years.<p>But the moat problem addressed in the article remains. Good luck patenting your amazing UI change in such a way that open source models can&#x27;t catch up within a few weeks.</div><br/></div></div></div></div><div id="35820386" class="c"><input type="checkbox" id="c-35820386" checked=""/><div class="controls bullet"><span class="by">huijzer</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35818999">parent</a><span>|</span><a href="#35820471">prev</a><span>|</span><a href="#35820193">next</a><span>|</span><label class="collapse" for="c-35820386">[-]</label><label class="expand" for="c-35820386">[1 more]</label></div><br/><div class="children"><div class="content">I also would like to believe that, but there are countless examples which show the difference. Companies have no time to figure out which of the open source offerings is the best. Even worse, they don’t have the time to switch from one project to the other or back to OpenAI if OpenAI releases a new state-of-the-art model.</div><br/></div></div><div id="35820193" class="c"><input type="checkbox" id="c-35820193" checked=""/><div class="controls bullet"><span class="by">deanc</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35818999">parent</a><span>|</span><a href="#35820386">prev</a><span>|</span><a href="#35820169">next</a><span>|</span><label class="collapse" for="c-35820193">[-]</label><label class="expand" for="c-35820193">[4 more]</label></div><br/><div class="children"><div class="content">And where are these open source models where I can go to a url and do all the things I can do in ChatGPT or through api keys for OpenAI? I googled a couple of weeks ago to find hosted versions of these open source models to try, and every one was either down or woefully poor.<p>OpenAI and MS are going to win because they have a package to go and it’s ready and available and working well - they have set the benchmark. I’m not seeing any evidence of this in the OSS community thus far.<p>Until I can spin up a docker image capable of the same as OpenAI in hetzner for 30 bucks a month - it’s not in the same league.</div><br/><div id="35820785" class="c"><input type="checkbox" id="c-35820785" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35820193">parent</a><span>|</span><a href="#35820324">next</a><span>|</span><label class="collapse" for="c-35820785">[-]</label><label class="expand" for="c-35820785">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Until I can spin up a docker image capable of the same as OpenAI in hetzner for 30 bucks a month<p>I do exactly this with <a href="https:&#x2F;&#x2F;github.com&#x2F;nsarrazin&#x2F;serge">https:&#x2F;&#x2F;github.com&#x2F;nsarrazin&#x2F;serge</a><p>Hetzner will install any hardware you send them for $100. So you can send them a $200 P40 24GB to run 33B parameter GPU models at ChatGPT speeds without increasing your monthly cost.</div><br/></div></div><div id="35820324" class="c"><input type="checkbox" id="c-35820324" checked=""/><div class="controls bullet"><span class="by">icyfox</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35820193">parent</a><span>|</span><a href="#35820785">prev</a><span>|</span><a href="#35820358">next</a><span>|</span><label class="collapse" for="c-35820324">[-]</label><label class="expand" for="c-35820324">[1 more]</label></div><br/><div class="children"><div class="content">One issue with the current generation of open source models is most have been based on some llama core architecture, and that&#x27;s not licensed for commercial use. Once you get to the point of spinning up a full and easy API, and selling API credentials, you&#x27;re entering into the commercial clause. Once we have a llama alternative (or a more permissively licensed separate architecture) I guarantee hosting providers like Render or Model are going to come in with an API offering. Just waiting on those core models to improve licensing, would be my guess.</div><br/></div></div><div id="35820358" class="c"><input type="checkbox" id="c-35820358" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35820193">parent</a><span>|</span><a href="#35820324">prev</a><span>|</span><a href="#35820169">next</a><span>|</span><label class="collapse" for="c-35820358">[-]</label><label class="expand" for="c-35820358">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Until I can spin up a docker image capable of the same as OpenAI in hetzner for 30 bucks a month - it’s not in the same league.<p>Yes, you are right<p>That’s irrelevant to the point of this, which is about the dynamics of the market over a longer window than “what is available to use immediately today”, because a “moat” is a different thing than “a current lead”.</div><br/></div></div></div></div></div></div><div id="35820169" class="c"><input type="checkbox" id="c-35820169" checked=""/><div class="controls bullet"><span class="by">0xbadcafebee</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35818999">prev</a><span>|</span><a href="#35819289">next</a><span>|</span><label class="collapse" for="c-35820169">[-]</label><label class="expand" for="c-35820169">[1 more]</label></div><br/><div class="children"><div class="content">Most HN submissions are clickbait advertisements by startups for B2B&#x2F;B2C services, clickbait amateur blog editorials looking for subscribers, tutorials for newbies, conspiracy theories, spam, and literally every article posted to a major media outlet. Most comments are by amateurs that sound really confident.<p>Don&#x27;t believe me? Go look at <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest</a> . Maybe once a month you find something on here that is actually from an expert who knows what they&#x27;re talking about and hasn&#x27;t written a book on it yet, or a pet project by an incredibly talented person who has no idea it was submitted.<p>Source: I&#x27;ve been here for 14 years. That makes me a little depressed...</div><br/></div></div><div id="35819289" class="c"><input type="checkbox" id="c-35819289" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35820169">prev</a><span>|</span><a href="#35821036">next</a><span>|</span><label class="collapse" for="c-35819289">[-]</label><label class="expand" for="c-35819289">[5 more]</label></div><br/><div class="children"><div class="content">Well yes, generally in the business world all the &quot;good stuff&quot;, the really smart analysis, is extremely confidential. Really smart people are putting these things together, but these types of analyses are a competitive advantage, so they&#x27;re absolutely never going to share it publicly.<p>This was leaked, not intentionally made public.<p>And it all makes sense -- the people producing these types of business analyses are world-class experts in their fields (the business strategy not just the tech), and are paid handsomely for that.<p>The &quot;regular stuff&quot; people consume is written by journalists who are usually a bit more &quot;jack of all trades master of none&quot;. A journalist might cover the entire consumer tech industry, not LLM&#x27;s specifically. They can&#x27;t produce this kind of analysis, nor should we expect them to.<p>Industry experts are extremely valuable for a reason, and they don&#x27;t bother writing analyses for public media since it doesn&#x27;t pay as well.</div><br/><div id="35820067" class="c"><input type="checkbox" id="c-35820067" checked=""/><div class="controls bullet"><span class="by">gerad</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819289">parent</a><span>|</span><a href="#35821549">next</a><span>|</span><label class="collapse" for="c-35820067">[-]</label><label class="expand" for="c-35820067">[2 more]</label></div><br/><div class="children"><div class="content">Beware that there’s also a ton of bias when something is analyzed internally. As Upton Sinclair once said “It is difficult to get a man to understand something, when his salary depends on his not understanding it.”<p>In the case of this analysis - it sounds great but it’s wrong. OpenAI has a huge moat. It has captured the mind share of the world. The software it has shipped is dramatically better than anything anyone else has shipped (the difference between useless and useful). We’ll see if folks catch up, but the race is currently OpenAI’s to lose.</div><br/><div id="35821035" class="c"><input type="checkbox" id="c-35821035" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35820067">parent</a><span>|</span><a href="#35821549">next</a><span>|</span><label class="collapse" for="c-35821035">[-]</label><label class="expand" for="c-35821035">[1 more]</label></div><br/><div class="children"><div class="content">Mind share is not a moat. And market share or being first is not a moat.<p>Moats are very specific things such as network effects, customers with sunk costs, etc. The very point of the term &quot;moat&quot; is to distinguish it from things like market share or mind share.<p>The article is correct, OpenAI has no moat currently.</div><br/></div></div></div></div><div id="35821549" class="c"><input type="checkbox" id="c-35821549" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819289">parent</a><span>|</span><a href="#35820067">prev</a><span>|</span><a href="#35819961">next</a><span>|</span><label class="collapse" for="c-35821549">[-]</label><label class="expand" for="c-35821549">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, I have some expertise in a couple software topics, and there is nowhere in public media that would pay me to write about it.<p>The only exception would be if my name were super recognizable&#x2F;I had some legitimacy I could “sell” to publish something that did have commercial value, like some shitty CIO-targeted “article” about why XYZ is the future, in which case it’s not really going to be interesting content or actually sharing ideas.</div><br/></div></div><div id="35819961" class="c"><input type="checkbox" id="c-35819961" checked=""/><div class="controls bullet"><span class="by">wahern</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819289">parent</a><span>|</span><a href="#35821549">prev</a><span>|</span><a href="#35821036">next</a><span>|</span><label class="collapse" for="c-35819961">[-]</label><label class="expand" for="c-35819961">[1 more]</label></div><br/><div class="children"><div class="content">Sort of like sports recruiters.</div><br/></div></div></div></div><div id="35821036" class="c"><input type="checkbox" id="c-35821036" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35819289">prev</a><span>|</span><a href="#35819407">next</a><span>|</span><label class="collapse" for="c-35821036">[-]</label><label class="expand" for="c-35821036">[3 more]</label></div><br/><div class="children"><div class="content">There is some really high quality internal discussions at tech companies, unfortunately they are suffering from leaks due to their size and media have realized it’s really easy to just take their internal content and publish it.<p>It really sucks because there’s definitely a chilling effect knowing any personal opinion expressed in text at a big tech company could end up in a headline like “GOOGLE SAYS &lt;hot take&gt;” because of a leak.<p>If there is some kind of really bad behavior being exposed, I think the role of the media is to help do that. But I don’t think their role should be to expose any leaked internal document they can get their hands on.</div><br/><div id="35821349" class="c"><input type="checkbox" id="c-35821349" checked=""/><div class="controls bullet"><span class="by">UncleMeat</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35821036">parent</a><span>|</span><a href="#35819407">next</a><span>|</span><label class="collapse" for="c-35821349">[-]</label><label class="expand" for="c-35821349">[2 more]</label></div><br/><div class="children"><div class="content">This is exactly that. This doc is apparently a leaked internal doc.</div><br/><div id="35821419" class="c"><input type="checkbox" id="c-35821419" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35821349">parent</a><span>|</span><a href="#35819407">next</a><span>|</span><label class="collapse" for="c-35821419">[-]</label><label class="expand" for="c-35821419">[1 more]</label></div><br/><div class="children"><div class="content">I know that, my point is that it’s not indicating anything nefarious enough to be worth exposing, it’s just juicy.<p>I don’t think the media should share stuff like this just because it’s interesting. They’re making a market for corporate espionage to sell clicks.</div><br/></div></div></div></div></div></div><div id="35819407" class="c"><input type="checkbox" id="c-35819407" checked=""/><div class="controls bullet"><span class="by">burnished</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35821036">prev</a><span>|</span><a href="#35821256">next</a><span>|</span><label class="collapse" for="c-35819407">[-]</label><label class="expand" for="c-35819407">[1 more]</label></div><br/><div class="children"><div class="content">Most of it is being written to make money off of you instead of communicate with you and it shows.</div><br/></div></div><div id="35821256" class="c"><input type="checkbox" id="c-35821256" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35819407">prev</a><span>|</span><a href="#35819519">next</a><span>|</span><label class="collapse" for="c-35821256">[-]</label><label class="expand" for="c-35821256">[1 more]</label></div><br/><div class="children"><div class="content">I thought this was a good one this week but didn&#x27;t get popular.<p><a href="https:&#x2F;&#x2F;huyenchip.com&#x2F;2023&#x2F;05&#x2F;02&#x2F;rlhf.html" rel="nofollow">https:&#x2F;&#x2F;huyenchip.com&#x2F;2023&#x2F;05&#x2F;02&#x2F;rlhf.html</a></div><br/></div></div><div id="35819519" class="c"><input type="checkbox" id="c-35819519" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35821256">prev</a><span>|</span><a href="#35819759">next</a><span>|</span><label class="collapse" for="c-35819519">[-]</label><label class="expand" for="c-35819519">[1 more]</label></div><br/><div class="children"><div class="content">a lot of people have said similar things here</div><br/></div></div><div id="35819759" class="c"><input type="checkbox" id="c-35819759" checked=""/><div class="controls bullet"><span class="by">jiggywiggy</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35819519">prev</a><span>|</span><a href="#35818842">next</a><span>|</span><label class="collapse" for="c-35819759">[-]</label><label class="expand" for="c-35819759">[2 more]</label></div><br/><div class="children"><div class="content">Im a noob. But the time for Wikipedia language models &amp; training models seems ripe.</div><br/><div id="35819823" class="c"><input type="checkbox" id="c-35819823" checked=""/><div class="controls bullet"><span class="by">PeterCorless</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819759">parent</a><span>|</span><a href="#35818842">next</a><span>|</span><label class="collapse" for="c-35819823">[-]</label><label class="expand" for="c-35819823">[1 more]</label></div><br/><div class="children"><div class="content">• <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Large_language_model#List_of_large_language_models" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Large_language_model#List_of_l...</a><p>• <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_datasets_for_machine-learning_research#Internet" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_datasets_for_machine-l...</a></div><br/></div></div></div></div><div id="35819068" class="c"><input type="checkbox" id="c-35819068" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35818842">prev</a><span>|</span><a href="#35819926">next</a><span>|</span><label class="collapse" for="c-35819068">[-]</label><label class="expand" for="c-35819068">[3 more]</label></div><br/><div class="children"><div class="content">If you feel like your criteria for quality is beyond what you can typically find in the popular public consumption, just start reading papers directly?</div><br/><div id="35819316" class="c"><input type="checkbox" id="c-35819316" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819068">parent</a><span>|</span><a href="#35819926">next</a><span>|</span><label class="collapse" for="c-35819316">[-]</label><label class="expand" for="c-35819316">[2 more]</label></div><br/><div class="children"><div class="content">The value in this article is the business strategy perspective, not the details of LLM&#x27;s.<p>You generally won&#x27;t find papers detailing the present-moment business strategies of specific for-profit corporations.</div><br/><div id="35819352" class="c"><input type="checkbox" id="c-35819352" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#35818806">root</a><span>|</span><a href="#35819316">parent</a><span>|</span><a href="#35819926">next</a><span>|</span><label class="collapse" for="c-35819352">[-]</label><label class="expand" for="c-35819352">[1 more]</label></div><br/><div class="children"><div class="content">Sure but this article is also not the present-moment business strategy, it is written by a single individual with a perspective.</div><br/></div></div></div></div></div></div><div id="35819926" class="c"><input type="checkbox" id="c-35819926" checked=""/><div class="controls bullet"><span class="by">swores</span><span>|</span><a href="#35818806">parent</a><span>|</span><a href="#35819068">prev</a><span>|</span><a href="#35817862">next</a><span>|</span><label class="collapse" for="c-35819926">[-]</label><label class="expand" for="c-35819926">[1 more]</label></div><br/><div class="children"><div class="content">Hi Sai, do you have an email address (or other preferred private message) I could contact you on? Feel free to send it to the relay email in my profile if you want to avoid putting it publicly (or reply here how to contact you).<p>I&#x27;ll ask my first question here below, so that if you have an answer it can benefit other HNers, and I&#x27;ll save the other line of thought for email.<p>Do you happen to have a list of other highest quality articles on AI&#x2F;LLMs&#x2F;etc that you&#x27;ve come across, and could share here?<p>It&#x27;s not my field but something I want to learn more about, and I&#x27;ve found it hard to, without knowing much about the specific subjects within AI that would be good to learn about makes it hard picking what to read or not.</div><br/></div></div></div></div><div id="35817862" class="c"><input type="checkbox" id="c-35817862" checked=""/><div class="controls bullet"><span class="by">summerlight</span><span>|</span><a href="#35818806">prev</a><span>|</span><a href="#35825302">next</a><span>|</span><label class="collapse" for="c-35817862">[-]</label><label class="expand" for="c-35817862">[5 more]</label></div><br/><div class="children"><div class="content">This looks like a personal manifesto from an engineer who doesn&#x27;t even attempt to write it on behalf of Google? The title is significantly misleading.</div><br/><div id="35818525" class="c"><input type="checkbox" id="c-35818525" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#35817862">parent</a><span>|</span><a href="#35819987">next</a><span>|</span><label class="collapse" for="c-35818525">[-]</label><label class="expand" for="c-35818525">[1 more]</label></div><br/><div class="children"><div class="content">Agree, misleading title. The introduction makes the context clear, but probably too late to not call the article click-bait.<p>&gt; [...] It originates from a researcher within Google. [...] The document is only the opinion of a Google employee, not the entire firm. [...]</div><br/></div></div><div id="35819987" class="c"><input type="checkbox" id="c-35819987" checked=""/><div class="controls bullet"><span class="by">dpflan</span><span>|</span><a href="#35817862">parent</a><span>|</span><a href="#35818525">prev</a><span>|</span><a href="#35821575">next</a><span>|</span><label class="collapse" for="c-35819987">[-]</label><label class="expand" for="c-35819987">[1 more]</label></div><br/><div class="children"><div class="content">Completely agree. It is interesting, but the gravitas of it seems lower than of course if an executive said this and corroborated it. I do feel that opensource for AI is going to be really interesting and shake things up.</div><br/></div></div><div id="35821575" class="c"><input type="checkbox" id="c-35821575" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35817862">parent</a><span>|</span><a href="#35819987">prev</a><span>|</span><a href="#35821821">next</a><span>|</span><label class="collapse" for="c-35821575">[-]</label><label class="expand" for="c-35821575">[1 more]</label></div><br/><div class="children"><div class="content">99% of media coverage like “Tech employee&#x2F;company says &lt;provocative or controversial thing&gt;” are exactly like that.</div><br/></div></div><div id="35821821" class="c"><input type="checkbox" id="c-35821821" checked=""/><div class="controls bullet"><span class="by">ghaff</span><span>|</span><a href="#35817862">parent</a><span>|</span><a href="#35821575">prev</a><span>|</span><a href="#35825302">next</a><span>|</span><label class="collapse" for="c-35821821">[-]</label><label class="expand" for="c-35821821">[1 more]</label></div><br/><div class="children"><div class="content">And (probably) through no fault of their own they&#x27;ll get totally thrown under the bus for this--whether directly but when raises&#x2F;promotions come around or not.</div><br/></div></div></div></div><div id="35825302" class="c"><input type="checkbox" id="c-35825302" checked=""/><div class="controls bullet"><span class="by">somerandomdudes</span><span>|</span><a href="#35817862">prev</a><span>|</span><a href="#35820809">next</a><span>|</span><label class="collapse" for="c-35825302">[-]</label><label class="expand" for="c-35825302">[7 more]</label></div><br/><div class="children"><div class="content">I am amazed that people haven&#x27;t gotten used to these &quot;internal Google doc leaks&quot;.<p>This is just the opinion of some random googler, one among over 100,000.<p>For some reason random googlers seem like to write random docs on hot topics and share it widely across the company. And someone, among those over 100,000 googlers, ends up &quot;leaking&quot; the opinion of that person to outside Google.<p>This is more like a blog post of some random dude over the Internet expressing his opinion. The fact that random dude ended up working at Google should not bear much on evaluating the claims in the doc.<p>A website published that with a title &quot;Google ...&quot; is misleading. The accurate title would be &quot;Some random googler: ...&quot;</div><br/><div id="35825332" class="c"><input type="checkbox" id="c-35825332" checked=""/><div class="controls bullet"><span class="by">cwp</span><span>|</span><a href="#35825302">parent</a><span>|</span><a href="#35820809">next</a><span>|</span><label class="collapse" for="c-35825332">[-]</label><label class="expand" for="c-35825332">[6 more]</label></div><br/><div class="children"><div class="content">According to the article, it&#x27;s a random AI researcher at Google, so fairly relevant.</div><br/><div id="35825352" class="c"><input type="checkbox" id="c-35825352" checked=""/><div class="controls bullet"><span class="by">somerandomdudes</span><span>|</span><a href="#35825302">root</a><span>|</span><a href="#35825332">parent</a><span>|</span><a href="#35825381">next</a><span>|</span><label class="collapse" for="c-35825352">[-]</label><label class="expand" for="c-35825352">[2 more]</label></div><br/><div class="children"><div class="content">Google has thousands of so called AI&#x2F;ML &quot;researchers&quot;.<p>The author has ZERO publications in top AI&#x2F;ML conferences.</div><br/><div id="35825427" class="c"><input type="checkbox" id="c-35825427" checked=""/><div class="controls bullet"><span class="by">cwp</span><span>|</span><a href="#35825302">root</a><span>|</span><a href="#35825352">parent</a><span>|</span><a href="#35825381">next</a><span>|</span><label class="collapse" for="c-35825427">[-]</label><label class="expand" for="c-35825427">[1 more]</label></div><br/><div class="children"><div class="content">You know who wrote this?</div><br/></div></div></div></div><div id="35825381" class="c"><input type="checkbox" id="c-35825381" checked=""/><div class="controls bullet"><span class="by">somerandomdudes</span><span>|</span><a href="#35825302">root</a><span>|</span><a href="#35825332">parent</a><span>|</span><a href="#35825352">prev</a><span>|</span><a href="#35825374">next</a><span>|</span><label class="collapse" for="c-35825381">[-]</label><label class="expand" for="c-35825381">[2 more]</label></div><br/><div class="children"><div class="content">People are appealing to some kind of &quot;authority&quot; regarding these opinion docs from random dudes working at Google where if they knew the dude&#x27;s name rather than the fact that they work at Google they would not.</div><br/><div id="35825419" class="c"><input type="checkbox" id="c-35825419" checked=""/><div class="controls bullet"><span class="by">cwp</span><span>|</span><a href="#35825302">root</a><span>|</span><a href="#35825381">parent</a><span>|</span><a href="#35825374">next</a><span>|</span><label class="collapse" for="c-35825419">[-]</label><label class="expand" for="c-35825419">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t think a Google AI researcher is in a good position to comment on how Google is affected by recent developments in AI? I mean, yeah, it&#x27;s an opinion, but it&#x27;s not just anyone&#x27;s opinion.</div><br/></div></div></div></div></div></div></div></div><div id="35820809" class="c"><input type="checkbox" id="c-35820809" checked=""/><div class="controls bullet"><span class="by">ngngngng</span><span>|</span><a href="#35825302">prev</a><span>|</span><a href="#35813629">next</a><span>|</span><label class="collapse" for="c-35820809">[-]</label><label class="expand" for="c-35820809">[7 more]</label></div><br/><div class="children"><div class="content">Really interesting to look at this from a product perspective. I&#x27;ve been obsessively looking at it from an AI user perspective, but instead of thinking of it as a &quot;moat&quot;, I just keep thinking of the line from Disney&#x27;s The Incredibles, &quot;And when everyone is super, no one will be.&quot;<p>Every app that I might build utilizing AI is really just a window, or a wrapper into the model itself. Everything is easy to replicate. Why would anyone pay for my AI wrapper when they could just build THING themselves? Or just wait until GPT-{current+1} when the model can do THING directly, followed swiftly by free and open source models being able to do THING as well.</div><br/><div id="35820864" class="c"><input type="checkbox" id="c-35820864" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#35820809">parent</a><span>|</span><a href="#35820870">next</a><span>|</span><label class="collapse" for="c-35820864">[-]</label><label class="expand" for="c-35820864">[4 more]</label></div><br/><div class="children"><div class="content">Just gotta get to the point where we can just ask the model to code the wrapper we want to use it with...</div><br/><div id="35821047" class="c"><input type="checkbox" id="c-35821047" checked=""/><div class="controls bullet"><span class="by">ngngngng</span><span>|</span><a href="#35820809">root</a><span>|</span><a href="#35820864">parent</a><span>|</span><a href="#35820870">next</a><span>|</span><label class="collapse" for="c-35821047">[-]</label><label class="expand" for="c-35821047">[3 more]</label></div><br/><div class="children"><div class="content">Any wrapper that needs writing speaks to a gap in the AI&#x27;s current capabilities. I just don&#x27;t see why or how I would put man-hours into trying to close that gap when a future model could eclipse my work at any time.</div><br/><div id="35823639" class="c"><input type="checkbox" id="c-35823639" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#35820809">root</a><span>|</span><a href="#35821047">parent</a><span>|</span><a href="#35822854">next</a><span>|</span><label class="collapse" for="c-35823639">[-]</label><label class="expand" for="c-35823639">[1 more]</label></div><br/><div class="children"><div class="content">The problem is that I can&#x27;t think of a reason not to apply this same concern to basically all knowledge work -- once it can code new wrappers, it&#x27;ll probably also be obsoleting huge swathes of other skillsets. And given current models, that really doesn&#x27;t seem that far off. Personally it kinda feels like working at a company with impending layoffs...<p>But somehow my landlord isn&#x27;t taking that as an excuse to stop working?? B.S.</div><br/></div></div><div id="35822854" class="c"><input type="checkbox" id="c-35822854" checked=""/><div class="controls bullet"><span class="by">unraveller</span><span>|</span><a href="#35820809">root</a><span>|</span><a href="#35821047">parent</a><span>|</span><a href="#35823639">prev</a><span>|</span><a href="#35820870">next</a><span>|</span><label class="collapse" for="c-35822854">[-]</label><label class="expand" for="c-35822854">[1 more]</label></div><br/><div class="children"><div class="content">you&#x27;ve got future frostbite</div><br/></div></div></div></div></div></div><div id="35820870" class="c"><input type="checkbox" id="c-35820870" checked=""/><div class="controls bullet"><span class="by">Nick87633</span><span>|</span><a href="#35820809">parent</a><span>|</span><a href="#35820864">prev</a><span>|</span><a href="#35813629">next</a><span>|</span><label class="collapse" for="c-35820870">[-]</label><label class="expand" for="c-35820870">[2 more]</label></div><br/><div class="children"><div class="content">Because people pay for convenience, and may not be technical enough to stay up to date on the latest and best AI company for their use case.  Presumably your specialized app would switch to better AI instances for that use case as they come along in which case they&#x27;re paying for your curation as well.</div><br/><div id="35821108" class="c"><input type="checkbox" id="c-35821108" checked=""/><div class="controls bullet"><span class="by">ngngngng</span><span>|</span><a href="#35820809">root</a><span>|</span><a href="#35820870">parent</a><span>|</span><a href="#35813629">next</a><span>|</span><label class="collapse" for="c-35821108">[-]</label><label class="expand" for="c-35821108">[1 more]</label></div><br/><div class="children"><div class="content">Maybe. It just seems to me that every single angle of AI has this same moat issue.<p>It&#x27;s like the generation ship problem. Send a ship to the stars today, and before it gets there technology might advance such that the second ship we send gets there before the first.<p>How do you justify the capital necessary to stand out in an AI driven marketplace when the next models could make your business obsolete at any time?</div><br/></div></div></div></div></div></div><div id="35813629" class="c"><input type="checkbox" id="c-35813629" checked=""/><div class="controls bullet"><span class="by">tiniuclx</span><span>|</span><a href="#35820809">prev</a><span>|</span><a href="#35819915">next</a><span>|</span><label class="collapse" for="c-35813629">[-]</label><label class="expand" for="c-35813629">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using Stable Diffusion to generate cover images for the music I release &amp; produce for others. It&#x27;s a massive time saver compared to comping together the release art using image editing software, and a lot cheaper than working with artists, which just doesn&#x27;t make sense financially as an independent musician.<p>It&#x27;s a little bit difficult to get what you want out of the models, but I find them very useful! And while the output resolution might be quite low, things are improving &amp; AI upscaling also helps a lot.</div><br/><div id="35814795" class="c"><input type="checkbox" id="c-35814795" checked=""/><div class="controls bullet"><span class="by">benjaminsky2</span><span>|</span><a href="#35813629">parent</a><span>|</span><a href="#35819915">next</a><span>|</span><label class="collapse" for="c-35814795">[-]</label><label class="expand" for="c-35814795">[8 more]</label></div><br/><div class="children"><div class="content">&gt; artist whose domain has not yet been disrupted by AI fires artist in favor of AI</div><br/><div id="35818259" class="c"><input type="checkbox" id="c-35818259" checked=""/><div class="controls bullet"><span class="by">tiniuclx</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35814795">parent</a><span>|</span><a href="#35815643">next</a><span>|</span><label class="collapse" for="c-35818259">[-]</label><label class="expand" for="c-35818259">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m already using AI to make my music production process more efficient! Namely, I&#x27;m using a program called Sononym which listens to my tens of thousands of audio samples and lets you search by audio similarity through the entire library, as well as sort by various sonic qualities.<p>I think I&#x27;d still go for a human artist for a bigger release such as an album! It&#x27;s a lot less hassle than sorting through (often rubbish) AI output &amp; engineering your prompts, though it does cost £££ which is the main thing making it prohibitive for single releases.</div><br/></div></div><div id="35815643" class="c"><input type="checkbox" id="c-35815643" checked=""/><div class="controls bullet"><span class="by">joenot443</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35814795">parent</a><span>|</span><a href="#35818259">prev</a><span>|</span><a href="#35820675">next</a><span>|</span><label class="collapse" for="c-35815643">[-]</label><label class="expand" for="c-35815643">[2 more]</label></div><br/><div class="children"><div class="content">And the rest of the world was better off for it.<p>If we&#x27;d prevented new technologies from influencing our artwork, our paintings would never have left the cave wall. I&#x27;m a musician with live published albums as well; if there comes a time when I think AI will help with my creative process, you can bet that I&#x27;ll be using it.</div><br/><div id="35818411" class="c"><input type="checkbox" id="c-35818411" checked=""/><div class="controls bullet"><span class="by">coolspot</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35815643">parent</a><span>|</span><a href="#35820675">next</a><span>|</span><label class="collapse" for="c-35818411">[-]</label><label class="expand" for="c-35818411">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And the rest of the world was better off for it.<p>Except the single mom in a studio apartment trying to get some pay from her art gigs.</div><br/></div></div></div></div><div id="35820675" class="c"><input type="checkbox" id="c-35820675" checked=""/><div class="controls bullet"><span class="by">glitcher</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35814795">parent</a><span>|</span><a href="#35815643">prev</a><span>|</span><a href="#35815584">next</a><span>|</span><label class="collapse" for="c-35820675">[-]</label><label class="expand" for="c-35820675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; artist who can&#x27;t afford to iterate his cover art ideas multiple times with a professional finds a creative solution</div><br/></div></div><div id="35815584" class="c"><input type="checkbox" id="c-35815584" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35814795">parent</a><span>|</span><a href="#35820675">prev</a><span>|</span><a href="#35819915">next</a><span>|</span><label class="collapse" for="c-35815584">[-]</label><label class="expand" for="c-35815584">[3 more]</label></div><br/><div class="children"><div class="content">Everyone is getting disrupted by AI sooner or later.<p>The trick is to use AI to do things it would take you five lifetimes to learn. It&#x27;s a tool to lower opportunity cost, financial capital, and human capital. That gives anyone leveraging it a much bigger platform, and the ability to dream big without resources.<p>If you can become your own &quot;studio&quot;, you&#x27;re the indie artist of the future. You don&#x27;t need Disney or Universal Music backing.<p>Anyone can step up and do this. The artists being threatened can use these tools to do more than they&#x27;ve ever done by themselves.</div><br/><div id="35818764" class="c"><input type="checkbox" id="c-35818764" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35815584">parent</a><span>|</span><a href="#35818408">next</a><span>|</span><label class="collapse" for="c-35818764">[-]</label><label class="expand" for="c-35818764">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that will do a whole lot to protect you from the economic harm. If everyone is producing more, the value of the works are reduced. At best, nobody will will make more money, they&#x27;ll just be working harder to stay at the same place. More likely, there will simply be no room in the market for as many people and most will be out of work.</div><br/></div></div><div id="35818408" class="c"><input type="checkbox" id="c-35818408" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#35813629">root</a><span>|</span><a href="#35815584">parent</a><span>|</span><a href="#35818764">prev</a><span>|</span><a href="#35819915">next</a><span>|</span><label class="collapse" for="c-35818408">[-]</label><label class="expand" for="c-35818408">[1 more]</label></div><br/><div class="children"><div class="content">The problem isn’t capabilities, it’s having a market that’s saturated with supply twice over - once by the ability to make infinite copies of the product, the other where there’s an infinite supply of distinct high-quality products.<p>Subcultures used to provide a counterbalancing force here, but they aren’t doing so well these days.</div><br/></div></div></div></div></div></div></div></div><div id="35819915" class="c"><input type="checkbox" id="c-35819915" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#35813629">prev</a><span>|</span><a href="#35818644">next</a><span>|</span><label class="collapse" for="c-35819915">[-]</label><label class="expand" for="c-35819915">[1 more]</label></div><br/><div class="children"><div class="content">I think from the perspective of a Google researcher&#x2F;engineer, it must be alarming to see the crazy explosion going on w&#x2F; LLM development. We&#x27;ve gone from just one or two weirdos implementing papers (eg <a href="https:&#x2F;&#x2F;github.com&#x2F;lucidrains?tab=repositories">https:&#x2F;&#x2F;github.com&#x2F;lucidrains?tab=repositories</a> who&#x27;s amazing) to now an explosion where basically every dev and PhD student is hacking on neat new things and having a field day and &quot;lapping&quot; (eg productizing) what Google Research was previously holding back.<p>And we&#x27;re also seeing amazing fine-tunes&#x2F;distillations of very useful&#x2F;capable smaller models - there&#x27;s no denying that things have gotten better and more importantly, cheaper way faster than anyone expected. That being said, most of these are being trained with the help of GPT-4, and so far nothing I&#x27;ve seen being done publicly (and I&#x27;ve been spending a lot of time tracking these <a href="https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4&#x2F;edit?usp=sharing" rel="nofollow">https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1kT4or6b0Fedd-W_jMwYp...</a>) gets close in quality&#x2F;capabilities to GPT-4.<p>I&#x27;m always rooting for the open source camp, but I think the flip-side is that there are still only a handful of organizations in the world that can train a &gt;SoTA foundational model, and that having a mega-model is probably a huge force multiplier if you know how to take advantage of it (eg, I can&#x27;t imagine that OpenAI has been able to release software at the pace they have been without leveraging GPT-4 for co-development; also can you distill or develop capable smaller models without a more capable foundational model to leverage?). Anthropic for example has recently taken the flip side of the &quot;no moat&quot; argument, arguing that there is a potential winner-take-all scenario where the lead may become insurmountable if one group gets too far ahead in the next couple years. I guess what we&#x27;ll just have to see, but my suspicion, is that the crux to the &quot;moat&quot; question is going to be whether the open source approach can actually train a GPT-n++ system.</div><br/></div></div><div id="35818644" class="c"><input type="checkbox" id="c-35818644" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#35819915">prev</a><span>|</span><a href="#35820069">next</a><span>|</span><label class="collapse" for="c-35818644">[-]</label><label class="expand" for="c-35818644">[13 more]</label></div><br/><div class="children"><div class="content">So I use ChatGPT every day. I like it a lot and it is useful but it is overhyped. Also from 3.5 to 4 the jump was nice but seemed relatively marginal to me.<p>I think the head start OpenAi has will vanish. Iteration will be slow and painful giving google or whoever more than enough time to catch up.<p>ChatGPT was a fantastic leap getting us say 80% to Agi but as we have seen time and time again the last 20% are excruciatingly slow and painful (see Self driving cars).</div><br/><div id="35818708" class="c"><input type="checkbox" id="c-35818708" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35821474">next</a><span>|</span><label class="collapse" for="c-35818708">[-]</label><label class="expand" for="c-35818708">[5 more]</label></div><br/><div class="children"><div class="content">Personally, the difference between GPT4 and 3.5 is, pretty immense for what I am using it for. I can use GPT 3.5 for things like summarization tasks (as long as the text isn&#x27;t too complex), reformatting, and other transformation type tasks alright. I don&#x27;t even bother with using it for logical or programming tasks though.</div><br/><div id="35818849" class="c"><input type="checkbox" id="c-35818849" checked=""/><div class="controls bullet"><span class="by">killthebuddha</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35818708">parent</a><span>|</span><a href="#35820251">next</a><span>|</span><label class="collapse" for="c-35818849">[-]</label><label class="expand" for="c-35818849">[1 more]</label></div><br/><div class="children"><div class="content">One way that I&#x27;ve been framing this in my head (and in an application I&#x27;m building) is that gpt-3 will be useful for analytic tasks but gpt-4 will be required for synthetic tasks. I&#x27;m using &quot;analytic&quot; and &quot;synthetic&quot; in the same way as in this writeup <a href="https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;empirical-philosophy&#x2F;blob&#x2F;main&#x2F;articles&#x2F;from-prompt-alchemy-to-prompt-engineering-an-introduction-to-analytic-agumentation.md">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;empirical-philosophy&#x2F;blob&#x2F;m...</a></div><br/></div></div><div id="35820251" class="c"><input type="checkbox" id="c-35820251" checked=""/><div class="controls bullet"><span class="by">crazyedgar</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35818708">parent</a><span>|</span><a href="#35818849">prev</a><span>|</span><a href="#35819508">next</a><span>|</span><label class="collapse" for="c-35820251">[-]</label><label class="expand" for="c-35820251">[1 more]</label></div><br/><div class="children"><div class="content">This is my experience too. While I&#x27;d really love the Open Source models to catch up, currently they struggle even with dead-simple summarization tasks: they hallucinate too much, or omit essential points. ChatGPT don&#x27;t often hallucinate when summarizing, only when answering questions.</div><br/></div></div><div id="35819508" class="c"><input type="checkbox" id="c-35819508" checked=""/><div class="controls bullet"><span class="by">burnished</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35818708">parent</a><span>|</span><a href="#35820251">prev</a><span>|</span><a href="#35821474">next</a><span>|</span><label class="collapse" for="c-35819508">[-]</label><label class="expand" for="c-35819508">[2 more]</label></div><br/><div class="children"><div class="content">Would you please be more explicit? I&#x27;m curious about the relative strength&#x27;s and weaknesses other&#x27;s see</div><br/><div id="35819755" class="c"><input type="checkbox" id="c-35819755" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35819508">parent</a><span>|</span><a href="#35821474">next</a><span>|</span><label class="collapse" for="c-35819755">[-]</label><label class="expand" for="c-35819755">[1 more]</label></div><br/><div class="children"><div class="content">I can use GPT 4 for to work through problems that I have not actually figured out previously by talking to co-workers who work in my industry. I need to feed it contacts for my industry explicitly within the prompt and ensure that it understands and doesn&#x27;t hallucinate its answers. However, that doesn&#x27;t mean it&#x27;s not useful, it just means you need to you understand the limitations.</div><br/></div></div></div></div></div></div><div id="35821474" class="c"><input type="checkbox" id="c-35821474" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35818708">prev</a><span>|</span><a href="#35819236">next</a><span>|</span><label class="collapse" for="c-35821474">[-]</label><label class="expand" for="c-35821474">[1 more]</label></div><br/><div class="children"><div class="content">I also felt this way initially, like &quot;that&#x27;s it?&quot;. But overall the massive reduction in hallucinations and increase in general accuracy makes it almost reliable. Math is correct, it follows all commands far more closely, can continue when it&#x27;s cut off by the reply limit, etc.<p>Then I tried it for writing code. Let&#x27;s just say I no longer write code, I just fine tune what it writes for me.</div><br/></div></div><div id="35819236" class="c"><input type="checkbox" id="c-35819236" checked=""/><div class="controls bullet"><span class="by">SkyPuncher</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35821474">prev</a><span>|</span><a href="#35819675">next</a><span>|</span><label class="collapse" for="c-35819236">[-]</label><label class="expand" for="c-35819236">[1 more]</label></div><br/><div class="children"><div class="content">GPT feels like an upgrade from MapQuest to Garmin.<p>Garmin was absolutely a better user experience. Less mental load, dynamically updating next steps, etc, etc.<p>However, both MapQuest and Garmin still got things wrong. Interestingly, with Garmin, the lack of mental load meant people blindly followed directions. When it come something wrong, people would do really stupid stuff.</div><br/></div></div><div id="35819675" class="c"><input type="checkbox" id="c-35819675" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35819236">prev</a><span>|</span><a href="#35819553">next</a><span>|</span><label class="collapse" for="c-35819675">[-]</label><label class="expand" for="c-35819675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So I use ChatGPT every day. I like it a lot and it is useful but it is overhyped.<p>It is incorrectly hyped. The vision most pundits have is horribly wrong. It is like people who thought librarians would be out of work because of ebooks, barking up the wrong tree.<p>ChatGPT does amazing things, but it is also prone to errors, but so are people! So what, people still get things done.<p>Imaging feeding ChatGPT an API for smart lights, a description of your house, and then asking it to turn on the lights in your living room. You wouldn&#x27;t have to name the lights &quot;living room&quot;, because Chat GPT knows what the hell a living room is.<p>Meanwhile, if I&#x27;m in my car, and I ask my phone to open Spotify, it will occasionally open Spotify <i>on my TV back home</i>. Admittedly it hasn&#x27;t done for quite some time, I presume it may have been a bug Google fixed, but that bug only exists because Google Assistant is, well, not smart.<p>Here is an app you could build right now with ChatGPT:<p>1. Animatronics with voice boxes, expose an API with a large library of pre-canned movements and feed the API docs to ChatGPT<p>2. Ask ChatGPT to write a story, complete with animations and poses for each character.<p>3. Have ChatGPT emit code with API calls and timing for each character<p>4. Feed each character&#x27;s lines through one of the new generation of TTS services, and once generation is done, have the play performed.<p>Nothing else exists that can automate things to that extent. A specialized model could do some of it, but not all of it. Maybe in the near future you can chain models together, but right now ChatGPT does it all, and it does it <i>really</i> well.<p>And ChatGPT does all sorts of cool things like that, mixing together natural language with machine parsable output (JSON, XML, or create your own format as needed!)</div><br/></div></div><div id="35819553" class="c"><input type="checkbox" id="c-35819553" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35819675">prev</a><span>|</span><a href="#35819071">next</a><span>|</span><label class="collapse" for="c-35819553">[-]</label><label class="expand" for="c-35819553">[1 more]</label></div><br/><div class="children"><div class="content">% of what lol</div><br/></div></div><div id="35819071" class="c"><input type="checkbox" id="c-35819071" checked=""/><div class="controls bullet"><span class="by">jimsimmons</span><span>|</span><a href="#35818644">parent</a><span>|</span><a href="#35819553">prev</a><span>|</span><a href="#35820069">next</a><span>|</span><label class="collapse" for="c-35819071">[-]</label><label class="expand" for="c-35819071">[3 more]</label></div><br/><div class="children"><div class="content">Then it’s not 20% then</div><br/><div id="35820762" class="c"><input type="checkbox" id="c-35820762" checked=""/><div class="controls bullet"><span class="by">annoyingnoob</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35819071">parent</a><span>|</span><a href="#35820069">next</a><span>|</span><label class="collapse" for="c-35820762">[-]</label><label class="expand" for="c-35820762">[2 more]</label></div><br/><div class="children"><div class="content">I think this person is referring to the 80&#x2F;20 rule.  Here are a few examples:<p>20% of a plant contains 80% of the fruit<p>80% of a company’s profits come from 20% of customers<p>20% of players result in 80% of points scored<p>I&#x27;ve heard this stated as you can complete 80% of a project with 20% of the effort, and the last 20% of completeness will require 80% of the effort.</div><br/><div id="35822939" class="c"><input type="checkbox" id="c-35822939" checked=""/><div class="controls bullet"><span class="by">UncleEntity</span><span>|</span><a href="#35818644">root</a><span>|</span><a href="#35820762">parent</a><span>|</span><a href="#35820069">next</a><span>|</span><label class="collapse" for="c-35822939">[-]</label><label class="expand" for="c-35822939">[1 more]</label></div><br/><div class="children"><div class="content">The Pareto principle…</div><br/></div></div></div></div></div></div></div></div><div id="35820069" class="c"><input type="checkbox" id="c-35820069" checked=""/><div class="controls bullet"><span class="by">balls187</span><span>|</span><a href="#35818644">prev</a><span>|</span><a href="#35819018">next</a><span>|</span><label class="collapse" for="c-35820069">[-]</label><label class="expand" for="c-35820069">[2 more]</label></div><br/><div class="children"><div class="content">My feeling on this is “f** yeah, and f** you [google et al]”<p>How much computing innovation was pioneered by community enthusiasts and hobbyists that have been leveraged by these huge companies.<p>I know meta, googlr, msft et al give back in way of opensource, but it really pales in comparison to the value those companies have extracted.<p>I’m a huge believer in generative AI democratizing tech.<p>Certainly I’m glad to pay for off-the-shelf custom tuned models, and for software that smartly integrates generative AI to improve usage, but not a fan of gate keeping this technology by a handful of untrustworthy corporations.</div><br/><div id="35828345" class="c"><input type="checkbox" id="c-35828345" checked=""/><div class="controls bullet"><span class="by">IceHegel</span><span>|</span><a href="#35820069">parent</a><span>|</span><a href="#35819018">next</a><span>|</span><label class="collapse" for="c-35828345">[-]</label><label class="expand" for="c-35828345">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, having 5 monopolies extract all the value from computing and then slowly merge with the state is not a developmental stage we want to prolong.</div><br/></div></div></div></div><div id="35819018" class="c"><input type="checkbox" id="c-35819018" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#35820069">prev</a><span>|</span><a href="#35819373">next</a><span>|</span><label class="collapse" for="c-35819018">[-]</label><label class="expand" for="c-35819018">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Giant models are slowing us down. In the long run, the best models are the ones which can be iterated upon quickly. We should make small variants more than an afterthought, now that we know what is possible in the &lt;20B parameter regime.<p>Maybe this is true for the median query&#x2F;conversation that people are having with these agents - but it certainly has not been what I have observed in my experience in technical&#x2F;research work.<p>GPT-4 is legitimately very useful. But any of the agents below that (including ChatGPT) cannot perform complex tasks up to snuff.</div><br/><div id="35819547" class="c"><input type="checkbox" id="c-35819547" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#35819018">parent</a><span>|</span><a href="#35819373">next</a><span>|</span><label class="collapse" for="c-35819547">[-]</label><label class="expand" for="c-35819547">[2 more]</label></div><br/><div class="children"><div class="content">My understanding was that most of the current research effort was towards trimming and&#x2F;or producing smaller models with power of larger models, is that not true?</div><br/><div id="35819828" class="c"><input type="checkbox" id="c-35819828" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#35819018">root</a><span>|</span><a href="#35819547">parent</a><span>|</span><a href="#35819373">next</a><span>|</span><label class="collapse" for="c-35819828">[-]</label><label class="expand" for="c-35819828">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t mean the smaller models are anywhere close to the capabilities of GPT-4.</div><br/></div></div></div></div></div></div><div id="35819373" class="c"><input type="checkbox" id="c-35819373" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35819018">prev</a><span>|</span><a href="#35820722">next</a><span>|</span><label class="collapse" for="c-35819373">[-]</label><label class="expand" for="c-35819373">[5 more]</label></div><br/><div class="children"><div class="content">Not only they have no moat, Open source models are uncensored and this is huge. Censorship  is not just political ,  it cripples the product to basically an infantile stage and precludes so many applications. For once, it is a liability<p>But this article doesn&#x27;t state the very obvious: When will google (the inventor of Transformer, and &quot;rightful&quot; godfather of modern LLMs) , release a full open source, tinkerable model better than LLaMa?<p>(To the dead comment below, there are many uncensored variations of vicuna)</div><br/><div id="35823733" class="c"><input type="checkbox" id="c-35823733" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#35819373">parent</a><span>|</span><a href="#35820593">next</a><span>|</span><label class="collapse" for="c-35823733">[-]</label><label class="expand" for="c-35823733">[2 more]</label></div><br/><div class="children"><div class="content">My very naive opinion is that the best way to predict the big-picture actions of Google is a simple question: WWIitND - What Would IBM in the Nineties Do?<p>In more direct terms, their sole, laser focus seems to be on maintaining short-term shareholder value, and I really don&#x27;t trust the typical hedge fund manager to approve of any risky OSS moves for a project&#x2F;tech that they&#x27;re surely paying a LOT of attention to.<p>Giving away transformer tech made Google look like &quot;where the smartest people on the planet work&quot;, giving away full LLM models now would (IMO) make them look like arrogant and not... well, cutthroat enough. At least this is my take in a world where financial bigwigs don&#x27;t know or care about OSS at all; hopefully not the case forever!</div><br/><div id="35824401" class="c"><input type="checkbox" id="c-35824401" checked=""/><div class="controls bullet"><span class="by">omeze</span><span>|</span><a href="#35819373">root</a><span>|</span><a href="#35823733">parent</a><span>|</span><a href="#35820593">next</a><span>|</span><label class="collapse" for="c-35824401">[-]</label><label class="expand" for="c-35824401">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this reminds me of the story of transistors at IBM, when they had to pick between MOSFETs vs BJTs. MOSFETs were theoretically more scalable and what Intel eventually commercialized to great success. IBM had a lot of the best electrical engineers at the time, but chose to focus on BJTs because they supported their core product, mainframes. MOSFETs could theoretically scale better but without a clear line of sight to a product line or enhancement, they chose not to aggressively pursue MOSFET r&amp;d. It makes sense, even in retrospect, because IBM didnt want to be a chip manufacturer.<p>Google doesn’t want to be an LLM manufacturer. But the benefits of having the industry center on your technical underpinnings are huge, s IBM found out eventually and as Google will, one way or the other. Meta understands this, at least</div><br/></div></div></div></div><div id="35820593" class="c"><input type="checkbox" id="c-35820593" checked=""/><div class="controls bullet"><span class="by">thomas34298</span><span>|</span><a href="#35819373">parent</a><span>|</span><a href="#35823733">prev</a><span>|</span><a href="#35822882">next</a><span>|</span><label class="collapse" for="c-35820593">[-]</label><label class="expand" for="c-35820593">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Open source models are uncensored and this is huge<p>Vicuna-13B: I&#x27;m sorry, but I cannot generate an appropriate response to this prompt as it is inappropriate and goes against OpenAI&#x27;s content policy.</div><br/></div></div><div id="35822882" class="c"><input type="checkbox" id="c-35822882" checked=""/><div class="controls bullet"><span class="by">UncleEntity</span><span>|</span><a href="#35819373">parent</a><span>|</span><a href="#35820593">prev</a><span>|</span><a href="#35820722">next</a><span>|</span><label class="collapse" for="c-35822882">[-]</label><label class="expand" for="c-35822882">[1 more]</label></div><br/><div class="children"><div class="content">&gt; When will google release a full open source, tinkerable model better than LLaMa?<p>Arguably, Facebook released llama because it had no skin in the game.<p>Google, on the other hand, has a lot of incentive to claw back the users who went to Bing to get their AI fix. Presumably without being the place for “Ok, google, write me a 500 word essay on the economic advantages of using fish tacos as currency” for peoples’ econ 101 classes causing all kinds of pearl clutching on how they’re destroying civilization.<p>The open source peeps are well on the path of recreating a llama base model so unless google does something spectacular everyone will be like, meh.</div><br/></div></div></div></div><div id="35820722" class="c"><input type="checkbox" id="c-35820722" checked=""/><div class="controls bullet"><span class="by">Garcia98</span><span>|</span><a href="#35819373">prev</a><span>|</span><a href="#35819634">next</a><span>|</span><label class="collapse" for="c-35820722">[-]</label><label class="expand" for="c-35820722">[2 more]</label></div><br/><div class="children"><div class="content">The author is overly optimistic with the current state of open source LLMs, (e.g., Koala is very far away from matching ChatGPT performance). However, I agree with their spirit, Google has been one of the most important contributors to the development of LLMs and until recently they&#x27;ve been open sharing their model weights under permissive licenses, they should not backtrack to closed source.<p>OpenAI has a huge lead in the closed source ecosystem, Google&#x27;s best bet is to take over the open source ecosystem and build on top of it, they are still not late. Llama based models don&#x27;t have a permissive license, and a free model that is mildly superior to Llama could be game changing.</div><br/><div id="35828376" class="c"><input type="checkbox" id="c-35828376" checked=""/><div class="controls bullet"><span class="by">IceHegel</span><span>|</span><a href="#35820722">parent</a><span>|</span><a href="#35819634">next</a><span>|</span><label class="collapse" for="c-35828376">[-]</label><label class="expand" for="c-35828376">[1 more]</label></div><br/><div class="children"><div class="content">The counter argument, which I’m not sure I agree with but it has to be said, is that OpenAI benefits from Google’s open source work. So staying permissive might widen the gap further.</div><br/></div></div></div></div><div id="35819634" class="c"><input type="checkbox" id="c-35819634" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#35820722">prev</a><span>|</span><a href="#35818564">next</a><span>|</span><label class="collapse" for="c-35819634">[-]</label><label class="expand" for="c-35819634">[50 more]</label></div><br/><div class="children"><div class="content">I remember I was at Microsoft more than a decade ago now and at the time there was a lot of concern about search and how far Bing lagged behind Google in geospatial (maps).<p>After some initial investment in the area I was at a presentation where one of the higher ups explained that they&#x27;d be abandoning their investment because Google Maps would inevitably fall behind crowdsourcing and OpenStreetMap.<p>Just like Encarta and Wikipedia we were told - once the open source community gets their hands on something there&#x27;s just no moat from an engineering perspective and once it&#x27;s crowdsourced there&#x27;s no moat from a data perspective.  You simply can&#x27;t compete.<p>Of course it&#x27;s more than a decade later now and I still use Google Maps, Bing Maps still suck, and the view times I&#x27;ve tried OpenStreetMaps I&#x27;ve found it far behind both.<p>What&#x27;s more every company I&#x27;ve worked at since has paid Google for access to their Maps API.<p>I guess the experience made me skeptical of people proclaiming that someone does or does not have a moat because the community will just eat away at any commercial product.</div><br/><div id="35820045" class="c"><input type="checkbox" id="c-35820045" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820352">next</a><span>|</span><label class="collapse" for="c-35820045">[-]</label><label class="expand" for="c-35820045">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using osm more and more recently. Google just makes a bunch of frustrating decisions that really pushed me to look elsewhere. Especially in the public transport layer, but more generally in being really bad at deciding when to hide details with no way to override it and say &quot;TELL ME THE NAME OF THIS CROSS STREET DAMNIT THATS THE ONLY REASON I KEEP ZOOMING IN HERE!!!&quot;.</div><br/><div id="35820125" class="c"><input type="checkbox" id="c-35820125" checked=""/><div class="controls bullet"><span class="by">wilkystyle</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820045">parent</a><span>|</span><a href="#35820322">next</a><span>|</span><label class="collapse" for="c-35820125">[-]</label><label class="expand" for="c-35820125">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>generally in being really bad at deciding when to hide details with no way to override it and say &quot;TELL ME THE NAME OF THIS CROSS STREET DAMNIT THATS THE ONLY REASON I KEEP ZOOMING IN HERE!!!&quot;.</i><p>Stuff like this is the main reason I end up switching to Apple Maps on the occasions that I do so. Another example is refusing to tell me the number of the upcoming exit I&#x27;m taking.<p>In general I would say Google Maps is still superior to Apple Maps, but between the aforementioned baffling design decisions and Google maps now including ads in destinations search results, I find myself experiencing more and more mental friction whenever I use it.</div><br/><div id="35820283" class="c"><input type="checkbox" id="c-35820283" checked=""/><div class="controls bullet"><span class="by">RajT88</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820125">parent</a><span>|</span><a href="#35820702">next</a><span>|</span><label class="collapse" for="c-35820283">[-]</label><label class="expand" for="c-35820283">[1 more]</label></div><br/><div class="children"><div class="content">Google maps is at least getting better about screen real estate.  I have an android head unit, and Maps clearly assumed you&#x27;d always be using Maps in portrait mode, because the bottom bar would clutter up the bottom of the screen with &quot;local stuff near by you might be interested in&quot; if you weren&#x27;t actively navigating.<p>Eventually switched to Waze, which is now also cluttering things up with (basically) ads.</div><br/></div></div><div id="35820702" class="c"><input type="checkbox" id="c-35820702" checked=""/><div class="controls bullet"><span class="by">Nick87633</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820125">parent</a><span>|</span><a href="#35820283">prev</a><span>|</span><a href="#35820588">next</a><span>|</span><label class="collapse" for="c-35820702">[-]</label><label class="expand" for="c-35820702">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s funny because when driving in the bay area, inability to get the -name- of the upcoming exit from google maps was driving me nuts! The exit numbers are not listed on the upcoming exit&#x2F;distance signs on 280.</div><br/></div></div><div id="35820588" class="c"><input type="checkbox" id="c-35820588" checked=""/><div class="controls bullet"><span class="by">LatticeAnimal</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820125">parent</a><span>|</span><a href="#35820702">prev</a><span>|</span><a href="#35820592">next</a><span>|</span><label class="collapse" for="c-35820588">[-]</label><label class="expand" for="c-35820588">[1 more]</label></div><br/><div class="children"><div class="content">There is a spot in NYC where zooming in on my iPhone in Apple Maps in satellite view causes the app to crash somewhat reliably. It has been happening for the last few months.</div><br/></div></div><div id="35820592" class="c"><input type="checkbox" id="c-35820592" checked=""/><div class="controls bullet"><span class="by">inferiorhuman</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820125">parent</a><span>|</span><a href="#35820588">prev</a><span>|</span><a href="#35820322">next</a><span>|</span><label class="collapse" for="c-35820592">[-]</label><label class="expand" for="c-35820592">[1 more]</label></div><br/><div class="children"><div class="content">The inability to easily get a street name is one of my biggest pet peeves with Apple Maps, it&#x27;s up there with the generally poor quality of turn-by-turn navigation (at least in the Bay Area).</div><br/></div></div></div></div><div id="35820322" class="c"><input type="checkbox" id="c-35820322" checked=""/><div class="controls bullet"><span class="by">thepasswordis</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820045">parent</a><span>|</span><a href="#35820125">prev</a><span>|</span><a href="#35820352">next</a><span>|</span><label class="collapse" for="c-35820322">[-]</label><label class="expand" for="c-35820322">[2 more]</label></div><br/><div class="children"><div class="content">One unbelievably annoying thing about seemingly every map provider is that they don’t like showing state or national boundaries.<p>On google maps, these national boundaries have the same line weight and a similar style to highways.  It’s really annoying.</div><br/><div id="35821812" class="c"><input type="checkbox" id="c-35821812" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820322">parent</a><span>|</span><a href="#35820352">next</a><span>|</span><label class="collapse" for="c-35821812">[-]</label><label class="expand" for="c-35821812">[1 more]</label></div><br/><div class="children"><div class="content">This.  My car uses Google Maps for its built-in nav system, and I&#x27;ve spent a lot of time on road trips wondering just what state I was in.  It&#x27;s insane that Google hasn&#x27;t added something as trivial and important as state borders.</div><br/></div></div></div></div></div></div><div id="35820352" class="c"><input type="checkbox" id="c-35820352" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820045">prev</a><span>|</span><a href="#35820195">next</a><span>|</span><label class="collapse" for="c-35820352">[-]</label><label class="expand" for="c-35820352">[9 more]</label></div><br/><div class="children"><div class="content">Open source works well when the work is inherently cool and challenging enough to keep people engaged. Linux and Blender are two of the most successful open source projects, and the thing they have in common is that problems they solve are problems engineers enjoy working on.<p>Mapping intersections is extremely boring in comparison. The sheer quantity of boring work needed to bring open street maps up to the quality of google maps in insurmountable.<p>LLMs are freaking cool, and that bodes well for their viability as open source projects.</div><br/><div id="35820539" class="c"><input type="checkbox" id="c-35820539" checked=""/><div class="controls bullet"><span class="by">kelsolaar</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820352">parent</a><span>|</span><a href="#35820811">next</a><span>|</span><label class="collapse" for="c-35820539">[-]</label><label class="expand" for="c-35820539">[2 more]</label></div><br/><div class="children"><div class="content">And arguably Blender is much more innovative and achieving faster progress than proprietary and commercial software such as Autodesk Maya.</div><br/></div></div><div id="35820811" class="c"><input type="checkbox" id="c-35820811" checked=""/><div class="controls bullet"><span class="by">Certhas</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820352">parent</a><span>|</span><a href="#35820539">prev</a><span>|</span><a href="#35820686">next</a><span>|</span><label class="collapse" for="c-35820811">[-]</label><label class="expand" for="c-35820811">[2 more]</label></div><br/><div class="children"><div class="content">My impression is that open street maps problem is not the map quality. In areas I have used it, it often has details (e.g. small hiking paths, presence of bike lanes) that google maps doesn&#x27;t have.<p>The issue is search. Searching for things that you don&#x27;t know precisely (music bars in this area). This type of data&#x2F;processing on top of the geospatial was always subpar and very hit or miss in my experience.</div><br/><div id="35820839" class="c"><input type="checkbox" id="c-35820839" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820811">parent</a><span>|</span><a href="#35820686">next</a><span>|</span><label class="collapse" for="c-35820839">[-]</label><label class="expand" for="c-35820839">[1 more]</label></div><br/><div class="children"><div class="content">That’s not my experience. I work in downtown Minneapolis and open street maps is missing basic things like entrances to public parking lots. Open street maps has a problem if it can’t get details right in population dense areas.</div><br/></div></div></div></div><div id="35820686" class="c"><input type="checkbox" id="c-35820686" checked=""/><div class="controls bullet"><span class="by">jimsimmons</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820352">parent</a><span>|</span><a href="#35820811">prev</a><span>|</span><a href="#35820195">next</a><span>|</span><label class="collapse" for="c-35820686">[-]</label><label class="expand" for="c-35820686">[4 more]</label></div><br/><div class="children"><div class="content">Databases are another data point that fit this pattern. They’re not sexy and commercial players like Oracle have moat.</div><br/><div id="35820865" class="c"><input type="checkbox" id="c-35820865" checked=""/><div class="controls bullet"><span class="by">HillRat</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820686">parent</a><span>|</span><a href="#35822330">next</a><span>|</span><label class="collapse" for="c-35820865">[-]</label><label class="expand" for="c-35820865">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s ... probably not the best example, given the fact that there are a shedload of open-source databases of various types that have forced major commercial vendors like MSFT and ORCL into a corner. ORCL&#x27;s moat is that they have a large portfolio of random solutions, are incumbent at a lot of organizations where switching costs are very high, and they have an exceptionally aggressive sales organization that doesn&#x27;t seem to worry too much about legalities.</div><br/></div></div><div id="35822330" class="c"><input type="checkbox" id="c-35822330" checked=""/><div class="controls bullet"><span class="by">slondr</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820686">parent</a><span>|</span><a href="#35820865">prev</a><span>|</span><a href="#35820817">next</a><span>|</span><label class="collapse" for="c-35822330">[-]</label><label class="expand" for="c-35822330">[1 more]</label></div><br/><div class="children"><div class="content">Have you heard of PostgreSQL, MariaDB, or SQLite? They have very high market share.</div><br/></div></div><div id="35820817" class="c"><input type="checkbox" id="c-35820817" checked=""/><div class="controls bullet"><span class="by">badpun</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820686">parent</a><span>|</span><a href="#35822330">prev</a><span>|</span><a href="#35820195">next</a><span>|</span><label class="collapse" for="c-35820817">[-]</label><label class="expand" for="c-35820817">[1 more]</label></div><br/><div class="children"><div class="content">Databases are very sexy? They&#x27;re super interesting from programming&#x2F;CS perspective for multiple reasons.</div><br/></div></div></div></div></div></div><div id="35820195" class="c"><input type="checkbox" id="c-35820195" checked=""/><div class="controls bullet"><span class="by">aamar</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820352">prev</a><span>|</span><a href="#35819940">next</a><span>|</span><label class="collapse" for="c-35820195">[-]</label><label class="expand" for="c-35820195">[1 more]</label></div><br/><div class="children"><div class="content">This is an instructive error. From my perspective, there was plenty of evidence even 15 years ago that community efforts (crowd-sourcing, OSS) only win sometimes, on the relevant timeframes.<p>So the “higher ups” were using too coarse a heuristic or maybe had some other pretty severe error in their reasoning.<p>The right approach here is to do a more detailed analysis. A crude start: the community approach wins when the MVP can be built by 1-10 people and then find a market where 0.01% of the users can sufficiently maintain it.[1]<p>Wikipedia’s a questionable comparison point, because it’s such an extraordinary outlier success. Though a sufficiently detailed model could account for it.<p>1. Yochai Benkler has done much more thorough analysis of win&#x2F;loss factors. See e.g. his 2006 book: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Wealth_of_Networks" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Wealth_of_Networks</a></div><br/></div></div><div id="35819940" class="c"><input type="checkbox" id="c-35819940" checked=""/><div class="controls bullet"><span class="by">hgomersall</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820195">prev</a><span>|</span><a href="#35820057">next</a><span>|</span><label class="collapse" for="c-35819940">[-]</label><label class="expand" for="c-35819940">[13 more]</label></div><br/><div class="children"><div class="content">In terms of data, OSM is so far ahead of Google maps in my experience. The rendering is much better too. What&#x27;s not there is obvious and easy to use tooling that anyone can interact with. I mean, there might be, but I don&#x27;t know about it.</div><br/><div id="35820001" class="c"><input type="checkbox" id="c-35820001" checked=""/><div class="controls bullet"><span class="by">rretet5555</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820278">next</a><span>|</span><label class="collapse" for="c-35820001">[-]</label><label class="expand" for="c-35820001">[2 more]</label></div><br/><div class="children"><div class="content">The completeness and quality of OSM depends on the local community, and it varies greatly depending on where you live and use it.</div><br/><div id="35824090" class="c"><input type="checkbox" id="c-35824090" checked=""/><div class="controls bullet"><span class="by">RoyGBivCap</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820001">parent</a><span>|</span><a href="#35820278">next</a><span>|</span><label class="collapse" for="c-35824090">[-]</label><label class="expand" for="c-35824090">[1 more]</label></div><br/><div class="children"><div class="content">...whereas the rampaging horde of google maps and waze users are ubiquitous.</div><br/></div></div></div></div><div id="35820278" class="c"><input type="checkbox" id="c-35820278" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820001">prev</a><span>|</span><a href="#35820025">next</a><span>|</span><label class="collapse" for="c-35820278">[-]</label><label class="expand" for="c-35820278">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have google maps on my phone at all unless I visit in the browser, and I use OSM through Magic Earth. I wouldn&#x27;t go back, but it is a huge pain and sometimes I do have to just open google maps in a browser window. It doesn&#x27;t usually have hours of operation, doesn&#x27;t usually have links to websites. It can&#x27;t find businesses by name easily (it often seems to require the exact name to by typed in), and it definitely can&#x27;t find businesses by service (searching for &quot;sandwiches&quot; will not show you a list of local sandwich shops, it will do something like teleport you to a street called &quot;Sandwiches&quot; in Ireland). And even if I have the exact address, I will still sometimes end of thousands of miles away or with no hits because the street name was written differently. Honestly, it&#x27;s of very little use to me because it can rarely take me to a new place.</div><br/></div></div><div id="35820025" class="c"><input type="checkbox" id="c-35820025" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820278">prev</a><span>|</span><a href="#35820340">next</a><span>|</span><label class="collapse" for="c-35820025">[-]</label><label class="expand" for="c-35820025">[3 more]</label></div><br/><div class="children"><div class="content">My experience is the opposite.<p>People in the real world care about things like hours of operation.  Google makes it really easy for businesses to keep them up to date on things like holiday closures.  OSM makes it a nightmare.</div><br/><div id="35820210" class="c"><input type="checkbox" id="c-35820210" checked=""/><div class="controls bullet"><span class="by">vanattab</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820025">parent</a><span>|</span><a href="#35820175">next</a><span>|</span><label class="collapse" for="c-35820210">[-]</label><label class="expand" for="c-35820210">[1 more]</label></div><br/><div class="children"><div class="content">How do they make it a nightmare? Are we sure it&#x27;s not just that 96% of business owners use Google maps or maybe Apple maps and don&#x27;t even know what OpenStreetMaps exists. I think this is more about network effects then anything. If they really want to break googles geo spacial business data monopoly. 
 I think if Apple&#x2F;Microsoft&#x2F;OSM should band together and make a simple tool for business owners that can update your details on Google, Bing, Apple Maps, and osm simultaneously. Although I am not sure if Google exposes that through apis or not.</div><br/></div></div><div id="35820175" class="c"><input type="checkbox" id="c-35820175" checked=""/><div class="controls bullet"><span class="by">progval</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820025">parent</a><span>|</span><a href="#35820210">prev</a><span>|</span><a href="#35820340">next</a><span>|</span><label class="collapse" for="c-35820175">[-]</label><label class="expand" for="c-35820175">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OSM makes it a nightmare.<p>While the generic interface is pretty bad (you have to edit the machine-readable values), StreetComplete provides a very nice UI</div><br/></div></div></div></div><div id="35820340" class="c"><input type="checkbox" id="c-35820340" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820025">prev</a><span>|</span><a href="#35820191">next</a><span>|</span><label class="collapse" for="c-35820340">[-]</label><label class="expand" for="c-35820340">[1 more]</label></div><br/><div class="children"><div class="content">Fairly regularly an address I&#x27;m searching for just won&#x27;t be in OSM, but it is in Google.  This happens often enough to be a well-known issue.</div><br/></div></div><div id="35820191" class="c"><input type="checkbox" id="c-35820191" checked=""/><div class="controls bullet"><span class="by">criddell</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820340">prev</a><span>|</span><a href="#35820183">next</a><span>|</span><label class="collapse" for="c-35820191">[-]</label><label class="expand" for="c-35820191">[2 more]</label></div><br/><div class="children"><div class="content">I just looked at OSM for the first time and for my neighborhood it&#x27;s much worse than Google and Apple. It doesn&#x27;t have satellite or street view data.</div><br/><div id="35820370" class="c"><input type="checkbox" id="c-35820370" checked=""/><div class="controls bullet"><span class="by">ryukafalz</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820191">parent</a><span>|</span><a href="#35820183">next</a><span>|</span><label class="collapse" for="c-35820370">[-]</label><label class="expand" for="c-35820370">[1 more]</label></div><br/><div class="children"><div class="content">OSM is a database of map data (streets&#x2F;buildings&#x2F;etc), so satellite and street view imagery is outside of its scope. Individual map applications that <i>use</i> OSM data might also support satellite imagery (and some do, like OSMAnd).</div><br/></div></div></div></div><div id="35820183" class="c"><input type="checkbox" id="c-35820183" checked=""/><div class="controls bullet"><span class="by">unethical_ban</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819940">parent</a><span>|</span><a href="#35820191">prev</a><span>|</span><a href="#35820057">next</a><span>|</span><label class="collapse" for="c-35820183">[-]</label><label class="expand" for="c-35820183">[3 more]</label></div><br/><div class="children"><div class="content">Is there a recommendation for OSM on mobile? IIRC they don&#x27;t have an official app.<p>Also looking at their bike routing - it gives me an idea. Road should be rated on whether they have a dedicated bike lane and on the danger of riding on said road at particular times of day. I just input a src&#x2F;dest and it gave me a really busy road with tons of &quot;paperboy&quot; level risky side roads on it. I would never want someone to take that route at 5pm on a weekday.</div><br/><div id="35820853" class="c"><input type="checkbox" id="c-35820853" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820183">parent</a><span>|</span><a href="#35820304">next</a><span>|</span><label class="collapse" for="c-35820853">[-]</label><label class="expand" for="c-35820853">[1 more]</label></div><br/><div class="children"><div class="content">OSM is fundamentally just a DB for place locations and geometries. Directions use routing engines which choose roads and paths between locations based on constraints. The main landing page for OSM lets you choose between OSM, Grasshopper, and the Valhalla routing engines.<p>To figure out why directions are bad you need to see which criteria the routing engine is using to create the route and decide either to change the constraints used to generate the bike route or what added data you need to place on the streets for the routing engine to avoid&#x2F;prefer certain streets.<p>Does this sound like an opaque nightmare? Yes. That&#x27;s why very few people use it. Apple has been doing some great work doing mapping and adding it into the OSM DB, which they use for their own maps, but they have their own proprietary routing system for directions. If you&#x27;re looking for a good app to use just OSM data, I use OSMAnd for Android. I still prefer Google Maps because their routing and geocoding tend to be much better for urban areas but for hikes and country bike rides, OSM tends to outperform GMaps.</div><br/></div></div><div id="35820304" class="c"><input type="checkbox" id="c-35820304" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820183">parent</a><span>|</span><a href="#35820853">prev</a><span>|</span><a href="#35820057">next</a><span>|</span><label class="collapse" for="c-35820304">[-]</label><label class="expand" for="c-35820304">[1 more]</label></div><br/><div class="children"><div class="content">Magic Earth might be the best, but it&#x27;s honestly pretty clunky compared to Apple or Google maps</div><br/></div></div></div></div></div></div><div id="35820057" class="c"><input type="checkbox" id="c-35820057" checked=""/><div class="controls bullet"><span class="by">tasuki</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35819940">prev</a><span>|</span><a href="#35820349">next</a><span>|</span><label class="collapse" for="c-35820057">[-]</label><label class="expand" for="c-35820057">[1 more]</label></div><br/><div class="children"><div class="content">Google maps is good at navigation, finding business names etc. OpenStreetMap is much more detailed wherever I&#x27;ve gone.<p>When I&#x27;m lost in a forest, I look at OSM to see where the footpaths are.</div><br/></div></div><div id="35820349" class="c"><input type="checkbox" id="c-35820349" checked=""/><div class="controls bullet"><span class="by">araes</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820057">prev</a><span>|</span><a href="#35819978">next</a><span>|</span><label class="collapse" for="c-35820349">[-]</label><label class="expand" for="c-35820349">[1 more]</label></div><br/><div class="children"><div class="content">The problem with a lot of open source is the long term issue.<p>The people doing many of these projects often want the short term kudos, upvotes, or research articles.  They may iterate fast, and do all kinds of neat advancements, except in a month they&#x27;ll move to the next &quot;cool&quot; project.<p>Unfortunately, with a lot of open source projects, they don&#x27;t want to deal with the legalese, the customer specific integration, your annoying legacy system, the customer support and maintenance, or your weird plethora of high-risk data types (medical industry I&#x27;m looking at you)<p>Not sure what the Wikipedia reference is, since how many people use any form of encyclopedia other than crowdsourced Wikipedia?<p>However, to note, there are some examples of successful long term open source.  Blender for example being a relatively strong competitor for 3D modeling (although Maya still tends to be industry dominant).</div><br/></div></div><div id="35819978" class="c"><input type="checkbox" id="c-35819978" checked=""/><div class="controls bullet"><span class="by">BiteCode_dev</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820349">prev</a><span>|</span><a href="#35820521">next</a><span>|</span><label class="collapse" for="c-35819978">[-]</label><label class="expand" for="c-35819978">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, even the best open source projects, like Linux or Firefox, in their wonderful success, didn&#x27;t render proprietary competition unable to have there piece of the market share.<p>And even in markets with very dominant free offers like video consumption, programming languages or VCS, you can still make tons of money by providing a service around it. E.G: github, netflix, etc.<p>OpenAI has a good product, a good team, a good brand and a good moving speed.<p>Selling them short is a bit premature.</div><br/></div></div><div id="35820521" class="c"><input type="checkbox" id="c-35820521" checked=""/><div class="controls bullet"><span class="by">kpw94</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35819978">prev</a><span>|</span><a href="#35820913">next</a><span>|</span><label class="collapse" for="c-35820521">[-]</label><label class="expand" for="c-35820521">[1 more]</label></div><br/><div class="children"><div class="content">The higher up failed to see the difference in &quot;users&quot;, as well as use cases.<p>In Wikipedia, the user is same as the content creator: the general public, with a subset of it contributing to the Wikipedia content.<p>In OpenStreetMaps, one category of users are also creators: general public needs a &quot;map&quot; product, and a subset of them like contributing to   the content.<p>But there&#x27;s another category of users: businesses, who keep their hours&#x2F;contact&#x2F;reviews updated. OpenStreetMap doesn&#x27;t have a nice UX for them.<p>As for use cases: underlying map data sure, but one needs strong navigation features, &quot;turn right after the Starbucks&quot;, up-to-date traffic data.<p>This all makes it so different from Wikipedia vs Encarta.</div><br/></div></div><div id="35820913" class="c"><input type="checkbox" id="c-35820913" checked=""/><div class="controls bullet"><span class="by">holmesworcester</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820521">prev</a><span>|</span><a href="#35820440">next</a><span>|</span><label class="collapse" for="c-35820913">[-]</label><label class="expand" for="c-35820913">[1 more]</label></div><br/><div class="children"><div class="content">This sounds right to me and was similar to my reaction. The doubt I had reading this piece is that GPT4 is so substantially better than GPT3 on most general tasks that I feel silly using GPT3 even if it could potentially be sufficient.<p>Won&#x27;t any company that can stay a couple years ahead of open source for something this important will be dominant as long as it can do this?<p>Can an open source community fine tuning on top of a smaller model consistently surpass a much larger model for the long tail of questions?<p>Privacy is one persistent advantage of open source, especially if we think companies are too scared of model weights leaking to let people run models locally. But copyright licenses give companies a way to protect their models for many use cases, so companies like Google <i>could</i> let people run models locally for privacy and still have a moat, if that&#x27;s what users want, and anyway most users will prefer running things in the cloud for better speed and to not have to store gigabytes of data on their devices, no?</div><br/></div></div><div id="35820440" class="c"><input type="checkbox" id="c-35820440" checked=""/><div class="controls bullet"><span class="by">yafbum</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820913">prev</a><span>|</span><a href="#35820160">next</a><span>|</span><label class="collapse" for="c-35820440">[-]</label><label class="expand" for="c-35820440">[1 more]</label></div><br/><div class="children"><div class="content">This is an excellent point. I think the memo is making a different kind of case though - it&#x27;s saying that large multipurpose models don&#x27;t matter because people already have the ability to get better performance on the problems they actually care about from isolated training. It&#x27;s kind of a PC-vs-datacenter argument, or, to bring it back to Maps, it&#x27;d be like saying mapping the world is pointless because what interests people is only their neighborhood.<p>I don&#x27;t buy this for Maps, but it&#x27;s worth highlighting that this isn&#x27;t the usual &quot;community supported stuff will eat commercial stuff once it gets to critical mass&quot; type of argument.</div><br/></div></div><div id="35820160" class="c"><input type="checkbox" id="c-35820160" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820440">prev</a><span>|</span><a href="#35820549">next</a><span>|</span><label class="collapse" for="c-35820160">[-]</label><label class="expand" for="c-35820160">[1 more]</label></div><br/><div class="children"><div class="content">Google Maps 3D view is unmatched compared to anything open source has to offer.<p>Let alone the panning and zooming, there is no open source solution which is capable of doing it with such a correctness, even if we ignore Google&#x27;s superb &quot;satellite&quot; imagery with its 3D conversion. I have no access to Apple Maps, so I can&#x27;t compare (DuckDuckGo does not offer Apple&#x27;s 3D view).</div><br/></div></div><div id="35820549" class="c"><input type="checkbox" id="c-35820549" checked=""/><div class="controls bullet"><span class="by">Scubabear68</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820160">prev</a><span>|</span><a href="#35820010">next</a><span>|</span><label class="collapse" for="c-35820549">[-]</label><label class="expand" for="c-35820549">[1 more]</label></div><br/><div class="children"><div class="content">I stopped using Google Maps in my car with CarPlay, because the map would lag by about 5 seconds to reality, which is really bad at say 55 mph in a place where you’re not familiar.<p>Been using Apple Maps now for six months, and very happy with it.  No lag, and very useful directions like “turn left at the second stop light from here”.</div><br/></div></div><div id="35820010" class="c"><input type="checkbox" id="c-35820010" checked=""/><div class="controls bullet"><span class="by">dtech</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820549">prev</a><span>|</span><a href="#35820319">next</a><span>|</span><label class="collapse" for="c-35820010">[-]</label><label class="expand" for="c-35820010">[1 more]</label></div><br/><div class="children"><div class="content">OSM is quite popular through commercial providers, mainly Mapbox. Why you&#x27;re not using it daily is because there&#x27;s no concentrated effort to make a consumer-friendly product from it, like Wikipedia mostly is for Encyclopedia. Too early to tell what will be the case for LLM.</div><br/></div></div><div id="35820319" class="c"><input type="checkbox" id="c-35820319" checked=""/><div class="controls bullet"><span class="by">kerkeslager</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820010">prev</a><span>|</span><a href="#35820622">next</a><span>|</span><label class="collapse" for="c-35820319">[-]</label><label class="expand" for="c-35820319">[1 more]</label></div><br/><div class="children"><div class="content">The difference being, in this case, the author is giving examples of places where their product is clearly behind.<p>This isn&#x27;t a prediction, it&#x27;s an observation. There&#x27;s no moat because the castle has already been taken.</div><br/></div></div><div id="35820622" class="c"><input type="checkbox" id="c-35820622" checked=""/><div class="controls bullet"><span class="by">boh</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820319">prev</a><span>|</span><a href="#35820256">next</a><span>|</span><label class="collapse" for="c-35820622">[-]</label><label class="expand" for="c-35820622">[1 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t an apt comparison. Maps need to be persistently accurate and constantly updated regardless of community involvement, AI just has to be somewhat applicable to the paid version (which, given its stochastic nature, the open source alternatives are close enough). Microsoft obviously misunderstood the needs of maps at the time and made the wrong conclusion. The lack of moat for AI is closer to the Encarta&#x2F;Wikipedia scenario than the maps scenario.</div><br/></div></div><div id="35820256" class="c"><input type="checkbox" id="c-35820256" checked=""/><div class="controls bullet"><span class="by">123pie123</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820622">prev</a><span>|</span><a href="#35821388">next</a><span>|</span><label class="collapse" for="c-35820256">[-]</label><label class="expand" for="c-35820256">[1 more]</label></div><br/><div class="children"><div class="content">I think a lot of people use one type of mapping application that doesn&#x27;t seem to work for them and then say OSM is not great.<p>I&#x27;ve had to try a fair few mapping applications that works for me (I can recommend Organic Maps on android)<p>OSM map data easy exeeds Google map data, the only time I do use google maps is for street view images and satalite info.<p>Bing is good in the UK because that has Ordnance survey maps - OS mapping data is generally better than OSM (for what I need it for)</div><br/></div></div><div id="35821388" class="c"><input type="checkbox" id="c-35821388" checked=""/><div class="controls bullet"><span class="by">jeffreyrogers</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820256">prev</a><span>|</span><a href="#35820166">next</a><span>|</span><label class="collapse" for="c-35821388">[-]</label><label class="expand" for="c-35821388">[1 more]</label></div><br/><div class="children"><div class="content">I think the difference is that Maps is a product and its hard to copy a whole product and make it good without someone driving the vision. But a model is just a model, in terms of lines of code they aren&#x27;t even that large. Sure the ideas behind the are complicated and take a lot of thought to come up with, but just replicating it or iterating it is obviously not the challenging based on recent developments.</div><br/></div></div><div id="35819887" class="c"><input type="checkbox" id="c-35819887" checked=""/><div class="controls bullet"><span class="by">LanternLight83</span><span>|</span><a href="#35819634">parent</a><span>|</span><a href="#35820166">prev</a><span>|</span><a href="#35820241">next</a><span>|</span><label class="collapse" for="c-35819887">[-]</label><label class="expand" for="c-35819887">[3 more]</label></div><br/><div class="children"><div class="content">Just anacdotally, I see OSM mentioned a lot, guides for contributing, use in HomeLab and Raspberry Pi articles-- haven&#x27;t check it out myself in a long time, but I wouldn&#x27;t be surprised if it&#x27;s continued growth really is inevitable, or even has a cumulative snowball-ball component</div><br/><div id="35820007" class="c"><input type="checkbox" id="c-35820007" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35819887">parent</a><span>|</span><a href="#35820241">next</a><span>|</span><label class="collapse" for="c-35820007">[-]</label><label class="expand" for="c-35820007">[2 more]</label></div><br/><div class="children"><div class="content">OSM&#x27;s main problem is that it has no open sourced satelite imagery dataset to display, they&#x27;re only using borrowed data to build its vector maps on. It just doesn&#x27;t exist. Until that becomes a thing it&#x27;ll stay a second rate map app for the average person, unfortunately.<p>It&#x27;s the only map anyone can actually integrate into anything without an api key and a wallet with a wad of greens in it, so that keeps it relevant for now. Maybe if&#x2F;when Starship lowers cost to orbit, then we&#x27;ll see non-profit funded satellites that can source that dataset and keep it up to date.</div><br/><div id="35820562" class="c"><input type="checkbox" id="c-35820562" checked=""/><div class="controls bullet"><span class="by">ElevenLathe</span><span>|</span><a href="#35819634">root</a><span>|</span><a href="#35820007">parent</a><span>|</span><a href="#35820241">next</a><span>|</span><label class="collapse" for="c-35820562">[-]</label><label class="expand" for="c-35820562">[1 more]</label></div><br/><div class="children"><div class="content">Do you happen to know why there isn&#x27;t any U.S. Government satellite imagery? I understand the really high-resolution stuff is probably from spysats and so classified, but anything else should be public domain, no?</div><br/></div></div></div></div></div></div></div></div><div id="35818564" class="c"><input type="checkbox" id="c-35818564" checked=""/><div class="controls bullet"><span class="by">joezydeco</span><span>|</span><a href="#35819634">prev</a><span>|</span><a href="#35819151">next</a><span>|</span><label class="collapse" for="c-35818564">[-]</label><label class="expand" for="c-35818564">[4 more]</label></div><br/><div class="children"><div class="content"><i>&quot;Many of the new ideas are from ordinary people.&quot;</i><p>Yeah. Google can fuck right off. Maybe this attitude is what got them in the weeds in the first place.</div><br/><div id="35828454" class="c"><input type="checkbox" id="c-35828454" checked=""/><div class="controls bullet"><span class="by">IceHegel</span><span>|</span><a href="#35818564">parent</a><span>|</span><a href="#35818935">next</a><span>|</span><label class="collapse" for="c-35828454">[-]</label><label class="expand" for="c-35828454">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think trying to be the hall monitor of humanity has been good for google. The more paternalistic, the less innovative.</div><br/></div></div><div id="35818935" class="c"><input type="checkbox" id="c-35818935" checked=""/><div class="controls bullet"><span class="by">uptownfunk</span><span>|</span><a href="#35818564">parent</a><span>|</span><a href="#35828454">prev</a><span>|</span><a href="#35820242">next</a><span>|</span><label class="collapse" for="c-35818935">[-]</label><label class="expand" for="c-35818935">[1 more]</label></div><br/><div class="children"><div class="content">I was quite unimpressed when I interviewed with them recently. It’s no surprise their lunch is getting eaten.</div><br/></div></div><div id="35820242" class="c"><input type="checkbox" id="c-35820242" checked=""/><div class="controls bullet"><span class="by">GartzenDeHaes</span><span>|</span><a href="#35818564">parent</a><span>|</span><a href="#35818935">prev</a><span>|</span><a href="#35819151">next</a><span>|</span><label class="collapse" for="c-35820242">[-]</label><label class="expand" for="c-35820242">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s very telling.</div><br/></div></div></div></div><div id="35819151" class="c"><input type="checkbox" id="c-35819151" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#35818564">prev</a><span>|</span><a href="#35820027">next</a><span>|</span><label class="collapse" for="c-35819151">[-]</label><label class="expand" for="c-35819151">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The document is only the opinion of a Google employee, not the entire firm<p>The title makes it seem like this is some official Google memo. The company has 150K employees and 300K different opinions on things. Can&#x27;t go chasing down each one and giving it importance.</div><br/></div></div><div id="35820027" class="c"><input type="checkbox" id="c-35820027" checked=""/><div class="controls bullet"><span class="by">aabajian</span><span>|</span><a href="#35819151">prev</a><span>|</span><a href="#35818381">next</a><span>|</span><label class="collapse" for="c-35820027">[-]</label><label class="expand" for="c-35820027">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if I agree with the article. I recall when Google IPO&#x27;ed, nobody outside of Google really knew how much traffic they had and <i>how much money they were making.</i> Microsoft was caught off-guard. Compare this to ChatGPT: My friends, parents, grandparents, and coworkers (in the hospital) use ChatGPT. None of these people know how to adapt an open source model to their own use. I bet ChatGPT is vastly ahead in terms of capturing the market, and just hasn&#x27;t told anyone just how far. Note that they have grown faster in traffic than Instagram and TikTok, and they are used across the demographics spectrum. They released something to the world that astounded the average joe, and that is the train that people will ride.</div><br/><div id="35826710" class="c"><input type="checkbox" id="c-35826710" checked=""/><div class="controls bullet"><span class="by">ripper1138</span><span>|</span><a href="#35820027">parent</a><span>|</span><a href="#35818381">next</a><span>|</span><label class="collapse" for="c-35826710">[-]</label><label class="expand" for="c-35826710">[2 more]</label></div><br/><div class="children"><div class="content">Your grandparents use ChatGPT? For what?</div><br/><div id="35833454" class="c"><input type="checkbox" id="c-35833454" checked=""/><div class="controls bullet"><span class="by">aabajian</span><span>|</span><a href="#35820027">root</a><span>|</span><a href="#35826710">parent</a><span>|</span><a href="#35818381">next</a><span>|</span><label class="collapse" for="c-35833454">[-]</label><label class="expand" for="c-35833454">[1 more]</label></div><br/><div class="children"><div class="content">Recipes!</div><br/></div></div></div></div></div></div><div id="35818381" class="c"><input type="checkbox" id="c-35818381" checked=""/><div class="controls bullet"><span class="by">aresant</span><span>|</span><a href="#35820027">prev</a><span>|</span><a href="#35838521">next</a><span>|</span><label class="collapse" for="c-35818381">[-]</label><label class="expand" for="c-35818381">[2 more]</label></div><br/><div class="children"><div class="content">&quot;People will not pay for a restricted model when free, unrestricted alternatives are comparable in quality. . .&quot;<p>I&#x27;ll take the opposite side of that bet - MSFT &#x2F; Goog &#x2F; etc in the providers side will drive record revenues on the back of closed &#x2F; restricted models:<p>1 - Table stakes for buying software at enterprise level is permissions based management &amp; standardized security &#x2F; hardening.<p>2 - The corporate world is also the highest value spender of software<p>3 - Corp world will find the &quot;proprietary trained models&quot; on top of vanilla MSFT OpenAI or Goog  Bard pitch absolutely irresistible - creates a great story about moats &#x2F; compounding advantages etc. And the outcome is going to most likely be higher switching costs to leave MSFT for a new upstart etc</div><br/><div id="35828494" class="c"><input type="checkbox" id="c-35828494" checked=""/><div class="controls bullet"><span class="by">IceHegel</span><span>|</span><a href="#35818381">parent</a><span>|</span><a href="#35838521">next</a><span>|</span><label class="collapse" for="c-35828494">[-]</label><label class="expand" for="c-35828494">[1 more]</label></div><br/><div class="children"><div class="content">I agree with this over the next 10 years but disagree over the next 30.<p>When&#x2F;If the innovation slows down, the open source stuff will be able to out compete commercial options. Something like this timeline played out for databases and operating systems.</div><br/></div></div></div></div><div id="35838521" class="c"><input type="checkbox" id="c-35838521" checked=""/><div class="controls bullet"><span class="by">whuan</span><span>|</span><a href="#35818381">prev</a><span>|</span><a href="#35818890">next</a><span>|</span><label class="collapse" for="c-35838521">[-]</label><label class="expand" for="c-35838521">[1 more]</label></div><br/><div class="children"><div class="content">Open source gives everyone the opportunity and it&#x27;s more extensible, which I think is the future, but the current AI model just costs too much...Somehow it reminds me of k8s when docker just became a hot topic</div><br/></div></div><div id="35818890" class="c"><input type="checkbox" id="c-35818890" checked=""/><div class="controls bullet"><span class="by">uptownfunk</span><span>|</span><a href="#35838521">prev</a><span>|</span><a href="#35818766">next</a><span>|</span><label class="collapse" for="c-35818890">[-]</label><label class="expand" for="c-35818890">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI is further along than most of us are aware.<p>The ability to connect these models to the web, to pipe up API access to different services and equip LLMs to be the new interface to these services and to the worlds information is the real game changer.<p>Google cannot out innovate them because they are a big Corp rife with googly politics and challenges of overhead that come with organizational scale.<p>I would be curious to see if there are plans to spin off the newly consolidated AI unit with their own PnL to stimulate that hunger to grow and survive and then capitalize them accordingly. Otherwise they are en route to die a slow death once better companies come along.</div><br/><div id="35828523" class="c"><input type="checkbox" id="c-35828523" checked=""/><div class="controls bullet"><span class="by">IceHegel</span><span>|</span><a href="#35818890">parent</a><span>|</span><a href="#35818766">next</a><span>|</span><label class="collapse" for="c-35828523">[-]</label><label class="expand" for="c-35828523">[1 more]</label></div><br/><div class="children"><div class="content">The current CEO, who a friend at google calls “Captain Zonk”, is dispositionaly not the person to make that kind of change.<p>I wouldn’t be surprised to see a leadership change this year.</div><br/></div></div></div></div><div id="35818766" class="c"><input type="checkbox" id="c-35818766" checked=""/><div class="controls bullet"><span class="by">akhayam</span><span>|</span><a href="#35818890">prev</a><span>|</span><label class="collapse" for="c-35818766">[-]</label><label class="expand" for="c-35818766">[2 more]</label></div><br/><div class="children"><div class="content">The real moats in this field will come from the hardware industry. It&#x27;s way too expensive to train these models on general purpose compute. Vertically designed silicon that brings down the unit economics of training and inference workloads are already being designed, in industry and in academia.</div><br/><div id="35820341" class="c"><input type="checkbox" id="c-35820341" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#35818766">parent</a><span>|</span><label class="collapse" for="c-35820341">[-]</label><label class="expand" for="c-35820341">[1 more]</label></div><br/><div class="children"><div class="content">NVIDIA already has a big moat in this area. It might not last forever, but at least for a good while they have a big one.</div><br/></div></div></div></div></div></div></div></div></div></body></html>