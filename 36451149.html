<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687597258424" as="style"/><link rel="stylesheet" href="styles.css?v=1687597258424"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2306.11827">Any Deep ReLU Network Is Shallow</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>headalgorithm</span> | <span>46 comments</span></div><br/><div><div id="36451740" class="c"><input type="checkbox" id="c-36451740" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36451968">next</a><span>|</span><label class="collapse" for="c-36451740">[-]</label><label class="expand" for="c-36451740">[22 more]</label></div><br/><div class="children"><div class="content">I thought it was known for a long time that any function can be represented with a neural network with a single layer. It&#x27;s an almost trivial finding if you think about it: imagine you have a steep step function that looks something like this: __&#x2F;^^ with the non-zero derivative in a small range, e.g. 0.000-0.001 (or ϵ if you like). Let&#x27;s call this f. You can piece together any function from these tiny pieces as ∑ᵢ cᵢf(aᵢx+bᵢ)+dᵢ. You just need an infinite number of them. This sum is a neural network with a single hidden layer.</div><br/><div id="36453575" class="c"><input type="checkbox" id="c-36453575" checked=""/><div class="controls bullet"><span class="by">blt</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36451901">next</a><span>|</span><label class="collapse" for="c-36453575">[-]</label><label class="expand" for="c-36453575">[2 more]</label></div><br/><div class="children"><div class="content">The result in the paper is not an approximation result. The shallow network is of bounded width and is exactly equal to the deep one.</div><br/><div id="36454520" class="c"><input type="checkbox" id="c-36454520" checked=""/><div class="controls bullet"><span class="by">elcomet</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36453575">parent</a><span>|</span><a href="#36451901">next</a><span>|</span><label class="collapse" for="c-36454520">[-]</label><label class="expand" for="c-36454520">[1 more]</label></div><br/><div class="children"><div class="content">Only for relu networks though, which are already piecewise linear functions.</div><br/></div></div></div></div><div id="36451901" class="c"><input type="checkbox" id="c-36451901" checked=""/><div class="controls bullet"><span class="by">curiousllama</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36453575">prev</a><span>|</span><a href="#36453146">next</a><span>|</span><label class="collapse" for="c-36451901">[-]</label><label class="expand" for="c-36451901">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Based on this proof, we provide an algorithm that, given a deep ReLU network, finds the explicit weights of the corresponding shallow network.<p>I’m out of date on the research, but I suspect the real value here is the algorithm. Sounds like some version of this could eventually help reduce inference time</div><br/><div id="36453136" class="c"><input type="checkbox" id="c-36453136" checked=""/><div class="controls bullet"><span class="by">tripplyons</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36451901">parent</a><span>|</span><a href="#36452005">next</a><span>|</span><label class="collapse" for="c-36453136">[-]</label><label class="expand" for="c-36453136">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t read the paper, but most of the time, in order to achieve matching outputs with less layers, you will need exponentially more neurons per layer.<p>If you have infinite parallelism I believe the shallow network would be faster, but deep networks will use less total operations and will be faster in practice.</div><br/></div></div><div id="36452005" class="c"><input type="checkbox" id="c-36452005" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36451901">parent</a><span>|</span><a href="#36453136">prev</a><span>|</span><a href="#36454150">next</a><span>|</span><label class="collapse" for="c-36452005">[-]</label><label class="expand" for="c-36452005">[5 more]</label></div><br/><div class="children"><div class="content">I suspect the trade-off for a shallow network is an exponential explosion in weights and computation.</div><br/><div id="36453527" class="c"><input type="checkbox" id="c-36453527" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36452005">parent</a><span>|</span><a href="#36453167">next</a><span>|</span><label class="collapse" for="c-36453527">[-]</label><label class="expand" for="c-36453527">[2 more]</label></div><br/><div class="children"><div class="content">From the paper:<p><pre><code>    Corollary 1. Given a ReLU network N : Rn → Rm, the shallow 
    network S : Rn → Rm of depth L = 3, as specified in the proof 
    of Theorem 1, has width bounded by 
    max{2n + k, 2n + p, 2 · p · m}
</code></pre>
I think p might be the number of layers but I&#x27;m not sure and I&#x27;m sure about k at all.<p>So it they might be claiming a pretty tight bound in on weights.</div><br/><div id="36455652" class="c"><input type="checkbox" id="c-36455652" checked=""/><div class="controls bullet"><span class="by">a1369209993</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36453527">parent</a><span>|</span><a href="#36453167">next</a><span>|</span><label class="collapse" for="c-36455652">[-]</label><label class="expand" for="c-36455652">[1 more]</label></div><br/><div class="children"><div class="content">They (suspiciously but not necessarily intentionally) avoid calling attension to it but:<p>&gt; Let ({fω}ω∈Ω,Ω) be the decomposition that corresponds to N. Label the parts 1,...,p.<p>p is the number of regions the deep network divides R^n into, and is in general exponential in the network depth. (Eg consider R^1 = [-1,+1], L[k](x) = 2*abs(x)-1 ∀k (where abs(x) = x - 2*ReLU(-x), IIRC), which divides R^1 into 2^D equal segments using only D individual ReLUs, assuming I wrote the formulas down correctly.)<p>So for a arbitrary deep network the shallow network size is definitely exponential in input depth, and while it&#x27;s not clear whether that&#x27;s true for typical &#x27;trained&#x27; deep networks, I would be surprised if it wasn&#x27;t.</div><br/></div></div></div></div><div id="36453167" class="c"><input type="checkbox" id="c-36453167" checked=""/><div class="controls bullet"><span class="by">throwawaymaths</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36452005">parent</a><span>|</span><a href="#36453527">prev</a><span>|</span><a href="#36452710">next</a><span>|</span><label class="collapse" for="c-36453167">[-]</label><label class="expand" for="c-36453167">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure it&#x27;s exponential, but it is dramatic.</div><br/></div></div><div id="36452710" class="c"><input type="checkbox" id="c-36452710" checked=""/><div class="controls bullet"><span class="by">tdullien</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36452005">parent</a><span>|</span><a href="#36453167">prev</a><span>|</span><a href="#36454150">next</a><span>|</span><label class="collapse" for="c-36452710">[-]</label><label class="expand" for="c-36452710">[1 more]</label></div><br/><div class="children"><div class="content">Yep</div><br/></div></div></div></div><div id="36454150" class="c"><input type="checkbox" id="c-36454150" checked=""/><div class="controls bullet"><span class="by">coderenegade</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36451901">parent</a><span>|</span><a href="#36452005">prev</a><span>|</span><a href="#36452932">next</a><span>|</span><label class="collapse" for="c-36454150">[-]</label><label class="expand" for="c-36454150">[1 more]</label></div><br/><div class="children"><div class="content">If you can go back and forth between representations with better than quadratic scaling, it would mean RNNs with infinite context lengths and no vanishing gradient. You wouldn&#x27;t need transformers.</div><br/></div></div></div></div><div id="36453146" class="c"><input type="checkbox" id="c-36453146" checked=""/><div class="controls bullet"><span class="by">throwawaymaths</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36451901">prev</a><span>|</span><a href="#36453688">next</a><span>|</span><label class="collapse" for="c-36453146">[-]</label><label class="expand" for="c-36453146">[1 more]</label></div><br/><div class="children"><div class="content">this is the &quot;universal approximator theorem&quot;.<p><a href="https:&#x2F;&#x2F;cognitivemedium.com&#x2F;magic_paper&#x2F;assets&#x2F;Hornik.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;cognitivemedium.com&#x2F;magic_paper&#x2F;assets&#x2F;Hornik.pdf</a><p>&gt; infinite number of [activations]<p>I don&#x27;t think you need an infinite number of them, there is a relationship between &quot;how close you want to get&quot; and &quot;how many of them you need&quot;.</div><br/></div></div><div id="36453688" class="c"><input type="checkbox" id="c-36453688" checked=""/><div class="controls bullet"><span class="by">hervature</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36453146">prev</a><span>|</span><a href="#36452006">next</a><span>|</span><label class="collapse" for="c-36453688">[-]</label><label class="expand" for="c-36453688">[1 more]</label></div><br/><div class="children"><div class="content">I would just add the caveat that it is a single <i>hidden</i> layer. If you were to write this as a sequential model you would have something like:<p>nn.Sequential(<p><pre><code>    Dense(many neurons),

    Dense(1)</code></pre>
)<p>From this, it&#x27;s pretty easy to see it is &quot;two&quot; layers but also from your equation c_i and a_i denote two separate matrix multiplications.</div><br/></div></div><div id="36452006" class="c"><input type="checkbox" id="c-36452006" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36453688">prev</a><span>|</span><a href="#36451879">next</a><span>|</span><label class="collapse" for="c-36452006">[-]</label><label class="expand" for="c-36452006">[1 more]</label></div><br/><div class="children"><div class="content">This is like how you can write any boolean function as a (large) sum of minterms.</div><br/></div></div><div id="36451879" class="c"><input type="checkbox" id="c-36451879" checked=""/><div class="controls bullet"><span class="by">extasia</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36452006">prev</a><span>|</span><a href="#36456184">next</a><span>|</span><label class="collapse" for="c-36451879">[-]</label><label class="expand" for="c-36451879">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the explanation. I&#x27;ve heard this before but think I get it now!</div><br/></div></div><div id="36456184" class="c"><input type="checkbox" id="c-36456184" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36451879">prev</a><span>|</span><a href="#36452356">next</a><span>|</span><label class="collapse" for="c-36456184">[-]</label><label class="expand" for="c-36456184">[1 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re being a little too quick to jump to the answer. There are plenty of functions where this isn&#x27;t true. Two easy examples are jump discontinuities (one that looks like this ____----- but more wiggly) (known as piecewise continuous) and functions with hole. These cannot be approximated to arbitrary accuracy, even with an infinite number of them.<p>You need to pay close attention to the wording in the approximation theorems.<p>Hornik[0] which does the proof you&#x27;re discussing says<p>&gt; This paper rigorously establishes that standard multilayer feedforward networks with as few as one _hidden layer_ using arbitrary squashing functions are capable of approximating any __Borel measurable function__ from one __finite__ dimensional space to another to any desired degree of accuracy<p>The confusion is probably in the Borel sigma-algebra. Borel means that it includes all finite open intervals in the real numbers. So (0,1) but not [0,1]. Open means boundary is not included! The interval also needs to be continuous, so our discontinuities violate the assumptions. Funahashi&#x27;s[1] and Cybenko&#x27;s[2] also require continuous functions.<p>This is actually a really important thing that gets ignored because it &quot;seems obvious.&quot; Or maybe we just see it too often. But it is __critical__ to pay attention to assumptions and limitations. There is a lot of that going off the rails lately with ML and it&#x27;s going to give us some roadblocks (we&#x27;re already seeing some[side note]). EVERYTHING (and I mean literally everything) has assumptions, and therefor biases[3]. Every evaluation method you use has a bias. Every learning method you use has a bias. Every dataset. Every architecture. Everything. This is because everything has a certain number of assumptions baked in. We try to reduce these and make them as sane as possible, but we should be aware of them. And in the case of the universal approximation, well the limitation is fairly meaningful. Data is not guaranteed to lie upon a smooth continuous manifold.<p>[0] <a href="https:&#x2F;&#x2F;cognitivemedium.com&#x2F;magic_paper&#x2F;assets&#x2F;Hornik.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;cognitivemedium.com&#x2F;magic_paper&#x2F;assets&#x2F;Hornik.pdf</a><p>[1] <a href="https:&#x2F;&#x2F;dx.doi.org&#x2F;10.1016&#x2F;0893-6080%2889%2990003-8" rel="nofollow noreferrer">https:&#x2F;&#x2F;dx.doi.org&#x2F;10.1016&#x2F;0893-6080%2889%2990003-8</a><p>[2] <a href="https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;BF02551274" rel="nofollow noreferrer">https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;BF02551274</a><p>[3] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bias_(statistics)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bias_(statistics)</a><p>[side note] We actually see this a lot in evaluation, and this is why benchmarkism is so problematic. Because it causes us to look at results as hard signals instead of guides. Evaluation is fucking hard. No empirical results will ever give you the full answer: the map is not the territory. We saw a hugging face blog today[4] about the LLM results differing and the reason is because the different evaluation methods biased towards different models. This means the metrics can be hacked, even specifically by the RLHF tuning. Or even the tokenization. These things are hard to make real good judgements on if you don&#x27;t know the limits of the evaluation method (i.e. the assumptions it makes).<p>[4] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;evaluating-mmlu-leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;evaluating-mmlu-leaderboard</a></div><br/></div></div><div id="36452356" class="c"><input type="checkbox" id="c-36452356" checked=""/><div class="controls bullet"><span class="by">madmaxmcfly</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36456184">prev</a><span>|</span><a href="#36453326">next</a><span>|</span><label class="collapse" for="c-36452356">[-]</label><label class="expand" for="c-36452356">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that just like a Taylor series?</div><br/><div id="36452445" class="c"><input type="checkbox" id="c-36452445" checked=""/><div class="controls bullet"><span class="by">charliea0</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36452356">parent</a><span>|</span><a href="#36453326">next</a><span>|</span><label class="collapse" for="c-36452445">[-]</label><label class="expand" for="c-36452445">[2 more]</label></div><br/><div class="children"><div class="content">Yes - or Fourier series or other decomposition into a sum of orthogonal basis functions.</div><br/><div id="36454599" class="c"><input type="checkbox" id="c-36454599" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36452445">parent</a><span>|</span><a href="#36453326">next</a><span>|</span><label class="collapse" for="c-36454599">[-]</label><label class="expand" for="c-36454599">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think orthogonality is important here.  Taylor series basis functions are not orthogonal, and nor are ReLUs.</div><br/></div></div></div></div></div></div><div id="36453326" class="c"><input type="checkbox" id="c-36453326" checked=""/><div class="controls bullet"><span class="by">wewxjfq</span><span>|</span><a href="#36451740">parent</a><span>|</span><a href="#36452356">prev</a><span>|</span><a href="#36451968">next</a><span>|</span><label class="collapse" for="c-36453326">[-]</label><label class="expand" for="c-36453326">[2 more]</label></div><br/><div class="children"><div class="content">This is such a bullshit HN comment, lmao.</div><br/><div id="36453416" class="c"><input type="checkbox" id="c-36453416" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36451740">root</a><span>|</span><a href="#36453326">parent</a><span>|</span><a href="#36451968">next</a><span>|</span><label class="collapse" for="c-36453416">[-]</label><label class="expand" for="c-36453416">[1 more]</label></div><br/><div class="children"><div class="content">Could you please stop posting unsubstantive comments and flamebait? You&#x27;ve unfortunately been doing it repeatedly. It&#x27;s not what this site is for, and destroys what it is for.<p>If you know more than others, that&#x27;s great—please share some of what you know, so the rest of us can learn something, or else don&#x27;t post. Sneers and putdowns only make everything worse.<p>If you wouldn&#x27;t mind reviewing <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a> and taking the intended spirit of the site more to heart, we&#x27;d be grateful.</div><br/></div></div></div></div></div></div><div id="36451968" class="c"><input type="checkbox" id="c-36451968" checked=""/><div class="controls bullet"><span class="by">kixiQu</span><span>|</span><a href="#36451740">prev</a><span>|</span><a href="#36451779">next</a><span>|</span><label class="collapse" for="c-36451968">[-]</label><label class="expand" for="c-36451968">[2 more]</label></div><br/><div class="children"><div class="content">The benefits here are not really to do with implementing inference, but rather the improvement in explainability that a shallow network can provide. Skip to section 5 (page 8) for that.</div><br/><div id="36453189" class="c"><input type="checkbox" id="c-36453189" checked=""/><div class="controls bullet"><span class="by">throwawaymaths</span><span>|</span><a href="#36451968">parent</a><span>|</span><a href="#36451779">next</a><span>|</span><label class="collapse" for="c-36453189">[-]</label><label class="expand" for="c-36453189">[1 more]</label></div><br/><div class="children"><div class="content">If anything inference will probably get worse.  Typically in ML constraining your architecture (which is what you&#x27;re doing when you make a deep narrow network out of a shallow wide network, or rnns or grus&#x2F;lstms, or transformers out of fcnns) yields inference and training performance benefits.</div><br/></div></div></div></div><div id="36451779" class="c"><input type="checkbox" id="c-36451779" checked=""/><div class="controls bullet"><span class="by">superkuh</span><span>|</span><a href="#36451968">prev</a><span>|</span><a href="#36451321">next</a><span>|</span><label class="collapse" for="c-36451779">[-]</label><label class="expand" for="c-36451779">[5 more]</label></div><br/><div class="children"><div class="content">So any N-layer network with the relu _&#x2F; activation function can be restated in terms of a 3 layer network as long as the 3 layers can have infinite parameters and as long as you have near infinite computing power to convert the big ones. Cool but not yet useful.</div><br/><div id="36453234" class="c"><input type="checkbox" id="c-36453234" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36451779">parent</a><span>|</span><a href="#36451951">next</a><span>|</span><label class="collapse" for="c-36453234">[-]</label><label class="expand" for="c-36453234">[3 more]</label></div><br/><div class="children"><div class="content">&gt; So any N-layer network with the relu _&#x2F; activation function<p>The paper talks only about models with additive operations among activations. It doesn&#x27;t say anything about more complex networks like transformers.<p>In transformers there are multiplicative interactions between activations inside the attention matrix, it is unclear if they can be approximated with just a 3 layer ReLU network, or if such conversion would be practical at all.</div><br/><div id="36456190" class="c"><input type="checkbox" id="c-36456190" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36451779">root</a><span>|</span><a href="#36453234">parent</a><span>|</span><a href="#36451951">next</a><span>|</span><label class="collapse" for="c-36456190">[-]</label><label class="expand" for="c-36456190">[2 more]</label></div><br/><div class="children"><div class="content">It would be very surprising if this result was relevant for transformers considering the softmax that&#x27;s present there.</div><br/><div id="36456753" class="c"><input type="checkbox" id="c-36456753" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36451779">root</a><span>|</span><a href="#36456190">parent</a><span>|</span><a href="#36451951">next</a><span>|</span><label class="collapse" for="c-36456753">[-]</label><label class="expand" for="c-36456753">[1 more]</label></div><br/><div class="children"><div class="content">true</div><br/></div></div></div></div></div></div><div id="36451951" class="c"><input type="checkbox" id="c-36451951" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36451779">parent</a><span>|</span><a href="#36453234">prev</a><span>|</span><a href="#36451321">next</a><span>|</span><label class="collapse" for="c-36451951">[-]</label><label class="expand" for="c-36451951">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How well does a classic deep net architecture like AlexNet or VGG19 classify on a
standard dataset such as CIFAR-10 when its “width”— namely, number of channels
in convolutional layers, and number of nodes in fully-connected internal layers —
is allowed to increase to infinity? Such questions have come to the forefront in the
quest to theoretically understand deep learning and its mysteries about optimization
and generalization. They also connect deep learning to notions such as Gaussian
processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural
Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in
the infinite width limit trained by gradient descent; this object was implicit in some
other recent papers. An attraction of such ideas is that a pure kernel-based method
is used to capture the power of a fully-trained deep net of infinite width.<p><a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=rkl4aESeUH" rel="nofollow noreferrer">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=rkl4aESeUH</a>, <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;neural-tangents">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;neural-tangents</a><p>&gt; It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.00165" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.00165</a><p>And of course, one needs to look back at SVMs applying a kernel function and separating with a line, which looks a lot like an ANN with a single hidden layer followed by a linear mapping.<p><a href="https:&#x2F;&#x2F;stats.stackexchange.com&#x2F;questions&#x2F;238635&#x2F;kernel-methods-how-do-the-infinite-dimensions-arise" rel="nofollow noreferrer">https:&#x2F;&#x2F;stats.stackexchange.com&#x2F;questions&#x2F;238635&#x2F;kernel-meth...</a></div><br/></div></div></div></div><div id="36451321" class="c"><input type="checkbox" id="c-36451321" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36451779">prev</a><span>|</span><a href="#36452741">next</a><span>|</span><label class="collapse" for="c-36451321">[-]</label><label class="expand" for="c-36451321">[2 more]</label></div><br/><div class="children"><div class="content">Nice! I have to admit I didn&#x27;t follow all the math, but the layers get really wide, right? You still need to describe all the partitions between the pieces of the piecewise linear functions. Does this save any computation at inference time?</div><br/><div id="36452126" class="c"><input type="checkbox" id="c-36452126" checked=""/><div class="controls bullet"><span class="by">polygamous_bat</span><span>|</span><a href="#36451321">parent</a><span>|</span><a href="#36452741">next</a><span>|</span><label class="collapse" for="c-36452126">[-]</label><label class="expand" for="c-36452126">[1 more]</label></div><br/><div class="children"><div class="content">My hunch is that you can really easily find (adversarial) counterexamples that may show that in the worst case you will always use more compute by shallow-ing. In my head it should be related to no free lunch theorem.</div><br/></div></div></div></div><div id="36452741" class="c"><input type="checkbox" id="c-36452741" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#36451321">prev</a><span>|</span><a href="#36455419">next</a><span>|</span><label class="collapse" for="c-36452741">[-]</label><label class="expand" for="c-36452741">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an expert, but I wonder if the wide network could then be trimmed down for special purposes? E.g., find the parts of the network needed for a certain task by looking at activations on inputs and dump the rest.</div><br/><div id="36455493" class="c"><input type="checkbox" id="c-36455493" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36452741">parent</a><span>|</span><a href="#36453860">next</a><span>|</span><label class="collapse" for="c-36455493">[-]</label><label class="expand" for="c-36455493">[1 more]</label></div><br/><div class="children"><div class="content">Besides pruning (which is what you describe) you might find the &quot;lottery ticket hypothesis&quot; interesting. The idea is essentially that in a randomly initialized large network there is a subset of weights that are already closeish for a given task and training helps tune that and suppress everything else, and that knowing this you can actually get better results by pruning before training.</div><br/></div></div><div id="36453860" class="c"><input type="checkbox" id="c-36453860" checked=""/><div class="controls bullet"><span class="by">neodypsis</span><span>|</span><a href="#36452741">parent</a><span>|</span><a href="#36455493">prev</a><span>|</span><a href="#36453845">next</a><span>|</span><label class="collapse" for="c-36453860">[-]</label><label class="expand" for="c-36453860">[1 more]</label></div><br/><div class="children"><div class="content">Weight pruning is already a thing. See, for example: <a href="https:&#x2F;&#x2F;www.tensorflow.org&#x2F;model_optimization&#x2F;guide&#x2F;pruning" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tensorflow.org&#x2F;model_optimization&#x2F;guide&#x2F;pruning</a></div><br/></div></div><div id="36453845" class="c"><input type="checkbox" id="c-36453845" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36452741">parent</a><span>|</span><a href="#36453860">prev</a><span>|</span><a href="#36455419">next</a><span>|</span><label class="collapse" for="c-36453845">[-]</label><label class="expand" for="c-36453845">[1 more]</label></div><br/><div class="children"><div class="content">That was my thought as well, it would be nice if someone more knowledgeable came and explained us why it&#x27;s stupid&#x2F;doesn&#x27;t work</div><br/></div></div></div></div><div id="36455419" class="c"><input type="checkbox" id="c-36455419" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#36452741">prev</a><span>|</span><a href="#36452399">next</a><span>|</span><label class="collapse" for="c-36455419">[-]</label><label class="expand" for="c-36455419">[1 more]</label></div><br/><div class="children"><div class="content">Another maybe silly thought, but if any relu network could be written in three layers, does this allow for a hyper efficient ReLu only hardware for ml where the pipeline is fixed?</div><br/></div></div><div id="36454727" class="c"><input type="checkbox" id="c-36454727" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#36452399">prev</a><span>|</span><a href="#36453638">next</a><span>|</span><label class="collapse" for="c-36454727">[-]</label><label class="expand" for="c-36454727">[3 more]</label></div><br/><div class="children"><div class="content">Any neural network (deep or shallow) can be rewritten as a simple (but potentially very large) lookup table.</div><br/><div id="36455868" class="c"><input type="checkbox" id="c-36455868" checked=""/><div class="controls bullet"><span class="by">cellis</span><span>|</span><a href="#36454727">parent</a><span>|</span><a href="#36453638">next</a><span>|</span><label class="collapse" for="c-36455868">[-]</label><label class="expand" for="c-36455868">[2 more]</label></div><br/><div class="children"><div class="content">Could you point to an inductive proof of this?</div><br/><div id="36456091" class="c"><input type="checkbox" id="c-36456091" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#36454727">root</a><span>|</span><a href="#36455868">parent</a><span>|</span><a href="#36453638">next</a><span>|</span><label class="collapse" for="c-36456091">[-]</label><label class="expand" for="c-36456091">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think you need induction, you can just use the fact that the input is a fixed size and the output is a fixed size. The &quot;constructive&quot; proof is, feed in all possible inputs, record the outputs in a lookup table.</div><br/></div></div></div></div></div></div><div id="36453638" class="c"><input type="checkbox" id="c-36453638" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#36454727">prev</a><span>|</span><a href="#36452405">next</a><span>|</span><label class="collapse" for="c-36453638">[-]</label><label class="expand" for="c-36453638">[2 more]</label></div><br/><div class="children"><div class="content">Does this result explicitly not hold for other activation functions, or have they just not explored it yet?</div><br/><div id="36453658" class="c"><input type="checkbox" id="c-36453658" checked=""/><div class="controls bullet"><span class="by">gqcwwjtg</span><span>|</span><a href="#36453638">parent</a><span>|</span><a href="#36452405">next</a><span>|</span><label class="collapse" for="c-36453658">[-]</label><label class="expand" for="c-36453658">[1 more]</label></div><br/><div class="children"><div class="content">It seems like it doesn’t hold since this relies on turning the whole thing into a piecewise linear function.</div><br/></div></div></div></div><div id="36452405" class="c"><input type="checkbox" id="c-36452405" checked=""/><div class="controls bullet"><span class="by">jmole</span><span>|</span><a href="#36453638">prev</a><span>|</span><a href="#36454042">next</a><span>|</span><label class="collapse" for="c-36452405">[-]</label><label class="expand" for="c-36452405">[1 more]</label></div><br/><div class="children"><div class="content">this is an interesting attempt at explainability, but that&#x27;s all.<p>The backward pass of &quot;Shallowed&quot; Deep network would likely result in a useless network with today&#x27;s training methods.</div><br/></div></div><div id="36454042" class="c"><input type="checkbox" id="c-36454042" checked=""/><div class="controls bullet"><span class="by">cheekyfibonacci</span><span>|</span><a href="#36452405">prev</a><span>|</span><a href="#36452533">next</a><span>|</span><label class="collapse" for="c-36454042">[-]</label><label class="expand" for="c-36454042">[1 more]</label></div><br/><div class="children"><div class="content">the authors seemed to have lost an opportunity to name the paper &quot;In the Shallow-lalalow&quot;</div><br/></div></div><div id="36452533" class="c"><input type="checkbox" id="c-36452533" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36454042">prev</a><span>|</span><label class="collapse" for="c-36452533">[-]</label><label class="expand" for="c-36452533">[1 more]</label></div><br/><div class="children"><div class="content">This was posted yesterday: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36430442">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36430442</a><p>Actually I know because I also tried posting it but wasn&#x27;t allowed because it was a dupe (4 or 5 hours old) - instead I just got taken to that post and was automatically deemed to have voted for it.</div><br/></div></div></div></div></div></div></div></body></html>