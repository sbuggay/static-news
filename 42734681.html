<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737104455656" as="style"/><link rel="stylesheet" href="styles.css?v=1737104455656"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.answer.ai/posts/2025-01-08-devin.html">Thoughts on a Month with Devin</a>Â <span class="domain">(<a href="https://www.answer.ai">www.answer.ai</a>)</span></div><div class="subtext"><span>swyx</span> | <span>28 comments</span></div><br/><div><div id="42735048" class="c"><input type="checkbox" id="c-42735048" checked=""/><div class="controls bullet"><span class="by">xmprt</span><span>|</span><a href="#42735028">next</a><span>|</span><label class="collapse" for="c-42735048">[-]</label><label class="expand" for="c-42735048">[3 more]</label></div><br/><div class="children"><div class="content">I think one of the big problems with Devin (and AI agents in general) is that they&#x27;re only ever as good as they are. Sometimes their intelligence feels magical and they accomplish things within minutes that even mid level or senior software engineers would take a few hours to do. Other times, they make simple mistakes and no matter how much help you give, they run around in circles.<p>A big quality that I value in junior engineers is coachability. If an AI agent can&#x27;t be coached (and it doesn&#x27;t look like it right now), then there&#x27;s no way I&#x27;ll ever enjoy using one.</div><br/><div id="42735186" class="c"><input type="checkbox" id="c-42735186" checked=""/><div class="controls bullet"><span class="by">ipnon</span><span>|</span><a href="#42735048">parent</a><span>|</span><a href="#42735086">next</a><span>|</span><label class="collapse" for="c-42735186">[-]</label><label class="expand" for="c-42735186">[1 more]</label></div><br/><div class="children"><div class="content">My first job I spent so much time reading Python docs, and the ancient art of Stack Overflow spelunking. But I could intuitively explain a solution in seconds because of my CS background. I used to encounter a certain kind of programmer often, who did not understand algorithms well but had many years of experience with a language like Ruby, and thus was faster in completing tasks because they didn&#x27;t need to do the reference work that I had to do. Now I think these kinds of programmers will slowly disappear and only the ones with the fast CS intuition will remain.</div><br/></div></div><div id="42735086" class="c"><input type="checkbox" id="c-42735086" checked=""/><div class="controls bullet"><span class="by">marcyb5st</span><span>|</span><a href="#42735048">parent</a><span>|</span><a href="#42735186">prev</a><span>|</span><a href="#42735028">next</a><span>|</span><label class="collapse" for="c-42735086">[-]</label><label class="expand" for="c-42735086">[1 more]</label></div><br/><div class="children"><div class="content">I completely agree with you. More precisely, I feel they are useful when you have specific tasks with limited scope.<p>For instance, just yesterday I was battling with a complex SQL query and I got halfway there. I gave our bot the query and an half assed description of what I wanted&#x2F;what was missing and it got it right on the first try.</div><br/></div></div></div></div><div id="42735028" class="c"><input type="checkbox" id="c-42735028" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#42735048">prev</a><span>|</span><a href="#42735023">next</a><span>|</span><label class="collapse" for="c-42735028">[-]</label><label class="expand" for="c-42735028">[3 more]</label></div><br/><div class="children"><div class="content">Disclosure: Working on a company in the space and have recently been compared to Devin in at least one public talk.<p>Devin has tried to do too much. There is value in producing a solid code artifact that can be handed off for review to other developers in limited capacities like P2s and minor bugs which pile up in business backlogs.<p>Focusing on specific elements of the development loop such as fix bugs, add small feature, run tests, produce pull request is enough.<p>Businesses like Factory AI or my own are taking that approach and we&#x27;re seeing real interest in our products.</div><br/><div id="42735280" class="c"><input type="checkbox" id="c-42735280" checked=""/><div class="controls bullet"><span class="by">yoavm</span><span>|</span><a href="#42735028">parent</a><span>|</span><a href="#42735023">next</a><span>|</span><label class="collapse" for="c-42735280">[-]</label><label class="expand" for="c-42735280">[2 more]</label></div><br/><div class="children"><div class="content">Not to take away from your opinion, but I guess time will tell? As models get better, it&#x27;s possible that wide tools like Devin will work better and swallow tools that do one thing. I think companies much rather have a AI solution that works like what they already know (developers), than one that works in the IDE, another that watches to Github issues, another that reviews PRs, and one that hangs on Slack and makes small fixes.<p>&gt; Businesses like Factory AI or my own are taking that approach and we&#x27;re seeing real interest in our products.<p>Interest isn&#x27;t what tools like Devin are lacking, (un)fortunately.<p>To be clear, I do share a lot of scepticism regarding all the businesses working around AI code generation. However, that isn&#x27;t because I think they&#x27;ll never be able to figure it out, but because I think they are all likely to figure it out at the end, at the same time, when better models come out. And none of them will have a real advantage over the other.</div><br/><div id="42735373" class="c"><input type="checkbox" id="c-42735373" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#42735028">root</a><span>|</span><a href="#42735280">parent</a><span>|</span><a href="#42735023">next</a><span>|</span><label class="collapse" for="c-42735373">[-]</label><label class="expand" for="c-42735373">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve recently had several enterprise level conversations with different companies and what we&#x27;re being asked for is specifically the simpler approach. I think that is the level of risk they&#x27;re willing to tolerate and it will still ameliorate a real issue for them.<p>The key here is my product is no worse positioned to do more things if and when the time comes, but building a solid foundation and trust, and not having the quiet part be (which I heard as early as several months ago) that your product doesn&#x27;t work means we&#x27;ll hopefully still have the customer base to roll that out to.<p>I&#x27;ve talked to Devin&#x27;s CEO once at Swyx&#x27;s conference last June, they&#x27;re very thoughtful and very kind so this must be very rough but between when they showed their demo then and what I&#x27;m hearing now the product has not evolved in a way where they are providing value commensurate with their marketing or hype.<p>I&#x27;m a fan of Guillermo Rauch&#x27;s (Vercel CEO) take on these things. You earn the right to take on bigger challenges and no one in this space has earned the right yet including us.<p>Devin&#x27;s investment was fueled by hyperspeculation early on when no one knew what the shape of the game was. In many ways we still don&#x27;t, but if you burn your reputation before we get there you may not be able to capitalize on it.<p>To be completely fair to them, taking the long view and the bank account to go with it they may still be entirely fine.</div><br/></div></div></div></div></div></div><div id="42735023" class="c"><input type="checkbox" id="c-42735023" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#42735028">prev</a><span>|</span><a href="#42735229">next</a><span>|</span><label class="collapse" for="c-42735023">[-]</label><label class="expand" for="c-42735023">[6 more]</label></div><br/><div class="children"><div class="content">One thing that surprised me a little is that there doesn&#x27;t seem to be an &quot;ask for help&quot; escape hatch in it - it would work away for literally <i>days</i> on a task where any human would admit they were stuck?<p>One of the more important features of agents is supposedly that they can stop and ask for human input when necessary. It seems it does do this for &quot;hard stops&quot; - like when it needed a human to setup API keys in their cloud console - but for &quot;soft stops&quot; it wouldn&#x27;t.<p>By contrast, a human dev would probably throw in the towel after a couple of hours and ask a senior dev for guidance. The chat interface definitely supports that with this system but apparently the agent will churn away in a sort of &quot;infinite thinking loop&quot;. (This matches my limited experience with other agentic systems too.)</div><br/><div id="42735329" class="c"><input type="checkbox" id="c-42735329" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42735023">parent</a><span>|</span><a href="#42735035">next</a><span>|</span><label class="collapse" for="c-42735329">[-]</label><label class="expand" for="c-42735329">[1 more]</label></div><br/><div class="children"><div class="content">&gt; One thing that surprised me a little is that there doesn&#x27;t seem to be an &quot;ask for help&quot; escape hatch in it - it would work away for literally days on a task where any human would admit they were stuck?<p>You are over-estimating the sophistication of their platform and infrastructure. Everyone was talking about Cursor (or maybe was it astroturfing?) but once I checked it out, it was not far from avante on neovim.</div><br/></div></div><div id="42735035" class="c"><input type="checkbox" id="c-42735035" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#42735023">parent</a><span>|</span><a href="#42735329">prev</a><span>|</span><a href="#42735343">next</a><span>|</span><label class="collapse" for="c-42735035">[-]</label><label class="expand" for="c-42735035">[3 more]</label></div><br/><div class="children"><div class="content">LLMs can create infinite worlds in the error message itâs receiving. It probably needs some outside signal to stop and re-assess. I donât think LLMs have any ability to reason if theyâre lost in their own world on their own. Theyâll just keep creating new less and less coherent context for themselves</div><br/><div id="42735183" class="c"><input type="checkbox" id="c-42735183" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#42735023">root</a><span>|</span><a href="#42735035">parent</a><span>|</span><a href="#42735326">next</a><span>|</span><label class="collapse" for="c-42735183">[-]</label><label class="expand" for="c-42735183">[1 more]</label></div><br/><div class="children"><div class="content">For sure - but if I&#x27;m paying for a tool like Devin then I&#x27;d expect the infrastructure around it to do things like stop it if it looks like that has happened.<p>What you often see with agentic systems is that there&#x27;s an agent whose role is to &quot;orchestrate&quot;, and that&#x27;s the kind of thing the orchestrator would do: every 10 minutes or so, check the output and elapsed time and decide if the &quot;developer&quot; agent needs a reality check.</div><br/></div></div><div id="42735326" class="c"><input type="checkbox" id="c-42735326" checked=""/><div class="controls bullet"><span class="by">someothherguyy</span><span>|</span><a href="#42735023">root</a><span>|</span><a href="#42735035">parent</a><span>|</span><a href="#42735183">prev</a><span>|</span><a href="#42735343">next</a><span>|</span><label class="collapse" for="c-42735326">[-]</label><label class="expand" for="c-42735326">[1 more]</label></div><br/><div class="children"><div class="content">If you correct an LLM based agent coder, you are always right. Often, if you give it advice, it pretends like it understands you, then goes on to do something different from what it said it was going to do. Likewise, it will outright lie to you telling you it did things it didn&#x27;t do. (In my experience)</div><br/></div></div></div></div><div id="42735343" class="c"><input type="checkbox" id="c-42735343" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#42735023">parent</a><span>|</span><a href="#42735035">prev</a><span>|</span><a href="#42735229">next</a><span>|</span><label class="collapse" for="c-42735343">[-]</label><label class="expand" for="c-42735343">[1 more]</label></div><br/><div class="children"><div class="content">There should be an energy coefficient to problems. You only get a set amount of energy to solve per issue. When the energy runs out. A human must help.</div><br/></div></div></div></div><div id="42735229" class="c"><input type="checkbox" id="c-42735229" checked=""/><div class="controls bullet"><span class="by">noodletheworld</span><span>|</span><a href="#42735023">prev</a><span>|</span><a href="#42735342">next</a><span>|</span><label class="collapse" for="c-42735229">[-]</label><label class="expand" for="c-42735229">[2 more]</label></div><br/><div class="children"><div class="content">Those âhow I feel about Devin after using itâ comments at the bottom are damning, when you compare them to the user testimonials of people using cursor.<p>Seems to me that agents just arenât the answer people want them to be, just a hype wave obscuring real progress in other areas (eg. MCST) because theyâre easy to implement.<p>â¦but really, if things are easy to implement, at this point, you have to ask why they havenât been done yet.<p>Probably, it seems, because itâs harder to implement in a way thatâs useful than it superficially appearsâ¦<p>Ie. If the smart folk working on Devin can only do something of this level, anyone working on agentic systems should be worried, because itâs unlikely you can do better, without better underlying models.</div><br/></div></div><div id="42735342" class="c"><input type="checkbox" id="c-42735342" checked=""/><div class="controls bullet"><span class="by">exo-cortex</span><span>|</span><a href="#42735229">prev</a><span>|</span><a href="#42734916">next</a><span>|</span><label class="collapse" for="c-42735342">[-]</label><label class="expand" for="c-42735342">[1 more]</label></div><br/><div class="children"><div class="content">I remain sceptical about the &quot;Planet Tracker&quot;-task. The task was to debunk claims about historical positions of Jupiter and Saturn. 
If the task was to find those planets were NOT in a certain (claimed) position an erroneous program would still appear to &quot;debunk&quot; the claims. Did they check if Devin&#x27;s code&#x27;s calculated positions were actually correct? Did they check in some NASA-database?
If Devin gave arbitrary positions for the planets it&#x27;s much more likely that they&#x27;re different than any claim and appear to debunk it.</div><br/></div></div><div id="42734916" class="c"><input type="checkbox" id="c-42734916" checked=""/><div class="controls bullet"><span class="by">tlarkworthy</span><span>|</span><a href="#42735342">prev</a><span>|</span><a href="#42734963">next</a><span>|</span><label class="collapse" for="c-42734916">[-]</label><label class="expand" for="c-42734916">[1 more]</label></div><br/><div class="children"><div class="content">Also trialed Devin, it&#x27;s quite impressive when it understands the code formatting and local test setup, producing well formatted and test case passing code, but it seems to always add extraneous changes beyond the task that can break other things. And it can&#x27;t seem to undo those changes if you ask. So everything requires more cleanup. Devin opened my eyes to the power of agentic workflows with closed loop feedback, and the coolness of a slack interface, but I am gonna recommend cancelling it because it&#x27;s not actually saving time and it&#x27;s quite expensive.</div><br/></div></div><div id="42734963" class="c"><input type="checkbox" id="c-42734963" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#42734916">prev</a><span>|</span><a href="#42734979">next</a><span>|</span><label class="collapse" for="c-42734963">[-]</label><label class="expand" for="c-42734963">[1 more]</label></div><br/><div class="children"><div class="content">What model does Devin use? How would it change if it used o1 or even o3 for times when it gets stuck?<p>IE. Generate the initial code using GPT4o&#x2F;Claude 3.5, then start testing the code, when it gets stuck, use o1&#x2F;o3 to help.</div><br/></div></div><div id="42734979" class="c"><input type="checkbox" id="c-42734979" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#42734963">prev</a><span>|</span><a href="#42735391">next</a><span>|</span><label class="collapse" for="c-42734979">[-]</label><label class="expand" for="c-42734979">[2 more]</label></div><br/><div class="children"><div class="content">Sounds exactly like my experience with the âagentsâ about a year ago. Autogpt or whatever it was called. Works great 1% of the time and the rest it gets stuck in the wrong places completely unable to back out.<p>Iâm now using o1 or Claude Sonnet 3.5 and usually one of them gets it right.</div><br/><div id="42735087" class="c"><input type="checkbox" id="c-42735087" checked=""/><div class="controls bullet"><span class="by">ipnon</span><span>|</span><a href="#42734979">parent</a><span>|</span><a href="#42735391">next</a><span>|</span><label class="collapse" for="c-42735087">[-]</label><label class="expand" for="c-42735087">[1 more]</label></div><br/><div class="children"><div class="content">The current frontier models are all neocortex. They have no midbrain or crocodile brain to reconcile any physical, legal or moral feedback. The current state of the art is to preprocess all LLM responses with a physical&#x2F;legal&#x2F;moral classifier and respond with a generic &quot;I&#x27;m sorry Dave, I&#x27;m afraid I can&#x27;t do that.&quot;<p>We are fooled into thinking these golems have a shred of humanity, but their method of processing information is completely backward. Humans begin with a fight&#x2F;flight classifier, then a social consensus regression, and only after this do we start generating tokens ... and we do this every moment of every day of our lives, uncountably often, the only prerequisite being the calories in an occasional slice of bread and butter.</div><br/></div></div></div></div><div id="42735391" class="c"><input type="checkbox" id="c-42735391" checked=""/><div class="controls bullet"><span class="by">suneater921</span><span>|</span><a href="#42734979">prev</a><span>|</span><a href="#42735001">next</a><span>|</span><label class="collapse" for="c-42735391">[-]</label><label class="expand" for="c-42735391">[1 more]</label></div><br/><div class="children"><div class="content">I canât believe they named it after Devin Franco - guess it can take a lot of load!</div><br/></div></div><div id="42735001" class="c"><input type="checkbox" id="c-42735001" checked=""/><div class="controls bullet"><span class="by">ipnon</span><span>|</span><a href="#42735391">prev</a><span>|</span><a href="#42735141">next</a><span>|</span><label class="collapse" for="c-42735001">[-]</label><label class="expand" for="c-42735001">[4 more]</label></div><br/><div class="children"><div class="content">Now is the time for us to hold seemingly contradictory propositions: A child born today will live to see 99% of all computer code written by artificial intelligence, but the current AI boom is massively overcapitalized.</div><br/><div id="42735398" class="c"><input type="checkbox" id="c-42735398" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#42735001">parent</a><span>|</span><a href="#42735434">next</a><span>|</span><label class="collapse" for="c-42735398">[-]</label><label class="expand" for="c-42735398">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t put much stock in predictions about 100 years into the future.</div><br/></div></div><div id="42735434" class="c"><input type="checkbox" id="c-42735434" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#42735001">parent</a><span>|</span><a href="#42735398">prev</a><span>|</span><a href="#42735072">next</a><span>|</span><label class="collapse" for="c-42735434">[-]</label><label class="expand" for="c-42735434">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s already the case if you call compilers&#x2F;interpreters &quot;AI&quot;. Just a new higher level abstraction for code.</div><br/></div></div><div id="42735072" class="c"><input type="checkbox" id="c-42735072" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#42735001">parent</a><span>|</span><a href="#42735434">prev</a><span>|</span><a href="#42735141">next</a><span>|</span><label class="collapse" for="c-42735072">[-]</label><label class="expand" for="c-42735072">[1 more]</label></div><br/><div class="children"><div class="content">How is it contradictory?</div><br/></div></div></div></div><div id="42735141" class="c"><input type="checkbox" id="c-42735141" checked=""/><div class="controls bullet"><span class="by">gtsop</span><span>|</span><a href="#42735001">prev</a><span>|</span><label class="collapse" for="c-42735141">[-]</label><label class="expand" for="c-42735141">[3 more]</label></div><br/><div class="children"><div class="content">Honestly, i have been bitten so many times by LLM hallucinations when I work in parallel with the LLM, I wouldn&#x27;t trust it autonomously running anything at all. If you have tried to use imaginary APIs, imaginary configuration and imaginary cli arguments, you know what I mean</div><br/><div id="42735224" class="c"><input type="checkbox" id="c-42735224" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42735141">parent</a><span>|</span><a href="#42735444">next</a><span>|</span><label class="collapse" for="c-42735224">[-]</label><label class="expand" for="c-42735224">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you have tried to use imaginary APIs, imaginary configuration and imaginary cli arguments, you know what I mean<p>I see this comment a lot but I can&#x27;t help but feel it&#x27;s 4 weeks out of date. The version of o1 released on 2024-12-17 so rarely hallucinates when asked code questions of basic to medium difficulty and provided with good context and a well written prompt, in my experience. If the context window is sub-10k tokens, I have very high confidence that the output will be correct. GPT-4o and o1-mini, on the other hand, hallucinates a lot and I have learned to put low trust in the output.</div><br/></div></div><div id="42735444" class="c"><input type="checkbox" id="c-42735444" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#42735141">parent</a><span>|</span><a href="#42735224">prev</a><span>|</span><label class="collapse" for="c-42735444">[-]</label><label class="expand" for="c-42735444">[1 more]</label></div><br/><div class="children"><div class="content">I have been feeling LLM burnout and favoring code it all my self after a year of LLM assistance.  When it gets things wrong it is too annoying.</div><br/></div></div></div></div></div></div></div></div></div></body></html>