<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731834066719" as="style"/><link rel="stylesheet" href="styles.css?v=1731834066719"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://duckdb.org/2024/11/14/optimizers.html">Optimizers: The Low-Key MVP</a>Â <span class="domain">(<a href="https://duckdb.org">duckdb.org</a>)</span></div><div class="subtext"><span>tosh</span> | <span>8 comments</span></div><br/><div><div id="42157512" class="c"><input type="checkbox" id="c-42157512" checked=""/><div class="controls bullet"><span class="by">adrian17</span><span>|</span><a href="#42162004">next</a><span>|</span><label class="collapse" for="c-42157512">[-]</label><label class="expand" for="c-42157512">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The SQL above results in a plan similar to the DuckDB optimized plan, but it is wordier and more error-prone to write, which can potentially lead to bugs.<p>FWIW, aside from manual filter pushdown, I consider the JOIN variant the canonical &#x2F; &quot;default&quot; way to merge multiple tables; it keeps all the join-related logic in one place, while mixing both joining conditions and filtering conditions in WHERE always felt more error-prone to me.</div><br/><div id="42162744" class="c"><input type="checkbox" id="c-42162744" checked=""/><div class="controls bullet"><span class="by">camgunz</span><span>|</span><a href="#42157512">parent</a><span>|</span><a href="#42157604">next</a><span>|</span><label class="collapse" for="c-42162744">[-]</label><label class="expand" for="c-42162744">[1 more]</label></div><br/><div class="children"><div class="content">Same here; I&#x27;ve always intuited that this would limit the generated tuples. I&#x27;m too lazy to do it now, but I wonder if other DB engines also perform this optimization that effectively makes filtering in JOIN conditions equivalent to filtering in WHERE clauses. I&#x27;d also be interested in some example queries that were hand-optimized to the point of obvious obscurity--my guess is it&#x27;s harder to do this in SQL than in something like C.</div><br/></div></div><div id="42157604" class="c"><input type="checkbox" id="c-42157604" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#42157512">parent</a><span>|</span><a href="#42162744">prev</a><span>|</span><a href="#42162004">next</a><span>|</span><label class="collapse" for="c-42157604">[-]</label><label class="expand" for="c-42157604">[1 more]</label></div><br/><div class="children"><div class="content">It is also the only way to represent join conditions for outer joins.</div><br/></div></div></div></div><div id="42162004" class="c"><input type="checkbox" id="c-42162004" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#42157512">prev</a><span>|</span><a href="#42160881">next</a><span>|</span><label class="collapse" for="c-42162004">[-]</label><label class="expand" for="c-42162004">[1 more]</label></div><br/><div class="children"><div class="content">Always a fan of query plan articles!<p>Note: the dig at dataframe libs is worth some care in case you think that means duckdb can optimize and they cannot<p>Dask, Polars, and others pick a lazy default in order to make distribution and other optimizations easier. When staying in their pure fragments (&#x27;vectorized&#x27;), the same scheduler rewriting opportunity is here.<p>This is a subtle but important distinction when looking at these frameworks. We are making our new graph query language &#x27;gfql&#x27; to be dataframe-native so it can run naturally &amp; natively as a step of pipelines people are already doing, but also to ensure we automatically run as optimized CPU&#x2F;GPU columnar opts. At the same time, because of the intent to allow room for query plan optimization, we are staying declarative &#x2F; lazy, even if the generated &amp; interpreted code uses an eager DF runtime . I&#x27;m optimistic about output target lazy DF systems doing query planner work for us long-term here, but for the eager framework targets, the query planning has to be on our side.</div><br/></div></div><div id="42160881" class="c"><input type="checkbox" id="c-42160881" checked=""/><div class="controls bullet"><span class="by">unwind</span><span>|</span><a href="#42162004">prev</a><span>|</span><a href="#42157797">next</a><span>|</span><label class="collapse" for="c-42160881">[-]</label><label class="expand" for="c-42160881">[1 more]</label></div><br/><div class="children"><div class="content">Meta: I think the title would be better here if it came out and said <i>query</i> optimizers.<p>That gives a less subtle clue that it&#x27;s about databases than looking at the domain.</div><br/></div></div><div id="42157797" class="c"><input type="checkbox" id="c-42157797" checked=""/><div class="controls bullet"><span class="by">ikesau</span><span>|</span><a href="#42160881">prev</a><span>|</span><label class="collapse" for="c-42157797">[-]</label><label class="expand" for="c-42157797">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This means your optimizations need to be applied by hand, which is sustainable if your data starts changing.<p>Seems like a missing &quot;un&quot; here<p>Compelling article! I&#x27;ve already found DuckDB to be the most ergonomic tool for quick and dirty wrangling, it&#x27;s good to know it can handle massive jobs too.</div><br/><div id="42159012" class="c"><input type="checkbox" id="c-42159012" checked=""/><div class="controls bullet"><span class="by">Nihilartikel</span><span>|</span><a href="#42157797">parent</a><span>|</span><label class="collapse" for="c-42159012">[-]</label><label class="expand" for="c-42159012">[1 more]</label></div><br/><div class="children"><div class="content">I regularly use duckdb on datasets of 1B+ rows, with nasty strong columns that may be over 10MB per value in the outliers. Mostly it just works, and fast too! When it doesn&#x27;t, I&#x27;ll usually just dump to parquet and hit it with sparksql, but that is the exception rather than the rule.</div><br/></div></div></div></div></div></div></div></div></div></body></html>