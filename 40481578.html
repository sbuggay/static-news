<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716800484453" as="style"/><link rel="stylesheet" href="styles.css?v=1716800484453"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/DiscoGrad/DiscoGrad">Show HN: Boldly go where Gradient Descent has never gone before with DiscoGrad</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>frankling_</span> | <span>59 comments</span></div><br/><div><div id="40483342" class="c"><input type="checkbox" id="c-40483342" checked=""/><div class="controls bullet"><span class="by">eranation</span><span>|</span><a href="#40483761">next</a><span>|</span><label class="collapse" for="c-40483342">[-]</label><label class="expand" for="c-40483342">[10 more]</label></div><br/><div class="children"><div class="content">Laymen question - I sort of understand what gradient descent is, but I&#x27;m not sure I fully understand what DiscoGrad is doing, my probably incorrect naive understanding is: to find optimal params for a program by converting the branches of a program into something that resembles a &quot;smooth&quot; loss function so a tradition gradient descent algorithm can find local minima and suggest the optimal params &#x2F; weights?<p>EDIT: removed part of the question that is answered in the article.</div><br/><div id="40483448" class="c"><input type="checkbox" id="c-40483448" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483342">parent</a><span>|</span><a href="#40483408">next</a><span>|</span><label class="collapse" for="c-40483448">[-]</label><label class="expand" for="c-40483448">[7 more]</label></div><br/><div class="children"><div class="content">Yep, that&#x27;s exactly it. The smoothness can either come from randomness in the program itself (then the objective function is asymptotically smooth and DiscoGrad estimates the gradient of that smooth function), or the smoothness can be introduced artificially.<p>As an example, the very first thing we looked into was a transportation engineering problem, where the red&#x2F;green phases of traffic lights lead to a non-smooth optimization problem. In essence, in that case we were looking for the &quot;best possible&quot; parameters for a transportation simulation (in the form of a C++ program) that&#x27;s full of branches.</div><br/><div id="40488477" class="c"><input type="checkbox" id="c-40488477" checked=""/><div class="controls bullet"><span class="by">pthr</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483448">parent</a><span>|</span><a href="#40483514">next</a><span>|</span><label class="collapse" for="c-40488477">[-]</label><label class="expand" for="c-40488477">[2 more]</label></div><br/><div class="children"><div class="content">Looks interesting, thanks for posting and commenting here!
Does it in any way attempt to find the global minimum, or will it merely enhance the decent to any local minimum of the cost function?</div><br/><div id="40488772" class="c"><input type="checkbox" id="c-40488772" checked=""/><div class="controls bullet"><span class="by">justinnk</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40488477">parent</a><span>|</span><a href="#40483514">next</a><span>|</span><label class="collapse" for="c-40488772">[-]</label><label class="expand" for="c-40488772">[1 more]</label></div><br/><div class="children"><div class="content">(I am one of the authors) Generally speaking, the latter. The purpose of DiscoGrad is just to deliver useful gradients. These provide information about the local behavior of the cost function around the currently evaluated point to an optimizer of your choice, e.g., gradient descent. Interestingly, the smoothing and noise can sometimes prevent getting stuck in undesired (shallow) local minima when using gradient descent.</div><br/></div></div></div></div><div id="40483514" class="c"><input type="checkbox" id="c-40483514" checked=""/><div class="controls bullet"><span class="by">eranation</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483448">parent</a><span>|</span><a href="#40488477">prev</a><span>|</span><a href="#40485651">next</a><span>|</span><label class="collapse" for="c-40483514">[-]</label><label class="expand" for="c-40483514">[3 more]</label></div><br/><div class="children"><div class="content">Awesome, thank you! Interesting. The first thing that came to my mind regarding the traffic light example is any problem that reduces to a SAT solver, I assume they are some that are clearly un-smoothable in polynomial time otherwise this will have interesting consequences...</div><br/><div id="40483687" class="c"><input type="checkbox" id="c-40483687" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483514">parent</a><span>|</span><a href="#40485651">next</a><span>|</span><label class="collapse" for="c-40483687">[-]</label><label class="expand" for="c-40483687">[2 more]</label></div><br/><div class="children"><div class="content">I agree with that intuition. In our experience, it&#x27;s easiest to see gains over other optimization techniques when the program is &quot;branch-wise smooth and non-constant&quot;. Then, we get the full benefits of exact autodiff gradients &quot;per branch&quot;, and our smoothing approach handles the branches. For SAT solving and other purely combinatorial problems, sufficiently accurate smoothing may indeed be too expensive. Also, in such problems, the average local minimum found via gradient descent may not always be that great. That said, we&#x27;re still exploring where the limits really are.</div><br/><div id="40483862" class="c"><input type="checkbox" id="c-40483862" checked=""/><div class="controls bullet"><span class="by">eranation</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483687">parent</a><span>|</span><a href="#40485651">next</a><span>|</span><label class="collapse" for="c-40483862">[-]</label><label class="expand" for="c-40483862">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the responses! I&#x27;ll be following your research for sure.</div><br/></div></div></div></div></div></div><div id="40485651" class="c"><input type="checkbox" id="c-40485651" checked=""/><div class="controls bullet"><span class="by">epr</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483448">parent</a><span>|</span><a href="#40483514">prev</a><span>|</span><a href="#40483408">next</a><span>|</span><label class="collapse" for="c-40485651">[-]</label><label class="expand" for="c-40485651">[1 more]</label></div><br/><div class="children"><div class="content">Obviously, some of this branching, etc. is not differentiable. Is it doing finite differences?</div><br/></div></div></div></div><div id="40483408" class="c"><input type="checkbox" id="c-40483408" checked=""/><div class="controls bullet"><span class="by">PeterHolzwarth</span><span>|</span><a href="#40483342">parent</a><span>|</span><a href="#40483448">prev</a><span>|</span><a href="#40483761">next</a><span>|</span><label class="collapse" for="c-40483408">[-]</label><label class="expand" for="c-40483408">[2 more]</label></div><br/><div class="children"><div class="content">You mean besides the examples of use cases mentioned in the linked page?</div><br/><div id="40483424" class="c"><input type="checkbox" id="c-40483424" checked=""/><div class="controls bullet"><span class="by">eranation</span><span>|</span><a href="#40483342">root</a><span>|</span><a href="#40483408">parent</a><span>|</span><a href="#40483761">next</a><span>|</span><label class="collapse" for="c-40483424">[-]</label><label class="expand" for="c-40483424">[1 more]</label></div><br/><div class="children"><div class="content">Good point, edited the question.</div><br/></div></div></div></div></div></div><div id="40483761" class="c"><input type="checkbox" id="c-40483761" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#40483342">prev</a><span>|</span><a href="#40483993">next</a><span>|</span><label class="collapse" for="c-40483761">[-]</label><label class="expand" for="c-40483761">[2 more]</label></div><br/><div class="children"><div class="content">When all you have is a hammer, ... you split up your house into wood and nails, and reduce it to a previously solved problem!<p>In all seriousness, this is super interesting. I really like the idea of implementing gradient descent solving branch by branch, and turning it into an optimization-level option for codebases.<p>I feel like this would normally be something commercialized by Intel&#x27;s compiler group; it&#x27;s hard for me to know how to get this out more broadly -- it would probably need to be standardized in some way?<p>Anyway, thanks for working on it and opening it up -- very cool. Needs more disco balls.</div><br/><div id="40483898" class="c"><input type="checkbox" id="c-40483898" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483761">parent</a><span>|</span><a href="#40483993">next</a><span>|</span><label class="collapse" for="c-40483898">[-]</label><label class="expand" for="c-40483898">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the kind words! We&#x27;d be super happy if this work gets picked up, whether in a commercial context or not.<p>We were thinking of some disco ball-based logo (among some other designs). With this encouragement, there&#x27;ll probably be an update in the next few days :)</div><br/></div></div></div></div><div id="40483993" class="c"><input type="checkbox" id="c-40483993" checked=""/><div class="controls bullet"><span class="by">dwrodri</span><span>|</span><a href="#40483761">prev</a><span>|</span><a href="#40483987">next</a><span>|</span><label class="collapse" for="c-40483993">[-]</label><label class="expand" for="c-40483993">[5 more]</label></div><br/><div class="children"><div class="content">This is the sort of thing I expected to see when Chris Lattner moved to Google and started working on the Swift for Tensorflow project. I am so grateful that someone is making it happen!<p>I remember being taught how to write Prolog in University, and then being shown how close the relationship was between building something that parses a grammar and building something that generates valid examples of that grammar. When I saw compiler&#x2F;language level support for differentiation, I the spark went off in my brain the same way: &quot;If you can build a program which follows a set of rules, and the rules for that language can be differentiated, could you not code a simulation in that differentiable language and then identify the optimal policy using it&#x27;s gradients?&quot;<p>Best of luck on your work!</div><br/><div id="40488893" class="c"><input type="checkbox" id="c-40488893" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#40483993">parent</a><span>|</span><a href="#40484793">next</a><span>|</span><label class="collapse" for="c-40488893">[-]</label><label class="expand" for="c-40488893">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; &quot;If you can build a program which follows a set of rules, and the rules for that language can be differentiated, could you not code a simulation in that differentiable language and then identify the optimal policy using it&#x27;s gradients?&quot;<p>What&#x27;s a &quot;policy&quot; here? In optimal control (and reinforcement learning) a policy is a function from a set of states to a set of actions, each action a transition between states. In a program synthesis context I guess that translates to a function from a set of _program_ states to a set of operations?<p>What is an &quot;optimal&quot; policy then? One that transitions between an initial state and a goal state in the least number of operations?<p>With those assumptions in place, I don&#x27;t think you want to do that with greadient descent: it will get stuck in local minima and fail in both optimality and generalisation.<p>Generalisation is easier to explain. Consider a program that has to traverse a graph. We can visualise it as solving a maze. Suppose we have two mazes, A and B, as below:<p><pre><code>        A               B
  S □ □ ■ □ □ □   S □ □ ■ □ □ □ 
  ■ ■ □ ■ □ ■ □   ■ ■ □ ■ □ ■ □ 
  □ ■ □ ■ □ ■ □   □ ■ □ ■ □ ■ □ 
  □ ■ □ ■ ■ ■ □   □ ■ □ ■ ■ ■ □ 
  □ ■ □ ■ □ □ □   □ ■ □ ■ □ □ □ 
  □ ■ □ ■ □ ■ □   □ ■ □ ■ □ ■ □ 
  □ □ □ □ □ ■ E   E □ □ □ □ ■ □ 
</code></pre>
Black squares are walls. Note that the two mazes are identical but the exit (&quot;E&quot;) is in a different place. An optimal policy that solves maze A will fail on maze B and v.v.  Meaning that for some classes of problem there is no policy that is optimal for the every instance in the class and finding an optimal solution requires computation. You can&#x27;t just set some weights in a function and call it a day.<p>It&#x27;s also easy to see what classes of problems are not amenable to this kind of solution: any decision problem that cannot be solved by a regular automaton (i.e. one that is no more than regular). Where there&#x27;s branching structure that introduces ambiguity -think of two different parses for one string in a language- you need a context-free grammar or above.<p>That&#x27;s a problem in Reinforcement Learning where &quot;agents&quot; (i.e. policies) can solve any instance of complex environment classes perfectly, but fail when tested in a different instance [1].<p>You&#x27;ll get the same problem with program synthesis.<p>___________<p>[1] This paper:<p><i>Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability</i><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.06277" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.06277</a><p>makes the point with what felt like a very convoluted example about a robotic zoo keeper looking for the otter habitat in a new zoo etc. I think it&#x27;s much more obvious what&#x27;s going on when we study the problem in a grid like a maze: there are ambiguities and a solution cannot be left to a policy that acts like a regular automaton.</div><br/></div></div><div id="40484793" class="c"><input type="checkbox" id="c-40484793" checked=""/><div class="controls bullet"><span class="by">justinnk</span><span>|</span><a href="#40483993">parent</a><span>|</span><a href="#40488893">prev</a><span>|</span><a href="#40484708">next</a><span>|</span><label class="collapse" for="c-40484793">[-]</label><label class="expand" for="c-40484793">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! You may find DeepProbLog by Manhaeve et al. interesting, which brings together logic programming, probabilistic programming and gradient descent&#x2F;neural networks. Also, more generally, I believe in the field of program synthesis there is some research on deriving programs with gradient descent. However, as also pointed out in the comment below, gradient descent may not always be the best approach to such problems (e.g., <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.04428" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.04428</a>).</div><br/></div></div><div id="40484708" class="c"><input type="checkbox" id="c-40484708" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#40483993">parent</a><span>|</span><a href="#40484793">prev</a><span>|</span><a href="#40483987">next</a><span>|</span><label class="collapse" for="c-40484708">[-]</label><label class="expand" for="c-40484708">[2 more]</label></div><br/><div class="children"><div class="content">Not really. The world of Bayesian modelling has much fancier tools: Hamiltonian MC. See MC Stan. There’s also been Gibbs samplers and other techniques which support discrete decisions for donkeys years.<p>You can write down just about anything as a BUGS model for example, but “identifying the model” —- finding the uniquely best parameters, even though it’s a globally optimisation —- is often very difficult.<p>Gradient descent is significantly more limiting than that. Worth understanding MC. The old school is a high bar to jump.</div><br/><div id="40485644" class="c"><input type="checkbox" id="c-40485644" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#40483993">root</a><span>|</span><a href="#40484708">parent</a><span>|</span><a href="#40483987">next</a><span>|</span><label class="collapse" for="c-40485644">[-]</label><label class="expand" for="c-40485644">[1 more]</label></div><br/><div class="children"><div class="content">MC: Monte Carlo</div><br/></div></div></div></div></div></div><div id="40483987" class="c"><input type="checkbox" id="c-40483987" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40483993">prev</a><span>|</span><a href="#40487822">next</a><span>|</span><label class="collapse" for="c-40483987">[-]</label><label class="expand" for="c-40483987">[5 more]</label></div><br/><div class="children"><div class="content">Awesome! Several of my colleagues are working on differentiable physics simulations (mostly FEM type stuff for structural design optimization) so I’m excited to share this with them! They mostly work in Julia. My own experiments with auto-diff’d physics sims have been in Python (specifically, Taichi for the JIT&#x2F;GPU acceleration or occasionally PyTorch&#x2F;Jax).<p>Can you talk a little bit about the challenges of bringing something like what you’ve implemented to existing autograd engines&#x2F;frameworks (like the ones previously mentioned)? Are you at all interested in exploring that as a mechanism for increasing access to your methodology? What are your thoughts on those autodiff engines?</div><br/><div id="40484186" class="c"><input type="checkbox" id="c-40484186" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483987">parent</a><span>|</span><a href="#40484166">next</a><span>|</span><label class="collapse" for="c-40484186">[-]</label><label class="expand" for="c-40484186">[2 more]</label></div><br/><div class="children"><div class="content">We actually did some preliminary experiments with Taichi hoping to benefit from the GPU parallelization. I think generally, the world of autodiff tooling is in very good shape. For anything non-exotic, we just use JAX or Torch to get things done quickly and with good performance.<p>Generally, integrating the ideas behind DiscoGrad into existing frameworks has been on our mind since day one, and the C++ implementation represents a bit of a compromise made to have a lot of flexibility during development while the algorithms were still a moving target, and good performance (albeit without parallelization and GPU support as of yet). Based on DiscoGrad&#x27;s current incarnation, however, it should not be terribly hard to, say, develop a JAX+DiscoGrad fork and offer some simple &quot;branch-like&quot; abstraction. While we&#x27;ve been looking into this, it can be a bit tricky in a university context to do the engineering leg work required to build something robust...</div><br/><div id="40484711" class="c"><input type="checkbox" id="c-40484711" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40483987">root</a><span>|</span><a href="#40484186">parent</a><span>|</span><a href="#40484166">next</a><span>|</span><label class="collapse" for="c-40484711">[-]</label><label class="expand" for="c-40484711">[1 more]</label></div><br/><div class="children"><div class="content">&gt; While we&#x27;ve been looking into this, it can be a bit tricky in a university context to do the engineering leg work required to build something robust...<p>I definitely hear you on this! As a grad student who is one of the only developers with actual professional dev xp in my lab, it can be brutal being tasked with turning academic spaghetti code into something semi-productionized&#x2F;robust.</div><br/></div></div></div></div><div id="40484166" class="c"><input type="checkbox" id="c-40484166" checked=""/><div class="controls bullet"><span class="by">avibryant</span><span>|</span><a href="#40483987">parent</a><span>|</span><a href="#40484186">prev</a><span>|</span><a href="#40487822">next</a><span>|</span><label class="collapse" for="c-40484166">[-]</label><label class="expand" for="c-40484166">[2 more]</label></div><br/><div class="children"><div class="content">Do you have any links to your experiments and&#x2F;or those of your colleagues?</div><br/><div id="40484758" class="c"><input type="checkbox" id="c-40484758" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40483987">root</a><span>|</span><a href="#40484166">parent</a><span>|</span><a href="#40487822">next</a><span>|</span><label class="collapse" for="c-40484758">[-]</label><label class="expand" for="c-40484758">[1 more]</label></div><br/><div class="children"><div class="content">Emailed you through the email listed on your HN profile</div><br/></div></div></div></div></div></div><div id="40487822" class="c"><input type="checkbox" id="c-40487822" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#40483987">prev</a><span>|</span><a href="#40485826">next</a><span>|</span><label class="collapse" for="c-40487822">[-]</label><label class="expand" for="c-40487822">[1 more]</label></div><br/><div class="children"><div class="content">Pretty cool. It is somewhat like Julia’s autodiff ecosystem - which also handles native, branching code.</div><br/></div></div><div id="40485826" class="c"><input type="checkbox" id="c-40485826" checked=""/><div class="controls bullet"><span class="by">zaitanz</span><span>|</span><a href="#40487822">prev</a><span>|</span><a href="#40483823">next</a><span>|</span><label class="collapse" for="c-40485826">[-]</label><label class="expand" for="c-40485826">[1 more]</label></div><br/><div class="children"><div class="content">So this confuses me slightly and I am keen to know the advantage of using this. I work on projects that heavily use auto-differentiation for complex models. The models are defined by user input files at run-time, so the state and execution pathway of the model is unknown at compilation time. Would this help?<p>Given that all auto-differentiation is an approximation anyways. I&#x27;ve found existing tooling (CppAD, ADMB, ADOL-C, Template Model Builder (TMB)) work fine. You don&#x27;t need to come up with a differentiable problem or re-parameterize. Why would I pick this over any of those?</div><br/></div></div><div id="40483823" class="c"><input type="checkbox" id="c-40483823" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#40485826">prev</a><span>|</span><a href="#40484787">next</a><span>|</span><label class="collapse" for="c-40483823">[-]</label><label class="expand" for="c-40483823">[3 more]</label></div><br/><div class="children"><div class="content">Discograd: a little-known top secret Soviet project where Brezhnev wanted to counter American influence in global popular music by creating an entire military town dedicated to evolving the four-on-the-floor beat towards Marxist-Leninist perfection through cybernetic principles of rhythm composition.<p>(After 1991 Discograd was demilitarized and renamed Grungetown to attract foreign investments.)</div><br/><div id="40483900" class="c"><input type="checkbox" id="c-40483900" checked=""/><div class="controls bullet"><span class="by">elpocko</span><span>|</span><a href="#40483823">parent</a><span>|</span><a href="#40484787">next</a><span>|</span><label class="collapse" for="c-40483900">[-]</label><label class="expand" for="c-40483900">[2 more]</label></div><br/><div class="children"><div class="content">In this alternate universe, Discograd was successful and became the cultural hub for Soviet rock music. It influenced bands like Kino, Aquarium and DDT who incorporated Marxist-Leninist themes into their music. Disco beats were indeed evolved but in a way that resonated with the ideology of the time. The four-on-the-floor beat became more intricate and complex, incorporating elements of jazz and folk music from various Soviet republics.<p>In this reality, Discograd hosted the first Soviet Rock Festival, which was attended by thousands of enthusiastic fans from all over the USSR. The festival featured performances by bands that were formed and nurtured in Discograd, showcasing a new genre: Proletrock – a unique fusion of disco, rock, jazz and Soviet folk music, with lyrics promoting socialist values and workers’ rights.<p>Proletrock eventually became the soundtrack of the late Soviet era, influencing not only the USSR but also countries in the Eastern Bloc, Latin America and even parts of Africa where Soviet influence was strong. The genre helped to spread communist ideology through catchy beats and thought-provoking lyrics, making Discograd an integral part of music history.<p>However, with the fall of the Soviet Union, Proletrock faded into obscurity, but its legacy lived on in the music of post-Soviet countries, where elements of this unique genre continue to influence modern artists today.<p>This is a fictional narrative inspired by real events and places that exist or existed within the context of Soviet history and culture. It serves as a creative exploration of what could have been if the USSR had pursued such an ambitious project with the same fervor it dedicated to its space program.<p>(WizardLM-2-7B)</div><br/><div id="40483955" class="c"><input type="checkbox" id="c-40483955" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#40483823">root</a><span>|</span><a href="#40483900">parent</a><span>|</span><a href="#40484787">next</a><span>|</span><label class="collapse" for="c-40483955">[-]</label><label class="expand" for="c-40483955">[1 more]</label></div><br/><div class="children"><div class="content">When the producers at Apple TV+ finally get bored with “For All Mankind”, they could greenlight this as a spin-off.</div><br/></div></div></div></div></div></div><div id="40484787" class="c"><input type="checkbox" id="c-40484787" checked=""/><div class="controls bullet"><span class="by">sundalia</span><span>|</span><a href="#40483823">prev</a><span>|</span><a href="#40484535">next</a><span>|</span><label class="collapse" for="c-40484787">[-]</label><label class="expand" for="c-40484787">[5 more]</label></div><br/><div class="children"><div class="content">This is very interesting. A few questions:<p>- Why do you think similar approaches never landed on jax? My guess is this is not that useful for the current optimizations in fashion (transformers)<p>- How would you convince jax to incorporate this?</div><br/><div id="40488332" class="c"><input type="checkbox" id="c-40488332" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#40484787">parent</a><span>|</span><a href="#40484863">next</a><span>|</span><label class="collapse" for="c-40488332">[-]</label><label class="expand" for="c-40488332">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Why do you think similar approaches never landed on jax?<p>Isn&#x27;t this just adding noise to some branching conditions? What would take for a framework like Jax to &quot;support&quot; it, it seems like all you have to do is change<p>&gt; if (x&gt;0)<p>to<p>&gt; if (x+n &gt; 0)<p>where n is a sampled Gaussian.<p>Not sure this warrants any kind of changes in a framework if it&#x27;s truly that trivial.</div><br/><div id="40488345" class="c"><input type="checkbox" id="c-40488345" checked=""/><div class="controls bullet"><span class="by">tomsmeding</span><span>|</span><a href="#40484787">root</a><span>|</span><a href="#40488332">parent</a><span>|</span><a href="#40484863">next</a><span>|</span><label class="collapse" for="c-40488345">[-]</label><label class="expand" for="c-40488345">[1 more]</label></div><br/><div class="children"><div class="content">Semantically it seems truly that trivial, but in practice handling expectations in AD requires some additional machinery not found in implementations that were not written for nondeterminism.</div><br/></div></div></div></div><div id="40484863" class="c"><input type="checkbox" id="c-40484863" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484787">parent</a><span>|</span><a href="#40488332">prev</a><span>|</span><a href="#40484535">next</a><span>|</span><label class="collapse" for="c-40484863">[-]</label><label class="expand" for="c-40484863">[2 more]</label></div><br/><div class="children"><div class="content">Well, the most common ML problems can be expressed as optimization over smooth functions (or reformulated that way manually). We might have to convince the ML world that branches do matter :) On the other hand, there are gradient-free approaches that solve problems with jumps in other ways, like many reinforcement learning algorithms, or metaheuristics such as genetic algorithms in simulation-based optimization. The jury&#x27;s still out on &quot;killer apps&quot; where gradient descent can outperform these approaches reliably, but we&#x27;re hoping to add to that body of knowledge...</div><br/><div id="40488987" class="c"><input type="checkbox" id="c-40488987" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#40484787">root</a><span>|</span><a href="#40484863">parent</a><span>|</span><a href="#40484535">next</a><span>|</span><label class="collapse" for="c-40488987">[-]</label><label class="expand" for="c-40488987">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div></div></div><div id="40484535" class="c"><input type="checkbox" id="c-40484535" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40484787">prev</a><span>|</span><a href="#40484673">next</a><span>|</span><label class="collapse" for="c-40484535">[-]</label><label class="expand" for="c-40484535">[5 more]</label></div><br/><div class="children"><div class="content">What do you mean by plain autodiff being mostly useless with normal&#x2F;discrete branching? Wouldn&#x27;t branches normally just be &quot;ignored&quot; by autodiff - each training sample being a different computational graph (but with parts in common) due to branching points, so the only effect of branching is which computational graph gets executed and backpropagated through?<p>What&#x27;s the general type of use case where this default behavior is useless, and &quot;non-discrete&quot; (stochastic?) branching helps?</div><br/><div id="40484620" class="c"><input type="checkbox" id="c-40484620" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484535">parent</a><span>|</span><a href="#40484673">next</a><span>|</span><label class="collapse" for="c-40484620">[-]</label><label class="expand" for="c-40484620">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right, plain autodiff just ignores branches. Our canonical &quot;why is this even needed&quot; example is a program like &quot;if (x &gt;= 0) return 1; else return 0&quot;, x being the input.<p>The autodiff derivative of this is zero, wherever you evaluate it, so if you sample x and run your program on each x as in a classical ML setup, you&#x27;d be averaging over a series of zero-derivatives. This is of course not helpful to gradient descent. In more complex programs, it&#x27;s less blatant, but the gist is that just averaging sampled gradients over programs (input-dependent!) branches yields biased or zero-valued derivatives. The traffic light optimization example shown on Github is a more complex example where averaged autodiff-gradients are always zero.</div><br/><div id="40485925" class="c"><input type="checkbox" id="c-40485925" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#40484535">root</a><span>|</span><a href="#40484620">parent</a><span>|</span><a href="#40485069">next</a><span>|</span><label class="collapse" for="c-40485925">[-]</label><label class="expand" for="c-40485925">[1 more]</label></div><br/><div class="children"><div class="content">Plain autodiff gives the correct derivative, but you modify the derivative to push people towards your global minimum?</div><br/></div></div><div id="40485069" class="c"><input type="checkbox" id="c-40485069" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40484535">root</a><span>|</span><a href="#40484620">parent</a><span>|</span><a href="#40485925">prev</a><span>|</span><a href="#40484673">next</a><span>|</span><label class="collapse" for="c-40485069">[-]</label><label class="expand" for="c-40485069">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, but could you briefly expand on what&#x27;s happening in the minimal if (x &gt;= 0) case with the discograd modification? What source code modification could the user could have made to achieve the same effect?</div><br/><div id="40485165" class="c"><input type="checkbox" id="c-40485165" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484535">root</a><span>|</span><a href="#40485069">parent</a><span>|</span><a href="#40484673">next</a><span>|</span><label class="collapse" for="c-40485165">[-]</label><label class="expand" for="c-40485165">[1 more]</label></div><br/><div class="children"><div class="content">In DiscoGrad, smoothing would be applied by adding Gaussian noise with some configurable variance to x and running the program on those x&#x27;s. The gradient would then be calculated based on the branch condition&#x27;s derivative wrt. x (which is 1) and an estimate of the distribution of the condition (which is Gaussian).<p>In this specific example, the smoothed derivative happens to be exactly the Gaussian cumulative distribution function, so the user could just replace the program with that function. However, for more complex programs, it&#x27;d be hard to find such correspondences manually.</div><br/></div></div></div></div></div></div></div></div><div id="40484673" class="c"><input type="checkbox" id="c-40484673" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#40484535">prev</a><span>|</span><a href="#40484296">next</a><span>|</span><label class="collapse" for="c-40484673">[-]</label><label class="expand" for="c-40484673">[6 more]</label></div><br/><div class="children"><div class="content">I used to replace strict Boolean conditionals with sigmoids in order to achieve continuous transfer for Bayesian change-point models.<p>Does this do something similar or is it fancier?</div><br/><div id="40484728" class="c"><input type="checkbox" id="c-40484728" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484673">parent</a><span>|</span><a href="#40484296">next</a><span>|</span><label class="collapse" for="c-40484728">[-]</label><label class="expand" for="c-40484728">[5 more]</label></div><br/><div class="children"><div class="content">Great point, the sigmoid approximation works well for certain problems and that&#x27;s in fact what I used in the exploratory papers that lead to this work. The downsides are the lack of a clear interpretation how the original program and its smooth counterpart are related, and the difficulty of controlling the degree of smoothing as programs get longer. What DiscoGrad computes has a statistical interpretation: it&#x27;s the convolution of the program output with whatever distribution is used for smoothing, typically a Gaussian with a configurable variance.<p>On top of that, if the program branches on random numbers (which is common in simulations), that suffices for the maths to work out and you get an estimate of the asymptotic gradient (for samples -&gt; infinity) of the original program, without any artificial smoothing.<p>So in short, I do think it is slightly fancier :)</div><br/><div id="40488547" class="c"><input type="checkbox" id="c-40488547" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#40484673">root</a><span>|</span><a href="#40484728">parent</a><span>|</span><a href="#40484837">next</a><span>|</span><label class="collapse" for="c-40488547">[-]</label><label class="expand" for="c-40488547">[2 more]</label></div><br/><div class="children"><div class="content">Does that imply that every possible branch is optimised separately and then convoluted thereafter?<p>If so, does it scale for very branchy programs?<p>Do you have any comparisons to a Gibbs based approach for any of the use case examples?</div><br/><div id="40488957" class="c"><input type="checkbox" id="c-40488957" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484673">root</a><span>|</span><a href="#40488547">parent</a><span>|</span><a href="#40484837">next</a><span>|</span><label class="collapse" for="c-40488957">[-]</label><label class="expand" for="c-40488957">[1 more]</label></div><br/><div class="children"><div class="content">The convolution is approximated via a form of sampling with additional bookkeeping at each encountered branch. How well that scales for deeply branching programs depends on the probabilities of the branches and the diversity in the output on the resulting paths, the worst case being a program where all branches are equally likely and each path generates an entirely different output (as in a hash function, for example). In practice, we&#x27;ve been dealing with problems involving up to tens of thousands of branches or so.<p>We&#x27;ve haven&#x27;t done a direct comparison to MCMC approaches yet, but it&#x27;s on the Todo list. My intuition is that MCMC will win out for problems where finding &quot;just any&quot; local optimum is not good enough.</div><br/></div></div></div></div><div id="40484837" class="c"><input type="checkbox" id="c-40484837" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40484673">root</a><span>|</span><a href="#40484728">parent</a><span>|</span><a href="#40488547">prev</a><span>|</span><a href="#40484296">next</a><span>|</span><label class="collapse" for="c-40484837">[-]</label><label class="expand" for="c-40484837">[2 more]</label></div><br/><div class="children"><div class="content">I’ve also used the sigmoid approximation to relax some problems (specifically for step changes in field properties in PINN problems) into continuous variables, cool to see this discussion here from a different perspective! Slightly off topic but the only other things I’m aware of that are vaguely related are things like the gumbel-softmax trick for making sampling from categorical distributions differentials or the Gaussian reparam trick (eg as used in VAEs). I’m curious if this is at least somewhat related to the approach taken in your work, in spirit if not in technical implementation?</div><br/><div id="40485014" class="c"><input type="checkbox" id="c-40485014" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484673">root</a><span>|</span><a href="#40484837">parent</a><span>|</span><a href="#40484296">next</a><span>|</span><label class="collapse" for="c-40485014">[-]</label><label class="expand" for="c-40485014">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, those tricks are highly related to what we do, the main difference being that we don&#x27;t require a priori information about the distributions involved in the program. Instead, we compute a density estimation of the distribution of branch conditions at runtime, which makes things quite general and fully automatic, at the cost of some accuracy.<p>As an aside, the combination &quot;known distributions + automation&quot; is covered in the Julia world  by stochasticAD (<a href="https:&#x2F;&#x2F;github.com&#x2F;gaurav-arya&#x2F;StochasticAD.jl">https:&#x2F;&#x2F;github.com&#x2F;gaurav-arya&#x2F;StochasticAD.jl</a>).</div><br/></div></div></div></div></div></div></div></div><div id="40484296" class="c"><input type="checkbox" id="c-40484296" checked=""/><div class="controls bullet"><span class="by">casualscience</span><span>|</span><a href="#40484673">prev</a><span>|</span><a href="#40484435">next</a><span>|</span><label class="collapse" for="c-40484296">[-]</label><label class="expand" for="c-40484296">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m confused as to the use cases for this? Are you saying if I want to fit some &quot;magic numbers&quot; in my cpp program, I can now do that by pulling in discograd and wrapping those numbers with some code that says &quot;please fit these&quot;, then adding some test cases somewhere?</div><br/><div id="40484456" class="c"><input type="checkbox" id="c-40484456" checked=""/><div class="controls bullet"><span class="by">justinnk</span><span>|</span><a href="#40484296">parent</a><span>|</span><a href="#40484364">next</a><span>|</span><label class="collapse" for="c-40484456">[-]</label><label class="expand" for="c-40484456">[1 more]</label></div><br/><div class="children"><div class="content">(I am one of the authors)
Thanks for your question. Yes, similar to what you describe but not quite. The prime use case is to apply DiscoGrad together with a gradient descent optimizer to optimization problems. For a C++ program to be regarded as such, you have to define what the &quot;inputs&quot; are and the program has to return some numerical value (loss) that is to be maximized&#x2F;minimized. The tool then delivers a &quot;direction&quot; (smoothed gradient), which gradient descent can use to adjust the inputs toward a local optimum.<p>So if you can express your test cases in a numerical way and make the placeholders for the &quot;magic numbers&quot; visible to the tool by regarding them as &quot;inputs&quot; (which should generally be possible), this may be a possible use-case. Hope this clarifies it.</div><br/></div></div><div id="40484364" class="c"><input type="checkbox" id="c-40484364" checked=""/><div class="controls bullet"><span class="by">jey</span><span>|</span><a href="#40484296">parent</a><span>|</span><a href="#40484456">prev</a><span>|</span><a href="#40484435">next</a><span>|</span><label class="collapse" for="c-40484364">[-]</label><label class="expand" for="c-40484364">[3 more]</label></div><br/><div class="children"><div class="content">No, the use cases for this are similar to regular autodiff, where you implement a function f(x) and the library helps you automatically compute derivatives such as the gradient g(x) := ∇f(x). Various autodiff methods differ in how they accomplish this, and the library shared here uses a code-generation approach where it performs a source-to-source transformation to generate source code for g(x) based on the code for f(x).</div><br/><div id="40484510" class="c"><input type="checkbox" id="c-40484510" checked=""/><div class="controls bullet"><span class="by">justinnk</span><span>|</span><a href="#40484296">root</a><span>|</span><a href="#40484364">parent</a><span>|</span><a href="#40484435">next</a><span>|</span><label class="collapse" for="c-40484510">[-]</label><label class="expand" for="c-40484510">[2 more]</label></div><br/><div class="children"><div class="content">You are right in that the use-cases are very similar to regular autodiff, with the added benefit that the returned gradient also accounts for the effects of taking alternative branches.<p>Just to clarify: we do a kind of source-to-source transformation by transparently injecting some API-calls in the right places (e.g., before branching-statements) before compilation. However, the compiled program then returns the program output alongside the gradient.<p>For the continuous parts, the AD library that comes with DiscoGrad uses operator overloading.</div><br/><div id="40487980" class="c"><input type="checkbox" id="c-40487980" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#40484296">root</a><span>|</span><a href="#40484510">parent</a><span>|</span><a href="#40484435">next</a><span>|</span><label class="collapse" for="c-40487980">[-]</label><label class="expand" for="c-40487980">[1 more]</label></div><br/><div class="children"><div class="content">&gt; with the added benefit that the returned gradient also accounts for the effects of taking alternative branches.<p>Does this mean that you can take the partial derivative in respect to some boolean variable that will be used in an if (for example), but with regular autodiff you can&#x27;t?<p>I&#x27;m struggling to understand why regular autodiff works even in presence of this limitation. Is it just a crude approximation of the &quot;true&quot; derivative?</div><br/></div></div></div></div></div></div></div></div><div id="40484435" class="c"><input type="checkbox" id="c-40484435" checked=""/><div class="controls bullet"><span class="by">brap</span><span>|</span><a href="#40484296">prev</a><span>|</span><a href="#40484167">next</a><span>|</span><label class="collapse" for="c-40484435">[-]</label><label class="expand" for="c-40484435">[2 more]</label></div><br/><div class="children"><div class="content">Somewhat related: is there autograd in python that uses AST analysis or something similar? The only method I’m familiar with uses tracer objects which have their gotchas. I’d like to compile a python function (at runtime) while writing its code as naturally as possible</div><br/><div id="40484808" class="c"><input type="checkbox" id="c-40484808" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40484435">parent</a><span>|</span><a href="#40484167">next</a><span>|</span><label class="collapse" for="c-40484808">[-]</label><label class="expand" for="c-40484808">[1 more]</label></div><br/><div class="children"><div class="content">Taichi (Python package) definitely uses AST for at least the JIT’ing&#x2F;kernel generation, not sure about how the autograd works under the hood but these links will get you started. There are plenty of publications about taichi which you can look up as well for more detail I am sure.<p><a href="https:&#x2F;&#x2F;docs.taichi-lang.org&#x2F;docs&#x2F;differentiable_programming" rel="nofollow">https:&#x2F;&#x2F;docs.taichi-lang.org&#x2F;docs&#x2F;differentiable_programming</a><p><a href="https:&#x2F;&#x2F;docs.taichi-lang.org&#x2F;docs&#x2F;compilation" rel="nofollow">https:&#x2F;&#x2F;docs.taichi-lang.org&#x2F;docs&#x2F;compilation</a></div><br/></div></div></div></div><div id="40484167" class="c"><input type="checkbox" id="c-40484167" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40484435">prev</a><span>|</span><a href="#40483912">next</a><span>|</span><label class="collapse" for="c-40484167">[-]</label><label class="expand" for="c-40484167">[2 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t replacing the flow control statements with ML models slow it down too much? Do you have the ability to automatically estimate the appropriate model complexity for a given statement based on how hot it is?</div><br/><div id="40484236" class="c"><input type="checkbox" id="c-40484236" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484167">parent</a><span>|</span><a href="#40483912">next</a><span>|</span><label class="collapse" for="c-40484236">[-]</label><label class="expand" for="c-40484236">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re doing something less expensive: essentially, the overall gradient is computed based on certain statistics based on the branch condition and its derivatives when a branch is encountered.<p>We mention neural networks because DiscoGrad lets you combine branching programs  with neural networks (via Torch) and jointly train&#x2F;optimize them.</div><br/></div></div></div></div><div id="40483912" class="c"><input type="checkbox" id="c-40483912" checked=""/><div class="controls bullet"><span class="by">s_tim</span><span>|</span><a href="#40484167">prev</a><span>|</span><a href="#40484199">next</a><span>|</span><label class="collapse" for="c-40483912">[-]</label><label class="expand" for="c-40483912">[2 more]</label></div><br/><div class="children"><div class="content">How does this compare to Enzyme (<a href="https:&#x2F;&#x2F;enzyme.mit.edu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;enzyme.mit.edu&#x2F;</a>)?</div><br/><div id="40483986" class="c"><input type="checkbox" id="c-40483986" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483912">parent</a><span>|</span><a href="#40484199">next</a><span>|</span><label class="collapse" for="c-40483986">[-]</label><label class="expand" for="c-40483986">[1 more]</label></div><br/><div class="children"><div class="content">Enzyme is traditional, but super duper optimized, autodiff, that is, it returns the partial derivatives for one path taken through the program, ignoring other branches. DiscoGrad captures the effects of alternative branches. What&#x27;s special about enzyme is that the gradient computations benefit from LLVM&#x27;s optimization passes and language support.</div><br/></div></div></div></div><div id="40484199" class="c"><input type="checkbox" id="c-40484199" checked=""/><div class="controls bullet"><span class="by">boywitharupee</span><span>|</span><a href="#40483912">prev</a><span>|</span><a href="#40483747">next</a><span>|</span><label class="collapse" for="c-40484199">[-]</label><label class="expand" for="c-40484199">[2 more]</label></div><br/><div class="children"><div class="content">how would you compare this to the polytope model? <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Polytope_model" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Polytope_model</a></div><br/><div id="40484324" class="c"><input type="checkbox" id="c-40484324" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40484199">parent</a><span>|</span><a href="#40483747">next</a><span>|</span><label class="collapse" for="c-40484324">[-]</label><label class="expand" for="c-40484324">[1 more]</label></div><br/><div class="children"><div class="content">Not super closely related: the polytope model (to the degree I&#x27;m familiar with it) is used as a representation that facilitates optimization of loop nests. That&#x27;s optimization in the sense of finding an efficient program.<p>DiscoGrad deals with (or provides gradients for) mathematical optimization. In our case, the goal is to minimize or maximize the program&#x27;s numerical output by adjusting it&#x27;s input parameters. Typically, your C++ program will run somewhat slower with DiscoGrad than without, but you can now use gradient descent to quickly find the best possible input parameters.</div><br/></div></div></div></div><div id="40483747" class="c"><input type="checkbox" id="c-40483747" checked=""/><div class="controls bullet"><span class="by">ipunchghosts</span><span>|</span><a href="#40484199">prev</a><span>|</span><label class="collapse" for="c-40483747">[-]</label><label class="expand" for="c-40483747">[2 more]</label></div><br/><div class="children"><div class="content">Talk about the differences between this and ceres <a href="http:&#x2F;&#x2F;ceres-solver.org&#x2F;" rel="nofollow">http:&#x2F;&#x2F;ceres-solver.org&#x2F;</a>.</div><br/><div id="40483870" class="c"><input type="checkbox" id="c-40483870" checked=""/><div class="controls bullet"><span class="by">frankling_</span><span>|</span><a href="#40483747">parent</a><span>|</span><label class="collapse" for="c-40483870">[-]</label><label class="expand" for="c-40483870">[1 more]</label></div><br/><div class="children"><div class="content">The key point is that Ceres requires derivatives, which can come from manually derived formulae, approximations via finite differences, or autodiff (<a href="http:&#x2F;&#x2F;ceres-solver.org&#x2F;derivatives.html" rel="nofollow">http:&#x2F;&#x2F;ceres-solver.org&#x2F;derivatives.html</a>). DiscoGrad doesn&#x27;t do the optimization itself (for that, we use gradient descent, for example via Adam), but essentially represents a fourth option to obtain derivatives, and one which captures the branches in an optimization problem (which autodiff doesn&#x27;t).<p>While I&#x27;m not super familiar with the typical use cases for Ceres, the gradient estimator from DiscoGrad could possibly be integrated to better handle branchy problems.</div><br/></div></div></div></div></div></div></div></div></div></body></html>