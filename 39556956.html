<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709283672982" as="style"/><link rel="stylesheet" href="styles.css?v=1709283672982"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.adamgrant.info/tiny-predictive-text">Show HN: Predictive text using only 13kb of JavaScript. no LLM</a> <span class="domain">(<a href="https://www.adamgrant.info">www.adamgrant.info</a>)</span></div><div class="subtext"><span>adamkochanowicz</span> | <span>9 comments</span></div><br/><div><div id="39559969" class="c"><input type="checkbox" id="c-39559969" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39559423">next</a><span>|</span><label class="collapse" for="c-39559969">[-]</label><label class="expand" for="c-39559969">[1 more]</label></div><br/><div class="children"><div class="content">Pretty cool, a js implementation of n-grams!<p>What is amazing to me is this: imagine that English only had 10,000 words. For each of those 10,000 words there’s 100 valid subsequent words. So there’s 1 million valid bigrams. Now if you want trigrams that takes you to 100 million, and for 4-grams it’ll be 10 billion. Just for that, you’d need 14 bytes per word and gigabytes of storage.<p>LLMs typically have context windows in the hundreds if not thousands. (<i>Back in my day</i> GPT2 had a context window of 1024 and we called that an LLM. And we liked it.) So it’s kind of amazing that a model that can fit on a flash drive can make reasonable next token prediction on the whole internet and with a context size that can fit a whole book.</div><br/></div></div><div id="39559423" class="c"><input type="checkbox" id="c-39559423" checked=""/><div class="controls bullet"><span class="by">adzm</span><span>|</span><a href="#39559969">prev</a><span>|</span><a href="#39558200">next</a><span>|</span><label class="collapse" for="c-39559423">[-]</label><label class="expand" for="c-39559423">[4 more]</label></div><br/><div class="children"><div class="content">So this is basically a Markov chain right?</div><br/><div id="39559531" class="c"><input type="checkbox" id="c-39559531" checked=""/><div class="controls bullet"><span class="by">hidelooktropic</span><span>|</span><a href="#39559423">parent</a><span>|</span><a href="#39558200">next</a><span>|</span><label class="collapse" for="c-39559531">[-]</label><label class="expand" for="c-39559531">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so. It&#x27;s basically just traversing nested arrays and picking a random member on each level.</div><br/><div id="39559627" class="c"><input type="checkbox" id="c-39559627" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#39559423">root</a><span>|</span><a href="#39559531">parent</a><span>|</span><a href="#39558200">next</a><span>|</span><label class="collapse" for="c-39559627">[-]</label><label class="expand" for="c-39559627">[2 more]</label></div><br/><div class="children"><div class="content">Yep. Sounds like a Markov chain to me.</div><br/><div id="39559895" class="c"><input type="checkbox" id="c-39559895" checked=""/><div class="controls bullet"><span class="by">fruktmix</span><span>|</span><a href="#39559423">root</a><span>|</span><a href="#39559627">parent</a><span>|</span><a href="#39558200">next</a><span>|</span><label class="collapse" for="c-39559895">[-]</label><label class="expand" for="c-39559895">[1 more]</label></div><br/><div class="children"><div class="content">Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.</div><br/></div></div></div></div></div></div></div></div><div id="39558200" class="c"><input type="checkbox" id="c-39558200" checked=""/><div class="controls bullet"><span class="by">pseudo_meta</span><span>|</span><a href="#39559423">prev</a><span>|</span><a href="#39559607">next</a><span>|</span><label class="collapse" for="c-39558200">[-]</label><label class="expand" for="c-39558200">[2 more]</label></div><br/><div class="children"><div class="content">Seeing that you use Obsidian: Have you thought about turning that into an Obsidian plugin that offers the predictions as editor suggestions?</div><br/><div id="39559526" class="c"><input type="checkbox" id="c-39559526" checked=""/><div class="controls bullet"><span class="by">hidelooktropic</span><span>|</span><a href="#39558200">parent</a><span>|</span><a href="#39559607">next</a><span>|</span><label class="collapse" for="c-39559526">[-]</label><label class="expand" for="c-39559526">[1 more]</label></div><br/><div class="children"><div class="content">Interesting application</div><br/></div></div></div></div><div id="39559607" class="c"><input type="checkbox" id="c-39559607" checked=""/><div class="controls bullet"><span class="by">dariosalvi78</span><span>|</span><a href="#39558200">prev</a><span>|</span><label class="collapse" for="c-39559607">[-]</label><label class="expand" for="c-39559607">[1 more]</label></div><br/><div class="children"><div class="content">An SLM?</div><br/></div></div></div></div></div></div></div></body></html>