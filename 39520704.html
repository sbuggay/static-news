<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709024454020" as="style"/><link rel="stylesheet" href="styles.css?v=1709024454020"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.cbc.ca/news/canada/british-columbia/lawyer-chatgpt-fake-precedent-1.7126393">B.C. lawyer reprimanded for citing fake cases invented by ChatGPT</a>Â <span class="domain">(<a href="https://www.cbc.ca">www.cbc.ca</a>)</span></div><div class="subtext"><span>uladzislau</span> | <span>11 comments</span></div><br/><div><div id="39521188" class="c"><input type="checkbox" id="c-39521188" checked=""/><div class="controls bullet"><span class="by">bell-cot</span><span>|</span><a href="#39521125">next</a><span>|</span><label class="collapse" for="c-39521188">[-]</label><label class="expand" for="c-39521188">[1 more]</label></div><br/><div class="children"><div class="content">The judge believed the offending lawyer&#x27;s plea of ignorant incompetence, and declined the other side&#x27;s request for extra penalties for reprehensible conduct and abuse of process.  But still ordered the offender to review all her previous work submitted to the court, to identify any previous submissions of fake cases...<p>So a complete train wreck, that could re-open a bunch of settled cases.  Or the offender and the &quot;justice&quot; system might quietly &quot;decide&quot; that they don&#x27;t want to work hard at making themselves look worse, and just leave a bunch of wrongly-settled cases lie.<p>IANAL, but it seems long past time for judges to start pretending that they actually care about the &quot;truth and justice&quot; stuff, and permabanning lawyers who pull this kind of crap from the practice of law.</div><br/></div></div><div id="39521125" class="c"><input type="checkbox" id="c-39521125" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#39521188">prev</a><span>|</span><a href="#39521660">next</a><span>|</span><label class="collapse" for="c-39521125">[-]</label><label class="expand" for="c-39521125">[5 more]</label></div><br/><div class="children"><div class="content"><i>&quot;I did not intend to generate or refer to fictitious cases in this matter. That is clearly wrong and not something I would knowingly do,&quot; Ke wrote in her deposition.<p>&quot;I never had any intention to rely upon any fictitious authorities or to mislead the court.&quot;</i><p>So beware what ChatGPT tells you. It might not be real and this can be a big problem in some situations.</div><br/><div id="39521517" class="c"><input type="checkbox" id="c-39521517" checked=""/><div class="controls bullet"><span class="by">255kb</span><span>|</span><a href="#39521125">parent</a><span>|</span><a href="#39521624">next</a><span>|</span><label class="collapse" for="c-39521517">[-]</label><label class="expand" for="c-39521517">[2 more]</label></div><br/><div class="children"><div class="content">Every time I see a company&#x2F;startup claiming to do an AI about X or Y, I wonder how they can be trusted at all. What about all the hallucinations, false positives, etc.? 
Aside from some sort of tool that classify cases, or extract key points from an agreement, and talk in probabilities rather than asserting things I don&#x27;t see a use for these. And I don&#x27;t know if we will be able to 100% trust these tools one day.</div><br/><div id="39521536" class="c"><input type="checkbox" id="c-39521536" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#39521125">root</a><span>|</span><a href="#39521517">parent</a><span>|</span><a href="#39521624">next</a><span>|</span><label class="collapse" for="c-39521536">[-]</label><label class="expand" for="c-39521536">[1 more]</label></div><br/><div class="children"><div class="content">We haven&#x27;t figured out how to deal with human intelligence effectively. It&#x27;s jumping the gun to imagine we can do AI well.<p>&#x2F;2 cents -- as if I need a &quot;disclaimer&quot; but the internet being what it is....</div><br/></div></div></div></div><div id="39521624" class="c"><input type="checkbox" id="c-39521624" checked=""/><div class="controls bullet"><span class="by">Lio</span><span>|</span><a href="#39521125">parent</a><span>|</span><a href="#39521517">prev</a><span>|</span><a href="#39521660">next</a><span>|</span><label class="collapse" for="c-39521624">[-]</label><label class="expand" for="c-39521624">[2 more]</label></div><br/><div class="children"><div class="content"><i>&quot;That is clearly wrong and not something I would knowingly do,&quot;</i><p>Such a bullshit excuse.  If you are using ChatGPT to do the donkey work for you then you are knowingly using it to cut corners.<p>It&#x27;s like turning up in court and saying &quot;well I asked this postman Cliff at the bar I go to his opinion on the case...&quot;.<p>She should loose here licence for pulling a stunt like that.</div><br/><div id="39521698" class="c"><input type="checkbox" id="c-39521698" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39521125">root</a><span>|</span><a href="#39521624">parent</a><span>|</span><a href="#39521660">next</a><span>|</span><label class="collapse" for="c-39521698">[-]</label><label class="expand" for="c-39521698">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s sufficiently good that it fools people into thinking its not even corner-cutting.<p>85% of the time, the source code it gives me is correct (50% of the time it&#x27;s mediocre, but still correct); how good or bad varies wildly in a way that suggests behind the scenes changes like all software, but it&#x27;s enough that I can easily believe someone sees it on a good day, is convinced it&#x27;s always that good, and doesn&#x27;t keep checking.</div><br/></div></div></div></div></div></div><div id="39521660" class="c"><input type="checkbox" id="c-39521660" checked=""/><div class="controls bullet"><span class="by">rcbdev</span><span>|</span><a href="#39521125">prev</a><span>|</span><a href="#39521105">next</a><span>|</span><label class="collapse" for="c-39521660">[-]</label><label class="expand" for="c-39521660">[2 more]</label></div><br/><div class="children"><div class="content">Despite what some in the tech space might think, I&#x27;m not sure I can lay the blame 100 % on the lawyer.<p>It&#x27;s true that this is definitely malpractice and they should have known better, it&#x27;s also true that big tech for years overplayed their hand with the marketing of &quot;AI&quot; to laypeople and management, which has created completely unreasonable expectations.<p>As long as OpenAI has a profit motive to make people believe ChatGPT is &quot;right&quot; more often than not they will never blatantly advertise that everything their product generates might be unverifiable garbage, especially in a way everyone will understand and that isn&#x27;t just a liability footnote.</div><br/><div id="39521781" class="c"><input type="checkbox" id="c-39521781" checked=""/><div class="controls bullet"><span class="by">bigstrat2003</span><span>|</span><a href="#39521660">parent</a><span>|</span><a href="#39521105">next</a><span>|</span><label class="collapse" for="c-39521781">[-]</label><label class="expand" for="c-39521781">[1 more]</label></div><br/><div class="children"><div class="content">Right. I think it&#x27;s fair to ask whether a reasonable, non-technical person would even know that ChatGPT will hallucinate answers. That is widely known in the tech world (and even still you have people relying on it for work, which blows my mind), but it takes time for that knowledge to get out to the general public. That goes double when vendors are putting out advertising which misleads people (as you pointed out).</div><br/></div></div></div></div><div id="39521105" class="c"><input type="checkbox" id="c-39521105" checked=""/><div class="controls bullet"><span class="by">loregate</span><span>|</span><a href="#39521660">prev</a><span>|</span><a href="#39520811">next</a><span>|</span><label class="collapse" for="c-39521105">[-]</label><label class="expand" for="c-39521105">[1 more]</label></div><br/><div class="children"><div class="content">Your honor, my source is that I made it the fuck up.</div><br/></div></div><div id="39520811" class="c"><input type="checkbox" id="c-39520811" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#39521105">prev</a><span>|</span><label class="collapse" for="c-39520811">[-]</label><label class="expand" for="c-39520811">[1 more]</label></div><br/><div class="children"><div class="content">Related:<p><i>Lawyer fined for legal filings that included &#x27;hallucinated&#x27; AI citations</i><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39491510">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39491510</a></div><br/></div></div></div></div></div></div></div></body></html>