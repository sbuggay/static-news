<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1689584451521" as="style"/><link rel="stylesheet" href="styles.css?v=1689584451521"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://automorphic.ai/playground">Show HN: Structured output from LLMs without reprompting</a> <span class="domain">(<a href="https://automorphic.ai">automorphic.ai</a>)</span></div><div class="subtext"><span>sandkoan</span> | <span>42 comments</span></div><br/><div><div id="36755669" class="c"><input type="checkbox" id="c-36755669" checked=""/><div class="controls bullet"><span class="by">jensneuse</span><span>|</span><a href="#36753232">next</a><span>|</span><label class="collapse" for="c-36755669">[-]</label><label class="expand" for="c-36755669">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re using a similar approach with OpenAI. The user can define a schema using zod and call a prompt. We&#x27;re then using OpenAI functions behind the scenes to parse the answer into the shape the user wants. Add JSON schema validation on top and we can be sure that the response conforms to our Schema. Some more details and examples can be found in this blog post: <a href="https:&#x2F;&#x2F;wundergraph.com&#x2F;blog&#x2F;beyond_functions_seamlessly_build_ai_enhanced_apis_with_openai" rel="nofollow noreferrer">https:&#x2F;&#x2F;wundergraph.com&#x2F;blog&#x2F;beyond_functions_seamlessly_bui...</a></div><br/></div></div><div id="36753232" class="c"><input type="checkbox" id="c-36753232" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36755669">prev</a><span>|</span><a href="#36752369">next</a><span>|</span><label class="collapse" for="c-36753232">[-]</label><label class="expand" for="c-36753232">[8 more]</label></div><br/><div class="children"><div class="content">the more it goes, the more I realize that the true power of LLMs is not in unstructured text that they can generate, but in structured output. but there are two approaches to achieve this:<p>1. LMQL&#x2F;guidance&#x2F;JSONformer&#x2F;OP&#x27;s post<p>2. finetuning the model to understand function calls and their (potentially) JSON schemas.<p>there was a comment here about OpenAI&#x27;s approach (finetuning a model to understand function call) which raised a good point: since finetuning is often forgetful (previous knowledge learnt by the model gets forgotten a little bit), it&#x27;s not clear if OpenAI&#x27;s approach has made GPT-4 less capable than it was before. Not to mention that you&#x27;re still dealing with a statistical process (LLM), not a locked-in algorithm that generates the desired schema 100% the time.<p>Which brings me to the other approach: steering the LLM&#x27;s output __as it is generating tokens__, which is what LMQL does. This results in less token usage (you don&#x27;t send function schema as part of your prompt&#x2F;message to OpenAI) and 100% accuracy because token probabilities are modified (e.g., 0% chance of any character except &quot;:&quot; after a double quotation mark).</div><br/><div id="36753611" class="c"><input type="checkbox" id="c-36753611" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36753232">parent</a><span>|</span><a href="#36754911">next</a><span>|</span><label class="collapse" for="c-36753611">[-]</label><label class="expand" for="c-36753611">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Which brings me to the other approach: steering the LLM&#x27;s output __as it is generating tokens__<p>A relevant PR:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773</a><p>The plan is to support arbitrary grammar files to constrain token generation, similar to the grammar files here:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;antlr&#x2F;grammars-v4">https:&#x2F;&#x2F;github.com&#x2F;antlr&#x2F;grammars-v4</a></div><br/></div></div><div id="36754911" class="c"><input type="checkbox" id="c-36754911" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#36753232">parent</a><span>|</span><a href="#36753611">prev</a><span>|</span><a href="#36754509">next</a><span>|</span><label class="collapse" for="c-36754911">[-]</label><label class="expand" for="c-36754911">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for bringing up LMQL. We have active branches with regex, parsers and types (structured and other types) which will also soon be upstreamed, improving typed LLM use beyond the current template-based approach we support.</div><br/></div></div><div id="36754509" class="c"><input type="checkbox" id="c-36754509" checked=""/><div class="controls bullet"><span class="by">sebmellen</span><span>|</span><a href="#36753232">parent</a><span>|</span><a href="#36754911">prev</a><span>|</span><a href="#36755037">next</a><span>|</span><label class="collapse" for="c-36754509">[-]</label><label class="expand" for="c-36754509">[1 more]</label></div><br/><div class="children"><div class="content">Yes! I don’t have much to say that wouldn’t be restating what I’ve already written, so I’ll link this for reference: <a href="https:&#x2F;&#x2F;www.sebastianmellen.com&#x2F;post&#x2F;2023&#x2F;the-killer-use-case-for-llms-is-summarization&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sebastianmellen.com&#x2F;post&#x2F;2023&#x2F;the-killer-use-cas...</a>.</div><br/></div></div><div id="36755037" class="c"><input type="checkbox" id="c-36755037" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#36753232">parent</a><span>|</span><a href="#36754509">prev</a><span>|</span><a href="#36754313">next</a><span>|</span><label class="collapse" for="c-36755037">[-]</label><label class="expand" for="c-36755037">[2 more]</label></div><br/><div class="children"><div class="content">has there been any work done to finetune OSS models to behave the same as openai functions (to constrain json output) ?<p>this is tablestakes now, but it doesnt seem ANY opensource model has this capability</div><br/><div id="36755083" class="c"><input type="checkbox" id="c-36755083" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36753232">root</a><span>|</span><a href="#36755037">parent</a><span>|</span><a href="#36754313">next</a><span>|</span><label class="collapse" for="c-36755083">[-]</label><label class="expand" for="c-36755083">[1 more]</label></div><br/><div class="children"><div class="content">You wouldn&#x27;t actually want to, because you&#x27;d be losing generalizability, and it&#x27;s a lot of unnecessary work.<p>I think approach #1 outlined above is the better (more cost- and time-efficient) technique—where a pretrained model already understands JSON (among myriad other formats), and you merely constrain it at text-gen time to valid JSON (or other format).</div><br/></div></div></div></div><div id="36754313" class="c"><input type="checkbox" id="c-36754313" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36753232">parent</a><span>|</span><a href="#36755037">prev</a><span>|</span><a href="#36752369">next</a><span>|</span><label class="collapse" for="c-36754313">[-]</label><label class="expand" for="c-36754313">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d never heard of LMQL before today, but it looks very nice.  Do you have any experience building with it and, if so, would you be willing to comment on what it&#x27;s like?</div><br/><div id="36755122" class="c"><input type="checkbox" id="c-36755122" checked=""/><div class="controls bullet"><span class="by">theblazehen</span><span>|</span><a href="#36753232">root</a><span>|</span><a href="#36754313">parent</a><span>|</span><a href="#36752369">next</a><span>|</span><label class="collapse" for="c-36755122">[-]</label><label class="expand" for="c-36755122">[1 more]</label></div><br/><div class="children"><div class="content">I did a POC project with it recently. The guidance on gpt-3.5-turbo and gpt-4 models isn&#x27;t as functional as plain gpt-3. I found I had better results using <a href="https:&#x2F;&#x2F;github.com&#x2F;piercefreeman&#x2F;gpt-json">https:&#x2F;&#x2F;github.com&#x2F;piercefreeman&#x2F;gpt-json</a> and it doesn&#x27;t require multiple calls to the API. Not as feature filled, but it may meet your needs</div><br/></div></div></div></div></div></div><div id="36752369" class="c"><input type="checkbox" id="c-36752369" checked=""/><div class="controls bullet"><span class="by">sunshadow</span><span>|</span><a href="#36753232">prev</a><span>|</span><a href="#36753155">next</a><span>|</span><label class="collapse" for="c-36752369">[-]</label><label class="expand" for="c-36752369">[12 more]</label></div><br/><div class="children"><div class="content">What are the benefits over <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance&#x2F;</a> ?</div><br/><div id="36752420" class="c"><input type="checkbox" id="c-36752420" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752369">parent</a><span>|</span><a href="#36753203">next</a><span>|</span><label class="collapse" for="c-36752420">[-]</label><label class="expand" for="c-36752420">[3 more]</label></div><br/><div class="children"><div class="content">We enable conforming to arbitrary context free grammars in addition to regex patterns, and have a bunch of speed optimizations, as well.<p>Though it may not seem too fast right now on account of the hundreds of simultaneous requests we&#x27;re getting :)</div><br/><div id="36752890" class="c"><input type="checkbox" id="c-36752890" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36752420">parent</a><span>|</span><a href="#36753203">next</a><span>|</span><label class="collapse" for="c-36752890">[-]</label><label class="expand" for="c-36752890">[2 more]</label></div><br/><div class="children"><div class="content">100s of RPS? did you have a successful launch elsewhere or something? bc this repo currently only has 21 stars, which taking normal correlation into account does not imply that level of traffic</div><br/><div id="36753073" class="c"><input type="checkbox" id="c-36753073" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36752890">parent</a><span>|</span><a href="#36753203">next</a><span>|</span><label class="collapse" for="c-36753073">[-]</label><label class="expand" for="c-36753073">[1 more]</label></div><br/><div class="children"><div class="content">We have folks playing around with it mostly through the playground &#x2F; raw HTTP endpoints as opposed to the Python API. And we&#x27;ve got some batch jobs running, which adds further traffic.</div><br/></div></div></div></div></div></div><div id="36753203" class="c"><input type="checkbox" id="c-36753203" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36752369">parent</a><span>|</span><a href="#36752420">prev</a><span>|</span><a href="#36753155">next</a><span>|</span><label class="collapse" for="c-36753203">[-]</label><label class="expand" for="c-36753203">[8 more]</label></div><br/><div class="children"><div class="content">guidance is a dead project. it worked well as a hobby side project by MS researchers, but it clearly isn&#x27;t a long-term solution as new LLMs are introduced.</div><br/><div id="36754214" class="c"><input type="checkbox" id="c-36754214" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36753203">parent</a><span>|</span><a href="#36754201">next</a><span>|</span><label class="collapse" for="c-36754214">[-]</label><label class="expand" for="c-36754214">[5 more]</label></div><br/><div class="children"><div class="content">Would you be able and willing to provide a bit more supporting evidence for this statement? We’ve been considering trialing guidance for a few weeks but won’t bother if it’s going nowhere.</div><br/><div id="36755220" class="c"><input type="checkbox" id="c-36755220" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36754214">parent</a><span>|</span><a href="#36754382">next</a><span>|</span><label class="collapse" for="c-36755220">[-]</label><label class="expand" for="c-36755220">[2 more]</label></div><br/><div class="children"><div class="content">If it helps I tried using it and the basic examples just straight up didn&#x27;t work at all and regularly got broken in different ways. Even if it&#x27;s going somewhere it was unusable for a serious project. I moved to custom code and left it on the &quot;watch this project&quot; list for the future.</div><br/></div></div><div id="36754382" class="c"><input type="checkbox" id="c-36754382" checked=""/><div class="controls bullet"><span class="by">nestorD</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36754214">parent</a><span>|</span><a href="#36755220">prev</a><span>|</span><a href="#36754201">next</a><span>|</span><label class="collapse" for="c-36754382">[-]</label><label class="expand" for="c-36754382">[2 more]</label></div><br/><div class="children"><div class="content">I am unclear on the status of the project but here is the conversation that seem to be tracking it: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance&#x2F;discussions&#x2F;201">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance&#x2F;discussions&#x2F;201</a></div><br/><div id="36754719" class="c"><input type="checkbox" id="c-36754719" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36754382">parent</a><span>|</span><a href="#36754201">next</a><span>|</span><label class="collapse" for="c-36754719">[-]</label><label class="expand" for="c-36754719">[1 more]</label></div><br/><div class="children"><div class="content">Okay interesting, thanks.  There does seem to be some recent activity on the `pythonic` branch but yeah, it does look like the open issues have been going ignored for a while now.</div><br/></div></div></div></div></div></div><div id="36754201" class="c"><input type="checkbox" id="c-36754201" checked=""/><div class="controls bullet"><span class="by">amkkma</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36753203">parent</a><span>|</span><a href="#36754214">prev</a><span>|</span><a href="#36753155">next</a><span>|</span><label class="collapse" for="c-36754201">[-]</label><label class="expand" for="c-36754201">[2 more]</label></div><br/><div class="children"><div class="content">What about LMQL?</div><br/><div id="36754350" class="c"><input type="checkbox" id="c-36754350" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752369">root</a><span>|</span><a href="#36754201">parent</a><span>|</span><a href="#36753155">next</a><span>|</span><label class="collapse" for="c-36754350">[-]</label><label class="expand" for="c-36754350">[1 more]</label></div><br/><div class="children"><div class="content">I hadn&#x27;t heard of LMQL before - have you tried building with it and, if so, would you be willing to share your experience?</div><br/></div></div></div></div></div></div></div></div><div id="36753155" class="c"><input type="checkbox" id="c-36753155" checked=""/><div class="controls bullet"><span class="by">roseway4</span><span>|</span><a href="#36752369">prev</a><span>|</span><a href="#36754222">next</a><span>|</span><label class="collapse" for="c-36753155">[-]</label><label class="expand" for="c-36753155">[4 more]</label></div><br/><div class="children"><div class="content">Looking at the playground, it appears the few shot examples in the prompt and CFG are duplicative. What is the relationship between the two?<p>When you say in another comment that using OpenAI functions to output JSON is a waste of tokens, how are you generating the JSON output? And why do your prompts then include few shot examples of JSON objects?</div><br/><div id="36753254" class="c"><input type="checkbox" id="c-36753254" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36753155">parent</a><span>|</span><a href="#36754222">next</a><span>|</span><label class="collapse" for="c-36753254">[-]</label><label class="expand" for="c-36753254">[3 more]</label></div><br/><div class="children"><div class="content">The prompt is given to our model as a guiding aid (a suggestion), and the cfg is used to constrain the model to generate only tokens that abide by the schema (an enforcement). That&#x27;s how we ensure only valid outputs at text generation time.<p>We also prefill some tokens depending on the set of allowed tokens at a given state, so the model doesn&#x27;t waste resources trying to predict them.</div><br/><div id="36753423" class="c"><input type="checkbox" id="c-36753423" checked=""/><div class="controls bullet"><span class="by">roseway4</span><span>|</span><a href="#36753155">root</a><span>|</span><a href="#36753254">parent</a><span>|</span><a href="#36754222">next</a><span>|</span><label class="collapse" for="c-36753423">[-]</label><label class="expand" for="c-36753423">[2 more]</label></div><br/><div class="children"><div class="content">When you say “our model”, are you using a custom LLM for completions vs OpenAI or other LLM vendor?</div><br/><div id="36753547" class="c"><input type="checkbox" id="c-36753547" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36753155">root</a><span>|</span><a href="#36753423">parent</a><span>|</span><a href="#36754222">next</a><span>|</span><label class="collapse" for="c-36753547">[-]</label><label class="expand" for="c-36753547">[1 more]</label></div><br/><div class="children"><div class="content">Custom LLM—hence the self-hostability.</div><br/></div></div></div></div></div></div></div></div><div id="36754222" class="c"><input type="checkbox" id="c-36754222" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#36753155">prev</a><span>|</span><a href="#36753551">next</a><span>|</span><label class="collapse" for="c-36754222">[-]</label><label class="expand" for="c-36754222">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget to put a license on your repository.</div><br/><div id="36754259" class="c"><input type="checkbox" id="c-36754259" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36754222">parent</a><span>|</span><a href="#36753551">next</a><span>|</span><label class="collapse" for="c-36754259">[-]</label><label class="expand" for="c-36754259">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the reminder—done!</div><br/></div></div></div></div><div id="36753551" class="c"><input type="checkbox" id="c-36753551" checked=""/><div class="controls bullet"><span class="by">easygenes</span><span>|</span><a href="#36754222">prev</a><span>|</span><a href="#36752851">next</a><span>|</span><label class="collapse" for="c-36753551">[-]</label><label class="expand" for="c-36753551">[2 more]</label></div><br/><div class="children"><div class="content">You mention self hosting the model. Do you have the model weights up on HuggingFace?</div><br/><div id="36753634" class="c"><input type="checkbox" id="c-36753634" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36753551">parent</a><span>|</span><a href="#36752851">next</a><span>|</span><label class="collapse" for="c-36753634">[-]</label><label class="expand" for="c-36753634">[1 more]</label></div><br/><div class="children"><div class="content">This is model agnostic, actually—any model on HuggingFace is compatible. So if someone wanted to run this with their own model, they could.</div><br/></div></div></div></div><div id="36752851" class="c"><input type="checkbox" id="c-36752851" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36753551">prev</a><span>|</span><a href="#36750084">next</a><span>|</span><label class="collapse" for="c-36752851">[-]</label><label class="expand" for="c-36752851">[9 more]</label></div><br/><div class="children"><div class="content">Could you contextualise this against OpenAI’s native functions?</div><br/><div id="36752991" class="c"><input type="checkbox" id="c-36752991" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752851">parent</a><span>|</span><a href="#36750084">next</a><span>|</span><label class="collapse" for="c-36752991">[-]</label><label class="expand" for="c-36752991">[8 more]</label></div><br/><div class="children"><div class="content">Problems with OpenAI:<p>1) You&#x27;re wasting GPT tokens on outputting JSON instead of meaningful information.<p>2) GPT functions won&#x27;t, with absolute, 100% certainty, return JSON in the schema you want. In 1% to 3% of cases it hallucinates fields, etc.<p>3) This also allows you to output data in arbitrary non-JSON formats.<p>4) You can&#x27;t self-host OpenAI functions.</div><br/><div id="36753170" class="c"><input type="checkbox" id="c-36753170" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36752991">parent</a><span>|</span><a href="#36750084">next</a><span>|</span><label class="collapse" for="c-36753170">[-]</label><label class="expand" for="c-36753170">[7 more]</label></div><br/><div class="children"><div class="content">Thanks, all good points that would seem to make this library a good fit for certain use-cases.<p>As with the other poster, I’d be interested to hear a bit more about point 1.</div><br/><div id="36753284" class="c"><input type="checkbox" id="c-36753284" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36753170">parent</a><span>|</span><a href="#36753268">next</a><span>|</span><label class="collapse" for="c-36753284">[-]</label><label class="expand" for="c-36753284">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36753254">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36753254</a><p>Does this help clarify?</div><br/><div id="36754295" class="c"><input type="checkbox" id="c-36754295" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36753284">parent</a><span>|</span><a href="#36753268">next</a><span>|</span><label class="collapse" for="c-36754295">[-]</label><label class="expand" for="c-36754295">[3 more]</label></div><br/><div class="children"><div class="content">Got it, thanks.  Certainly a very interesting and active space.  I was playing around with FLARE (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.06983" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.06983</a>) for RAG this week, and LMQL (mentioned by another poster) seems to use a similar technique.</div><br/><div id="36754368" class="c"><input type="checkbox" id="c-36754368" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36754295">parent</a><span>|</span><a href="#36754333">next</a><span>|</span><label class="collapse" for="c-36754368">[-]</label><label class="expand" for="c-36754368">[1 more]</label></div><br/><div class="children"><div class="content">In response to your sister comment: the implementation we used was the naive one from LangChain (<a href="https:&#x2F;&#x2F;python.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;additional&#x2F;flare" rel="nofollow noreferrer">https:&#x2F;&#x2F;python.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;additional&#x2F;...</a>).  We&#x27;ve decomposed that to use as a starting point but early results are promising, yes, although it doesn&#x27;t yet seem to be possible to get the necessary `logprobs` out of the GPT-4 API, so we&#x27;re stuck with 3.5-turbo atm.</div><br/></div></div><div id="36754333" class="c"><input type="checkbox" id="c-36754333" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36754295">parent</a><span>|</span><a href="#36754368">prev</a><span>|</span><a href="#36753268">next</a><span>|</span><label class="collapse" for="c-36754333">[-]</label><label class="expand" for="c-36754333">[1 more]</label></div><br/><div class="children"><div class="content">Ahh, I&#x27;ve been meaning to try FLARE—was it a marked improvement over traditional RAG?</div><br/></div></div></div></div></div></div><div id="36753268" class="c"><input type="checkbox" id="c-36753268" checked=""/><div class="controls bullet"><span class="by">jacky2wong</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36753170">parent</a><span>|</span><a href="#36753284">prev</a><span>|</span><a href="#36750084">next</a><span>|</span><label class="collapse" for="c-36753268">[-]</label><label class="expand" for="c-36753268">[2 more]</label></div><br/><div class="children"><div class="content">Point 1 doesn&#x27;t feel like a good enough reason. The number of tokens outputted as a JSON is so small if you tell GPT to output it properly.</div><br/><div id="36753292" class="c"><input type="checkbox" id="c-36753292" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36752851">root</a><span>|</span><a href="#36753268">parent</a><span>|</span><a href="#36750084">next</a><span>|</span><label class="collapse" for="c-36753292">[-]</label><label class="expand" for="c-36753292">[1 more]</label></div><br/><div class="children"><div class="content">Costs add up surprisingly quickly. A quote-colon-space-quote combo alone is four tokens wasted. Now scale that up....</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36751839" class="c"><input type="checkbox" id="c-36751839" checked=""/><div class="controls bullet"><span class="by">beefnugs</span><span>|</span><a href="#36750084">prev</a><span>|</span><label class="collapse" for="c-36751839">[-]</label><label class="expand" for="c-36751839">[2 more]</label></div><br/><div class="children"><div class="content">oh its 100% predictable alright, predictable to be garbage : the default example chooses height as the wrong &quot;number&quot; whatever that might assume to be, then if you try to change it to define height as perhaps &quot;height in total inches&quot; it still gets it wrong</div><br/><div id="36752333" class="c"><input type="checkbox" id="c-36752333" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#36751839">parent</a><span>|</span><label class="collapse" for="c-36752333">[-]</label><label class="expand" for="c-36752333">[1 more]</label></div><br/><div class="children"><div class="content">Ahh, that—due to compute limitations we&#x27;re forced to run a very small model that isn&#x27;t as capable of converting 5&#x27;8&quot; to inches. The larger model is, though.</div><br/></div></div></div></div></div></div></div></div></div></body></html>