<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1719565266066" as="style"/><link rel="stylesheet" href="styles.css?v=1719565266066"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://imbue.com/research/70b-infrastructure/">Infrastructure set-up &amp; open-source scripts to train a 70B model from bare metal</a> <span class="domain">(<a href="https://imbue.com">imbue.com</a>)</span></div><div class="subtext"><span>thejash</span> | <span>13 comments</span></div><br/><div><div id="40816159" class="c"><input type="checkbox" id="c-40816159" checked=""/><div class="controls bullet"><span class="by">thejash</span><span>|</span><a href="#40817990">next</a><span>|</span><label class="collapse" for="c-40816159">[-]</label><label class="expand" for="c-40816159">[3 more]</label></div><br/><div class="children"><div class="content">In the span of a few months, with a small team of researchers and engineers, we trained a 70B parameter model from scratch on our own infrastructure that outperformed zero-shot GPT-4o on reasoning-related tasks. Using our cluster for high performance training meant that every component — InfiniBand, Ethernet, GPUs, and the nodes themselves — had to work perfectly. If even a single one of the over 12,000 connections was a little flaky, it could slow down the entire training run.<p>We&#x27;re sharing open-source scripts and an end-to-end guide for infrastructure set-up that details the process of making everything work perfectly, and ensuring that it stays that way.<p>This is one of a three-part toolkit on training a 70b model from scratch. The other two sections focus on evaluations and CARBS, our hyperparameter optimizer; you can find them here: <a href="https:&#x2F;&#x2F;imbue.com&#x2F;research&#x2F;70b-intro&#x2F;" rel="nofollow">https:&#x2F;&#x2F;imbue.com&#x2F;research&#x2F;70b-intro&#x2F;</a><p>Thoughts and questions welcome! :)</div><br/><div id="40818501" class="c"><input type="checkbox" id="c-40818501" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#40816159">parent</a><span>|</span><a href="#40818606">next</a><span>|</span><label class="collapse" for="c-40818501">[-]</label><label class="expand" for="c-40818501">[1 more]</label></div><br/><div class="children"><div class="content">What happened to the Minecraft-like 3d world your team built? Did you guys pivot?</div><br/></div></div><div id="40818606" class="c"><input type="checkbox" id="c-40818606" checked=""/><div class="controls bullet"><span class="by">Flumio</span><span>|</span><a href="#40816159">parent</a><span>|</span><a href="#40818501">prev</a><span>|</span><a href="#40817990">next</a><span>|</span><label class="collapse" for="c-40818606">[-]</label><label class="expand" for="c-40818606">[1 more]</label></div><br/><div class="children"><div class="content">Nice. Tx for the write up</div><br/></div></div></div></div><div id="40817990" class="c"><input type="checkbox" id="c-40817990" checked=""/><div class="controls bullet"><span class="by">john2x</span><span>|</span><a href="#40816159">prev</a><span>|</span><a href="#40818372">next</a><span>|</span><label class="collapse" for="c-40817990">[-]</label><label class="expand" for="c-40817990">[7 more]</label></div><br/><div class="children"><div class="content">once the model is trained, what happens to the hardware and infrastructure?</div><br/><div id="40818534" class="c"><input type="checkbox" id="c-40818534" checked=""/><div class="controls bullet"><span class="by">trashtester</span><span>|</span><a href="#40817990">parent</a><span>|</span><a href="#40818079">next</a><span>|</span><label class="collapse" for="c-40818534">[-]</label><label class="expand" for="c-40818534">[1 more]</label></div><br/><div class="children"><div class="content">Voltage Park is a cloud provider. This is no different from renting barebone infra from AWS, GCP or Azure.<p>Except Voltage Park, being smaller, is probably more willing to provide some customized setup.<p>Indeed, they may even see it as a learning opportunity for when they rent similar setups to other customers.</div><br/></div></div><div id="40818079" class="c"><input type="checkbox" id="c-40818079" checked=""/><div class="controls bullet"><span class="by">pvg</span><span>|</span><a href="#40817990">parent</a><span>|</span><a href="#40818534">prev</a><span>|</span><a href="#40818247">next</a><span>|</span><label class="collapse" for="c-40818079">[-]</label><label class="expand" for="c-40818079">[4 more]</label></div><br/><div class="children"><div class="content">It probably isn&#x27;t the answer but should be - LAN party.</div><br/><div id="40818102" class="c"><input type="checkbox" id="c-40818102" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#40817990">root</a><span>|</span><a href="#40818079">parent</a><span>|</span><a href="#40818247">next</a><span>|</span><label class="collapse" for="c-40818102">[-]</label><label class="expand" for="c-40818102">[3 more]</label></div><br/><div class="children"><div class="content">GPUs will be reused for mining Monero and exfiltrate money to the founders at the expense of the investors.<p>Oops, don&#x27;t tell I told you.<p>EDIT: Sorry Dogecoin, thanks to the tip!</div><br/><div id="40818356" class="c"><input type="checkbox" id="c-40818356" checked=""/><div class="controls bullet"><span class="by">BetaDeltaAlpha</span><span>|</span><a href="#40817990">root</a><span>|</span><a href="#40818102">parent</a><span>|</span><a href="#40818232">next</a><span>|</span><label class="collapse" for="c-40818356">[-]</label><label class="expand" for="c-40818356">[1 more]</label></div><br/><div class="children"><div class="content">Monero uses a CPU-optimized consensus algorithm. Dogecoin is a better bet.</div><br/></div></div><div id="40818232" class="c"><input type="checkbox" id="c-40818232" checked=""/><div class="controls bullet"><span class="by">surfingdino</span><span>|</span><a href="#40817990">root</a><span>|</span><a href="#40818102">parent</a><span>|</span><a href="#40818356">prev</a><span>|</span><a href="#40818247">next</a><span>|</span><label class="collapse" for="c-40818232">[-]</label><label class="expand" for="c-40818232">[1 more]</label></div><br/><div class="children"><div class="content">Are you suggesting training models is a cover for mining crypto? The hardware is dual-purpose...</div><br/></div></div></div></div></div></div><div id="40818247" class="c"><input type="checkbox" id="c-40818247" checked=""/><div class="controls bullet"><span class="by">gostsamo</span><span>|</span><a href="#40817990">parent</a><span>|</span><a href="#40818079">prev</a><span>|</span><a href="#40818372">next</a><span>|</span><label class="collapse" for="c-40818247">[-]</label><label class="expand" for="c-40818247">[1 more]</label></div><br/><div class="children"><div class="content">Either training the next model or inference for the already trained one. In some cases, you might even offer it as a service.</div><br/></div></div></div></div><div id="40818372" class="c"><input type="checkbox" id="c-40818372" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40817990">prev</a><span>|</span><a href="#40818007">next</a><span>|</span><label class="collapse" for="c-40818372">[-]</label><label class="expand" for="c-40818372">[1 more]</label></div><br/><div class="children"><div class="content">This is hella cool. Cisco has a new nvidia collab with 800G per-port. I don’t recall if it was RoCE or not. The infiniband is accessible by the GPUs here? Beautiful.<p>Thank you for sharing all this. One of the more directly useful posts.</div><br/></div></div></div></div></div></div></div></body></html>