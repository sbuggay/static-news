<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698051664920" as="style"/><link rel="stylesheet" href="styles.css?v=1698051664920"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://signoz.io/blog/maximizing-scalability-apache-kafka-and-opentelemetry/">OpenTelemetry at Scale: Using Kafka to handle bursty traffic</a>Â <span class="domain">(<a href="https://signoz.io">signoz.io</a>)</span></div><div class="subtext"><span>pranay01</span> | <span>42 comments</span></div><br/><div><div id="37980236" class="c"><input type="checkbox" id="c-37980236" checked=""/><div class="controls bullet"><span class="by">blinded</span><span>|</span><a href="#37979462">next</a><span>|</span><label class="collapse" for="c-37980236">[-]</label><label class="expand" for="c-37980236">[3 more]</label></div><br/><div class="children"><div class="content">This arch is how the big players do it at scale (ie. datadog, new relic - the second it passes their edge it lands in a kafka cluster). Also otel components lack rate limiting(1) meaning its super easy to overload your backend storage (s3).<p>Grafana has some posts how they softened the s3 blow with memcached(2,3).<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-collector-contrib&#x2F;issues&#x2F;6908">https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-collector-co...</a>
2. <a href="https:&#x2F;&#x2F;grafana.com&#x2F;docs&#x2F;loki&#x2F;latest&#x2F;operations&#x2F;caching&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;grafana.com&#x2F;docs&#x2F;loki&#x2F;latest&#x2F;operations&#x2F;caching&#x2F;</a>
3. <a href="https:&#x2F;&#x2F;grafana.com&#x2F;blog&#x2F;2023&#x2F;08&#x2F;23&#x2F;how-we-scaled-grafana-cloud-logs-memcached-cluster-to-50tb-and-improved-reliability&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;grafana.com&#x2F;blog&#x2F;2023&#x2F;08&#x2F;23&#x2F;how-we-scaled-grafana-cl...</a><p>I know the post is about telemetry data and my comments on grafana are logs, but the arch bits still apply.</div><br/><div id="37982093" class="c"><input type="checkbox" id="c-37982093" checked=""/><div class="controls bullet"><span class="by">wardb</span><span>|</span><a href="#37980236">parent</a><span>|</span><a href="#37981908">next</a><span>|</span><label class="collapse" for="c-37982093">[-]</label><label class="expand" for="c-37982093">[1 more]</label></div><br/><div class="children"><div class="content">Grafana Labs employee here =&gt; On the linked articles: I&#x27;m not aware of any caching being used in the writing data to S3 part of the pipeline other then some time based&#x2F;volume based buffering at the ingester microservices before writing the chunks of data to object storage.<p>The linked Loki caching docs&#x2F;articles are for optimising the read access patterns of S3&#x2F;object storage, not for writes.</div><br/></div></div><div id="37981908" class="c"><input type="checkbox" id="c-37981908" checked=""/><div class="controls bullet"><span class="by">ankitnayan</span><span>|</span><a href="#37980236">parent</a><span>|</span><a href="#37982093">prev</a><span>|</span><a href="#37979462">next</a><span>|</span><label class="collapse" for="c-37981908">[-]</label><label class="expand" for="c-37981908">[1 more]</label></div><br/><div class="children"><div class="content">Caching is to improve read performance whereas Kafka is used to handle ingest volume. I couldn&#x27;t correlate the Grafana articles shared</div><br/></div></div></div></div><div id="37979462" class="c"><input type="checkbox" id="c-37979462" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37980236">prev</a><span>|</span><a href="#37980462">next</a><span>|</span><label class="collapse" for="c-37979462">[-]</label><label class="expand" for="c-37979462">[19 more]</label></div><br/><div class="children"><div class="content">I heard several times that Kafka was put in front of elasticsearch clusters for handling traffic burst. You can also use Redpanda, Pulsar, NATS and other distributed queues.<p>One thing that is also very interesting with Kafka is that you can achieve exactly-once semantic without too much efforts: by keeping track of the positions of partitions in your own database and carefully acknowledging them when you are sure data is safely stored in your db. That&#x27;s what we did with our engine Quickwit, so far it&#x27;s the most efficient way to index data in it.<p>One obvious drawback with Kafka is that it&#x27;s one more piece to maintain... and it&#x27;s not a small one.</div><br/><div id="37981934" class="c"><input type="checkbox" id="c-37981934" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37981867">next</a><span>|</span><label class="collapse" for="c-37981934">[-]</label><label class="expand" for="c-37981934">[10 more]</label></div><br/><div class="children"><div class="content">&gt; exactly-once semantic without too much efforts: by keeping track of the positions of partitions in your own database and carefully acknowledging them when you are sure data is safely stored in your db<p>That&#x27;s not really &quot;exactly once&quot;. What happens when your system dies after it made sure the data is safely stored in the db and before ack-ing?</div><br/><div id="37981996" class="c"><input type="checkbox" id="c-37981996" checked=""/><div class="controls bullet"><span class="by">Svenskunganka</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981934">parent</a><span>|</span><a href="#37981867">next</a><span>|</span><label class="collapse" for="c-37981996">[-]</label><label class="expand" for="c-37981996">[9 more]</label></div><br/><div class="children"><div class="content">Depending on how you use the database it is. If you write the data as well as the offset to the DB in the same transaction, you can then seek to the offset stored in the DB after application restart and continue from there.</div><br/><div id="37982045" class="c"><input type="checkbox" id="c-37982045" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981996">parent</a><span>|</span><a href="#37982031">next</a><span>|</span><label class="collapse" for="c-37982045">[-]</label><label class="expand" for="c-37982045">[5 more]</label></div><br/><div class="children"><div class="content">You should drop &quot;(...) and carefully acknowledging them when you are sure data is safely stored in your db (...)&quot; part then, because it means it&#x27;s not necessary, you don&#x27;t rely on it.<p>One-or-more semantics + local deduplication gives one-and-only semantics.<p>In this case you&#x27;re optimising local deduplication with strictly monotonic index.<p>One downside is that you leak internals of other system (partitions).<p>The other is that it implies serialised processing - you can&#x27;t process anything in parallel as you have single index threshold that defines what has been and what has yet not been processed.</div><br/><div id="37983182" class="c"><input type="checkbox" id="c-37983182" checked=""/><div class="controls bullet"><span class="by">fulmicoton</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37982045">parent</a><span>|</span><a href="#37982258">next</a><span>|</span><label class="collapse" for="c-37983182">[-]</label><label class="expand" for="c-37983182">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The other is that it implies serialised processing - you can&#x27;t process anything &gt; in parallel as you have single index threshold that defines what has been and &gt; what has yet not been processed.<p>Fortunately Kafka is partitioned. You cannot work in parallel along partitions.<p>Also, you can streamline your process.
If you are running your data through operation (A, B, C).
(C on batch N) can run at the same time as (B on batch N+1), and (A on batch N+2)<p>We do both at quickwit.</div><br/></div></div><div id="37982258" class="c"><input type="checkbox" id="c-37982258" checked=""/><div class="controls bullet"><span class="by">Svenskunganka</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37982045">parent</a><span>|</span><a href="#37983182">prev</a><span>|</span><a href="#37982344">next</a><span>|</span><label class="collapse" for="c-37982258">[-]</label><label class="expand" for="c-37982258">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the one who wrote the original comment, so I can&#x27;t modify it. But one should still commit offsets because it is the happy-path; DB transaction successful? Commit offset. If the latter fails due to e.g application crash and you seek at startup to the partition offset stored in the DB + 1, you get exactly-once semantics. There&#x27;s some more details, e.g you&#x27;d have to do the same during consumer group rebalance, and topic configuration also plays a role, for example if the topic is a compacted topic or not, and if you write tombstones, what its retention policy is.<p>edit: You added some more to your comment after I posted this one, so I&#x27;ll try to cover them as well:<p>&gt; One downside is that you leak internals of other system (partitions).<p>Yeah, sure.<p>&gt; The other is that it implies serialised processing - you can&#x27;t process anything in parallel as you have single index threshold that defines what has been and what has yet not been processed.<p>It doesn&#x27;t imply serialised processing. It depends on the use-case, if each record in a topic has to be processed serially, you can&#x27;t parallelize full-stop; number of partitions equals 1. But if each record can be individually processed you get parallelism equal to the number of partitions the topic has configured.
You also achieve parallelism in the same way if only some records in a topic needs to be processed serially, at which point you can use the same key for the records needing to be serially processed and they will end up in the same partition, for example recording the coordinates of a plane - each plane can be processed in parallel, but an individual plane&#x27;s coordinates need to be processed serially - just use the planes unique identifier as key and the coordinates for the same plane will be appended to the log of the same partition.</div><br/><div id="37982487" class="c"><input type="checkbox" id="c-37982487" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37982258">parent</a><span>|</span><a href="#37982344">next</a><span>|</span><label class="collapse" for="c-37982487">[-]</label><label class="expand" for="c-37982487">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s good option but it requires serialised processing in partition scope, which may or may not be desirable.<p>If one-and-only-one semantics are needed and processing should be parallel, other methods have to be used.</div><br/></div></div></div></div><div id="37982344" class="c"><input type="checkbox" id="c-37982344" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37982045">parent</a><span>|</span><a href="#37982258">prev</a><span>|</span><a href="#37982031">next</a><span>|</span><label class="collapse" for="c-37982344">[-]</label><label class="expand" for="c-37982344">[1 more]</label></div><br/><div class="children"><div class="content">Good point: first you&#x27;re right, we do the ack on Kafka but it&#x27;s not necessary. 
Second, this is not what I wanted to stress... and I should have not used the verb &quot;acknowledge&quot;. What we do is upload the data on S3, then we commit partitions + positions in what we call the metastore. I can&#x27;t edit my comment unfortunately.<p>&gt; One downside is that you leak internals of other system (partitions).<p>True, but we generalized the concept of partitions for other datasources, pretty convenient to use it for distributing indexing tasks.</div><br/></div></div></div></div><div id="37982031" class="c"><input type="checkbox" id="c-37982031" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981996">parent</a><span>|</span><a href="#37982045">prev</a><span>|</span><a href="#37982026">next</a><span>|</span><label class="collapse" for="c-37982031">[-]</label><label class="expand" for="c-37982031">[2 more]</label></div><br/><div class="children"><div class="content">&gt; after application restart and continue from there.<p>What if the application doesn&#x27;t restart before the queue decides the message was lost and resends?</div><br/><div id="37982225" class="c"><input type="checkbox" id="c-37982225" checked=""/><div class="controls bullet"><span class="by">hashhar</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37982031">parent</a><span>|</span><a href="#37982026">next</a><span>|</span><label class="collapse" for="c-37982225">[-]</label><label class="expand" for="c-37982225">[1 more]</label></div><br/><div class="children"><div class="content">In Kafka the &quot;queue&quot; is dumb, it doesn&#x27;t lose messages (it&#x27;s an append only durable log) nor does it resend anything unless the consumer requests it.</div><br/></div></div></div></div></div></div></div></div><div id="37981867" class="c"><input type="checkbox" id="c-37981867" checked=""/><div class="controls bullet"><span class="by">richieartoul</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37981934">prev</a><span>|</span><a href="#37981690">next</a><span>|</span><label class="collapse" for="c-37981867">[-]</label><label class="expand" for="c-37981867">[2 more]</label></div><br/><div class="children"><div class="content">You have to do a bit more than that if you want exactly once end-to-end (I.E if Kafka itself can contain duplicates). One of my former colleagues did a good write up on how Husky does it: <a href="https:&#x2F;&#x2F;www.datadoghq.com&#x2F;blog&#x2F;engineering&#x2F;husky-deep-dive&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.datadoghq.com&#x2F;blog&#x2F;engineering&#x2F;husky-deep-dive&#x2F;</a></div><br/><div id="37982414" class="c"><input type="checkbox" id="c-37982414" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981867">parent</a><span>|</span><a href="#37981690">next</a><span>|</span><label class="collapse" for="c-37982414">[-]</label><label class="expand" for="c-37982414">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I was only talking about exactly once semantic between Kafka and Quickwit.</div><br/></div></div></div></div><div id="37981690" class="c"><input type="checkbox" id="c-37981690" checked=""/><div class="controls bullet"><span class="by">pranay01</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37981867">prev</a><span>|</span><a href="#37982122">next</a><span>|</span><label class="collapse" for="c-37981690">[-]</label><label class="expand" for="c-37981690">[2 more]</label></div><br/><div class="children"><div class="content">Have you done&#x2F;seen any benchmarks between Redpanda&#x2F;NATS and Kafka for this use case?<p>Some folks in SigNoz community have also suggested NATS for this, but I have not deep dived into benchmarks&#x2F;features yet</div><br/><div id="37982372" class="c"><input type="checkbox" id="c-37982372" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981690">parent</a><span>|</span><a href="#37982122">next</a><span>|</span><label class="collapse" for="c-37982372">[-]</label><label class="expand" for="c-37982372">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately no :&#x2F;</div><br/></div></div></div></div><div id="37982122" class="c"><input type="checkbox" id="c-37982122" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37981690">prev</a><span>|</span><a href="#37981746">next</a><span>|</span><label class="collapse" for="c-37982122">[-]</label><label class="expand" for="c-37982122">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t exactly once delivery the kind of problem like the CAP thereom where it&#x27;s not possible?<p>You can make the downstream idemptoent wrt what the queue is delivering, but the queue might still redeliver things.</div><br/></div></div><div id="37981746" class="c"><input type="checkbox" id="c-37981746" checked=""/><div class="controls bullet"><span class="by">radicality</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37982122">prev</a><span>|</span><a href="#37982164">next</a><span>|</span><label class="collapse" for="c-37981746">[-]</label><label class="expand" for="c-37981746">[2 more]</label></div><br/><div class="children"><div class="content">Exactly-once semantics of what specifically? Or do you mean at-least-once ?</div><br/><div id="37982386" class="c"><input type="checkbox" id="c-37982386" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37979462">root</a><span>|</span><a href="#37981746">parent</a><span>|</span><a href="#37982164">next</a><span>|</span><label class="collapse" for="c-37982386">[-]</label><label class="expand" for="c-37982386">[1 more]</label></div><br/><div class="children"><div class="content">Exactly-once semantic between Kafka and the observability engine.</div><br/></div></div></div></div><div id="37982164" class="c"><input type="checkbox" id="c-37982164" checked=""/><div class="controls bullet"><span class="by">ankitnayan</span><span>|</span><a href="#37979462">parent</a><span>|</span><a href="#37981746">prev</a><span>|</span><a href="#37980462">next</a><span>|</span><label class="collapse" for="c-37982164">[-]</label><label class="expand" for="c-37982164">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.confluent.io&#x2F;blog&#x2F;exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.confluent.io&#x2F;blog&#x2F;exactly-once-semantics-are-pos...</a></div><br/></div></div></div></div><div id="37980462" class="c"><input type="checkbox" id="c-37980462" checked=""/><div class="controls bullet"><span class="by">chris_armstrong</span><span>|</span><a href="#37979462">prev</a><span>|</span><a href="#37979488">next</a><span>|</span><label class="collapse" for="c-37980462">[-]</label><label class="expand" for="c-37980462">[1 more]</label></div><br/><div class="children"><div class="content">A similar idea [^1] has cropped up in the serverless OpenTelemetry world to collate OpenTelemetry spans in a Kinesis stream before forwarding them to a third-party service for analysis, obviating the need for a separate collector, reducing forwarding latency and removing the cold-start overhead of the AWS Distribution for OpenTelemetry Lambda Layer.<p>[^1] <a href="https:&#x2F;&#x2F;x.com&#x2F;donkersgood&#x2F;status&#x2F;1662074303456636929?s=20" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;donkersgood&#x2F;status&#x2F;1662074303456636929?s=20</a></div><br/></div></div><div id="37979488" class="c"><input type="checkbox" id="c-37979488" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#37980462">prev</a><span>|</span><a href="#37981054">next</a><span>|</span><label class="collapse" for="c-37979488">[-]</label><label class="expand" for="c-37979488">[10 more]</label></div><br/><div class="children"><div class="content">Seems like overkill no? Otel collectors are fairly cheap, why add expensive Kafka into the mix. If you need to buffer why not just dump to s3 or similar data store as a temporary storage array.</div><br/><div id="37979976" class="c"><input type="checkbox" id="c-37979976" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#37979488">parent</a><span>|</span><a href="#37981885">next</a><span>|</span><label class="collapse" for="c-37979976">[-]</label><label class="expand" for="c-37979976">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If you need to buffer why not just dump to s3 or similar data store as a temporary storage array.<p>At that point it&#x27;s very easy to sleepwalk into implementing your own database on top of s3, which is very hard to get good semantics out of - e.g. it offers essentially no ordering guarantees, and forget atomicity. For telemetry you might well be ok with fuzzy data, but if you want exact traces every time then Kafka could make sense.</div><br/><div id="37980935" class="c"><input type="checkbox" id="c-37980935" checked=""/><div class="controls bullet"><span class="by">dikei</span><span>|</span><a href="#37979488">root</a><span>|</span><a href="#37979976">parent</a><span>|</span><a href="#37982201">next</a><span>|</span><label class="collapse" for="c-37980935">[-]</label><label class="expand" for="c-37980935">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, and to use S3 efficiently you also need to batch your messages into large blobs of at least 10s of MB, which further complicates the matter, especially if you don&#x27;t want to lose those messages buffers.</div><br/><div id="37981443" class="c"><input type="checkbox" id="c-37981443" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#37979488">root</a><span>|</span><a href="#37980935">parent</a><span>|</span><a href="#37982201">next</a><span>|</span><label class="collapse" for="c-37981443">[-]</label><label class="expand" for="c-37981443">[1 more]</label></div><br/><div class="children"><div class="content">if your otel collector is being overwhelmed. In such cases you have a lot of backlogged data not able to be ingested. So you dead letter queue it to s3 for freeing up buffers.<p>The approach here is to only send data to s3 as a last ditch resort.</div><br/></div></div></div></div><div id="37982201" class="c"><input type="checkbox" id="c-37982201" checked=""/><div class="controls bullet"><span class="by">ankitnayan</span><span>|</span><a href="#37979488">root</a><span>|</span><a href="#37979976">parent</a><span>|</span><a href="#37980935">prev</a><span>|</span><a href="#37981885">next</a><span>|</span><label class="collapse" for="c-37982201">[-]</label><label class="expand" for="c-37982201">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s very hard to think s3 work as a buffer. Every datastore can work for almost all storage usecases buffer&#x2F;queue&#x2F;db when the scale is low but the latter were designed to work at scale</div><br/></div></div></div></div><div id="37981885" class="c"><input type="checkbox" id="c-37981885" checked=""/><div class="controls bullet"><span class="by">richieartoul</span><span>|</span><a href="#37979488">parent</a><span>|</span><a href="#37979976">prev</a><span>|</span><a href="#37979547">next</a><span>|</span><label class="collapse" for="c-37981885">[-]</label><label class="expand" for="c-37981885">[1 more]</label></div><br/><div class="children"><div class="content">(WarpStream founder)<p>This is more or less exactly what WarpStream is: <a href="https:&#x2F;&#x2F;www.warpstream.com&#x2F;blog&#x2F;minimizing-s3-api-costs-with-distributed-mmap" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.warpstream.com&#x2F;blog&#x2F;minimizing-s3-api-costs-with...</a><p>Kafka API, S3 costs and ease of use</div><br/></div></div><div id="37979547" class="c"><input type="checkbox" id="c-37979547" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#37979488">parent</a><span>|</span><a href="#37981885">prev</a><span>|</span><a href="#37982198">next</a><span>|</span><label class="collapse" for="c-37979547">[-]</label><label class="expand" for="c-37979547">[1 more]</label></div><br/><div class="children"><div class="content">I really like this idea. And there is an OTEL exporter to AWS S3, still in alpha but I&#x27;m gonna test it soon: <a href="https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-collector-contrib&#x2F;tree&#x2F;main&#x2F;exporter&#x2F;awss3exporter">https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-collector-co...</a></div><br/></div></div><div id="37979617" class="c"><input type="checkbox" id="c-37979617" checked=""/><div class="controls bullet"><span class="by">prpl</span><span>|</span><a href="#37979488">parent</a><span>|</span><a href="#37982198">prev</a><span>|</span><a href="#37981054">next</a><span>|</span><label class="collapse" for="c-37979617">[-]</label><label class="expand" for="c-37979617">[2 more]</label></div><br/><div class="children"><div class="content">Why not both, dump to S3 and write pointers to kafka for portable event-based ingestion (since everybody does messages a bit differently)</div><br/><div id="37979765" class="c"><input type="checkbox" id="c-37979765" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#37979488">root</a><span>|</span><a href="#37979617">parent</a><span>|</span><a href="#37981054">next</a><span>|</span><label class="collapse" for="c-37979765">[-]</label><label class="expand" for="c-37979765">[1 more]</label></div><br/><div class="children"><div class="content">No need as s3 objects is your dead letter queue and the system should be designed anyway to coupe with multiple write of same event.<p>The point is to only use s3 etc in the event of system instability. Not as a primary data transfer means.</div><br/></div></div></div></div></div></div><div id="37981054" class="c"><input type="checkbox" id="c-37981054" checked=""/><div class="controls bullet"><span class="by">nicognaw</span><span>|</span><a href="#37979488">prev</a><span>|</span><a href="#37980118">next</a><span>|</span><label class="collapse" for="c-37981054">[-]</label><label class="expand" for="c-37981054">[1 more]</label></div><br/><div class="children"><div class="content">Signoz is too good at SEO.<p>Early days, I looked up otel and observability stuff, and I always saw Signoz articles on the first screen.</div><br/></div></div><div id="37980118" class="c"><input type="checkbox" id="c-37980118" checked=""/><div class="controls bullet"><span class="by">daurnimator</span><span>|</span><a href="#37981054">prev</a><span>|</span><a href="#37981019">next</a><span>|</span><label class="collapse" for="c-37980118">[-]</label><label class="expand" for="c-37980118">[5 more]</label></div><br/><div class="children"><div class="content">I expect it would be far cheaper to scale up tempo&#x2F;loki than it would be to even run an idle kafka cluster. This feels like spending thousands of dollars to save tens of dollars.</div><br/><div id="37981849" class="c"><input type="checkbox" id="c-37981849" checked=""/><div class="controls bullet"><span class="by">pranay01</span><span>|</span><a href="#37980118">parent</a><span>|</span><a href="#37982217">next</a><span>|</span><label class="collapse" for="c-37981849">[-]</label><label class="expand" for="c-37981849">[1 more]</label></div><br/><div class="children"><div class="content">Querying in Tempo&#x2F;Loki does seem to not scale particularly well, and Loki has known issues with high cardinality data, so...</div><br/></div></div><div id="37982217" class="c"><input type="checkbox" id="c-37982217" checked=""/><div class="controls bullet"><span class="by">ankitnayan</span><span>|</span><a href="#37980118">parent</a><span>|</span><a href="#37981849">prev</a><span>|</span><a href="#37981045">next</a><span>|</span><label class="collapse" for="c-37982217">[-]</label><label class="expand" for="c-37982217">[1 more]</label></div><br/><div class="children"><div class="content">When handling surges of the order of 10x, it&#x27;s much more difficult to scale the different components of loki than to write them to Kafka&#x2F;Redpanda first and consume at a consistent rate.</div><br/></div></div><div id="37981045" class="c"><input type="checkbox" id="c-37981045" checked=""/><div class="controls bullet"><span class="by">neetle</span><span>|</span><a href="#37980118">parent</a><span>|</span><a href="#37982217">prev</a><span>|</span><a href="#37981701">next</a><span>|</span><label class="collapse" for="c-37981045">[-]</label><label class="expand" for="c-37981045">[1 more]</label></div><br/><div class="children"><div class="content">Tempo can still buckle under huge bursts of traffic, and you donât need the retention to be in the hours</div><br/></div></div></div></div><div id="37981019" class="c"><input type="checkbox" id="c-37981019" checked=""/><div class="controls bullet"><span class="by">Joel_Mckay</span><span>|</span><a href="#37980118">prev</a><span>|</span><a href="#37980258">next</a><span>|</span><label class="collapse" for="c-37981019">[-]</label><label class="expand" for="c-37981019">[1 more]</label></div><br/><div class="children"><div class="content">If you have distributed concurrent data streams that exhibit coherent temporal events, than at some point you pretty much have to implement a queuing balancer.<p>One simply trades latency for capacity and eventual coherent data locality.<p>Its almost a arbitrary detail whether you use Kafka, RabbitMQ, or Erlang channels.  If you can add smart client application-layer predictive load-balancing, than it is possible to cut burst traffic loads by a magnitude or two. Cost optimized Dynamic host scaling is not always a solution that solves every problem.<p>Good luck out there =)</div><br/></div></div></div></div></div></div></div></body></html>