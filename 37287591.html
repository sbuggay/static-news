<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693213263719" as="style"/><link rel="stylesheet" href="styles.css?v=1693213263719"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2308.10335">A study on robustness and reliability of large language model code generation</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>floridsleeves</span> | <span>183 comments</span></div><br/><div><div id="37288141" class="c"><input type="checkbox" id="c-37288141" checked=""/><div class="controls bullet"><span class="by">teraflop</span><span>|</span><a href="#37290491">next</a><span>|</span><label class="collapse" for="c-37288141">[-]</label><label class="expand" for="c-37288141">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sympathetic to the viewpoint that GPT-4 is prone to mistakes when writing code. Unfortunately, the analysis in this paper is pretty bad and doesn&#x27;t support that conclusion.<p>The authors assume that for any given method under consideration, it <i>must only</i> occur within a particular pattern of other method calls and control flow instructions. But the templates they have chosen are clearly only applicable in certain situations.<p>For example, they claim that I&#x2F;O operations are &quot;wrong&quot; unless they are wrapped in exception handlers that log any errors:<p><pre><code>    try {
        ...
    } catch (IOException e) {
        e.printStackTrace();
    }
</code></pre>
But of course, this will cause execution to continue as though the I&#x2F;O was successful, which might be exactly the wrong thing to do! In many cases, you <i>want</i> the exception to propagate, so that the caller can decide how to handle the failure. (And even if you do want to report the error somehow, writing it to stderr might not be correct; it&#x27;s pointless in a GUI app.)<p>Similarly, the authors assume that every time you create a file or directory, you always want to call .exists() first (even though doing so has an inherent race condition); that Map.get() must always be followed by an &quot;if&quot; block; that List.get() must always be guarded by an explicit bounds check; that after doing a database query, you always want to close the connection; and so on. None of those rules are universally applicable.<p>I would expect the <i>real</i> problem with LLM-generated code to be semantic bugs and &quot;misunderstandings&quot; of the requirements, which would not be caught by superficial checks like this.</div><br/><div id="37290779" class="c"><input type="checkbox" id="c-37290779" checked=""/><div class="controls bullet"><span class="by">oceanplexian</span><span>|</span><a href="#37288141">parent</a><span>|</span><a href="#37288719">next</a><span>|</span><label class="collapse" for="c-37290779">[-]</label><label class="expand" for="c-37290779">[4 more]</label></div><br/><div class="children"><div class="content">I see humans do this all the time, especially abuse of exception handling, even among “Senior” developers. They don’t have a semantic understanding of what they are doing or why they are creating a race conditions or creating perverse control flow logic N layers down in the stack.<p>The fact that researchers get it wrong is, well, unsurprising. LLMs might actually be an improvement.</div><br/><div id="37290910" class="c"><input type="checkbox" id="c-37290910" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#37288141">root</a><span>|</span><a href="#37290779">parent</a><span>|</span><a href="#37291082">next</a><span>|</span><label class="collapse" for="c-37290910">[-]</label><label class="expand" for="c-37290910">[1 more]</label></div><br/><div class="children"><div class="content">But this is because almost everyone gets taught this badly. When you ask how to do exception handling best practices etc, even from teachers&#x2F;college profs etc you get wildly different answers from every single one of them. So people either learn themselves or from colleagues or, most likely, not at all.</div><br/></div></div><div id="37291082" class="c"><input type="checkbox" id="c-37291082" checked=""/><div class="controls bullet"><span class="by">Anduia</span><span>|</span><a href="#37288141">root</a><span>|</span><a href="#37290779">parent</a><span>|</span><a href="#37290910">prev</a><span>|</span><a href="#37288719">next</a><span>|</span><label class="collapse" for="c-37291082">[-]</label><label class="expand" for="c-37291082">[2 more]</label></div><br/><div class="children"><div class="content">Hi, do you have a recommended read for those of us who might inadvertently create race conditions?</div><br/><div id="37291493" class="c"><input type="checkbox" id="c-37291493" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#37288141">root</a><span>|</span><a href="#37291082">parent</a><span>|</span><a href="#37288719">next</a><span>|</span><label class="collapse" for="c-37291493">[-]</label><label class="expand" for="c-37291493">[1 more]</label></div><br/><div class="children"><div class="content">So race conditions are simply when two processes &#x2F; threads are likely to affect a single resource.  In this case it&#x27;s a file - and the problem is test if a file exists, then if it does not, create it and then write to it.<p>If two threads do this, say a log file, the first one creates the file and logs it&#x27;s important stuff, the second then creates it again wiping out the first log data.<p>Solutions in this area include<p>- create as append file (the concept is basically deviates old because this is a decades old problem)<p>- avoid sharing resources.  for logging log to per thread locations. Not always possible but you sure as hell can minimise this to one or two resources you must share.<p>- hand off creating files to a seperate part of the application.  There is a balance between &quot;scripting&quot; and &quot;application&quot; and using small little library functions to do in one line indirectly something that also takes one line using the methods shown in the docs.<p>- handing off batons &#x2F; mutexes etc etc. This gets wildly complex. Honestly given a world of async libraries, Erlang, and distributed computing, if you find yourself having to use multi-threading think very carefully if this is the right approach.<p>Anyway, hopefully wot get horribly dinged for mistakes and poor advice here. What I am trying to say is that I too read &quot;even senior devs don&#x27;t understand the race conditions they create downstream.&quot; And I thought - oh God, don&#x27;t I.<p>But five minutes thought can help you walk through most issues.  For most applications most of the time you can reason your way through without fear, and when you do encounter gnarly problems they often can go away by redesigning your application! Often the problems you encounter you caused.  retrace your steps and find an easier path.  Save the hard thinking for genuine problems &#x2F; value creation.</div><br/></div></div></div></div></div></div><div id="37288719" class="c"><input type="checkbox" id="c-37288719" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#37288141">parent</a><span>|</span><a href="#37290779">prev</a><span>|</span><a href="#37288443">next</a><span>|</span><label class="collapse" for="c-37288719">[-]</label><label class="expand" for="c-37288719">[1 more]</label></div><br/><div class="children"><div class="content">I have only glanced at a few examples in the paper so far but I would rate some of the cases listed as being better responses from the LLM than their exemplars.<p>If you ask someone how to open a can of soda you do not want them to tell you how to check to see if the can has been shaken and what to do if it has.  You want the instructions to the question you asked.<p>If anything I would a LLM to produce code that does the fundamental operation, possibly I might like it to offer a more robust framing of the operation as an extended example but I suspect even that would get annoying after a while.<p>I absolutely would not want The most technically correct but harder to read response to a question of &quot;how do I X?&quot;</div><br/></div></div><div id="37288443" class="c"><input type="checkbox" id="c-37288443" checked=""/><div class="controls bullet"><span class="by">13yuan</span><span>|</span><a href="#37288141">parent</a><span>|</span><a href="#37288719">prev</a><span>|</span><a href="#37290144">next</a><span>|</span><label class="collapse" for="c-37288443">[-]</label><label class="expand" for="c-37288443">[2 more]</label></div><br/><div class="children"><div class="content">The paper actually explains that it targets at the API misuse problem, not the semantic alignment or bugs. Semantic bugs are difficult to detect, which is already a consensus in software engineering field and still many ongoing work on it. And when we say &#x27;semantic&#x27; in this special problem it means more than &#x27;semantic&#x27; in programs but also how developers express their semantics, which is definitely a problem bigger than checking the code itself. The API usage patterns are created to help check the code snippets given by LLMs, while the race condition you mentioned could exist but not checkable unless given other components of the programs. If adding the bugs you mentioned, the buggy code generated by LLMs could even exceed the number claimed in the paper.</div><br/><div id="37288894" class="c"><input type="checkbox" id="c-37288894" checked=""/><div class="controls bullet"><span class="by">teraflop</span><span>|</span><a href="#37288141">root</a><span>|</span><a href="#37288443">parent</a><span>|</span><a href="#37290144">next</a><span>|</span><label class="collapse" for="c-37288894">[-]</label><label class="expand" for="c-37288894">[1 more]</label></div><br/><div class="children"><div class="content">But what is &quot;misuse&quot;, then, if not something that causes a bug?<p>&quot;Misuse&quot; is not a formally defined thing in Java, and the authors never define what they mean by it.<p>&gt; If adding the bugs you mentioned, the buggy code generated by LLMs could even exceed the number claimed in the paper.<p>Or it could be much fewer. Aside from a few scarce examples, the paper gives no <i>evidence</i> that most of the patterns that were selected are actually associated with &quot;misuse&quot;. They just declare it to be so. (The 2018 paper they cite for their dataset also provides little such evidence. It just says that the authors reviewed the patterns, reviewed documentation, and decided which ones they considered to be poor code quality.)<p>It is easy to come up with valid situations where a piece of code violates those patterns, but behaves as intended and is not misusing the API. So why should I assign any meaning to the fact that some percentage of code snippets violate the patterns?<p>I could make a list of adjectives that frequently appear in comments near buggy code, and then count how many LLM outputs contain those outputs, and then say that means the LLM output is buggy. But I would not be saying anything meaningful about the LLM&#x27;s quality by doing so.</div><br/></div></div></div></div><div id="37290797" class="c"><input type="checkbox" id="c-37290797" checked=""/><div class="controls bullet"><span class="by">gonzo41</span><span>|</span><a href="#37288141">parent</a><span>|</span><a href="#37288455">prev</a><span>|</span><a href="#37290491">next</a><span>|</span><label class="collapse" for="c-37290797">[-]</label><label class="expand" for="c-37290797">[1 more]</label></div><br/><div class="children"><div class="content">If you take the point of view that LLM&#x27;s have been trained on all the code that humans write, then that sort of things is probably &#x27;correct&#x27; to the model.<p>For coding it seems like there almost needs to be a weighting to certain &#x27;correct and orthodox&#x27; handling of events if you&#x27;re going to give over control of code generation to an LLM.</div><br/></div></div></div></div><div id="37290491" class="c"><input type="checkbox" id="c-37290491" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#37288141">prev</a><span>|</span><a href="#37287858">next</a><span>|</span><label class="collapse" for="c-37290491">[-]</label><label class="expand" for="c-37290491">[15 more]</label></div><br/><div class="children"><div class="content">Is this worth reading? When authors cannot write a grammatically correct abstract I tune out. Try to make sense of this monster sentence:<p>“The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes, this http URL make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them.”</div><br/><div id="37290529" class="c"><input type="checkbox" id="c-37290529" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37290491">parent</a><span>|</span><a href="#37287858">next</a><span>|</span><label class="collapse" for="c-37290529">[-]</label><label class="expand" for="c-37290529">[14 more]</label></div><br/><div class="children"><div class="content">Bear in mind that most researchers are not native English speakers.</div><br/><div id="37290827" class="c"><input type="checkbox" id="c-37290827" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290529">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37290827">[-]</label><label class="expand" for="c-37290827">[7 more]</label></div><br/><div class="children"><div class="content">I’m confused, do you think we’re not aware of that?</div><br/><div id="37290876" class="c"><input type="checkbox" id="c-37290876" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290827">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37290876">[-]</label><label class="expand" for="c-37290876">[6 more]</label></div><br/><div class="children"><div class="content">I try to restrict my comments to addressing the content of the parent comment, rather than what my assumptions about people are.</div><br/><div id="37290908" class="c"><input type="checkbox" id="c-37290908" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290876">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37290908">[-]</label><label class="expand" for="c-37290908">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see how it added any extra information to the parent comment</div><br/><div id="37290953" class="c"><input type="checkbox" id="c-37290953" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290908">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37290953">[-]</label><label class="expand" for="c-37290953">[4 more]</label></div><br/><div class="children"><div class="content">They asked whether this paper was worth reading, because the English wasn&#x27;t conventional in their dialect.<p>I&#x27;m pointing out that that isn&#x27;t a good way to screen papers, because most English speakers don&#x27;t share the same dialect.<p>Perhaps unstated or understated is the implication that, were you to discard papers in this way, you&#x27;re liable to miss out.<p>I&#x27;ll leave it to you whether that added information. That wasn&#x27;t really my goal in this case, my goal was to respond to the question in the manner I viewed appropriate. Feel free to downvote my comment if you don&#x27;t feel it was appropriate or informative or otherwise didn&#x27;t uphold whatever criteria you&#x27;re judging it by.</div><br/><div id="37291015" class="c"><input type="checkbox" id="c-37291015" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290953">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37291015">[-]</label><label class="expand" for="c-37291015">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m pointing out that that isn&#x27;t a good way to screen papers, because most English speakers don&#x27;t share the same dialect.<p>You did not make that clear at all.<p>&gt; Perhaps unstated or understated is the implication that, were you to discard papers in this way, you&#x27;re liable to miss out.<p>Indeed, that implication was totally missing.<p>&gt; Feel free to downvote my comment if you don&#x27;t feel it was appropriate or informative or otherwise didn&#x27;t uphold whatever criteria you&#x27;re judging it by.<p>I would certainly do so. Like their paper, it is quite poor, and not helpful for this forum. Unfortunately, &#x2F;u&#x2F;dang has removed my ability to downvote.</div><br/><div id="37291018" class="c"><input type="checkbox" id="c-37291018" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37291015">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37291018">[-]</label><label class="expand" for="c-37291018">[2 more]</label></div><br/><div class="children"><div class="content">Alrighty. Thanks for the feedback. Have a great day.<p>(For what it&#x27;s worth, I often feel my comments are too long and wordy, and occasionally I&#x27;ve gotten feedback to that effect, so I was trying to be brief in my original comment.)</div><br/><div id="37291127" class="c"><input type="checkbox" id="c-37291127" checked=""/><div class="controls bullet"><span class="by">bt1a</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37291018">parent</a><span>|</span><a href="#37290565">next</a><span>|</span><label class="collapse" for="c-37291127">[-]</label><label class="expand" for="c-37291127">[1 more]</label></div><br/><div class="children"><div class="content">i understood your original comment :)<p>totally agree that dismissing the content of a paper for its grammatical mistakes alone is foolish.<p>this isn’t a paper about classic roman literature</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37290565" class="c"><input type="checkbox" id="c-37290565" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290529">parent</a><span>|</span><a href="#37290827">prev</a><span>|</span><a href="#37287858">next</a><span>|</span><label class="collapse" for="c-37290565">[-]</label><label class="expand" for="c-37290565">[6 more]</label></div><br/><div class="children"><div class="content">This argument is not really valid anymore, especially in a paper that talks about LLMs.</div><br/><div id="37290587" class="c"><input type="checkbox" id="c-37290587" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290565">parent</a><span>|</span><a href="#37291166">next</a><span>|</span><label class="collapse" for="c-37290587">[-]</label><label class="expand" for="c-37290587">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an observation, not an argument, but note that this is a paper about <i>LLM mistakes</i>. But if the language bothers you and you view LLMs as the solution, you&#x27;re certainly free to feed it into an LLM yourself.<p>To be frank, I find it a little off-putting to suggest being a non-native English speaker is &quot;no longer valid.&quot;</div><br/><div id="37291004" class="c"><input type="checkbox" id="c-37291004" checked=""/><div class="controls bullet"><span class="by">clarionbell</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290587">parent</a><span>|</span><a href="#37290639">next</a><span>|</span><label class="collapse" for="c-37291004">[-]</label><label class="expand" for="c-37291004">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a native english speaker. For serious work, that is, anything that may be printed or published with my real name on it, I use grammar checks. That&#x27;s the least I can do.</div><br/></div></div><div id="37290639" class="c"><input type="checkbox" id="c-37290639" checked=""/><div class="controls bullet"><span class="by">boxed</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290587">parent</a><span>|</span><a href="#37291004">prev</a><span>|</span><a href="#37291166">next</a><span>|</span><label class="collapse" for="c-37290639">[-]</label><label class="expand" for="c-37290639">[1 more]</label></div><br/><div class="children"><div class="content">Maybe the previous commenter meant that they could have used an LLM to translate from Mandarin to English to get a better sentence?<p>Which is... ironic I think :P</div><br/></div></div></div></div><div id="37291166" class="c"><input type="checkbox" id="c-37291166" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290565">parent</a><span>|</span><a href="#37290587">prev</a><span>|</span><a href="#37290684">next</a><span>|</span><label class="collapse" for="c-37291166">[-]</label><label class="expand" for="c-37291166">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>not really valid anymore</i><p>You have to express reasons when not evident.<p>In case, just in case (and to also show how lack of definition may trigger any weak interpretation), after suggestion from a nearby member, the idea would had been that today people could have sentences reformulated by language models: the composer <i>intends to express a logic</i>, so any translator would have to grasp said logic primarily and first.</div><br/></div></div><div id="37290684" class="c"><input type="checkbox" id="c-37290684" checked=""/><div class="controls bullet"><span class="by">barbarr</span><span>|</span><a href="#37290491">root</a><span>|</span><a href="#37290565">parent</a><span>|</span><a href="#37291166">prev</a><span>|</span><a href="#37287858">next</a><span>|</span><label class="collapse" for="c-37290684">[-]</label><label class="expand" for="c-37290684">[1 more]</label></div><br/><div class="children"><div class="content">I found it somewhat charming that the authors, who express skepticism about the use of LLMs by novices, indeed stuck to their views and decided not to run their phrasings through an LLM. This will probably be one of the dwindling number of papers released each year with &quot;fairly bad&quot; grammar - and part of me wonders if we&#x27;re losing something in the process of LLM-meditated homogenization.</div><br/></div></div></div></div></div></div></div></div><div id="37287858" class="c"><input type="checkbox" id="c-37287858" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#37290491">prev</a><span>|</span><a href="#37288013">next</a><span>|</span><label class="collapse" for="c-37287858">[-]</label><label class="expand" for="c-37287858">[21 more]</label></div><br/><div class="children"><div class="content">Ok but what are we calling API misuses?<p><pre><code>    We collect 1208 coding questions from StackOverflow on 24 representative Java APIs. We summarize thecommon misuse patterns of these APIs and evaluate them oncurrent popular LLMs. The evaluation results show that evenfor GPT-4, 62% of the generated code contains API misuses,which would cause unexpected consequences if the code isintroduced into real-world software.
</code></pre>
Should have used ChatGPT to correct those sentences. &#x2F;s<p>What do we consider an API misuse at the end of the day? And also against the Java APIs... Which are some of the oldest.<p>I&#x27;m not saying ChatGPT answers work, 50% of the time they don&#x27;t work out of the box. But overal, the time savings are incredible, compared to the fossil digging way of googling. And I value the time savings towards the equally correct way of googling for answers. You reap what you sow. The knowledge the LLM is based upon is the same stuff you used to distill manually. It shouldn&#x27;t be more or less correct, if you think of it that way.<p>Surprise, ChatGPT will not replace devs. But it is like having the electrical drill vs. screwdriver type of situation.</div><br/><div id="37288185" class="c"><input type="checkbox" id="c-37288185" checked=""/><div class="controls bullet"><span class="by">dventimi</span><span>|</span><a href="#37287858">parent</a><span>|</span><a href="#37288017">next</a><span>|</span><label class="collapse" for="c-37288185">[-]</label><label class="expand" for="c-37288185">[3 more]</label></div><br/><div class="children"><div class="content">Evidently, THEY are calling the following API misuses:<p>&quot;To evaluate the API usage correctness in code, RO-
BUSTAPI detects the API misuses against the API usage
rules by extracting call consequences and control structures
from the code snippet, as shown in Figure 2. The code
checker firstly check the code snippets to see whether it is
a snippet of a method or a method of a class, so that it can
enclose this code snippet and constructs abstract syntax tree
(AST) from the code snippet. Then the checker traverses the
AST to record all the method calls and control structures
in order, which generate a call sequence. Next, the checker
compare the call sequence against the API usage rules. It
infers the instance type of each method calls and use the
type and method as keys to retrieve corresponding API us-
age rules. Finally, the checker computes the longest common
sequence between the call sequence and the API usage rules.
If the call sequence does not match the expected API usage
rules, the checker will report API misuses.&quot;</div><br/><div id="37289471" class="c"><input type="checkbox" id="c-37289471" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288185">parent</a><span>|</span><a href="#37288017">next</a><span>|</span><label class="collapse" for="c-37289471">[-]</label><label class="expand" for="c-37289471">[2 more]</label></div><br/><div class="children"><div class="content">&quot;compare the call sequence against the API usage rules&quot;<p>The validity of this entire paper would seem to depend on how robust and agreed upon these &quot;API usage rules&quot; are.</div><br/><div id="37290361" class="c"><input type="checkbox" id="c-37290361" checked=""/><div class="controls bullet"><span class="by">dventimi</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37289471">parent</a><span>|</span><a href="#37288017">next</a><span>|</span><label class="collapse" for="c-37290361">[-]</label><label class="expand" for="c-37290361">[1 more]</label></div><br/><div class="children"><div class="content">Everything depends on something else. That&#x27;s life.</div><br/></div></div></div></div></div></div><div id="37288017" class="c"><input type="checkbox" id="c-37288017" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#37287858">parent</a><span>|</span><a href="#37288185">prev</a><span>|</span><a href="#37287882">next</a><span>|</span><label class="collapse" for="c-37288017">[-]</label><label class="expand" for="c-37288017">[9 more]</label></div><br/><div class="children"><div class="content">I just don’t see how it could save time.<p>Programmers nearly universally agree that reading code is harder than writing it.<p>So when you have chat GPT writing your code, you have to read and understand it to ensure it’s actually doing what you need it to without awkward bugs or problems.<p>Given that it’s harder to read than write code, it seems to stand to reason that the “time savings” must be nil.</div><br/><div id="37289480" class="c"><input type="checkbox" id="c-37289480" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37290465">next</a><span>|</span><label class="collapse" for="c-37289480">[-]</label><label class="expand" for="c-37289480">[2 more]</label></div><br/><div class="children"><div class="content">&quot;I just don’t see how it could save time.&quot;<p>Have you tried it much?<p>It&#x27;s saved me a ton of time over the past 8 months. I don&#x27;t know what else to say - I&#x27;m not the kind of person to deceive myself into thinking something is saving me time when it isn&#x27;t.<p>The time saved is mainly in the micro-research you no longer have to do - the bits where you have to go and look up how to write a for loop in Bash, or how to call super() in a Python class, or which exceptions you need to catch for a call to httpx.get().<p>GPT-4 writes the code right 90% of the time. The 10% of the time it doesn&#x27;t you catch in the same testing you would have done against code you had written yourself the long way.</div><br/><div id="37291156" class="c"><input type="checkbox" id="c-37291156" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37289480">parent</a><span>|</span><a href="#37290465">next</a><span>|</span><label class="collapse" for="c-37291156">[-]</label><label class="expand" for="c-37291156">[1 more]</label></div><br/><div class="children"><div class="content">I have found it to save time when I&#x27;m learning a new, widely used framework. (Presumably this would hold for a language as well.) I used it to learn Keras and React + Redux, and it was helpful there. For instance I was able to ask it about what sort of messages would be emitted by Redux taking certain actions, and the precise values were wrong but it didn&#x27;t really matter. That was very cool.<p>Once I have a good sense for how things work, I&#x27;d much rather go to the documentation. Most of the time I can do this straight from my editor by typing the method I want and querying the LSP for documentation. In those cases it&#x27;s more or less instant, there&#x27;s no improvement to be made here.<p>Maybe in some of the other cases it  would be faster via an LLM integrated with my editor, but I don&#x27;t think it would justify the cognitive load of considering whether or not it&#x27;s correct. I&#x27;d like to worry about whether the application is correct. And I don&#x27;t really think I&#x27;m wasting time waiting for the Python documentation to load, I&#x27;m continuing to chew on the problem.<p>Additionally, when I go to the documentation, I&#x27;m looking for callouts and the safety of an API, and I take the lack of such callouts as authoritative. Eg, recently I was reading that in node-postgres you have to return connections to the pool, which was a good refresher for me, because previously I&#x27;d been using Rust where resources are generally cleaned up automatically. I just don&#x27;t trust a lack of a callout from GPT-4 as being a confirmation of a lack of a safety issue.</div><br/></div></div></div></div><div id="37290465" class="c"><input type="checkbox" id="c-37290465" checked=""/><div class="controls bullet"><span class="by">Yodel0914</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37289480">prev</a><span>|</span><a href="#37290223">next</a><span>|</span><label class="collapse" for="c-37290465">[-]</label><label class="expand" for="c-37290465">[1 more]</label></div><br/><div class="children"><div class="content">It depends on your baseline. If you&#x27;re comparing it with &quot;I know how to do this already but don&#x27;t want to type&quot; I think ChatGPT is slower. If you&#x27;re comparing it to &quot;I can&#x27;t remember how to use this API so I&#x27;m going to read a bunch of Stack Overflow posts&quot; than ChatGPT is seriously faster.<p>One of the reasons is that you can iterate to refine and expand your answer. Here&#x27;s a transcript of a recent chat, where I was too lazy to write a script:<p>Me&gt; I have a CSV file with a header row, whose first column is a date formatted like this: &quot;March 16, 2022 1:51:19 PM&quot;. Could you write a script to convert the dates in this CSV to ISO date format? I am using a mac would would prefer to not install any software, but other than that you can choose any language you&#x27;d like<p>ChatGPT&gt;Sure! Since macOS comes with Python pre-installed, you can use a Python script to read the CSV file and convert the dates to the ISO date format.<p>&lt;provides script and details of running it, but doesn&#x27;t handle the header row &#x2F;&gt;<p>Me&gt; the first row is a header row, could you please modify the script to handle that?<p>ChatGPT&gt; Certainly! We&#x27;ll modify the script to handle the header row separately, ensuring that it is copied to the output file without modification.<p>&lt;script and details, now correct &#x2F;&gt;<p>Me&gt; can you make it so the input file is a commandline argument?<p>ChatGPT&gt; Certainly! We can modify the script to accept the input file path as a command-line argument. Here&#x27;s the updated code<p>You get the idea.</div><br/></div></div><div id="37290223" class="c"><input type="checkbox" id="c-37290223" checked=""/><div class="controls bullet"><span class="by">dagw</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37290465">prev</a><span>|</span><a href="#37289500">next</a><span>|</span><label class="collapse" for="c-37290223">[-]</label><label class="expand" for="c-37290223">[1 more]</label></div><br/><div class="children"><div class="content">GPT won&#x27;t only writes code, but also documentation and unit tests.  It can also read code for you and explain what is going on. Furthermore, even as an academic researcher, most of the code I write is simple boilerplate code that GPT excels at. This means I get to spend more time on the actual code that is hard and novel and that GPT cannot really help with.<p>Back when GitHub Copilot was first released I though very much like you and was somewhat underwhelmed by my experience with it, however since then the state of the art has improved dramatically.</div><br/></div></div><div id="37289500" class="c"><input type="checkbox" id="c-37289500" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37290223">prev</a><span>|</span><a href="#37288518">next</a><span>|</span><label class="collapse" for="c-37289500">[-]</label><label class="expand" for="c-37289500">[1 more]</label></div><br/><div class="children"><div class="content">GPT can read and understand both code and the comments about 1000x faster than a human.<p>It&#x27;s not just about the code it can generate out of a vacuum, it can also <i>understand code for you</i>.<p>I use it to generate doc-comments, check for differences between the comment and the code, or to explain code I&#x27;m not familiar with and don&#x27;t understand myself.<p>E.g.: I don&#x27;t use Python and I had to figure out what a spaghetti-code Python script actually did. I fed it to GPT 4 and started asking questions. That&#x27;s way faster than <i>learning Python</i> first and then deciphering the script.</div><br/></div></div><div id="37288518" class="c"><input type="checkbox" id="c-37288518" checked=""/><div class="controls bullet"><span class="by">sharemywin</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37289500">prev</a><span>|</span><a href="#37288060">next</a><span>|</span><label class="collapse" for="c-37288518">[-]</label><label class="expand" for="c-37288518">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT is pretty good about telling you what a line of code does. So I just copy it in and ask it.</div><br/></div></div><div id="37288060" class="c"><input type="checkbox" id="c-37288060" checked=""/><div class="controls bullet"><span class="by">Yiin</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37288518">prev</a><span>|</span><a href="#37289899">next</a><span>|</span><label class="collapse" for="c-37288060">[-]</label><label class="expand" for="c-37288060">[1 more]</label></div><br/><div class="children"><div class="content">To write the code you need to know what to write. In many cases I find it easier to read proposed solution to my problem and then figure out from there how I actually want to implement a solution. It&#x27;s great starting point.</div><br/></div></div><div id="37289899" class="c"><input type="checkbox" id="c-37289899" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37288017">parent</a><span>|</span><a href="#37288060">prev</a><span>|</span><a href="#37287882">next</a><span>|</span><label class="collapse" for="c-37289899">[-]</label><label class="expand" for="c-37289899">[1 more]</label></div><br/><div class="children"><div class="content">Depends what you&#x27;re doing. If you tend to hop between languages, software stacks, platforms etc. then you probably (as I do) spend a lot of time looking up what the options are to achieve any given task, finding and interpreting API calls, etc. Having an LLM spit out code that&#x27;s in the right direction would be a huge time saver.</div><br/></div></div></div></div><div id="37287882" class="c"><input type="checkbox" id="c-37287882" checked=""/><div class="controls bullet"><span class="by">makestuff</span><span>|</span><a href="#37287858">parent</a><span>|</span><a href="#37288017">prev</a><span>|</span><a href="#37287992">next</a><span>|</span><label class="collapse" for="c-37287882">[-]</label><label class="expand" for="c-37287882">[7 more]</label></div><br/><div class="children"><div class="content">I have been trying to use ChatGPT to make a VueJS website (I’m a backend dev). What I have noticed with VueJS specifically is that it has little to no knowledge of the composition API, and when I ask it to help build a component it is pretty good at the scaffolding. The component will generally work; however, it is pretty useless for CSS styling.<p>I probably should try Copilot as I bet that would work better. Also the VS Code integration would be really nice.</div><br/><div id="37287924" class="c"><input type="checkbox" id="c-37287924" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37287882">parent</a><span>|</span><a href="#37289513">next</a><span>|</span><label class="collapse" for="c-37287924">[-]</label><label class="expand" for="c-37287924">[2 more]</label></div><br/><div class="children"><div class="content">Copilot probably wins because it holds more of _your_ code against the desired output.<p>I find ChatGPT is really great at getting something going, think scaffolding wise. But if you enter the realm of gnarly stuff, it can get completely delirious with answers full of red herrings and sends you running in circles very quickly.</div><br/><div id="37287977" class="c"><input type="checkbox" id="c-37287977" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37287924">parent</a><span>|</span><a href="#37289513">next</a><span>|</span><label class="collapse" for="c-37287977">[-]</label><label class="expand" for="c-37287977">[1 more]</label></div><br/><div class="children"><div class="content">The only truly helpful use-case I’ve found is in generating some well defined text in a different form. Say - here’s a JSON object , please write a MD file describing it or turn it to X language struct&#x2F;object.</div><br/></div></div></div></div><div id="37289513" class="c"><input type="checkbox" id="c-37289513" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37287882">parent</a><span>|</span><a href="#37287924">prev</a><span>|</span><a href="#37288439">next</a><span>|</span><label class="collapse" for="c-37289513">[-]</label><label class="expand" for="c-37289513">[1 more]</label></div><br/><div class="children"><div class="content">How stable was the Vue composition API prior to the September 2021 training cut-off date for the OpenAI models?<p>Looks to me like <a href="https:&#x2F;&#x2F;blog.vuejs.org&#x2F;posts&#x2F;vue-2-7-naruto" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.vuejs.org&#x2F;posts&#x2F;vue-2-7-naruto</a> back-ported it in July of 2022, and the earliest snapshot of the documentation for it in Vue 3 was <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220210121247&#x2F;https:&#x2F;&#x2F;vuejs.org&#x2F;guide&#x2F;extras&#x2F;composition-api-faq.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220210121247&#x2F;https:&#x2F;&#x2F;vuejs.org...</a> in February 2022 - so my guess is it mostly happened after that magic date.</div><br/></div></div><div id="37288439" class="c"><input type="checkbox" id="c-37288439" checked=""/><div class="controls bullet"><span class="by">earthboundkid</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37287882">parent</a><span>|</span><a href="#37289513">prev</a><span>|</span><a href="#37289329">next</a><span>|</span><label class="collapse" for="c-37288439">[-]</label><label class="expand" for="c-37288439">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT is very bad at CSS. The only good part is you can test it and see that it’s not working very quickly. Unfortunately if you go back to ChatGPT it will waste your time with endless apologies and more broken CSS.</div><br/></div></div><div id="37289329" class="c"><input type="checkbox" id="c-37289329" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37287882">parent</a><span>|</span><a href="#37288439">prev</a><span>|</span><a href="#37287992">next</a><span>|</span><label class="collapse" for="c-37289329">[-]</label><label class="expand" for="c-37289329">[2 more]</label></div><br/><div class="children"><div class="content">Can you confirm if you used gpt-4? This was not my experience</div><br/><div id="37289495" class="c"><input type="checkbox" id="c-37289495" checked=""/><div class="controls bullet"><span class="by">makestuff</span><span>|</span><a href="#37287858">root</a><span>|</span><a href="#37289329">parent</a><span>|</span><a href="#37287992">next</a><span>|</span><label class="collapse" for="c-37289495">[-]</label><label class="expand" for="c-37289495">[1 more]</label></div><br/><div class="children"><div class="content">It was gpt-3.5 (the free version offered). I will give get-4 a try though that is good to know.</div><br/></div></div></div></div></div></div></div></div><div id="37288013" class="c"><input type="checkbox" id="c-37288013" checked=""/><div class="controls bullet"><span class="by">splatzone</span><span>|</span><a href="#37287858">prev</a><span>|</span><a href="#37287892">next</a><span>|</span><label class="collapse" for="c-37288013">[-]</label><label class="expand" for="c-37288013">[8 more]</label></div><br/><div class="children"><div class="content">Run the code it writes, if it gives an error, paste it into the chat and 90% of the time the LLM can fix the issue.<p>People are missing the point here - it&#x27;s not about writing code in one-shot. An LLM-enabled loop can generate the code and test and refine it until it works</div><br/><div id="37288097" class="c"><input type="checkbox" id="c-37288097" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#37288013">parent</a><span>|</span><a href="#37290728">next</a><span>|</span><label class="collapse" for="c-37288097">[-]</label><label class="expand" for="c-37288097">[5 more]</label></div><br/><div class="children"><div class="content">Someone posted a transcript of having chatgpt write them a bash script with the comment &quot;see how much easier this was than figuring it out&quot; and it took like a dozen tries of pasting error messages back in. I was infuriated just reading it. I cannot imagine trying to develop this way. But if people like it, whatever blows your hair back.<p>Allegedly the benefit is it will do the boring stuff like write the error handling code for you, but I have no faith it would work if it takes so many tries to get the happy path correct.</div><br/><div id="37291238" class="c"><input type="checkbox" id="c-37291238" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#37288013">root</a><span>|</span><a href="#37288097">parent</a><span>|</span><a href="#37288385">next</a><span>|</span><label class="collapse" for="c-37291238">[-]</label><label class="expand" for="c-37291238">[1 more]</label></div><br/><div class="children"><div class="content">I think you’re missing the point here.<p>Language models scale.<p>It doesn’t matter if a single pass doesn’t solve the problem, has syntax errors, etc. A single pass costs a fraction of a cent.<p>You can just automate the process of code -&gt; create variant -&gt; fix from LLM -&gt; apply deterministic tests until the code at least <i>compiles</i> -&gt; pass it to the user; the fact you can’t do that with chatgpt is just because it’s not a coding tool.<p>Heck, there are already companies doing exactly this with vulnerability scanners (ie. the deterministic feedback loop) to suggest security fixes for code.<p>You just repeat a heap of times until you get a solution that passes all the scanners.<p>If it takes 10 tries, or 100 tries, it still is zero effort from a human.<p>Of course, whether the result <i>does the right thing</i> is another matter, but the frustrating ergonomics of copy-paste cycle is because of the ui, not the technology.<p>You will see “surprisingly good” output from professional tools in this space (we already are); but a lot of it is not magic sauce; it’s just the same tools, run multiple times, in a way that saves you doing it manually and just shows the best results, with a pretty ribbon on it.</div><br/></div></div><div id="37288385" class="c"><input type="checkbox" id="c-37288385" checked=""/><div class="controls bullet"><span class="by">arp242</span><span>|</span><a href="#37288013">root</a><span>|</span><a href="#37288097">parent</a><span>|</span><a href="#37291238">prev</a><span>|</span><a href="#37289098">next</a><span>|</span><label class="collapse" for="c-37288385">[-]</label><label class="expand" for="c-37288385">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I cannot imagine trying to develop this way. But if people like it, whatever blows your hair back.<p>I agree; who am I to comment on how you write the code, as long as it gets written, right? That said, I&#x27;ve already had a &quot;this is really odd code you committed last week, what&#x27;s up with that?&quot; and the reply was &quot;oh, dunno, that&#x27;s just what ChatGPT gave me&quot;. Meh. Actually writing things yourself does increase your understanding, so it&#x27;s not the same, not really. It&#x27;s when they told you to take notes at school: I didn&#x27;t believe my teachers it&#x27;ll help retain knowledge on account of being a stubborn little idiot, but they were right!<p>For people who have already done this programming thing for a while I guess it&#x27;ll work out, but my main worry is the effect it will have on more junior people who will &quot;grow up&quot; on ChatGPT. &quot;Figuring it out&quot; yourself has a lot of value.<p>Just because the code is free of syntax errors doesn&#x27;t mean it&#x27;s free of bugs. Shell scripting is a classic case where it&#x27;s hard to make something work but also buggy. You need to actually understand the code and reason about it. Trail-and-error programming rarely leads to good code.<p>I also fear we&#x27;ll end up with hard to read overly verbose&#x2F;repetitive code, &quot;because ChatGPT&#x2F;copilot will just generate it&quot;.</div><br/><div id="37290366" class="c"><input type="checkbox" id="c-37290366" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#37288013">root</a><span>|</span><a href="#37288385">parent</a><span>|</span><a href="#37289098">next</a><span>|</span><label class="collapse" for="c-37290366">[-]</label><label class="expand" for="c-37290366">[1 more]</label></div><br/><div class="children"><div class="content">Anyone committing code they don’t understand should be put on a PIP.</div><br/></div></div></div></div><div id="37289098" class="c"><input type="checkbox" id="c-37289098" checked=""/><div class="controls bullet"><span class="by">wavemode</span><span>|</span><a href="#37288013">root</a><span>|</span><a href="#37288097">parent</a><span>|</span><a href="#37288385">prev</a><span>|</span><a href="#37290728">next</a><span>|</span><label class="collapse" for="c-37289098">[-]</label><label class="expand" for="c-37289098">[1 more]</label></div><br/><div class="children"><div class="content">I also cannot understand how people develop that way.<p>That being said, better workflows do exist. I imagine IDE-integrated LLM tools like Copilot and CodeGPT are much more productivity-enhancing than copy-pasting code between a browser and an editor.</div><br/></div></div></div></div><div id="37290728" class="c"><input type="checkbox" id="c-37290728" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#37288013">parent</a><span>|</span><a href="#37288097">prev</a><span>|</span><a href="#37288048">next</a><span>|</span><label class="collapse" for="c-37290728">[-]</label><label class="expand" for="c-37290728">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re writing eg a bash script and it contains a difficult to spot bug which causes causes data loss (see [1] caused by a single space), what then?<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;MrMEEE&#x2F;bumblebee-Old-and-abbandoned&#x2F;issues&#x2F;123">https:&#x2F;&#x2F;github.com&#x2F;MrMEEE&#x2F;bumblebee-Old-and-abbandoned&#x2F;issue...</a></div><br/></div></div><div id="37288048" class="c"><input type="checkbox" id="c-37288048" checked=""/><div class="controls bullet"><span class="by">_bramses</span><span>|</span><a href="#37288013">parent</a><span>|</span><a href="#37290728">prev</a><span>|</span><a href="#37287892">next</a><span>|</span><label class="collapse" for="c-37288048">[-]</label><label class="expand" for="c-37288048">[1 more]</label></div><br/><div class="children"><div class="content">Completely agree. Any metric unto itself will only show a partial picture. Using LLMs as an iteration partner can solve any problem which is embedded in latent space (which is pretty much all problems that devs get paid to solve).<p>People seemingly desire to zealously defend the LeetCode way of solving problems for some inane reason.</div><br/></div></div></div></div><div id="37287892" class="c"><input type="checkbox" id="c-37287892" checked=""/><div class="controls bullet"><span class="by">taspeotis</span><span>|</span><a href="#37288013">prev</a><span>|</span><a href="#37287884">next</a><span>|</span><label class="collapse" for="c-37287892">[-]</label><label class="expand" for="c-37287892">[4 more]</label></div><br/><div class="children"><div class="content">I mean the landing page of GitHub Copilot just shoves text unencoded into a urlencoded body, this is nothing new...<p><pre><code>    const response = await fetch(`http:&#x2F;&#x2F;text-processing.com&#x2F;api&#x2F;sentiment&#x2F;`, {
      method: &quot;POST&quot;,
      body: `text=${text}`,
      headers: {
        &quot;Content-Type&quot;: &quot;application&#x2F;x-www-form-urlencoded&quot;,
      },
    });</code></pre></div><br/><div id="37287906" class="c"><input type="checkbox" id="c-37287906" checked=""/><div class="controls bullet"><span class="by">rany_</span><span>|</span><a href="#37287892">parent</a><span>|</span><a href="#37288429">next</a><span>|</span><label class="collapse" for="c-37287906">[-]</label><label class="expand" for="c-37287906">[1 more]</label></div><br/><div class="children"><div class="content">At least they can&#x27;t be sued for false advertising. That&#x27;s unfortunately commendable these days.</div><br/></div></div><div id="37288429" class="c"><input type="checkbox" id="c-37288429" checked=""/><div class="controls bullet"><span class="by">earthboundkid</span><span>|</span><a href="#37287892">parent</a><span>|</span><a href="#37287906">prev</a><span>|</span><a href="#37287884">next</a><span>|</span><label class="collapse" for="c-37288429">[-]</label><label class="expand" for="c-37288429">[2 more]</label></div><br/><div class="children"><div class="content">I find it kind of crazy that they haven’t fixed given how prominently it was called out. The Go example is wrong too. It doesn’t check the database call for a final error.</div><br/><div id="37290343" class="c"><input type="checkbox" id="c-37290343" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#37287892">root</a><span>|</span><a href="#37288429">parent</a><span>|</span><a href="#37287884">next</a><span>|</span><label class="collapse" for="c-37290343">[-]</label><label class="expand" for="c-37290343">[1 more]</label></div><br/><div class="children"><div class="content">I think to avoid false advertising claims they are using actual outputs. And if the listed examples are doing their job (getting people to sign up) they won’t change them.</div><br/></div></div></div></div></div></div><div id="37287884" class="c"><input type="checkbox" id="c-37287884" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#37287892">prev</a><span>|</span><a href="#37288116">next</a><span>|</span><label class="collapse" for="c-37287884">[-]</label><label class="expand" for="c-37287884">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an interesting idea, but why is this written so weirdly?<p>&quot;the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them&quot;<p>It looks like they could&#x27;ve benefited from an LLM doing a pass-over. Are they saying it&#x27;s only &quot;novice developers&quot; using LLMs?</div><br/><div id="37287945" class="c"><input type="checkbox" id="c-37287945" checked=""/><div class="controls bullet"><span class="by">sen</span><span>|</span><a href="#37287884">parent</a><span>|</span><a href="#37287907">next</a><span>|</span><label class="collapse" for="c-37287945">[-]</label><label class="expand" for="c-37287945">[1 more]</label></div><br/><div class="children"><div class="content">Just looks to me like the people who wrote this don’t speak English as a first language? It’s not difficult to parse what they meant to say.<p>Most of the users who are likely to turn to LLMs to help them code, are  people who aren’t very experienced programmers. Hence needing help. These same people are more likely to fall for mistakes in the generated code as they don’t have enough experience to notice the errors.<p>LLMs are very good at sounding confidently correct about things that are subtly wrong. You need experience in the domain to notice these issues usually.</div><br/></div></div><div id="37287907" class="c"><input type="checkbox" id="c-37287907" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#37287884">parent</a><span>|</span><a href="#37287945">prev</a><span>|</span><a href="#37287915">next</a><span>|</span><label class="collapse" for="c-37287907">[-]</label><label class="expand" for="c-37287907">[3 more]</label></div><br/><div class="children"><div class="content">I think the author is simply weak at English, although there are some typos that really should have been corrected even in non-idiomatic English (e.g. missing spaces between words).<p>Really, as long as the premise, evidence, and results are clear and reproducible, the quality of the English doesn’t much matter.</div><br/><div id="37290622" class="c"><input type="checkbox" id="c-37290622" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#37287884">root</a><span>|</span><a href="#37287907">parent</a><span>|</span><a href="#37287918">next</a><span>|</span><label class="collapse" for="c-37290622">[-]</label><label class="expand" for="c-37290622">[1 more]</label></div><br/><div class="children"><div class="content">Writing is code too. Writing English well does matter if you want to have your work read.</div><br/></div></div><div id="37287918" class="c"><input type="checkbox" id="c-37287918" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#37287884">root</a><span>|</span><a href="#37287907">parent</a><span>|</span><a href="#37290622">prev</a><span>|</span><a href="#37287915">next</a><span>|</span><label class="collapse" for="c-37287918">[-]</label><label class="expand" for="c-37287918">[1 more]</label></div><br/><div class="children"><div class="content">The claim “They are always novice developers that are not familiar with the APIs that LLMs generate code for them” seems pretty outlandish to me.</div><br/></div></div></div></div><div id="37287915" class="c"><input type="checkbox" id="c-37287915" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#37287884">parent</a><span>|</span><a href="#37287907">prev</a><span>|</span><a href="#37288116">next</a><span>|</span><label class="collapse" for="c-37287915">[-]</label><label class="expand" for="c-37287915">[1 more]</label></div><br/><div class="children"><div class="content">Yeah that statement seemed very strange to me too. I’ve been writing software for 20 years and I use ChatGPT4 everyday because it’s faster to edit and debug some code with a LLM than it is to write it all from scratch</div><br/></div></div></div></div><div id="37288116" class="c"><input type="checkbox" id="c-37288116" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#37287884">prev</a><span>|</span><a href="#37288307">next</a><span>|</span><label class="collapse" for="c-37288116">[-]</label><label class="expand" for="c-37288116">[2 more]</label></div><br/><div class="children"><div class="content">There was a good video posted here yesterday about a (for me) seemingly typical experience writing code with chatGPT <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U2Q3KAOSAEY">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U2Q3KAOSAEY</a><p>The combination of hallucination and just bad advice makes it time consuming and not clearly worth it. I think it&#x27;s a step in the right direction for conversational interfaces. The fact that you really can have a back and forth to clarify intent, make corrections, and arrive at a &quot;meeting of the minds&quot; is lightyears beyond &quot;intent recognition&quot; type chat, and what a conversation should be. It just needs more work, which may or may not be straightforward.</div><br/><div id="37289311" class="c"><input type="checkbox" id="c-37289311" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#37288116">parent</a><span>|</span><a href="#37288307">next</a><span>|</span><label class="collapse" for="c-37289311">[-]</label><label class="expand" for="c-37289311">[1 more]</label></div><br/><div class="children"><div class="content">Having the ChatGPT 4 icon being purple has been a godsend when evaluating claims like these.</div><br/></div></div></div></div><div id="37288307" class="c"><input type="checkbox" id="c-37288307" checked=""/><div class="controls bullet"><span class="by">damowangcy</span><span>|</span><a href="#37288116">prev</a><span>|</span><a href="#37287928">next</a><span>|</span><label class="collapse" for="c-37288307">[-]</label><label class="expand" for="c-37288307">[1 more]</label></div><br/><div class="children"><div class="content">API misuses is one thing, the more concerning outcome is the misuse of AI itself.<p>Just like how there is &quot;common misuse pattern of x language&quot;, there is also &quot;common misuse of copilot&#x2F;chatgpt4&quot;.<p>From my observation, those who are successful with code generation tools are using it as an assistant, they already know the language quite well, AI is there just to help, most of the code are boilerplate code or common patterns.<p>Those who complaint are usually using it to do more than just that, relying it to generate working piece of code for a particular function without knowledge of the language. Currently, we use StackOverflow for this purpose, when we asked question, we don&#x27;t just say, &quot;hey, code please&quot; but we are trying to understand why and how things work instead. This knowledge will then help us to code contextually, which current AIs are incapable of. The plus side is that code generation is faster.<p>Also the point of the paper is not to prove that GPT-4 is unusable but that it can be further improve. They didn&#x27;t just manually determine misuses but did it via an API checker that they designed. So, in the future, AIs are just going to be more reliable not less.<p>We are not at a point that AI is common enough to talk about misuse yet though, most don&#x27;t even have access to CoPilot or ChatGPT 4.</div><br/></div></div><div id="37287928" class="c"><input type="checkbox" id="c-37287928" checked=""/><div class="controls bullet"><span class="by">stephc_int13</span><span>|</span><a href="#37288307">prev</a><span>|</span><a href="#37287889">next</a><span>|</span><label class="collapse" for="c-37287928">[-]</label><label class="expand" for="c-37287928">[1 more]</label></div><br/><div class="children"><div class="content">I used Copilot for a few months, and I&#x27;ve toyed with different versions of Chat-GPT, for code.<p>Not impressed so far. With some effort and improvement this kind of tech can be used to fill boilerplate and glue code, and that is very nice as this is something that can help to stay in the flow by avoiding boring work.<p>But, the problem is that it is too unreliable even for this style of simple tasks, sometimes it works directly but it is too often plain wrong. Frustrating to use, not enough value, so I will try again later.</div><br/></div></div><div id="37287889" class="c"><input type="checkbox" id="c-37287889" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#37287928">prev</a><span>|</span><a href="#37290375">next</a><span>|</span><label class="collapse" for="c-37287889">[-]</label><label class="expand" for="c-37287889">[85 more]</label></div><br/><div class="children"><div class="content">I feel like AI for programming has been so overhyped. I&#x27;ve attempted to use ChatGPT for programming so many times, and almost every time it&#x27;s just wasted my time. Giving me outright lies or generating stuff that looks right but doesn&#x27;t work. And just throwing out it&#x27;s answer and starting from scratch is faster than fixing its output.<p>I&#x27;ve only found it useful for explaining basic terminology or concepts for a topic I&#x27;m not familiar with. Though this is the most dangerous use case since I&#x27;m not familiar with the answer, I can&#x27;t easily fact check it.</div><br/><div id="37287933" class="c"><input type="checkbox" id="c-37287933" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288066">next</a><span>|</span><label class="collapse" for="c-37287933">[-]</label><label class="expand" for="c-37287933">[20 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard this from many people now but I cannot relate at all. Copilot has changed my entire strategy of programming (which I have been doing for 20 years)<p>It writes lots of code before I even think about what I was going to do in that file. Half the time it just works outright, and if not, with minor changes.<p>It is fantastic when I have to build functionality in languages I am not great at.<p>I regularly copy and paste code from my colleagues PR&#x27;s and paste it into GPT-4, it explains it perfectly and gives tips on how to improve it (which I add as comments to my PR review)</div><br/><div id="37288539" class="c"><input type="checkbox" id="c-37288539" checked=""/><div class="controls bullet"><span class="by">enumjorge</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287933">parent</a><span>|</span><a href="#37288165">next</a><span>|</span><label class="collapse" for="c-37288539">[-]</label><label class="expand" for="c-37288539">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s comments like these that make me wish I could stand behind the chair of the people who get these results because I feel like there&#x27;s something lost in translation. I don&#x27;t know if I&#x27;m taking your comment too literally but this part confuses me:<p>&gt; It writes lots of code before I even think about what I was going to do in that file.<p>If you haven&#x27;t even thought of what you want to do in the file, how are you prompting Copilot to write the code you need? Am I understanding correctly that Copilot not only generates the correct code, but it&#x27;s also able to deduce what code you meant to ask for without any input from you? I don&#x27;t see how this is possible except in the uncommon case where you are bringing a file to be more in line with other files in your code base that have a similar structure.<p>I do think Copilot can be useful, but I&#x27;m confused at how different my experience is from what others are getting out of the tool.</div><br/><div id="37288657" class="c"><input type="checkbox" id="c-37288657" checked=""/><div class="controls bullet"><span class="by">abootstrapper</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288539">parent</a><span>|</span><a href="#37288672">next</a><span>|</span><label class="collapse" for="c-37288657">[-]</label><label class="expand" for="c-37288657">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT 4 is amazing! I use it when I’m blocked to get unstuck. I don’t need perfectly functioning code, just something to get my gears turning. I use it to review my own code. It often has pretty good suggestions, or can validate my approach. And I use it to sketch out unit tests for me. I still have fill in pieces, but it’s absolutely improved my output. It’s like having an egoless programming partner. Yeah, it makes mistakes, but I treat the AI like a programming buddy, not a flawless code wizard. It doesn’t solve problems for me, but we come to solutions together.</div><br/></div></div><div id="37288672" class="c"><input type="checkbox" id="c-37288672" checked=""/><div class="controls bullet"><span class="by">squeaky-clean</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288539">parent</a><span>|</span><a href="#37288657">prev</a><span>|</span><a href="#37288833">next</a><span>|</span><label class="collapse" for="c-37288672">[-]</label><label class="expand" for="c-37288672">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Am I understanding correctly that Copilot not only generates the correct code, but it&#x27;s also able to deduce what code you meant to ask for without any input from you?<p>You can know what you want to program, but not how you would approach the code. &quot;Hey ChatGPT, how do I draw a curved line plot in JUCE?&quot;<p>If I just ask it &quot;Can you write me a script that gathers the current stories on the front page of hacker news and sorts them by number of comments, then prints the title and number of comments?&quot; it writes a script in Python using requests and BeautifulSoup4.</div><br/></div></div><div id="37288833" class="c"><input type="checkbox" id="c-37288833" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288539">parent</a><span>|</span><a href="#37288672">prev</a><span>|</span><a href="#37288165">next</a><span>|</span><label class="collapse" for="c-37288833">[-]</label><label class="expand" for="c-37288833">[1 more]</label></div><br/><div class="children"><div class="content">What I find useful is I write two lines of comments when starting a new file, about what it is going to do.<p>Otherwise, even just creating a function, generally they will be filled out automatically.<p>I suppose I&#x27;m quite big on naming (vars and functions)<p>Maybe if your language or code is more terse, it might struggle more.</div><br/></div></div></div></div><div id="37288165" class="c"><input type="checkbox" id="c-37288165" checked=""/><div class="controls bullet"><span class="by">redhale</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287933">parent</a><span>|</span><a href="#37288539">prev</a><span>|</span><a href="#37288026">next</a><span>|</span><label class="collapse" for="c-37288165">[-]</label><label class="expand" for="c-37288165">[3 more]</label></div><br/><div class="children"><div class="content">This!<p>I wonder if it&#x27;s a language difference thing (I use C# mostly), but my experience with Copilot has been nothing short of mind-blowing.<p>It&#x27;s not writing every line, and when writing truly new feature code it&#x27;s less useful. But here are two patterns that I&#x27;ve noticed it is especially and consistently good at as a potential place to look for initial value if you are skeptical:<p>- If you have any kind of repeated pattern, even very complex ones, like performing a set of operations on a set of objects, or initializing a set of things, or whatever, it will guess everything else after the first line 90% of the time. This stuff is almost always plumbing&#x2F;wiring&#x2F;boilerplate-type code, so pure time gained. Think about Excel filling incrementing numbers down a column, but for pattern-matched lines or blocks of code.<p>- For any reasonably testable class, if I write the name of the unit test, Copilot will write the entire unit test perfectly 90% of the time, down to variable names and &#x2F;&#x2F;Arrange&#x2F;&#x2F;Act&#x2F;&#x2F;Assert comments that I stylistically prefer. Seriously, it&#x27;s sort of scary how good it is at this.</div><br/><div id="37288263" class="c"><input type="checkbox" id="c-37288263" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288165">parent</a><span>|</span><a href="#37288770">next</a><span>|</span><label class="collapse" for="c-37288263">[-]</label><label class="expand" for="c-37288263">[1 more]</label></div><br/><div class="children"><div class="content">Languages like C# and Java have always required a lot of boilerplate and repetitive (sorry, &quot;patterned&quot;) code. They are perfectly suited to GPTs.</div><br/></div></div><div id="37288770" class="c"><input type="checkbox" id="c-37288770" checked=""/><div class="controls bullet"><span class="by">justinlloyd</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288165">parent</a><span>|</span><a href="#37288263">prev</a><span>|</span><a href="#37288026">next</a><span>|</span><label class="collapse" for="c-37288770">[-]</label><label class="expand" for="c-37288770">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used ChatGPT and Copilot with Javascript &amp; Typescript and a bunch of frameworks. Python, C, C++, C#, Go, 6502, Z80, ARM and a few other languages so far. They&#x27;ve all worked pretty good. I wish it had a wider breadth of APIs and documentation, but it is pretty good so far.</div><br/></div></div></div></div><div id="37288026" class="c"><input type="checkbox" id="c-37288026" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287933">parent</a><span>|</span><a href="#37288165">prev</a><span>|</span><a href="#37288002">next</a><span>|</span><label class="collapse" for="c-37288026">[-]</label><label class="expand" for="c-37288026">[7 more]</label></div><br/><div class="children"><div class="content">Meh.  My coworkers do what you’re doing, and then I end up rewriting their stuff.  (AI generated stuff generally passes code reviews because it gets the benefit of the doubt.)</div><br/><div id="37288198" class="c"><input type="checkbox" id="c-37288198" checked=""/><div class="controls bullet"><span class="by">wesleywt</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288026">parent</a><span>|</span><a href="#37288002">next</a><span>|</span><label class="collapse" for="c-37288198">[-]</label><label class="expand" for="c-37288198">[6 more]</label></div><br/><div class="children"><div class="content">Meh. I started coding professionally in the age of AI. My productivity is way higher than it should be. I don&#x27;t let the AI &quot;write&quot; the code for me. I use it as a companion that I asked question of and suggestions.<p>It suggests solutions to problems, I add the complexity. So far my code has been both clear and performant. This should not be the case at my level.</div><br/><div id="37288575" class="c"><input type="checkbox" id="c-37288575" checked=""/><div class="controls bullet"><span class="by">enumjorge</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288198">parent</a><span>|</span><a href="#37288002">next</a><span>|</span><label class="collapse" for="c-37288575">[-]</label><label class="expand" for="c-37288575">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I started coding professionally in the age of AI.<p>What does this mean?<p>Copilot was released in March of this year. ChatGPT 4, which the community considers to be the only version of ChatGPT to be competent enough at coding tasks, was also released in March.<p>My guess is that you didn&#x27;t mean that statement to be a fancy way of saying &quot;I&#x27;ve been coding professionally for around 6 months&quot;, but I don&#x27;t know what else you mean by the &quot;age of AI&quot;.</div><br/><div id="37290858" class="c"><input type="checkbox" id="c-37290858" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288575">parent</a><span>|</span><a href="#37288693">next</a><span>|</span><label class="collapse" for="c-37290858">[-]</label><label class="expand" for="c-37290858">[1 more]</label></div><br/><div class="children"><div class="content">Minor correction - the original version of GitHub Copilot was released in late-2021.</div><br/></div></div><div id="37288693" class="c"><input type="checkbox" id="c-37288693" checked=""/><div class="controls bullet"><span class="by">anon25783</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288575">parent</a><span>|</span><a href="#37290858">prev</a><span>|</span><a href="#37290488">next</a><span>|</span><label class="collapse" for="c-37288693">[-]</label><label class="expand" for="c-37288693">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they think this is LinkedIn? &#x2F;j</div><br/></div></div><div id="37290488" class="c"><input type="checkbox" id="c-37290488" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288575">parent</a><span>|</span><a href="#37288693">prev</a><span>|</span><a href="#37288723">next</a><span>|</span><label class="collapse" for="c-37290488">[-]</label><label class="expand" for="c-37290488">[1 more]</label></div><br/><div class="children"><div class="content">The community is wrong, ChatGPT 3.5 is fine.</div><br/></div></div></div></div></div></div></div></div><div id="37288002" class="c"><input type="checkbox" id="c-37288002" checked=""/><div class="controls bullet"><span class="by">master_crab</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287933">parent</a><span>|</span><a href="#37288026">prev</a><span>|</span><a href="#37288492">next</a><span>|</span><label class="collapse" for="c-37288002">[-]</label><label class="expand" for="c-37288002">[2 more]</label></div><br/><div class="children"><div class="content">I feel like using suggestions for line by line composition might lend itself to better review by programmers.<p>As opposed to ChatGPT which spits out dozens of lines of code based on a request and therefore requires more involved editing after the fact to understand what’s happening.</div><br/><div id="37288212" class="c"><input type="checkbox" id="c-37288212" checked=""/><div class="controls bullet"><span class="by">wesleywt</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288002">parent</a><span>|</span><a href="#37288492">next</a><span>|</span><label class="collapse" for="c-37288212">[-]</label><label class="expand" for="c-37288212">[1 more]</label></div><br/><div class="children"><div class="content">Yes, GPT is an aid not a programmer. You should still be doing the programming while ChatGPT gives you quick solutions to problems without having to look up Stack Overflow.</div><br/></div></div></div></div><div id="37288492" class="c"><input type="checkbox" id="c-37288492" checked=""/><div class="controls bullet"><span class="by">darklycan51</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287933">parent</a><span>|</span><a href="#37288002">prev</a><span>|</span><a href="#37288066">next</a><span>|</span><label class="collapse" for="c-37288492">[-]</label><label class="expand" for="c-37288492">[3 more]</label></div><br/><div class="children"><div class="content">copilot? lol<p>I can understand using chatgpt 4 but copilot??? copilot can barely autocomplete... and half the time it does it incorrectly when variables and other stuff are involved</div><br/><div id="37289557" class="c"><input type="checkbox" id="c-37289557" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288492">parent</a><span>|</span><a href="#37288497">next</a><span>|</span><label class="collapse" for="c-37289557">[-]</label><label class="expand" for="c-37289557">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like you would benefit from spending some time learning how to use Copilot.<p>Which isn&#x27;t easy, because there&#x27;s virtually no documentation for it.<p>Once you get the hang of it it&#x27;s incredibly useful. I really feel it when I&#x27;m working in an editing environment without it now.</div><br/></div></div><div id="37288497" class="c"><input type="checkbox" id="c-37288497" checked=""/><div class="controls bullet"><span class="by">biohax2015</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288492">parent</a><span>|</span><a href="#37289557">prev</a><span>|</span><a href="#37288066">next</a><span>|</span><label class="collapse" for="c-37288497">[-]</label><label class="expand" for="c-37288497">[1 more]</label></div><br/><div class="children"><div class="content">Copilot has been incredibly useful for me</div><br/></div></div></div></div></div></div><div id="37288066" class="c"><input type="checkbox" id="c-37288066" checked=""/><div class="controls bullet"><span class="by">skepticATX</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37287933">prev</a><span>|</span><a href="#37288023">next</a><span>|</span><label class="collapse" for="c-37288066">[-]</label><label class="expand" for="c-37288066">[5 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a big gap between people using it to write greenfield applications and&#x2F;or smaller tools, and people working on large codebases.<p>I am in the latter group, and I don&#x27;t find it all that helpful. There simply aren&#x27;t any tools that can plug into a massive codebase with millions of lines. I never just work on one specific repository either - a change generally involves multiple repositories.<p>On the other hand, if you&#x27;re writing a smaller standalone utility, or working on a greenfield application, it can be helpful (with all the useful caveats about hallucations).<p>I think that a lot of ML folks, especially those in research, fall into the former category, which is why there has been so much hype.</div><br/><div id="37288407" class="c"><input type="checkbox" id="c-37288407" checked=""/><div class="controls bullet"><span class="by">plorkyeran</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288066">parent</a><span>|</span><a href="#37288365">next</a><span>|</span><label class="collapse" for="c-37288407">[-]</label><label class="expand" for="c-37288407">[1 more]</label></div><br/><div class="children"><div class="content">I do think that&#x27;s the big disconnect. There&#x27;s jobs where you basically only ever create brand new code from scratch - writing lots of little scripts, creating new screens in a webapp, or whatever - and current AI tools can save a ton of time for that. There&#x27;s also jobs where it&#x27;s normal to spend a week figuring out what to change and then five minutes changing it, and current AI tools are worthless for that. Most jobs are somewhere in between those extremes, but the hype is coming from people pretty far on the &quot;mostly writing new code&quot; end.</div><br/></div></div><div id="37288365" class="c"><input type="checkbox" id="c-37288365" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288066">parent</a><span>|</span><a href="#37288407">prev</a><span>|</span><a href="#37288145">next</a><span>|</span><label class="collapse" for="c-37288365">[-]</label><label class="expand" for="c-37288365">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d go further and say the sweet spot is probably writing a simple function that fits in the model&#x27;s context window, in a language you don&#x27;t know. Even here it screws up, but you can go back and forth and get somewhere. I can only imagine the mess one would make using it to build an actual application of any size. The analogy that comes to mind is using google translate to try and write an essay.</div><br/></div></div><div id="37288145" class="c"><input type="checkbox" id="c-37288145" checked=""/><div class="controls bullet"><span class="by">CharlesW</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288066">parent</a><span>|</span><a href="#37288365">prev</a><span>|</span><a href="#37288128">next</a><span>|</span><label class="collapse" for="c-37288145">[-]</label><label class="expand" for="c-37288145">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>There simply aren&#x27;t any tools that can plug into a massive codebase with millions of lines.</i><p>If Sourcegraph&#x27;s offering (<a href="https:&#x2F;&#x2F;about.sourcegraph.com&#x2F;cody" rel="nofollow noreferrer">https:&#x2F;&#x2F;about.sourcegraph.com&#x2F;cody</a>) has limits I&#x27;m not aware of, this is just a matter of time. But in my experience, this is a &quot;nice to have&quot; rather than a &quot;must have&quot; when it comes to the benefits of GenAI as it applies to coding.</div><br/></div></div><div id="37288128" class="c"><input type="checkbox" id="c-37288128" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288066">parent</a><span>|</span><a href="#37288145">prev</a><span>|</span><a href="#37288023">next</a><span>|</span><label class="collapse" for="c-37288128">[-]</label><label class="expand" for="c-37288128">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I think this is really one of the key issues. I found all of this tech to be really great with my side projects and really lacking with my big corpo codebase fragmented across multiple teams, projects and libraries.</div><br/></div></div></div></div><div id="37288023" class="c"><input type="checkbox" id="c-37288023" checked=""/><div class="controls bullet"><span class="by">throwaway09223</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288066">prev</a><span>|</span><a href="#37287937">next</a><span>|</span><label class="collapse" for="c-37288023">[-]</label><label class="expand" for="c-37288023">[9 more]</label></div><br/><div class="children"><div class="content">You have to put it in context: How good is the human alternative?<p>I have interviewed hundreds of engineers across the entire skill spectrum. I think GPT4 right now is about on-par with a mid level developer.<p>It makes a lot of mistakes, especially around counting, and usually can notice and fix them if they&#x27;re pointed out. Humans do this all the time -- how often do you get a compiler error from something silly?<p>It often misapplies interfaces on the first go-around. Again, this is just like humans. We make mistakes, notice them, fix them. If you simulate this by telling GPT that its code produced an error it will often correct itself.<p>The absolutely killer feature of GPT4 is that it has these skills in <i>every</i> subject. It&#x27;s fluent in kernel operations. Databases. Networking. Various UX frameworks. Any language.<p>It&#x27;s definitely not perfect. But, if the alternative is hiring a mid-level human engineer, GPT4 is a really compelling alternative.</div><br/><div id="37290781" class="c"><input type="checkbox" id="c-37290781" checked=""/><div class="controls bullet"><span class="by">Yodel0914</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288023">parent</a><span>|</span><a href="#37288037">next</a><span>|</span><label class="collapse" for="c-37290781">[-]</label><label class="expand" for="c-37290781">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think GPT4 right now is about on-par with a mid level developer.<p>At writing code, that might be a slight exaggeration. At <i>explaining</i> code it&#x27;s at least at mid level, possibly better.</div><br/></div></div><div id="37288037" class="c"><input type="checkbox" id="c-37288037" checked=""/><div class="controls bullet"><span class="by">xtagon</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288023">parent</a><span>|</span><a href="#37290781">prev</a><span>|</span><a href="#37288737">next</a><span>|</span><label class="collapse" for="c-37288037">[-]</label><label class="expand" for="c-37288037">[6 more]</label></div><br/><div class="children"><div class="content">A mid-level human engineer can iteratively fix the mistakes they start making, instead of that just being the final result. Can GPT-4 do that?</div><br/><div id="37288049" class="c"><input type="checkbox" id="c-37288049" checked=""/><div class="controls bullet"><span class="by">throwaway09223</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288037">parent</a><span>|</span><a href="#37288139">next</a><span>|</span><label class="collapse" for="c-37288049">[-]</label><label class="expand" for="c-37288049">[2 more]</label></div><br/><div class="children"><div class="content">Yes, like I said if you give it the results, eg &quot;That code resulted in this error. What&#x27;s wrong?&quot; it will more often than not correct its mistake.<p>Hooking it up to automatically run the code in question and examine the output is a trivial undertaking - many folks have already done this.</div><br/><div id="37288428" class="c"><input type="checkbox" id="c-37288428" checked=""/><div class="controls bullet"><span class="by">jhugo</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288049">parent</a><span>|</span><a href="#37288139">next</a><span>|</span><label class="collapse" for="c-37288428">[-]</label><label class="expand" for="c-37288428">[1 more]</label></div><br/><div class="children"><div class="content">My experience has usually been that it will apologize and then produce another snippet with a different flaw. When that is pointed out, it will usually go back to the original snippet with the original flaw. It sometimes also insists that it has “run the test suite and they all pass”, just like a human programmer that is trying to fake it until they make it I guess?</div><br/></div></div></div></div><div id="37288139" class="c"><input type="checkbox" id="c-37288139" checked=""/><div class="controls bullet"><span class="by">kubrickslair</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288037">parent</a><span>|</span><a href="#37288049">prev</a><span>|</span><a href="#37288054">next</a><span>|</span><label class="collapse" for="c-37288139">[-]</label><label class="expand" for="c-37288139">[1 more]</label></div><br/><div class="children"><div class="content">It does it pretty well for Python with code interpreter, especially for quant&#x2F; ML heavy code.</div><br/></div></div><div id="37288054" class="c"><input type="checkbox" id="c-37288054" checked=""/><div class="controls bullet"><span class="by">tomjakubowski</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288037">parent</a><span>|</span><a href="#37288139">prev</a><span>|</span><a href="#37288737">next</a><span>|</span><label class="collapse" for="c-37288054">[-]</label><label class="expand" for="c-37288054">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if anyone has done a feedback loop with GPT and compiler errors to train this sort of thing</div><br/><div id="37288430" class="c"><input type="checkbox" id="c-37288430" checked=""/><div class="controls bullet"><span class="by">aldarisbm</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288054">parent</a><span>|</span><a href="#37288737">next</a><span>|</span><label class="collapse" for="c-37288430">[-]</label><label class="expand" for="c-37288430">[1 more]</label></div><br/><div class="children"><div class="content">they have, with langchain</div><br/></div></div></div></div></div></div><div id="37288737" class="c"><input type="checkbox" id="c-37288737" checked=""/><div class="controls bullet"><span class="by">bcrosby95</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288023">parent</a><span>|</span><a href="#37288037">prev</a><span>|</span><a href="#37287937">next</a><span>|</span><label class="collapse" for="c-37288737">[-]</label><label class="expand" for="c-37288737">[1 more]</label></div><br/><div class="children"><div class="content">I would peg gpt as between junior and mid.  Mids (around 5-10 years of experience) tend to produce overly complex code for the problem at hand.</div><br/></div></div></div></div><div id="37287937" class="c"><input type="checkbox" id="c-37287937" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288023">prev</a><span>|</span><a href="#37287984">next</a><span>|</span><label class="collapse" for="c-37287937">[-]</label><label class="expand" for="c-37287937">[10 more]</label></div><br/><div class="children"><div class="content">Which version of GPT are you using?<p>I&#x27;ve found GPT4 moderately helpful, like getting help from someone with a wide but shallow experience of lots of things.<p>&gt; I can&#x27;t easily fact check it<p>Why not? How did you find out things about basic terminology or concepts you&#x27;re not familiar about before GPT? Apply the same methods, although you just have to fact check rather than coming up with what to check, so removes a small initial discovery, at least for me.</div><br/><div id="37289927" class="c"><input type="checkbox" id="c-37289927" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287937">parent</a><span>|</span><a href="#37287976">next</a><span>|</span><label class="collapse" for="c-37289927">[-]</label><label class="expand" for="c-37289927">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Why not? How did you find out things about basic terminology or concepts you&#x27;re not familiar about before GPT?<p>Because if it tells me something that could just be found on google, I could have found it there first and not have to do as much fact checking. And if it tells me something I can&#x27;t easily find, I can&#x27;t tell if it&#x27;s got some deep insight on harder to locate info, or if it&#x27;s just made up.</div><br/><div id="37290496" class="c"><input type="checkbox" id="c-37290496" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37289927">parent</a><span>|</span><a href="#37287976">next</a><span>|</span><label class="collapse" for="c-37290496">[-]</label><label class="expand" for="c-37290496">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT gives you ideas and terms that you can google. That&#x27;s often a rarity in a new language&#x2F;framework.</div><br/></div></div></div></div><div id="37287976" class="c"><input type="checkbox" id="c-37287976" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287937">parent</a><span>|</span><a href="#37289927">prev</a><span>|</span><a href="#37287978">next</a><span>|</span><label class="collapse" for="c-37287976">[-]</label><label class="expand" for="c-37287976">[4 more]</label></div><br/><div class="children"><div class="content">It’s a question of time investment, fact checking is slower  you than actually learning the material directly.  So if you need to fact check every single thing you’re better off just leaning it in the first place.</div><br/><div id="37288007" class="c"><input type="checkbox" id="c-37288007" checked=""/><div class="controls bullet"><span class="by">pnpnp</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287976">parent</a><span>|</span><a href="#37288433">next</a><span>|</span><label class="collapse" for="c-37288007">[-]</label><label class="expand" for="c-37288007">[2 more]</label></div><br/><div class="children"><div class="content">In the original comment’s defense, sometimes you need to find where to start. For example: when writing a research paper, one might hastily cast a wide net before locating and drilling into a topic from a respected source.<p>I’m not well-versed in JavaScript (I’d like to be, but neither me nor my company have the resources right now to commit). When JS work comes up, I’ll often Google&#x2F;ChatGPT to point me in a general direction before pulling up technical documentation on whatever comes back. I’m pretty good at learning, but sometimes it takes me a while to find out where to start.</div><br/><div id="37288410" class="c"><input type="checkbox" id="c-37288410" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288007">parent</a><span>|</span><a href="#37288433">next</a><span>|</span><label class="collapse" for="c-37288410">[-]</label><label class="expand" for="c-37288410">[1 more]</label></div><br/><div class="children"><div class="content">I get where you’re coming from.  However it’s easy to fall into the generalist trap where muddling through works well enough that you never spend the time to actually learn anything.  It’s risky to really lean the details of a web framework which you may only use for a single 6 month project.<p>However, there’s a few things like SQL and JavaScrip that are likely to stick around mostly unchanged for your entire career.  The risks are therefore much lower.<p>IMO, a reasonable heuristic is spend around 10% of the time you expect to work on technology in the next year actually learning the fundamentals until you feel comfortable.  Often what looks like a major time sink goes away when you stop fumbling around.</div><br/></div></div></div></div><div id="37288433" class="c"><input type="checkbox" id="c-37288433" checked=""/><div class="controls bullet"><span class="by">jay_kyburz</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287976">parent</a><span>|</span><a href="#37288007">prev</a><span>|</span><a href="#37287978">next</a><span>|</span><label class="collapse" for="c-37288433">[-]</label><label class="expand" for="c-37288433">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I have been learning some new topics lately, and GTP is actually very helpful in giving me the language I need to use start searching.<p>I&#x27;m not interested in starting at the beginning and learning a whole new language or API, I just want to get my task done, so I can ask GTP to get me started, then I can run the code it writes and start building tests and things to verify it works as expected.</div><br/></div></div></div></div><div id="37287978" class="c"><input type="checkbox" id="c-37287978" checked=""/><div class="controls bullet"><span class="by">pnpnp</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287937">parent</a><span>|</span><a href="#37287976">prev</a><span>|</span><a href="#37287984">next</a><span>|</span><label class="collapse" for="c-37287978">[-]</label><label class="expand" for="c-37287978">[3 more]</label></div><br/><div class="children"><div class="content">This is how I use it as well. I don’t trust it, but find it more useful than Google these days for zeroing in on a topic.</div><br/><div id="37287997" class="c"><input type="checkbox" id="c-37287997" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287978">parent</a><span>|</span><a href="#37287984">next</a><span>|</span><label class="collapse" for="c-37287997">[-]</label><label class="expand" for="c-37287997">[2 more]</label></div><br/><div class="children"><div class="content">Particularly with Google Search getting shittier and shittier with time.</div><br/><div id="37288014" class="c"><input type="checkbox" id="c-37288014" checked=""/><div class="controls bullet"><span class="by">pnpnp</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287997">parent</a><span>|</span><a href="#37287984">next</a><span>|</span><label class="collapse" for="c-37288014">[-]</label><label class="expand" for="c-37288014">[1 more]</label></div><br/><div class="children"><div class="content">It’s really too bad! I’d rather not be using AI as a search replacement, but I do feel like search results have degraded significantly.</div><br/></div></div></div></div></div></div></div></div><div id="37287984" class="c"><input type="checkbox" id="c-37287984" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37287937">prev</a><span>|</span><a href="#37290504">next</a><span>|</span><label class="collapse" for="c-37287984">[-]</label><label class="expand" for="c-37287984">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t relate, I&#x27;m currently designing a lower level data structure based on some papers and its been a pretty valuable rubber duck. I&#x27;ve only had one real instance of it being incorrect that wasted my time, higher ranked trait bounds in Rust can only be applied over lifetimes and instead it was suggesting I try to use them for non lifetime generics as well.<p>That said I&#x27;m not asking ChatGPT to write code that I use directly, I&#x27;m basically asking clarifying questions about the papers and other implementations I have on hand, and that&#x27;s similar to how I use it in most cases.<p>For code generation I rely on co-pilot, which actually has the context of my codebase.<p>Edit: I will say this because someone else made me think of it: I find this tech all super useful on my like 20k loc and smaller side projects which are all self contained where as when I tried co pilot at work on a fragmented big corp code base I found it comparatively lackluster.</div><br/></div></div><div id="37290504" class="c"><input type="checkbox" id="c-37290504" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37287984">prev</a><span>|</span><a href="#37288733">next</a><span>|</span><label class="collapse" for="c-37290504">[-]</label><label class="expand" for="c-37290504">[1 more]</label></div><br/><div class="children"><div class="content">My experience is that ChatGPT often makes errors, but the errors are <i>different</i> than the errors I&#x27;d make. So it&#x27;s easy to work with it collaboratively: I take a turn, GPT takes a turn, I take a turn... and it has an extremely broad spectrum of surface-level knowledge about tech.<p>The most annoying part is it&#x27;s impossible for it to say that it doesn&#x27;t know something. Hard to train for, I know.</div><br/></div></div><div id="37288733" class="c"><input type="checkbox" id="c-37288733" checked=""/><div class="controls bullet"><span class="by">justinlloyd</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37290504">prev</a><span>|</span><a href="#37288710">next</a><span>|</span><label class="collapse" for="c-37288733">[-]</label><label class="expand" for="c-37288733">[1 more]</label></div><br/><div class="children"><div class="content">I have been happy about 90% to 95% of the time with code that gets spat out by ChatGPT, though I don&#x27;t fear for my job being taken by an LLM any time soon. It usually gives good insight in to unfamiliar code, or code in a language that I am familiar with but might have forgotten how to use. That said, I don&#x27;t use it for every piece of code I write. Usually sections where I am exploring an idea.<p>At times, I need to correct the LLM on some usually obscure detail. It got the memory layout of the video screen on the BBC Micro completely mixed up with the ZX Spectrum, and I had to correct it about five times before it got it, and then it stuck for the rest of the conversation.<p>I&#x27;ve been on some wild goose chases, where I have fooled myself into thinking a particular approach would work and ChatGPT has been enthusiastically right there cheering me on.<p>It&#x27;s like my dog going on an adventure with me, the dog doesn&#x27;t care about where we&#x27;re going or what we&#x27;re doing, it&#x27;s just excited to be part of the journey.<p>And in other cases, ChatGPT has been exceptionally useful in pointing out some blindingly obvious mistakes. It is like having a very knowledgeable, but exceptionally junior developer at your elbow.<p>If you ask the right questions, and don&#x27;t except one shot questions to provide perfect answers, it works well for the most part.</div><br/></div></div><div id="37288710" class="c"><input type="checkbox" id="c-37288710" checked=""/><div class="controls bullet"><span class="by">beatthatflight</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288733">prev</a><span>|</span><a href="#37288698">next</a><span>|</span><label class="collapse" for="c-37288710">[-]</label><label class="expand" for="c-37288710">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used it for performance boosts.  It&#x27;s not perfect, but if I paste a method (my own code) and say &#x27;rewrite in fewer lines&#x27; to simplify, or &#x27;rewrite to run faster&#x27;, I&#x27;ve been in awe at what it comes up with that hadn&#x27;t occured to me. Tricks in python I wasn&#x27;t aware of, or hadn&#x27;t considered using a different datastructure that can be searched faster (for some reason my brain always defaults to lists, when a set may be better, for example).
It absolutely makes errors though, so unit tests are critical, but I&#x27;ve got code running so much faster as a result.</div><br/></div></div><div id="37288698" class="c"><input type="checkbox" id="c-37288698" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288710">prev</a><span>|</span><a href="#37287955">next</a><span>|</span><label class="collapse" for="c-37288698">[-]</label><label class="expand" for="c-37288698">[1 more]</label></div><br/><div class="children"><div class="content">My experience is that you need to do a few back and forth get get it right especially for a more detailed functions.  What works really well is if you need it to explain to you how something works, but to verify, you need to have a good sniff test which novices won’t have so they take it dangerously straight up</div><br/></div></div><div id="37287955" class="c"><input type="checkbox" id="c-37287955" checked=""/><div class="controls bullet"><span class="by">lockhouse</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288698">prev</a><span>|</span><a href="#37288160">next</a><span>|</span><label class="collapse" for="c-37287955">[-]</label><label class="expand" for="c-37287955">[2 more]</label></div><br/><div class="children"><div class="content">AI for nearly everything has been very overhyped.  Paintings of people have extra fingers and other strange artifacts.  Using it for writing prose is hit or miss.  Full self driving cars are thwarted by rogue traffic cones.<p>I think we&#x27;ll have AI some day, but today it&#x27;s just not at the level that all the hype claims it is.</div><br/><div id="37288205" class="c"><input type="checkbox" id="c-37288205" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37287955">parent</a><span>|</span><a href="#37288160">next</a><span>|</span><label class="collapse" for="c-37288205">[-]</label><label class="expand" for="c-37288205">[1 more]</label></div><br/><div class="children"><div class="content">There you go. But even before that 8 years ago, ConvNets, AlexNet, etc were getting all the hype and then came the adversarial images and issues which weren&#x27;t addressed and then that hype fizzled out very quickly.<p>Now the AI bros here are attempting to sell us their new snake-oil in the form of a stochastic parrot which promises to be the solution to everything.<p>Well, unsurprisingly it is another unexplainable AI black box which still requires the human to check every single output so that it doesn&#x27;t hallucinate something incorrect, which it does almost all the time with a lack of transparent explainability as to why it hallucinated.<p>So the fact is, it is already overpromising and under-delivering for serious use-cases. Just like FSD (Fools Self Driving) was when that was over-hyped and with little to no Tesla Robo-taxis on the road.</div><br/></div></div></div></div><div id="37288160" class="c"><input type="checkbox" id="c-37288160" checked=""/><div class="controls bullet"><span class="by">drewfis</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37287955">prev</a><span>|</span><a href="#37287957">next</a><span>|</span><label class="collapse" for="c-37288160">[-]</label><label class="expand" for="c-37288160">[2 more]</label></div><br/><div class="children"><div class="content">Chat GPT is a game changer for a lot of my work. I make it write stored procedures in MS SQL along with the calling code in .NET, C#, and Dapper.<p>The generated code will likely have a few small issues, but it still makes me way more productive. It allows me to work ~10 hours a week less and enjoy my life.</div><br/><div id="37288294" class="c"><input type="checkbox" id="c-37288294" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288160">parent</a><span>|</span><a href="#37287957">next</a><span>|</span><label class="collapse" for="c-37288294">[-]</label><label class="expand" for="c-37288294">[1 more]</label></div><br/><div class="children"><div class="content">Until your boss&#x2F;customer gets wind of it, and claims back that time.</div><br/></div></div></div></div><div id="37287957" class="c"><input type="checkbox" id="c-37287957" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288160">prev</a><span>|</span><a href="#37288016">next</a><span>|</span><label class="collapse" for="c-37287957">[-]</label><label class="expand" for="c-37287957">[1 more]</label></div><br/><div class="children"><div class="content">Yea, I had a thought early on that programmers might start poisoning the well with these LLM by uploading a lot of broken code.   But I think people have  been unintentionally doing so for years.</div><br/></div></div><div id="37288016" class="c"><input type="checkbox" id="c-37288016" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37287957">prev</a><span>|</span><a href="#37288029">next</a><span>|</span><label class="collapse" for="c-37288016">[-]</label><label class="expand" for="c-37288016">[1 more]</label></div><br/><div class="children"><div class="content">It’s both under and over-hyped. The whole “AI is going to write your entire app for you with a couple sentences prompt” crowd is full of shit, but for small sections of code, variations on existing scripts and functions, writing tests, etc, GPT-4 is pretty incredible.<p>I work in data science and have to write a lot of repetitive stuff for parsing and cleaning data. It’s reduced my toil so dramatically in this respect, I can’t imagine going back to writing all that stuff again. I’m now much more ambitious in what I’ll experiment with as well because I know setting up the first stages of the data pipeline are going to be 10X less work than before.</div><br/></div></div><div id="37288029" class="c"><input type="checkbox" id="c-37288029" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288016">prev</a><span>|</span><a href="#37287942">next</a><span>|</span><label class="collapse" for="c-37288029">[-]</label><label class="expand" for="c-37288029">[28 more]</label></div><br/><div class="children"><div class="content">The over-hype is causing it to look under-hyped. 48% of the code being freaking correct from 0% about 5 years ago is huge.<p>With everyone and all the news talking about it constantly inevitably people are going to start rolling their eyes.<p>This is bias. 48% is half way to 100%. Once it reaches 100% you don&#x27;t have a job. You realize that right? It&#x27;s halfway their to taking your job and you&#x27;re underwhelmed. The bias is on your side.<p>It&#x27;s typical. It&#x27;s like an indie band is only popular when not many people know about it. Once everybody starts talking about it all the time it loses it&#x27;s popularity. People start thinking it&#x27;s not cool anymore. That&#x27;s the bias you are suffering from.</div><br/><div id="37288480" class="c"><input type="checkbox" id="c-37288480" checked=""/><div class="controls bullet"><span class="by">jhugo</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288197">next</a><span>|</span><label class="collapse" for="c-37288480">[-]</label><label class="expand" for="c-37288480">[2 more]</label></div><br/><div class="children"><div class="content">You assume that getting from “48% as good” as a human programmer (on an undoubtedly biased sample) to “100% as good” is about equally hard as getting from 0% to 48%. That seems a pretty big assumption.<p>Many programmers also do work that doesn’t just involve stitching APIs together; GPT consistently fails badly when forced to reason, making it useless for many tasks. For example, ask it to implement a common algorithm like SHA - it will do a decent job. Then ask it to do it with an arbitrary limitation which no implementation it was trained on would have (e.g. use no integer type wider than 8 bits). In my experience, it cannot achieve this task with a correct result, even with significant hand-holding.</div><br/><div id="37288563" class="c"><input type="checkbox" id="c-37288563" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288480">parent</a><span>|</span><a href="#37288197">next</a><span>|</span><label class="collapse" for="c-37288563">[-]</label><label class="expand" for="c-37288563">[1 more]</label></div><br/><div class="children"><div class="content">&gt;You assume that getting from “48% as good” as a human programmer (on an undoubtedly biased sample) to “100% as good” is about equally hard as getting from 0% to 48%. That seems a pretty big assumption.<p>I meant 38% aka 40% made a mistake on my math.<p>It&#x27;s not a big assumption. It&#x27;s the most reasonable assumption. When you drive 50% of 10 miles the next 50% takes the same amount of time. It&#x27;s the default assumption.<p>I understand where you&#x27;re coming from though. Many products made by entrepreneurs follow that model where the remaining percentage is always harder than the beginning green fielded tech that was built. But can we honestly say that this is what AGI will be like? The LLM was an unexpected jump forward by an unprecedented amount. It could be we fill the gap to 100% with another such jump.</div><br/></div></div></div></div><div id="37288197" class="c"><input type="checkbox" id="c-37288197" checked=""/><div class="controls bullet"><span class="by">wpietri</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288480">prev</a><span>|</span><a href="#37288357">next</a><span>|</span><label class="collapse" for="c-37288197">[-]</label><label class="expand" for="c-37288197">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Once it reaches 100% you don&#x27;t have a job. You realize that right? It&#x27;s halfway their to taking your job and you&#x27;re underwhelmed. The bias is on your side.<p>What this study looked at was feeding StackOverflow questions to LLMs and then looking at the quality of the code. If you think a programmer&#x27;s job is just turning an english-language description of a function into isolated code that never gets modified, I don&#x27;t know what to tell you. In my opinion, anybody like that should not have a job today, never mind the future.<p>A proper professional programming job involved AGI-level understanding of human users and their needs as embedded in a social context. Plus the ability to create novel solutions. Plus the ability to use code as a collaborative medium to make a code base that is sustainable over the long term by their colleagues.<p>LLMs are not even 1% of the way to replacing professional developers.</div><br/><div id="37288353" class="c"><input type="checkbox" id="c-37288353" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288197">parent</a><span>|</span><a href="#37288357">next</a><span>|</span><label class="collapse" for="c-37288353">[-]</label><label class="expand" for="c-37288353">[3 more]</label></div><br/><div class="children"><div class="content">Not true. They are well past 1%. That&#x27;s not looking at reality. You can lower it below 38% but 1% is pure fantasy.</div><br/><div id="37288915" class="c"><input type="checkbox" id="c-37288915" checked=""/><div class="controls bullet"><span class="by">wpietri</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288353">parent</a><span>|</span><a href="#37288357">next</a><span>|</span><label class="collapse" for="c-37288915">[-]</label><label class="expand" for="c-37288915">[2 more]</label></div><br/><div class="children"><div class="content">First off, you did not address most of my point.<p>To answer your complaint, I am absolutely looking at reality. Please point us to an actual real-world professional programming job, matching the criteria I list above, for which a current LLM can economically replace a human for over a 5-year period.<p>My believe is that there are exactly zero such jobs. If your claim is that we&#x27;re at least at 1%, then you&#x27;re claiming that there are at least 269k fully automatable programmer jobs [1]. It shouldn&#x27;t be hard for you to find at least one to start.<p>[1] Wikipedia says there are an estimated 26.9m professional programmers: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Software_engineering_demographics" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Software_engineering_demograph...</a></div><br/><div id="37291092" class="c"><input type="checkbox" id="c-37291092" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288915">parent</a><span>|</span><a href="#37288357">next</a><span>|</span><label class="collapse" for="c-37291092">[-]</label><label class="expand" for="c-37291092">[1 more]</label></div><br/><div class="children"><div class="content">&gt;My believe is that there are exactly zero such jobs. If your claim is that we&#x27;re at least at 1%, then you&#x27;re claiming that there are at least 269k fully automatable programmer jobs [1]. It shouldn&#x27;t be hard for you to find at least one to start.<p>If I built an entire car but I am missing the key. I cannot drive the car but the car is 99% complete. It&#x27;s just missing the key. So what happens is, it can replace 0% of human locomotion but it&#x27;s 99% complete? get it?<p>Just because the tool can&#x27;t be used doesn&#x27;t mean it&#x27;s zero percent of the way to being drive able. Same with your job. The LLM can&#x27;t replace any job yet, but it doesn&#x27;t mean it&#x27;s 1% of the way there.<p>But you see what I just explained to you is obvious. You already know this just like I and every one else on the face of the earth already knows this fact.<p>You&#x27;re taking the discussion into a play on words. What does 1% apply to? Rather then use common sense and derive what I mean you prefer to redirect the conversation into a very specific definition of 1% that serves your own purpose.<p>We can play this game all day. We can discuss whether your application of 1% is more fitting than my application of 1%. What a waste of everyone&#x27;s time.<p>I think it&#x27;s better if rather then playing these games to &quot;win&quot; discussions, use your common sense to move the discussion past these games. Otherwise we&#x27;re going to be talking about obvious things all day and getting all worked up about personal definitions.<p>Clearly the LLM is more than just 1%.</div><br/></div></div></div></div></div></div></div></div><div id="37288357" class="c"><input type="checkbox" id="c-37288357" checked=""/><div class="controls bullet"><span class="by">jsunderland323</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288197">prev</a><span>|</span><a href="#37288325">next</a><span>|</span><label class="collapse" for="c-37288357">[-]</label><label class="expand" for="c-37288357">[5 more]</label></div><br/><div class="children"><div class="content">&gt; 48% if half way to 100% … It&#x27;s halfway their to taking your job and your underwhelmed.<p>You’re implying 100% reliability is actually attainable. If that were the case, wouldn’t that mean the halting problem would have been solved by AI? I’m not an expert but I’ve heard that’s like one of those fundamental laws of information theory that really can’t be broken.<p>&gt; It&#x27;s typical. It&#x27;s like an indie band is only popular when not many people know about it. Once everybody starts talking about it all the time it loses it&#x27;s popularity.<p>I think applying the sociology of hipster band fans to LLMs is a mistake and I’m not sure how the vogueness of the technology correlates with the correctness of the actual models. Sometimes an early technology seems docile or useless at first but eventually reaches ubiquity and in retrospect the utility is obvious. But sometimes (more often than not) standard adoption curves don’t make sense to apply to a new technology because it isn’t useful enough to go through an adoption cycle. I think there’s a temptation to apply the analogy of something like the early internet or smartphone to LLMs but those are networked products. LLMs don’t really improve with the various applications built on top of them if the LLM is itself fundamentally broken or faulty to the point that it is unsafe to use in practice. Furthermore given the massive amount of premature hype due to the AI zeitgeist, you can safely assume enough user hours have been spent messing with LLMs to get a verdict on their utility. Unlike the feeble technology that takes a longtime to reach a scale to know its utility, we don’t have to wait 10 years for 100m people to try LLMs, it happened in a week. My only point being, I think we should be apprehensive about trying to draw analogies of other adoption cycles that structurally are very very different to this one.<p>Obviously, I, like probably everyone else on this website would love LLMs to be reliable to a high degree. Just this morning I had such a good use for an LLM that I was seriously considering building (and admittedly still am pondering) but the second I started to think through the LLM faultiness, I had to consider the complexity of the safe guards and weigh if it was really better to use GPT or just write a nasty regex script and constrain the problem. I’m leaning heavily towards the latter but I’d much prefer a silver bullet if it really killed vampires. Until then (if that day ever comes), it’s lead bullets for me.</div><br/><div id="37288544" class="c"><input type="checkbox" id="c-37288544" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288357">parent</a><span>|</span><a href="#37288325">next</a><span>|</span><label class="collapse" for="c-37288544">[-]</label><label class="expand" for="c-37288544">[4 more]</label></div><br/><div class="children"><div class="content">&gt;You’re implying 100% reliability is actually attainable. If that were the case, wouldn’t that mean the halting problem would have been solved by AI? I’m not an expert but I’ve heard that’s like one of those fundamental laws of information theory that really can’t be broken.<p>Nah even 100% reliability isn&#x27;t attainable by a human. 100% obviously doesn&#x27;t imply solving the halting problem.<p>100% as in 100% as reliable as a human. Even surpassing a human. Sort of in the same way as a computer now beats humans at chess.<p>&gt;I think applying the sociology of hipster band fans to LLMs is a mistake<p>Why would it be a mistake? Human psychology is similar across all spectrums. What happens in one area is likely possible in another area. If it happens among hipster bands it can happen among hipster technology fads.<p>&gt;I think there’s a temptation to apply the analogy of something like the early internet or smartphone to LLMs but those are networked products. LLMs don’t really improve with the various applications built on top of them if the LLM is itself fundamentally broken or faulty to the point that it is unsafe to use in practice.<p>This is a valid speculation. But it&#x27;s speculation. Basically your saying that LLMs are fundamentally broken and stuck at 38% forever because of fundamental and permanent flaws. The jury on that one is still out. And your point is highly, highly speculative.<p>We see quantitative improvements on LLMs constantly AND this is a nascent technology we don&#x27;t completely understand yet. The most probably and logical conclusion is to follow the technological trendline. That trendline is pointing up.<p>To speculate on fundamental flaws of the LLM when people don&#x27;t even fully understand what&#x27;s going on with the LLM is illogical because you can&#x27;t derive conclusions from something you don&#x27;t understand. We can only generalize the trendline and constant improvements we&#x27;ve seen in AI for the past decade. Again that trendline is pointing to further break throughs in the future.<p>&gt;Obviously, I, like probably everyone else on this website would love LLMs to be reliable to a high degree.<p>No this is not obvious to me. I disagree. I think some people are like you but other people, for example Geoffrey Hinton are in the apocalyptic camp. Personally I&#x27;m in the middle, I think it could go either way. It will definitely harm a segment of our society by taking over work, but whether the benefits of AGI outweighs the harm remains to be seen.</div><br/><div id="37288714" class="c"><input type="checkbox" id="c-37288714" checked=""/><div class="controls bullet"><span class="by">jsunderland323</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288544">parent</a><span>|</span><a href="#37288325">next</a><span>|</span><label class="collapse" for="c-37288714">[-]</label><label class="expand" for="c-37288714">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not going to rebut everything but I want to point out that I think Geoffrey Hinton is way more in your camp in regards to faith in the technology (which is what we&#x27;re discussing). I&#x27;m in the camp that thinks LLMs are at best a viable competitor to furby -- I have zero existential fears and have very little confidence in them. I&#x27;m not opposed to AIs, I just think the state of the art is really really bad (sorry) and the doom and existentialism is a marketing ploy to a world imbued in conspiracy theory and institutional distrust in order to compensate for a wildly over promised and under delivered product. But hey, when you gotta raise money, you gotta raise money, and as you put it, the &quot;trend line is going up&quot; and that&#x27;s all that matters.</div><br/><div id="37290519" class="c"><input type="checkbox" id="c-37290519" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288714">parent</a><span>|</span><a href="#37291148">next</a><span>|</span><label class="collapse" for="c-37290519">[-]</label><label class="expand" for="c-37290519">[1 more]</label></div><br/><div class="children"><div class="content">Your hypothesis is &quot;our company will destroy the world&quot; is a marketing move?<p>Look. People in reality are basically <i>never</i> this gigabrained. Maybe consider as your first-line theory, that when people say &quot;AI will destroy the world&quot;, that they mean to express that they believe that AI will destroy the world?</div><br/></div></div><div id="37291148" class="c"><input type="checkbox" id="c-37291148" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288714">parent</a><span>|</span><a href="#37290519">prev</a><span>|</span><a href="#37288325">next</a><span>|</span><label class="collapse" for="c-37291148">[-]</label><label class="expand" for="c-37291148">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I&#x27;m not going to rebut everything but I want to point out that I think Geoffrey Hinton is way more in your camp in regards to faith in the technology (which is what we&#x27;re discussing). I&#x27;m in the camp that thinks LLMs are at best a viable competitor to furby<p>Your point was on whether everybody wants to see AI take over. To that Geoffrey Hinton doesn&#x27;t want AI to take over, while you do. I for one am not sure.<p>As for whether Geoffrey Hinton thinks AI is legit or not is a different story. On that topic he&#x27;s on my side, but that was besides the point I brought him up to point out that your take on &quot;everybody&quot; wanting AI to develop further is incorrect.<p>&gt; and the doom and existentialism is a marketing ploy to a world imbued in conspiracy theory and institutional distrust in order to compensate for a wildly over promised and under delivered product.<p>Other way around. With all the money and business interests going into LLMs business interests are promoting LLMs in a future that you want and that is not apocalyptic. The conspiracy theories aren&#x27;t a thing. It makes no sense as those theories don&#x27;t align with where the money is being thrown.<p>&gt;But hey, when you gotta raise money, you gotta raise money, and as you put it, the &quot;trend line is going up&quot; and that&#x27;s all that matters.<p>Bro. I am not saying &quot;trendline&quot; as if it&#x27;s something I have to keep throwing money at to support.<p>I am talking about a mathematical projection based on data. The pace of technology in the past when graphed points to an ever increasing line on a line graph. When you take the slope of that line and use it to do a quantitative prediction, that line just points up. That&#x27;s just a fact of reality. The logical outcome of the data we see.</div><br/></div></div></div></div></div></div></div></div><div id="37288325" class="c"><input type="checkbox" id="c-37288325" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288357">prev</a><span>|</span><a href="#37288176">next</a><span>|</span><label class="collapse" for="c-37288325">[-]</label><label class="expand" for="c-37288325">[4 more]</label></div><br/><div class="children"><div class="content">38%.<p>And 38% is not &quot;a third way to 100%&quot;. I&#x27;m sure you know what diminishing return is.</div><br/><div id="37288333" class="c"><input type="checkbox" id="c-37288333" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288325">parent</a><span>|</span><a href="#37288176">next</a><span>|</span><label class="collapse" for="c-37288333">[-]</label><label class="expand" for="c-37288333">[3 more]</label></div><br/><div class="children"><div class="content">my mistake. 40% of the way there, point still stands.</div><br/><div id="37288774" class="c"><input type="checkbox" id="c-37288774" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288333">parent</a><span>|</span><a href="#37288176">next</a><span>|</span><label class="collapse" for="c-37288774">[-]</label><label class="expand" for="c-37288774">[2 more]</label></div><br/><div class="children"><div class="content">&gt; point still stands<p>No?<p>I assume you actually don&#x27;t know the concept of diminishing return, and it&#x27;s totally fine. Every other comment here is explaining it to you already. I won&#x27;t bother to repeat. Please read the sibling comments carefully.</div><br/><div id="37291214" class="c"><input type="checkbox" id="c-37291214" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288774">parent</a><span>|</span><a href="#37288176">next</a><span>|</span><label class="collapse" for="c-37291214">[-]</label><label class="expand" for="c-37291214">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Hey do you know what exponential growth is?&quot; You think I just say that sentence and suddenly all your arguments are suddenly flushed down the toilet because I stated some random concept out of nowhere? Come on. You need evidence.<p>You brought up this question of diminishing returns out of nowhere and offer no evidence for it. So why would my point not stand?<p>I read the sibling comments. One person brought it up but offered no proof that this is what&#x27;s happening. Simply did what you did in a manner that was less rude, just stated the concept of diminishing returns applies to LLMs without offering a shred of evidence that indicates this is what is happening.<p>There is a difference between introducing the concept of diminishing returns out of nowhere, and providing evidence that diminishing returns is WHAT is actually HAPPENING with LLMS.<p>We&#x27;re about a year out from the introduction of chatgpt, that&#x27;s not enough time to know if all the gains in the past decade of AI has suddenly hit wall of diminishing returns.</div><br/></div></div></div></div></div></div></div></div><div id="37288176" class="c"><input type="checkbox" id="c-37288176" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288325">prev</a><span>|</span><a href="#37288084">next</a><span>|</span><label class="collapse" for="c-37288176">[-]</label><label class="expand" for="c-37288176">[3 more]</label></div><br/><div class="children"><div class="content">Except the eternal problem with all &quot;AI&quot; so far is edge cases. A product that is 90% correct may as well be useless, honestly.</div><br/><div id="37288406" class="c"><input type="checkbox" id="c-37288406" checked=""/><div class="controls bullet"><span class="by">jki275</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288176">parent</a><span>|</span><a href="#37288360">next</a><span>|</span><label class="collapse" for="c-37288406">[-]</label><label class="expand" for="c-37288406">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t argue useless, I&#x27;d argue it&#x27;s a product that still needs an expert user to validate.</div><br/></div></div><div id="37288360" class="c"><input type="checkbox" id="c-37288360" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288176">parent</a><span>|</span><a href="#37288406">prev</a><span>|</span><a href="#37288084">next</a><span>|</span><label class="collapse" for="c-37288360">[-]</label><label class="expand" for="c-37288360">[1 more]</label></div><br/><div class="children"><div class="content">Well then we are part of the way their still right?<p>It works but only edge cases are a problem. Next step is to fix the edge cases.</div><br/></div></div></div></div><div id="37288084" class="c"><input type="checkbox" id="c-37288084" checked=""/><div class="controls bullet"><span class="by">tofukant</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288176">prev</a><span>|</span><a href="#37288106">next</a><span>|</span><label class="collapse" for="c-37288084">[-]</label><label class="expand" for="c-37288084">[4 more]</label></div><br/><div class="children"><div class="content">100-62=38%</div><br/><div id="37288326" class="c"><input type="checkbox" id="c-37288326" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288084">parent</a><span>|</span><a href="#37288101">next</a><span>|</span><label class="collapse" for="c-37288326">[-]</label><label class="expand" for="c-37288326">[1 more]</label></div><br/><div class="children"><div class="content">dumb. I admit the mistake.</div><br/></div></div></div></div><div id="37288149" class="c"><input type="checkbox" id="c-37288149" checked=""/><div class="controls bullet"><span class="by">Blahah</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288106">prev</a><span>|</span><a href="#37288397">next</a><span>|</span><label class="collapse" for="c-37288149">[-]</label><label class="expand" for="c-37288149">[2 more]</label></div><br/><div class="children"><div class="content">100% - 62% = 38%</div><br/><div id="37288335" class="c"><input type="checkbox" id="c-37288335" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288149">parent</a><span>|</span><a href="#37288397">next</a><span>|</span><label class="collapse" for="c-37288335">[-]</label><label class="expand" for="c-37288335">[1 more]</label></div><br/><div class="children"><div class="content">my mistake.</div><br/></div></div></div></div><div id="37288397" class="c"><input type="checkbox" id="c-37288397" checked=""/><div class="controls bullet"><span class="by">jki275</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288029">parent</a><span>|</span><a href="#37288149">prev</a><span>|</span><a href="#37287942">next</a><span>|</span><label class="collapse" for="c-37288397">[-]</label><label class="expand" for="c-37288397">[2 more]</label></div><br/><div class="children"><div class="content">Even if it were possible to get to 100% (it isn&#x27;t), I&#x27;d still have a job.<p>It&#x27;s a great assistant.  I use it.  It&#x27;s not taking anybody&#x27;s job.</div><br/><div id="37291220" class="c"><input type="checkbox" id="c-37291220" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#37287889">root</a><span>|</span><a href="#37288397">parent</a><span>|</span><a href="#37287942">next</a><span>|</span><label class="collapse" for="c-37291220">[-]</label><label class="expand" for="c-37291220">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s taking your assistants job.</div><br/></div></div></div></div></div></div><div id="37287942" class="c"><input type="checkbox" id="c-37287942" checked=""/><div class="controls bullet"><span class="by">malux85</span><span>|</span><a href="#37287889">parent</a><span>|</span><a href="#37288029">prev</a><span>|</span><a href="#37290375">next</a><span>|</span><label class="collapse" for="c-37287942">[-]</label><label class="expand" for="c-37287942">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, {zero, one}-shot is frequently wrong, to get good results you need to ToT or GoT (Tree of thought, graph of thought) which is currently only useful in more automated codewriting systems (like I&#x27;m building with <a href="https:&#x2F;&#x2F;atomictessellator.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;atomictessellator.com</a>) and not really useful in a co-pilot scenario.</div><br/></div></div></div></div><div id="37290375" class="c"><input type="checkbox" id="c-37290375" checked=""/><div class="controls bullet"><span class="by">Denote6737</span><span>|</span><a href="#37287889">prev</a><span>|</span><a href="#37287912">next</a><span>|</span><label class="collapse" for="c-37290375">[-]</label><label class="expand" for="c-37290375">[1 more]</label></div><br/><div class="children"><div class="content">Given that chat gpt is trained on the internet. Places like Reddit.<p>Think to how many times you have seen code written with the caveat &#x27;this is a general gist. I haven&#x27;t tested this code&#x27;<p>I&#x27;ve seen it many times. More than anything else really. So it should come as no surprise that models trained on that data produce similarly wonky code.<p>This is then compounded by the fact that the user thinks of the model as they would a person. They receive a humanesqe response. So attribute the expected human backend. The understanding of the request and the feedback.<p>All current &quot;AI&quot; LLMs are just Chinese rooms.</div><br/></div></div><div id="37287912" class="c"><input type="checkbox" id="c-37287912" checked=""/><div class="controls bullet"><span class="by">rckrd</span><span>|</span><a href="#37290375">prev</a><span>|</span><a href="#37287592">next</a><span>|</span><label class="collapse" for="c-37287912">[-]</label><label class="expand" for="c-37287912">[2 more]</label></div><br/><div class="children"><div class="content">In more impressive news, &quot;38% of code generated by GPT-4 does not contain API misuses&quot;</div><br/><div id="37287972" class="c"><input type="checkbox" id="c-37287972" checked=""/><div class="controls bullet"><span class="by">mekster</span><span>|</span><a href="#37287912">parent</a><span>|</span><a href="#37287592">next</a><span>|</span><label class="collapse" for="c-37287972">[-]</label><label class="expand" for="c-37287972">[1 more]</label></div><br/><div class="children"><div class="content">Seems to be already surpassing humans.</div><br/></div></div></div></div><div id="37287592" class="c"><input type="checkbox" id="c-37287592" checked=""/><div class="controls bullet"><span class="by">floridsleeves</span><span>|</span><a href="#37287912">prev</a><span>|</span><a href="#37287841">next</a><span>|</span><label class="collapse" for="c-37287592">[-]</label><label class="expand" for="c-37287592">[1 more]</label></div><br/><div class="children"><div class="content">The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes, etc. Existing code evaluation benchmark and datasets focus on crafting small tasks such as programming questions in coding interviews, which however deviates from the problem that developers would ask LLM for real-world coding help. To fill the missing piece, researchers from UCSD propose a dataset RobustAPI for evaluating the reliability and robustness of code generated by LLMs. By collecting 1208 coding questions from StackOverflow on 24 representative Java APIs, they evaluate them on popular LLMs including GPT-3.5, GPT-4, Llama2, Vicuna. The evaluation results show that even for GPT-4, 62% of the generated code contains API misuses, which would cause severe consequences if the code is introduced into real-world software.</div><br/></div></div><div id="37287841" class="c"><input type="checkbox" id="c-37287841" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#37287592">prev</a><span>|</span><a href="#37289860">next</a><span>|</span><label class="collapse" for="c-37287841">[-]</label><label class="expand" for="c-37287841">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s more an indictment of APIs, (which fundamentally do sort of suck) than it is of, e.g. GPTs</div><br/></div></div><div id="37289860" class="c"><input type="checkbox" id="c-37289860" checked=""/><div class="controls bullet"><span class="by">zeroCalories</span><span>|</span><a href="#37287841">prev</a><span>|</span><a href="#37287839">next</a><span>|</span><label class="collapse" for="c-37289860">[-]</label><label class="expand" for="c-37289860">[1 more]</label></div><br/><div class="children"><div class="content">While I do see LLMs helping programmers a lot, I&#x27;m not super impressed by seeing it write what looks like a lot of boilerplate. If things become so common that it can be replicated by an LLM, it seems like we need to be abstracting it away.</div><br/></div></div><div id="37288409" class="c"><input type="checkbox" id="c-37288409" checked=""/><div class="controls bullet"><span class="by">earthboundkid</span><span>|</span><a href="#37287839">prev</a><span>|</span><a href="#37289665">next</a><span>|</span><label class="collapse" for="c-37288409">[-]</label><label class="expand" for="c-37288409">[1 more]</label></div><br/><div class="children"><div class="content">At least two of the four examples on <a href="https:&#x2F;&#x2F;github.com&#x2F;features&#x2F;copilot&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;features&#x2F;copilot&#x2F;</a> have API misuses.</div><br/></div></div><div id="37287950" class="c"><input type="checkbox" id="c-37287950" checked=""/><div class="controls bullet"><span class="by">progrus</span><span>|</span><a href="#37289665">prev</a><span>|</span><a href="#37287993">next</a><span>|</span><label class="collapse" for="c-37287950">[-]</label><label class="expand" for="c-37287950">[1 more]</label></div><br/><div class="children"><div class="content">So, sorta like a human, then.</div><br/></div></div><div id="37287993" class="c"><input type="checkbox" id="c-37287993" checked=""/><div class="controls bullet"><span class="by">asguy</span><span>|</span><a href="#37287950">prev</a><span>|</span><a href="#37288103">next</a><span>|</span><label class="collapse" for="c-37287993">[-]</label><label class="expand" for="c-37287993">[1 more]</label></div><br/><div class="children"><div class="content">TL;DR: Treat LLMs like undergrad interns, and you won&#x27;t be disappointed.</div><br/></div></div><div id="37288103" class="c"><input type="checkbox" id="c-37288103" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#37287993">prev</a><span>|</span><a href="#37288078">next</a><span>|</span><label class="collapse" for="c-37288103">[-]</label><label class="expand" for="c-37288103">[1 more]</label></div><br/><div class="children"><div class="content">I mean, of course?  It&#x27;s trained on real world code.  Real world code &quot;misuses&quot; APIs at, sure, a 62% rate.  Sounds roughly right to me.  Obviously there&#x27;s dithering to be done over what constitutes &quot;misuse&quot; vs. actual bugs, etc... But really this sounds unsurprising.<p>AI isn&#x27;t going to give you perfect code (or answers, or anything really).  It&#x27;s going to give you <i>typical</i> code, based on extremely broad &quot;intuition&quot; about how others (&quot;all&quot; others, really) have solved (or answered) the same problem.  And that has value.<p>But it&#x27;s not going to produce something better than the existing consensus, by definition.</div><br/></div></div><div id="37288078" class="c"><input type="checkbox" id="c-37288078" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37288103">prev</a><span>|</span><a href="#37287780">next</a><span>|</span><label class="collapse" for="c-37288078">[-]</label><label class="expand" for="c-37288078">[2 more]</label></div><br/><div class="children"><div class="content">I can guarantee you that no-one here fully trusts any LLM to write complicated bug free code without you (a human) to keep checking over it.<p>Anyone with an understanding of unexplainable black-box AIs knows that LLMs hallucinating is not <i>&#x27;the same thing as a human&#x27;</i>. Humans can be held accountable for their mistakes and can explain themselves transparently. LLMs fundamentally cannot reason or explain themselves transparently, other than rewording its original answer(s) to make themselves sound credible; like an expert sophist.<p>It goes to show that this overhyped snake-oil is now at the late stage peak of inflated expectations of the Gartner hype cycle.</div><br/><div id="37290528" class="c"><input type="checkbox" id="c-37290528" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#37288078">parent</a><span>|</span><a href="#37287780">next</a><span>|</span><label class="collapse" for="c-37290528">[-]</label><label class="expand" for="c-37290528">[1 more]</label></div><br/><div class="children"><div class="content">Of course, humans also often try to bullshit their way through wrong answers.</div><br/></div></div></div></div><div id="37287780" class="c"><input type="checkbox" id="c-37287780" checked=""/><div class="controls bullet"><span class="by">jojobas</span><span>|</span><a href="#37288078">prev</a><span>|</span><a href="#37288222">next</a><span>|</span><label class="collapse" for="c-37287780">[-]</label><label class="expand" for="c-37287780">[2 more]</label></div><br/><div class="children"><div class="content">Garbage in, garbage out. I wonder if it can contextualize the code in StackOverflow questions (i.e. why doesn&#x27;t this work?) as bad and that in highly rated answers as good, or &quot;code is code&quot;.</div><br/><div id="37287883" class="c"><input type="checkbox" id="c-37287883" checked=""/><div class="controls bullet"><span class="by">ldhough</span><span>|</span><a href="#37287780">parent</a><span>|</span><a href="#37288222">next</a><span>|</span><label class="collapse" for="c-37287883">[-]</label><label class="expand" for="c-37287883">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve noticed that one of the most common failure patterns I get from GPT4 for code generation is that it incorrectly asserts something and then corrects itself in the same response.<p>ex: &quot;This code `(some-fn 1 2)` does x because y. That is incorrect because abc&quot;<p>I wondered if this has to do with common StackOverflow post formats.</div><br/></div></div></div></div><div id="37288222" class="c"><input type="checkbox" id="c-37288222" checked=""/><div class="controls bullet"><span class="by">wesleywt</span><span>|</span><a href="#37287780">prev</a><span>|</span><a href="#37288081">next</a><span>|</span><label class="collapse" for="c-37288222">[-]</label><label class="expand" for="c-37288222">[1 more]</label></div><br/><div class="children"><div class="content">Just as AI is being overhyped. There seems to be an equally silly trend on HN to undercut its obvious and massive impact.</div><br/></div></div><div id="37288081" class="c"><input type="checkbox" id="c-37288081" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#37288222">prev</a><span>|</span><a href="#37287770">next</a><span>|</span><label class="collapse" for="c-37288081">[-]</label><label class="expand" for="c-37288081">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t care. I can easily fix them. It&#x27;s a very good debugging assistant and a very good programming assistant.</div><br/></div></div><div id="37287770" class="c"><input type="checkbox" id="c-37287770" checked=""/><div class="controls bullet"><span class="by">lgas</span><span>|</span><a href="#37288081">prev</a><span>|</span><a href="#37288210">next</a><span>|</span><label class="collapse" for="c-37287770">[-]</label><label class="expand" for="c-37287770">[5 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s already beating humans at this too?</div><br/><div id="37287821" class="c"><input type="checkbox" id="c-37287821" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#37287770">parent</a><span>|</span><a href="#37288210">next</a><span>|</span><label class="collapse" for="c-37287821">[-]</label><label class="expand" for="c-37287821">[4 more]</label></div><br/><div class="children"><div class="content">I wonder what would happen in 39 years if an AI which is designed to feel and emulate humans enters human competitions and beats them at everything.<p>Like can Liutenant Commander Data be excluded from human competitions? Yes. But can a replicant from Blade Runner? I guess the answer is that they will not feel the need to compete. But what if they do?<p>Level 1: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Measure_of_a_Man_(Star_Trek:_The_Next_Generation)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Measure_of_a_Man_(Star_T...</a><p>Level 2: <a href="https:&#x2F;&#x2F;memory-alpha.fandom.com&#x2F;wiki&#x2F;Soji_Asha" rel="nofollow noreferrer">https:&#x2F;&#x2F;memory-alpha.fandom.com&#x2F;wiki&#x2F;Soji_Asha</a></div><br/><div id="37287861" class="c"><input type="checkbox" id="c-37287861" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#37287770">root</a><span>|</span><a href="#37287821">parent</a><span>|</span><a href="#37288210">next</a><span>|</span><label class="collapse" for="c-37287861">[-]</label><label class="expand" for="c-37287861">[3 more]</label></div><br/><div class="children"><div class="content">If there&#x27;s a human only competition and the AI &quot;identifies&quot; as a human, you&#x27;d expect it still wouldn&#x27;t be let in. Anything else would be absurd, right?</div><br/><div id="37287926" class="c"><input type="checkbox" id="c-37287926" checked=""/><div class="controls bullet"><span class="by">tadfisher</span><span>|</span><a href="#37287770">root</a><span>|</span><a href="#37287861">parent</a><span>|</span><a href="#37287878">next</a><span>|</span><label class="collapse" for="c-37287926">[-]</label><label class="expand" for="c-37287926">[1 more]</label></div><br/><div class="children"><div class="content">More damning of competition as a concept than the AI, methinks.</div><br/></div></div><div id="37287878" class="c"><input type="checkbox" id="c-37287878" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#37287770">root</a><span>|</span><a href="#37287861">parent</a><span>|</span><a href="#37287926">prev</a><span>|</span><a href="#37288210">next</a><span>|</span><label class="collapse" for="c-37287878">[-]</label><label class="expand" for="c-37287878">[1 more]</label></div><br/><div class="children"><div class="content">Why not ?</div><br/></div></div></div></div></div></div></div></div><div id="37288210" class="c"><input type="checkbox" id="c-37288210" checked=""/><div class="controls bullet"><span class="by">pmcf</span><span>|</span><a href="#37287770">prev</a><span>|</span><a href="#37289627">next</a><span>|</span><label class="collapse" for="c-37288210">[-]</label><label class="expand" for="c-37288210">[1 more]</label></div><br/><div class="children"><div class="content">This link is being copied to slack channels everywhere with “I told you so” statements and something about “You kids and your GPTs” and “Back in my day”<p>Meanwhile copilot is becoming a superpower to those who figure it out.<p>And it hasn’t even been a year! I’m going to need  a lot more popcorn.</div><br/></div></div><div id="37289627" class="c"><input type="checkbox" id="c-37289627" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37288210">prev</a><span>|</span><a href="#37290231">next</a><span>|</span><label class="collapse" for="c-37289627">[-]</label><label class="expand" for="c-37289627">[2 more]</label></div><br/><div class="children"><div class="content">Proposed alternative title for this paper: A study on whether large language models generate Java code that fits our extremely specific ideas of how a small collection of APIs should have their exceptions checked.</div><br/></div></div><div id="37290231" class="c"><input type="checkbox" id="c-37290231" checked=""/><div class="controls bullet"><span class="by">nforgerit</span><span>|</span><a href="#37289627">prev</a><span>|</span><label class="collapse" for="c-37290231">[-]</label><label class="expand" for="c-37290231">[2 more]</label></div><br/><div class="children"><div class="content">I think we&#x27;re seeing a re-iteration of the last generation&#x27;s &quot;greybeards vs young hipsters&quot; wars. Last time it was &quot;those hipsters are just copy pasting stuff they find on Google and call it a day&quot;. This time the young hipsters turned greybeards undercutting the good parts of gpt or copilot.<p>That said, I&#x27;m really underwhelmed by the output of both those tools in the context of the ongoing hype. They&#x27;re far away from taking anyone&#x27;s job. They&#x27;re producing misleading and even manipulative output in such fine-granular deceiving manners, it&#x27;s like reading a whole contract in fine-print. Given that our job is already mostly reading and understanding vast amounts of code, I don&#x27;t really see a productivity boost in reading generated erroneous code. And if it boosts productivity because of boilerplate, we already have plenty of old tools to deal with that. Heck, every CRUD Framework from mid-2000s is better at generating boilerplate code, with 100% correctness.<p>So there&#x27;s no &quot;big disruptive innovation&quot; going on but new nice-to-have tools. Just know, when not to use it.</div><br/></div></div></div></div></div></div></div></body></html>