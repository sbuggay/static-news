<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725958871810" as="style"/><link rel="stylesheet" href="styles.css?v=1725958871810"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.arxiv.org/abs/2408.11039">Transfusion: Predict the next token and diffuse images with one multimodal model</a> <span class="domain">(<a href="https://www.arxiv.org">www.arxiv.org</a>)</span></div><div class="subtext"><span>fzliu</span> | <span>6 comments</span></div><br/><div><div id="41493480" class="c"><input type="checkbox" id="c-41493480" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#41495067">next</a><span>|</span><label class="collapse" for="c-41493480">[-]</label><label class="expand" for="c-41493480">[1 more]</label></div><br/><div class="children"><div class="content">This is such a natural extension to LLMs. I’m shocked it hasn’t been tried before.<p>When I ask a diffusion model to generate a chessboard, I’d expect the pieces to be placed randomly. We are getting closer to image generators that not only know what chess pieces look like but also where to place them.</div><br/></div></div><div id="41495067" class="c"><input type="checkbox" id="c-41495067" checked=""/><div class="controls bullet"><span class="by">cosmicjedi</span><span>|</span><a href="#41493480">prev</a><span>|</span><a href="#41495091">next</a><span>|</span><label class="collapse" for="c-41495067">[-]</label><label class="expand" for="c-41495067">[1 more]</label></div><br/><div class="children"><div class="content">You can talk to the authors directly on alphaXiv! <a href="https:&#x2F;&#x2F;www.alphaxiv.org&#x2F;abs&#x2F;2408.11039v1" rel="nofollow">https:&#x2F;&#x2F;www.alphaxiv.org&#x2F;abs&#x2F;2408.11039v1</a></div><br/></div></div><div id="41495091" class="c"><input type="checkbox" id="c-41495091" checked=""/><div class="controls bullet"><span class="by">BaculumMeumEst</span><span>|</span><a href="#41495067">prev</a><span>|</span><a href="#41494315">next</a><span>|</span><label class="collapse" for="c-41495091">[-]</label><label class="expand" for="c-41495091">[1 more]</label></div><br/><div class="children"><div class="content">Stupid question: is their 7B model available? Is there public inference code that we could run? Or do they not usually release them along with these kinds of papers?</div><br/></div></div><div id="41494315" class="c"><input type="checkbox" id="c-41494315" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#41495091">prev</a><span>|</span><label class="collapse" for="c-41494315">[-]</label><label class="expand" for="c-41494315">[2 more]</label></div><br/><div class="children"><div class="content">Hmm. I wonder if this is similar to Diffusion Transformers?</div><br/><div id="41494734" class="c"><input type="checkbox" id="c-41494734" checked=""/><div class="controls bullet"><span class="by">darknoon</span><span>|</span><a href="#41494315">parent</a><span>|</span><label class="collapse" for="c-41494734">[-]</label><label class="expand" for="c-41494734">[1 more]</label></div><br/><div class="children"><div class="content">this is somewhat similar, but diffusion transformers typically use a pre-trained text model as the text conditioning whereas, in this case it&#x27;s integrated and trained together multimodally.</div><br/></div></div></div></div></div></div></div></div></div></body></html>