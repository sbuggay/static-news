<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700470865350" as="style"/><link rel="stylesheet" href="styles.css?v=1700470865350"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.theverge.com/2023/11/20/23967515/sam-altman-openai-board-fired-new-ceo">Emmett Shear becomes interim OpenAI CEO as Altman talks break down</a> <span class="domain">(<a href="https://www.theverge.com">www.theverge.com</a>)</span></div><div class="subtext"><span>andsoitis</span> | <span>573 comments</span></div><br/><div><div id="38343855" class="c"><input type="checkbox" id="c-38343855" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343508">next</a><span>|</span><label class="collapse" for="c-38343855">[-]</label><label class="expand" for="c-38343855">[80 more]</label></div><br/><div class="children"><div class="content">Through all of this, no one has cogently explained why Altman leaving is such a big deal. Why would workers immediately quit their job when he has no other company, and does he even know who these workers are? Are these people <i>that</i> desperate to make a buck (or the prospect of big bucks)? It seems like half of the people working at the non-profit were not actually concerned about the mission but rather just waiting out their turn for big bucks and fame.<p>What does Altman bring to the table besides raising money from foreign governments and states, apparently? I just do not understand all of this. Like, how does him leaving and getting replaced by another CEO the next week really change anything at the ground level other than distractions from the mission being gone?<p>And the outpouring of support for someone who was clearly not operating how he marketed himself publicly is strange and disturbing indeed.</div><br/><div id="38344074" class="c"><input type="checkbox" id="c-38344074" checked=""/><div class="controls bullet"><span class="by">jmerz</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344168">next</a><span>|</span><label class="collapse" for="c-38344074">[-]</label><label class="expand" for="c-38344074">[15 more]</label></div><br/><div class="children"><div class="content">I think he&#x27;s not as known in the outside world but it&#x27;s really difficult to understate the amount of social capital sama has in the inner circles of Silicon Valley. It sounds like he did a good job instilling loyalty as a CEO as well, but the SV thing means that the more connected someone at the company is to the SV ecosystem, the more likely they like him&#x2F;want to be on his good side.<p>This is kind of like the leadership of the executive branch switching parties. You&#x27;re not going to say &quot;why would the staff immediately quit?&quot; Especially since this is corporate America, and sama can have another &quot;country&quot; next week.</div><br/><div id="38344099" class="c"><input type="checkbox" id="c-38344099" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344074">parent</a><span>|</span><a href="#38344830">next</a><span>|</span><label class="collapse" for="c-38344099">[-]</label><label class="expand" for="c-38344099">[12 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s a big deal because he has a cult of personality?</div><br/><div id="38344110" class="c"><input type="checkbox" id="c-38344110" checked=""/><div class="controls bullet"><span class="by">belugacat</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344099">parent</a><span>|</span><a href="#38344123">next</a><span>|</span><label class="collapse" for="c-38344110">[-]</label><label class="expand" for="c-38344110">[8 more]</label></div><br/><div class="children"><div class="content">It’s a big deal because he’s extremely charismatic and well connected and that matters much, much more for a tech company’s success than some programmers like to think.</div><br/><div id="38344193" class="c"><input type="checkbox" id="c-38344193" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344110">parent</a><span>|</span><a href="#38344529">next</a><span>|</span><label class="collapse" for="c-38344193">[-]</label><label class="expand" for="c-38344193">[3 more]</label></div><br/><div class="children"><div class="content">I have watched him speak, and he doesn&#x27;t seem charismatic at all. I remember hearing the same things about Sam Bankman-Fried and then going and watching his interviews and feeling the same.<p>There is just a giant gap here where I simply do not get it, and I see no evidence that explains me not getting it is missing some key aspect of all this. This just seems like classic cargo cult, cult of personality, and following money and people who think they know best</div><br/><div id="38344603" class="c"><input type="checkbox" id="c-38344603" checked=""/><div class="controls bullet"><span class="by">creshal</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344193">parent</a><span>|</span><a href="#38344294">next</a><span>|</span><label class="collapse" for="c-38344603">[-]</label><label class="expand" for="c-38344603">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s different types of charisma; some people appear extremely charismatic in person but not through a camera (there&#x27;s a bunch of politicians you could name here), and vice versa (a lot actors).</div><br/></div></div><div id="38344294" class="c"><input type="checkbox" id="c-38344294" checked=""/><div class="controls bullet"><span class="by">djokkataja</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344193">parent</a><span>|</span><a href="#38344603">prev</a><span>|</span><a href="#38344529">next</a><span>|</span><label class="collapse" for="c-38344294">[-]</label><label class="expand" for="c-38344294">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I have watched him speak, and he doesn&#x27;t seem charismatic at all.<p>Consider the relative charisma of the people <i>around</i> him, though.</div><br/></div></div></div></div><div id="38344529" class="c"><input type="checkbox" id="c-38344529" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344110">parent</a><span>|</span><a href="#38344193">prev</a><span>|</span><a href="#38344512">next</a><span>|</span><label class="collapse" for="c-38344529">[-]</label><label class="expand" for="c-38344529">[1 more]</label></div><br/><div class="children"><div class="content">I understand why this would be uniquely valuable for a startup, but why is this be uniquely valuable for MSFT? Are they planning on raising a series B next year?</div><br/></div></div><div id="38344512" class="c"><input type="checkbox" id="c-38344512" checked=""/><div class="controls bullet"><span class="by">iwsk</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344110">parent</a><span>|</span><a href="#38344529">prev</a><span>|</span><a href="#38344439">next</a><span>|</span><label class="collapse" for="c-38344512">[-]</label><label class="expand" for="c-38344512">[1 more]</label></div><br/><div class="children"><div class="content">We live in a society.</div><br/></div></div><div id="38344439" class="c"><input type="checkbox" id="c-38344439" checked=""/><div class="controls bullet"><span class="by">Solvency</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344110">parent</a><span>|</span><a href="#38344512">prev</a><span>|</span><a href="#38344794">next</a><span>|</span><label class="collapse" for="c-38344439">[-]</label><label class="expand" for="c-38344439">[1 more]</label></div><br/><div class="children"><div class="content">What am I missing here: Sam Altman has zero charisma or cool factor. Every talk I&#x27;ve seen him in, he comes off as lethargic and sluggish. I get zero sense of passion or rallying drive around the hype of AI from him. He&#x27;s not an AI visionary. He&#x27;s not a hype man. He simply &quot;is&quot;, and just because he happens to have been the CEO he&#x27;s been thrust into the spotlight, but there&#x27;s literally nothing interesting about him.</div><br/></div></div><div id="38344794" class="c"><input type="checkbox" id="c-38344794" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344110">parent</a><span>|</span><a href="#38344439">prev</a><span>|</span><a href="#38344123">next</a><span>|</span><label class="collapse" for="c-38344794">[-]</label><label class="expand" for="c-38344794">[1 more]</label></div><br/><div class="children"><div class="content">I don’t find him charismatic at all. I find Donald Trump more charismatic and I think he is the devil in disguise.</div><br/></div></div></div></div><div id="38344123" class="c"><input type="checkbox" id="c-38344123" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344099">parent</a><span>|</span><a href="#38344110">prev</a><span>|</span><a href="#38344830">next</a><span>|</span><label class="collapse" for="c-38344123">[-]</label><label class="expand" for="c-38344123">[3 more]</label></div><br/><div class="children"><div class="content">I wouldn’t call the entire YC community a cult of personality. And that’s just a subset of his network.</div><br/><div id="38344318" class="c"><input type="checkbox" id="c-38344318" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344123">parent</a><span>|</span><a href="#38344209">next</a><span>|</span><label class="collapse" for="c-38344318">[-]</label><label class="expand" for="c-38344318">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not all, but you see plenty of it here.</div><br/></div></div><div id="38344209" class="c"><input type="checkbox" id="c-38344209" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344123">parent</a><span>|</span><a href="#38344318">prev</a><span>|</span><a href="#38344830">next</a><span>|</span><label class="collapse" for="c-38344209">[-]</label><label class="expand" for="c-38344209">[1 more]</label></div><br/><div class="children"><div class="content">People see what they want to see.</div><br/></div></div></div></div></div></div><div id="38344830" class="c"><input type="checkbox" id="c-38344830" checked=""/><div class="controls bullet"><span class="by">steakscience</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344074">parent</a><span>|</span><a href="#38344099">prev</a><span>|</span><a href="#38344208">next</a><span>|</span><label class="collapse" for="c-38344830">[-]</label><label class="expand" for="c-38344830">[1 more]</label></div><br/><div class="children"><div class="content">Every SV CEO has a &quot;Sam Altman saved my butt during crucial incident X&quot; story</div><br/></div></div><div id="38344208" class="c"><input type="checkbox" id="c-38344208" checked=""/><div class="controls bullet"><span class="by">basicoperation</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344074">parent</a><span>|</span><a href="#38344830">prev</a><span>|</span><a href="#38344168">next</a><span>|</span><label class="collapse" for="c-38344208">[-]</label><label class="expand" for="c-38344208">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean “difficult to overstate”?<p>“Difficult to understate” would mean he has little to no social capital.</div><br/></div></div></div></div><div id="38344168" class="c"><input type="checkbox" id="c-38344168" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344074">prev</a><span>|</span><a href="#38344125">next</a><span>|</span><label class="collapse" for="c-38344168">[-]</label><label class="expand" for="c-38344168">[1 more]</label></div><br/><div class="children"><div class="content">Based on Andrej Karpathy&#x27;s comment on Twitter today, the board never explained any of this to the staff. So siding with Altman seems like a far better option since his return would mean a much higher likelihood of continuing business as usual.<p>If Ilya &amp; co. want the staff to side with them, they have to give a reason first. It doesn&#x27;t necessarily have to be convincing, but not giving a reason at all will never be convincing.</div><br/></div></div><div id="38344125" class="c"><input type="checkbox" id="c-38344125" checked=""/><div class="controls bullet"><span class="by">doomleika</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344168">prev</a><span>|</span><a href="#38344183">next</a><span>|</span><label class="collapse" for="c-38344125">[-]</label><label class="expand" for="c-38344125">[1 more]</label></div><br/><div class="children"><div class="content">As much as @sama is not exactly &quot;great&quot; (World Coin is...ehem). The firing reeks political strife and anyone with enough work experience knows what happens the next year at OpenAI will be anything but grandstanding for those &quot;revolutionists&quot; to stamp out any dissenting voice and fertile ground for the oppotunitists to use the chaos to make things worse. Most of the employee&#x27;s prime objective will be navigating the political shitstorm than doing their job. The chance OpenAI stay as is before ChatGPT is little to none.<p>Better run for the lifeboat before the ship hits the iceberg.</div><br/></div></div><div id="38344183" class="c"><input type="checkbox" id="c-38344183" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344125">prev</a><span>|</span><a href="#38343906">next</a><span>|</span><label class="collapse" for="c-38344183">[-]</label><label class="expand" for="c-38344183">[5 more]</label></div><br/><div class="children"><div class="content">I am so confused by how this question is asked, and the reactions.<p>It&#x27;s &quot;such a big deal&quot; because he has been leading the company, and apparently some people really like how and they really don&#x27;t like, that&#x2F;how it ended.<p>Why would it require any other explanation? Are you asking what leaders do and why an employee would care about what they do...?</div><br/><div id="38344282" class="c"><input type="checkbox" id="c-38344282" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344183">parent</a><span>|</span><a href="#38343906">next</a><span>|</span><label class="collapse" for="c-38344282">[-]</label><label class="expand" for="c-38344282">[4 more]</label></div><br/><div class="children"><div class="content">Do you understand why he was fired? The company had a charter, one the board is to help uphold. Altman and his crew were leading the company, and seemingly its employees, away from that charter. He was not open about how he was doing that. The board fired him.<p>This is like a bunch of people joining a basketball team where the coach starts turning it into a soccer team, and then the GM fires the coach for doing this and everyone calls the GM crazy and stupid. If you want to play soccer, go play soccer!<p>If you want to make a ton of money in a startup moving fast, how about don&#x27;t setup a non-profit company spouting a bunch of humanitarian shit? It&#x27;s even worse, because Altman very clearly did all this intentionally by playing the &quot;I care about humanity card&quot; just long enough while riding on the coattails of researchers where he could start up side processes to use his new AI profile to make the big bucks. But now people want to make him a martyr simply because the board called his bluff. It&#x27;s bewildering.</div><br/><div id="38344433" class="c"><input type="checkbox" id="c-38344433" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344282">parent</a><span>|</span><a href="#38344382">next</a><span>|</span><label class="collapse" for="c-38344433">[-]</label><label class="expand" for="c-38344433">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Do you understand why he was fired?<p>Do you? Because that part is way more irritating, and, honestly, starting to read your original comment I thought that was where you were going with this: <i>Why was he fired, exactly?</i><p>The way the statement was framed basically painted him a liar, in a way, so vague, that people put forth the most insane theories about why. I can sense some animosity, but do you really think it&#x27;s okay to fire <i>anyone</i> in a way, where to the outside the possible explanation ranges from a big data slip to molesting his sister?<p>Nothing has changed. That is the part that needs transparency and its lack is bewildering.</div><br/><div id="38344660" class="c"><input type="checkbox" id="c-38344660" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344433">parent</a><span>|</span><a href="#38344382">next</a><span>|</span><label class="collapse" for="c-38344660">[-]</label><label class="expand" for="c-38344660">[1 more]</label></div><br/><div class="children"><div class="content">One of the comments here had a good possible explanation which is that sharing the details might expose the board to liability since they now would have admitted that they know the details of some illicit thing Sam did, for which a lawsuit is coming.<p>For example, one scenario someone in a different thread conjectured is that Sam was secretly green-lighting the intentional (rather than incidental) collection of large amounts of copyrighted training data, exposing the firm to a great risk of a lawsuit from the media industry.<p>If he hid this from the board, “not being candid” would be the reason for his firing, but if the board admits that they know the details of the malfeasance, they could become entangled in the litigation.</div><br/></div></div></div></div><div id="38344382" class="c"><input type="checkbox" id="c-38344382" checked=""/><div class="controls bullet"><span class="by">ffgjgf1</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344282">parent</a><span>|</span><a href="#38344433">prev</a><span>|</span><a href="#38343906">next</a><span>|</span><label class="collapse" for="c-38344382">[-]</label><label class="expand" for="c-38344382">[1 more]</label></div><br/><div class="children"><div class="content">But if the board seems to be doing everything they can to make sure that longterm OpenAI wouldn’t be able to execute anything in their charter in a meaningful way (assuming they end up being left behind technologically and not that relevant) does it really make that much sense?</div><br/></div></div></div></div></div></div><div id="38343906" class="c"><input type="checkbox" id="c-38343906" checked=""/><div class="controls bullet"><span class="by">JanSt</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344183">prev</a><span>|</span><a href="#38343919">next</a><span>|</span><label class="collapse" for="c-38343906">[-]</label><label class="expand" for="c-38343906">[2 more]</label></div><br/><div class="children"><div class="content">Seems like the board wants to slow down progress which pretty much means sitting there waiting for alignment instead of putting out the work you came for. Sam will let them work to progress I guess, plus a mountain of cash&#x2F;equity for them.</div><br/></div></div><div id="38343919" class="c"><input type="checkbox" id="c-38343919" checked=""/><div class="controls bullet"><span class="by">varjag</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343906">prev</a><span>|</span><a href="#38343932">next</a><span>|</span><label class="collapse" for="c-38343919">[-]</label><label class="expand" for="c-38343919">[3 more]</label></div><br/><div class="children"><div class="content">A CEO typically builds up a network of his people within the org and if he falls hard they are next on the chopping block. Same deal as with dictators.<p>&quot;Dozens&quot; sounds like about right amount for a large org.</div><br/><div id="38344616" class="c"><input type="checkbox" id="c-38344616" checked=""/><div class="controls bullet"><span class="by">mcv</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343919">parent</a><span>|</span><a href="#38343932">next</a><span>|</span><label class="collapse" for="c-38344616">[-]</label><label class="expand" for="c-38344616">[2 more]</label></div><br/><div class="children"><div class="content">So having Altman&#x27;s loyalists leave is probably exactly what Sutskever wants?<p>Still, what do they actually want? It seems a bit overly dramatic for such an organisation.</div><br/><div id="38344955" class="c"><input type="checkbox" id="c-38344955" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344616">parent</a><span>|</span><a href="#38343932">next</a><span>|</span><label class="collapse" for="c-38344955">[-]</label><label class="expand" for="c-38344955">[1 more]</label></div><br/><div class="children"><div class="content">This is very short and explains exactly what they want: <a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a><p>I think it&#x27;s pretty obvious after reading it why people who were really committed to that Charter weren&#x27;t happy with the direction that Sam was taking the company.</div><br/></div></div></div></div></div></div><div id="38343932" class="c"><input type="checkbox" id="c-38343932" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343919">prev</a><span>|</span><a href="#38344437">next</a><span>|</span><label class="collapse" for="c-38343932">[-]</label><label class="expand" for="c-38343932">[3 more]</label></div><br/><div class="children"><div class="content">Looks like they have about 700 employees.  A handful quitting  doesn’t seem like a mutiny.</div><br/><div id="38344133" class="c"><input type="checkbox" id="c-38344133" checked=""/><div class="controls bullet"><span class="by">redlampdesk</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343932">parent</a><span>|</span><a href="#38344064">next</a><span>|</span><label class="collapse" for="c-38344133">[-]</label><label class="expand" for="c-38344133">[1 more]</label></div><br/><div class="children"><div class="content">More senior employees can easily know ~1000x more about the company than new employees. These employees are like lower branches on a tree, their knowledge crucially supporting many others. Key departures can sever entire branches.</div><br/></div></div><div id="38344064" class="c"><input type="checkbox" id="c-38344064" checked=""/><div class="controls bullet"><span class="by">zuppy</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343932">parent</a><span>|</span><a href="#38344133">prev</a><span>|</span><a href="#38344437">next</a><span>|</span><label class="collapse" for="c-38344064">[-]</label><label class="expand" for="c-38344064">[1 more]</label></div><br/><div class="children"><div class="content">yes, but although we can all be replaced in a company, some of the people can be replaced much harder. so, i wouldn’t say that the number is high but maybe (and i only speculate) some of them are key people.</div><br/></div></div></div></div><div id="38344437" class="c"><input type="checkbox" id="c-38344437" checked=""/><div class="controls bullet"><span class="by">4734573</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343932">prev</a><span>|</span><a href="#38344132">next</a><span>|</span><label class="collapse" for="c-38344437">[-]</label><label class="expand" for="c-38344437">[1 more]</label></div><br/><div class="children"><div class="content">Professionals tend to value their work in the real way of assigning value to it. So I doubt it was desperation so much as having a sense of self worth and a belief that the structure of Open-AI was largely a matter of word games the lawyers came up with.<p>As for Altman... I don&#x27;t understand what&#x27;s insignificant about raising money and resources from outside groups? Even if he wasn&#x27;t working directly on the product itself, that role is still valuable in that it means he knows the amounts of resources that kind of project will require while also commanding some amount of familiarity with how to allocate them effectively. And on top of that he seems understand how to monetize the existent product a lot better than the Ilya who mostly came out of this looking like a giant hazard for anyone who isn&#x27;t wearing rose tinted sci-fi goggles.</div><br/></div></div><div id="38344789" class="c"><input type="checkbox" id="c-38344789" checked=""/><div class="controls bullet"><span class="by">vaxman</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344132">prev</a><span>|</span><a href="#38344396">next</a><span>|</span><label class="collapse" for="c-38344789">[-]</label><label class="expand" for="c-38344789">[1 more]</label></div><br/><div class="children"><div class="content">TBH, my primary concern is this will be the catalyst for another market crash by destroying the public trust in AI, which is currently benefiting from investor FOMO.<p>Bear in mind that the cause of an equity market crash and its trigger are two different things.<p>The 2000 crash in Tech was caused by market speculation in enthusiastic dot-com companies with poor management YES, but the trigger was simply the DOJ finally making Bill throw a chair (they had enough of being humiliated by him for decades as they struggled with old mainframe tech and limited staffing).<p>If the dot-com crash trigger had not arrived for another 12-18 months, I’m sure the whole mess could have been swept under the rug by traders during the Black Swan event and the recovery of the healthy companies would have been 5-6 months, not 5-6 years (or 20 years in MSFT’s case).</div><br/></div></div><div id="38344396" class="c"><input type="checkbox" id="c-38344396" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344789">prev</a><span>|</span><a href="#38344323">next</a><span>|</span><label class="collapse" for="c-38344396">[-]</label><label class="expand" for="c-38344396">[1 more]</label></div><br/><div class="children"><div class="content">A poorly planned poorly executing of a CEO with such a high profile and so important to investors that the CEO of Microsoft is surprised, angry, and negotiating his return… is the kind of absolute chaos that I would like to avoid.  I would definitely consider quitting in that circumstance.<p>I would think to myself, what if management ever had a small disagreement with me?<p>I quit a line cook job once in a very similar circumstance scaled down to a small restaurant.  The inexperienced owners were making chaotic decisions and fired the chef and I quit the same day, not out of any kind of particular loyalty or anger, I just declined the chaos of the situation. Quitting before the chaos hurt me or my reputation by getting mixed up in it… to move on to other things.</div><br/></div></div><div id="38344323" class="c"><input type="checkbox" id="c-38344323" checked=""/><div class="controls bullet"><span class="by">3cats-in-a-coat</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344396">prev</a><span>|</span><a href="#38343967">next</a><span>|</span><label class="collapse" for="c-38344323">[-]</label><label class="expand" for="c-38344323">[2 more]</label></div><br/><div class="children"><div class="content">The new CEO, (Emmett, not Mura, who was CEO for two days I guess) has publicly stated on multiple occasions &quot;we need to slow down from a 10 to a 1-2&quot;. Ilya is also in favor of dramatically &quot;slowing down&quot;. That&#x27;s who&#x27;s left in this company, running it.<p>In the field of AI, right now, &quot;slowing down&quot; is like deciding to stop the car and walk the track by foot in the middle of a Formula 1 race. It&#x27;s like going backwards.<p>Unless things change from the current status quo, OpenAI will be irrelevant in less than 2 years. And of course many will quit such a company and go work somewhere where the CEO wants to innovate, not slow down.</div><br/><div id="38344854" class="c"><input type="checkbox" id="c-38344854" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344323">parent</a><span>|</span><a href="#38343967">next</a><span>|</span><label class="collapse" for="c-38344854">[-]</label><label class="expand" for="c-38344854">[1 more]</label></div><br/><div class="children"><div class="content">Well many of the top researches in the world seem keen for a slow down so I’m not sure you’re right. You can’t force people to work on things at a pace they’re uncomfortable with.</div><br/></div></div></div></div><div id="38343967" class="c"><input type="checkbox" id="c-38343967" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344323">prev</a><span>|</span><a href="#38344029">next</a><span>|</span><label class="collapse" for="c-38343967">[-]</label><label class="expand" for="c-38343967">[8 more]</label></div><br/><div class="children"><div class="content">The board fired Altman for shipping too fast compared to their safety-ist doom preferences. The new interim CEO has said that he wants to slow AI development down 80-90%. Why on earth would you stay, <i>if you joined to build + ship technology?</i><p>Of course, some employees may agree with the doom&#x2F;safety board ideology, and will no doubt stay. But I highly doubt everyone will, especially the researchers who were working on new, powerful models — many of them view this as their life&#x27;s work. Sam offers them the ability to continue.<p>If you think this is about &quot;the big bucks&quot; or &quot;fame,&quot; I think you don&#x27;t understand the people on the other side of this argument at all.</div><br/><div id="38344158" class="c"><input type="checkbox" id="c-38344158" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343967">parent</a><span>|</span><a href="#38344050">next</a><span>|</span><label class="collapse" for="c-38344158">[-]</label><label class="expand" for="c-38344158">[3 more]</label></div><br/><div class="children"><div class="content">This is exactly why you would want people on the board who understand the technology. Unless they have some other technology that we don&#x27;t know about, that maybe brought all this on, a GPT is not a clear path to AGI. That is a technical thing that to understand seems to be beyond most people without real experience in the field. It is certainly beyond the understanding of some dude that lucked into a great training set and became an expert, much the same way the The Knack became industry leaders.</div><br/><div id="38344259" class="c"><input type="checkbox" id="c-38344259" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344158">parent</a><span>|</span><a href="#38344050">next</a><span>|</span><label class="collapse" for="c-38344259">[-]</label><label class="expand" for="c-38344259">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Unless they have some other technology that we don&#x27;t know about, that maybe brought all this on, a GPT is not a clear path to AGI.<p>So Ilya Sutskever, one of the most distinguished ML researchers of his generation does not understand the technology ?<p>The same guy who&#x27;s been on record saying LLMs are enough for AGI ?</div><br/><div id="38345088" class="c"><input type="checkbox" id="c-38345088" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344259">parent</a><span>|</span><a href="#38344050">next</a><span>|</span><label class="collapse" for="c-38345088">[-]</label><label class="expand" for="c-38345088">[1 more]</label></div><br/><div class="children"><div class="content">To be clear, he thinks that LLMs are probably a general architecture, and thus capable of reaching AGI in principle with enormous amounts of compute, data, and work. He thinks for cost and economics reasons it&#x27;s much more feasible to build or train other parts and have them work together, because that&#x27;s much cheaper in terms of compute. As an example, with a big enough model, enough work, and the right mix of data you could probably have an LMM interpret speech just as well as Whisper can. But how much work does it take to make that happen without losing other capabilities? How efficient is the resulting huge model? Is the end result better than having the text&#x2F;intelligence segment separate from the speech and hearing segment? The answer could be yes, depending, but it could also be no. Basically his beliefs are that it&#x27;s complicated and it&#x27;s not really a &quot;Can X architecture do this&quot; question but a &quot;How cheap is this architecture to accomplish this task&quot; question.</div><br/></div></div></div></div></div></div><div id="38344050" class="c"><input type="checkbox" id="c-38344050" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343967">parent</a><span>|</span><a href="#38344158">prev</a><span>|</span><a href="#38344029">next</a><span>|</span><label class="collapse" for="c-38344050">[-]</label><label class="expand" for="c-38344050">[4 more]</label></div><br/><div class="children"><div class="content">Not enough people understand what OpenAI was actually built on.<p>OpenAI would not exist if FAANG had been capable of getting out of it&#x27;s own way and shipping things. The moment OpenAI starts acting like the companies these people left, it&#x27;s a no brainer that they&#x27;ll start looking for the door.<p>I&#x27;m sure Ilya has 10 lifetimes more knowledge than me locked away in his mind on topics I don&#x27;t even know exist... but the last 72 hours are the most brain dead actions I&#x27;ve ever seen out of the leadership of a company.<p>This isn&#x27;t even cutting your own nose of to spite the face: this is like slashing your own tires to avoid going in the wrong direction.<p>The only possible justification would have been some jailable offense from Sam Altman, and ironically their initial release almost seemed to want to hint that before they were forced to explicitly state that wasn&#x27;t the case. At the point where you&#x27;re forced to admit you surprise fired your CEO for relatively benign reasons how much must have gone completely sideways to land you in that position?</div><br/><div id="38344164" class="c"><input type="checkbox" id="c-38344164" checked=""/><div class="controls bullet"><span class="by">jonbell</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344050">parent</a><span>|</span><a href="#38344206">next</a><span>|</span><label class="collapse" for="c-38344164">[-]</label><label class="expand" for="c-38344164">[1 more]</label></div><br/><div class="children"><div class="content">It’s possible be extremely smart in one narrow way and a complete idiot when it comes to understanding leadership, people, politics, etc.<p>For example, Elon Musk was smart enough to do some things … then he crashed and burned with Twitter because it’s about people and politics. He could not have done a worse job, despite being “smart.”</div><br/></div></div><div id="38344206" class="c"><input type="checkbox" id="c-38344206" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344050">parent</a><span>|</span><a href="#38344164">prev</a><span>|</span><a href="#38344029">next</a><span>|</span><label class="collapse" for="c-38344206">[-]</label><label class="expand" for="c-38344206">[2 more]</label></div><br/><div class="children"><div class="content">I really hope this comes back around and bites Ilya and OAI in the ass. What an absurd decision. They will rightfully get absolutely crushed by the free market.</div><br/><div id="38344872" class="c"><input type="checkbox" id="c-38344872" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344206">parent</a><span>|</span><a href="#38344029">next</a><span>|</span><label class="collapse" for="c-38344872">[-]</label><label class="expand" for="c-38344872">[1 more]</label></div><br/><div class="children"><div class="content">Looks like you got your wish earlier than anyone would have expected: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726509045803336122" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726509045803336122</a></div><br/></div></div></div></div></div></div></div></div><div id="38344029" class="c"><input type="checkbox" id="c-38344029" checked=""/><div class="controls bullet"><span class="by">fevangelou</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343967">prev</a><span>|</span><a href="#38344150">next</a><span>|</span><label class="collapse" for="c-38344029">[-]</label><label class="expand" for="c-38344029">[7 more]</label></div><br/><div class="children"><div class="content">100% spot on.<p>The world is filled with Sam Altmans, but surely not enough Ilya Sutskevers.</div><br/><div id="38344067" class="c"><input type="checkbox" id="c-38344067" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344029">parent</a><span>|</span><a href="#38344163">next</a><span>|</span><label class="collapse" for="c-38344067">[-]</label><label class="expand" for="c-38344067">[5 more]</label></div><br/><div class="children"><div class="content">Was Sutskever really that instrumental to OpenAI&#x27;s success, if it was at all possible for him to be surprised at the direction the company is taking. It doesn&#x27;t seem that he is that involved in the day-to-day operations.</div><br/><div id="38344200" class="c"><input type="checkbox" id="c-38344200" checked=""/><div class="controls bullet"><span class="by">fredoliveira</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344067">parent</a><span>|</span><a href="#38344138">next</a><span>|</span><label class="collapse" for="c-38344200">[-]</label><label class="expand" for="c-38344200">[2 more]</label></div><br/><div class="children"><div class="content">Anyone asking this question has never gone through Ilya&#x27;s achievements. He is quite brilliant, and clearly instrumental here. And Sam is amazing in his own way too, for sure.</div><br/><div id="38344264" class="c"><input type="checkbox" id="c-38344264" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344200">parent</a><span>|</span><a href="#38344138">next</a><span>|</span><label class="collapse" for="c-38344264">[-]</label><label class="expand" for="c-38344264">[1 more]</label></div><br/><div class="children"><div class="content">I understand his achievements, but is he involved right now? Does he, nowadays, provide to the company anything other than his oversight?</div><br/></div></div></div></div><div id="38344138" class="c"><input type="checkbox" id="c-38344138" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344067">parent</a><span>|</span><a href="#38344200">prev</a><span>|</span><a href="#38344163">next</a><span>|</span><label class="collapse" for="c-38344138">[-]</label><label class="expand" for="c-38344138">[2 more]</label></div><br/><div class="children"><div class="content">Is operations responsible for their success? Or is it rather their technology?</div><br/><div id="38344212" class="c"><input type="checkbox" id="c-38344212" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344138">parent</a><span>|</span><a href="#38344163">next</a><span>|</span><label class="collapse" for="c-38344212">[-]</label><label class="expand" for="c-38344212">[1 more]</label></div><br/><div class="children"><div class="content">I understand that we was instrumental in the earlier days, but does it seem like he is involved in the day-to-day work on the technology, today? When the new CEO advocates for a near-pause in AI development, does he mean operations?</div><br/></div></div></div></div></div></div><div id="38344163" class="c"><input type="checkbox" id="c-38344163" checked=""/><div class="controls bullet"><span class="by">AbrahamParangi</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344029">parent</a><span>|</span><a href="#38344067">prev</a><span>|</span><a href="#38344150">next</a><span>|</span><label class="collapse" for="c-38344163">[-]</label><label class="expand" for="c-38344163">[1 more]</label></div><br/><div class="children"><div class="content">This is deeply wrong. Just because you don’t see what’s special about him doesn’t mean he isn’t a rare talent.</div><br/></div></div></div></div><div id="38344150" class="c"><input type="checkbox" id="c-38344150" checked=""/><div class="controls bullet"><span class="by">spoonjim</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344029">prev</a><span>|</span><a href="#38343970">next</a><span>|</span><label class="collapse" for="c-38344150">[-]</label><label class="expand" for="c-38344150">[1 more]</label></div><br/><div class="children"><div class="content">He is the CEO! He sets the entire agenda for the company. Of course he is important - how could he not be?</div><br/></div></div><div id="38343970" class="c"><input type="checkbox" id="c-38343970" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344150">prev</a><span>|</span><a href="#38344076">next</a><span>|</span><label class="collapse" for="c-38343970">[-]</label><label class="expand" for="c-38343970">[16 more]</label></div><br/><div class="children"><div class="content">&gt; Why would workers immediately quit their job when he has no other company<p>It is Sam Altman. He will have one in a week.<p>&gt;  It seems like half of the people working at the non-profit were not actually concerned about the mission but rather just waiting out their turn for big bucks and fame.<p>I would imagine most employees at any organization are not really there because of corporate values, but their own interests.<p>&gt; What does Altman bring to the table besides raising money from foreign governments and states, apparently?<p>And one of the world&#x27;s largest tech corporations. If you are interested in the money side, that isn&#x27;t something to take lightly.<p>So I would bet it is just following the money, or at least the expected money.<p>The new board also wants to slow development. That isn&#x27;t very exciting either.</div><br/><div id="38344139" class="c"><input type="checkbox" id="c-38344139" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343970">parent</a><span>|</span><a href="#38344046">next</a><span>|</span><label class="collapse" for="c-38344139">[-]</label><label class="expand" for="c-38344139">[3 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; Why would workers immediately quit their job when he has no other company<p>&gt; It is Sam Altman. He will have one in a week.<p>His previous companies were Loopt and Worldcoin. Won&#x27;t his next venture require finding someone else to piggyback off of?<p>&gt; If you are interested in the money side, that isn&#x27;t something to take lightly.<p>I am interested in how taking billions from foreign companies and states could lead to national security and conflict of interest problems.<p>&gt; The new board also wants to slow development.<p>It&#x27;s not a new board as far as I know.</div><br/><div id="38344191" class="c"><input type="checkbox" id="c-38344191" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344139">parent</a><span>|</span><a href="#38344046">next</a><span>|</span><label class="collapse" for="c-38344191">[-]</label><label class="expand" for="c-38344191">[2 more]</label></div><br/><div class="children"><div class="content">His previous ventures don&#x27;t matter. If he seeks funding, whether millions or billions, he will get it. Period. I don&#x27;t know how people can reasonably argue that he will have a hard time raising money for a new AI startup along with Greg.<p>It&#x27;s not a new board, but it&#x27;s the time when the board decided to assert their power and make their statement&#x2F;vision clear.</div><br/><div id="38344359" class="c"><input type="checkbox" id="c-38344359" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344191">parent</a><span>|</span><a href="#38344046">next</a><span>|</span><label class="collapse" for="c-38344359">[-]</label><label class="expand" for="c-38344359">[1 more]</label></div><br/><div class="children"><div class="content">So Sam and Greg are going to invent some new thing out of thin air in a matter of days? Or will they attach themselves to something else, like I implied? Or take on millions of dollars of funding to &quot;figure it out&quot;?</div><br/></div></div></div></div></div></div><div id="38344046" class="c"><input type="checkbox" id="c-38344046" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343970">parent</a><span>|</span><a href="#38344139">prev</a><span>|</span><a href="#38344076">next</a><span>|</span><label class="collapse" for="c-38344046">[-]</label><label class="expand" for="c-38344046">[12 more]</label></div><br/><div class="children"><div class="content">&gt; It is Sam Altman. He will have one in a week.<p>Welcome to Cargo Cult AI.</div><br/><div id="38344078" class="c"><input type="checkbox" id="c-38344078" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344046">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344078">[-]</label><label class="expand" for="c-38344078">[10 more]</label></div><br/><div class="children"><div class="content">What&#x27;s wrong with that statement though?<p>It&#x27;s the AI era - VCs are going crazy funding AI startups. What makes you think Greg and Sam would have a hard time raising millions&#x2F;billions and starting a new company in a week if they want to?</div><br/><div id="38344148" class="c"><input type="checkbox" id="c-38344148" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344078">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344148">[-]</label><label class="expand" for="c-38344148">[9 more]</label></div><br/><div class="children"><div class="content">How will they come up with the idea? One is an investor and the other is an infrastructure software engineer.</div><br/><div id="38344211" class="c"><input type="checkbox" id="c-38344211" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344148">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344211">[-]</label><label class="expand" for="c-38344211">[8 more]</label></div><br/><div class="children"><div class="content">What idea are you talking about? They are not your classic founders coming up with an idea to join Y combinator. They build OpenAI for many years, they know what to do.<p>It won&#x27;t be hard for them to hire researchers and engineers, from OpenAI or other places.<p>Questions like this makes me wonder if you are a troll. I won&#x27;t continue this thread.</div><br/><div id="38344252" class="c"><input type="checkbox" id="c-38344252" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344211">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344252">[-]</label><label class="expand" for="c-38344252">[7 more]</label></div><br/><div class="children"><div class="content">Being able to hire researchers and, even the top talent doesn&#x27;t guarantee that they&#x27;ll be the top company or even succeed at what they&#x27;re building.<p>This is what I referred as &quot;Cargo Cult AI&quot;. You can get the money, but money is not the only ingredient needed to make things happen.<p>edit: Looks like they won&#x27;t have a brand new company next week, but joining an existing one.</div><br/><div id="38344833" class="c"><input type="checkbox" id="c-38344833" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344252">parent</a><span>|</span><a href="#38344346">next</a><span>|</span><label class="collapse" for="c-38344833">[-]</label><label class="expand" for="c-38344833">[1 more]</label></div><br/><div class="children"><div class="content">Case in point: Google and Bard.</div><br/></div></div><div id="38344346" class="c"><input type="checkbox" id="c-38344346" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344252">parent</a><span>|</span><a href="#38344833">prev</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344346">[-]</label><label class="expand" for="c-38344346">[5 more]</label></div><br/><div class="children"><div class="content">Nothing can guarantee that. Investors always accept risk.<p>He has a better chance than some other random guy who was not the CEO of OpenAI.</div><br/><div id="38344657" class="c"><input type="checkbox" id="c-38344657" checked=""/><div class="controls bullet"><span class="by">mcv</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344346">parent</a><span>|</span><a href="#38344522">next</a><span>|</span><label class="collapse" for="c-38344657">[-]</label><label class="expand" for="c-38344657">[1 more]</label></div><br/><div class="children"><div class="content">&gt; He has a better chance than some other random guy who was not the CEO of OpenAI.<p>Yes, but that doesn&#x27;t mean it&#x27;s enough. Not every random guy who wasn&#x27;t the CEO of OpenAI is about to start an AI company (though some probably are).<p>It&#x27;s quite possible an AI company does need a better vision than &quot;hire some engineers and have them make AI&quot;.</div><br/></div></div><div id="38344522" class="c"><input type="checkbox" id="c-38344522" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344346">parent</a><span>|</span><a href="#38344657">prev</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344522">[-]</label><label class="expand" for="c-38344522">[3 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s see whether Satya Nadella&#x27;s bet on that risk will pay or not. Chance is a &quot;biased random&quot; in the real world. Let&#x27;s see whether his bias is strong enough to make a difference.</div><br/><div id="38344608" class="c"><input type="checkbox" id="c-38344608" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344522">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344608">[-]</label><label class="expand" for="c-38344608">[2 more]</label></div><br/><div class="children"><div class="content">Are you talking about OpenAI or about Sam Altman&#x27;s hypothetical new company?<p>OpenAI already had the best technology fully developed and in production when Microsoft invested in them.<p>I believe &quot;cargo cult&quot; means something quite different to how you&#x27;re using it.<p>It&#x27;s not &quot;cargo cult&quot; to consider someone&#x27;s CV when you hire them for a new job. Sam Altman ran a successful AI company before and he most likely can do it again if provided enough support and resources.</div><br/><div id="38344975" class="c"><input type="checkbox" id="c-38344975" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344608">parent</a><span>|</span><a href="#38344126">next</a><span>|</span><label class="collapse" for="c-38344975">[-]</label><label class="expand" for="c-38344975">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Are you talking about OpenAI or about Sam Altman&#x27;s hypothetical new company?<p>About him and Greg joining to Microsoft.<p>&gt; I believe &quot;cargo cult&quot; means something quite different to how you&#x27;re using it.<p>I don&#x27;t think so.<p>Tribes believed that building wooden air strips or planes would bring the goods they have seen during wartime.<p>People believe that bringing Altman will bring the same thing (OpenAI <i>as is</i>) <i>exactly where it&#x27;s left off</i>.<p>Altman is just tip of the iceberg. Might have some catalyst inside him, but he&#x27;s not the research itself or the researcher himself.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38344126" class="c"><input type="checkbox" id="c-38344126" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344046">parent</a><span>|</span><a href="#38344078">prev</a><span>|</span><a href="#38344076">next</a><span>|</span><label class="collapse" for="c-38344126">[-]</label><label class="expand" for="c-38344126">[1 more]</label></div><br/><div class="children"><div class="content">All the more reason he will have one within a week. All sorts of people are raising millions for AI. One of the creators of modern startup venture capital who is buddies with many of the creators of modern startup venture capital as well as the CEOs of the major tech companies is unlikely to struggle here.</div><br/></div></div></div></div></div></div><div id="38344076" class="c"><input type="checkbox" id="c-38344076" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343970">prev</a><span>|</span><a href="#38343960">next</a><span>|</span><label class="collapse" for="c-38344076">[-]</label><label class="expand" for="c-38344076">[1 more]</label></div><br/><div class="children"><div class="content">It is likely that wherever Altman goes next, @gdb would follow, and _he_ is deeply loved by many at OAI (but so is Altman).<p>CEOs should be judged by their vision for the company, their ability to execute on that vision, bringing in funding, and building the best executive team for that job. That is what Altman brings to the table.<p>You make it seem that wanting to make money is a zero-sum game, which is a narrow view to take - you can be heavily emotionally and intellectually invested in what you do for a living and wanting to be financially independent at the same time. You also appear to find it “disturbing” that people support someone that is doing a good job - there has always been a difference between marketing and operations, and it is rather weird you find that disturbing - and appreciate stability, or love working for a team that gets shit done.<p>To address your initial strawman, why would workers quit when the boss leaves? Besides all the normal reasons listed above, they also might not like the remaining folks, or they may have lost faith in those folks, given the epic clusterfuck they turned this whole thing into. All other issues aside, if I would see my leadership team fuck up this badly, on so many levels, i’d be getting right out of dodge.<p>These are all common sense, adult considerations for anyone that has an IQ and age above room temperature and that has held down a job that has to pay the bills, and combining that with your general tone of voice, I’m going to take a wild leap here and posit that you may not be asking these questions in good faith.</div><br/></div></div><div id="38343960" class="c"><input type="checkbox" id="c-38343960" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38344076">prev</a><span>|</span><a href="#38343864">next</a><span>|</span><label class="collapse" for="c-38343960">[-]</label><label class="expand" for="c-38343960">[4 more]</label></div><br/><div class="children"><div class="content">&lt;deleted&gt;</div><br/><div id="38343984" class="c"><input type="checkbox" id="c-38343984" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343960">parent</a><span>|</span><a href="#38344192">next</a><span>|</span><label class="collapse" for="c-38343984">[-]</label><label class="expand" for="c-38343984">[1 more]</label></div><br/><div class="children"><div class="content">&gt;why else would they bring a hyper-capitalist like Sam Altman on board<p>They didn&#x27;t &quot;bring&quot; a hyper capitalist. Sam Co-founded this entire thing lol. He was there from the beginning.</div><br/></div></div><div id="38344192" class="c"><input type="checkbox" id="c-38344192" checked=""/><div class="controls bullet"><span class="by">krystianantoni</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343960">parent</a><span>|</span><a href="#38343984">prev</a><span>|</span><a href="#38344005">next</a><span>|</span><label class="collapse" for="c-38344192">[-]</label><label class="expand" for="c-38344192">[1 more]</label></div><br/><div class="children"><div class="content">He is the one of two original founders :)</div><br/></div></div><div id="38344005" class="c"><input type="checkbox" id="c-38344005" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343960">parent</a><span>|</span><a href="#38344192">prev</a><span>|</span><a href="#38343864">next</a><span>|</span><label class="collapse" for="c-38344005">[-]</label><label class="expand" for="c-38344005">[1 more]</label></div><br/><div class="children"><div class="content">Who among the founders isn&#x27;t a hyper-capitalist? Elon Musk? Peter Thiel? Reid Hoffman?</div><br/></div></div></div></div><div id="38343864" class="c"><input type="checkbox" id="c-38343864" checked=""/><div class="controls bullet"><span class="by">lazystar</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343960">prev</a><span>|</span><a href="#38344147">next</a><span>|</span><label class="collapse" for="c-38343864">[-]</label><label class="expand" for="c-38343864">[5 more]</label></div><br/><div class="children"><div class="content">stability.</div><br/><div id="38343892" class="c"><input type="checkbox" id="c-38343892" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343864">parent</a><span>|</span><a href="#38344147">next</a><span>|</span><label class="collapse" for="c-38343892">[-]</label><label class="expand" for="c-38343892">[4 more]</label></div><br/><div class="children"><div class="content">But Altman, the ousted CEO, appears to have been adding to the instability. His firing seems like a step in getting back to a desired stability.</div><br/><div id="38344149" class="c"><input type="checkbox" id="c-38344149" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38343892">parent</a><span>|</span><a href="#38344017">prev</a><span>|</span><a href="#38344147">next</a><span>|</span><label class="collapse" for="c-38344149">[-]</label><label class="expand" for="c-38344149">[2 more]</label></div><br/><div class="children"><div class="content">Can you, you know, bring facts and data to this discussion, as opposed to vague handwaving of weird accusations? Altman has been doing an amazing job at running the business he co-founded, and “instability” isn’t something _anyone_ at any side of the discussion is accusing him of.<p>What is this instability, in your view? And how is this “desired stability” going to come back?</div><br/><div id="38344434" class="c"><input type="checkbox" id="c-38344434" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343855">root</a><span>|</span><a href="#38344149">parent</a><span>|</span><a href="#38344147">next</a><span>|</span><label class="collapse" for="c-38344434">[-]</label><label class="expand" for="c-38344434">[1 more]</label></div><br/><div class="children"><div class="content">What discussion, specifically, as you&#x27;re just joining in here?<p>If a CEO of a non-profit is raising billions of dollars from foreign companies and states to create a product that he will then sell to the non-profit he is CEO of, I view that as adding instability to the non-profit given its original mission. Because that mission wasn&#x27;t to create a market for the CEO to take advantage of for personal gain.</div><br/></div></div></div></div></div></div></div></div><div id="38344147" class="c"><input type="checkbox" id="c-38344147" checked=""/><div class="controls bullet"><span class="by">AbrahamParangi</span><span>|</span><a href="#38343855">parent</a><span>|</span><a href="#38343864">prev</a><span>|</span><a href="#38343508">next</a><span>|</span><label class="collapse" for="c-38344147">[-]</label><label class="expand" for="c-38344147">[1 more]</label></div><br/><div class="children"><div class="content">This is worse than firing Jobs, at least when they fired him it was for poor performance not “doing too good a job”.</div><br/></div></div></div></div><div id="38343508" class="c"><input type="checkbox" id="c-38343508" checked=""/><div class="controls bullet"><span class="by">mfiguiere</span><span>|</span><a href="#38343855">prev</a><span>|</span><a href="#38343644">next</a><span>|</span><label class="collapse" for="c-38343508">[-]</label><label class="expand" for="c-38343508">[43 more]</label></div><br/><div class="children"><div class="content">TheInformation: Dozens of Staffers Quit OpenAI After Sutskever Says Altman Won’t Return<p>&gt;Dozens of OpenAI staffers internally announced they were quitting the company Sunday night, said a person with knowledge of the situation, after board director and chief scientist Ilya Sutskever told employees that fired CEO Sam Altman would not return.<p><a href="https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;dozens-of-staffers-quit-openai-after-sutskever-says-altman-wont-return" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;dozens-of-staffers-q...</a></div><br/><div id="38343763" class="c"><input type="checkbox" id="c-38343763" checked=""/><div class="controls bullet"><span class="by">chimney</span><span>|</span><a href="#38343508">parent</a><span>|</span><a href="#38343638">next</a><span>|</span><label class="collapse" for="c-38343763">[-]</label><label class="expand" for="c-38343763">[10 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this expected? Nearly everyone who joined post ChatGPT was primarily financially motivated. What is more interesting is how many of the core research team stays.</div><br/><div id="38343939" class="c"><input type="checkbox" id="c-38343939" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343763">parent</a><span>|</span><a href="#38344312">next</a><span>|</span><label class="collapse" for="c-38343939">[-]</label><label class="expand" for="c-38343939">[3 more]</label></div><br/><div class="children"><div class="content">This is actually pretty surprising to me, since a financially motivated person would normally wait until a better deal, and just collect their paycheck in the meantime.<p>There&#x27;s also no guarantee that Altman will really start a new company, or be able to collect funding to hire everyone quickly. I wonder if these people are just very loyal to Sam.</div><br/><div id="38344008" class="c"><input type="checkbox" id="c-38344008" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343939">parent</a><span>|</span><a href="#38344055">next</a><span>|</span><label class="collapse" for="c-38344008">[-]</label><label class="expand" for="c-38344008">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is actually pretty surprising to me, since a financially motivated person would normally wait until a better deal, and just collect their paycheck in the meantime.<p>I imagine you need to signal that you want in on the deal by departing. Get founder equity.</div><br/></div></div><div id="38344055" class="c"><input type="checkbox" id="c-38344055" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343939">parent</a><span>|</span><a href="#38344008">prev</a><span>|</span><a href="#38344312">next</a><span>|</span><label class="collapse" for="c-38344055">[-]</label><label class="expand" for="c-38344055">[1 more]</label></div><br/><div class="children"><div class="content">Or they could be loyal to the e&#x2F;acc cult.</div><br/></div></div></div></div><div id="38344312" class="c"><input type="checkbox" id="c-38344312" checked=""/><div class="controls bullet"><span class="by">exizt88</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343763">parent</a><span>|</span><a href="#38343939">prev</a><span>|</span><a href="#38343876">next</a><span>|</span><label class="collapse" for="c-38344312">[-]</label><label class="expand" for="c-38344312">[1 more]</label></div><br/><div class="children"><div class="content">How do you know that? Maybe they wanted to ship AI products at an unprecedented speed at the most prestigious AI company in the world.</div><br/></div></div><div id="38343876" class="c"><input type="checkbox" id="c-38343876" checked=""/><div class="controls bullet"><span class="by">quietthrow</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343763">parent</a><span>|</span><a href="#38344312">prev</a><span>|</span><a href="#38343638">next</a><span>|</span><label class="collapse" for="c-38343876">[-]</label><label class="expand" for="c-38343876">[5 more]</label></div><br/><div class="children"><div class="content">This. Very accurate. At the end of they day this is a battle between academics and capitalists and what they stand for. We generally know how this typically goes…</div><br/><div id="38344035" class="c"><input type="checkbox" id="c-38344035" checked=""/><div class="controls bullet"><span class="by">simseye</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343876">parent</a><span>|</span><a href="#38343952">next</a><span>|</span><label class="collapse" for="c-38344035">[-]</label><label class="expand" for="c-38344035">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see many academics indulge in sensationalist doomsaying. That&#x27;s the real difference here. SETI wouldn&#x27;t and couldn&#x27;t seek grants by proposing to contact murderous aliens.<p>I think academics have a general faith in goodwill of intelligence.Benevolence may be a convergent phenomenon. Maybe the mechanisms of reason themselves require empathy and goodness</div><br/><div id="38344062" class="c"><input type="checkbox" id="c-38344062" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38344035">parent</a><span>|</span><a href="#38343952">next</a><span>|</span><label class="collapse" for="c-38344062">[-]</label><label class="expand" for="c-38344062">[2 more]</label></div><br/><div class="children"><div class="content">Huh? There&#x27;s plenty of AI doomerism amongst academics, see Bengio, Hinton, etc...</div><br/><div id="38344272" class="c"><input type="checkbox" id="c-38344272" checked=""/><div class="controls bullet"><span class="by">simseye</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38344062">parent</a><span>|</span><a href="#38343952">next</a><span>|</span><label class="collapse" for="c-38344272">[-]</label><label class="expand" for="c-38344272">[1 more]</label></div><br/><div class="children"><div class="content">Hinton makes cliched statements as if he&#x27;s not given much thought to safety but feels obliged for whatever reason</div><br/></div></div></div></div></div></div><div id="38343952" class="c"><input type="checkbox" id="c-38343952" checked=""/><div class="controls bullet"><span class="by">irrational</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343876">parent</a><span>|</span><a href="#38344035">prev</a><span>|</span><a href="#38343638">next</a><span>|</span><label class="collapse" for="c-38343952">[-]</label><label class="expand" for="c-38343952">[1 more]</label></div><br/><div class="children"><div class="content">The capitalists run it into the ground while the academics stand around confused asking each other what happened?</div><br/></div></div></div></div></div></div><div id="38343638" class="c"><input type="checkbox" id="c-38343638" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38343508">parent</a><span>|</span><a href="#38343763">prev</a><span>|</span><a href="#38343635">next</a><span>|</span><label class="collapse" for="c-38343638">[-]</label><label class="expand" for="c-38343638">[4 more]</label></div><br/><div class="children"><div class="content">Does anyone have a non-paywall version of this? Or like excerpts from the article?</div><br/><div id="38343816" class="c"><input type="checkbox" id="c-38343816" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343638">parent</a><span>|</span><a href="#38343635">next</a><span>|</span><label class="collapse" for="c-38343816">[-]</label><label class="expand" for="c-38343816">[3 more]</label></div><br/><div class="children"><div class="content">The information is a 300 dollar annual subscription, I don’t think they will allow it</div><br/><div id="38343852" class="c"><input type="checkbox" id="c-38343852" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343816">parent</a><span>|</span><a href="#38343635">next</a><span>|</span><label class="collapse" for="c-38343852">[-]</label><label class="expand" for="c-38343852">[2 more]</label></div><br/><div class="children"><div class="content">Oh wow, that&#x27;s like the most I&#x27;ve seen for any news subscription.</div><br/><div id="38344042" class="c"><input type="checkbox" id="c-38344042" checked=""/><div class="controls bullet"><span class="by">pg_1234</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343852">parent</a><span>|</span><a href="#38343635">next</a><span>|</span><label class="collapse" for="c-38344042">[-]</label><label class="expand" for="c-38344042">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.ph&#x2F;Berx9" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;Berx9</a></div><br/></div></div></div></div></div></div></div></div><div id="38343635" class="c"><input type="checkbox" id="c-38343635" checked=""/><div class="controls bullet"><span class="by">intellectronica</span><span>|</span><a href="#38343508">parent</a><span>|</span><a href="#38343638">prev</a><span>|</span><a href="#38343644">next</a><span>|</span><label class="collapse" for="c-38343635">[-]</label><label class="expand" for="c-38343635">[28 more]</label></div><br/><div class="children"><div class="content">Tip for builders: you can use the GPT APIs on Microsoft Azure. Managed reliably, nobody&#x27;s quitting, no drama. Same APIs, just with better controls, global availability, and a very stable, reliable, and trustworthy provider.
(disclosure: I work at Azure, but this is just my own observation).</div><br/><div id="38343756" class="c"><input type="checkbox" id="c-38343756" checked=""/><div class="controls bullet"><span class="by">Xenoamorphous</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38344154">next</a><span>|</span><label class="collapse" for="c-38343756">[-]</label><label class="expand" for="c-38343756">[1 more]</label></div><br/><div class="children"><div class="content">GPT on Azure has become incredibly slow for us in the past few weeks.</div><br/></div></div><div id="38344154" class="c"><input type="checkbox" id="c-38344154" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38343756">prev</a><span>|</span><a href="#38343934">next</a><span>|</span><label class="collapse" for="c-38344154">[-]</label><label class="expand" for="c-38344154">[1 more]</label></div><br/><div class="children"><div class="content">The Azure-hosted versions are consistently behind the OpenAI versions.<p>For example, the GPT4 128K-token model is unavailable, and the GPT-4V model is also unavailable.</div><br/></div></div><div id="38343934" class="c"><input type="checkbox" id="c-38343934" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38344154">prev</a><span>|</span><a href="#38343668">next</a><span>|</span><label class="collapse" for="c-38343934">[-]</label><label class="expand" for="c-38343934">[6 more]</label></div><br/><div class="children"><div class="content">You want me to trust M$ in all this? Embrace, extend, extinguish.<p>Fellow nerds, you really need to go into work on Monday and have a hard chat with your C levels and legal (Because IANAL). The question is: Who owns the output of LLM&#x2F;AI&#x2F;ML tooling?<p>I will give you a hint, it&#x27;s not you.<p>Do you need to copyright what a CS agent says, no, you want them on script as much as possible. An LLM parroting your training data is a good thing (assuming a human wrote it). Do you want an LLM writing code, or copy for your product, or a song for your next corporate sing along (Where did you go old IBM)? No you dont, because it&#x27;s likely going straight to the public domain. Depending on what your doing with the tool and how your using it, it might not matter that this is the case (its an internal thing) but M$, or openAI, or whoever your vendor is,  having a copy that they are free to use might be very bad...</div><br/><div id="38344170" class="c"><input type="checkbox" id="c-38344170" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343934">parent</a><span>|</span><a href="#38343968">next</a><span>|</span><label class="collapse" for="c-38344170">[-]</label><label class="expand" for="c-38344170">[1 more]</label></div><br/><div class="children"><div class="content">Have I just been transported to Slashdot in 2003?<p>I&#x27;m not sure you appreciate how enterprise licence agreements work. Every detail of who owns what will have been spelled out, along with the copyright indemnities for the output.</div><br/></div></div><div id="38343968" class="c"><input type="checkbox" id="c-38343968" checked=""/><div class="controls bullet"><span class="by">irrational</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343934">parent</a><span>|</span><a href="#38344170">prev</a><span>|</span><a href="#38344061">next</a><span>|</span><label class="collapse" for="c-38343968">[-]</label><label class="expand" for="c-38343968">[2 more]</label></div><br/><div class="children"><div class="content">Also, you might be given someone else’s proprietary IP, setting yourself up for a lawsuit.</div><br/><div id="38344028" class="c"><input type="checkbox" id="c-38344028" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343968">parent</a><span>|</span><a href="#38344061">next</a><span>|</span><label class="collapse" for="c-38344028">[-]</label><label class="expand" for="c-38344028">[1 more]</label></div><br/><div class="children"><div class="content">If I grab something off GitHub, and the license there is GPL, but it was someone else&#x27;s IP I do have some recourse and for my infraction.<p>In the case of an LLM handing it to me can I sue MS or OpenAI for giving out that IP, or is it on me for not checking first? Is any of this covered in the TOS?</div><br/></div></div></div></div><div id="38344061" class="c"><input type="checkbox" id="c-38344061" checked=""/><div class="controls bullet"><span class="by">zabzonk</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343934">parent</a><span>|</span><a href="#38343968">prev</a><span>|</span><a href="#38344122">next</a><span>|</span><label class="collapse" for="c-38344061">[-]</label><label class="expand" for="c-38344061">[1 more]</label></div><br/><div class="children"><div class="content">a hint - the &quot;M$&quot; thing is not smart or funny, just old.</div><br/></div></div><div id="38344122" class="c"><input type="checkbox" id="c-38344122" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343934">parent</a><span>|</span><a href="#38344061">prev</a><span>|</span><a href="#38343668">next</a><span>|</span><label class="collapse" for="c-38344122">[-]</label><label class="expand" for="c-38344122">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Embrace, extend, extinguish.<p>Microsoft hasn&#x27;t embraced that ideology in close to more than a decade by now. Might be the time to let go of the boomer compulsion.</div><br/></div></div></div></div><div id="38343668" class="c"><input type="checkbox" id="c-38343668" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38343934">prev</a><span>|</span><a href="#38343670">next</a><span>|</span><label class="collapse" for="c-38343668">[-]</label><label class="expand" for="c-38343668">[4 more]</label></div><br/><div class="children"><div class="content">Question: how difficult is it to get that no retention waiver on prompts and responses?</div><br/><div id="38343684" class="c"><input type="checkbox" id="c-38343684" checked=""/><div class="controls bullet"><span class="by">intellectronica</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343668">parent</a><span>|</span><a href="#38343670">next</a><span>|</span><label class="collapse" for="c-38343684">[-]</label><label class="expand" for="c-38343684">[3 more]</label></div><br/><div class="children"><div class="content">Not difficult. I&#x27;ve not heard of anyone who asked and _didn&#x27;t_ get the waiver. It&#x27;s just a responsible stop-gap in case a user does something questionable or dangerous.</div><br/><div id="38343716" class="c"><input type="checkbox" id="c-38343716" checked=""/><div class="controls bullet"><span class="by">apstls</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343684">parent</a><span>|</span><a href="#38343670">next</a><span>|</span><label class="collapse" for="c-38343716">[-]</label><label class="expand" for="c-38343716">[2 more]</label></div><br/><div class="children"><div class="content">The waiver still allows for logging of prompts for the specific purpose of abuse monitoring for some limited retention period, right? How difficult is it to have this waived as well?</div><br/><div id="38343753" class="c"><input type="checkbox" id="c-38343753" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343716">parent</a><span>|</span><a href="#38343670">next</a><span>|</span><label class="collapse" for="c-38343753">[-]</label><label class="expand" for="c-38343753">[1 more]</label></div><br/><div class="children"><div class="content">I work in academia and with somewhat protected data so YMMV but it wasn&#x27;t hard for me at all (I just filled out the form and MS approved it).</div><br/></div></div></div></div></div></div></div></div><div id="38343670" class="c"><input type="checkbox" id="c-38343670" checked=""/><div class="controls bullet"><span class="by">mrtksn</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38343668">prev</a><span>|</span><a href="#38343679">next</a><span>|</span><label class="collapse" for="c-38343670">[-]</label><label class="expand" for="c-38343670">[2 more]</label></div><br/><div class="children"><div class="content">How the same? Does it have the new Assistant API too?</div><br/><div id="38343694" class="c"><input type="checkbox" id="c-38343694" checked=""/><div class="controls bullet"><span class="by">intellectronica</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343670">parent</a><span>|</span><a href="#38343679">next</a><span>|</span><label class="collapse" for="c-38343694">[-]</label><label class="expand" for="c-38343694">[1 more]</label></div><br/><div class="children"><div class="content">Basically, yes (there are some variations but same functionality, and much more).</div><br/></div></div></div></div><div id="38343679" class="c"><input type="checkbox" id="c-38343679" checked=""/><div class="controls bullet"><span class="by">mlindner</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343635">parent</a><span>|</span><a href="#38343670">prev</a><span>|</span><a href="#38343644">next</a><span>|</span><label class="collapse" for="c-38343679">[-]</label><label class="expand" for="c-38343679">[13 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand what point you&#x27;re trying to make. Yes Microsoft uses OpenAI APIs. What is the point you&#x27;re trying to make beyond that? It&#x27;s still OpenAI software.</div><br/><div id="38343758" class="c"><input type="checkbox" id="c-38343758" checked=""/><div class="controls bullet"><span class="by">intellectronica</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343679">parent</a><span>|</span><a href="#38343732">next</a><span>|</span><label class="collapse" for="c-38343758">[-]</label><label class="expand" for="c-38343758">[4 more]</label></div><br/><div class="children"><div class="content">Yes, the model weights were developed by OpenAI. They are licensed exclusively and irrevocably to Microsoft, and operated by Microsoft, not OpenAI. If you are building with these APIs and concerned that consuming them from OpenAI (which also runs them on Azure, but managed by OpenAI staff) because of the drama there, you can de-risk by consuming from Azure directly.</div><br/><div id="38343796" class="c"><input type="checkbox" id="c-38343796" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343758">parent</a><span>|</span><a href="#38343802">next</a><span>|</span><label class="collapse" for="c-38343796">[-]</label><label class="expand" for="c-38343796">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They are licensed exclusively and irrevocably to Microsoft, and operated by Microsoft, not OpenAI.<p>No wonder why CEO got fired.</div><br/><div id="38344181" class="c"><input type="checkbox" id="c-38344181" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343796">parent</a><span>|</span><a href="#38343802">next</a><span>|</span><label class="collapse" for="c-38344181">[-]</label><label class="expand" for="c-38344181">[1 more]</label></div><br/><div class="children"><div class="content">Let me guess: Ilya and his team had developed GPT5, decided it very-nearly had consciousness, and then Sam immediately turned around and asked Microsoft what they&#x27;re willing to pay for a copy to use and abuse.</div><br/></div></div></div></div><div id="38343802" class="c"><input type="checkbox" id="c-38343802" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343758">parent</a><span>|</span><a href="#38343796">prev</a><span>|</span><a href="#38343732">next</a><span>|</span><label class="collapse" for="c-38343802">[-]</label><label class="expand" for="c-38343802">[1 more]</label></div><br/><div class="children"><div class="content">If folks care enough to move to Azure, I think they might as well derisk entirely from OpenAI models, despite its quality?</div><br/></div></div></div></div><div id="38343732" class="c"><input type="checkbox" id="c-38343732" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343679">parent</a><span>|</span><a href="#38343758">prev</a><span>|</span><a href="#38343740">next</a><span>|</span><label class="collapse" for="c-38343732">[-]</label><label class="expand" for="c-38343732">[5 more]</label></div><br/><div class="children"><div class="content">Microsoft doesn&#x27;t &quot;use&quot; the APIs, they host them on their own servers and have a license to do so and re-license to Azure users. If something goes wrong with OpenAI (given that it sounds like many key employees are leaving), Azure will stay up and you can keep using the APIs from MS.</div><br/><div id="38343784" class="c"><input type="checkbox" id="c-38343784" checked=""/><div class="controls bullet"><span class="by">rob74</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343732">parent</a><span>|</span><a href="#38344038">next</a><span>|</span><label class="collapse" for="c-38343784">[-]</label><label class="expand" for="c-38343784">[1 more]</label></div><br/><div class="children"><div class="content">Or, to say it another way, they are cooperating with OpenAI - OpenAI uses Microsoft&#x27;s cloud services, and Microsoft incorporates OpenAI&#x27;s products in its own offerings. But the worries people have are not about OpenAI&#x27;s products suddenly vanishing, it&#x27;s about the turmoil at OpenAI affecting the future of those products.<p>Actually the exodus of talent from OpenAI may turn out to be beneficial for the development of AI by increasing competition - however it will certainly go against the stated goal of the board for firing Altman, which was basically keeping the development under control.</div><br/></div></div><div id="38344038" class="c"><input type="checkbox" id="c-38344038" checked=""/><div class="controls bullet"><span class="by">deeringc</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343732">parent</a><span>|</span><a href="#38343784">prev</a><span>|</span><a href="#38343740">next</a><span>|</span><label class="collapse" for="c-38344038">[-]</label><label class="expand" for="c-38344038">[3 more]</label></div><br/><div class="children"><div class="content">That may provide short term stability, but medium term (which in this field is a few months) how will Azure&#x27;s offering move forward if OpenAI is in such crisis? I guess it really comes down to OpenAI&#x27;s ability to continue without Altman and Co. I don&#x27;t believe that Microsoft&#x27;s license allows them to independently develop the models? Wouldn&#x27;t this become a stale fork pretty quickly while the rest of the industry moves on (llama2 etc ..)?</div><br/><div id="38344840" class="c"><input type="checkbox" id="c-38344840" checked=""/><div class="controls bullet"><span class="by">intellectronica</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38344038">parent</a><span>|</span><a href="#38344145">next</a><span>|</span><label class="collapse" for="c-38344840">[-]</label><label class="expand" for="c-38344840">[1 more]</label></div><br/><div class="children"><div class="content">Or ... cut the middleman: Sam Altman and Greg Brockman joining MS to start a new AI unit - <a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726516824597258569" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726516824597258569</a></div><br/></div></div><div id="38344145" class="c"><input type="checkbox" id="c-38344145" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38344038">parent</a><span>|</span><a href="#38344840">prev</a><span>|</span><a href="#38343740">next</a><span>|</span><label class="collapse" for="c-38344145">[-]</label><label class="expand" for="c-38344145">[1 more]</label></div><br/><div class="children"><div class="content">I agree that medium term is up in the air and highly dependent on what happens next. If many OAI employees defect to Sam&#x27;s new company, maybe that becomes the thing everyone migrates to...</div><br/></div></div></div></div></div></div><div id="38343740" class="c"><input type="checkbox" id="c-38343740" checked=""/><div class="controls bullet"><span class="by">apstls</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343679">parent</a><span>|</span><a href="#38343732">prev</a><span>|</span><a href="#38343791">next</a><span>|</span><label class="collapse" for="c-38343740">[-]</label><label class="expand" for="c-38343740">[2 more]</label></div><br/><div class="children"><div class="content">The current models would presumably be accessible for customers regardless of OpenAI’s state. If OpenAI were to hypothetically somehow vanish into thin air, products and features built on their products could still be supported by Azure’s offering.</div><br/><div id="38344221" class="c"><input type="checkbox" id="c-38344221" checked=""/><div class="controls bullet"><span class="by">deeringc</span><span>|</span><a href="#38343508">root</a><span>|</span><a href="#38343740">parent</a><span>|</span><a href="#38343791">next</a><span>|</span><label class="collapse" for="c-38344221">[-]</label><label class="expand" for="c-38344221">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but what&#x27;s the point on building a product on top of a stable API that exposes a technology that won&#x27;t evolve because it&#x27;s actual creators have imploded? It remains to be seen whether OpenAI will implode, but at this point it seems the dream team is t getting back together.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38343644" class="c"><input type="checkbox" id="c-38343644" checked=""/><div class="controls bullet"><span class="by">icyfox</span><span>|</span><a href="#38343508">prev</a><span>|</span><a href="#38343589">next</a><span>|</span><label class="collapse" for="c-38343644">[-]</label><label class="expand" for="c-38343644">[6 more]</label></div><br/><div class="children"><div class="content">This will be an interesting test to see how fast you can bootstrap GPT-4 level performance with unlimited funds and talent that already has deep knowledge of the internals. With the initial adoption of ChatGPT alongside Copilot, OpenAI&#x27;s data moat of crawled data &amp; RLHF is pretty vast. And that&#x27;s not leaving the walled garden of OpenAI. You can simulate a lot of this using other off-the-shelf LLMs (see Alpaca) but nothing is a substitute for real world observed usage.<p>In a related note, has this meaningfully broken through to the mainstream yet? If a ChatGPT competitor comes out tomorrow that is just as good - but under a different brand - how many people will switch because it&#x27;s Altman backed? I&#x27;ll be curious to find out.</div><br/><div id="38343951" class="c"><input type="checkbox" id="c-38343951" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38343644">parent</a><span>|</span><a href="#38343943">next</a><span>|</span><label class="collapse" for="c-38343951">[-]</label><label class="expand" for="c-38343951">[4 more]</label></div><br/><div class="children"><div class="content">Many of OpenAIs most talented people left to start Anthropic. They have billions in funding and have not yet got particularly close to GPT-4.<p>I think that illustrates it will be a be a big uphill battle for any new entrant no matter how well funded or resourced.</div><br/><div id="38344057" class="c"><input type="checkbox" id="c-38344057" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#38343644">root</a><span>|</span><a href="#38343951">parent</a><span>|</span><a href="#38344054">next</a><span>|</span><label class="collapse" for="c-38344057">[-]</label><label class="expand" for="c-38344057">[1 more]</label></div><br/><div class="children"><div class="content">And the new CEO was a consultant to Anthropic, apparently. I&#x27;m only grateful I don&#x27;t have to make sense of this drama.</div><br/></div></div><div id="38344054" class="c"><input type="checkbox" id="c-38344054" checked=""/><div class="controls bullet"><span class="by">adonese</span><span>|</span><a href="#38343644">root</a><span>|</span><a href="#38343951">parent</a><span>|</span><a href="#38344057">prev</a><span>|</span><a href="#38344037">next</a><span>|</span><label class="collapse" for="c-38344054">[-]</label><label class="expand" for="c-38344054">[1 more]</label></div><br/><div class="children"><div class="content">noob ai here, but is it gonna be challenging because of something intrinsic to gpt4? or about collecting equivalent amount of data to train a comparable model. Because I see Facebook releasing their models down to the weights</div><br/></div></div><div id="38344037" class="c"><input type="checkbox" id="c-38344037" checked=""/><div class="controls bullet"><span class="by">leoh</span><span>|</span><a href="#38343644">root</a><span>|</span><a href="#38343951">parent</a><span>|</span><a href="#38344054">prev</a><span>|</span><a href="#38343943">next</a><span>|</span><label class="collapse" for="c-38344037">[-]</label><label class="expand" for="c-38344037">[1 more]</label></div><br/><div class="children"><div class="content">The parent post is literally true yet keeps getting downvoted — what a mess HN has become, too</div><br/></div></div></div></div><div id="38343943" class="c"><input type="checkbox" id="c-38343943" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38343644">parent</a><span>|</span><a href="#38343951">prev</a><span>|</span><a href="#38343589">next</a><span>|</span><label class="collapse" for="c-38343943">[-]</label><label class="expand" for="c-38343943">[1 more]</label></div><br/><div class="children"><div class="content">I would switch, but not because of Altman backing or not. I would switch if their strategy were to be to progress at pace. I’m not big on AI safety as it is parroted these days, I just want more AI, faster.</div><br/></div></div></div></div><div id="38343589" class="c"><input type="checkbox" id="c-38343589" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#38343644">prev</a><span>|</span><a href="#38343383">next</a><span>|</span><label class="collapse" for="c-38343589">[-]</label><label class="expand" for="c-38343589">[18 more]</label></div><br/><div class="children"><div class="content">Honest question:<p>Other than 1) Microsoft and 2) anyone building a product with the OpenAI api 3) OpenAI employees…<p>…is OpenAI crashing a burning a big deal?<p>This seems rather over hyped… everyone has an opinion, everyone cares because OpenAI has a high profile.<p>…but <i>really</i>, alternatives to chatGPT exist now, and most people will be, really… not affected by this in any meaningful degree.<p>Isn’t breaking the strangle hold on AI what <i>everyone wanted</i> with open source models last week?<p>Feels a lot like Twitter; people said it would crash and burn, but really, it’s just a bit rubbish now, and a bunch of other competitors have turned up.<p>…and competitive pressure is good right?<p>I predict: what happens will look a lot like what happened with Twitter.<p>Ultimately, most people will not be affected.<p>The people who care will leave.<p>New competitors will turn up.<p>Life goes on…</div><br/><div id="38343921" class="c"><input type="checkbox" id="c-38343921" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38345063">next</a><span>|</span><label class="collapse" for="c-38343921">[-]</label><label class="expand" for="c-38343921">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll be probably downvoted to hell, but, I think what is happening is healthy to the ecosystem.<p>Pine forests are known to grow by fires. Fires scatter the seeds around, the area which is unsustainable is reset, new forests are seeded, life goes on.<p>This is what we&#x27;re seeing, too. A very dense forest has burned, seeds are scattered, new, smaller forests will start growing.<p>Things will slow down a bit, bit accelerate again in a more healthy manner. We&#x27;ll see competition, and different approaches to training and sharing models.<p>Life will go on...</div><br/></div></div><div id="38345063" class="c"><input type="checkbox" id="c-38345063" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38343921">prev</a><span>|</span><a href="#38343847">next</a><span>|</span><label class="collapse" for="c-38345063">[-]</label><label class="expand" for="c-38345063">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve not found anything that really competes with GPT4, and that&#x27;s been released for some time.<p>&gt; Isn’t breaking the strangle hold on AI what everyone wanted with open source models last week?<p>By other things getting better, not by stalling the leader of the pack.</div><br/></div></div><div id="38343847" class="c"><input type="checkbox" id="c-38343847" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38345063">prev</a><span>|</span><a href="#38344022">next</a><span>|</span><label class="collapse" for="c-38343847">[-]</label><label class="expand" for="c-38343847">[5 more]</label></div><br/><div class="children"><div class="content">Totally agree. It seems like OpenAI is ahead of the curve, but even some free open source projects have become really good. I am no expert, so take this with a grain of salt. It seems OpenAI has a lead, but only of a few months or so and others are racing behind. I guess it really sucks if you built something that relies on the OpenAI api, but even then one could replace the api layer.</div><br/><div id="38343924" class="c"><input type="checkbox" id="c-38343924" checked=""/><div class="controls bullet"><span class="by">ComplexSystems</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343847">parent</a><span>|</span><a href="#38344454">next</a><span>|</span><label class="collapse" for="c-38343924">[-]</label><label class="expand" for="c-38343924">[2 more]</label></div><br/><div class="children"><div class="content">For coding, at least, nothing out there is even close to as good as GPT-4. Not Claude, not Grok, and certainly not llama.</div><br/><div id="38344080" class="c"><input type="checkbox" id="c-38344080" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343924">parent</a><span>|</span><a href="#38344454">next</a><span>|</span><label class="collapse" for="c-38344080">[-]</label><label class="expand" for="c-38344080">[1 more]</label></div><br/><div class="children"><div class="content">For coding tasks (without API access), especially in a conversational setting, Phind has been by far the best one for me. I sometimes still compare it to ChatGPT with GPT-4, but it almost always comes out on top (not missing the point of the questions + amount of required editing for integration into codebase), and it does produce the answers a lot faster.</div><br/></div></div></div></div><div id="38344454" class="c"><input type="checkbox" id="c-38344454" checked=""/><div class="controls bullet"><span class="by">OccamsMirror</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343847">parent</a><span>|</span><a href="#38343924">prev</a><span>|</span><a href="#38343949">next</a><span>|</span><label class="collapse" for="c-38344454">[-]</label><label class="expand" for="c-38344454">[1 more]</label></div><br/><div class="children"><div class="content">I mean, OpenAI aren&#x27;t just going to close up shop. I would very much doubt they&#x27;re just going to turn off their APIs. I would just keep building and if you have to swap LLMs at some point then do so.</div><br/></div></div><div id="38343949" class="c"><input type="checkbox" id="c-38343949" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343847">parent</a><span>|</span><a href="#38344454">prev</a><span>|</span><a href="#38344022">next</a><span>|</span><label class="collapse" for="c-38343949">[-]</label><label class="expand" for="c-38343949">[1 more]</label></div><br/><div class="children"><div class="content">None of the open source stuff even comes close to GPT4, I’ve tried them repeatedly.</div><br/></div></div></div></div><div id="38344022" class="c"><input type="checkbox" id="c-38344022" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38343847">prev</a><span>|</span><a href="#38343908">next</a><span>|</span><label class="collapse" for="c-38344022">[-]</label><label class="expand" for="c-38344022">[6 more]</label></div><br/><div class="children"><div class="content">In time of Windows, around let&#x27;s say mid 1990s, people thought Windows is irreplaceable.<p>Now turns out Linux is the workhorse everywhere for running workloads or consuming content. Almost every programming language (other than Microsoft&#x27;s own SDKs) gets developed on Linux, has first class support for Linux and Windows is always an afterthought.<p>It has gone to that extent that to lure developers, Microsoft has to embed a Lunux in a virtual machine on Windows called WSL.<p>Local inference is going to get cheaper and affordable and that&#x27;s for sure.<p>New models would also emerge.<p>So OpenAI doesn&#x27;t seem to have an IP that can withstand all that IMHO.</div><br/><div id="38344136" class="c"><input type="checkbox" id="c-38344136" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38344022">parent</a><span>|</span><a href="#38343908">next</a><span>|</span><label class="collapse" for="c-38344136">[-]</label><label class="expand" for="c-38344136">[5 more]</label></div><br/><div class="children"><div class="content">Linux isn&#x27;t the workhorse in any business that isn&#x27;t tech based. The dev bubble here is pretty strong. I&#x27;ve done IT for a couple MSPs now so I&#x27;ve seen 100s of different tech stacks. No one uses Linux for anything. ESXi for the hypervisors, various version of Windows server, and M365 for everything else. Graphics&#x2F;marketing uses Macs sometimes but other than that, it&#x27;s all Windows&#x2F;MS. Seeing a Linux VM is exceeding rare and usually runs some bespoke software that no one knows how to service or support. Yes, Linux is much more viable these days, but it&#x27;s not even close to being mainstream.</div><br/><div id="38345060" class="c"><input type="checkbox" id="c-38345060" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38344136">parent</a><span>|</span><a href="#38344225">next</a><span>|</span><label class="collapse" for="c-38345060">[-]</label><label class="expand" for="c-38345060">[1 more]</label></div><br/><div class="children"><div class="content">True. You&#x27;ll find Windows XP based terminals on many industrial machines. Its pervasive but outnumbered where &quot;running the workloads&quot; comea into picture.<p>The dev bubble is not that small. This very website is I&#x27;m pretty sure not served from Windows.<p>Other than stack overflow or few handful of exceptions, very little is actually served from Windows if I&#x27;m not wrong.</div><br/></div></div><div id="38344225" class="c"><input type="checkbox" id="c-38344225" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38344136">parent</a><span>|</span><a href="#38345060">prev</a><span>|</span><a href="#38344386">next</a><span>|</span><label class="collapse" for="c-38344225">[-]</label><label class="expand" for="c-38344225">[2 more]</label></div><br/><div class="children"><div class="content">I think GP is referring to servers. Linux may still be tiny on the desktop, but it dominates servers (and mobile)</div><br/></div></div><div id="38344386" class="c"><input type="checkbox" id="c-38344386" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38344136">parent</a><span>|</span><a href="#38344225">prev</a><span>|</span><a href="#38343908">next</a><span>|</span><label class="collapse" for="c-38344386">[-]</label><label class="expand" for="c-38344386">[1 more]</label></div><br/><div class="children"><div class="content">So I’m guessing you have never heard of AWS then…</div><br/></div></div></div></div></div></div><div id="38343908" class="c"><input type="checkbox" id="c-38343908" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38344022">prev</a><span>|</span><a href="#38343841">next</a><span>|</span><label class="collapse" for="c-38343908">[-]</label><label class="expand" for="c-38343908">[1 more]</label></div><br/><div class="children"><div class="content">In the &quot;grand scheme of things&quot;, no, it&#x27;s probably not a big deal. I think in the short term, I think it has the potential to set back the space a few months, as a lot of the ecosystem is still oriented around OpenAI (as they are the best at productivizing). I think that even extends to many community&#x2F;open source models, which are commonly trained against GPT-4.<p>If they are able to retain enough people to properly release a GPT-5 with significant performance increases in a few months, I would assume that the effect is less pronounced.</div><br/></div></div><div id="38343841" class="c"><input type="checkbox" id="c-38343841" checked=""/><div class="controls bullet"><span class="by">emodendroket</span><span>|</span><a href="#38343589">parent</a><span>|</span><a href="#38343908">prev</a><span>|</span><a href="#38343383">next</a><span>|</span><label class="collapse" for="c-38343841">[-]</label><label class="expand" for="c-38343841">[3 more]</label></div><br/><div class="children"><div class="content">In Twitter&#x27;s case that&#x27;s the main product getting worse without any of the wannabes getting that much traction.</div><br/><div id="38343917" class="c"><input type="checkbox" id="c-38343917" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343841">parent</a><span>|</span><a href="#38344081">next</a><span>|</span><label class="collapse" for="c-38343917">[-]</label><label class="expand" for="c-38343917">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s different. People spend YEARS building their social media presence, following, and algorithmic advantage.<p>Jumping to a different platform is a huge sacrifice for power users - those who create content and value.<p>None of this is a factor here. ChatGPT is just a tool, like an online image resizer.</div><br/></div></div><div id="38344081" class="c"><input type="checkbox" id="c-38344081" checked=""/><div class="controls bullet"><span class="by">flarg</span><span>|</span><a href="#38343589">root</a><span>|</span><a href="#38343841">parent</a><span>|</span><a href="#38343917">prev</a><span>|</span><a href="#38343383">next</a><span>|</span><label class="collapse" for="c-38344081">[-]</label><label class="expand" for="c-38344081">[1 more]</label></div><br/><div class="children"><div class="content">IMHO Twitter drove its own need and now that it has pretty much gone no one wants the hassle of serving a new master.</div><br/></div></div></div></div></div></div><div id="38343383" class="c"><input type="checkbox" id="c-38343383" checked=""/><div class="controls bullet"><span class="by">zoogeny</span><span>|</span><a href="#38343589">prev</a><span>|</span><a href="#38344227">next</a><span>|</span><label class="collapse" for="c-38343383">[-]</label><label class="expand" for="c-38343383">[24 more]</label></div><br/><div class="children"><div class="content">I’m genuinely surprised that they stuck to their guns. The PR push behind Altman’s return was convincing enough that I had my doubts.<p>Altman will be more than fine, he’ll get a bucket of money and the chance to prove he is the golden boy he’s been sold to the world. He will get to recruit a team that believes in his vision of accelerating AI for commercial use. This will lead to a more diverse market.<p>I hope for the best for those who remain at OpenAI. I hope for the best for Altman and Brockman.</div><br/><div id="38343741" class="c"><input type="checkbox" id="c-38343741" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38343383">parent</a><span>|</span><a href="#38344102">next</a><span>|</span><label class="collapse" for="c-38343741">[-]</label><label class="expand" for="c-38343741">[20 more]</label></div><br/><div class="children"><div class="content">The whole situation should make it clear that SV media is beholden to VCs and will print anything they tell them to.<p>Bloomberg, the verge and the information all went to bat for Altman in a big way on this.</div><br/><div id="38343783" class="c"><input type="checkbox" id="c-38343783" checked=""/><div class="controls bullet"><span class="by">lajawfe</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343741">parent</a><span>|</span><a href="#38344091">next</a><span>|</span><label class="collapse" for="c-38343783">[-]</label><label class="expand" for="c-38343783">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I felt the same. In every piece, there was very little news but a lot of fluff to lead the public with opinions. Probably VCs saw their money burning and wanted Sam back at the helm to protect their asset.</div><br/></div></div><div id="38344091" class="c"><input type="checkbox" id="c-38344091" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343741">parent</a><span>|</span><a href="#38343783">prev</a><span>|</span><a href="#38344071">next</a><span>|</span><label class="collapse" for="c-38344091">[-]</label><label class="expand" for="c-38344091">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;m also pretty suspicious of people in forums like these who say nothing can compare to GPT4 and they&#x27;re miles ahead of everyone else etc. How much of that is venture capital speaking?<p>It&#x27;s not quite where it is (or was) with Tesla, where it was hopeless to know what was sincere and what was just people talking up their investment&#x2F;talking down their short, but it&#x27;s getting there.</div><br/><div id="38344411" class="c"><input type="checkbox" id="c-38344411" checked=""/><div class="controls bullet"><span class="by">exizt88</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344091">parent</a><span>|</span><a href="#38344218">next</a><span>|</span><label class="collapse" for="c-38344411">[-]</label><label class="expand" for="c-38344411">[1 more]</label></div><br/><div class="children"><div class="content">Anyone who works with text generation will tell you that GPT-4 is far, far beyond anything anyone else has put out for general purpose text gen. The benchmarks don’t really tell you the whole picture. It’s impossible to prompt other models for anything as complex as what GPT-4 can do, both semantically and stylistically.</div><br/></div></div><div id="38344218" class="c"><input type="checkbox" id="c-38344218" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344091">parent</a><span>|</span><a href="#38344411">prev</a><span>|</span><a href="#38344219">next</a><span>|</span><label class="collapse" for="c-38344218">[-]</label><label class="expand" for="c-38344218">[1 more]</label></div><br/><div class="children"><div class="content">There are concrete benchmarks like “how good is it at answering multiple choice questions accurately or “how good is it at producing valid code to solve a particular coding problem”.<p>There’s also a chatbot Elo ranking which crowd sources model comparisons  <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboar...</a><p>GPT-4 is the king right now</div><br/></div></div><div id="38344219" class="c"><input type="checkbox" id="c-38344219" checked=""/><div class="controls bullet"><span class="by">lajawfe</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344091">parent</a><span>|</span><a href="#38344218">prev</a><span>|</span><a href="#38344356">next</a><span>|</span><label class="collapse" for="c-38344219">[-]</label><label class="expand" for="c-38344219">[2 more]</label></div><br/><div class="children"><div class="content">The crypto bros switched to AI hype and are now hyping OpenAI&#x2F;GPT4 hoping to pump MSFT&#x2F;NVDA. In every HN conversation where someone mentions competing products, there are people talking it down and saying GPT4 is miles ahead, and in a tone to undermine the competition. I see a pattern and it is definitely not sincere.</div><br/><div id="38344381" class="c"><input type="checkbox" id="c-38344381" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344219">parent</a><span>|</span><a href="#38344356">next</a><span>|</span><label class="collapse" for="c-38344381">[-]</label><label class="expand" for="c-38344381">[1 more]</label></div><br/><div class="children"><div class="content">You clearly haven&#x27;t tried GPT-4 if you think people are lying about how much better it is.</div><br/></div></div></div></div><div id="38344356" class="c"><input type="checkbox" id="c-38344356" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344091">parent</a><span>|</span><a href="#38344219">prev</a><span>|</span><a href="#38344071">next</a><span>|</span><label class="collapse" for="c-38344356">[-]</label><label class="expand" for="c-38344356">[2 more]</label></div><br/><div class="children"><div class="content">I mean, try and compare for yourself. It is quite obviously miles ahead of everything else.<p>I want OpenAI to be absolutely crushed in the free market after this move. But it will take years for anyone to catch up with GPT-4, if even Anthropic is nowhere close.</div><br/><div id="38344492" class="c"><input type="checkbox" id="c-38344492" checked=""/><div class="controls bullet"><span class="by">OccamsMirror</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344356">parent</a><span>|</span><a href="#38344071">next</a><span>|</span><label class="collapse" for="c-38344492">[-]</label><label class="expand" for="c-38344492">[1 more]</label></div><br/><div class="children"><div class="content">Why do you want them to be crushed? They decided that Sam didn&#x27;t represent the charter and acted accordingly. Do I think it was a boneheaded move? Sure. But maybe it was the right move for them even in spite of the optics?</div><br/></div></div></div></div></div></div><div id="38344071" class="c"><input type="checkbox" id="c-38344071" checked=""/><div class="controls bullet"><span class="by">ahartmetz</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343741">parent</a><span>|</span><a href="#38344091">prev</a><span>|</span><a href="#38343785">next</a><span>|</span><label class="collapse" for="c-38344071">[-]</label><label class="expand" for="c-38344071">[1 more]</label></div><br/><div class="children"><div class="content">My favorite was that part from Financial Times:<p>&quot;Investors were hoping that Altman would return to a company “which has been his life&#x27;s work”&quot;<p>As opposed to Sutskever, who they found on the street somehow, yeah?</div><br/></div></div><div id="38343785" class="c"><input type="checkbox" id="c-38343785" checked=""/><div class="controls bullet"><span class="by">browserman</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343741">parent</a><span>|</span><a href="#38344071">prev</a><span>|</span><a href="#38343768">next</a><span>|</span><label class="collapse" for="c-38343785">[-]</label><label class="expand" for="c-38343785">[6 more]</label></div><br/><div class="children"><div class="content">Kara Swisher was basically working as Altman’s press secretary</div><br/><div id="38343834" class="c"><input type="checkbox" id="c-38343834" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343785">parent</a><span>|</span><a href="#38343768">next</a><span>|</span><label class="collapse" for="c-38343834">[-]</label><label class="expand" for="c-38343834">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get the vibe that Swisher particularly likes techbros or billionaires, let alone bat for them.</div><br/><div id="38343874" class="c"><input type="checkbox" id="c-38343874" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343834">parent</a><span>|</span><a href="#38343895">next</a><span>|</span><label class="collapse" for="c-38343874">[-]</label><label class="expand" for="c-38343874">[3 more]</label></div><br/><div class="children"><div class="content">Have you read her recent Tweets on the matter? She was definitely editorializing quite subjectively in favor of Altman. That&#x27;s not exactly unbiased journalism happening.</div><br/><div id="38344004" class="c"><input type="checkbox" id="c-38344004" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343874">parent</a><span>|</span><a href="#38343895">next</a><span>|</span><label class="collapse" for="c-38344004">[-]</label><label class="expand" for="c-38344004">[2 more]</label></div><br/><div class="children"><div class="content">I read her Threads post and do not see the same advocacy you claim here.  Just valuable information.</div><br/><div id="38344087" class="c"><input type="checkbox" id="c-38344087" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38344004">parent</a><span>|</span><a href="#38343895">next</a><span>|</span><label class="collapse" for="c-38344087">[-]</label><label class="expand" for="c-38344087">[1 more]</label></div><br/><div class="children"><div class="content">Well I wasn&#x27;t referring to her Threads posts. I was referring to her recent Tweets.</div><br/></div></div></div></div></div></div><div id="38343895" class="c"><input type="checkbox" id="c-38343895" checked=""/><div class="controls bullet"><span class="by">fatbird</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343834">parent</a><span>|</span><a href="#38343874">prev</a><span>|</span><a href="#38343768">next</a><span>|</span><label class="collapse" for="c-38343895">[-]</label><label class="expand" for="c-38343895">[1 more]</label></div><br/><div class="children"><div class="content">She&#x27;s an access journalist.  She&#x27;ll shill for the biggest voice who&#x27;ll talk to her.</div><br/></div></div></div></div></div></div><div id="38343768" class="c"><input type="checkbox" id="c-38343768" checked=""/><div class="controls bullet"><span class="by">zaptheimpaler</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343741">parent</a><span>|</span><a href="#38343785">prev</a><span>|</span><a href="#38344102">next</a><span>|</span><label class="collapse" for="c-38343768">[-]</label><label class="expand" for="c-38343768">[4 more]</label></div><br/><div class="children"><div class="content">You could say the same thing if they were rooting for the board instead..</div><br/><div id="38343815" class="c"><input type="checkbox" id="c-38343815" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343768">parent</a><span>|</span><a href="#38344102">next</a><span>|</span><label class="collapse" for="c-38343815">[-]</label><label class="expand" for="c-38343815">[3 more]</label></div><br/><div class="children"><div class="content">It’s not the job of the media to root for anyone. The media should dispassionately report the truth. In this case they did not do so.</div><br/><div id="38343964" class="c"><input type="checkbox" id="c-38343964" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343815">parent</a><span>|</span><a href="#38344102">next</a><span>|</span><label class="collapse" for="c-38343964">[-]</label><label class="expand" for="c-38343964">[2 more]</label></div><br/><div class="children"><div class="content">In most cases they do not.  We haven’t had unfiltered media for a very long time now.  Your voice is blocked from a large audience by many many barriers if you mention any forbidden keywords together.</div><br/><div id="38344142" class="c"><input type="checkbox" id="c-38344142" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#38343383">root</a><span>|</span><a href="#38343964">parent</a><span>|</span><a href="#38344102">next</a><span>|</span><label class="collapse" for="c-38344142">[-]</label><label class="expand" for="c-38344142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We haven’t had unfiltered media for a very long time now.<p>When did we have it?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38344102" class="c"><input type="checkbox" id="c-38344102" checked=""/><div class="controls bullet"><span class="by">tunesmith</span><span>|</span><a href="#38343383">parent</a><span>|</span><a href="#38343741">prev</a><span>|</span><a href="#38343859">next</a><span>|</span><label class="collapse" for="c-38344102">[-]</label><label class="expand" for="c-38344102">[1 more]</label></div><br/><div class="children"><div class="content">I read something a while ago: when trying to interpret the truth of what is happening, the value of public statements is only that it&#x27;s an indication of what that source would like the public to believe. And when looked at that way, that signal does have value. Not as truth, but as motive.<p>So that helped cut through all the cruft with this. There was a lot of effort behind putting across the <i>perception</i> that the board was going to resign and that Altman was going to come back.<p>Looked at through that lens, it makes more sense: the existing board had little incentive to quit and rehire Sam&#x2F;Greg. The only incentive was if mass resignations threatened their priorities of working on safety and alignment, and I get the sense that most of these resignations are more on the product engineering side.<p>So I don&#x27;t really think this is a twist that no one saw coming.</div><br/></div></div><div id="38343859" class="c"><input type="checkbox" id="c-38343859" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38343383">parent</a><span>|</span><a href="#38344102">prev</a><span>|</span><a href="#38344505">next</a><span>|</span><label class="collapse" for="c-38343859">[-]</label><label class="expand" for="c-38343859">[1 more]</label></div><br/><div class="children"><div class="content">Same<p>If OpenAI ceases to be Sam’s vision someone will replace it.<p>It is a good thing for the ecosystem I guess, we will have more diverse products to choose.<p>But making AI more safe? Not likely. The tech will spread and Ilya will probably not a safer AGI, because he will not control it</div><br/></div></div><div id="38344505" class="c"><input type="checkbox" id="c-38344505" checked=""/><div class="controls bullet"><span class="by">pg_1234</span><span>|</span><a href="#38343383">parent</a><span>|</span><a href="#38343859">prev</a><span>|</span><a href="#38344227">next</a><span>|</span><label class="collapse" for="c-38344505">[-]</label><label class="expand" for="c-38344505">[1 more]</label></div><br/><div class="children"><div class="content">I think that the pro-capitalist faction forgot that the opposing side are people capable of planing the development of an artificial consciousness.<p>Should they decide to sink to the level of VC scheming briefly, it will be like child&#x27;s play for them.</div><br/></div></div></div></div><div id="38344227" class="c"><input type="checkbox" id="c-38344227" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38343383">prev</a><span>|</span><a href="#38343824">next</a><span>|</span><label class="collapse" for="c-38344227">[-]</label><label class="expand" for="c-38344227">[6 more]</label></div><br/><div class="children"><div class="content">Update:<p>Sam and Greg, and left OpenAI staffers now join in Microsoft<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726509045803336122" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1726509045803336122</a></div><br/><div id="38344519" class="c"><input type="checkbox" id="c-38344519" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#38344227">parent</a><span>|</span><a href="#38344503">next</a><span>|</span><label class="collapse" for="c-38344519">[-]</label><label class="expand" for="c-38344519">[1 more]</label></div><br/><div class="children"><div class="content">Seems like a logical choice. Microsoft’s next big play is generative AI, and they’ve put a lot of money into that.<p>They need to show they’re taking steps to stabilize things now that their hype factory has come unraveled.<p>I don’t think they particularly need these people , because they likely already have in house talent that is competitive. But having these people on board now will allow them to paint a much more stable picture to their shareholders.</div><br/></div></div><div id="38344503" class="c"><input type="checkbox" id="c-38344503" checked=""/><div class="controls bullet"><span class="by">exizt88</span><span>|</span><a href="#38344227">parent</a><span>|</span><a href="#38344519">prev</a><span>|</span><a href="#38344826">next</a><span>|</span><label class="collapse" for="c-38344503">[-]</label><label class="expand" for="c-38344503">[1 more]</label></div><br/><div class="children"><div class="content">I bet &quot;new advanced AI research team&quot; at Microsoft is going to be underwhelming for many, but really, it should be eye-opening. This is what startups, especially VC-backed capital-intensive AI startups, usually are.</div><br/></div></div><div id="38344826" class="c"><input type="checkbox" id="c-38344826" checked=""/><div class="controls bullet"><span class="by">baal80spam</span><span>|</span><a href="#38344227">parent</a><span>|</span><a href="#38344503">prev</a><span>|</span><a href="#38344307">next</a><span>|</span><label class="collapse" for="c-38344826">[-]</label><label class="expand" for="c-38344826">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow.</div><br/></div></div><div id="38344307" class="c"><input type="checkbox" id="c-38344307" checked=""/><div class="controls bullet"><span class="by">mark_mart</span><span>|</span><a href="#38344227">parent</a><span>|</span><a href="#38344826">prev</a><span>|</span><a href="#38343824">next</a><span>|</span><label class="collapse" for="c-38344307">[-]</label><label class="expand" for="c-38344307">[2 more]</label></div><br/><div class="children"><div class="content">This was unexpected.</div><br/><div id="38344488" class="c"><input type="checkbox" id="c-38344488" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#38344227">root</a><span>|</span><a href="#38344307">parent</a><span>|</span><a href="#38343824">next</a><span>|</span><label class="collapse" for="c-38344488">[-]</label><label class="expand" for="c-38344488">[1 more]</label></div><br/><div class="children"><div class="content">Idk it’s been one of the top speculations since the beginning of this drama.</div><br/></div></div></div></div></div></div><div id="38343824" class="c"><input type="checkbox" id="c-38343824" checked=""/><div class="controls bullet"><span class="by">gzer0</span><span>|</span><a href="#38344227">prev</a><span>|</span><a href="#38342767">next</a><span>|</span><label class="collapse" for="c-38343824">[-]</label><label class="expand" for="c-38343824">[8 more]</label></div><br/><div class="children"><div class="content">@karpathy on Twitter:<p><i>I just don’t have anything too remarkable to add right now. I like and respect Sam and I think so does the majority of OpenAI. The board had a chance to explain their drastic actions and they did not take it, so there is nothing to go on except exactly what it looks like.</i><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1726289070345855126" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1726289070345855126</a></div><br/><div id="38344012" class="c"><input type="checkbox" id="c-38344012" checked=""/><div class="controls bullet"><span class="by">lajawfe</span><span>|</span><a href="#38343824">parent</a><span>|</span><a href="#38342767">next</a><span>|</span><label class="collapse" for="c-38344012">[-]</label><label class="expand" for="c-38344012">[7 more]</label></div><br/><div class="children"><div class="content">I for one thought Karpathy would side with the core researchers and not the corpos. To me, this whole ordeal is a clash between profit motives of Sam vs Non Profit and Safety motives of OpenAI&#x27;s original charter. I mean didn&#x27;t HN hate when OpenAI changed their open nature and become completely closed and profit oriented? This could be the healing of the cancer that OpenAI brought to this field to make it closed as a whole.</div><br/><div id="38344320" class="c"><input type="checkbox" id="c-38344320" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344159">next</a><span>|</span><label class="collapse" for="c-38344320">[-]</label><label class="expand" for="c-38344320">[1 more]</label></div><br/><div class="children"><div class="content">There are at least three competing perspectives.<p>One is Sutskever, who believes AI is very dangerous and must be slowed down and closed. He believes this is in line with OpenAI&#x27;s original charter.<p>Another is the HN open source crowd who believes AI should be developed quickly and be open to everyone. They believe this is in line with OpenAI&#x27;s original charter.<p>Then there is Altman, who agrees that AI should be developed rapidly, but wants it to stay closed so he can directly profit by selling it. He probably believes this is in line with OpenAI&#x27;s original charter, or at least the most realistic way to achieve it, effective altruism &quot;earn to give&quot; style.<p>Karpathy <i>may</i> be more amenable to the second perspective, which he <i>may</i> think Altman is closer to achieving.</div><br/></div></div><div id="38344159" class="c"><input type="checkbox" id="c-38344159" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344320">prev</a><span>|</span><a href="#38344230">next</a><span>|</span><label class="collapse" for="c-38344159">[-]</label><label class="expand" for="c-38344159">[1 more]</label></div><br/><div class="children"><div class="content">Karpathy is a very agreeable guy and a fantastic educator, and he&#x27;s very respected by everyone including leader-owners like Altman and Musk, but he doesn&#x27;t seem like he has very strong opinions one way or another about the hot button issues.</div><br/></div></div><div id="38344230" class="c"><input type="checkbox" id="c-38344230" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344159">prev</a><span>|</span><a href="#38344502">next</a><span>|</span><label class="collapse" for="c-38344230">[-]</label><label class="expand" for="c-38344230">[1 more]</label></div><br/><div class="children"><div class="content">He spent 5 years at Tesla backing up their self driving lies for money.</div><br/></div></div><div id="38344502" class="c"><input type="checkbox" id="c-38344502" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344230">prev</a><span>|</span><a href="#38344111">next</a><span>|</span><label class="collapse" for="c-38344502">[-]</label><label class="expand" for="c-38344502">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This could be the healing of the cancer that OpenAI brought to this field to make it closed as a whole.<p>I don’t know. The damage might be permanent. Everyone is probably going to be way more careful with what information they release and how they release it. Altman corrupted the entire community with his aggressive corporate push. The happy-go-lucky “look what we created” attitude of the community might be probably gone for good. Now every suit is going to be asking “can we make massive amount of money with this” or “can I spin up a hype train with this”.</div><br/></div></div><div id="38344111" class="c"><input type="checkbox" id="c-38344111" checked=""/><div class="controls bullet"><span class="by">wilg</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344502">prev</a><span>|</span><a href="#38344173">next</a><span>|</span><label class="collapse" for="c-38344111">[-]</label><label class="expand" for="c-38344111">[1 more]</label></div><br/><div class="children"><div class="content">But isn&#x27;t Ilya&#x27;s thing that open sourcing it is too dangerous?</div><br/></div></div><div id="38344173" class="c"><input type="checkbox" id="c-38344173" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38343824">root</a><span>|</span><a href="#38344012">parent</a><span>|</span><a href="#38344111">prev</a><span>|</span><a href="#38342767">next</a><span>|</span><label class="collapse" for="c-38344173">[-]</label><label class="expand" for="c-38344173">[1 more]</label></div><br/><div class="children"><div class="content">Karpathy is a hybrid. He’s smart, but he clearly enjoys both the money and the attention. This is the guy who defended Elon’s heavily exaggerated self driving claims when the impact was actual human lives.</div><br/></div></div></div></div></div></div><div id="38342767" class="c"><input type="checkbox" id="c-38342767" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#38343824">prev</a><span>|</span><a href="#38343241">next</a><span>|</span><label class="collapse" for="c-38342767">[-]</label><label class="expand" for="c-38342767">[211 more]</label></div><br/><div class="children"><div class="content">I still cannot process what’s happened to one of the most prominent and hyped companies of the past year in just one weekend.<p>If it’s true that Altman won’t return to OpenAI (or alternatively: that the current board won’t step down) then where does that leave OpenAI? Microsoft can’t be happy, as evidenced by reporting that Nadella was acting as mediator to bring him back. Does OpenAI survive this?<p>Will be super interesting when all the details come out regarding the board’s decision making. I’m especially curious how the (former) CEO of Twitch gets nominated as interim CEO.<p>Finally, if Altman goes his own way, it’s clear the fervent support he’s getting will lead to massive funding. Combined with the reporting that he’s trying to create his own AI chips with Middle East funding, Altman has big ambitions for being fully self reliant to own the stack completely.<p>No idea what the future holds for any of the players here. Reality truly is stranger than fiction.</div><br/><div id="38342841" class="c"><input type="checkbox" id="c-38342841" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342886">next</a><span>|</span><label class="collapse" for="c-38342841">[-]</label><label class="expand" for="c-38342841">[119 more]</label></div><br/><div class="children"><div class="content">OpenAI has hundreds more employees, all of whom are incredibly smart. While they will definitely lose the leadership and talent of those two, it’s not as if a nuclear bomb dropped on their HQ and wiped out all their engineers!<p>So questioning whether they will survive seems very silly and incredibly premature to me</div><br/><div id="38342901" class="c"><input type="checkbox" id="c-38342901" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342985">next</a><span>|</span><label class="collapse" for="c-38342901">[-]</label><label class="expand" for="c-38342901">[83 more]</label></div><br/><div class="children"><div class="content">Pretty much every researcher I know at OpenAI who are on twitter re-tweeted Sam Atlman&#x27;s heart tweet with their own heart or some other supportive message.<p>I&#x27;m sure that&#x27;s a sign that they are all team Sam - this includes a ton of researchers you see on most papers that came out of OpenAI. That&#x27;s a good chunk of their research team and that&#x27;d be a very big loss. Also there are tons of engineers (and I know a few of them) who joined OpenAI recently with pure financial incentives. They&#x27;ll jump to Sam&#x27;s new company cause of course that&#x27;s where they&#x27;d make real money.<p>This coupled with investors like Microsoft backing off definitely makes it fair to question the survival of OpenAI in the form we see today.<p>And this is exactly what makes me question Adam D&#x27;Angelo&#x27;s motives as a board member. Maybe he wanted OpenAI to slow down or stop existing, to keep his Poe by Quora (and their custom assistants) relevant. GPT Agents pretty much did what Poe was doing overnight, and you can have as many as them with your existing 20$ ChatGPT Plus subscription. But who knows I&#x27;m just speculating here like everyone else.</div><br/><div id="38343190" class="c"><input type="checkbox" id="c-38343190" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38343718">next</a><span>|</span><label class="collapse" for="c-38343190">[-]</label><label class="expand" for="c-38343190">[22 more]</label></div><br/><div class="children"><div class="content">The heart tweet rebellion is about as meaningful as adding a hashtag supporting one side of your favorite conflict.<p>Come on.  “By 5 pm everyone will quit if you don’t do x”.  Response: tens of heart emojis.</div><br/><div id="38343253" class="c"><input type="checkbox" id="c-38343253" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343190">parent</a><span>|</span><a href="#38343456">next</a><span>|</span><label class="collapse" for="c-38343253">[-]</label><label class="expand" for="c-38343253">[1 more]</label></div><br/><div class="children"><div class="content">It wasn&#x27;t a question of &quot;will these people quit there jobs at OpenAI and get into the job market because they support Sam&quot;.<p>It was a question of whether they&#x27;d leave OpenAI and join a new company that Sam starts with billions in funding at comparable or higher comp.  In that case, of course who the employees are siding with matters.</div><br/></div></div><div id="38343456" class="c"><input type="checkbox" id="c-38343456" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343190">parent</a><span>|</span><a href="#38343253">prev</a><span>|</span><a href="#38343500">next</a><span>|</span><label class="collapse" for="c-38343456">[-]</label><label class="expand" for="c-38343456">[1 more]</label></div><br/><div class="children"><div class="content">Sam hasn&#x27;t yet lined up the funding, so therefore they can&#x27;t yet offer decent jobs, so therefore the  openai employees haven&#x27;t left<p>But they will.</div><br/></div></div><div id="38343500" class="c"><input type="checkbox" id="c-38343500" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343190">parent</a><span>|</span><a href="#38343456">prev</a><span>|</span><a href="#38343648">next</a><span>|</span><label class="collapse" for="c-38343500">[-]</label><label class="expand" for="c-38343500">[1 more]</label></div><br/><div class="children"><div class="content">Talk is easy. But also the good employees will be paid well to get poached.</div><br/></div></div><div id="38343371" class="c"><input type="checkbox" id="c-38343371" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343190">parent</a><span>|</span><a href="#38343648">prev</a><span>|</span><a href="#38343402">next</a><span>|</span><label class="collapse" for="c-38343371">[-]</label><label class="expand" for="c-38343371">[13 more]</label></div><br/><div class="children"><div class="content">Anyone worth a shit will leave and go work with Sam. OpenAI will be left with a bunch of below average grifters.</div><br/><div id="38343563" class="c"><input type="checkbox" id="c-38343563" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343371">parent</a><span>|</span><a href="#38343454">next</a><span>|</span><label class="collapse" for="c-38343563">[-]</label><label class="expand" for="c-38343563">[6 more]</label></div><br/><div class="children"><div class="content">What is it with all this personality cult about founders, CEOs and CTOs nowadays? I thpught the cult around Steve Jobs was, bad it pales in comparison to today.<p>As soon as one person becomes more important than the team, as in the team starts to be structured <i>around</i> said person instead of <i>with</i> the person, that person should be replaced. Because otherwise, the team will not be functioning properly without the &quot;star player&quot; nor is the team more the sum of its members anymore...</div><br/><div id="38343682" class="c"><input type="checkbox" id="c-38343682" checked=""/><div class="controls bullet"><span class="by">OscarTheGrinch</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343563">parent</a><span>|</span><a href="#38344249">prev</a><span>|</span><a href="#38343632">next</a><span>|</span><label class="collapse" for="c-38343682">[-]</label><label class="expand" for="c-38343682">[1 more]</label></div><br/><div class="children"><div class="content">People love to pick sides then retroactively rationalise that decision. None of us reading about it have the facts required to make a rational judgement. So it&#x27;s Johnny vs Amber time.</div><br/></div></div><div id="38343632" class="c"><input type="checkbox" id="c-38343632" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343563">parent</a><span>|</span><a href="#38343682">prev</a><span>|</span><a href="#38343454">next</a><span>|</span><label class="collapse" for="c-38343632">[-]</label><label class="expand" for="c-38343632">[3 more]</label></div><br/><div class="children"><div class="content">While your post sounds like something that would be true, there are loads of examples of where companies have thrived under a clear vision from a specific person.<p>The example of Steve Jobs used in the above post is probably a prime example - Apple just wouldn’t be the company it is today without that period of his singular vision and drive.<p>Of course they struggled after losing him, but the current version of Apple that has lived with Jobs and lost him is probably better than the hypothetical version of Apple where he never returned.<p>Great teams are important, but great teams plus great leadership is better.</div><br/><div id="38344330" class="c"><input type="checkbox" id="c-38344330" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343632">parent</a><span>|</span><a href="#38344113">next</a><span>|</span><label class="collapse" for="c-38344330">[-]</label><label class="expand" for="c-38344330">[1 more]</label></div><br/><div class="children"><div class="content">Steve Jobs is actually a great example: He was, sucessfully at each time, replaced twice, once aftwr he almost ran Apple into the ground and then after his death. In fact, he shoes how to build an org that explicitly does <i>not</i> depend on war star player.</div><br/></div></div><div id="38344113" class="c"><input type="checkbox" id="c-38344113" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343632">parent</a><span>|</span><a href="#38344330">prev</a><span>|</span><a href="#38343454">next</a><span>|</span><label class="collapse" for="c-38344113">[-]</label><label class="expand" for="c-38344113">[1 more]</label></div><br/><div class="children"><div class="content">Newsflash.  Altman is no Steve Jobs.</div><br/></div></div></div></div></div></div><div id="38343454" class="c"><input type="checkbox" id="c-38343454" checked=""/><div class="controls bullet"><span class="by">austhrow743</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343371">parent</a><span>|</span><a href="#38343563">prev</a><span>|</span><a href="#38343414">next</a><span>|</span><label class="collapse" for="c-38343454">[-]</label><label class="expand" for="c-38343454">[5 more]</label></div><br/><div class="children"><div class="content">In a dispute between people willing to sacrifice profit for values and those chasing the profit, why on earth would you put grifters on team values over profit?</div><br/><div id="38343674" class="c"><input type="checkbox" id="c-38343674" checked=""/><div class="controls bullet"><span class="by">bertil</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343454">parent</a><span>|</span><a href="#38343624">next</a><span>|</span><label class="collapse" for="c-38343674">[-]</label><label class="expand" for="c-38343674">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m assuming the original comment meant that the grifters would not be extended a new offer after their colleagues learned that they were not as good as their CV said at open AI.</div><br/></div></div><div id="38343574" class="c"><input type="checkbox" id="c-38343574" checked=""/><div class="controls bullet"><span class="by">throwawayhno</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343454">parent</a><span>|</span><a href="#38343624">prev</a><span>|</span><a href="#38343414">next</a><span>|</span><label class="collapse" for="c-38343574">[-]</label><label class="expand" for="c-38343574">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to hn. Here it&#x27;s all about money</div><br/></div></div></div></div><div id="38343414" class="c"><input type="checkbox" id="c-38343414" checked=""/><div class="controls bullet"><span class="by">Gigablah</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343371">parent</a><span>|</span><a href="#38343454">prev</a><span>|</span><a href="#38343402">next</a><span>|</span><label class="collapse" for="c-38343414">[-]</label><label class="expand" for="c-38343414">[1 more]</label></div><br/><div class="children"><div class="content">Only on HN: your worth is tied to your choice of CEO.</div><br/></div></div></div></div><div id="38343402" class="c"><input type="checkbox" id="c-38343402" checked=""/><div class="controls bullet"><span class="by">happytiger</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343190">parent</a><span>|</span><a href="#38343371">prev</a><span>|</span><a href="#38343718">next</a><span>|</span><label class="collapse" for="c-38343402">[-]</label><label class="expand" for="c-38343402">[4 more]</label></div><br/><div class="children"><div class="content">I take it you have never made a pledge to someone.<p>It’s a signal. The only meaning is the circumstances under which the signal is given: Sam made an ask. These were answers.</div><br/><div id="38343469" class="c"><input type="checkbox" id="c-38343469" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343402">parent</a><span>|</span><a href="#38343520">next</a><span>|</span><label class="collapse" for="c-38343469">[-]</label><label class="expand" for="c-38343469">[2 more]</label></div><br/><div class="children"><div class="content">This is how one answers if they actually intend to quit: <a href="https:&#x2F;&#x2F;x.com&#x2F;gdb&#x2F;status&#x2F;1725667410387378559?s=46&amp;t=Q5EXJgwOhFksDcS2uz525w" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;gdb&#x2F;status&#x2F;1725667410387378559?s=46&amp;t=Q5EXJgwO...</a><p>There’s nothing wrong with not following, it’s a brave and radical thing to do.   A heart emoji tweet doesn’t mean much by itself.</div><br/><div id="38343605" class="c"><input type="checkbox" id="c-38343605" checked=""/><div class="controls bullet"><span class="by">happytiger</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343469">parent</a><span>|</span><a href="#38343520">next</a><span>|</span><label class="collapse" for="c-38343605">[-]</label><label class="expand" for="c-38343605">[1 more]</label></div><br/><div class="children"><div class="content">Did I say there was something wrong with either case? No. I said it was a signal. And it certainly can mean a lot by itself.<p>You can disagree. You can say only explicit non-emoji messages matter. That’s ok. We can agree to disagree.</div><br/></div></div></div></div><div id="38343520" class="c"><input type="checkbox" id="c-38343520" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343402">parent</a><span>|</span><a href="#38343469">prev</a><span>|</span><a href="#38343718">next</a><span>|</span><label class="collapse" for="c-38343520">[-]</label><label class="expand" for="c-38343520">[1 more]</label></div><br/><div class="children"><div class="content">So is this a company or something else that starts with a c? (Thinking of a 4 letter word.)</div><br/></div></div></div></div></div></div><div id="38343718" class="c"><input type="checkbox" id="c-38343718" checked=""/><div class="controls bullet"><span class="by">zq</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38343190">prev</a><span>|</span><a href="#38343667">next</a><span>|</span><label class="collapse" for="c-38343718">[-]</label><label class="expand" for="c-38343718">[1 more]</label></div><br/><div class="children"><div class="content">The two most important to OpenAI&#x27;s mission - Alec Radford and Ilya Sutskever - did not respond with a heart.</div><br/></div></div><div id="38343667" class="c"><input type="checkbox" id="c-38343667" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38343718">prev</a><span>|</span><a href="#38343030">next</a><span>|</span><label class="collapse" for="c-38343667">[-]</label><label class="expand" for="c-38343667">[1 more]</label></div><br/><div class="children"><div class="content">Presumably there is some IP assignment agreement that would make it tricky for Sam to start an OpenAI competitor without a lot of legal exposure?</div><br/></div></div><div id="38343030" class="c"><input type="checkbox" id="c-38343030" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38343667">prev</a><span>|</span><a href="#38342960">next</a><span>|</span><label class="collapse" for="c-38343030">[-]</label><label class="expand" for="c-38343030">[12 more]</label></div><br/><div class="children"><div class="content">Team Sam = Team Money.<p>If you&#x27;re an employee at OpenAI there is a huge opportunity to leave and get in early with decent equity at potentially the next giant tech company.<p>Pretty sure everyone at OpenAI&#x27;s HQ in San Francisco remembers how many overnight millionaires Facebook&#x27;s IPO created.</div><br/><div id="38343201" class="c"><input type="checkbox" id="c-38343201" checked=""/><div class="controls bullet"><span class="by">bnralt</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343154">next</a><span>|</span><label class="collapse" for="c-38343201">[-]</label><label class="expand" for="c-38343201">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a financial incentive. And there will be more opportunity for funding if you jump ship as well (it seems like OpenAI will have difficulty with investors after this).<p>But also, if you&#x27;re a cutting edge researcher, do you want to stay at a company that just ousted the CEO because they thought the speed of technology was going too fast (it&#x27;s sounded like this might be the reason)? You don&#x27;t want to be shackled when by the organization becoming a new MIRI.</div><br/><div id="38343597" class="c"><input type="checkbox" id="c-38343597" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343201">parent</a><span>|</span><a href="#38343154">next</a><span>|</span><label class="collapse" for="c-38343597">[-]</label><label class="expand" for="c-38343597">[1 more]</label></div><br/><div class="children"><div class="content">It seems that MS spent 10 <i>billion</i> to become a minority shareholder in company <i>controlled</i> by a non-profit. They were warned, or maybe even Sam oversold the potential profitability of the investment.<p>Just as another perspective.</div><br/></div></div></div></div><div id="38343154" class="c"><input type="checkbox" id="c-38343154" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343201">prev</a><span>|</span><a href="#38343164">next</a><span>|</span><label class="collapse" for="c-38343154">[-]</label><label class="expand" for="c-38343154">[4 more]</label></div><br/><div class="children"><div class="content">Money = building boring enterprise products, not building AI gods I would suspect</div><br/><div id="38343215" class="c"><input type="checkbox" id="c-38343215" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343154">parent</a><span>|</span><a href="#38343164">next</a><span>|</span><label class="collapse" for="c-38343215">[-]</label><label class="expand" for="c-38343215">[3 more]</label></div><br/><div class="children"><div class="content">OpenAI <i>was</i> building boring enterprise and developer products.<p>Which likely most of the company was working on.</div><br/><div id="38343363" class="c"><input type="checkbox" id="c-38343363" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343215">parent</a><span>|</span><a href="#38343164">next</a><span>|</span><label class="collapse" for="c-38343363">[-]</label><label class="expand" for="c-38343363">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI was building boring enterprise and developer products <i>under Sam Altman&#x27;s leadership</i></div><br/><div id="38344343" class="c"><input type="checkbox" id="c-38344343" checked=""/><div class="controls bullet"><span class="by">mirzap</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343363">parent</a><span>|</span><a href="#38343164">next</a><span>|</span><label class="collapse" for="c-38344343">[-]</label><label class="expand" for="c-38344343">[1 more]</label></div><br/><div class="children"><div class="content">And that could be a core problem. He wasn&#x27;t really free to decide the speed of development. He wanted to change that and deliver faster. Obviously, they achieved something in the past weeks, so doomers pulled the plug to stop him.</div><br/></div></div></div></div></div></div></div></div><div id="38343625" class="c"><input type="checkbox" id="c-38343625" checked=""/><div class="controls bullet"><span class="by">behringer</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343164">prev</a><span>|</span><a href="#38343390">next</a><span>|</span><label class="collapse" for="c-38343625">[-]</label><label class="expand" for="c-38343625">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re looking for money you probably chose wrong going with a non-profit.</div><br/></div></div><div id="38343390" class="c"><input type="checkbox" id="c-38343390" checked=""/><div class="controls bullet"><span class="by">zo1</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343625">prev</a><span>|</span><a href="#38343364">next</a><span>|</span><label class="collapse" for="c-38343390">[-]</label><label class="expand" for="c-38343390">[1 more]</label></div><br/><div class="children"><div class="content">All this talk of a new venture and more money makes this smell highly fishy to me. Take this with a grain of salt, it&#x27;s a random thought.<p>It&#x27;s created huge noise and hype and controversy, and shaken things up to make people &quot;think&quot; they can be in on the next AI hype train &quot;if only&quot; they join whatever Sam Altman does now. Riding the next wave kind of thing because you have FOMO and didn&#x27;t get in on the first wave.</div><br/></div></div><div id="38343364" class="c"><input type="checkbox" id="c-38343364" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343390">prev</a><span>|</span><a href="#38343504">next</a><span>|</span><label class="collapse" for="c-38343364">[-]</label><label class="expand" for="c-38343364">[1 more]</label></div><br/><div class="children"><div class="content">Salaries at openai already make them millionaires.</div><br/></div></div><div id="38343504" class="c"><input type="checkbox" id="c-38343504" checked=""/><div class="controls bullet"><span class="by">tempsy</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343030">parent</a><span>|</span><a href="#38343364">prev</a><span>|</span><a href="#38342960">next</a><span>|</span><label class="collapse" for="c-38343504">[-]</label><label class="expand" for="c-38343504">[1 more]</label></div><br/><div class="children"><div class="content">being a lowly millionaire doesn’t get you much these days. almost certainly anyone who was hired into a mid level or senior role was probably already at least a millionaire</div><br/></div></div></div></div><div id="38343603" class="c"><input type="checkbox" id="c-38343603" checked=""/><div class="controls bullet"><span class="by">behringer</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38342960">prev</a><span>|</span><a href="#38342966">next</a><span>|</span><label class="collapse" for="c-38343603">[-]</label><label class="expand" for="c-38343603">[4 more]</label></div><br/><div class="children"><div class="content">Why a researcher would concern him or herself with management politics is beyond me? Particularly with a glorified sales man. Sounds like they aren&#x27;t spending enough time actually working.</div><br/><div id="38343696" class="c"><input type="checkbox" id="c-38343696" checked=""/><div class="controls bullet"><span class="by">bertil</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343603">parent</a><span>|</span><a href="#38343840">next</a><span>|</span><label class="collapse" for="c-38343696">[-]</label><label class="expand" for="c-38343696">[1 more]</label></div><br/><div class="children"><div class="content">My experience of academic research is that there&#x27;s a lot of energy spent on laboratory politics.</div><br/></div></div><div id="38343840" class="c"><input type="checkbox" id="c-38343840" checked=""/><div class="controls bullet"><span class="by">vvrm</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343603">parent</a><span>|</span><a href="#38343696">prev</a><span>|</span><a href="#38343774">next</a><span>|</span><label class="collapse" for="c-38343840">[-]</label><label class="expand" for="c-38343840">[1 more]</label></div><br/><div class="children"><div class="content">Because a salesman’s skills complements those of a researcher. Salesman sells what the researcher built and brings in money to keep the lights on. Researcher gets to do what they love without having to worry about the real world. That’s a much sweeter deal than a micromanaging PI.</div><br/></div></div><div id="38343774" class="c"><input type="checkbox" id="c-38343774" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343603">parent</a><span>|</span><a href="#38343840">prev</a><span>|</span><a href="#38342966">next</a><span>|</span><label class="collapse" for="c-38343774">[-]</label><label class="expand" for="c-38343774">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just management politics - it&#x27;s about money and what they want to work on.<p>A lot of researchers like to work on cutting edge stuff, that actually ends up in a product. Part of the reason why so many researchers moved from Google to OpenAI was to be able to work on products that get into production.<p>&gt; Particularly with a glorified sales man
&gt; Sounds like they aren&#x27;t spending enough time actually working.
Lmao I love how people come down to personal attacks on people.</div><br/></div></div></div></div><div id="38342966" class="c"><input type="checkbox" id="c-38342966" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38343603">prev</a><span>|</span><a href="#38342965">next</a><span>|</span><label class="collapse" for="c-38342966">[-]</label><label class="expand" for="c-38342966">[19 more]</label></div><br/><div class="children"><div class="content">&gt; Pretty much every researcher I know at OpenAI who are on twitter<p>Selection bias?</div><br/><div id="38343012" class="c"><input type="checkbox" id="c-38343012" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342966">parent</a><span>|</span><a href="#38343209">next</a><span>|</span><label class="collapse" for="c-38343012">[-]</label><label class="expand" for="c-38343012">[16 more]</label></div><br/><div class="children"><div class="content">Not if it&#x27;s a big sample set.  There&#x27;s a guy on twitter who make a list with every OpenAI researcher he could find on twitter and almost all of them did react to Sams tweet in a supportive way.</div><br/><div id="38343233" class="c"><input type="checkbox" id="c-38343233" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343012">parent</a><span>|</span><a href="#38343160">next</a><span>|</span><label class="collapse" for="c-38343233">[-]</label><label class="expand" for="c-38343233">[1 more]</label></div><br/><div class="children"><div class="content">A majority of the early team that joined the non-profit OpenAI over BigTech did not do so for money but for its mission. Post-2019 hires may be more aligned with Sam but the early hires embody OpenAI&#x27;s charter, Sustkever might argue.<p>Of course, OpenAI as a cloud-platform is DoA if Sam leaves, and that&#x27;s a catastrophic business hit to take. It is a very bold decision. Whether it was a stupid one, time will tell.</div><br/></div></div><div id="38343160" class="c"><input type="checkbox" id="c-38343160" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343012">parent</a><span>|</span><a href="#38343233">prev</a><span>|</span><a href="#38343125">next</a><span>|</span><label class="collapse" for="c-38343160">[-]</label><label class="expand" for="c-38343160">[6 more]</label></div><br/><div class="children"><div class="content">&gt; every OpenAI researcher he could find on twitter<p>Literally the literal definition of &#x27;selection bias&#x27; dude, like, the pure unadulterated definition of it.</div><br/><div id="38343216" class="c"><input type="checkbox" id="c-38343216" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343160">parent</a><span>|</span><a href="#38343125">next</a><span>|</span><label class="collapse" for="c-38343216">[-]</label><label class="expand" for="c-38343216">[5 more]</label></div><br/><div class="children"><div class="content">Like I said, if the subset of OpenAI researchers who are on twitter is very small, sure.<p>But people in AI&#x2F;learning community are very active on twitter. I don&#x27;t know every AI researcher on OpenAIs payroll. But the fact that most active researchers (looking at the list of OpenAI paper authors, and tbh the people I know, as a researcher in this space) are on twitter.</div><br/><div id="38343640" class="c"><input type="checkbox" id="c-38343640" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343216">parent</a><span>|</span><a href="#38343298">next</a><span>|</span><label class="collapse" for="c-38343640">[-]</label><label class="expand" for="c-38343640">[3 more]</label></div><br/><div class="children"><div class="content">It seems like you&#x27;re misunderstanding selection bias.<p>It doesn&#x27;t matter if it&#x27;s large, unless the &quot;very active on twitter&quot; group is large enough to be the majority.<p>The point is that there may be (arguably very likely) a trait AI researchers active on Twitter have in common which differentiates them from the population therefore introducing bias.<p>It could be that the 30% (made up) of OpenAI researchers who are active on Twitter are startup&#x2F;business&#x2F;financially oriented and therefore align with Sam Altman. This doesn&#x27;t say as much about the other 70% as you think.</div><br/><div id="38343833" class="c"><input type="checkbox" id="c-38343833" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343640">parent</a><span>|</span><a href="#38343298">next</a><span>|</span><label class="collapse" for="c-38343833">[-]</label><label class="expand" for="c-38343833">[2 more]</label></div><br/><div class="children"><div class="content">You reckon 30% (made up) of staff having a personal &#x27;alignment&#x27; with (or, put another way, &#x27;having sworn an oath of fealty to&#x27;) a CEO is something investors would like?<p>Seems like a bit of a commercial risk there if the CEO can &#x27;make&#x27; a third of the company down tools.</div><br/><div id="38344131" class="c"><input type="checkbox" id="c-38344131" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343833">parent</a><span>|</span><a href="#38343298">next</a><span>|</span><label class="collapse" for="c-38344131">[-]</label><label class="expand" for="c-38344131">[1 more]</label></div><br/><div class="children"><div class="content">I randomly chose 30% to represent a seemingly large non majority sample which may not be representative of the underlying population.<p>I have no idea what the actual proportion is, nor how investors feel about this right now.<p>The true proportion of researchers who actively voice their political positions on twitter is probably much smaller and almost certainly a biased sample.</div><br/></div></div></div></div></div></div><div id="38343298" class="c"><input type="checkbox" id="c-38343298" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343216">parent</a><span>|</span><a href="#38343640">prev</a><span>|</span><a href="#38343125">next</a><span>|</span><label class="collapse" for="c-38343298">[-]</label><label class="expand" for="c-38343298">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But the fact that most active researchers ... are on twitter<p>On twitter != &#x27;active on twitter&#x27;<p>There&#x27;s a biiiiiig difference between being &#x27;on twitter&#x27; and what I shall refer to kindly as terminally online behaviour aka &#x27;very active on twitter.&#x27;</div><br/></div></div></div></div></div></div><div id="38343125" class="c"><input type="checkbox" id="c-38343125" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343012">parent</a><span>|</span><a href="#38343160">prev</a><span>|</span><a href="#38343474">next</a><span>|</span><label class="collapse" for="c-38343125">[-]</label><label class="expand" for="c-38343125">[1 more]</label></div><br/><div class="children"><div class="content">Large sample =&#x2F;= (inherently) representative. What percentage of OpenAI researchers are on Twitter?<p>Follow-up: Why is only some fraction on Twitter?<p>This is almost certainly a confounder, as is often the case when discussing reactions on Twitter vs reactions in the population.</div><br/></div></div><div id="38343474" class="c"><input type="checkbox" id="c-38343474" checked=""/><div class="controls bullet"><span class="by">djvdq</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343012">parent</a><span>|</span><a href="#38343125">prev</a><span>|</span><a href="#38343211">next</a><span>|</span><label class="collapse" for="c-38343474">[-]</label><label class="expand" for="c-38343474">[1 more]</label></div><br/><div class="children"><div class="content">They can support Sam, but still stay in the company.</div><br/></div></div><div id="38343211" class="c"><input type="checkbox" id="c-38343211" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343012">parent</a><span>|</span><a href="#38343474">prev</a><span>|</span><a href="#38343209">next</a><span>|</span><label class="collapse" for="c-38343211">[-]</label><label class="expand" for="c-38343211">[6 more]</label></div><br/><div class="children"><div class="content">How childish are employees to publicly get involved with this on Twitter?<p>If the CEO of my company got shitcanned and then he&#x2F;she and the board were feuding?<p>... I&#x27;d talk to my colleagues and friends privately, and not go anywhere near the dumpster fire publicly. If I felt strongly, hell, turn in my resignation. But 100% &quot;no comment&quot; in public.</div><br/><div id="38343501" class="c"><input type="checkbox" id="c-38343501" checked=""/><div class="controls bullet"><span class="by">djvdq</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343211">parent</a><span>|</span><a href="#38343438">next</a><span>|</span><label class="collapse" for="c-38343501">[-]</label><label class="expand" for="c-38343501">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You should find a better place to work.<p>Work is work. If you start being emotional about it, it&#x27;s a bad, not good, thing.</div><br/><div id="38343623" class="c"><input type="checkbox" id="c-38343623" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343501">parent</a><span>|</span><a href="#38343438">next</a><span>|</span><label class="collapse" for="c-38343623">[-]</label><label class="expand" for="c-38343623">[1 more]</label></div><br/><div class="children"><div class="content">Nah, it&#x27;s fine to be passionate about your work and relationships with your colleagues.<p>You just need to temper that before you start swearing oaths of fealty on twitter; because that&#x27;s giving real Jim Jones vibes which isn&#x27;t a good thing.</div><br/></div></div></div></div><div id="38343432" class="c"><input type="checkbox" id="c-38343432" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343211">parent</a><span>|</span><a href="#38343438">prev</a><span>|</span><a href="#38343429">next</a><span>|</span><label class="collapse" for="c-38343432">[-]</label><label class="expand" for="c-38343432">[1 more]</label></div><br/><div class="children"><div class="content">tl;dr: Any OAI employee tweeting about this is unhinged.</div><br/></div></div><div id="38343429" class="c"><input type="checkbox" id="c-38343429" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343211">parent</a><span>|</span><a href="#38343432">prev</a><span>|</span><a href="#38343209">next</a><span>|</span><label class="collapse" for="c-38343429">[-]</label><label class="expand" for="c-38343429">[1 more]</label></div><br/><div class="children"><div class="content">These are people very active on Twitter and work for a company that unashamedly harvested all of the data it could for free with out asking to make money. It&#x27;s not like shame and self-respect are allowed anywhere near this company.</div><br/></div></div></div></div></div></div><div id="38343209" class="c"><input type="checkbox" id="c-38343209" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342966">parent</a><span>|</span><a href="#38343012">prev</a><span>|</span><a href="#38342965">next</a><span>|</span><label class="collapse" for="c-38343209">[-]</label><label class="expand" for="c-38343209">[2 more]</label></div><br/><div class="children"><div class="content">Which would mean that he specifically selected who to follow due to their closeness to &#x2F; alignment with Sam, pre-ousting? How would he do that?</div><br/><div id="38343477" class="c"><input type="checkbox" id="c-38343477" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343209">parent</a><span>|</span><a href="#38342965">next</a><span>|</span><label class="collapse" for="c-38343477">[-]</label><label class="expand" for="c-38343477">[1 more]</label></div><br/><div class="children"><div class="content">Big question!</div><br/></div></div></div></div></div></div><div id="38342965" class="c"><input type="checkbox" id="c-38342965" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38342966">prev</a><span>|</span><a href="#38342949">next</a><span>|</span><label class="collapse" for="c-38342965">[-]</label><label class="expand" for="c-38342965">[14 more]</label></div><br/><div class="children"><div class="content">It&#x27;s always been my observation that the actual heavyweights of any hardcore engineering project are the ones that avoid snarky lightweight platforms like twitter like the plague.<p>I would imagine that if you based hiring and firing decisions on the metric of &#x27;how often this employee tweets&#x27; you could quite effectively cut deadwood.<p>With that in mind...</div><br/><div id="38342997" class="c"><input type="checkbox" id="c-38342997" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342965">parent</a><span>|</span><a href="#38343003">next</a><span>|</span><label class="collapse" for="c-38342997">[-]</label><label class="expand" for="c-38342997">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the case with AI community. Twitter is heavily used by almost every professor&#x2F;researcher&#x2F;PhD student who is doing learning. Ilya has one. Heck even Jitendra Malik who&#x27;s probably as old as my grand father joined twitter.</div><br/><div id="38343737" class="c"><input type="checkbox" id="c-38343737" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342997">parent</a><span>|</span><a href="#38343003">next</a><span>|</span><label class="collapse" for="c-38343737">[-]</label><label class="expand" for="c-38343737">[1 more]</label></div><br/><div class="children"><div class="content">Mostly for professional purposes such as networking and promoting academic activities. Sometimes for their side startups.<p>I rarely see a professor or PhD student voicing a political viewpoint (which is what the Sam Altman vs Ilya Sutskever debate is) on their Twitter.</div><br/></div></div></div></div><div id="38343003" class="c"><input type="checkbox" id="c-38343003" checked=""/><div class="controls bullet"><span class="by">OfficialTurkey</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342965">parent</a><span>|</span><a href="#38342997">prev</a><span>|</span><a href="#38343070">next</a><span>|</span><label class="collapse" for="c-38343003">[-]</label><label class="expand" for="c-38343003">[3 more]</label></div><br/><div class="children"><div class="content">I have never used twitter but this strikes me as a strange take at best. Many of the most brilliant and passionate engineers I&#x27;ve had the pleasure to work with have been massive shitposters.</div><br/><div id="38343026" class="c"><input type="checkbox" id="c-38343026" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343003">parent</a><span>|</span><a href="#38343070">next</a><span>|</span><label class="collapse" for="c-38343026">[-]</label><label class="expand" for="c-38343026">[2 more]</label></div><br/><div class="children"><div class="content">&gt; massive shitposters<p>Yes, agreed, but on _twitter_?<p>The massive_disgruntled_engineer_rant does have a lot of precedent but I&#x27;ve never considered twitter to be their domain. Mailing lists, maybe.</div><br/><div id="38343985" class="c"><input type="checkbox" id="c-38343985" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343026">parent</a><span>|</span><a href="#38343070">next</a><span>|</span><label class="collapse" for="c-38343985">[-]</label><label class="expand" for="c-38343985">[1 more]</label></div><br/><div class="children"><div class="content">Yes, on Twitter. Mailing lists are old boomer shit.</div><br/></div></div></div></div></div></div><div id="38343070" class="c"><input type="checkbox" id="c-38343070" checked=""/><div class="controls bullet"><span class="by">kvathupo</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342965">parent</a><span>|</span><a href="#38343003">prev</a><span>|</span><a href="#38343035">next</a><span>|</span><label class="collapse" for="c-38343070">[-]</label><label class="expand" for="c-38343070">[1 more]</label></div><br/><div class="children"><div class="content">Completely disagree: Yann LeCun, John Carmack, Rui Ueyama, Andrei Alexandrescu, Matt Goldbolt, Horace He, Tarun Chitra, George Hotz, etc.</div><br/></div></div><div id="38343035" class="c"><input type="checkbox" id="c-38343035" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342965">parent</a><span>|</span><a href="#38343070">prev</a><span>|</span><a href="#38343127">next</a><span>|</span><label class="collapse" for="c-38343035">[-]</label><label class="expand" for="c-38343035">[1 more]</label></div><br/><div class="children"><div class="content">Discredit people using twitter is a weird take, and didn&#x27;t resemble critical thinking to me.</div><br/></div></div><div id="38343127" class="c"><input type="checkbox" id="c-38343127" checked=""/><div class="controls bullet"><span class="by">dorkwood</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342965">parent</a><span>|</span><a href="#38343035">prev</a><span>|</span><a href="#38343369">next</a><span>|</span><label class="collapse" for="c-38343127">[-]</label><label class="expand" for="c-38343127">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s always been my observation that the actual heavyweights of any hardcore engineering project are the ones that avoid snarky lightweight platforms like twitter like the plague.<p>What other places are there to engage with the developer community?</div><br/><div id="38343219" class="c"><input type="checkbox" id="c-38343219" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343127">parent</a><span>|</span><a href="#38343369">next</a><span>|</span><label class="collapse" for="c-38343219">[-]</label><label class="expand" for="c-38343219">[2 more]</label></div><br/><div class="children"><div class="content">Engagement is not necessarily constructive engagement</div><br/><div id="38343449" class="c"><input type="checkbox" id="c-38343449" checked=""/><div class="controls bullet"><span class="by">dorkwood</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343219">parent</a><span>|</span><a href="#38343369">next</a><span>|</span><label class="collapse" for="c-38343449">[-]</label><label class="expand" for="c-38343449">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a strange thing to say. I find a lot of value in the developer community on Twitter. I wouldn&#x27;t have my career without it.<p>I also wasn&#x27;t being facetious. If there are other places to share work and ideas with developers online, I&#x27;d love to hear about them!</div><br/></div></div></div></div></div></div></div></div><div id="38342949" class="c"><input type="checkbox" id="c-38342949" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342901">parent</a><span>|</span><a href="#38342965">prev</a><span>|</span><a href="#38342985">next</a><span>|</span><label class="collapse" for="c-38342949">[-]</label><label class="expand" for="c-38342949">[8 more]</label></div><br/><div class="children"><div class="content">Also, serious investors won&#x27;t touch OpenAI with a ten foot pole after these events.<p>There&#x27;s an idealistic bunch of people that think this was the best thing to happen to OpenAI, time will tell but I personally think this is the end of the company (and Ilya).<p>Satya must be quite pissed off and rightly so, he gave them big money, believed in them and got backstabbed as well; disregarding @sama, MS is their single largest investor and it didn&#x27;t even warrant a courtesy phone call to let them know of all this fiasco (even thought some savants were saying they shouldn&#x27;t have to, because they &quot;only&quot; owned 49% of the LLC. LMAO).<p>Next bit of news will be Microsoft pulling out of the deal but, unlike this board, Satya is not a manchild going through a crisis, so it will happen without it being a scandal. MS should probably just grow their own AI in-house at this point, they have all the resources in the world to do so. People who think that MS (a ~50 old company, with 200k employees, valued at almost 3 <i>trillion</i>) is now lost without OpenAI and the Ilya gang must have room temperature IQs.</div><br/><div id="38343222" class="c"><input type="checkbox" id="c-38343222" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342949">parent</a><span>|</span><a href="#38343225">next</a><span>|</span><label class="collapse" for="c-38343222">[-]</label><label class="expand" for="c-38343222">[4 more]</label></div><br/><div class="children"><div class="content">200k MS employees can&#x27;t do what 500 from OAI can, the more you pile on the problem, the worse the outcome. The problem with Microsoft is that, like Google, Amazon and IBM, they are not a good medium for radical innovation, are old, ossified companies. Apple used to be nimble when Steve was alive, but went to coasting mode since then. Having large revenue from old business is an obstacle in the new world, maybe Apple was nimble because it had small market share.</div><br/><div id="38343386" class="c"><input type="checkbox" id="c-38343386" checked=""/><div class="controls bullet"><span class="by">codebolt</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343222">parent</a><span>|</span><a href="#38343542">next</a><span>|</span><label class="collapse" for="c-38343386">[-]</label><label class="expand" for="c-38343386">[1 more]</label></div><br/><div class="children"><div class="content">MS isn&#x27;t starting from scratch, it already has the weights of the worlds most powerful LM, and it&#x27;s all running on their datacenters. Even without Sam, they just need to keep the current momentum going. Maybe axe ChatGPT and focus solely on Bing&#x2F;Copilot going forward. It would give me great satisfaction to see the laughing stock search engine of the past decade being the undisputed face of AI over the next.</div><br/></div></div><div id="38343542" class="c"><input type="checkbox" id="c-38343542" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343222">parent</a><span>|</span><a href="#38343386">prev</a><span>|</span><a href="#38343225">next</a><span>|</span><label class="collapse" for="c-38343542">[-]</label><label class="expand" for="c-38343542">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Apple used to be nimble when Steve was alive, but went to coasting mode since then<p>Give me a break. Apple Watch and Air pods are far and away leaders in their category, Apple&#x27;s silicon is a huge leap forward, there is innovation in displays, CarPlay is the standard auto interface for millions of people, while I may question the utility the Vision Pro is a technological marvel, iPhone is still a juggernaut (and the only one of these examples that predate Jobs&#x27; passing), etc. etc.<p>Other companies dream about &quot;coasting&quot; as successfully.</div><br/><div id="38343618" class="c"><input type="checkbox" id="c-38343618" checked=""/><div class="controls bullet"><span class="by">Freedom2</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343542">parent</a><span>|</span><a href="#38343225">next</a><span>|</span><label class="collapse" for="c-38343618">[-]</label><label class="expand" for="c-38343618">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Apple Watch and Air pods are far and away leaders in their category,<p>By what metric? I prefer open hardware and modifiable software - these products are in no way leaders for me. Not to mention all the bluetooth issues my family and friends have had when trying to use them.</div><br/></div></div></div></div></div></div><div id="38343225" class="c"><input type="checkbox" id="c-38343225" checked=""/><div class="controls bullet"><span class="by">cloverich</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342949">parent</a><span>|</span><a href="#38343222">prev</a><span>|</span><a href="#38343742">next</a><span>|</span><label class="collapse" for="c-38343225">[-]</label><label class="expand" for="c-38343225">[1 more]</label></div><br/><div class="children"><div class="content">My first question to this scenario would be: Could MS provide the seed funding for Sam&#x27;s next gig? As in, they bet on OpenAI, and either OpenAI keeps on keeping on or Sam&#x27;s gig steals the thunder, and they presumably have the cash to play a role in both.</div><br/></div></div><div id="38343742" class="c"><input type="checkbox" id="c-38343742" checked=""/><div class="controls bullet"><span class="by">didibus</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342949">parent</a><span>|</span><a href="#38343225">prev</a><span>|</span><a href="#38343377">next</a><span>|</span><label class="collapse" for="c-38343742">[-]</label><label class="expand" for="c-38343742">[1 more]</label></div><br/><div class="children"><div class="content">But OpenAI is a non for profit that was exploring a goal that it saw financial incentives as misaligned.<p>It&#x27;s what kind of got it achieved. Because every other company didn&#x27;t really see the benefit of going straight to AGI, instead working on incremental addition and small iteration.<p>I don&#x27;t know why the board decided to do what it did, but maybe it sees that OpenAI was moving away from R&amp;D and too much into operations and selling a product.<p>So my point is that, OpenAI started as a charity and literally was setup in a way to protect that model, by having the for-profit arm be governed by the non-for-profit wing.<p>The funny thing is, Sam Altman himself was part of the people who wanted it that way, along with Elon Musk, Illya and others.<p>And I kind of agree, what kind of future is there here? OoenAI becomes another billion dollar startup that what? Eventually sells out with a big exit?<p>It&#x27;s possible to see the whole venture as taking away from the goal set out by the non for profit.</div><br/></div></div></div></div></div></div><div id="38342985" class="c"><input type="checkbox" id="c-38342985" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342901">prev</a><span>|</span><a href="#38342893">next</a><span>|</span><label class="collapse" for="c-38342985">[-]</label><label class="expand" for="c-38342985">[19 more]</label></div><br/><div class="children"><div class="content">Survive as existing? They will.<p>But this is a disaster that can&#x27;t be sugarcoated. Working in an AI company with a doomer as head is ridiculous. It will be like working in a tobacco company advocating for lung cancer awareness.<p>I don&#x27;t think the new CEO can do anything to get back trust in record short amount of time. The sam loyalists will leave. The question remain, how is the new CEO going to hire new people, and will he be able to do so fast enough, and the ones who remain will accept the company that is a drastically different.</div><br/><div id="38343076" class="c"><input type="checkbox" id="c-38343076" checked=""/><div class="controls bullet"><span class="by">peanuty1</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342985">parent</a><span>|</span><a href="#38343036">next</a><span>|</span><label class="collapse" for="c-38343076">[-]</label><label class="expand" for="c-38343076">[3 more]</label></div><br/><div class="children"><div class="content">Surely the employees knew before joining that OpenAI is a non-profit aiming to develop safe AGI?</div><br/><div id="38343269" class="c"><input type="checkbox" id="c-38343269" checked=""/><div class="controls bullet"><span class="by">alexgartrell</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343076">parent</a><span>|</span><a href="#38343277">next</a><span>|</span><label class="collapse" for="c-38343269">[-]</label><label class="expand" for="c-38343269">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s recruiting pitch was 5-10+ million&#x2F;year in the form of equity. The structure of the grants is super weird by traditional big-company standards, but it was plausible enough that you could squint and call it the same. I&#x27;d posit that many of the people jumping to OpenAI are doing it for the cash and not the mission.<p><a href="https:&#x2F;&#x2F;the-decoder.com&#x2F;openai-lures-googles-top-ai-researchers-with-multimillion-dollar-offers&#x2F;#:~:text=OpenAI&#x27;s%20recruiters%20are%20targeting%20senior,Information%20reported%2C%20citing%20insider%20sources" rel="nofollow noreferrer">https:&#x2F;&#x2F;the-decoder.com&#x2F;openai-lures-googles-top-ai-research...</a>.</div><br/></div></div><div id="38343277" class="c"><input type="checkbox" id="c-38343277" checked=""/><div class="controls bullet"><span class="by">sgift</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343076">parent</a><span>|</span><a href="#38343269">prev</a><span>|</span><a href="#38343036">next</a><span>|</span><label class="collapse" for="c-38343277">[-]</label><label class="expand" for="c-38343277">[1 more]</label></div><br/><div class="children"><div class="content">They thought so. Now, they know that instead they work for one aiming to satisfy the ego of a specific group of people - same as everywhere else.</div><br/></div></div></div></div><div id="38343036" class="c"><input type="checkbox" id="c-38343036" checked=""/><div class="controls bullet"><span class="by">bottlepalm</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342985">parent</a><span>|</span><a href="#38343076">prev</a><span>|</span><a href="#38342893">next</a><span>|</span><label class="collapse" for="c-38343036">[-]</label><label class="expand" for="c-38343036">[15 more]</label></div><br/><div class="children"><div class="content">Ah yes you&#x27;re either a doomer or e&#x2F;acc. Pick an extreme. Everything must be polarized.</div><br/><div id="38343444" class="c"><input type="checkbox" id="c-38343444" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343036">parent</a><span>|</span><a href="#38342893">next</a><span>|</span><label class="collapse" for="c-38343444">[-]</label><label class="expand" for="c-38343444">[14 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a character in HPMOR named after the new CEO.<p>(That&#x27;s the religious text of the anti-AI cult that founded OpenAI. It&#x27;s in the form of a very long Harry Potter fanfic.)</div><br/><div id="38343792" class="c"><input type="checkbox" id="c-38343792" checked=""/><div class="controls bullet"><span class="by">tempusalaria</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343444">parent</a><span>|</span><a href="#38343524">next</a><span>|</span><label class="collapse" for="c-38343792">[-]</label><label class="expand" for="c-38343792">[2 more]</label></div><br/><div class="children"><div class="content">Imagine how bad a reputation EA would have if the general public knew about HPMOR</div><br/><div id="38344891" class="c"><input type="checkbox" id="c-38344891" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343792">parent</a><span>|</span><a href="#38343524">next</a><span>|</span><label class="collapse" for="c-38344891">[-]</label><label class="expand" for="c-38344891">[1 more]</label></div><br/><div class="children"><div class="content">Even HP fanfiction lovers HATED HPMOR. It had a clowny reputation<p>It is wild to see how closely connected the web is though. Yudkowsky, Shear, and Sutskever. The EA movement today controls a staggering amount of power.</div><br/></div></div></div></div><div id="38343524" class="c"><input type="checkbox" id="c-38343524" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343444">parent</a><span>|</span><a href="#38343792">prev</a><span>|</span><a href="#38343487">next</a><span>|</span><label class="collapse" for="c-38343524">[-]</label><label class="expand" for="c-38343524">[10 more]</label></div><br/><div class="children"><div class="content">Sorry, which character are you talking about? (Also lol &quot;religious text&quot;, how dare people have didactic opinions.)</div><br/><div id="38343576" class="c"><input type="checkbox" id="c-38343576" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343524">parent</a><span>|</span><a href="#38343487">next</a><span>|</span><label class="collapse" for="c-38343576">[-]</label><label class="expand" for="c-38343576">[9 more]</label></div><br/><div class="children"><div class="content">The one with the same name as the new CEO. Pretty straightforward.<p>&gt; Also lol &quot;religious text&quot;, how dare people have didactic opinions.<p>That&#x27;s not what a religious text is, that&#x27;d just be a blog post. It&#x27;s the part where reading it causes you to join a cult group house polycule and donate all your money to stopping computers from becoming alive.</div><br/><div id="38343651" class="c"><input type="checkbox" id="c-38343651" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343576">parent</a><span>|</span><a href="#38343487">next</a><span>|</span><label class="collapse" for="c-38343651">[-]</label><label class="expand" for="c-38343651">[8 more]</label></div><br/><div class="children"><div class="content">Oh hey there he is, cool. I had a typo in my search, I think.<p>&gt; That&#x27;s not what a religious text is, that&#x27;d just be a blog post.<p>Yes, almost as if &quot;Lesswrong is a <i>community blog</i> dedicated to refining the art of human rationality.&quot;<p>&gt; It&#x27;s the part where reading it causes you to join a cult group house polycule and donate all your money to stopping computers from becoming alive.<p>I don&#x27;t think anybody either asked somebody to, or actually did, donate all their money. As to &quot;joining a cult group house polycule&quot;, to my knowledge that&#x27;s just SF. There&#x27;s certainly nothing in the Sequences about how you have to join a cult group house polycule. To be honest, I consider all the people who joined cult group house polycules, whose existence I don&#x27;t deny, to have a preexisting cult group house polycule situational condition. (Living in San Francisco, that is.)</div><br/><div id="38344036" class="c"><input type="checkbox" id="c-38344036" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343651">parent</a><span>|</span><a href="#38343863">next</a><span>|</span><label class="collapse" for="c-38344036">[-]</label><label class="expand" for="c-38344036">[1 more]</label></div><br/><div class="children"><div class="content">Well, Berkeley isn&#x27;t exactly San Francisco, but joining cults is all those people get up to there. Some are Buddhist, some are Leverage, some are Lesswrong.<p>The most recent case was notably in the Bahamas though.</div><br/></div></div><div id="38343863" class="c"><input type="checkbox" id="c-38343863" checked=""/><div class="controls bullet"><span class="by">avalys</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343651">parent</a><span>|</span><a href="#38344036">prev</a><span>|</span><a href="#38343487">next</a><span>|</span><label class="collapse" for="c-38343863">[-]</label><label class="expand" for="c-38343863">[6 more]</label></div><br/><div class="children"><div class="content">“The Sequences”? Yes, this doesn’t sound like a quasi-religious cult at all…</div><br/><div id="38344024" class="c"><input type="checkbox" id="c-38344024" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343863">parent</a><span>|</span><a href="#38344041">next</a><span>|</span><label class="collapse" for="c-38344024">[-]</label><label class="expand" for="c-38344024">[4 more]</label></div><br/><div class="children"><div class="content">The message is that if you do math in your head in a specific way involving Bayes&#x27; theorem, it will make you always right about everything. So it&#x27;s not even quasi-religious, the good deity is probability theory and the bad one is evil computer gods.<p>This then causes young men to decide they should be in open relationships because it&#x27;s &quot;more logical&quot;, and then decide they need to spend their life fighting evil computer gods because the Bayes&#x27; theorem thing is weak to an attack called &quot;Pascal&#x27;s mugging&quot; where you tell them an infinitely bad thing has a finite chance of happening if they don&#x27;t stop it.<p>Also they invent effective altruism, which works until the math tells them it&#x27;s ethical to steal a bunch of investor money as long as you use it on charity.<p><a href="https:&#x2F;&#x2F;metarationality.com&#x2F;bayesianism-updating" rel="nofollow noreferrer">https:&#x2F;&#x2F;metarationality.com&#x2F;bayesianism-updating</a><p>Bit old but still relevant.</div><br/><div id="38344073" class="c"><input type="checkbox" id="c-38344073" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344024">parent</a><span>|</span><a href="#38344041">next</a><span>|</span><label class="collapse" for="c-38344073">[-]</label><label class="expand" for="c-38344073">[3 more]</label></div><br/><div class="children"><div class="content">&gt; This then causes young men to decide they should be in open relationships because it&#x27;s &quot;more logical&quot;<p>Yes, which is 100% because of &quot;LessWrong&quot; and 0% because groups of young nerds do that every time, so much so that there&#x27;s actually an XKCD about it (<a href="https:&#x2F;&#x2F;xkcd.com&#x2F;592&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;xkcd.com&#x2F;592&#x2F;</a>).<p>The actual message regarding Bayes&#x27; Theorem is that there <i>is</i> a correct way to respond to evidence in the first place. LessWrong does not mandate, nor would that be a good idea, that you manually calculate these updates: humans are very bad at it.<p>&gt; Also they invent effective altruism, which works until the math tells them it&#x27;s ethical to steal a bunch of investor money as long as you use it on charity.<p>Given that this didn&#x27;t happen with anyone else, and most other EAs will tell you that it&#x27;s morally correct to uphold the law, and in any case nearly all EAs will <i>act</i> like it&#x27;s morally correct, I&#x27;m inclined to think this was an SBF thing, not an EA thing. Every belief system will have antisocial adherents.</div><br/><div id="38344175" class="c"><input type="checkbox" id="c-38344175" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344073">parent</a><span>|</span><a href="#38344041">next</a><span>|</span><label class="collapse" for="c-38344175">[-]</label><label class="expand" for="c-38344175">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The actual message regarding Bayes&#x27; Theorem is that there is a correct way to respond to evidence in the first place.<p>No, there isn&#x27;t a correct way to do anything in the real world, only in logic problems.<p>This would be well known if anyone had read philosophy; it&#x27;s the failed program of logical positivism. (Also the failed 70s-ish AI programs of GOFAI.)<p>The main reason it doesn&#x27;t work is that you don&#x27;t know what all the counterfactuals are, so you&#x27;ll miss one. Aka what Rumsfeld once called &quot;unknown unknowns&quot;.<p><a href="https:&#x2F;&#x2F;metarationality.com&#x2F;probabilism" rel="nofollow noreferrer">https:&#x2F;&#x2F;metarationality.com&#x2F;probabilism</a><p>&gt; Given that this didn&#x27;t happen with anyone else<p>They&#x27;re instead buying castles, deciding scientific racism is real (though still buying mosquito nets for the people they&#x27;re racist about), and getting tripped up reinventing Jainism when they realize drinking water causes infinite harm to microscopic shrimp.<p>And of course, they think evil computer gods are going to kill them.</div><br/><div id="38344267" class="c"><input type="checkbox" id="c-38344267" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344175">parent</a><span>|</span><a href="#38344041">next</a><span>|</span><label class="collapse" for="c-38344267">[-]</label><label class="expand" for="c-38344267">[1 more]</label></div><br/><div class="children"><div class="content">&gt; No, there isn&#x27;t a correct way to do anything in the real world, only in logic problems.<p>Agree to disagree? If there&#x27;s one thing physics teaches us, it&#x27;s that the real world is just math. I mean, re GOFAI, it&#x27;s not like Transformers and DL are any <i>less</i> &quot;logic problem&quot; than Eurisko or Eliza were. Re counterfactuals, yes, the problem is uncomputable at the limit. That&#x27;s not &quot;unknown unknowns&quot;, that&#x27;s just the problem of induction. However, it&#x27;s not like there&#x27;s any alternative system of knowledge that can do better. The point isn&#x27;t to be right all the time, the point is to make <i>optimal use of available evidence.</i><p>&gt; buying castles<p>They make the case that the castle was good value for money, and given the insane overhead for renting meeting spaces, I&#x27;m inclined to believe them.<p>&gt; scientific racism is real (though still buying mosquito nets for the people they&#x27;re racist about)<p>Honestly, give me scientific racists who buy mosquito nets over antiracists who don&#x27;t any day.<p>&gt; getting tripped up reinventing Jainism when they realize drinking water causes infinite harm to microscopic shrimp.<p>As far as I can tell, that&#x27;s one guy.<p>&gt; And of course, they think evil computer gods are going to kill them.<p>I mean, I do think that, yes. Got any argument against it other than &quot;lol sci-fi&quot;?</div><br/></div></div></div></div></div></div></div></div><div id="38344041" class="c"><input type="checkbox" id="c-38344041" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343863">parent</a><span>|</span><a href="#38344024">prev</a><span>|</span><a href="#38343487">next</a><span>|</span><label class="collapse" for="c-38344041">[-]</label><label class="expand" for="c-38344041">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can tell, any single noun that&#x27;s capitalized sounds religious. I blame the Bible. However, in this case it&#x27;s just a short-hand for the sequences of topically related blog posts written by Eliezer between 2006 and 2009, which are written to fit together as one interconnected work. (<a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;tag&#x2F;sequences" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;tag&#x2F;sequences</a> , <a href="https:&#x2F;&#x2F;www.readthesequences.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.readthesequences.com&#x2F;</a>)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38343487" class="c"><input type="checkbox" id="c-38343487" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343444">parent</a><span>|</span><a href="#38343524">prev</a><span>|</span><a href="#38342893">next</a><span>|</span><label class="collapse" for="c-38343487">[-]</label><label class="expand" for="c-38343487">[1 more]</label></div><br/><div class="children"><div class="content">Is Chat GPT writing this whole dialogue?</div><br/></div></div></div></div></div></div></div></div><div id="38342893" class="c"><input type="checkbox" id="c-38342893" checked=""/><div class="controls bullet"><span class="by">questime</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342985">prev</a><span>|</span><a href="#38343163">next</a><span>|</span><label class="collapse" for="c-38342893">[-]</label><label class="expand" for="c-38342893">[1 more]</label></div><br/><div class="children"><div class="content">The perception right now is that the board doesn&#x27;t care about investors, this will kill this company that is burning money at an insane rate. Employees will run for the exits unless they are convinced that there is a future exit.</div><br/></div></div><div id="38343163" class="c"><input type="checkbox" id="c-38343163" checked=""/><div class="controls bullet"><span class="by">thekevan</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342893">prev</a><span>|</span><a href="#38342872">next</a><span>|</span><label class="collapse" for="c-38343163">[-]</label><label class="expand" for="c-38343163">[1 more]</label></div><br/><div class="children"><div class="content">Funny you should reference a nuclear bomb. This was 14 minutes after your post.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1726478716166123851" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1726478716166123851</a></div><br/></div></div><div id="38342872" class="c"><input type="checkbox" id="c-38342872" checked=""/><div class="controls bullet"><span class="by">jxf</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38343163">prev</a><span>|</span><a href="#38343151">next</a><span>|</span><label class="collapse" for="c-38342872">[-]</label><label class="expand" for="c-38342872">[6 more]</label></div><br/><div class="children"><div class="content">But a number of those other employees have said they&#x27;ll leave if Altman isn&#x27;t rehired.</div><br/><div id="38342945" class="c"><input type="checkbox" id="c-38342945" checked=""/><div class="controls bullet"><span class="by">zombiwoof</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342872">parent</a><span>|</span><a href="#38343151">next</a><span>|</span><label class="collapse" for="c-38342945">[-]</label><label class="expand" for="c-38342945">[5 more]</label></div><br/><div class="children"><div class="content">Bullshit. They are not quitting</div><br/><div id="38342986" class="c"><input type="checkbox" id="c-38342986" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342945">parent</a><span>|</span><a href="#38343649">next</a><span>|</span><label class="collapse" for="c-38342986">[-]</label><label class="expand" for="c-38342986">[1 more]</label></div><br/><div class="children"><div class="content">Even if you don’t believe many employees would consider leaving for Altman, I find it probable that many would consider leaving for financial reasons. What will their PPUs be worth if OpenAI is seen as a funding risk?</div><br/></div></div><div id="38343649" class="c"><input type="checkbox" id="c-38343649" checked=""/><div class="controls bullet"><span class="by">bartimus</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342945">parent</a><span>|</span><a href="#38342986">prev</a><span>|</span><a href="#38342984">next</a><span>|</span><label class="collapse" for="c-38343649">[-]</label><label class="expand" for="c-38343649">[1 more]</label></div><br/><div class="children"><div class="content">Maybe not instantly. But there&#x27;s a version where they don&#x27;t agree with certain decisions and will now be more open to other opportunities.</div><br/></div></div><div id="38342984" class="c"><input type="checkbox" id="c-38342984" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342945">parent</a><span>|</span><a href="#38343649">prev</a><span>|</span><a href="#38343739">next</a><span>|</span><label class="collapse" for="c-38342984">[-]</label><label class="expand" for="c-38342984">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re either not quitting or they&#x27;ve outed themselves as being part of a personality cult and they&#x27;ll just hinder things if they&#x27;re not ejected promptly.</div><br/></div></div><div id="38343739" class="c"><input type="checkbox" id="c-38343739" checked=""/><div class="controls bullet"><span class="by">icy_deadposts</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342945">parent</a><span>|</span><a href="#38342984">prev</a><span>|</span><a href="#38343151">next</a><span>|</span><label class="collapse" for="c-38343739">[-]</label><label class="expand" for="c-38343739">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right. They&#x27;re fired.</div><br/></div></div></div></div></div></div><div id="38343151" class="c"><input type="checkbox" id="c-38343151" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342872">prev</a><span>|</span><a href="#38343642">next</a><span>|</span><label class="collapse" for="c-38343151">[-]</label><label class="expand" for="c-38343151">[1 more]</label></div><br/><div class="children"><div class="content">If the funding dries up for OpenAI, those engineers have no incentive to keep working there. No point wasting your career on an organization that&#x27;s destined to die.</div><br/></div></div><div id="38343642" class="c"><input type="checkbox" id="c-38343642" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38343151">prev</a><span>|</span><a href="#38342981">next</a><span>|</span><label class="collapse" for="c-38343642">[-]</label><label class="expand" for="c-38343642">[1 more]</label></div><br/><div class="children"><div class="content">The GPT-4 pre-training research lead quit on Friday.</div><br/></div></div><div id="38342981" class="c"><input type="checkbox" id="c-38342981" checked=""/><div class="controls bullet"><span class="by">patapong</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38343642">prev</a><span>|</span><a href="#38343527">next</a><span>|</span><label class="collapse" for="c-38342981">[-]</label><label class="expand" for="c-38342981">[3 more]</label></div><br/><div class="children"><div class="content">I am guessing they are super reliant on Microsoft to keep running ChatGPT... If Microsoft decides to get out and finds a way they would be in deep trouble.</div><br/><div id="38343382" class="c"><input type="checkbox" id="c-38343382" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342981">parent</a><span>|</span><a href="#38343527">next</a><span>|</span><label class="collapse" for="c-38343382">[-]</label><label class="expand" for="c-38343382">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure Google will throw a couple of billions their way, given the chance</div><br/><div id="38343564" class="c"><input type="checkbox" id="c-38343564" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343382">parent</a><span>|</span><a href="#38343527">next</a><span>|</span><label class="collapse" for="c-38343564">[-]</label><label class="expand" for="c-38343564">[1 more]</label></div><br/><div class="children"><div class="content">Why though? Companies invest to see profit or get products they can sell. This is not only about the CEO. The CEO change signals a radical strategic shift.</div><br/></div></div></div></div></div></div><div id="38343527" class="c"><input type="checkbox" id="c-38343527" checked=""/><div class="controls bullet"><span class="by">DantesKite</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38342981">prev</a><span>|</span><a href="#38343157">next</a><span>|</span><label class="collapse" for="c-38343527">[-]</label><label class="expand" for="c-38343527">[1 more]</label></div><br/><div class="children"><div class="content">Andrej Karpathy literally just tweeted the nuclear radiation emoji lol.</div><br/></div></div><div id="38343157" class="c"><input type="checkbox" id="c-38343157" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38343527">prev</a><span>|</span><a href="#38342928">next</a><span>|</span><label class="collapse" for="c-38343157">[-]</label><label class="expand" for="c-38343157">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it’s not as if a nuclear bomb dropped on their HQ<p>Oh yes it is.</div><br/></div></div><div id="38342928" class="c"><input type="checkbox" id="c-38342928" checked=""/><div class="controls bullet"><span class="by">simultsop</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342841">parent</a><span>|</span><a href="#38343157">prev</a><span>|</span><a href="#38342886">next</a><span>|</span><label class="collapse" for="c-38342928">[-]</label><label class="expand" for="c-38342928">[1 more]</label></div><br/><div class="children"><div class="content">With a PR damage such this one, if they survive it will be a miracle.</div><br/></div></div></div></div><div id="38342886" class="c"><input type="checkbox" id="c-38342886" checked=""/><div class="controls bullet"><span class="by">chubot</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342841">prev</a><span>|</span><a href="#38342839">next</a><span>|</span><label class="collapse" for="c-38342886">[-]</label><label class="expand" for="c-38342886">[54 more]</label></div><br/><div class="children"><div class="content">What I think is funny is how the whole &quot;we&#x27;re just doing this to make sure AI is safe&quot; meme breaks down, if you have OpenAI, Anthropic, and Altman AI all competing, which seems likely now.<p>Do you really need all 3?   Is each one going to claim that they&#x27;re the only ones who can develop AGI safely?<p>Since Sam left, now OpenAI is unsafe?  But I thought they were the safe ones, and he was being reckless.<p>Or is Sam just going to abandon the pretense, competing Google- and Microsoft-style?  e.g. doing placement deals, attracting eyeballs, and crushing the competition.<p>Surely that&#x27;s what you need for safety?</div><br/><div id="38343050" class="c"><input type="checkbox" id="c-38343050" checked=""/><div class="controls bullet"><span class="by">ryanSrich</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342886">parent</a><span>|</span><a href="#38342955">next</a><span>|</span><label class="collapse" for="c-38343050">[-]</label><label class="expand" for="c-38343050">[48 more]</label></div><br/><div class="children"><div class="content">Can someone explain to me what they mean by &quot;safe&quot; AGI? I&#x27;ve looked in many places and everyone is extremely vague. Certainly no one is suggesting these systems can become &quot;alive&quot;, so what exactly are we trying to remain safe from? Job loss?</div><br/><div id="38343155" class="c"><input type="checkbox" id="c-38343155" checked=""/><div class="controls bullet"><span class="by">cthalupa</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343503">next</a><span>|</span><label class="collapse" for="c-38343155">[-]</label><label class="expand" for="c-38343155">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Certainly no one is suggesting these systems can become &quot;alive&quot;<p>No, that very much is the fear. They believe that by training AI on all of the things that it takes to make AI, at a certain level of sophistication, the AI can rapidly and continually improve itself until it becomes a superintelligence.</div><br/><div id="38343418" class="c"><input type="checkbox" id="c-38343418" checked=""/><div class="controls bullet"><span class="by">ryanSrich</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343155">parent</a><span>|</span><a href="#38343503">next</a><span>|</span><label class="collapse" for="c-38343418">[-]</label><label class="expand" for="c-38343418">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not alive in any meaningful sense.<p>When I say alive, I mean it&#x27;s like something to be that thing. The lights are on. It has subjective experience.<p>It seems many are defining ASI as just a really fast self learning computer. And while sure, given the wrong type of access and motive, that could be dangerous. But it isn&#x27;t anymore dangerous than any other faulty software that has access to sensitive systems.</div><br/><div id="38343569" class="c"><input type="checkbox" id="c-38343569" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343418">parent</a><span>|</span><a href="#38343503">next</a><span>|</span><label class="collapse" for="c-38343569">[-]</label><label class="expand" for="c-38343569">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re thinking about &quot;alive&quot; as &quot;humanlike&quot; as &quot;subjective experience&quot; as &quot;dangerous&quot;. Instead, think of agentic behavior as a certain kind of algorithm. You don&#x27;t need the human cognitive architecture to execute an input&#x2F;output loop trying to maximize the value of a certain function over states of reality.<p>&gt; But it isn&#x27;t anymore dangerous than any other faulty software that has access to sensitive systems.<p>Seems to me that can be unboundedly dangerous? Like, I don&#x27;t see you making an argument here that there&#x27;s a limit to what kind of dangerous that class entails.</div><br/></div></div></div></div></div></div><div id="38343503" class="c"><input type="checkbox" id="c-38343503" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343155">prev</a><span>|</span><a href="#38343786">next</a><span>|</span><label class="collapse" for="c-38343503">[-]</label><label class="expand" for="c-38343503">[19 more]</label></div><br/><div class="children"><div class="content">&gt; Certainly no one is suggesting these systems can become &quot;alive&quot;,<p>Lots of people have been publicly suggesting that, and that, if not properly aligned, it poses an existential risk to human civilization; that group includes pretty much the entire  founding team of OpenAI, including Altman.<p>The perception of that risk as the downside, as well as the perception that on the other side there is the promise of almost unlimited upside for humanity from properly aligned AI, is pretty much the entire motivation for the OpenAI nonprofit.</div><br/><div id="38343588" class="c"><input type="checkbox" id="c-38343588" checked=""/><div class="controls bullet"><span class="by">idontwantthis</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343503">parent</a><span>|</span><a href="#38343893">next</a><span>|</span><label class="collapse" for="c-38343588">[-]</label><label class="expand" for="c-38343588">[15 more]</label></div><br/><div class="children"><div class="content">How does it actually kill a person? When does it stop existing in boxes that require a continuous source of electricity and can’t survive water or fire?</div><br/><div id="38344190" class="c"><input type="checkbox" id="c-38344190" checked=""/><div class="controls bullet"><span class="by">grey-area</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343588">parent</a><span>|</span><a href="#38343698">next</a><span>|</span><label class="collapse" for="c-38344190">[-]</label><label class="expand" for="c-38344190">[1 more]</label></div><br/><div class="children"><div class="content">The network is the computer.<p>If you live in a city right now there are millions of networked computers that humans depend on in their everyday life and do not want to turn off. Many of those computers keep humans alive (grid control, traffic control, comms, hospitals etc).  Some are actual robotic killing machines but most have other purposes. Hardly any are air-gapped nowadays and all our security assumes the network nodes have no agency.<p>A super intelligence residing in that network would be very difficult to kill and could very easily kill lots of people (destroy a dam for example), however that sort of crude threat is unlikely to be a problem. There are lots of potentially bad scenarios though many of them involving the wrong sort of dictator getting control of such an intelligence. There are legitimate concerns here IMO.</div><br/></div></div><div id="38343698" class="c"><input type="checkbox" id="c-38343698" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343588">parent</a><span>|</span><a href="#38344190">prev</a><span>|</span><a href="#38343827">next</a><span>|</span><label class="collapse" for="c-38343698">[-]</label><label class="expand" for="c-38343698">[6 more]</label></div><br/><div class="children"><div class="content">&gt;  When does it stop existing in boxes that require a continuous source of electricity and can’t survive water or fire?<p>When someone runs a model in a reasonably durable housing with a battery?<p>(I&#x27;m not big on the AI as destroyer or saviour cult myself, but that particular question doesn&#x27;t seem like all that big of a refutation of it.)</div><br/><div id="38343789" class="c"><input type="checkbox" id="c-38343789" checked=""/><div class="controls bullet"><span class="by">idontwantthis</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343698">parent</a><span>|</span><a href="#38343827">next</a><span>|</span><label class="collapse" for="c-38343789">[-]</label><label class="expand" for="c-38343789">[5 more]</label></div><br/><div class="children"><div class="content">But my point is what is it actually doing to reach out and touch someone in the doomsday scenario?</div><br/><div id="38344086" class="c"><input type="checkbox" id="c-38344086" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343789">parent</a><span>|</span><a href="#38343977">next</a><span>|</span><label class="collapse" for="c-38344086">[-]</label><label class="expand" for="c-38344086">[2 more]</label></div><br/><div class="children"><div class="content">Nukes, power grids, planes, blackmail, etc. Surely you’ve seen plenty of media over the years that’s explored this.</div><br/><div id="38344233" class="c"><input type="checkbox" id="c-38344233" checked=""/><div class="controls bullet"><span class="by">idontwantthis</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344086">parent</a><span>|</span><a href="#38343977">next</a><span>|</span><label class="collapse" for="c-38344233">[-]</label><label class="expand" for="c-38344233">[1 more]</label></div><br/><div class="children"><div class="content">What is “nukes” though? Like the missiles in silos that could have been networked decades ago but still require mechanical keys in order to fire? Like is it just making phone calls pretending to be the president and everyone down the line says “ok let’s destroy the world”?</div><br/></div></div></div></div><div id="38343977" class="c"><input type="checkbox" id="c-38343977" checked=""/><div class="controls bullet"><span class="by">LordDragonfang</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343789">parent</a><span>|</span><a href="#38344086">prev</a><span>|</span><a href="#38343827">next</a><span>|</span><label class="collapse" for="c-38343977">[-]</label><label class="expand" for="c-38343977">[2 more]</label></div><br/><div class="children"><div class="content">I mean, the cliched answer is &quot;when it figures out how to override the nuclear launch process&quot;. And while that cliche might have a certain degree of unrealism, it would certainly be possible for a system with access to arbitrary compute power that&#x27;s specifically trained to impersonate human personas to use social engineering to precipitate WW3.<p>And even that isn&#x27;t the easiest scenario if an AI just wants us dead; a smart enough AI could just as easily use send a request to any of the the many labs that will synthesize&#x2F;print genetic sequences for you and create things that combine into a plague worse than covid. And if it&#x27;s <i>really</i> smart, it can figure out how to use those same labs to begin producing self-replicating nanomachines (because that&#x27;s what viruses <i>are</i>) that give it substrate to run on.<p>Oh, and good luck destroying it when it can copy and shard itself onto every unpatched smarthome device on Earth.<p>Now, granted, none of these individual scenarios have a high absolute likelihood. That said, even at a 10% (or 0.1%) chance of destroying all life, you should probably at least give it some thought.</div><br/><div id="38344188" class="c"><input type="checkbox" id="c-38344188" checked=""/><div class="controls bullet"><span class="by">idontwantthis</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343977">parent</a><span>|</span><a href="#38343827">next</a><span>|</span><label class="collapse" for="c-38344188">[-]</label><label class="expand" for="c-38344188">[1 more]</label></div><br/><div class="children"><div class="content">How can it call one of those labs and place an order for the apocalypse and I can’t right now?<p>Also about the smart home devices: if a current iPhone can’t run Siri locally then how is a Roomba supposed to run an AGI?</div><br/></div></div></div></div></div></div></div></div><div id="38343827" class="c"><input type="checkbox" id="c-38343827" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343588">parent</a><span>|</span><a href="#38343698">prev</a><span>|</span><a href="#38343893">next</a><span>|</span><label class="collapse" for="c-38343827">[-]</label><label class="expand" for="c-38343827">[7 more]</label></div><br/><div class="children"><div class="content">One route is if AI (not through malice but simply through incompetence) plays a part in a terrorist plan to trick the US and China or US and Russia into fighting an unwanted nuclear war.  A working group I’m a part of, DISARM:SIMC4, has a lot of papers about this here: <a href="https:&#x2F;&#x2F;simc4.org" rel="nofollow noreferrer">https:&#x2F;&#x2F;simc4.org</a></div><br/><div id="38344207" class="c"><input type="checkbox" id="c-38344207" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343827">parent</a><span>|</span><a href="#38344151">next</a><span>|</span><label class="collapse" for="c-38344207">[-]</label><label class="expand" for="c-38344207">[4 more]</label></div><br/><div class="children"><div class="content">Since you work on this, do you think leaders will wait until confirmation of actual nuclear detonations, maybe on TV, before believing that a massive attack was launched?</div><br/><div id="38344392" class="c"><input type="checkbox" id="c-38344392" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344207">parent</a><span>|</span><a href="#38344151">next</a><span>|</span><label class="collapse" for="c-38344392">[-]</label><label class="expand" for="c-38344392">[3 more]</label></div><br/><div class="children"><div class="content">According to current nuclear doctrine, no, they won’t wait.  The current doctrine is called Launch On Warning which means you retaliate immediately after receiving the first indications of incoming missiles.<p>This is incredibly dumb, which is why those of us who study the intersection of AI and global strategic stability are advocating a change to a different doctrine called Decide Under Attack.<p>Decide Under Attack has been shown by game theory to have equally strong deterrence as Launch On Warning, while also having a much much lower chance of accidental or terrorist-triggered war.<p>Here is the paper that introduced Decide Under Attack:<p><i>A Commonsense Policy for Avoiding a Disastrous Nuclear Decision</i>, Admiral James A Winnefeld, Jr.<p><a href="https:&#x2F;&#x2F;carnegieendowment.org&#x2F;2019&#x2F;09&#x2F;10&#x2F;commonsense-policy-for-avoiding-disastrous-nuclear-decision-pub-79799" rel="nofollow noreferrer">https:&#x2F;&#x2F;carnegieendowment.org&#x2F;2019&#x2F;09&#x2F;10&#x2F;commonsense-policy-...</a></div><br/><div id="38344450" class="c"><input type="checkbox" id="c-38344450" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344392">parent</a><span>|</span><a href="#38344151">next</a><span>|</span><label class="collapse" for="c-38344450">[-]</label><label class="expand" for="c-38344450">[2 more]</label></div><br/><div class="children"><div class="content">I know about the doctrine.<p>Yet everytime there was a &quot;real&quot; attack, somehow the doctrine was not followed (in US or USSR).<p>It seems to me that the doctrine is not actually followed because leaders understand the consequences and wait for very solid confirmation?<p>Soviets also had the perimeter system, which was also supposed to relieve pressure for an immediate response.</div><br/><div id="38344819" class="c"><input type="checkbox" id="c-38344819" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344450">parent</a><span>|</span><a href="#38344151">next</a><span>|</span><label class="collapse" for="c-38344819">[-]</label><label class="expand" for="c-38344819">[1 more]</label></div><br/><div class="children"><div class="content">Agree wholeheartedly.  Human skepticism of computer systems has saved our species from nuclear extinction multiple times (Stanislav Petrov incident, 1979 NORAD training tapes incident, etc.)<p>The specific concern that we in DISARM:SIMC4 have is that as AI systems start to be <i>perceived</i> as being smarter (due to being better and better at natural language rhetoric and at generating infographics), people in command will become more likely to set aside their skepticism and just trust the computer, <i>even if the computer is convincingly hallucinating</i>.<p>The tendency of decision makers (including soldiers) to have higher trust in smarter-<i>seeming</i> systems is called Automation Bias.<p>&gt; The dangers of automation bias and pre-delegating authority were evident during the early stages of the 2003 Iraq invasion. Two out of 11 successful interceptions involving automated US Patriot missile systems were fratricides (friendly-fire incidents).<p><a href="https:&#x2F;&#x2F;thebulletin.org&#x2F;2023&#x2F;02&#x2F;keeping-humans-in-the-loop-is-not-enough-to-make-ai-safe-for-nuclear-weapons&#x2F;amp&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;thebulletin.org&#x2F;2023&#x2F;02&#x2F;keeping-humans-in-the-loop-i...</a><p>Perhaps Stanislav Petrov would not have ignored the erroneous Soviet missile warning computer he operated, if it generated paragraphs of convincing text and several infographics as hallucinated “evidence” of the reality of the supposed inbound strike. He himself later recollected that he felt the chances of the strike being real were 50-50, an even gamble, so in this situation of moral quandary he struggled for several minutes, until, finally, he went with his gut and countermanded the system which required <i>disobeying the Soviet military’s procedures</i> and should have gotten him shot for treason.  Even a slight increase in the persuasiveness of the computer’s rhetoric and graphics could have tipped this to 51-49 and thus caused our extinction.</div><br/></div></div></div></div></div></div></div></div><div id="38344151" class="c"><input type="checkbox" id="c-38344151" checked=""/><div class="controls bullet"><span class="by">justcool393</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343827">parent</a><span>|</span><a href="#38344207">prev</a><span>|</span><a href="#38343893">next</a><span>|</span><label class="collapse" for="c-38344151">[-]</label><label class="expand" for="c-38344151">[2 more]</label></div><br/><div class="children"><div class="content">so the plot of WarGames?</div><br/><div id="38344419" class="c"><input type="checkbox" id="c-38344419" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38344151">parent</a><span>|</span><a href="#38343893">next</a><span>|</span><label class="collapse" for="c-38344419">[-]</label><label class="expand" for="c-38344419">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.  WarGames is very similar to a true incident that occurred in 1979, four years before the release of the film.<p><a href="https:&#x2F;&#x2F;blog.ucsusa.org&#x2F;david-wright&#x2F;nuclear-false-alarm-950&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.ucsusa.org&#x2F;david-wright&#x2F;nuclear-false-alarm-950...</a><p><pre><code>    In this case, it turns out that a technician mistakenly inserted into a NORAD computer a training tape that simulated a large Soviet attack on the United States. Because of the design of the warning system, that information was sent out widely through the U.S. nuclear command network.</code></pre></div><br/></div></div></div></div></div></div></div></div><div id="38343893" class="c"><input type="checkbox" id="c-38343893" checked=""/><div class="controls bullet"><span class="by">mlindner</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343503">parent</a><span>|</span><a href="#38343588">prev</a><span>|</span><a href="#38343786">next</a><span>|</span><label class="collapse" for="c-38343893">[-]</label><label class="expand" for="c-38343893">[3 more]</label></div><br/><div class="children"><div class="content">What does &quot;properly aligned&quot; even mean? Democracies even with countries don&#x27;t have alignment, let alone democracies across the world. They&#x27;re a complete mess of many conflicting and contradictory stances and opinions.<p>This sounds, to me, like the company leadership want the ability to do some sort of picking of winners and losers, bypassing the electorate.</div><br/><div id="38344675" class="c"><input type="checkbox" id="c-38344675" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343893">parent</a><span>|</span><a href="#38344484">next</a><span>|</span><label class="collapse" for="c-38344675">[-]</label><label class="expand" for="c-38344675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What does &quot;properly aligned&quot; even mean?<p>You know those stories where someone makes a pact with the devil&#x2F;djin&#x2F;other wish granting entity, and the entity does one interpretation of what was wished, but since it is not what the wisher intended it all goes terribly wrong? The idea of alignment is to make the djin which not only can grant wishes, but it does them according to the unstated intention of the wisher.<p>You might have heard the story of the paper clip maximiser. The leadership of the paperclip factory buys one of those fancy new AI agents and asks it to maximise paperclip production.<p>What a not-well aligned AI might do: Reach out through the internet to a drug cartel’s communication nodes. Hack the communications and take over the operation. Optimise the drug traficking operations to gain more profit. Divert the funds to manufacture weapons for multiple competing factions on multiple crisis points on Earth. Use the factions against each other. Divert the funds and the weapons to protect a rapidly expanding paperclip factory. Manipulate and blackmail world leaders into inaction. If the original leaders of the paperclip factory try to stop the AI eliminate them, since that is the way to maximise paper clip production. And this is just the begining.<p>What a well alligned AI would do: Fine tune the paperclip manufacturing machinery to eliminate rejects. Reorganise the factory layout to optimise logistics. Run a succesfull advertising campaign which leads to a 130% increase in sales. (Because clearly this is what the factory owner intended it to do. Altough they did a poor job of expressing their wishes.)</div><br/></div></div><div id="38344484" class="c"><input type="checkbox" id="c-38344484" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343893">parent</a><span>|</span><a href="#38344675">prev</a><span>|</span><a href="#38343786">next</a><span>|</span><label class="collapse" for="c-38344484">[-]</label><label class="expand" for="c-38344484">[1 more]</label></div><br/><div class="children"><div class="content">Any AGI must at a minimum be aligned with these two values:<p>(1) humanity should not be subjugated<p>(2) humanity should not go extinct before it’s our time<p>Even Kim Jong Un would agree with these principles.<p>Currently, any AGI or ASI built based on any of the known architectures contemplated in the literature which have been invented thus far would <i>not</i> meet a beyond-a-reasonable-doubt standard of being aligned with these two values.</div><br/></div></div></div></div></div></div><div id="38343786" class="c"><input type="checkbox" id="c-38343786" checked=""/><div class="controls bullet"><span class="by">bartimus</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343503">prev</a><span>|</span><a href="#38343107">next</a><span>|</span><label class="collapse" for="c-38343786">[-]</label><label class="expand" for="c-38343786">[1 more]</label></div><br/><div class="children"><div class="content">It being &quot;alive&quot; is sort of what AGI implies (depending on your definition of life).<p>Now consider the training has caused it to have undesirable behavior (misaligned with human values).</div><br/></div></div><div id="38343107" class="c"><input type="checkbox" id="c-38343107" checked=""/><div class="controls bullet"><span class="by">hsrada</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343786">prev</a><span>|</span><a href="#38343142">next</a><span>|</span><label class="collapse" for="c-38343107">[-]</label><label class="expand" for="c-38343107">[18 more]</label></div><br/><div class="children"><div class="content">Death.<p>The default consequence of AGI&#x27;s arrival is doom. Aligning a super intelligence with our desires is a problem that no one has solved yet.<p>&quot;The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.&quot;<p>----<p>Listen to Dwarkesh Podcast with Eliezer or Carl Shulman to know more about this.</div><br/><div id="38343349" class="c"><input type="checkbox" id="c-38343349" checked=""/><div class="controls bullet"><span class="by">ryanSrich</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343107">parent</a><span>|</span><a href="#38343239">next</a><span>|</span><label class="collapse" for="c-38343349">[-]</label><label class="expand" for="c-38343349">[4 more]</label></div><br/><div class="children"><div class="content">I like science fiction too, but all of these potential scenarios seem so far removed from the low level realities of how these systems work.<p>I&#x27;m not suggesting we don&#x27;t see ASI in some distant future, maybe 100+ years away. But to suggest we&#x27;re even within a decade of having ASI seems silly to me. Maybe there&#x27;s research I haven&#x27;t read, but as a daily user of AI, it&#x27;s hilarious to think people are existentially concerned with it.</div><br/><div id="38343857" class="c"><input type="checkbox" id="c-38343857" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343349">parent</a><span>|</span><a href="#38343600">next</a><span>|</span><label class="collapse" for="c-38343857">[-]</label><label class="expand" for="c-38343857">[1 more]</label></div><br/><div class="children"><div class="content">&gt; maybe 100+ years away<p>I have two toddlers.  This is within their lifetimes no matter what.  I think about this every day because it affects them directly.  Some of the bad outcomes of ASI involve what’s called s-risk (“suffering risk”) which is the class of outcomes like the one depicted in The Matrix where humans do not go extinct but are subjugated and suffer.  I will do anything to prevent that from happening to my children.</div><br/></div></div><div id="38343600" class="c"><input type="checkbox" id="c-38343600" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343349">parent</a><span>|</span><a href="#38343857">prev</a><span>|</span><a href="#38344039">next</a><span>|</span><label class="collapse" for="c-38343600">[-]</label><label class="expand" for="c-38343600">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I like science fiction too, but all of these potential scenarios seem so far removed from the low level realities of how these systems work.<p>Maybe they don&#x27;t seem that to others? I mean, you&#x27;re not really making an argument here. I also use GPT daily and I&#x27;m definitely worried. It seems to me that we&#x27;re pretty close to a point where a system using GPT as a strategy generator can &quot;close the loop&quot; and generate its own training data on a short timeframe. At that point, all bets are off.</div><br/></div></div><div id="38344039" class="c"><input type="checkbox" id="c-38344039" checked=""/><div class="controls bullet"><span class="by">hsrada</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343349">parent</a><span>|</span><a href="#38343600">prev</a><span>|</span><a href="#38343239">next</a><span>|</span><label class="collapse" for="c-38344039">[-]</label><label class="expand" for="c-38344039">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I like science fiction too, but all of these potential scenarios seem so far removed from the low level realities of how these systems work.<p>Today, yes. Nobody is saying GPT-3 or 4 or even 5 will cause this. None of the chatbots we have today will evolve to be the AGI that everyone is fearing.<p>But when you go beyond that, it becomes difficult to ignore trend lines.<p>Here&#x27;s a detailed scenario breakdown of how it might come to be –<a href="https:&#x2F;&#x2F;www.dwarkeshpatel.com&#x2F;p&#x2F;carl-shulman" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.dwarkeshpatel.com&#x2F;p&#x2F;carl-shulman</a></div><br/></div></div></div></div><div id="38343239" class="c"><input type="checkbox" id="c-38343239" checked=""/><div class="controls bullet"><span class="by">bnralt</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343107">parent</a><span>|</span><a href="#38343349">prev</a><span>|</span><a href="#38343193">next</a><span>|</span><label class="collapse" for="c-38343239">[-]</label><label class="expand" for="c-38343239">[10 more]</label></div><br/><div class="children"><div class="content">&gt;  Aligning a super intelligence with our desires is a problem that no one has solved yet.<p>It&#x27;s a problem that we haven&#x27;t seen the existence of yet. It&#x27;s like saying no one has solved the problem of alien invasions.</div><br/><div id="38344319" class="c"><input type="checkbox" id="c-38344319" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343239">parent</a><span>|</span><a href="#38343287">next</a><span>|</span><label class="collapse" for="c-38344319">[-]</label><label class="expand" for="c-38344319">[1 more]</label></div><br/><div class="children"><div class="content">Survivorship bias.<p>It&#x27;s like saying don&#x27;t worry about global thermonuclear war because we haven&#x27;t seen it yet.<p>The Neandethals on the other hand have encountered a super-intelligence.</div><br/></div></div><div id="38343287" class="c"><input type="checkbox" id="c-38343287" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343239">parent</a><span>|</span><a href="#38344319">prev</a><span>|</span><a href="#38343797">next</a><span>|</span><label class="collapse" for="c-38343287">[-]</label><label class="expand" for="c-38343287">[5 more]</label></div><br/><div class="children"><div class="content">No, the problem with AGI is potential exponential growth.<p>So less like an alien invasion.<p>And more like a pandemic at the speed of light.</div><br/><div id="38343430" class="c"><input type="checkbox" id="c-38343430" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343287">parent</a><span>|</span><a href="#38343471">next</a><span>|</span><label class="collapse" for="c-38343430">[-]</label><label class="expand" for="c-38343430">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s assuming a big overshoot of human intelligence and goal-seeking.  An average human capability counts as &quot;AGI.&quot;<p>If lots of the smartest human minds make AGI, and it exceeds a mediocre human-- why assume it can make itself more efficient or bigger?  Indeed, <i>even if</i> it&#x27;s smarter than the collective effort of  the scientists that made it, there&#x27;s no real guarantee that there&#x27;s lots of low hanging fruit for it to self-improve.<p>I think the near problem with AGI isn&#x27;t a potential tech singularity, but instead just the tendency for it potentially to be societally destabilizing.</div><br/><div id="38343773" class="c"><input type="checkbox" id="c-38343773" checked=""/><div class="controls bullet"><span class="by">MrScruff</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343430">parent</a><span>|</span><a href="#38343471">next</a><span>|</span><label class="collapse" for="c-38343773">[-]</label><label class="expand" for="c-38343773">[2 more]</label></div><br/><div class="children"><div class="content">If AI gets to human levels of intelligence (ie. can do novel research in theoretical physics) then at the very least it’s likely that over time it will be able to do this reasoning faster than humans. I think it’s very hard to imagine a scenario where we create an actual AGI and then within a few years at most of that event the AGIs are far more capable than human brains. That would imply there was some arbitrary physical limit to intelligence but even within humans the variance is quite dramatic.</div><br/><div id="38343980" class="c"><input type="checkbox" id="c-38343980" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343773">parent</a><span>|</span><a href="#38343471">next</a><span>|</span><label class="collapse" for="c-38343980">[-]</label><label class="expand" for="c-38343980">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it’s very hard to imagine a scenario where we create an actual AGI and then within a few years at most of that event the AGIs are far more capable than human brains.<p>I&#x27;m assuming you meant &quot;aren&#x27;t&quot; here.<p>&gt; That would imply there was some arbitrary physical limit to intelligence<p>All you need is some kind of sub-linear scaling law for peak possible &quot;intelligence&quot; vs. the amount of raw computation.  There&#x27;s a lot of reason to think that this is true.<p>Also there&#x27;s no guarantee the amount of raw computation is going to increase quickly.<p>In any case, the kind of exponential runaway you mention (years) isn&#x27;t &quot;pandemic at the speed of light&quot; as mentioned in the grandparent.<p>I&#x27;m more worried about scenarios where we end up with an 75IQ savant (access encyclopedic training knowledge and very quick interface to run native computer code for math and data processing help) that can plug away 24&#x2F;7 and fit on an A100.  You&#x27;d have millions of new cheap &quot;superhuman&quot; workers per year even if they&#x27;re not very smart and not very fast.  It would be economically destabilizing <i>very</i> quickly, and many of them will be employed in ways that just completely thrash the signal to noise ratio of written text, etc.</div><br/></div></div></div></div></div></div><div id="38343471" class="c"><input type="checkbox" id="c-38343471" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343287">parent</a><span>|</span><a href="#38343430">prev</a><span>|</span><a href="#38343797">next</a><span>|</span><label class="collapse" for="c-38343471">[-]</label><label class="expand" for="c-38343471">[1 more]</label></div><br/><div class="children"><div class="content">Exponential growth is not intrinsically a feature of an AGI except that you&#x27;ve decided it is. It&#x27;s also almost certainly impossible.<p>Main problems stopping it are:<p>- no intelligent agent is motivated to improve itself because the new improved thing would be someone else, and not it.<p>- that costs money and you&#x27;re just pretending everything is free.</div><br/></div></div></div></div><div id="38343797" class="c"><input type="checkbox" id="c-38343797" checked=""/><div class="controls bullet"><span class="by">dminik</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343239">parent</a><span>|</span><a href="#38343287">prev</a><span>|</span><a href="#38343654">next</a><span>|</span><label class="collapse" for="c-38343797">[-]</label><label class="expand" for="c-38343797">[1 more]</label></div><br/><div class="children"><div class="content">We see alignment problems all the time. Current systems are not particularly smart or dangerous. But they lie on purpose and funnily enough considering the current situation, Microsoft&#x27;s attempt was threatening users shortly after launch.</div><br/></div></div><div id="38343654" class="c"><input type="checkbox" id="c-38343654" checked=""/><div class="controls bullet"><span class="by">MrScruff</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343239">parent</a><span>|</span><a href="#38343797">prev</a><span>|</span><a href="#38343606">next</a><span>|</span><label class="collapse" for="c-38343654">[-]</label><label class="expand" for="c-38343654">[1 more]</label></div><br/><div class="children"><div class="content">The argument would be that by the time we see the problem it will be too late. We didn’t really anticipate the unreasonable effectiveness of transformers until people started scaling them, which happened very quickly.</div><br/></div></div><div id="38343606" class="c"><input type="checkbox" id="c-38343606" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343239">parent</a><span>|</span><a href="#38343654">prev</a><span>|</span><a href="#38343193">next</a><span>|</span><label class="collapse" for="c-38343606">[-]</label><label class="expand" for="c-38343606">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a problem that we haven&#x27;t seen the existence of yet. It&#x27;s like saying no one has solved the problem of alien invasions.<p>But if we&#x27;re seeing the existence of an unaligned superintelligence, surely it&#x27;s squarely too late to do something about it.</div><br/></div></div></div></div><div id="38343193" class="c"><input type="checkbox" id="c-38343193" checked=""/><div class="controls bullet"><span class="by">jbgt</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343107">parent</a><span>|</span><a href="#38343239">prev</a><span>|</span><a href="#38343353">next</a><span>|</span><label class="collapse" for="c-38343193">[-]</label><label class="expand" for="c-38343193">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps listen to this podcast instead.<p><a href="https:&#x2F;&#x2F;www.matthewgeleta.com&#x2F;p&#x2F;joscha-bach-ai-risk-and-the-future" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.matthewgeleta.com&#x2F;p&#x2F;joscha-bach-ai-risk-and-the-...</a></div><br/></div></div><div id="38343353" class="c"><input type="checkbox" id="c-38343353" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343107">parent</a><span>|</span><a href="#38343193">prev</a><span>|</span><a href="#38343918">next</a><span>|</span><label class="collapse" for="c-38343353">[-]</label><label class="expand" for="c-38343353">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure that it&#x27;s a matter of &quot;knowing&quot; as much as it is &quot;believing&quot;</div><br/></div></div><div id="38343918" class="c"><input type="checkbox" id="c-38343918" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343107">parent</a><span>|</span><a href="#38343353">prev</a><span>|</span><a href="#38343142">next</a><span>|</span><label class="collapse" for="c-38343918">[-]</label><label class="expand" for="c-38343918">[1 more]</label></div><br/><div class="children"><div class="content">There is absolutely no AGI risk. These are mere marketing ploys to sell a chatbot &#x2F; feel super important. A fancy chatbot, but a chatbot none the less.</div><br/></div></div></div></div><div id="38343142" class="c"><input type="checkbox" id="c-38343142" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343107">prev</a><span>|</span><a href="#38343993">next</a><span>|</span><label class="collapse" for="c-38343142">[-]</label><label class="expand" for="c-38343142">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.&quot;<p>Signed by Sam Altman, Ilya Sutskever, Yoshua Bengio, Geoff Hinton, Demis Hassabis (DeepMind CEO), Dario Amodei (Anthropic CEO), and Bill Gates.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;robbensinger&#x2F;status&#x2F;1726039794197872939" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;robbensinger&#x2F;status&#x2F;1726039794197872939</a></div><br/></div></div><div id="38343993" class="c"><input type="checkbox" id="c-38343993" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343142">prev</a><span>|</span><a href="#38343714">next</a><span>|</span><label class="collapse" for="c-38343993">[-]</label><label class="expand" for="c-38343993">[1 more]</label></div><br/><div class="children"><div class="content">They give it stupid terms like “alignment” to make it opaque to the common person. It’s basically sitting on your hands and pointing to sci-fi as to why progress should be stopped.</div><br/></div></div><div id="38343714" class="c"><input type="checkbox" id="c-38343714" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343050">parent</a><span>|</span><a href="#38343993">prev</a><span>|</span><a href="#38343394">next</a><span>|</span><label class="collapse" for="c-38343714">[-]</label><label class="expand" for="c-38343714">[1 more]</label></div><br/><div class="children"><div class="content">Smart people like Ilya really are worried about extinction, not piddling near-term stuff like job loss or some chat app saying some stuff that will hurt someone&#x27;s feelings.<p>The worry is not necessarily that the systems become &quot;alive&quot;, though, we are already bad enough ourselves as a species in terms of motivation so machines don&#x27;t need to supply the murderous intent: at any given moment there are at least thousands if not millions of people on the planet that would love nothing more than be able to push a button an murder millions of other people in some outgroup. That&#x27;s very obvious if you pay even a little bit of attention to any of the Israel&#x2F;Palestine hatred going back and forth lately. [There are probably at least hundreds to thousands that are insane enough to want to destroy all of humanity if they could, for that matter...] If AI becomes powerful enough to make it easy for a small group to kill large numbers of people that they hate, we are probably all going to end up dead, because almost all of us belong to a group that <i>someone</i> wants to exterminate.<p>Killing people isn&#x27;t a super difficult problem, so I don&#x27;t think you really even need AGI to get to that sort of an outcome, TBH, which is why I think a lot of the worry is misplaced. I think the sort of control systems that we could pretty easily build with the LLMs of today could very competently execute genocides if they were paired with suitably advanced robotics, it&#x27;s the latter that is lacking. But in any case, the concern is that having <i>even stronger</i> AI, especially once it reliably surpasses us in every way, makes it even easier to imagine an effectively unstoppable extermination campaign that runs on its own and couldn&#x27;t be stopped even by the people who started it up.<p>I personally think that stronger AI is also the solution and we&#x27;re already too far down the cat-and-mouse rabbithole to pause the game (which some e&#x2F;acc people believe as the main reason they want to push forward faster and make sure a good AI is the first one to really achieve full domination), but that&#x27;s a different discussion.</div><br/></div></div></div></div><div id="38342955" class="c"><input type="checkbox" id="c-38342955" checked=""/><div class="controls bullet"><span class="by">zombiwoof</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342886">parent</a><span>|</span><a href="#38343050">prev</a><span>|</span><a href="#38343297">next</a><span>|</span><label class="collapse" for="c-38342955">[-]</label><label class="expand" for="c-38342955">[2 more]</label></div><br/><div class="children"><div class="content">Two words: Laundry Buddy<p>Sam doomed himself. Laundry Buddy is the new Clippy</div><br/><div id="38343258" class="c"><input type="checkbox" id="c-38343258" checked=""/><div class="controls bullet"><span class="by">chubot</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342955">parent</a><span>|</span><a href="#38343297">next</a><span>|</span><label class="collapse" for="c-38343258">[-]</label><label class="expand" for="c-38343258">[1 more]</label></div><br/><div class="children"><div class="content">If we do not release Laundry Buddy, that increases humanity&#x27;s extinction risk</div><br/></div></div></div></div><div id="38343297" class="c"><input type="checkbox" id="c-38343297" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342886">parent</a><span>|</span><a href="#38342955">prev</a><span>|</span><a href="#38343620">next</a><span>|</span><label class="collapse" for="c-38343297">[-]</label><label class="expand" for="c-38343297">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Do you really need all 3? Is each one going to claim that they&#x27;re the only ones who can develop AGI safely?<p>What we need at this point is a neutral 3rd party who can examine their safety claims in detail and give a relatively objective report to the public.</div><br/></div></div><div id="38343620" class="c"><input type="checkbox" id="c-38343620" checked=""/><div class="controls bullet"><span class="by">asdkl234890</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342886">parent</a><span>|</span><a href="#38343297">prev</a><span>|</span><a href="#38343267">next</a><span>|</span><label class="collapse" for="c-38343620">[-]</label><label class="expand" for="c-38343620">[1 more]</label></div><br/><div class="children"><div class="content">And as if researches in other nations like China will sit on their hands and do nothing. They are busy catching up but without any ethics boards.</div><br/></div></div></div></div><div id="38342839" class="c"><input type="checkbox" id="c-38342839" checked=""/><div class="controls bullet"><span class="by">tempsy</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342886">prev</a><span>|</span><a href="#38343199">next</a><span>|</span><label class="collapse" for="c-38342839">[-]</label><label class="expand" for="c-38342839">[9 more]</label></div><br/><div class="children"><div class="content">Yeah Emmett Shear seems like an odd choice if they’re worried about retention because 1) Twitch was never known to be a particularly great place to work and 2) he stepped down for some reason and not because Twitch was in an amazing place or anything at the time</div><br/><div id="38342877" class="c"><input type="checkbox" id="c-38342877" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342839">parent</a><span>|</span><a href="#38343368">next</a><span>|</span><label class="collapse" for="c-38342877">[-]</label><label class="expand" for="c-38342877">[6 more]</label></div><br/><div class="children"><div class="content">Emmett&#x27;s just a placeholder after Murati turned. I suspect he won&#x27;t stay in his position for long.</div><br/><div id="38343263" class="c"><input type="checkbox" id="c-38343263" checked=""/><div class="controls bullet"><span class="by">PepperdineG</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342877">parent</a><span>|</span><a href="#38343368">next</a><span>|</span><label class="collapse" for="c-38343263">[-]</label><label class="expand" for="c-38343263">[5 more]</label></div><br/><div class="children"><div class="content">Recursive Interim CEOs. Will there be a Mandelbrot set of Interim CEOs?</div><br/><div id="38343374" class="c"><input type="checkbox" id="c-38343374" checked=""/><div class="controls bullet"><span class="by">mickdarling</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343263">parent</a><span>|</span><a href="#38343340">next</a><span>|</span><label class="collapse" for="c-38343374">[-]</label><label class="expand" for="c-38343374">[1 more]</label></div><br/><div class="children"><div class="content">This particular board won’t even let ChatGPT help the CEO because they’re afraid there’s a Basilisk hiding in every response.</div><br/></div></div><div id="38343340" class="c"><input type="checkbox" id="c-38343340" checked=""/><div class="controls bullet"><span class="by">sgift</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343263">parent</a><span>|</span><a href="#38343374">prev</a><span>|</span><a href="#38343887">next</a><span>|</span><label class="collapse" for="c-38343340">[-]</label><label class="expand" for="c-38343340">[1 more]</label></div><br/><div class="children"><div class="content">The new research focus demanded by the board in the name of safety will be an CEO AI, which will be aligned to humanities interests - the benchmark to show this will be if it does whatever the board wants. It&#x27;s the only way to make sure they cannot be stabbed in the back again by a pesky human.</div><br/></div></div><div id="38343887" class="c"><input type="checkbox" id="c-38343887" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343263">parent</a><span>|</span><a href="#38343340">prev</a><span>|</span><a href="#38343368">next</a><span>|</span><label class="collapse" for="c-38343887">[-]</label><label class="expand" for="c-38343887">[2 more]</label></div><br/><div class="children"><div class="content">And people say there aren&#x27;t real-world applications to n-ary tree rebalancing.</div><br/><div id="38344388" class="c"><input type="checkbox" id="c-38344388" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343887">parent</a><span>|</span><a href="#38343368">next</a><span>|</span><label class="collapse" for="c-38344388">[-]</label><label class="expand" for="c-38344388">[1 more]</label></div><br/><div class="children"><div class="content">I laughed, but actually I think the utility of tree rebalancing is widely appreciated!</div><br/></div></div></div></div></div></div></div></div><div id="38343368" class="c"><input type="checkbox" id="c-38343368" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342839">parent</a><span>|</span><a href="#38342877">prev</a><span>|</span><a href="#38343199">next</a><span>|</span><label class="collapse" for="c-38343368">[-]</label><label class="expand" for="c-38343368">[2 more]</label></div><br/><div class="children"><div class="content">Emmett Shear is probably the person most friendly to OpenAI board&#x27;s AI safety agenda among possible candidates. Source: have a look at his Twitter.</div><br/></div></div></div></div><div id="38343199" class="c"><input type="checkbox" id="c-38343199" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342839">prev</a><span>|</span><a href="#38342856">next</a><span>|</span><label class="collapse" for="c-38343199">[-]</label><label class="expand" for="c-38343199">[5 more]</label></div><br/><div class="children"><div class="content">The big question in my mind is the reported threat from MSFT to withhold cloud credits (i.e. the actual currency of their $10B investment). Is this true? And are they going to follow through?<p>I don&#x27;t buy for a second that enough employees will walk to sink the company (though it could be very be disruptive). But for OpenAI, losing a big chunk of their compute could mean they are unable to support their userbase and that could permanently damage their market position.</div><br/><div id="38343558" class="c"><input type="checkbox" id="c-38343558" checked=""/><div class="controls bullet"><span class="by">justcool393</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343199">parent</a><span>|</span><a href="#38343388">next</a><span>|</span><label class="collapse" for="c-38343558">[-]</label><label class="expand" for="c-38343558">[1 more]</label></div><br/><div class="children"><div class="content">was it even reported? i heard a bunch of stuff that seemed to be hypothetical guessing like &quot;satya must be furious&quot; that seemed to morph into &quot;it was reported satya is furious&quot;<p>i&#x27;ve seen similar with the cloud credits thing, people just pontificating whether it&#x27;s even a viable strategy.</div><br/></div></div><div id="38343388" class="c"><input type="checkbox" id="c-38343388" checked=""/><div class="controls bullet"><span class="by">cthalupa</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343199">parent</a><span>|</span><a href="#38343558">prev</a><span>|</span><a href="#38343479">next</a><span>|</span><label class="collapse" for="c-38343388">[-]</label><label class="expand" for="c-38343388">[1 more]</label></div><br/><div class="children"><div class="content">The report was that investors were talking to microsoft about the threat to withhold credits.<p>Which does not say whether microsoft was open to the idea or ultimately chose to pursue that path.</div><br/></div></div><div id="38343479" class="c"><input type="checkbox" id="c-38343479" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343199">parent</a><span>|</span><a href="#38343388">prev</a><span>|</span><a href="#38342856">next</a><span>|</span><label class="collapse" for="c-38343479">[-]</label><label class="expand" for="c-38343479">[2 more]</label></div><br/><div class="children"><div class="content">MS is not going to randomly withhold cloud credits, as OpenAI is going to sue them for billions of damages.</div><br/><div id="38343579" class="c"><input type="checkbox" id="c-38343579" checked=""/><div class="controls bullet"><span class="by">vaxman</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343479">parent</a><span>|</span><a href="#38342856">next</a><span>|</span><label class="collapse" for="c-38343579">[-]</label><label class="expand" for="c-38343579">[1 more]</label></div><br/><div class="children"><div class="content">So they should keep buying H100s (and H200s) and pouring billions into their own chips on the expectation that OpenAI will fulfill its contractual obligations under THESE circumstances? If they stop doing that, how long before all of Azure is busy on a money losing chat program under all new leadership that doesn’t have the same plan that was sold to MSFT?</div><br/></div></div></div></div></div></div><div id="38342856" class="c"><input type="checkbox" id="c-38342856" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343199">prev</a><span>|</span><a href="#38343820">next</a><span>|</span><label class="collapse" for="c-38342856">[-]</label><label class="expand" for="c-38342856">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>No idea what the future holds for any of the players here. Reality truly is stranger than fiction.</i><p>Is it though? &quot;No outcome where [OpenAI] is one of the big five technology companies. My hope is that we can do a lot more good for the world than just become another corporation that gets that big.&quot; -Adam D&#x27;Angelo</div><br/><div id="38343628" class="c"><input type="checkbox" id="c-38343628" checked=""/><div class="controls bullet"><span class="by">Palmik</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38342856">parent</a><span>|</span><a href="#38343820">next</a><span>|</span><label class="collapse" for="c-38343628">[-]</label><label class="expand" for="c-38343628">[2 more]</label></div><br/><div class="children"><div class="content">I guess he would prefer is the existing incumbents got even larger, or if his competitor to ChatGPT (Poe) could capture significant fraction of the market.</div><br/><div id="38344403" class="c"><input type="checkbox" id="c-38344403" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343628">parent</a><span>|</span><a href="#38343820">next</a><span>|</span><label class="collapse" for="c-38344403">[-]</label><label class="expand" for="c-38344403">[1 more]</label></div><br/><div class="children"><div class="content">Can’t beat em so join em?  You’re framing this as a capitalist competition.  Non-profits don’t care if their “competitors” win market share.</div><br/></div></div></div></div></div></div><div id="38343820" class="c"><input type="checkbox" id="c-38343820" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342856">prev</a><span>|</span><a href="#38342956">next</a><span>|</span><label class="collapse" for="c-38343820">[-]</label><label class="expand" for="c-38343820">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I still cannot process what’s happened to one of the most prominent and hyped companies of the past year in just one weekend.<p>That&#x27;s kinda what happened. The latest gist I read was that the non-profit, idealistic(?) board clashed with the for-profit, hypergrowth CEO over the direction to take the company. When you read the board&#x27;s bios, they&#x27;re weren&#x27;t ready for this job (few are; these rocket ship stories are rare), the rocket ship got ahead of their non-profit goals, and they found themselves in over their heads, then failed to game out how this would go over (poor communication with MS, not expecting Altman to get so much support).<p>From here, the remaining board either needs to either surface some very damning evidence (the memo ain&#x27;t it) or step down and let MS and Sequoia find a new board (even if they&#x27;re not officially entitled to do that). Someone needs to be saying mea culpa.</div><br/><div id="38343903" class="c"><input type="checkbox" id="c-38343903" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343820">parent</a><span>|</span><a href="#38342956">next</a><span>|</span><label class="collapse" for="c-38343903">[-]</label><label class="expand" for="c-38343903">[4 more]</label></div><br/><div class="children"><div class="content">I am not sure why. As far as I can tell, the board doesn&#x27;t need to answer to anyone.</div><br/><div id="38344417" class="c"><input type="checkbox" id="c-38344417" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343903">parent</a><span>|</span><a href="#38343954">next</a><span>|</span><label class="collapse" for="c-38344417">[-]</label><label class="expand" for="c-38344417">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately (or fortunately?), you always have to answer to somebody. In this board&#x27;s case, they have to answer to investors, Microsoft in particular. Why? Because Microsoft can pull the money (apparently they only sent a fraction of $10Bn so far) and can sabotage the partnership deal. The OpenAI won&#x27;t meet the payroll and won&#x27;t be able to run the GPU farm. Microsoft already threatened to do exactly that.<p>My suspicion is that Microsoft will do exactly that: they will pull the money, sabotage the partnership deal and focus on rebuilding GPT in-house (with some of the key OpenAI people hired away). They will do this gradually, on their own timetable, so that it does not disrupt the GPT Azure access to their own customers.<p>I doubt that there could be a replacement for the Microsoft deal, because who would want to go through this again? OpenAI might be able to raise a billion or two from the hard core AI Safety enthusiasts, but they won&#x27;t be able to raise $10s of Billions needed to run the next cycle of scaling.</div><br/></div></div><div id="38343954" class="c"><input type="checkbox" id="c-38343954" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343903">parent</a><span>|</span><a href="#38344417">prev</a><span>|</span><a href="#38342956">next</a><span>|</span><label class="collapse" for="c-38343954">[-]</label><label class="expand" for="c-38343954">[2 more]</label></div><br/><div class="children"><div class="content">I think the diagram I saw showed they don&#x27;t actually answer to MS, VCs, or employee investors? And not even that they&#x27;re out-voted, they <i>don&#x27;t answer to them at all</i>.</div><br/><div id="38344016" class="c"><input type="checkbox" id="c-38344016" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343954">parent</a><span>|</span><a href="#38342956">next</a><span>|</span><label class="collapse" for="c-38344016">[-]</label><label class="expand" for="c-38344016">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can tell, this is correct.</div><br/></div></div></div></div></div></div></div></div><div id="38342956" class="c"><input type="checkbox" id="c-38342956" checked=""/><div class="controls bullet"><span class="by">mym1990</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343820">prev</a><span>|</span><a href="#38343314">next</a><span>|</span><label class="collapse" for="c-38342956">[-]</label><label class="expand" for="c-38342956">[1 more]</label></div><br/><div class="children"><div class="content">Middle East funding and fully self reliant seem to be at odds here.</div><br/></div></div><div id="38343314" class="c"><input type="checkbox" id="c-38343314" checked=""/><div class="controls bullet"><span class="by">yeck</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38342956">prev</a><span>|</span><a href="#38343251">next</a><span>|</span><label class="collapse" for="c-38343314">[-]</label><label class="expand" for="c-38343314">[4 more]</label></div><br/><div class="children"><div class="content">Well, despite what Musk did, X (Twitter?) has still been limping along for quite a while now. While more abrupt and surprising, this doesn&#x27;t seem nearly as bad as that.</div><br/><div id="38343404" class="c"><input type="checkbox" id="c-38343404" checked=""/><div class="controls bullet"><span class="by">extheat</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343314">parent</a><span>|</span><a href="#38343470">prev</a><span>|</span><a href="#38343251">next</a><span>|</span><label class="collapse" for="c-38343404">[-]</label><label class="expand" for="c-38343404">[2 more]</label></div><br/><div class="children"><div class="content">This is far worse. OpenAI simply cannot survive without Microsoft and skeleton staff. It&#x27;s not like a static codebase where you can keep the service up and running indefinitely barring bugs. Why would anyone building with the OpenAI APIs, their customers, have any faith in the company if they openly don&#x27;t care about business? Working on AI is highly capital intensive, on the scale of many tens of billions of dollars. Where are they going to get that funding? How will they pay their staff? There is no way Microsoft is going to HODL after this embarrassment.</div><br/><div id="38343549" class="c"><input type="checkbox" id="c-38343549" checked=""/><div class="controls bullet"><span class="by">yeck</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343404">parent</a><span>|</span><a href="#38343251">next</a><span>|</span><label class="collapse" for="c-38343549">[-]</label><label class="expand" for="c-38343549">[1 more]</label></div><br/><div class="children"><div class="content">Musk fired most of the engineers. I&#x27;d be pretty surprised if we see the level of attrition at OpenAI getting within an order of magnitude of that. We are just making predictions, though. I could be way off the mark and many more people are willing to jump ship than I imagine.<p>As for Microsoft, if they let OpenAI go, then what? Does Google pick them up? Elon? They are still looking to invent AGI, so I&#x27;d be surprised if no one wants to take advantage of that opportunity. I&#x27;d expect Microsoft to be aware of this and weigh into their calculus.</div><br/></div></div></div></div></div></div><div id="38343251" class="c"><input type="checkbox" id="c-38343251" checked=""/><div class="controls bullet"><span class="by">jumelles</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343314">prev</a><span>|</span><a href="#38343726">next</a><span>|</span><label class="collapse" for="c-38343251">[-]</label><label class="expand" for="c-38343251">[1 more]</label></div><br/><div class="children"><div class="content">The dirty secret of the business world is that the C-suite is the most easily replaceable.</div><br/></div></div><div id="38343726" class="c"><input type="checkbox" id="c-38343726" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343251">prev</a><span>|</span><a href="#38343109">next</a><span>|</span><label class="collapse" for="c-38343726">[-]</label><label class="expand" for="c-38343726">[2 more]</label></div><br/><div class="children"><div class="content">Can microsoft buy IP from openAI? recruit their engineers? asking for a friend</div><br/><div id="38343948" class="c"><input type="checkbox" id="c-38343948" checked=""/><div class="controls bullet"><span class="by">BOOSTERHIDROGEN</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343726">parent</a><span>|</span><a href="#38343109">next</a><span>|</span><label class="collapse" for="c-38343948">[-]</label><label class="expand" for="c-38343948">[1 more]</label></div><br/><div class="children"><div class="content">Exclusive use up until pre-AGI tech.</div><br/></div></div></div></div><div id="38343109" class="c"><input type="checkbox" id="c-38343109" checked=""/><div class="controls bullet"><span class="by">brotchie</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343726">prev</a><span>|</span><a href="#38343282">next</a><span>|</span><label class="collapse" for="c-38343109">[-]</label><label class="expand" for="c-38343109">[4 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t fully believe this, but the only rational explanation I can see is that Ilya knows they have AGI.<p><pre><code>   - Nuke employee morale: massive attrition, not getting upside (tender offer),
   - Nuke the talent magnet: who&#x27;s going to want to work there now?
   - Nuke Microsoft relationship: all those GPUs gone,
   - Nuke future fundraising: who&#x27;s going to fund this shit show?
</code></pre>
Just doesn&#x27;t make sense.</div><br/><div id="38344520" class="c"><input type="checkbox" id="c-38344520" checked=""/><div class="controls bullet"><span class="by">vultour</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343109">parent</a><span>|</span><a href="#38343911">next</a><span>|</span><label class="collapse" for="c-38344520">[-]</label><label class="expand" for="c-38344520">[1 more]</label></div><br/><div class="children"><div class="content">People really need to stop with this AGI bullshit. They make a glorified Markov chain and suddenly they should have AGI? Self-driving cars are barely able to stay on the road after all this time, but sure, someone&#x27;s hiding conscious machines in their basement.</div><br/></div></div><div id="38343911" class="c"><input type="checkbox" id="c-38343911" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343109">parent</a><span>|</span><a href="#38344520">prev</a><span>|</span><a href="#38343761">next</a><span>|</span><label class="collapse" for="c-38343911">[-]</label><label class="expand" for="c-38343911">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of the very ending of the show Silicon Valley.  Crazy twist and great last two episodes of the show.</div><br/></div></div><div id="38343761" class="c"><input type="checkbox" id="c-38343761" checked=""/><div class="controls bullet"><span class="by">lazystar</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343109">parent</a><span>|</span><a href="#38343911">prev</a><span>|</span><a href="#38343282">next</a><span>|</span><label class="collapse" for="c-38343761">[-]</label><label class="expand" for="c-38343761">[1 more]</label></div><br/><div class="children"><div class="content">burnout and sleep deprivation can lead to some pretty bad choices; thats why you want to surround yourself with people that will stand up to you when your ideas and plans suffer from too much tunnel vision.  sounds like the other 3 board members were yes-men&#x2F;women; the house of cards was there for a while, it seems.</div><br/></div></div></div></div><div id="38343282" class="c"><input type="checkbox" id="c-38343282" checked=""/><div class="controls bullet"><span class="by">vaxman</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343109">prev</a><span>|</span><a href="#38343289">next</a><span>|</span><label class="collapse" for="c-38343282">[-]</label><label class="expand" for="c-38343282">[2 more]</label></div><br/><div class="children"><div class="content">No, OpenAI will not survive as a company with more than one shareholder. At the end of the day, MSFT has a fiduciary duty to its own shareholders. MSFT has  set certain expectations for its own financial performance based on its agreements with OpenAI and MSFT shares traded based on those expectations. Now OpenAI has sustained a hemorrhage of its leadership that negotiated those agreements, including a public admission by OpenAI of deception in their boardroom and private talk of a potential competitor involving employees. The only question is if OpenAI will capitulate or the lawyers and supply chain will be leveraged to compel their cooperation with protecting the MSFT shareholders. MSFT has deep enough pockets to retain all of the workers. One way or another, the IP and their ops are now the property of the bank, in this case MSFT shareholders. Let’s hope nobody goes to jail by resisting what is a standard cleanup operation at this point.</div><br/><div id="38345002" class="c"><input type="checkbox" id="c-38345002" checked=""/><div class="controls bullet"><span class="by">vaxman</span><span>|</span><a href="#38342767">root</a><span>|</span><a href="#38343282">parent</a><span>|</span><a href="#38343289">next</a><span>|</span><label class="collapse" for="c-38345002">[-]</label><label class="expand" for="c-38345002">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div><div id="38343289" class="c"><input type="checkbox" id="c-38343289" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#38342767">parent</a><span>|</span><a href="#38343282">prev</a><span>|</span><a href="#38343241">next</a><span>|</span><label class="collapse" for="c-38343289">[-]</label><label class="expand" for="c-38343289">[1 more]</label></div><br/><div class="children"><div class="content">Don’t have twits on the board. Lesson learnt.</div><br/></div></div></div></div><div id="38343241" class="c"><input type="checkbox" id="c-38343241" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38342767">prev</a><span>|</span><a href="#38342738">next</a><span>|</span><label class="collapse" for="c-38343241">[-]</label><label class="expand" for="c-38343241">[25 more]</label></div><br/><div class="children"><div class="content">For a change, maybe it&#x27;d be a good idea to get a CEO who at least has faint idea about how ML works on a technical level? Would you like a company that builds rockets to be led by some salesman who doesn&#x27;t understand basic Physics? Probably not. You don&#x27;t need to be Hinton or Schmidhuber, but come on, who thinks it&#x27;s a good idea to have these typical &quot;Silicon Valley VC CEOs&quot; lead an AI company?</div><br/><div id="38343499" class="c"><input type="checkbox" id="c-38343499" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38343241">parent</a><span>|</span><a href="#38343578">next</a><span>|</span><label class="collapse" for="c-38343499">[-]</label><label class="expand" for="c-38343499">[6 more]</label></div><br/><div class="children"><div class="content">The trick is that execs do have unusually good insight into how their tech works, because they can ask their reports to explain it.<p>Btw, I think it&#x27;s funny how much credit Hinton gets for AI. His contribution is pretty much just keeping some grad students on the problem.</div><br/><div id="38344103" class="c"><input type="checkbox" id="c-38344103" checked=""/><div class="controls bullet"><span class="by">ninjin</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343499">parent</a><span>|</span><a href="#38343554">next</a><span>|</span><label class="collapse" for="c-38344103">[-]</label><label class="expand" for="c-38344103">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think it&#x27;s funny how much credit Hinton gets for AI. His contribution is pretty much just keeping some grad students on the problem.<p>Yes, <i>clearly</i> overrated in terms of credit. Doing foundational work in the field going back to the 70s which laid the groundwork and inspired the resurgence of neural networks in the late 80s. Being a solid community organiser throughout his career and keeping neural network research alive through the more formal statistical methods dominating for over a decade. Supervising and thus raising many others who themselves contributed greatly to the explosion of neural network utility we have seen since around 2010 until now. Should I carry on?<p>I think it is <i>absolutely</i> clear that Hinton has contributed plenty enough to get a massive amount of credit for where we are today. The kind of mentality at display here is akin to ahistoricity on the level of saying that Gordon Moore &quot;just started a company&quot; after Apple released the M1 under the delusion that there is not a direct lineage between what we have today and breakthroughs and efforts in the past. Believe it or not, but we stand on the shoulders of giants and cutting them some slack is not the same as downplaying the impact of people more active in the present day; that are gradually becoming future giants.</div><br/></div></div><div id="38343554" class="c"><input type="checkbox" id="c-38343554" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343499">parent</a><span>|</span><a href="#38344103">prev</a><span>|</span><a href="#38343567">next</a><span>|</span><label class="collapse" for="c-38343554">[-]</label><label class="expand" for="c-38343554">[1 more]</label></div><br/><div class="children"><div class="content">I think there&#x27;s an important difference between not understanding and not doing the work yourself because you are in a managerial&#x2F;advisor position. If you give Hinton a recent paper on LLM RLHF he will <i>understand</i> the nuances in it, he just delegates the actual work. If you give Emmett Shear or whoever such a thing, they almost certainly don&#x27;t. For a deep tech company focused on research (not some consumer SaaS thing) I don&#x27;t think you can be a good CEO if you don&#x27;t even have an understanding of what you are building.</div><br/></div></div><div id="38343567" class="c"><input type="checkbox" id="c-38343567" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343499">parent</a><span>|</span><a href="#38343554">prev</a><span>|</span><a href="#38344350">next</a><span>|</span><label class="collapse" for="c-38343567">[-]</label><label class="expand" for="c-38343567">[1 more]</label></div><br/><div class="children"><div class="content">&gt; His contribution is pretty much just keeping some grad students on the problem.<p>I think the second best thing after having technical knowledge is to recognize smart employees and then not get in their way...</div><br/></div></div><div id="38344350" class="c"><input type="checkbox" id="c-38344350" checked=""/><div class="controls bullet"><span class="by">rreichman</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343499">parent</a><span>|</span><a href="#38343567">prev</a><span>|</span><a href="#38344166">next</a><span>|</span><label class="collapse" for="c-38344350">[-]</label><label class="expand" for="c-38344350">[1 more]</label></div><br/><div class="children"><div class="content">Hinton is overrated? That&#x27;s quite a take.</div><br/></div></div><div id="38344166" class="c"><input type="checkbox" id="c-38344166" checked=""/><div class="controls bullet"><span class="by">Upvoter33</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343499">parent</a><span>|</span><a href="#38344350">prev</a><span>|</span><a href="#38343578">next</a><span>|</span><label class="collapse" for="c-38344166">[-]</label><label class="expand" for="c-38344166">[1 more]</label></div><br/><div class="children"><div class="content">Wow that really undersells Hinton.</div><br/></div></div></div></div><div id="38343578" class="c"><input type="checkbox" id="c-38343578" checked=""/><div class="controls bullet"><span class="by">Kwpolska</span><span>|</span><a href="#38343241">parent</a><span>|</span><a href="#38343499">prev</a><span>|</span><a href="#38343971">next</a><span>|</span><label class="collapse" for="c-38343578">[-]</label><label class="expand" for="c-38343578">[2 more]</label></div><br/><div class="children"><div class="content">The CEO is so far removed from day-to-day operations that there&#x27;s no benefit in them having an idea about the technical nitty gritty.</div><br/><div id="38344187" class="c"><input type="checkbox" id="c-38344187" checked=""/><div class="controls bullet"><span class="by">mcv</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343578">parent</a><span>|</span><a href="#38343971">next</a><span>|</span><label class="collapse" for="c-38344187">[-]</label><label class="expand" for="c-38344187">[1 more]</label></div><br/><div class="children"><div class="content">That varies wildly per company. And whether or not that&#x27;s a good idea also varies. But if company exists specifically to develop a single specific technology, I think the CEO should know a thing or two about that technology. Especially when it&#x27;s something so easily misunderstand as AI.</div><br/></div></div></div></div><div id="38343971" class="c"><input type="checkbox" id="c-38343971" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38343241">parent</a><span>|</span><a href="#38343578">prev</a><span>|</span><a href="#38343376">next</a><span>|</span><label class="collapse" for="c-38343971">[-]</label><label class="expand" for="c-38343971">[1 more]</label></div><br/><div class="children"><div class="content">I think so. People don’t add value just by being technical. That’s a very low man on the totem pole perspective.</div><br/></div></div><div id="38343376" class="c"><input type="checkbox" id="c-38343376" checked=""/><div class="controls bullet"><span class="by">justrealist</span><span>|</span><a href="#38343241">parent</a><span>|</span><a href="#38343971">prev</a><span>|</span><a href="#38343285">next</a><span>|</span><label class="collapse" for="c-38343376">[-]</label><label class="expand" for="c-38343376">[2 more]</label></div><br/><div class="children"><div class="content">What special credentials do you think Sam Altman had in AI?</div><br/><div id="38343881" class="c"><input type="checkbox" id="c-38343881" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38343241">root</a><span>|</span><a href="#38343376">parent</a><span>|</span><a href="#38343285">next</a><span>|</span><label class="collapse" for="c-38343881">[-]</label><label class="expand" for="c-38343881">[1 more]</label></div><br/><div class="children"><div class="content">I think the commenter you replied to was saying that Altman doesn&#x27;t have special or any credentials for AI.</div><br/></div></div></div></div></div></div><div id="38342738" class="c"><input type="checkbox" id="c-38342738" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#38343241">prev</a><span>|</span><a href="#38342860">next</a><span>|</span><label class="collapse" for="c-38342738">[-]</label><label class="expand" for="c-38342738">[16 more]</label></div><br/><div class="children"><div class="content">So long Mira Murati. That&#x27;s the second CEO OpenAI has ousted in one week. <a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-announces-leadership-transition" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-announces-leadership-transiti...</a></div><br/><div id="38342889" class="c"><input type="checkbox" id="c-38342889" checked=""/><div class="controls bullet"><span class="by">jxi</span><span>|</span><a href="#38342738">parent</a><span>|</span><a href="#38342843">next</a><span>|</span><label class="collapse" for="c-38342889">[-]</label><label class="expand" for="c-38342889">[13 more]</label></div><br/><div class="children"><div class="content">Her move makes even less sense than what the board did. The board told her the day before that they&#x27;re firing Sam, so she obviously accepted it. But, one day later she caves and sides with Sam (that&#x27;s what the heart tweet means)? That&#x27;s weak leadership and resolve.</div><br/><div id="38343068" class="c"><input type="checkbox" id="c-38343068" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343017">next</a><span>|</span><label class="collapse" for="c-38343068">[-]</label><label class="expand" for="c-38343068">[3 more]</label></div><br/><div class="children"><div class="content">Seems pretty reasonable she would accept it at first while she was still figuring out what&#x27;s going on.<p>Like the board presumably called her and said, &quot;hey Sam is out, you&#x27;re the CEO for now, more details to come&quot;<p>And then in the next 48 hours she had a chance to talk to Sam and others and realize that she was on his side.</div><br/><div id="38343310" class="c"><input type="checkbox" id="c-38343310" checked=""/><div class="controls bullet"><span class="by">awb</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38343068">parent</a><span>|</span><a href="#38343260">next</a><span>|</span><label class="collapse" for="c-38343310">[-]</label><label class="expand" for="c-38343310">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the board presumably called her and said, &quot;hey Sam is out, you&#x27;re the CEO for now, more details to come&quot;<p>I wouldn’t take over as CEO or interim-CEO unless I knew why the previous CEO was fired and was OK with the process and reasoning.</div><br/></div></div><div id="38343260" class="c"><input type="checkbox" id="c-38343260" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38343068">parent</a><span>|</span><a href="#38343310">prev</a><span>|</span><a href="#38343017">next</a><span>|</span><label class="collapse" for="c-38343260">[-]</label><label class="expand" for="c-38343260">[1 more]</label></div><br/><div class="children"><div class="content">And even if she did have the full context, she was going to be able to do more as CEO than as not-CEO.</div><br/></div></div></div></div><div id="38343017" class="c"><input type="checkbox" id="c-38343017" checked=""/><div class="controls bullet"><span class="by">Maxion</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343068">prev</a><span>|</span><a href="#38343069">next</a><span>|</span><label class="collapse" for="c-38343017">[-]</label><label class="expand" for="c-38343017">[1 more]</label></div><br/><div class="children"><div class="content">They might&#x27;ve just told her that she&#x27;s now CEO without her actual approval.</div><br/></div></div><div id="38343069" class="c"><input type="checkbox" id="c-38343069" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343017">prev</a><span>|</span><a href="#38343048">next</a><span>|</span><label class="collapse" for="c-38343069">[-]</label><label class="expand" for="c-38343069">[1 more]</label></div><br/><div class="children"><div class="content">Quite the contrary, that’s strong leadership having the courage to do so under those extreme circumstances.</div><br/></div></div><div id="38343048" class="c"><input type="checkbox" id="c-38343048" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343069">prev</a><span>|</span><a href="#38343491">next</a><span>|</span><label class="collapse" for="c-38343048">[-]</label><label class="expand" for="c-38343048">[4 more]</label></div><br/><div class="children"><div class="content">Who sends heart emojis to their boss? Is this level of sycophancy normal nowadays?</div><br/><div id="38343096" class="c"><input type="checkbox" id="c-38343096" checked=""/><div class="controls bullet"><span class="by">peanuty1</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38343048">parent</a><span>|</span><a href="#38343688">next</a><span>|</span><label class="collapse" for="c-38343096">[-]</label><label class="expand" for="c-38343096">[2 more]</label></div><br/><div class="children"><div class="content">Apparently, OpenAI President Greg Brockman doesn&#x27;t use uppercase letters in his official communications with employees. So I&#x27;m not surprised.</div><br/><div id="38343848" class="c"><input type="checkbox" id="c-38343848" checked=""/><div class="controls bullet"><span class="by">lazystar</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38343096">parent</a><span>|</span><a href="#38343688">next</a><span>|</span><label class="collapse" for="c-38343848">[-]</label><label class="expand" for="c-38343848">[1 more]</label></div><br/><div class="children"><div class="content">yeah... as more folks join the no-uppercase wave, it makes me consider using capitals again.  but, its just a lot more of an expressive way to talk to another human in a text based format.</div><br/></div></div></div></div><div id="38343688" class="c"><input type="checkbox" id="c-38343688" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38343048">parent</a><span>|</span><a href="#38343096">prev</a><span>|</span><a href="#38343491">next</a><span>|</span><label class="collapse" for="c-38343688">[-]</label><label class="expand" for="c-38343688">[1 more]</label></div><br/><div class="children"><div class="content">There was a weird coordinated show of support for Altman by a lot of his employees, quote tweeting &quot;i love the openai team so much&quot;<p>I also found it weird and cultish. I guess it&#x27;s not so different than signing a birthday card going around the office tho. &quot;Sorry you got fired, see you at the next burning man&quot;</div><br/></div></div></div></div><div id="38343491" class="c"><input type="checkbox" id="c-38343491" checked=""/><div class="controls bullet"><span class="by">qaq</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343048">prev</a><span>|</span><a href="#38343238">next</a><span>|</span><label class="collapse" for="c-38343491">[-]</label><label class="expand" for="c-38343491">[1 more]</label></div><br/><div class="children"><div class="content">Well if she talked to Sam and he showed her hypothetical 5 Billion in commitment and offered 1% in &quot;SamAI&quot; ...</div><br/></div></div><div id="38343459" class="c"><input type="checkbox" id="c-38343459" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342889">parent</a><span>|</span><a href="#38343238">prev</a><span>|</span><a href="#38342843">next</a><span>|</span><label class="collapse" for="c-38343459">[-]</label><label class="expand" for="c-38343459">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But, one day later she caves and sides with Sam (that&#x27;s what the heart tweet means)<p>The amount of weight people here give to an _emoji_ on this site... Rampant, unnecessary, baseless speculation in every comment thread bout Altman.<p>Just wait til monday next time. These ultra wealthy over-privileged Worldcoin fucks are not worth this much attention.</div><br/></div></div></div></div><div id="38342843" class="c"><input type="checkbox" id="c-38342843" checked=""/><div class="controls bullet"><span class="by">peanuty1</span><span>|</span><a href="#38342738">parent</a><span>|</span><a href="#38342889">prev</a><span>|</span><a href="#38342860">next</a><span>|</span><label class="collapse" for="c-38342843">[-]</label><label class="expand" for="c-38342843">[2 more]</label></div><br/><div class="children"><div class="content">Thank god they went with Emmett over Murati.</div><br/><div id="38342944" class="c"><input type="checkbox" id="c-38342944" checked=""/><div class="controls bullet"><span class="by">matt_daemon</span><span>|</span><a href="#38342738">root</a><span>|</span><a href="#38342843">parent</a><span>|</span><a href="#38342860">next</a><span>|</span><label class="collapse" for="c-38342944">[-]</label><label class="expand" for="c-38342944">[1 more]</label></div><br/><div class="children"><div class="content">Why?</div><br/></div></div></div></div></div></div><div id="38342860" class="c"><input type="checkbox" id="c-38342860" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38342738">prev</a><span>|</span><a href="#38343573">next</a><span>|</span><label class="collapse" for="c-38342860">[-]</label><label class="expand" for="c-38342860">[35 more]</label></div><br/><div class="children"><div class="content">Not a word from Ilya. I can’t wrap my mind around his motivation. Did he really fire Sam over “AI safety” concerns? How is that remotely rational.</div><br/><div id="38343146" class="c"><input type="checkbox" id="c-38343146" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38343079">next</a><span>|</span><label class="collapse" for="c-38343146">[-]</label><label class="expand" for="c-38343146">[2 more]</label></div><br/><div class="children"><div class="content">It might be because of AI safety, but I think it&#x27;s more likely because Sam was executing plans without informing the board, such as making deals with outside companies, allocating funds to profit-oriented products and making announcements about them, and so on. Perhaps he also wanted to reduce investment in the alignment research that Ilya considered important. Hopefully we&#x27;ll learn the truth soon, though I suspect that it involves confidential deals with other companies and that&#x27;s why we haven&#x27;t heard anything.</div><br/><div id="38343828" class="c"><input type="checkbox" id="c-38343828" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343146">parent</a><span>|</span><a href="#38343079">next</a><span>|</span><label class="collapse" for="c-38343828">[-]</label><label class="expand" for="c-38343828">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s to do with a tribe in openAI that believes ai will take over the world in the next 10 years so we need to spend much of our efforts towards that goal.  What that translates to is strong prompt censorship and automated tools to ban those who keep asking things we don&#x27;t want you to ask.<p>Sam has been agreeing with this group and using this as the reason to go commercial to provide funding for that goal.  The problem is these new products are coming too fast and taking resources which affects the resources they can use for safety training.<p>This group never wanted to release chatGPT but were forced to because a rival company made up of ex openAI employees were going to release their own version.  To the safety group things have been getting worse since that release.<p>Sam is smart enough to use the safety group&#x27;s fear against them.  They finally clued in.<p>OpenAI never wanted to give us chatGPT.  Their hands were forced by a rival and Sam and the board made a decision that brought in the next breakthrough.   From that point things snowballed.  Sam knew he needed to run before bigger players moved in.  It became too obvious after devday that the safety team would never be able to catch up and they pulled the breaks.<p>OpenAI&#x27;s vision of a safe AI has turned into a vision of human censorship rather than protecting society from a rogue AI with the power to harm.</div><br/></div></div></div></div><div id="38343079" class="c"><input type="checkbox" id="c-38343079" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38343146">prev</a><span>|</span><a href="#38342921">next</a><span>|</span><label class="collapse" for="c-38343079">[-]</label><label class="expand" for="c-38343079">[13 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Did he really fire Sam over &quot;AI safety&quot; concerns? How is that remotely rational.</i><p>Not rational iff (and unlike Sustkever, Hinton, Bengio) you are <i>not</i> a &quot;doomer&quot; &#x2F; &quot;decel&quot;. Ilya&#x27;s very vocal and on record that he suspects there may be &quot;something else&quot; going on with these models. He <i>and</i> DeepMind claim AlphaGo is already AGI (correction: ASI) in a very narrow domain (<a href="https:&#x2F;&#x2F;www.arxiv-vanity.com&#x2F;papers&#x2F;2311.02462&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.arxiv-vanity.com&#x2F;papers&#x2F;2311.02462&#x2F;</a>). Ilya particularly predicts it is a <i>given</i> that Neural Networks would achieve broad AGI (superintelligence) <i>before</i> alignment is figured out, unless researchers start putting more resources in it.<p>(like LeCun, I am not a doomer; but I am also not Hinton to know any better)</div><br/><div id="38343328" class="c"><input type="checkbox" id="c-38343328" checked=""/><div class="controls bullet"><span class="by">esjeon</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343079">parent</a><span>|</span><a href="#38343292">next</a><span>|</span><label class="collapse" for="c-38343328">[-]</label><label class="expand" for="c-38343328">[2 more]</label></div><br/><div class="children"><div class="content">&gt; AGI in a very narrow domain<p>The definition of AGI always puzzles me, because &quot;G&quot; in AGI is <i>general</i>, and the word certainly don&#x27;t play well w&#x2F; &quot;narrow&quot;. AGI is a new buzzword I guess.</div><br/><div id="38343397" class="c"><input type="checkbox" id="c-38343397" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343328">parent</a><span>|</span><a href="#38343292">next</a><span>|</span><label class="collapse" for="c-38343397">[-]</label><label class="expand" for="c-38343397">[1 more]</label></div><br/><div class="children"><div class="content">Well there&#x27;s nothing narrow about sota LLMs. The main hinge is just competence.<p>i think the guy you&#x27;re replying to misunderstood the article he&#x27;s alluding to though. They don&#x27;t claim anything about a narrow agi</div><br/></div></div></div></div><div id="38343292" class="c"><input type="checkbox" id="c-38343292" checked=""/><div class="controls bullet"><span class="by">sgregnt</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343079">parent</a><span>|</span><a href="#38343328">prev</a><span>|</span><a href="#38343176">next</a><span>|</span><label class="collapse" for="c-38343292">[-]</label><label class="expand" for="c-38343292">[4 more]</label></div><br/><div class="children"><div class="content">Can you please share the sources for Ilyas views?</div><br/><div id="38343309" class="c"><input type="checkbox" id="c-38343309" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343292">parent</a><span>|</span><a href="#38343176">next</a><span>|</span><label class="collapse" for="c-38343309">[-]</label><label class="expand" for="c-38343309">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;yjOmt" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;yjOmt</a></div><br/><div id="38343582" class="c"><input type="checkbox" id="c-38343582" checked=""/><div class="controls bullet"><span class="by">zxexz</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343309">parent</a><span>|</span><a href="#38343176">next</a><span>|</span><label class="collapse" for="c-38343582">[-]</label><label class="expand" for="c-38343582">[2 more]</label></div><br/><div class="children"><div class="content">For what it&#x27;s worth, the MIT Technology Review these days is considered to be closer to a &quot;tech tabloid&quot; than an actual news source. I personally would find it hard to believe (on gut instinct, nothing empirical) that AGI has been achieved before we have a general playbook for domain-specific SotA models. And I&#x27;m of the &#x27;faction&#x27; that AGI can&#x27;t come soon enough.</div><br/><div id="38343762" class="c"><input type="checkbox" id="c-38343762" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343582">parent</a><span>|</span><a href="#38343176">next</a><span>|</span><label class="collapse" for="c-38343762">[-]</label><label class="expand" for="c-38343762">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>hard to believe (on gut instinct, nothing empirical) that AGI has been achieved before we have a general playbook for domain-specific SotA models</i><p>Ilya is pretty serious about alignment (precisely?) due to his gut instinct: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ft0gTO2K85A">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ft0gTO2K85A</a> (2 Nov 2023)</div><br/></div></div></div></div></div></div></div></div><div id="38343176" class="c"><input type="checkbox" id="c-38343176" checked=""/><div class="controls bullet"><span class="by">mcpackieh</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343079">parent</a><span>|</span><a href="#38343292">prev</a><span>|</span><a href="#38342921">next</a><span>|</span><label class="collapse" for="c-38343176">[-]</label><label class="expand" for="c-38343176">[6 more]</label></div><br/><div class="children"><div class="content">&gt;  &quot;[Artificial <i>General</i> Intelligence] in a very <i>narrow domain</i>.&quot;<p>Which is it?</div><br/><div id="38343360" class="c"><input type="checkbox" id="c-38343360" checked=""/><div class="controls bullet"><span class="by">maxlin</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343176">parent</a><span>|</span><a href="#38343319">next</a><span>|</span><label class="collapse" for="c-38343360">[-]</label><label class="expand" for="c-38343360">[1 more]</label></div><br/><div class="children"><div class="content">I think the guy read the paper he linked the wrong way. The paper explicitly separates &quot;narrow&quot; and &quot;AGI&quot; types where AlphaGo is in the virtuoso bracket for narrow AI, and ChatGPT is in the &quot;emerging&quot; bracket for &quot;general&quot; AI. Only thing it puts to be AGI is few levels up from virtuoso, but in the &quot;general&quot; type.</div><br/></div></div><div id="38343319" class="c"><input type="checkbox" id="c-38343319" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343176">parent</a><span>|</span><a href="#38343360">prev</a><span>|</span><a href="#38342921">next</a><span>|</span><label class="collapse" for="c-38343319">[-]</label><label class="expand" for="c-38343319">[4 more]</label></div><br/><div class="children"><div class="content">Read the paper linked above, and if you don&#x27;t agree that&#x27;s okay. There are many who don&#x27;t.</div><br/><div id="38343393" class="c"><input type="checkbox" id="c-38343393" checked=""/><div class="controls bullet"><span class="by">maxlin</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343319">parent</a><span>|</span><a href="#38343495">next</a><span>|</span><label class="collapse" for="c-38343393">[-]</label><label class="expand" for="c-38343393">[2 more]</label></div><br/><div class="children"><div class="content">Check it again, I think you might have misread the thing. It categorizes things in a way that clearly separates AlphaGO from even shooting towards &quot;AGI&quot;. The &quot;General&quot; part of AGI can&#x27;t really be skipped or words don&#x27;t make any sense anymore.</div><br/><div id="38343416" class="c"><input type="checkbox" id="c-38343416" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343393">parent</a><span>|</span><a href="#38343495">next</a><span>|</span><label class="collapse" for="c-38343416">[-]</label><label class="expand" for="c-38343416">[1 more]</label></div><br/><div class="children"><div class="content">Ah, gotcha; I meant &quot;superintelligence&quot; (which is ASI and not AGI).</div><br/></div></div></div></div><div id="38343495" class="c"><input type="checkbox" id="c-38343495" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343319">parent</a><span>|</span><a href="#38343393">prev</a><span>|</span><a href="#38342921">next</a><span>|</span><label class="collapse" for="c-38343495">[-]</label><label class="expand" for="c-38343495">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone written a response to this paper? Their main gist is to try to define AGI empirically using only what is measurable.</div><br/></div></div></div></div></div></div></div></div><div id="38342921" class="c"><input type="checkbox" id="c-38342921" checked=""/><div class="controls bullet"><span class="by">bufferoverflow</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38343079">prev</a><span>|</span><a href="#38343200">next</a><span>|</span><label class="collapse" for="c-38342921">[-]</label><label class="expand" for="c-38342921">[9 more]</label></div><br/><div class="children"><div class="content">Because that&#x27;s not the actual reason. It looks like a hostile takeover. The &quot;king&quot; of, arguably, the most important company in the world, got kicked out with very little effort. It&#x27;s pretty extraordinary, and the power shift is extraordinary too.</div><br/><div id="38342991" class="c"><input type="checkbox" id="c-38342991" checked=""/><div class="controls bullet"><span class="by">voidfunc</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38342921">parent</a><span>|</span><a href="#38343078">next</a><span>|</span><label class="collapse" for="c-38342991">[-]</label><label class="expand" for="c-38342991">[1 more]</label></div><br/><div class="children"><div class="content">Kicked out is a bit hyperbole. They don&#x27;t have their champion anymore but the deal and their minority ownership stake are inked. They still get tech and profits. They might not have a path to owning OpenAI now but that was a problem a few years down the road. They can also invest in Altmans new thing and poach OpenAI talent to bolster their internal AI research which is probably going to get a massive funding boost.<p>The PR hit will be bad for a few days. Good time to buy MS stock on discount but this won&#x27;t matter in a year or two.</div><br/></div></div><div id="38343078" class="c"><input type="checkbox" id="c-38343078" checked=""/><div class="controls bullet"><span class="by">yreg</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38342921">parent</a><span>|</span><a href="#38342991">prev</a><span>|</span><a href="#38343029">next</a><span>|</span><label class="collapse" for="c-38343078">[-]</label><label class="expand" for="c-38343078">[5 more]</label></div><br/><div class="children"><div class="content">The board firing a CEO is hardly a hostile takeover.</div><br/><div id="38343100" class="c"><input type="checkbox" id="c-38343100" checked=""/><div class="controls bullet"><span class="by">surrealize</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343078">parent</a><span>|</span><a href="#38343517">next</a><span>|</span><label class="collapse" for="c-38343100">[-]</label><label class="expand" for="c-38343100">[3 more]</label></div><br/><div class="children"><div class="content">If you fire one board member (Altman) and remove another from the board (Brockman) it&#x27;s not exactly friendly either</div><br/><div id="38343332" class="c"><input type="checkbox" id="c-38343332" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343100">parent</a><span>|</span><a href="#38343517">next</a><span>|</span><label class="collapse" for="c-38343332">[-]</label><label class="expand" for="c-38343332">[2 more]</label></div><br/><div class="children"><div class="content">Firing generally isn&#x27;t friendly, but no one &quot;took over.&quot; The people who had the power exercised it. Maybe they shouldn&#x27;t have, I feel no compulsion to argue on their behalf, but calling it a &quot;takeover&quot; isn&#x27;t correct.<p>I think when people say &quot;takeover&quot; or &quot;coup&quot; it&#x27;s because they want to convey their view of the moral character of events, that they believe it was an improper decision. But it muddies the waters and I wish they&#x27;d be more direct. &quot;It&#x27;s a coup&quot; is a criticism of <i>how</i> things happened, but the substantive disagreements are actually about <i>that</i> it happened and <i>why</i> it happened.<p>I see lots of polarized debate any time something AI safety related comes up, so I just don&#x27;t really believe that most people would feel differently if the same thing happened but the corporate structure was more conventional, or if Brockman&#x27;s board seat happened to be occupied by someone who was sympathetic to ousting Altman.</div><br/><div id="38343523" class="c"><input type="checkbox" id="c-38343523" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343332">parent</a><span>|</span><a href="#38343517">next</a><span>|</span><label class="collapse" for="c-38343523">[-]</label><label class="expand" for="c-38343523">[1 more]</label></div><br/><div class="children"><div class="content">&quot;It&#x27;s a coup&quot; is loaded language and lets the user insinuate their position without actually explaining and justifying it.</div><br/></div></div></div></div></div></div><div id="38343517" class="c"><input type="checkbox" id="c-38343517" checked=""/><div class="controls bullet"><span class="by">juped</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343078">parent</a><span>|</span><a href="#38343100">prev</a><span>|</span><a href="#38343029">next</a><span>|</span><label class="collapse" for="c-38343517">[-]</label><label class="expand" for="c-38343517">[1 more]</label></div><br/><div class="children"><div class="content">Boards have exactly one job.<p>(It&#x27;s firing the CEO, if anyone wasn&#x27;t aware.)</div><br/></div></div></div></div><div id="38343029" class="c"><input type="checkbox" id="c-38343029" checked=""/><div class="controls bullet"><span class="by">sdwvit</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38342921">parent</a><span>|</span><a href="#38343078">prev</a><span>|</span><a href="#38343200">next</a><span>|</span><label class="collapse" for="c-38343029">[-]</label><label class="expand" for="c-38343029">[2 more]</label></div><br/><div class="children"><div class="content">Maybe someone from higher up called the board?</div><br/><div id="38343621" class="c"><input type="checkbox" id="c-38343621" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343029">parent</a><span>|</span><a href="#38343200">next</a><span>|</span><label class="collapse" for="c-38343621">[-]</label><label class="expand" for="c-38343621">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT-5?</div><br/></div></div></div></div></div></div><div id="38343200" class="c"><input type="checkbox" id="c-38343200" checked=""/><div class="controls bullet"><span class="by">tdubhro1</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38342921">prev</a><span>|</span><a href="#38343128">next</a><span>|</span><label class="collapse" for="c-38343200">[-]</label><label class="expand" for="c-38343200">[6 more]</label></div><br/><div class="children"><div class="content">If it really was about “safety” then why wouldn’t Ilya have made some statement about opening the details of their model at least to some independent researchers under some tight controls. This is what makes it look like a simple power grab, the board has said absolutely nothing about what actions they would take to move toward a safer model of development.</div><br/><div id="38343400" class="c"><input type="checkbox" id="c-38343400" checked=""/><div class="controls bullet"><span class="by">snovv_crash</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343200">parent</a><span>|</span><a href="#38343992">next</a><span>|</span><label class="collapse" for="c-38343400">[-]</label><label class="expand" for="c-38343400">[4 more]</label></div><br/><div class="children"><div class="content">Because they want to slow down further research which would push AGI closer until the safety&#x2F;alignment aspect can catch up.</div><br/><div id="38343630" class="c"><input type="checkbox" id="c-38343630" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343400">parent</a><span>|</span><a href="#38344040">next</a><span>|</span><label class="collapse" for="c-38343630">[-]</label><label class="expand" for="c-38343630">[2 more]</label></div><br/><div class="children"><div class="content">But if you really cared about that why would you be so opaque on everything. Usually people with strong conviction try to convince other people of that conviction.  For a non profit that is supposedly acting in the interests of all mankind, they aren&#x27;t actually telling us shit. Transparency is pretty much the first thing everybody does who actually cares about ethics and social responsibilities.</div><br/><div id="38344051" class="c"><input type="checkbox" id="c-38344051" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343630">parent</a><span>|</span><a href="#38344040">next</a><span>|</span><label class="collapse" for="c-38344051">[-]</label><label class="expand" for="c-38344051">[1 more]</label></div><br/><div class="children"><div class="content">Ilya might be a believer in what Eliezer Yudkowsky is currently saying, which is that opacity is safer.<p><a href="https:&#x2F;&#x2F;x.com&#x2F;esyudkowsky&#x2F;status&#x2F;1725630614723084627?s=46" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;esyudkowsky&#x2F;status&#x2F;1725630614723084627?s=46</a><p>Mr. Yudkowsky is a lot like Richard Stallman.  He’s a historically vital but now-controversial figure whom a lot of AI Safety people tend to distance themselves from nowadays, because he has a tendency to exaggerate for rhetorical effect.  This means that he ends up “preaching to the choir” while pushing away or offending people in the general public who might be open to learning about AI x-risk scenarios but haven’t made up their mind yet.<p>But we in this field owe him a huge debt.  I’d sincerely like to publicly thank Mr. Yudkowsky and say that even if he has fallen out of favor for being too extreme in his views and statements,  Mr. Yudkowsky was one of the 3 or 4 people most central to creating the field of AI safety, and without him, OpenAI and Anthropic would most certainly not exist.<p>I don’t agree with him that opacity is safer, but he’s a brilliant guy and I personally only discovered the field of AI safety through his writings, through which I read about and agreed with the many ways he had thought of by which AGI can cause extinction, and I as well as another of my college friends decided to heed his call for people to start doing something to avert potential exctintion.<p>He’s not always right (a more moderate and accurate figure is someone like Prof. Stuart Russell) but our whole field owes him our gratitude.</div><br/></div></div></div></div><div id="38344040" class="c"><input type="checkbox" id="c-38344040" checked=""/><div class="controls bullet"><span class="by">ffgjgf1</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343400">parent</a><span>|</span><a href="#38343630">prev</a><span>|</span><a href="#38343992">next</a><span>|</span><label class="collapse" for="c-38344040">[-]</label><label class="expand" for="c-38344040">[1 more]</label></div><br/><div class="children"><div class="content">wouldn’t that mean that they’ll just be left behind and it won’t matter what their goal is?</div><br/></div></div></div></div><div id="38343992" class="c"><input type="checkbox" id="c-38343992" checked=""/><div class="controls bullet"><span class="by">victor9000</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343200">parent</a><span>|</span><a href="#38343400">prev</a><span>|</span><a href="#38343128">next</a><span>|</span><label class="collapse" for="c-38343992">[-]</label><label class="expand" for="c-38343992">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because it&#x27;s not about safety, it&#x27;s about ego, vanity, and delusion.</div><br/></div></div></div></div><div id="38343128" class="c"><input type="checkbox" id="c-38343128" checked=""/><div class="controls bullet"><span class="by">singularity2001</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38343200">prev</a><span>|</span><a href="#38343049">next</a><span>|</span><label class="collapse" for="c-38343128">[-]</label><label class="expand" for="c-38343128">[1 more]</label></div><br/><div class="children"><div class="content">To shine some light on the true nature of the &quot;AI safety tribe&quot; aspects I highly recommend reading the other top HN post &#x2F; article : <a href="https:&#x2F;&#x2F;archive.is&#x2F;Vqjpr" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;Vqjpr</a></div><br/></div></div><div id="38343049" class="c"><input type="checkbox" id="c-38343049" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#38342860">parent</a><span>|</span><a href="#38343128">prev</a><span>|</span><a href="#38343573">next</a><span>|</span><label class="collapse" for="c-38343049">[-]</label><label class="expand" for="c-38343049">[3 more]</label></div><br/><div class="children"><div class="content">No he didn&#x27;t fire Sam over AI safety concerns.  That&#x27;s completely made up by people in the twittersphere. The only thing we know is that the board said the reason was that he lied to the board.  The guardian[1] reported that he was working on a new startup[1] and that staff had been told it was due to a breakdown in communication and not to do with anything regarding safety, security, malfeasance or a bunch of other things.<p>[1] <a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2023&#x2F;nov&#x2F;18&#x2F;earthquake-at-chatgpt-developer-as-senior-staff-quit-after-sacking-of-boss-sam-altman" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2023&#x2F;nov&#x2F;18&#x2F;earthquak...</a></div><br/><div id="38343198" class="c"><input type="checkbox" id="c-38343198" checked=""/><div class="controls bullet"><span class="by">frabcus</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343049">parent</a><span>|</span><a href="#38343555">next</a><span>|</span><label class="collapse" for="c-38343198">[-]</label><label class="expand" for="c-38343198">[1 more]</label></div><br/><div class="children"><div class="content">The Atlantic Article makes it pretty clear that the fast growth of the commercial business was giving Ilya too few resources and too little time to do the safety work he wanted to do: <a href="https:&#x2F;&#x2F;archive.ph&#x2F;UjqmQ" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;UjqmQ</a></div><br/></div></div><div id="38343555" class="c"><input type="checkbox" id="c-38343555" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#38342860">root</a><span>|</span><a href="#38343049">parent</a><span>|</span><a href="#38343198">prev</a><span>|</span><a href="#38343573">next</a><span>|</span><label class="collapse" for="c-38343555">[-]</label><label class="expand" for="c-38343555">[1 more]</label></div><br/><div class="children"><div class="content">Spoken to a bunch of folk at OpenAI, it really does seem to be regarding safety. Ilya was extremely worried, did not like the idea of GPT’s as users can train AI’s to do arbitrarily harmful stuff.</div><br/></div></div></div></div></div></div><div id="38343573" class="c"><input type="checkbox" id="c-38343573" checked=""/><div class="controls bullet"><span class="by">ansk</span><span>|</span><a href="#38342860">prev</a><span>|</span><a href="#38344109">next</a><span>|</span><label class="collapse" for="c-38343573">[-]</label><label class="expand" for="c-38343573">[26 more]</label></div><br/><div class="children"><div class="content">The contrast between the media&#x27;s depiction of today&#x27;s events with this outcome demonstrates how much Sam and his aligned interests can influence a narrative.  The vast majority of reporting indicated that Sam held all the leverage, the board members were about to be fired, and a new board would be appointed which would be much better aligned with Sam.  These accounts took special care to portray the current board as inept, wavering, and eager to backtrack.  However, the reality appears to be that the board was steadfast in their decision and focused on moving forward in search of a new CEO.  The truth is, we still don&#x27;t know the real reason why Sam was ousted.  His removal may be justified and it may not.  But in the absence of information, media speculation was overwhelmingly biased in Sam&#x27;s interests.  If the news that the board did not immediately backtrack and capitulate to Sam&#x27;s demands seems to be coming out of left field, you&#x27;ve likely fallen victim to this narrative.  Chances are the board is not as incompetent as you were led to believe, and any judgement of their competence should be reserved until further details are provided on the reasons for Sam&#x27;s removal.</div><br/><div id="38343703" class="c"><input type="checkbox" id="c-38343703" checked=""/><div class="controls bullet"><span class="by">lajawfe</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343806">next</a><span>|</span><label class="collapse" for="c-38343703">[-]</label><label class="expand" for="c-38343703">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the media and the general conversation seems very one sided; and I do not see any basis to take a side. Sam being an overachiever, might actually be acting with maleficence and deceit. Why is no-one even considering that?<p>Everyone is just reiterating that board is inept and trying to undermine them. This does not sit right with me.</div><br/></div></div><div id="38343806" class="c"><input type="checkbox" id="c-38343806" checked=""/><div class="controls bullet"><span class="by">b0tch7</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343703">prev</a><span>|</span><a href="#38343704">next</a><span>|</span><label class="collapse" for="c-38343806">[-]</label><label class="expand" for="c-38343806">[2 more]</label></div><br/><div class="children"><div class="content">The fact that this outcome occurred proves the board&#x27;s resolve &amp; determination (stubbornness?) but not much else.<p>some important questions:
- if Ilya had 4:2, why not just sit Sam down and work all this out in private? 
- why has the board been completely unable to explain themselves to OAI employees? to the public? 
- why not take a more neutral &quot;parting ways&quot; tone?
- latest reporting suggests that the board is doing this without any outside council (legal or professional network). it seems absolutely bonkers to risk funding sources eg MSFT on a decision like this.</div><br/><div id="38345093" class="c"><input type="checkbox" id="c-38345093" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343806">parent</a><span>|</span><a href="#38343704">next</a><span>|</span><label class="collapse" for="c-38345093">[-]</label><label class="expand" for="c-38345093">[1 more]</label></div><br/><div class="children"><div class="content">Human character doesn&#x27;t change that much, let&#x27;s say that in his heart Sam is more of of a move fast and commercialize type of leader and Ilya doesn&#x27;t want that. Do you think them sitting down and talking about it is really going to change things that much? People are who they are. If anything they&#x27;ve probably had these exact conversations many times already. Not every relationship is fixable, sometimes people are just incompatible.<p>As for the board&#x27;s silence to the public, this should be obvious. Talking about their thinking&#x2F;plans&#x2F;reasons for firing Sam exposes them to all kinds of risk both legally and otherwise. The safe move is to stay quiet in public and continue talks with the relevant stakeholders (Microsoft, Sam + loyalists) in private</div><br/></div></div></div></div><div id="38343704" class="c"><input type="checkbox" id="c-38343704" checked=""/><div class="controls bullet"><span class="by">hooande</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343806">prev</a><span>|</span><a href="#38343809">next</a><span>|</span><label class="collapse" for="c-38343704">[-]</label><label class="expand" for="c-38343704">[10 more]</label></div><br/><div class="children"><div class="content">If this were true they never would have had talks to bring him back. That&#x27;s the opposite of steadfast commitment to principles. If Sam wronged them or the company in a significant way they never should have let him back in the building.<p>The board&#x27;s decisions may or may not turn out to be correct in hindsight. But it&#x27;s very difficult to say that this was a good example of leadership or decision making.</div><br/><div id="38343790" class="c"><input type="checkbox" id="c-38343790" checked=""/><div class="controls bullet"><span class="by">dundarious</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343704">parent</a><span>|</span><a href="#38343749">next</a><span>|</span><label class="collapse" for="c-38343790">[-]</label><label class="expand" for="c-38343790">[6 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;ashleevance&#x2F;status&#x2F;1726469283734274338" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;ashleevance&#x2F;status&#x2F;1726469283734274338</a><p>&gt; So, here&#x27;s what happened at OpenAI tonight. Mira planned to hire Sam and Greg back. She turned Team Sam over past couple of days. Idea was to force board to fire everyone, which they figured the board would not do. Board went into total silence. Found their own CEO Emmett Shear<p>Written by the person who broke the story at Bloomberg.<p>So it appears a single person on the board wanted the talks to bring him back, and nobody else. I think that&#x27;s 1 against 3, but the point is that the board wasn&#x27;t totally united (which is not surprising).</div><br/><div id="38343870" class="c"><input type="checkbox" id="c-38343870" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343790">parent</a><span>|</span><a href="#38343990">next</a><span>|</span><label class="collapse" for="c-38343870">[-]</label><label class="expand" for="c-38343870">[3 more]</label></div><br/><div class="children"><div class="content">Mira isn&#x27;t on the OpenAI Board.</div><br/><div id="38343982" class="c"><input type="checkbox" id="c-38343982" checked=""/><div class="controls bullet"><span class="by">dundarious</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343870">parent</a><span>|</span><a href="#38343990">next</a><span>|</span><label class="collapse" for="c-38343982">[-]</label><label class="expand" for="c-38343982">[2 more]</label></div><br/><div class="children"><div class="content">I genuinely don&#x27;t remember who&#x27;s on it, so thanks for the data point. Regardless, my argument is they needn&#x27;t act in total unanimity.<p>I presume this Mira person wasn&#x27;t totally freelancing -- how would this even end up being presented to the board without some direction from someone on the board. So maybe more like 3.5 against 0.5. It could have been a total flip flop, but that&#x27;s a bigger assumption. I have no problem not assuming grand narratives until the basic reporting shakes out.</div><br/><div id="38344377" class="c"><input type="checkbox" id="c-38344377" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343982">parent</a><span>|</span><a href="#38343990">next</a><span>|</span><label class="collapse" for="c-38344377">[-]</label><label class="expand" for="c-38344377">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I presume this Mira person wasn&#x27;t totally freelancing<p>She was the interim CEO; it seems that it was her and some of the rest of the executive team, not the board, that wanted Sam to come back. The board apparently was working on finding a new interim CEO to replace Mira that wasn&#x27;t in Sam&#x27;s camp more than it was trying to bring Sam back.</div><br/></div></div></div></div></div></div><div id="38343990" class="c"><input type="checkbox" id="c-38343990" checked=""/><div class="controls bullet"><span class="by">ffgjgf1</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343790">parent</a><span>|</span><a href="#38343870">prev</a><span>|</span><a href="#38343835">next</a><span>|</span><label class="collapse" for="c-38343990">[-]</label><label class="expand" for="c-38343990">[1 more]</label></div><br/><div class="children"><div class="content">She was the interim CEO not a board member? Considering was supposedly happened appointing her was the smartest thing to do (from the perspective of the board)</div><br/></div></div></div></div><div id="38343749" class="c"><input type="checkbox" id="c-38343749" checked=""/><div class="controls bullet"><span class="by">lostmsu</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343704">parent</a><span>|</span><a href="#38343790">prev</a><span>|</span><a href="#38343734">next</a><span>|</span><label class="collapse" for="c-38343749">[-]</label><label class="expand" for="c-38343749">[1 more]</label></div><br/><div class="children"><div class="content">That depends on what &quot;talks&quot; consisted of. If it was Altman throwing arguments at them, and them just replying &quot;no thank you&quot;, I don&#x27;t see a problem.</div><br/></div></div><div id="38343734" class="c"><input type="checkbox" id="c-38343734" checked=""/><div class="controls bullet"><span class="by">lajawfe</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343704">parent</a><span>|</span><a href="#38343749">prev</a><span>|</span><a href="#38343765">next</a><span>|</span><label class="collapse" for="c-38343734">[-]</label><label class="expand" for="c-38343734">[1 more]</label></div><br/><div class="children"><div class="content">That is just current narrative, we don&#x27;t know the details right? There was immense pressure from investors&#x2F;Microsoft and board had to have that meeting. But the board probably already made their mind and did not balk under pressure.</div><br/></div></div><div id="38343765" class="c"><input type="checkbox" id="c-38343765" checked=""/><div class="controls bullet"><span class="by">jay_kyburz</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343704">parent</a><span>|</span><a href="#38343734">prev</a><span>|</span><a href="#38343809">next</a><span>|</span><label class="collapse" for="c-38343765">[-]</label><label class="expand" for="c-38343765">[1 more]</label></div><br/><div class="children"><div class="content">If I had to guess, they had the talks to bring him back as a favor to somebody, or as a sign of good faith, but neither party had changed their position so there was no compromise to be had.</div><br/></div></div></div></div><div id="38343809" class="c"><input type="checkbox" id="c-38343809" checked=""/><div class="controls bullet"><span class="by">didibus</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343704">prev</a><span>|</span><a href="#38343680">next</a><span>|</span><label class="collapse" for="c-38343809">[-]</label><label class="expand" for="c-38343809">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still surprised how little attention there has been on the fact that Sam Altman&#x27;s sister is accusing him of sexually assaulting her when she was younger.<p>His own sister, even if it&#x27;s not true, it reflects poorly to have this kind of relationship with your sister that she&#x27;d say this, and if it&#x27;s true, it&#x27;s very problematic.<p>And for some reason, very very little mention of this. I just find it suspicious from a media behavior point of view.</div><br/><div id="38343997" class="c"><input type="checkbox" id="c-38343997" checked=""/><div class="controls bullet"><span class="by">nearbuy</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343809">parent</a><span>|</span><a href="#38343873">next</a><span>|</span><label class="collapse" for="c-38343997">[-]</label><label class="expand" for="c-38343997">[1 more]</label></div><br/><div class="children"><div class="content">No, this is the proper way to handle accusations from someone who may not be credible. You investigate privately, and only report after, if the accusations seem credible. You don&#x27;t blast across the media that so-and-so is accused of sexual assault, because then the damage is done, regardless of the truth. Signal boost it enough, and every lay-person&#x27;s main association with the person will become, &quot;oh, that guy accused of sexually assaulting his sister&quot;.<p>The accusations are about events 25 years ago, when they were children. No one will ever be able to disprove this, so there&#x27;s no way to undo the reputational damage.</div><br/></div></div><div id="38343873" class="c"><input type="checkbox" id="c-38343873" checked=""/><div class="controls bullet"><span class="by">emodendroket</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343809">parent</a><span>|</span><a href="#38343997">prev</a><span>|</span><a href="#38343680">next</a><span>|</span><label class="collapse" for="c-38343873">[-]</label><label class="expand" for="c-38343873">[2 more]</label></div><br/><div class="children"><div class="content">Where has this been reported?</div><br/><div id="38343888" class="c"><input type="checkbox" id="c-38343888" checked=""/><div class="controls bullet"><span class="by">didibus</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343873">parent</a><span>|</span><a href="#38343680">next</a><span>|</span><label class="collapse" for="c-38343888">[-]</label><label class="expand" for="c-38343888">[1 more]</label></div><br/><div class="children"><div class="content">She tweeted it herself:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;phuckfilosophy&#x2F;status&#x2F;1459696376133001218" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;phuckfilosophy&#x2F;status&#x2F;145969637613300121...</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;phuckfilosophy&#x2F;status&#x2F;1635704398939832321" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;phuckfilosophy&#x2F;status&#x2F;163570439893983232...</a></div><br/></div></div></div></div></div></div><div id="38343680" class="c"><input type="checkbox" id="c-38343680" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343809">prev</a><span>|</span><a href="#38343637">next</a><span>|</span><label class="collapse" for="c-38343680">[-]</label><label class="expand" for="c-38343680">[1 more]</label></div><br/><div class="children"><div class="content">How much controlling this influence of a narrative impacts for decision to resign for workers as a protest in OpenAI? I hope that not too much…</div><br/></div></div><div id="38343637" class="c"><input type="checkbox" id="c-38343637" checked=""/><div class="controls bullet"><span class="by">systemvoltage</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343680">prev</a><span>|</span><a href="#38343717">next</a><span>|</span><label class="collapse" for="c-38343637">[-]</label><label class="expand" for="c-38343637">[5 more]</label></div><br/><div class="children"><div class="content">There is one thing that sticks out:<p>Why didn&#x27;t the board explain itself clearly?<p>There are times when saying anything publicly would be considered defamation and openining themselves to lawsuits, but it seems that they owe it to their own staff in plain words. They didn&#x27;t explain the situation properly as per leaked internal announcements.</div><br/><div id="38343836" class="c"><input type="checkbox" id="c-38343836" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343637">parent</a><span>|</span><a href="#38344043">next</a><span>|</span><label class="collapse" for="c-38343836">[-]</label><label class="expand" for="c-38343836">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s possible that Sam had some secret plans involving deals with external companies, that the board learned about. They can&#x27;t reveal that information without potentially damaging other businesses and becoming liable.</div><br/><div id="38344199" class="c"><input type="checkbox" id="c-38344199" checked=""/><div class="controls bullet"><span class="by">xiphias2</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343836">parent</a><span>|</span><a href="#38344043">next</a><span>|</span><label class="collapse" for="c-38344199">[-]</label><label class="expand" for="c-38344199">[1 more]</label></div><br/><div class="children"><div class="content">While Sam tried to make the impression that he doesn&#x27;t know why he was fired, he didn&#x27;t even try to deny the allegations that he was in talks with the Saudis to create a for profit AI hardware company.<p>I think you are right that Ilya didn&#x27;t want to give out secret information to not open up himself to lawsuits.</div><br/></div></div></div></div><div id="38344043" class="c"><input type="checkbox" id="c-38344043" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343637">parent</a><span>|</span><a href="#38343836">prev</a><span>|</span><a href="#38343764">next</a><span>|</span><label class="collapse" for="c-38344043">[-]</label><label class="expand" for="c-38344043">[1 more]</label></div><br/><div class="children"><div class="content">I question if any board in history has explained itself with clarity and honesty. By my cynical lens they would never stoop to engage in virtues other than signalling.</div><br/></div></div><div id="38343764" class="c"><input type="checkbox" id="c-38343764" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343637">parent</a><span>|</span><a href="#38344043">prev</a><span>|</span><a href="#38343717">next</a><span>|</span><label class="collapse" for="c-38343764">[-]</label><label class="expand" for="c-38343764">[1 more]</label></div><br/><div class="children"><div class="content">Maybe for a company of 12-50 there would be more candid discussion internally, but over 100 and especially at OpenAI size (and with Microsoft involved) liability control is at the max.  Moreover, if the Board thought the decision would help improve retention, then they would comment, but that&#x27;s clearly not the case.<p>OpenAI is not a typical LLC or S&#x2F;C-corp though, so the Board also has to overcome that conceptual hurdle.</div><br/></div></div></div></div><div id="38343717" class="c"><input type="checkbox" id="c-38343717" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#38343573">parent</a><span>|</span><a href="#38343637">prev</a><span>|</span><a href="#38344109">next</a><span>|</span><label class="collapse" for="c-38343717">[-]</label><label class="expand" for="c-38343717">[2 more]</label></div><br/><div class="children"><div class="content">The board demonstrated their incompetency in how they fired Sam without communicating this decision to their biggest stakeholder, Microsoft, or with any clear transition plan in place.</div><br/><div id="38343759" class="c"><input type="checkbox" id="c-38343759" checked=""/><div class="controls bullet"><span class="by">swalling</span><span>|</span><a href="#38343573">root</a><span>|</span><a href="#38343717">parent</a><span>|</span><a href="#38344109">next</a><span>|</span><label class="collapse" for="c-38343759">[-]</label><label class="expand" for="c-38343759">[1 more]</label></div><br/><div class="children"><div class="content">The board governs a mission-driven nonprofit, not a profit-focused enterprise where Microsoft has board-level influence as investor. This tension (operating as if it is a startup when it is not) is why Altman was fired.</div><br/></div></div></div></div></div></div><div id="38344109" class="c"><input type="checkbox" id="c-38344109" checked=""/><div class="controls bullet"><span class="by">fidotron</span><span>|</span><a href="#38343573">prev</a><span>|</span><a href="#38343461">next</a><span>|</span><label class="collapse" for="c-38344109">[-]</label><label class="expand" for="c-38344109">[1 more]</label></div><br/><div class="children"><div class="content">It is quite clear the true purpose of OpenAI is the exact opposite of the name, meaning it is to run ahead of the curve, understand the impact of developments, and ensure they are locked away by any means necessary at least until they can be exploited by groups represented by the board.<p>Altman was trying to play this game in parallel with commercialization, which brings a whole pile of conflicting groups into the picture. People have utterly underestimated the depth of interest represented by the board.<p>It is highly amusing how many of the EA cult are on each side, and how both will portray whatever they are pursuing entirely for personal goals as for the greater good when in reality no one has a clue.</div><br/></div></div><div id="38343461" class="c"><input type="checkbox" id="c-38343461" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38344109">prev</a><span>|</span><a href="#38343321">next</a><span>|</span><label class="collapse" for="c-38343461">[-]</label><label class="expand" for="c-38343461">[1 more]</label></div><br/><div class="children"><div class="content">May I hope that after all those that were seduced by the money leave with Sam, Ilya will see the light and realize the only &quot;safe&quot; way to deal with AI is to have it 100% open, free and public?</div><br/></div></div><div id="38343321" class="c"><input type="checkbox" id="c-38343321" checked=""/><div class="controls bullet"><span class="by">rf15</span><span>|</span><a href="#38343461">prev</a><span>|</span><a href="#38344591">next</a><span>|</span><label class="collapse" for="c-38343321">[-]</label><label class="expand" for="c-38343321">[4 more]</label></div><br/><div class="children"><div class="content">This entire show will damage Altman and what remains of OpenAI equally - OpenAI because of its unprofessional way of dealing with internal problems, and Altman, well, there&#x27;s apparently a reason they were unhappy with him.</div><br/><div id="38343595" class="c"><input type="checkbox" id="c-38343595" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38343321">parent</a><span>|</span><a href="#38343516">next</a><span>|</span><label class="collapse" for="c-38343595">[-]</label><label class="expand" for="c-38343595">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This entire show will damage Altman and what remains of OpenAI equally<p>The only thing it damages about Altman is the credibility of him using his purported concern for AI safety as a PR lever for regulatory capture.</div><br/></div></div><div id="38343516" class="c"><input type="checkbox" id="c-38343516" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38343321">parent</a><span>|</span><a href="#38343595">prev</a><span>|</span><a href="#38344591">next</a><span>|</span><label class="collapse" for="c-38343516">[-]</label><label class="expand" for="c-38343516">[2 more]</label></div><br/><div class="children"><div class="content">They were apparently unhappy with him because he&#x27;s too good at business, so I think his reputation is intact.</div><br/><div id="38343610" class="c"><input type="checkbox" id="c-38343610" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#38343321">root</a><span>|</span><a href="#38343516">parent</a><span>|</span><a href="#38344591">next</a><span>|</span><label class="collapse" for="c-38343610">[-]</label><label class="expand" for="c-38343610">[1 more]</label></div><br/><div class="children"><div class="content">Or he is not doing what the board wants, which is damaging.<p>If I am good at hacking computers, it does not mean that I should hack all of them and get to the jail.</div><br/></div></div></div></div></div></div><div id="38344591" class="c"><input type="checkbox" id="c-38344591" checked=""/><div class="controls bullet"><span class="by">mcv</span><span>|</span><a href="#38343321">prev</a><span>|</span><a href="#38342744">next</a><span>|</span><label class="collapse" for="c-38344591">[-]</label><label class="expand" for="c-38344591">[1 more]</label></div><br/><div class="children"><div class="content">Is there a good article, or does anyone have the slightest inkling, about what the real conflict here is? There&#x27;s a lot of articles about the symptoms, but what&#x27;s the core issue here?<p>The board claims Altman lied. Is that it? About what? Did he consistently misinform the board about a ton of different things? Or about one really important issue? Or is this just an excuse disguising the actual issues?<p>I notice a lot of people in the comments talking about Altman being more about profit than about OpenAI&#x27;s original mission of developing safe, beneficial AGI. Is Altman threatening that mission or disagreeing with it? It would be really interesting if this was the real issue, but if it was, I can&#x27;t believe it came out of nowhere like that, and I would expect the board to have a new CEO lined up already and not be fumbling for a new CEO and go for one with no particular AI or ethics background.<p>Sutskever gets mentioned as the primary force behind firing Altman. Is this a blatant power grab? Or is Sutskever known to have strong opinions about that mission of beneficial AGI?<p>I feel a bit like I&#x27;m expected to divine the nature of an elephant by only feeling a trunk and an ear.</div><br/></div></div><div id="38342744" class="c"><input type="checkbox" id="c-38342744" checked=""/><div class="controls bullet"><span class="by">flylib</span><span>|</span><a href="#38344591">prev</a><span>|</span><a href="#38342732">next</a><span>|</span><label class="collapse" for="c-38342744">[-]</label><label class="expand" for="c-38342744">[7 more]</label></div><br/><div class="children"><div class="content">Seems like he liked anti sama stuff as well<p><a href="https:&#x2F;&#x2F;x.com&#x2F;moridinamael&#x2F;status&#x2F;1725893666663768321?s=46" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;moridinamael&#x2F;status&#x2F;1725893666663768321?s=46</a></div><br/><div id="38342874" class="c"><input type="checkbox" id="c-38342874" checked=""/><div class="controls bullet"><span class="by">polygamous_bat</span><span>|</span><a href="#38342744">parent</a><span>|</span><a href="#38343983">next</a><span>|</span><label class="collapse" for="c-38342874">[-]</label><label class="expand" for="c-38342874">[2 more]</label></div><br/><div class="children"><div class="content">Would be pretty weird to step in Sam’s replacement if he was philosophically aligned with him?</div><br/><div id="38343407" class="c"><input type="checkbox" id="c-38343407" checked=""/><div class="controls bullet"><span class="by">tempsy</span><span>|</span><a href="#38342744">root</a><span>|</span><a href="#38342874">parent</a><span>|</span><a href="#38343983">next</a><span>|</span><label class="collapse" for="c-38343407">[-]</label><label class="expand" for="c-38343407">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but you rarely see two people who run in the same circles&#x2F;part of the same OG YC class publicly criticize one or the other.</div><br/></div></div></div></div><div id="38343983" class="c"><input type="checkbox" id="c-38343983" checked=""/><div class="controls bullet"><span class="by">schleck8</span><span>|</span><a href="#38342744">parent</a><span>|</span><a href="#38342874">prev</a><span>|</span><a href="#38343133">next</a><span>|</span><label class="collapse" for="c-38343983">[-]</label><label class="expand" for="c-38343983">[1 more]</label></div><br/><div class="children"><div class="content">Unless the tweet I saw was fake, he&#x27;s also decided to slow down pace to 1 or 2 on a scale of 1 to 10. Going to run that company into the floor</div><br/></div></div><div id="38343133" class="c"><input type="checkbox" id="c-38343133" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#38342744">parent</a><span>|</span><a href="#38343983">prev</a><span>|</span><a href="#38342890">next</a><span>|</span><label class="collapse" for="c-38343133">[-]</label><label class="expand" for="c-38343133">[1 more]</label></div><br/><div class="children"><div class="content">Part of the interview process.</div><br/></div></div><div id="38342890" class="c"><input type="checkbox" id="c-38342890" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#38342744">parent</a><span>|</span><a href="#38343133">prev</a><span>|</span><a href="#38342732">next</a><span>|</span><label class="collapse" for="c-38342890">[-]</label><label class="expand" for="c-38342890">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not Emmett?</div><br/><div id="38342935" class="c"><input type="checkbox" id="c-38342935" checked=""/><div class="controls bullet"><span class="by">flylib</span><span>|</span><a href="#38342744">root</a><span>|</span><a href="#38342890">parent</a><span>|</span><a href="#38342732">next</a><span>|</span><label class="collapse" for="c-38342935">[-]</label><label class="expand" for="c-38342935">[1 more]</label></div><br/><div class="children"><div class="content">he liked the tweet</div><br/></div></div></div></div></div></div><div id="38342732" class="c"><input type="checkbox" id="c-38342732" checked=""/><div class="controls bullet"><span class="by">d3nt</span><span>|</span><a href="#38342744">prev</a><span>|</span><a href="#38344276">next</a><span>|</span><label class="collapse" for="c-38342732">[-]</label><label class="expand" for="c-38342732">[1 more]</label></div><br/><div class="children"><div class="content">More details in this tweet thread: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;ashleevance&#x2F;status&#x2F;1726469283734274338" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;ashleevance&#x2F;status&#x2F;1726469283734274338</a></div><br/></div></div><div id="38344276" class="c"><input type="checkbox" id="c-38344276" checked=""/><div class="controls bullet"><span class="by">LrnByTeach</span><span>|</span><a href="#38342732">prev</a><span>|</span><a href="#38342661">next</a><span>|</span><label class="collapse" for="c-38344276">[-]</label><label class="expand" for="c-38344276">[3 more]</label></div><br/><div class="children"><div class="content">This may be a fair workable solution to all the parties involved.<p>Context:<p>---------<p>1.1&#x2F; ILya Sukhar and Board do not agree with Sam Altman vision of a) too fast commercialization of Open AI AND&#x2F;OR  b) too fast progression to GPT-5 level<p>1.2&#x2F; Sam Altman thinks fast iteration and Commercialization is needed in-order to make Open AI financially viable as it is burning too much cash and stay ahead of competition.<p>1.3&#x2F; Microsoft, after investing $10+ Billions do not want this fight enable slow progress of AI Commercialization and fall behind Google AI etc..<p>a workable solution:<p>--------------------<p>2.1&#x2F; @sama @gdb form a new AI company, let us call it e&#x2F;acc Inc.<p>2.2&#x2F; e&#x2F;acc Inc. raises $3 Billions as SAFE instrument from VCs who believed in Sam Altman&#x27;s vision.<p>2.3&#x2F; Open AI and e&#x2F;acc Inc. reach an agreement such that:<p>a) GPT-4 IP transferred to  e&#x2F;acc Inc., this IP transfer is valued as $8 Billion SAFE instrument investment from Open AI into e&#x2F;acc Inc.<p>b) existing Microsoft&#x27;s 49% share in Open AI is transferred to e&#x2F;acc Inc., such that Microsoft owns 49% of e&#x2F;acc Inc.<p>c) the resulted &quot;Lean and pure non-profit Open AI&quot;  with Ilya Sukhar and Board can steer AI progress as they wish, their stake in e&#x2F;acc Inc. will act as funding source to cover their future Research Costs.<p>d) employees can join from Open AI to e&#x2F;acc Inc. as they wish with no antipoaching lawsuits from OpenAI</div><br/><div id="38344345" class="c"><input type="checkbox" id="c-38344345" checked=""/><div class="controls bullet"><span class="by">eightnoteight</span><span>|</span><a href="#38344276">parent</a><span>|</span><a href="#38344325">next</a><span>|</span><label class="collapse" for="c-38344345">[-]</label><label class="expand" for="c-38344345">[1 more]</label></div><br/><div class="children"><div class="content">in hindsight, you got the context pretty accurate i.e importance of microsoft in all of this</div><br/></div></div><div id="38344325" class="c"><input type="checkbox" id="c-38344325" checked=""/><div class="controls bullet"><span class="by">eightnoteight</span><span>|</span><a href="#38344276">parent</a><span>|</span><a href="#38344345">prev</a><span>|</span><a href="#38342661">next</a><span>|</span><label class="collapse" for="c-38344325">[-]</label><label class="expand" for="c-38344325">[1 more]</label></div><br/><div class="children"><div class="content">@sama @gdb joined microsoft</div><br/></div></div></div></div><div id="38342661" class="c"><input type="checkbox" id="c-38342661" checked=""/><div class="controls bullet"><span class="by">tempsy</span><span>|</span><a href="#38344276">prev</a><span>|</span><a href="#38343641">next</a><span>|</span><label class="collapse" for="c-38342661">[-]</label><label class="expand" for="c-38342661">[10 more]</label></div><br/><div class="children"><div class="content">The Twitch guy who now spends his day tweeting about mundane YIMBY stuff? Bizarre…</div><br/><div id="38342675" class="c"><input type="checkbox" id="c-38342675" checked=""/><div class="controls bullet"><span class="by">operatingthetan</span><span>|</span><a href="#38342661">parent</a><span>|</span><a href="#38342688">next</a><span>|</span><label class="collapse" for="c-38342675">[-]</label><label class="expand" for="c-38342675">[3 more]</label></div><br/><div class="children"><div class="content">The whole affair has been bizarre.  Professionals discuss all this stuff out of the public eye and execute when they have a plan.  Every single move from all parties here has been run and gun and looks like amateur hour.  These people do business like the characters on Succession.</div><br/><div id="38343897" class="c"><input type="checkbox" id="c-38343897" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38342675">parent</a><span>|</span><a href="#38342688">next</a><span>|</span><label class="collapse" for="c-38343897">[-]</label><label class="expand" for="c-38343897">[2 more]</label></div><br/><div class="children"><div class="content">I think trump and elon sort of made it ok to showcase the shit online. Like how YC got involved with fighting other VCs on twitter. I have huge respect for YC and never thought they would do that, but here we are.<p>Again a stark reminder that all of these guys from Ray Dalio to the run of the mill SF VC are all just normal, twisted people who don&#x27;t know much better about anything and merely had a run of good luck. Stop paying attention to them.</div><br/><div id="38344988" class="c"><input type="checkbox" id="c-38344988" checked=""/><div class="controls bullet"><span class="by">AutoDunkGPT</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38343897">parent</a><span>|</span><a href="#38342688">next</a><span>|</span><label class="collapse" for="c-38344988">[-]</label><label class="expand" for="c-38344988">[1 more]</label></div><br/><div class="children"><div class="content">Or in other words, there’s no downside to narcissism when you can broadcast it and accumulate loyal followers who will ply you with money and fame</div><br/></div></div></div></div></div></div><div id="38342688" class="c"><input type="checkbox" id="c-38342688" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38342661">parent</a><span>|</span><a href="#38342675">prev</a><span>|</span><a href="#38343641">next</a><span>|</span><label class="collapse" for="c-38342688">[-]</label><label class="expand" for="c-38342688">[6 more]</label></div><br/><div class="children"><div class="content">Feels like the board were &quot;true believers&quot; in the nonprofit&#x2F;human first&#x2F;guardrails and sam just wanted to zuckerberg openai by growing as fast as possible and in the end the true believers won.</div><br/><div id="38342728" class="c"><input type="checkbox" id="c-38342728" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38342688">parent</a><span>|</span><a href="#38343641">next</a><span>|</span><label class="collapse" for="c-38342728">[-]</label><label class="expand" for="c-38342728">[5 more]</label></div><br/><div class="children"><div class="content">What did they win exactly? This is far from the only effort to develop AI models. They were a leader for a time, but seem unlikely to continue in that position.</div><br/><div id="38343355" class="c"><input type="checkbox" id="c-38343355" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38342728">parent</a><span>|</span><a href="#38342963">next</a><span>|</span><label class="collapse" for="c-38343355">[-]</label><label class="expand" for="c-38343355">[3 more]</label></div><br/><div class="children"><div class="content">Even so it buys some time to do safety work</div><br/><div id="38343619" class="c"><input type="checkbox" id="c-38343619" checked=""/><div class="controls bullet"><span class="by">apstls</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38343355">parent</a><span>|</span><a href="#38342963">next</a><span>|</span><label class="collapse" for="c-38343619">[-]</label><label class="expand" for="c-38343619">[2 more]</label></div><br/><div class="children"><div class="content">I don’t really understand what safety work is or entails here, given OpenAI will surely not be the only group to achieve AGI (assuming any group does.) What stops other companies from offering similar models with no (or just less) regard for safety&#x2F;alignment, which may even be seen as a sort of competitive edge against other providers? Would the “safety work” being done or thought about somehow affect other eventual players in the market? Even regulation has the same challenges, but with nations instead of companies, and AFAIK that was more Sam’s domain than Ilya’s. It almost seems like acceleration for the sake of establishing a monopolistic presence in the market to prevent other players from viability, and then working in safety afterwards, would give a better chance of safety long-term… but that of course also seems very unrealistic. I think more broadly, if we’re concerned with the safety of humanity as a species we can’t think about the safety problem on the timescale of individual companies or people, or even governments. I do wonder how Ilya and team are thinking about this.</div><br/></div></div></div></div><div id="38342963" class="c"><input type="checkbox" id="c-38342963" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38342661">root</a><span>|</span><a href="#38342728">parent</a><span>|</span><a href="#38343355">prev</a><span>|</span><a href="#38343641">next</a><span>|</span><label class="collapse" for="c-38342963">[-]</label><label class="expand" for="c-38342963">[1 more]</label></div><br/><div class="children"><div class="content">They won the purity contest. I should start calling openai&#x27;s board of directors The Squad from now on.</div><br/></div></div></div></div></div></div></div></div><div id="38343641" class="c"><input type="checkbox" id="c-38343641" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#38342661">prev</a><span>|</span><a href="#38342881">next</a><span>|</span><label class="collapse" for="c-38343641">[-]</label><label class="expand" for="c-38343641">[4 more]</label></div><br/><div class="children"><div class="content">Kara Swisher has some additional details: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726477828072382480" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;karaswisher&#x2F;status&#x2F;1726477828072382480</a></div><br/><div id="38343981" class="c"><input type="checkbox" id="c-38343981" checked=""/><div class="controls bullet"><span class="by">skygazer</span><span>|</span><a href="#38343641">parent</a><span>|</span><a href="#38342881">next</a><span>|</span><label class="collapse" for="c-38343981">[-]</label><label class="expand" for="c-38343981">[3 more]</label></div><br/><div class="children"><div class="content">Oh wow, she’s definitely taken sides. I wonder if Elon will be paying their legal bills. She alludes to shadowy machinations. This reaches an end, then gets wackier, and repeats.</div><br/><div id="38344569" class="c"><input type="checkbox" id="c-38344569" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#38343641">root</a><span>|</span><a href="#38343981">parent</a><span>|</span><a href="#38342881">next</a><span>|</span><label class="collapse" for="c-38344569">[-]</label><label class="expand" for="c-38344569">[2 more]</label></div><br/><div class="children"><div class="content">Kara Swisher is so unhinged, she thinks Emmett Shear, founder and CEO of Twitch, is &quot;being generous here, less than impressive in comparison to&quot; Mira Murati...</div><br/><div id="38345056" class="c"><input type="checkbox" id="c-38345056" checked=""/><div class="controls bullet"><span class="by">skygazer</span><span>|</span><a href="#38343641">root</a><span>|</span><a href="#38344569">parent</a><span>|</span><a href="#38342881">next</a><span>|</span><label class="collapse" for="c-38345056">[-]</label><label class="expand" for="c-38345056">[1 more]</label></div><br/><div class="children"><div class="content">Noticed that. She did soften that stance later. She seemed oddly invested.</div><br/></div></div></div></div></div></div></div></div><div id="38342881" class="c"><input type="checkbox" id="c-38342881" checked=""/><div class="controls bullet"><span class="by">nilkn</span><span>|</span><a href="#38343641">prev</a><span>|</span><a href="#38343592">next</a><span>|</span><label class="collapse" for="c-38342881">[-]</label><label class="expand" for="c-38342881">[2 more]</label></div><br/><div class="children"><div class="content">At this point, is there any reason to think this arrangement will last longer than 24-48 hours?</div><br/><div id="38342931" class="c"><input type="checkbox" id="c-38342931" checked=""/><div class="controls bullet"><span class="by">skygazer</span><span>|</span><a href="#38342881">parent</a><span>|</span><a href="#38343592">next</a><span>|</span><label class="collapse" for="c-38342931">[-]</label><label class="expand" for="c-38342931">[1 more]</label></div><br/><div class="children"><div class="content">I would think that the board would have tried to (or is still continuing to try to) pick someone to try to placate Microsoft, other than Altman.</div><br/></div></div></div></div><div id="38343592" class="c"><input type="checkbox" id="c-38343592" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#38342881">prev</a><span>|</span><a href="#38343259">next</a><span>|</span><label class="collapse" for="c-38343592">[-]</label><label class="expand" for="c-38343592">[3 more]</label></div><br/><div class="children"><div class="content">This is wild speculation, but I just noticed whenever I load the ChatGPT page, it will briefly say &#x27;ChatGPT Alpha&#x27; before switching to ChatGPT 4.<p>Maybe they created the new model and there&#x27;s something interesting about it?</div><br/><div id="38343780" class="c"><input type="checkbox" id="c-38343780" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#38343592">parent</a><span>|</span><a href="#38343656">next</a><span>|</span><label class="collapse" for="c-38343780">[-]</label><label class="expand" for="c-38343780">[1 more]</label></div><br/><div class="children"><div class="content">I think they were exprimenting with a more advanced 3.5 version for non-paying users - it was showing to some people as an option between gpt-3.5 and gpt4</div><br/></div></div><div id="38343656" class="c"><input type="checkbox" id="c-38343656" checked=""/><div class="controls bullet"><span class="by">sidcool</span><span>|</span><a href="#38343592">parent</a><span>|</span><a href="#38343780">prev</a><span>|</span><a href="#38343259">next</a><span>|</span><label class="collapse" for="c-38343656">[-]</label><label class="expand" for="c-38343656">[1 more]</label></div><br/><div class="children"><div class="content">Same here.  I thought it&#x27;s a React state management issue.  But it could be GPT-5 Alpha.</div><br/></div></div></div></div><div id="38343259" class="c"><input type="checkbox" id="c-38343259" checked=""/><div class="controls bullet"><span class="by">rawgabbit</span><span>|</span><a href="#38343592">prev</a><span>|</span><a href="#38342880">next</a><span>|</span><label class="collapse" for="c-38343259">[-]</label><label class="expand" for="c-38343259">[4 more]</label></div><br/><div class="children"><div class="content">Someone help me understand OpenAI’s situation. If Sutskever remains at the company, OpenAi can continue to improve its ChatGPT models and produce model 5.0?<p>What leverage does Microsoft does have over OpenAi?  Can Microsoft shut off access to their hardware to support Altman? Why would Microsoft want this?</div><br/><div id="38343533" class="c"><input type="checkbox" id="c-38343533" checked=""/><div class="controls bullet"><span class="by">sgift</span><span>|</span><a href="#38343259">parent</a><span>|</span><a href="#38343481">next</a><span>|</span><label class="collapse" for="c-38343533">[-]</label><label class="expand" for="c-38343533">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If Sutskever remains at the company, OpenAi can continue to improve its ChatGPT models and produce model 5.0?<p>I think the more important question is: Is Sutskever interested in a model 5.0 anytime soon? If he really ousted Sam A. because he thought they moved &quot;too fast&quot; wouldn&#x27;t he rather work on making 4.0 &quot;more secure&quot; (whatever that means) instead of producing a 5.0?</div><br/></div></div><div id="38343481" class="c"><input type="checkbox" id="c-38343481" checked=""/><div class="controls bullet"><span class="by">rain_iwakura</span><span>|</span><a href="#38343259">parent</a><span>|</span><a href="#38343533">prev</a><span>|</span><a href="#38342880">next</a><span>|</span><label class="collapse" for="c-38343481">[-]</label><label class="expand" for="c-38343481">[2 more]</label></div><br/><div class="children"><div class="content">the biggest leverage is the billions in compute that Microsoft holds over OpenAI. Without this compute they can&#x27;t run most of the experiments to get number five before others, who are very close, especially Anthropic.</div><br/><div id="38343793" class="c"><input type="checkbox" id="c-38343793" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38343259">root</a><span>|</span><a href="#38343481">parent</a><span>|</span><a href="#38342880">next</a><span>|</span><label class="collapse" for="c-38343793">[-]</label><label class="expand" for="c-38343793">[1 more]</label></div><br/><div class="children"><div class="content">Which is weird because Nvidia&#x2F;TSMC must have some leverage over MS there and could ship out containers of their big cluster units.<p>Also AWS could be the sugar daddy.</div><br/></div></div></div></div></div></div><div id="38342880" class="c"><input type="checkbox" id="c-38342880" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#38343259">prev</a><span>|</span><a href="#38342941">next</a><span>|</span><label class="collapse" for="c-38342880">[-]</label><label class="expand" for="c-38342880">[1 more]</label></div><br/><div class="children"><div class="content">This is the guy <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cw_ckNH-tT8">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cw_ckNH-tT8</a></div><br/></div></div><div id="38342941" class="c"><input type="checkbox" id="c-38342941" checked=""/><div class="controls bullet"><span class="by">losthubble</span><span>|</span><a href="#38342880">prev</a><span>|</span><a href="#38343922">next</a><span>|</span><label class="collapse" for="c-38342941">[-]</label><label class="expand" for="c-38342941">[4 more]</label></div><br/><div class="children"><div class="content">Hopefully this leads to a lot of internal dissent and someone leaks the models</div><br/><div id="38343113" class="c"><input type="checkbox" id="c-38343113" checked=""/><div class="controls bullet"><span class="by">maxlin</span><span>|</span><a href="#38342941">parent</a><span>|</span><a href="#38343106">next</a><span>|</span><label class="collapse" for="c-38343113">[-]</label><label class="expand" for="c-38343113">[1 more]</label></div><br/><div class="children"><div class="content">Would be fun to see the training material, source code (engine &amp; training data scraping systems), and models all leak. With Sam not returning that would be the double tap the now-zombie OpenAI&#x27;d need.</div><br/></div></div><div id="38343197" class="c"><input type="checkbox" id="c-38343197" checked=""/><div class="controls bullet"><span class="by">jessenaser</span><span>|</span><a href="#38342941">parent</a><span>|</span><a href="#38343106">prev</a><span>|</span><a href="#38343922">next</a><span>|</span><label class="collapse" for="c-38343197">[-]</label><label class="expand" for="c-38343197">[1 more]</label></div><br/><div class="children"><div class="content">Betting on Snowden part 2…</div><br/></div></div></div></div><div id="38343922" class="c"><input type="checkbox" id="c-38343922" checked=""/><div class="controls bullet"><span class="by">metamate419</span><span>|</span><a href="#38342941">prev</a><span>|</span><a href="#38343713">next</a><span>|</span><label class="collapse" for="c-38343922">[-]</label><label class="expand" for="c-38343922">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t believe Meta is now the leader in generative AI because of an own goal.</div><br/></div></div><div id="38343713" class="c"><input type="checkbox" id="c-38343713" checked=""/><div class="controls bullet"><span class="by">huxflux</span><span>|</span><a href="#38343922">prev</a><span>|</span><a href="#38344223">next</a><span>|</span><label class="collapse" for="c-38343713">[-]</label><label class="expand" for="c-38343713">[8 more]</label></div><br/><div class="children"><div class="content">HN! 
If I had a recorded phone call, emails and chats I thought it would be the better for the public to know about, how would I go ahead and share such in the best and most anonymous way?</div><br/><div id="38343744" class="c"><input type="checkbox" id="c-38343744" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#38343713">parent</a><span>|</span><a href="#38343819">next</a><span>|</span><label class="collapse" for="c-38343744">[-]</label><label class="expand" for="c-38343744">[3 more]</label></div><br/><div class="children"><div class="content">First of all know that California is a two party consent state. You’d be putting yourself in grave legal danger if your identity could be inferred from a leaked recorded phone call.</div><br/><div id="38343856" class="c"><input type="checkbox" id="c-38343856" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38343713">root</a><span>|</span><a href="#38343744">parent</a><span>|</span><a href="#38343819">next</a><span>|</span><label class="collapse" for="c-38343856">[-]</label><label class="expand" for="c-38343856">[2 more]</label></div><br/><div class="children"><div class="content">Would that apply to an international call?<p>Not that I am encouraging the GP. I upvoted the “laaaaaaaawyer” comment.</div><br/><div id="38344020" class="c"><input type="checkbox" id="c-38344020" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#38343713">root</a><span>|</span><a href="#38343856">parent</a><span>|</span><a href="#38343819">next</a><span>|</span><label class="collapse" for="c-38344020">[-]</label><label class="expand" for="c-38344020">[1 more]</label></div><br/><div class="children"><div class="content">Not a lawyer so: “laaaaaaaawyer!”</div><br/></div></div></div></div></div></div><div id="38343819" class="c"><input type="checkbox" id="c-38343819" checked=""/><div class="controls bullet"><span class="by">8bitchemistry</span><span>|</span><a href="#38343713">parent</a><span>|</span><a href="#38343744">prev</a><span>|</span><a href="#38343751">next</a><span>|</span><label class="collapse" for="c-38343819">[-]</label><label class="expand" for="c-38343819">[1 more]</label></div><br/><div class="children"><div class="content">NYTimes has the SecureDrop tip submission which uses Tor (see details at <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;tips" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nytimes.com&#x2F;tips</a>)</div><br/></div></div><div id="38343751" class="c"><input type="checkbox" id="c-38343751" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#38343713">parent</a><span>|</span><a href="#38343819">prev</a><span>|</span><a href="#38343770">next</a><span>|</span><label class="collapse" for="c-38343751">[-]</label><label class="expand" for="c-38343751">[1 more]</label></div><br/><div class="children"><div class="content">theverge and theinformation have tip lines&#x2F;e-mails, and you can message them, or write to one of the reporters writing about that directly. I would trust them to keep the confidentiality</div><br/></div></div><div id="38343770" class="c"><input type="checkbox" id="c-38343770" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#38343713">parent</a><span>|</span><a href="#38343751">prev</a><span>|</span><a href="#38343794">next</a><span>|</span><label class="collapse" for="c-38343770">[-]</label><label class="expand" for="c-38343770">[1 more]</label></div><br/><div class="children"><div class="content">I believe most major news orgs have secure anonymous mechanisms for communicating with them. E.g. the guardian etc.</div><br/></div></div><div id="38343794" class="c"><input type="checkbox" id="c-38343794" checked=""/><div class="controls bullet"><span class="by">smitty1110</span><span>|</span><a href="#38343713">parent</a><span>|</span><a href="#38343770">prev</a><span>|</span><a href="#38344223">next</a><span>|</span><label class="collapse" for="c-38343794">[-]</label><label class="expand" for="c-38343794">[1 more]</label></div><br/><div class="children"><div class="content">Stop thinking about posting things and talk to a lawyer. I&#x27;m 100% serious here.  Depending on what you post you could end up either a) sued for libel&#x2F;slander&#x2F;illegally recording (CA is a two-party consent state), or b) you could end up called as a witness for any legal action in the fallout of this situation. Seriously, look out for yourself, my dude, there&#x27;s billions of dollars at stake here, and in a fight between whales the shrimp&#x27;s back gets broken.</div><br/></div></div></div></div><div id="38344223" class="c"><input type="checkbox" id="c-38344223" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#38343713">prev</a><span>|</span><a href="#38342749">next</a><span>|</span><label class="collapse" for="c-38344223">[-]</label><label class="expand" for="c-38344223">[1 more]</label></div><br/><div class="children"><div class="content">Good companies are supposed to survive the exit of a CEO. No matter how good that CEO was. If those companies cannot, then perhaps their only value was the CEO and not the product they are offering.</div><br/></div></div><div id="38342749" class="c"><input type="checkbox" id="c-38342749" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38344223">prev</a><span>|</span><label class="collapse" for="c-38342749">[-]</label><label class="expand" for="c-38342749">[18 more]</label></div><br/><div class="children"><div class="content">I think Adam D&#x27;Angelo has a very strong conflict of interest and shouldn&#x27;t have been on the board of OpenAI.<p>I&#x27;m sure Quora views took a hit after ChatGPT. Not like Quora was any good before ChatGPT, they just managed to get to the top of Google results for a lot of common questions.<p>Now, Poe by Quora was trying to go big on custom agents. The GPT Agents announcement on DevDay was a fundamental threat to Poe in many ways.<p>I&#x27;m convinced that Adam D&#x27;Angelo probably had some influence on the other two board members too. He should&#x27;ve left the board of OpenAI the moment OpenAI and his own company were competing in the same space.</div><br/><div id="38342916" class="c"><input type="checkbox" id="c-38342916" checked=""/><div class="controls bullet"><span class="by">dereg</span><span>|</span><a href="#38342749">parent</a><span>|</span><a href="#38343134">next</a><span>|</span><label class="collapse" for="c-38342916">[-]</label><label class="expand" for="c-38342916">[7 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget Tasha McCauley&#x27;s husband, Joseph Gordon Levitt, has been vocally anti-AI during the SAG-AFTRA strike, an event for which AI was a huge point of contention. It&#x27;s a poisoned board.</div><br/><div id="38343720" class="c"><input type="checkbox" id="c-38343720" checked=""/><div class="controls bullet"><span class="by">Klonoar</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38342916">parent</a><span>|</span><a href="#38342973">next</a><span>|</span><label class="collapse" for="c-38343720">[-]</label><label class="expand" for="c-38343720">[1 more]</label></div><br/><div class="children"><div class="content">What? Being vocally anti-AI <i>for the purposes of respecting artists</i> is not being anti-AI period.<p>There is nuance to this point.</div><br/></div></div><div id="38342973" class="c"><input type="checkbox" id="c-38342973" checked=""/><div class="controls bullet"><span class="by">zombiwoof</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38342916">parent</a><span>|</span><a href="#38343720">prev</a><span>|</span><a href="#38343134">next</a><span>|</span><label class="collapse" for="c-38342973">[-]</label><label class="expand" for="c-38342973">[5 more]</label></div><br/><div class="children"><div class="content">Their whole board is a joke<p>The smartest white hot startup on the planet has the smallest board and most inexperienced<p>How did that even happen on Sam’s watch?<p>My take: he always thought Ilya would have his back with Greg and the 3 overrule ruled anybody , so they kept it small<p>Bad idea</div><br/><div id="38343522" class="c"><input type="checkbox" id="c-38343522" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38342973">parent</a><span>|</span><a href="#38343485">next</a><span>|</span><label class="collapse" for="c-38343522">[-]</label><label class="expand" for="c-38343522">[3 more]</label></div><br/><div class="children"><div class="content">&gt; How did that even happen on Sam’s watch?<p>What do you imagine he could have done about the board of a non-profit as CEO and fellow board-member?</div><br/><div id="38343570" class="c"><input type="checkbox" id="c-38343570" checked=""/><div class="controls bullet"><span class="by">ytoawwhra92</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343522">parent</a><span>|</span><a href="#38343664">next</a><span>|</span><label class="collapse" for="c-38343570">[-]</label><label class="expand" for="c-38343570">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What do you imagine he could have done about the board of a non-profit as CEO and fellow board-member?<p>As board members, both Altman and Brockman would have presumably had to vote on any changes to the board - including reduction in number of members and appointment of new members.<p>Do you think the composition of the board before Friday could&#x27;ve been reached without some level of support from Altman and Brockman?</div><br/></div></div><div id="38343664" class="c"><input type="checkbox" id="c-38343664" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343522">parent</a><span>|</span><a href="#38343570">prev</a><span>|</span><a href="#38343485">next</a><span>|</span><label class="collapse" for="c-38343664">[-]</label><label class="expand" for="c-38343664">[1 more]</label></div><br/><div class="children"><div class="content">As CEO and a board member, he was better positioned than literally anyone else to move changes to the governance structure of the nonprofit.</div><br/></div></div></div></div><div id="38343485" class="c"><input type="checkbox" id="c-38343485" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38342973">parent</a><span>|</span><a href="#38343522">prev</a><span>|</span><a href="#38343134">next</a><span>|</span><label class="collapse" for="c-38343485">[-]</label><label class="expand" for="c-38343485">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI was not founded to be a white hot startup: <a href="https:&#x2F;&#x2F;archive.is&#x2F;Vqjpr" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;Vqjpr</a></div><br/></div></div></div></div></div></div><div id="38343134" class="c"><input type="checkbox" id="c-38343134" checked=""/><div class="controls bullet"><span class="by">slkdjfalzkdfj</span><span>|</span><a href="#38342749">parent</a><span>|</span><a href="#38342916">prev</a><span>|</span><a href="#38344246">next</a><span>|</span><label class="collapse" for="c-38343134">[-]</label><label class="expand" for="c-38343134">[7 more]</label></div><br/><div class="children"><div class="content">Adam was appointed to the OpenAI board in April 2018, long before ChatGPT and Poe. He&#x27;s always been somewhat interested&#x2F;involved in AI&#x2F;ML so the appointment broadly makes sense to me.<p>Also keep in mind that a year earlier in Spring 2017 Sam Altman led Quora&#x27;s Series D, after YC previously joined in on Quora&#x27;s Series C in 2014. So the two of them clearly had some pre-existing relationship.<p>I don&#x27;t think OpenAI and Quora (the product) are a serious conflict of interest. You claim &quot;I&#x27;m sure Quora views took a hit after ChatGPT&quot; but I really doubt that&#x27;s true in any meaningful way. Quora&#x27;s struggles are a separate issue and predate the GPT craze of the last year.<p>Nor were Poe and OpenAI competitors until recently; Poe was simply building on top of OpenAI models, the same as hundreds of other ventures in the space right now.<p>However...I do agree that the GPTs announcement two weeks ago now creates a very clear conflict of interest--OpenAI is now competing directly against Poe. And because of that, I agree that Adam probably should leave the board.<p>The timing also raises the question of whether booting Sam is in any way related to the GPTs launch and to Poe. Perhaps Sam wasn&#x27;t candid about the fact that they were about to be competing with Adam&#x27;s company. The whole thing is messy and not a good look and exactly why you try to avoid these conflicts of interest to begin with.</div><br/><div id="38343166" class="c"><input type="checkbox" id="c-38343166" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343134">parent</a><span>|</span><a href="#38343467">next</a><span>|</span><label class="collapse" for="c-38343166">[-]</label><label class="expand" for="c-38343166">[4 more]</label></div><br/><div class="children"><div class="content">I never said Adam should&#x27;ve never been on board.  I was arguing about the part after Poe was competing with OpenAI after DevDay.  That&#x27;s where he has a clear, very strong conflict of interest and to be honest that&#x27;s where the board&#x2F;Adam took the most impactful decision that OpenAI board ever made.</div><br/><div id="38343227" class="c"><input type="checkbox" id="c-38343227" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343166">parent</a><span>|</span><a href="#38343467">next</a><span>|</span><label class="collapse" for="c-38343227">[-]</label><label class="expand" for="c-38343227">[3 more]</label></div><br/><div class="children"><div class="content">On the other hand, Sam &amp; Greg had the opportunity to confront Adam about the obvious conflict and likely could have forced him to step down if they wanted him to. They made their choice. Zero mention about Adam &amp; Poe in the leaks from Sam&#x27;s camp also suggests Sam doesn&#x27;t fault Adam&#x27;s character here.</div><br/><div id="38343271" class="c"><input type="checkbox" id="c-38343271" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343227">parent</a><span>|</span><a href="#38343467">next</a><span>|</span><label class="collapse" for="c-38343271">[-]</label><label class="expand" for="c-38343271">[2 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t read OpenAI&#x27;s company charter, but forcing Adam down would probably require a board majority. It&#x27;s not like they would have made Adam step down if they wanted to.</div><br/><div id="38343300" class="c"><input type="checkbox" id="c-38343300" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343271">parent</a><span>|</span><a href="#38343467">next</a><span>|</span><label class="collapse" for="c-38343300">[-]</label><label class="expand" for="c-38343300">[1 more]</label></div><br/><div class="children"><div class="content">It would, but a PR campaign like the one waged this weekend would probably leave Adam little choice. Sam clearly underestimated the board either way.</div><br/></div></div></div></div></div></div></div></div><div id="38343467" class="c"><input type="checkbox" id="c-38343467" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343134">parent</a><span>|</span><a href="#38343166">prev</a><span>|</span><a href="#38344246">next</a><span>|</span><label class="collapse" for="c-38343467">[-]</label><label class="expand" for="c-38343467">[2 more]</label></div><br/><div class="children"><div class="content">I thought Poe was a partnership with Anthropic?</div><br/><div id="38343626" class="c"><input type="checkbox" id="c-38343626" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343467">parent</a><span>|</span><a href="#38344246">next</a><span>|</span><label class="collapse" for="c-38343626">[-]</label><label class="expand" for="c-38343626">[1 more]</label></div><br/><div class="children"><div class="content">Nope, Poe was always building on OpenAI API and their GPTs. In fact Poe was one of the first companies to get access to GPT-4-32k context length a few months ago and they were the first to make it accessible to their users.</div><br/></div></div></div></div></div></div><div id="38344246" class="c"><input type="checkbox" id="c-38344246" checked=""/><div class="controls bullet"><span class="by">Axsuul</span><span>|</span><a href="#38342749">parent</a><span>|</span><a href="#38343134">prev</a><span>|</span><a href="#38343061">next</a><span>|</span><label class="collapse" for="c-38344246">[-]</label><label class="expand" for="c-38344246">[1 more]</label></div><br/><div class="children"><div class="content">The number of board members should&#x27;ve increased alongside OpenAI&#x27;s growth. Too few board members means the higher potential for corruptibility and too much power being held by each member. It makes no sense for OpenAI in the future to be worth $1T and a leader in AI while still being governed by a small inner circle.</div><br/></div></div><div id="38343061" class="c"><input type="checkbox" id="c-38343061" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#38342749">parent</a><span>|</span><a href="#38344246">prev</a><span>|</span><label class="collapse" for="c-38343061">[-]</label><label class="expand" for="c-38343061">[2 more]</label></div><br/><div class="children"><div class="content">I could be wrong, but I thought I saw something about Quora&#x27;s use of LLMs improving their SEO (the LLM answer to most questions is embedded on the Quora page) and potentially driving more traffic.<p>If you look at Poe as a value add for existing Quora users, instead of a feature that is going to grow their userbase, it&#x27;s still a net win for Quora even if GPT agents exist simultaneously.</div><br/><div id="38343131" class="c"><input type="checkbox" id="c-38343131" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38342749">root</a><span>|</span><a href="#38343061">parent</a><span>|</span><label class="collapse" for="c-38343131">[-]</label><label class="expand" for="c-38343131">[1 more]</label></div><br/><div class="children"><div class="content">Quora SEO&#x27;d their way to the top of most Google searches before the LLMs era.<p>Poe is not really meant as a value addition for Quora users. Poe was a general AI chat company, like ChatGPT.<p>Poe&#x27;s unique selling point was their &#x27;chat agents with customizable instructions&#x2F;personality&#x27; and they were charging people money for this while pretty much building on OpenAI GPT API. They also had an agents store.<p>During DevDay when Sam announced GPTAgents and store, that was a fundamental threat to Poes existance.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>