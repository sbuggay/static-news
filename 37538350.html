<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694941255658" as="style"/><link rel="stylesheet" href="styles.css?v=1694941255658"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/guidance-ai/guidance">Guidance: A guidance language for controlling large language models</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>bx376</span> | <span>38 comments</span></div><br/><div><div id="37540147" class="c"><input type="checkbox" id="c-37540147" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37540824">next</a><span>|</span><label class="collapse" for="c-37540147">[-]</label><label class="expand" for="c-37540147">[2 more]</label></div><br/><div class="children"><div class="content">The thing I most want from this project is a technical explanation of what it&#x27;s actually doing for me and how it works.<p>I dug into this the other day, and just about figured out how the old text-davinci-003 version works.<p>When it runs against a text completion model (like text-davinci-003) the trick seems to be that it breaks your overall Mustache-templated program up into a sequence of prompts.<p>These are executed one at a time. Some of them will be open ended, but some of them will include restrictions based on the rules that you laid out.<p>So you might have a completion prompt that asks for a maximum of 1 token and uses the logit_bias argument to ensure that the returned value can only come from a specific set of tokens. That&#x27;s how you would answer a piece in the program that says &quot;next should be just the sequence &#x27;true&#x27; or &#x27;false&#x27;&quot; for example.<p>What I don&#x27;t yet understand is how it works against non-completion models. There are open issues complaining about broken examples using it with gpt-3.5-turbo for example.<p>And how does it work with models other than the OpenAI ones?</div><br/><div id="37540318" class="c"><input type="checkbox" id="c-37540318" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37540147">parent</a><span>|</span><a href="#37540824">next</a><span>|</span><label class="collapse" for="c-37540318">[-]</label><label class="expand" for="c-37540318">[1 more]</label></div><br/><div class="children"><div class="content">I dug into this a while back, iirc, :handwavy: it comes down to &quot;pausing&quot; template rendering and calling the LLM with all content generated so far. <a href="https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance&#x2F;blob&#x2F;main&#x2F;guidance&#x2F;library&#x2F;_role.py">https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance&#x2F;blob&#x2F;main&#x2F;guidance&#x2F;l...</a><p>This is how we implemented it anyhow, with some more parameters to control how that all works (and the LLM params) at each &quot;pause&quot; point. The _neat_ part for us was that a template helper could make use of the partially generated content. Hadn&#x27;t thought about that before for a templating engine, but was trivial to implement in the end</div><br/></div></div></div></div><div id="37540824" class="c"><input type="checkbox" id="c-37540824" checked=""/><div class="controls bullet"><span class="by">rckrd</span><span>|</span><a href="#37540147">prev</a><span>|</span><a href="#37542160">next</a><span>|</span><label class="collapse" for="c-37540824">[-]</label><label class="expand" for="c-37540824">[1 more]</label></div><br/><div class="children"><div class="content">Logit-bias guidance goes a long way -- LLM structure for regex, context-free grammars, categorization, and typed construction. I&#x27;m working on a hosted and model-agnostic version of this with thiggle<p>[0] <a href="https:&#x2F;&#x2F;thiggle.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;thiggle.com</a></div><br/></div></div><div id="37542160" class="c"><input type="checkbox" id="c-37542160" checked=""/><div class="controls bullet"><span class="by">PUSH_AX</span><span>|</span><a href="#37540824">prev</a><span>|</span><a href="#37538467">next</a><span>|</span><label class="collapse" for="c-37542160">[-]</label><label class="expand" for="c-37542160">[2 more]</label></div><br/><div class="children"><div class="content">The thing that’s bugging me about this eco system is the library, although it augments, has to become the thing running the LLM, I can’t use guidance as a plug-in on some other LLM system.<p>I look forward to when we have something that can run any LLM without compatibility issues, can expose APIs etc and has a robust plugin or augmentation system.</div><br/><div id="37542533" class="c"><input type="checkbox" id="c-37542533" checked=""/><div class="controls bullet"><span class="by">dave1010uk</span><span>|</span><a href="#37542160">parent</a><span>|</span><a href="#37538467">next</a><span>|</span><label class="collapse" for="c-37542533">[-]</label><label class="expand" for="c-37542533">[1 more]</label></div><br/><div class="children"><div class="content">`llm` might be the closest thing to that right now.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm</a></div><br/></div></div></div></div><div id="37538467" class="c"><input type="checkbox" id="c-37538467" checked=""/><div class="controls bullet"><span class="by">adamgordonbell</span><span>|</span><a href="#37542160">prev</a><span>|</span><a href="#37538728">next</a><span>|</span><label class="collapse" for="c-37538467">[-]</label><label class="expand" for="c-37538467">[1 more]</label></div><br/><div class="children"><div class="content">Is this microsoft guidance? It looks like it is and they spun it out.<p>I find guidance to be fantastic for doing complicated prompting. I haven&#x27;t used the &#x27;controlling&#x27; the output feature as much as used it for chain prompting. Ask to come up with answers to a prompt N times, then discuss pros and cons of each answer, then make a new answer based on the best parts of the output. Stuff like that.</div><br/></div></div><div id="37538728" class="c"><input type="checkbox" id="c-37538728" checked=""/><div class="controls bullet"><span class="by">hexman</span><span>|</span><a href="#37538467">prev</a><span>|</span><a href="#37539858">next</a><span>|</span><label class="collapse" for="c-37538728">[-]</label><label class="expand" for="c-37538728">[1 more]</label></div><br/><div class="children"><div class="content">I found that the approach of template processing at large prompts leads to difficulty in reading programs. Their attractive part is that control flow is not separate from prompt as in langchain, which allows you to write prompts as classical programs. But the problem remains in unintuitive syntax for large programs</div><br/></div></div><div id="37539858" class="c"><input type="checkbox" id="c-37539858" checked=""/><div class="controls bullet"><span class="by">lukasb</span><span>|</span><a href="#37538728">prev</a><span>|</span><a href="#37539494">next</a><span>|</span><label class="collapse" for="c-37539858">[-]</label><label class="expand" for="c-37539858">[9 more]</label></div><br/><div class="children"><div class="content">Can anyone comment on how well this does at coercing json output vs OpenAI function calling?</div><br/><div id="37539890" class="c"><input type="checkbox" id="c-37539890" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539858">parent</a><span>|</span><a href="#37540234">next</a><span>|</span><label class="collapse" for="c-37539890">[-]</label><label class="expand" for="c-37539890">[6 more]</label></div><br/><div class="children"><div class="content">This is just a different way to write prompts, it allows some interleaving of calls to the API so you can build things up, write a conversation as a single file, with conventions around the text to send to the LLM.<p>I would not expect it to make a difference in your current applications. Getting JSON is all about the model, training, and prompt, in that order<p>If you are looking for low-hanging fruit to improve your JSON responses from LLMs, fine-tuning will likely get you the most bang for your buck. Start from a coding model like codellama, code-bison, or starcoder</div><br/><div id="37539940" class="c"><input type="checkbox" id="c-37539940" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37539890">parent</a><span>|</span><a href="#37540234">next</a><span>|</span><label class="collapse" for="c-37539940">[-]</label><label class="expand" for="c-37539940">[5 more]</label></div><br/><div class="children"><div class="content">For the local model it forces valid json structure and formatting tokens are being produced by code rather than generated by an LLM.</div><br/><div id="37540037" class="c"><input type="checkbox" id="c-37540037" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37539940">parent</a><span>|</span><a href="#37540234">next</a><span>|</span><label class="collapse" for="c-37540037">[-]</label><label class="expand" for="c-37540037">[4 more]</label></div><br/><div class="children"><div class="content">sounds like post-processing made out to be something more?<p>everyone is doing this, it&#x27;s just part of the pipeline, certainly nothing innovative on that front in guidance</div><br/><div id="37540158" class="c"><input type="checkbox" id="c-37540158" checked=""/><div class="controls bullet"><span class="by">mmoskal</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37540037">parent</a><span>|</span><a href="#37540234">next</a><span>|</span><label class="collapse" for="c-37540158">[-]</label><label class="expand" for="c-37540158">[3 more]</label></div><br/><div class="children"><div class="content">It updates token logits (probabilities) after every token before sampling. I don&#x27;t think this is very common yet.</div><br/><div id="37540219" class="c"><input type="checkbox" id="c-37540219" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37540158">parent</a><span>|</span><a href="#37540334">next</a><span>|</span><label class="collapse" for="c-37540219">[-]</label><label class="expand" for="c-37540219">[1 more]</label></div><br/><div class="children"><div class="content">Right, there are many folks (dozens of us!) yelling about logit processors and building them into various frameworks.<p>The mostly widely accessible form of this is probably BNF grammar biasing in llama.cpp: <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;grammars&#x2F;README.md">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;grammars&#x2F;...</a></div><br/></div></div><div id="37540334" class="c"><input type="checkbox" id="c-37540334" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37540158">parent</a><span>|</span><a href="#37540219">prev</a><span>|</span><a href="#37540234">next</a><span>|</span><label class="collapse" for="c-37540334">[-]</label><label class="expand" for="c-37540334">[1 more]</label></div><br/><div class="children"><div class="content">anecdotal counter evidence, I&#x27;ve seen multiple projects &#x2F; papers manipulating the logits, it&#x27;s a very common thing to think of doing now to improve performance (by eliminating bad options from consideration)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37540234" class="c"><input type="checkbox" id="c-37540234" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#37539858">parent</a><span>|</span><a href="#37539890">prev</a><span>|</span><a href="#37539494">next</a><span>|</span><label class="collapse" for="c-37540234">[-]</label><label class="expand" for="c-37540234">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI function calling + JSON schema is dead simple and has never failed for me, where as I had a bunch of errors with guidance when trying to do things like nested, repeating values.</div><br/><div id="37540339" class="c"><input type="checkbox" id="c-37540339" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539858">root</a><span>|</span><a href="#37540234">parent</a><span>|</span><a href="#37539494">next</a><span>|</span><label class="collapse" for="c-37540339">[-]</label><label class="expand" for="c-37540339">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, my problem with this is that you have to buy into their way of interacting with and calling an LLM. Seems more like Handcuffs than Guidance to me</div><br/></div></div></div></div></div></div><div id="37539494" class="c"><input type="checkbox" id="c-37539494" checked=""/><div class="controls bullet"><span class="by">guyrt</span><span>|</span><a href="#37539858">prev</a><span>|</span><a href="#37539844">next</a><span>|</span><label class="collapse" for="c-37539494">[-]</label><label class="expand" for="c-37539494">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been trying to figure out how projects like this, semantic kernel (also msft), and langchain add value. Is the paradigm sort of like a web framework? It reduces the boilerplate you need to write so you can focus on the business problem?<p>Is that needed in the LLM space yet? I&#x27;m just not convinced the abstraction pays for itself in reduced cognitive load, or at least not yet, but very happy to be convinced otherwise.</div><br/><div id="37539657" class="c"><input type="checkbox" id="c-37539657" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#37539494">parent</a><span>|</span><a href="#37540715">next</a><span>|</span><label class="collapse" for="c-37539657">[-]</label><label class="expand" for="c-37539657">[1 more]</label></div><br/><div class="children"><div class="content">In my experience, they add cognitive load to working with LLMs, including when doing more than just calling an LLM, like RAG. But maybe others feel differently. I’m glad there’s variety.</div><br/></div></div><div id="37540715" class="c"><input type="checkbox" id="c-37540715" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#37539494">parent</a><span>|</span><a href="#37539657">prev</a><span>|</span><a href="#37542624">next</a><span>|</span><label class="collapse" for="c-37540715">[-]</label><label class="expand" for="c-37540715">[1 more]</label></div><br/><div class="children"><div class="content">imo Guidance is valuable, the underlying logic is sufficiently complex that I&#x27;m glad I didn&#x27;t need to DIY it. Same goes for the faster Outlines project from Normal Computing.<p>LangChain: I found having a framework useful to ramp up people without prior LLM exposure, in an open-ended experimental space. The library covers many usecases and gets people thinking. But honestly their documentation is somewhat lacking for that purpose (stale text, shallow examples). Personally, coming from a search background I was able to DIY semantic RAG in the time it took to figure out how to do the same thing in LangChain.</div><br/></div></div><div id="37542624" class="c"><input type="checkbox" id="c-37542624" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#37539494">parent</a><span>|</span><a href="#37540715">prev</a><span>|</span><a href="#37539825">next</a><span>|</span><label class="collapse" for="c-37542624">[-]</label><label class="expand" for="c-37542624">[1 more]</label></div><br/><div class="children"><div class="content">It lets you actually control the output structure and more or less guarantee the LLM is doing what you want. Plus it <i>reliably</i> extracts structured results.<p>It&#x27;s obviously extremely valuable if you&#x27;re doing anything with the LLM output other than displaying it as a block of text to the user, or if you care about the output format at all.</div><br/></div></div><div id="37539825" class="c"><input type="checkbox" id="c-37539825" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539494">parent</a><span>|</span><a href="#37542624">prev</a><span>|</span><a href="#37539844">next</a><span>|</span><label class="collapse" for="c-37539825">[-]</label><label class="expand" for="c-37539825">[1 more]</label></div><br/><div class="children"><div class="content">Yea, in particular for this project, they have created a bespoke templating system.<p>You can get the same thing with Go text&#x2F;templates by adding chat function(s) as custom a helper: <a href="https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;lib&#x2F;templates&#x2F;helpers.go#L29">https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;lib&#x2F;templates...</a><p>As a developer of these things, I don&#x27;t get why they want to put so much effort into the mundane parts rather than focusing on the interesting parts. These things are mostly just the same as any other workflow or API call: <a href="https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;flow&#x2F;chat&#x2F;cmds.cue">https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;flow&#x2F;chat&#x2F;cmd...</a> (unless you get into the python and (i.e.) start messing with the logits or token probabilities)</div><br/></div></div></div></div><div id="37539844" class="c"><input type="checkbox" id="c-37539844" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#37539494">prev</a><span>|</span><a href="#37540073">next</a><span>|</span><label class="collapse" for="c-37539844">[-]</label><label class="expand" for="c-37539844">[4 more]</label></div><br/><div class="children"><div class="content">Is this alive? Last release June 21<p>There are many projects like these I&#x27;m tracking, but they all kinda cool off after the initial prototype and have thus many quirks and limitations<p>So far the only one that I could reliably use was llamacpp grammars, and those are fairly slow</div><br/><div id="37540199" class="c"><input type="checkbox" id="c-37540199" checked=""/><div class="controls bullet"><span class="by">Forgotthepass8</span><span>|</span><a href="#37539844">parent</a><span>|</span><a href="#37540353">next</a><span>|</span><label class="collapse" for="c-37540199">[-]</label><label class="expand" for="c-37540199">[2 more]</label></div><br/><div class="children"><div class="content">LMQL seems to be alive and takes some of these concepts even further.  It&#x27;s the project of 1 or 2 PhD students at ETH Zürich so I&#x27;m hopeful they&#x27;ll see it through.<p>I thought guidance was smart, but LMQL seems brilliant as it merges pythonic constructions with LLMs (I think it may be an outright superset of python with LLM functionalities?)<p>It&#x27;s predicated off a paper as well : <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2212.06094" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2212.06094</a></div><br/><div id="37540371" class="c"><input type="checkbox" id="c-37540371" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539844">root</a><span>|</span><a href="#37540199">parent</a><span>|</span><a href="#37540353">next</a><span>|</span><label class="collapse" for="c-37540371">[-]</label><label class="expand" for="c-37540371">[1 more]</label></div><br/><div class="children"><div class="content">LMQL requires a user to learn a bespoke programming language. Not a good idea, no one really wants to have to learn a new programming language to work with one library or framework. You have to have a really compelling offering. With LLMs, the libraries and frameworks are a dime-a-dozen, so it&#x27;s going to be a much bigger ask of your users</div><br/></div></div></div></div><div id="37540353" class="c"><input type="checkbox" id="c-37540353" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539844">parent</a><span>|</span><a href="#37540199">prev</a><span>|</span><a href="#37540073">next</a><span>|</span><label class="collapse" for="c-37540353">[-]</label><label class="expand" for="c-37540353">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Is this alive? Last release June 21<p>How often does a project need to release to not be considered dead? It&#x27;s only been 10 weeks, in the summer, at the peak of vacation time<p>Look at the most recent commits, they are setting up new governance, which likely took more than 1o weeks to work through the bureaucracy of Mircosoft</div><br/></div></div></div></div><div id="37540073" class="c"><input type="checkbox" id="c-37540073" checked=""/><div class="controls bullet"><span class="by">gsuuon</span><span>|</span><a href="#37539844">prev</a><span>|</span><a href="#37539438">next</a><span>|</span><label class="collapse" for="c-37540073">[-]</label><label class="expand" for="c-37540073">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m hacking on a library (<a href="https:&#x2F;&#x2F;github.com&#x2F;gsuuon&#x2F;ad-llama">https:&#x2F;&#x2F;github.com&#x2F;gsuuon&#x2F;ad-llama</a>) inspired by guidance, but in TS and for the browser. I think structured inference and controlled sampling are really good ways of getting consistent responses out of LLM&#x27;s. It lets smaller models really punch above their weight.<p>I wonder what other folks are building on this sort of workflow? I&#x27;ve been playing around with it and trying to figure out interesting applications that weren&#x27;t possible before.</div><br/></div></div><div id="37539438" class="c"><input type="checkbox" id="c-37539438" checked=""/><div class="controls bullet"><span class="by">maccam912</span><span>|</span><a href="#37540073">prev</a><span>|</span><a href="#37539953">next</a><span>|</span><label class="collapse" for="c-37539438">[-]</label><label class="expand" for="c-37539438">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen this link pop up in various places now, but it seems like it&#x27;s still mostly not being developed? Is there a reason it was posted today? Some new development in it?</div><br/><div id="37540123" class="c"><input type="checkbox" id="c-37540123" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539438">parent</a><span>|</span><a href="#37539953">next</a><span>|</span><label class="collapse" for="c-37540123">[-]</label><label class="expand" for="c-37540123">[1 more]</label></div><br/><div class="children"><div class="content">they are changing the governance and contributors, maybe in prep to do something more or raise money? Every AI library seems to try that path these days<p>Somehow, the VCs and investors made us think it was cool to be working for them rather than our users</div><br/></div></div></div></div><div id="37539953" class="c"><input type="checkbox" id="c-37539953" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#37539438">prev</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37539953">[-]</label><label class="expand" for="c-37539953">[8 more]</label></div><br/><div class="children"><div class="content">This seems just a clone of Microsoft Guidance.</div><br/><div id="37540112" class="c"><input type="checkbox" id="c-37540112" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37539953">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540112">[-]</label><label class="expand" for="c-37540112">[7 more]</label></div><br/><div class="children"><div class="content">This IS Microsoft Guidance, they seem to have spun off a separate GitHub organization for it.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance</a> redirects to <a href="https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance</a> now.</div><br/><div id="37540142" class="c"><input type="checkbox" id="c-37540142" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540112">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540142">[-]</label><label class="expand" for="c-37540142">[6 more]</label></div><br/><div class="children"><div class="content">Simon in the house to clear the air!<p>Do you have similar capabilities in your LLM project?</div><br/><div id="37540153" class="c"><input type="checkbox" id="c-37540153" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540142">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540153">[-]</label><label class="expand" for="c-37540153">[5 more]</label></div><br/><div class="children"><div class="content">Not yet. I&#x27;ve been investigating llama-cpp grammars recently with an eye to getting those working in LLM - maybe even using them to get an equivalent to OpenAI Functions working (which I&#x27;d like to include in LLM too).<p>Notes on grammars here: <a href="https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;llama-cpp-python-grammars" rel="nofollow noreferrer">https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;llama-cpp-python-grammars</a></div><br/><div id="37540232" class="c"><input type="checkbox" id="c-37540232" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540153">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540232">[-]</label><label class="expand" for="c-37540232">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still unclear to me if that is the right direction or a scalable solution.<p>Seeing how far prompt engineering can get you on this from (specifying the grammar as a one&#x2F;few shot) does pretty well, it seems like something that could be better handled at training&#x2F;refining time? My general feeling is that it is inserting a specific and complicated cog, and probably has to be tweaked for each model (as they all have their little quirks)<p>Curious what you think having been working directly on these things?<p>From my experience, you can get an LLM to follow a &quot;grammar&quot; for pretty much anything, without it being an actual grammar spec in one of the many formats. You can pretty much make it up. Here&#x27;s an example of us getting CUE out of a model by giving &quot;tricking&quot; the LLM to generate JSON with less syntax (a subset of both CUE and JSON). Bonus, fewer quotes and commas meant fewer tokens. We turn this into JSON afterwards, works surprisingly well<p><a href="https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;flow&#x2F;chat&#x2F;prompts&#x2F;dm.cue#L27">https:&#x2F;&#x2F;github.com&#x2F;hofstadter-io&#x2F;hof&#x2F;blob&#x2F;_dev&#x2F;flow&#x2F;chat&#x2F;pro...</a></div><br/><div id="37540678" class="c"><input type="checkbox" id="c-37540678" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540232">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540678">[-]</label><label class="expand" for="c-37540678">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t trust most LLMs to reliably follow instructions to &quot;only output JSON with no extra text&quot;. Llama 2 for example really isn&#x27;t very good at following those kinds of instructions in my experience.<p>I really like how grammars offer a realistic path to getting completely dependable formatted output from these models.</div><br/><div id="37540783" class="c"><input type="checkbox" id="c-37540783" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540678">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37540783">[-]</label><label class="expand" for="c-37540783">[2 more]</label></div><br/><div class="children"><div class="content">interesting, I hadn&#x27;t thought about the problem where they don&#x27;t follow the instruction &quot;only output the JSON, do not add explanations or other text&quot;<p>I haven&#x27;t pushed on codellama2 much yet, but my initial experiments, it did not really output anything extra, and my prompt became a one-liner compared to the really long instructions I had to give chatgpt for controlling output. Shows how far you can get with a purpose trained model<p>fine-tuning is important to getting more consistent output, none of the smaller models (open-source sized) are going to get there with just few-shot. Sounds like the grammar logit influencer is a low-cost&#x2F;effort way to constrain output without the fine-tuning cycle. I can imagine they might be better together,  but my hunch is that fine-tuning will still dominate the improvements and consistency. If you don&#x27;t have the training data, that is a very good reason to use this technique too</div><br/><div id="37541886" class="c"><input type="checkbox" id="c-37541886" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37539953">root</a><span>|</span><a href="#37540783">parent</a><span>|</span><a href="#37540213">next</a><span>|</span><label class="collapse" for="c-37541886">[-]</label><label class="expand" for="c-37541886">[1 more]</label></div><br/><div class="children"><div class="content">My favourite joke about LLMs not following formatting instructions is this from Riley Goodside: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;goodside&#x2F;status&#x2F;1657396491676164096" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;goodside&#x2F;status&#x2F;1657396491676164096</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37540213" class="c"><input type="checkbox" id="c-37540213" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#37539953">prev</a><span>|</span><label class="collapse" for="c-37540213">[-]</label><label class="expand" for="c-37540213">[1 more]</label></div><br/><div class="children"><div class="content">I’ve found using a JSON schema and function calling, as described in this blog post, to be just as effective and less opaque than this library:<p><a href="https:&#x2F;&#x2F;blog.simonfarshid.com&#x2F;native-json-output-from-gpt-4" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.simonfarshid.com&#x2F;native-json-output-from-gpt-4</a><p>(it works perfectly with GPT-3.5 as well)</div><br/></div></div></div></div></div></div></div></body></html>