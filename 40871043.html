<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720083676209" as="style"/><link rel="stylesheet" href="styles.css?v=1720083676209"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://people.csail.mit.edu/asolar/SynthesisCourse/Lecture1.htm">Introduction to Program Synthesis</a> <span class="domain">(<a href="https://people.csail.mit.edu">people.csail.mit.edu</a>)</span></div><div class="subtext"><span>squircle</span> | <span>20 comments</span></div><br/><div><div id="40872158" class="c"><input type="checkbox" id="c-40872158" checked=""/><div class="controls bullet"><span class="by">evanthebouncy</span><span>|</span><a href="#40871695">next</a><span>|</span><label class="collapse" for="c-40872158">[-]</label><label class="expand" for="c-40872158">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;evanthebouncy.github.io&#x2F;program-synthesis-minimal&#x2F;" rel="nofollow">https:&#x2F;&#x2F;evanthebouncy.github.io&#x2F;program-synthesis-minimal&#x2F;</a><p>Here&#x27;s my take on it, you can view it as a modern extension to Armando&#x27;s work (he&#x27;s my PhD advisor)</div><br/></div></div><div id="40871695" class="c"><input type="checkbox" id="c-40871695" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40872158">prev</a><span>|</span><a href="#40871624">next</a><span>|</span><label class="collapse" for="c-40871695">[-]</label><label class="expand" for="c-40871695">[4 more]</label></div><br/><div class="children"><div class="content">This is a very classic view, and while interesting, IMO the modern take doesn&#x27;t start till lecture 22. I would expect a reformulation of the lecture series by now. As is, it reads as if an AI course does 21 lectures on Bayesian methods and then ends with a couple on neural networks: Bayesian tricks are neat, but not how I&#x27;d structure a general course. Cool but... I wonder what an update would look like.<p>(I overlapped in the same synthesis research lab as the author by a few years, and currently do LLMs for code synthesis in louie.ai... and much of the coursework was from around those Berkeley years and some MIT ones 10-20 years ago afaict. A lot of foundational work has happened since then.).</div><br/><div id="40871722" class="c"><input type="checkbox" id="c-40871722" checked=""/><div class="controls bullet"><span class="by">SnowflakeOnIce</span><span>|</span><a href="#40871695">parent</a><span>|</span><a href="#40871624">next</a><span>|</span><label class="collapse" for="c-40871722">[-]</label><label class="expand" for="c-40871722">[3 more]</label></div><br/><div class="children"><div class="content">The classical synthesis approaches seem to have much more emphasis on correctness and specification than modern LLM-based synthesis though — things like deriving provably correct lock-free data structures.<p>The LLM-based synthesis work I&#x27;ve seen, in contrast, maybe uses a set of unit tests for correctness testing.<p>It doesn&#x27;t feel like modern LLM-based synthesis supplants the classical approaches.</div><br/><div id="40872148" class="c"><input type="checkbox" id="c-40872148" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40871695">root</a><span>|</span><a href="#40871722">parent</a><span>|</span><a href="#40871624">next</a><span>|</span><label class="collapse" for="c-40872148">[-]</label><label class="expand" for="c-40872148">[2 more]</label></div><br/><div class="children"><div class="content">If you think about classical synthesis as fancy tricks around optimizing SAT encodings &amp; search, neural synthesis becomes about how to solve np-hard problems there instantly. There are other perspectives as well, but that&#x27;s already a dual LLM paper for a bunch of individual classical papers, without losing safety. Ex:  leapfrog the concolic execution papers via a fast oracle.<p>Likewise, a lot of cool work is about automating the proof theory much better. Terrance Tao has been going down that rabbithole, which is amazing, and I hope the security community does too. I know Dawn Song, one of the big names here, is.<p>Another big area is making programming more accessible by assuming synthesizers, and language design decisions around that. A lot of that work has been shifting bc LLMs too. Ex: Historically PLs had zero domain understanding, just logic, and that has really flipped since GPT4, so the concept of a DSL is now also flipping.<p>Finally.. a lot of neural synthesis can and does entirely ignore the SAT aspect. There is a lot of depth to it on its own, and amazing results.</div><br/><div id="40872684" class="c"><input type="checkbox" id="c-40872684" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#40871695">root</a><span>|</span><a href="#40872148">parent</a><span>|</span><a href="#40871624">next</a><span>|</span><label class="collapse" for="c-40872684">[-]</label><label class="expand" for="c-40872684">[1 more]</label></div><br/><div class="children"><div class="content">Have a few papers on hand to start reading about these?</div><br/></div></div></div></div></div></div></div></div><div id="40871624" class="c"><input type="checkbox" id="c-40871624" checked=""/><div class="controls bullet"><span class="by">Darmani</span><span>|</span><a href="#40871695">prev</a><span>|</span><a href="#40871100">next</a><span>|</span><label class="collapse" for="c-40871624">[-]</label><label class="expand" for="c-40871624">[6 more]</label></div><br/><div class="children"><div class="content">Hi! I was the TA for this course in 2020, and did my Ph. D. under the professor. Ask me anything.</div><br/><div id="40872906" class="c"><input type="checkbox" id="c-40872906" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#40871624">parent</a><span>|</span><a href="#40871751">next</a><span>|</span><label class="collapse" for="c-40872906">[-]</label><label class="expand" for="c-40872906">[1 more]</label></div><br/><div class="children"><div class="content">OK!<p>I work in financial services, a lot of customers want tools to support their creaking code bases.<p>What are the state of the art options, both commercial and open source?<p>What are the prospects for things like translating COBOL to Python or Java?</div><br/></div></div><div id="40871751" class="c"><input type="checkbox" id="c-40871751" checked=""/><div class="controls bullet"><span class="by">squircle</span><span>|</span><a href="#40871624">parent</a><span>|</span><a href="#40872906">prev</a><span>|</span><a href="#40872082">next</a><span>|</span><label class="collapse" for="c-40871751">[-]</label><label class="expand" for="c-40871751">[2 more]</label></div><br/><div class="children"><div class="content">Hi @Darmami, what have you been working on in the meanwhile? Given the current state of programming and compsci research, what interests you these days? (What do you see as most important 5 to 10 years down the road?) As a layperson I don&#x27;t have time to grok most of this but revisit from time to time.</div><br/><div id="40872115" class="c"><input type="checkbox" id="c-40872115" checked=""/><div class="controls bullet"><span class="by">Darmani</span><span>|</span><a href="#40871624">root</a><span>|</span><a href="#40871751">parent</a><span>|</span><a href="#40872082">next</a><span>|</span><label class="collapse" for="c-40872115">[-]</label><label class="expand" for="c-40872115">[1 more]</label></div><br/><div class="children"><div class="content">Hi Squircle!<p>I mostly left academia after graduating, and am not actively following current research, although I still live in Cambridge and attend a fair number of research events. I can say that deep learning has taken over PL research, just like everything else. A good number of PL and synthesis people have shifted heavily into pure deep learning, and a large proportion of those that haven&#x27;t are working either on applying deep learning and LLMs to solve PL problems, fusing PL and ML techniques (aka &quot;neurosymbolic programming&quot; -- the Scallop project from Mayur Naik&#x27;s group is particularly exciting to me), or finding ways to use PL techniques to solve ML problems. For an example of the latter, I just flipped through this year&#x27;s PLDI papers, and one caught my eye that sounds like it has nothing to do with AI, &quot;Hashing Modulo Context-Sensitive Alpha Equivalence.&quot; (Decoding the jargon, that means &quot;How to deal with an enormous set of programs that contain lambdas&quot; -- something that comes up when doing search-based synthesis and superoptimization.) Its abstract ends: &quot;We have employed the algorithm to obtain a large-scale, densely packed, interconnected graph of mathematical knowledge from the Coq proof assistant for machine learning purposes.&quot;<p>I think PL techniques do provide the key to overcoming a lot of the problems with LLMs. You want your LLM to have better correctness, reasoning, and goal-directed search -- researchers in programming languages and formal methods are expert at this. I am here to some extent conflating PL&#x2F;FM techniques with traditional automated reasoning, but I think that&#x27;s a fine conflation to make, because such techniques have been incubated by the PL&#x2F;FM communities for the past 30 years since they were sidelined by AI. Case in point: very large fraction of computational logic and automated reasoning papers are motivated  by problems in program analysis, verification, and synthesis.. <a href="https:&#x2F;&#x2F;easychair.org&#x2F;smart-program&#x2F;FLoC2022&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;easychair.org&#x2F;smart-program&#x2F;FLoC2022&#x2F;index.html</a><p>As for what I have been up to: Trained a few hundred more software engineers, mirdin.com . While I mostly stayed away from AI stuff during my Ph. D., I&#x27;ve given in to the tides, and am now building a startup using my AI, PL, and pedagogy expertise to solve all problems related to codebase-learning (onboarding new hires, changing teams faster, etc).<p>At the very end of my Ph. D., I discovered a new program synthesis technique based on constrained tree automata, and used it  to build a synthesizer which is 8x more performant on one benchmark than the previous SOTA while using 10x less code. <a href="https:&#x2F;&#x2F;www.jameskoppel.com&#x2F;files&#x2F;papers&#x2F;ecta.pdf" rel="nofollow">https:&#x2F;&#x2F;www.jameskoppel.com&#x2F;files&#x2F;papers&#x2F;ecta.pdf</a> .  So the research I&#x27;ve done since graduating has largely been follow-ups to that. See <a href="https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;proceedings-article&#x2F;icst&#x2F;2023&#x2F;566600a293&#x2F;1NsXOaMsvja" rel="nofollow">https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;proceedings-article&#x2F;icst&#x2F;2023&#x2F;...</a> , <a href="https:&#x2F;&#x2F;pldi22.sigplan.org&#x2F;details&#x2F;egraphs-2022-papers&#x2F;4&#x2F;E-Graphs-VSAs-and-Tree-Automata-a-Rosetta-Stone" rel="nofollow">https:&#x2F;&#x2F;pldi22.sigplan.org&#x2F;details&#x2F;egraphs-2022-papers&#x2F;4&#x2F;E-G...</a> . I&#x27;m currently on two collaborations. One is continuing to develop algorithms for new kinds of constrained tree automata that can synthesize more kinds of programs. The other is an outgrowth of my startup: an empirical study on existing tools for codebase learning.<p>Anyway, that&#x27;s not a comprehensive answer on what to watch out for in the field, which I am not presently qualified to give if I ever was, but it&#x27;s the things that have my attention.<p>Oh, but: watch Isil Dillig. Everything that comes out of her lab is good.</div><br/></div></div></div></div><div id="40872082" class="c"><input type="checkbox" id="c-40872082" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#40871624">parent</a><span>|</span><a href="#40871751">prev</a><span>|</span><a href="#40871100">next</a><span>|</span><label class="collapse" for="c-40872082">[-]</label><label class="expand" for="c-40872082">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for offering your time!<p>1. How do you&#x2F;y&#x27;all feel about the ethics of publishing this kind of detailed instructional material for self-replicating machines on the open internet, given the potential risk of behavioral singularities from as-of-yet-uncharted intelligence explosion dynamics? I mean this question in the most friendly, least “gotcha” way possible — feel free to answer flippantly!<p>2. What would you say was the “frame problem” of this work that blocked progress, either recently or in your historical readings? I’m just starting to examine this literature after intentionally not engaging while designing my own systems, and it seems pretty damn robust in a post-frame-problem world. What might I be missing out of naïveté?</div><br/><div id="40872127" class="c"><input type="checkbox" id="c-40872127" checked=""/><div class="controls bullet"><span class="by">Darmani</span><span>|</span><a href="#40871624">root</a><span>|</span><a href="#40872082">parent</a><span>|</span><a href="#40871100">next</a><span>|</span><label class="collapse" for="c-40872127">[-]</label><label class="expand" for="c-40872127">[1 more]</label></div><br/><div class="children"><div class="content">1. I&#x27;ve been a doomer since before the term was invented, and I never had any worry about synthesis research based on symbolic techniques. Gödel is our friend here: they&#x27;re not powerful enough to model themselves. The best you get is stuff like <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;7886678?casa_token=XcQTz0HnqJcAAAAA:U9YCIDopCla_slF3fHzJwjPPf_UsRRVJ25DDhyuWlaIfYZbldPi2TQFhpMhLGXg5Up2YMLTE" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;7886678?casa_t...</a> . An important component of the Sketch synthesizer is its simplifier, and this paper used Sketch to synthesize a better simplifier, and that speeds up synthesis times by 15%-60%. But that&#x27;s a one-time improvement. The exponential take off comes from somewhere else.<p>2. Let me see if I understand your question: I think you&#x27;re saying &quot;The frame problem of AI and philosophy, <a href="https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;frame-problem&#x2F;" rel="nofollow">https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;frame-problem&#x2F;</a> , was the major blocker in AI systems, and now it&#x27;s been solved by deep learning. What is the corresponding problem in program synthesis?&quot; I think your &quot;pretty damn robust&quot; comment is important, but haven&#x27;t yet figured out what you mean.<p>Part of the reason I found this confusing is that the literal frame problem also appears in PL and synthesis, primarily in the verification of heap-based imperative programs. See the &quot;frame rule&quot; of separation logic.<p>So anyway, what do I see as the big challenges stopping synthesis from reaching its dream of being able to generate well-designed large programs with little input?<p>My two answers:<p>First, there&#x27;s the problem of finding good abstractions. You see this in very old work:trying to prove an imperative program works is easy to automate EXCEPT for the problem of finding loop invariants. This has remained a challenging problem in the 50 years since it was first described. Craig interpolation is the classic solution, but it only goes so far. The synthesis view is: figuring out how to write loops is not straightforward because you need to summarize infinitely possible states. And that&#x27;s loops; designing data structures and finding good invariants for stateful applications is harder still.<p>Second is what I like to call the &quot;semantic veil.&quot; Generally, for any given chunk of code, there are multiple goals and abstractions that yield the same chunk of code. See my analogy to dairy-free chocolate chips in <a href="https:&#x2F;&#x2F;www.pathsensitive.com&#x2F;2023&#x2F;03&#x2F;modules-matter-most-for-masses.html" rel="nofollow">https:&#x2F;&#x2F;www.pathsensitive.com&#x2F;2023&#x2F;03&#x2F;modules-matter-most-fo...</a> . So deducing the intentions of a piece of code from just the code itself is literally impossible. Unfortunately, the way humans design programs is much better understood as being about these higher-level organizational structures, and not about the code itself. This is an area where I&#x27;m excited about the potential of LLMs: they can make excellent use of the information in priors and in natural language to guess said intentions.</div><br/></div></div></div></div></div></div><div id="40871100" class="c"><input type="checkbox" id="c-40871100" checked=""/><div class="controls bullet"><span class="by">gnabgib</span><span>|</span><a href="#40871624">prev</a><span>|</span><a href="#40871945">next</a><span>|</span><label class="collapse" for="c-40871100">[-]</label><label class="expand" for="c-40871100">[2 more]</label></div><br/><div class="children"><div class="content">(2018) Discussion on HN in 2021 (132 points) <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28099928">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28099928</a></div><br/><div id="40871129" class="c"><input type="checkbox" id="c-40871129" checked=""/><div class="controls bullet"><span class="by">squircle</span><span>|</span><a href="#40871100">parent</a><span>|</span><a href="#40871945">next</a><span>|</span><label class="collapse" for="c-40871129">[-]</label><label class="expand" for="c-40871129">[1 more]</label></div><br/><div class="children"><div class="content">Nice. Thanks @gnabgib</div><br/></div></div></div></div><div id="40871945" class="c"><input type="checkbox" id="c-40871945" checked=""/><div class="controls bullet"><span class="by">uptownfunk</span><span>|</span><a href="#40871100">prev</a><span>|</span><a href="#40872170">next</a><span>|</span><label class="collapse" for="c-40871945">[-]</label><label class="expand" for="c-40871945">[1 more]</label></div><br/><div class="children"><div class="content">Agree with the other commenter the new approaches are mostly neurosymbolic and based on DNNs vs the approaches given here. FWIW I think this is one of the critical pieces to AGI and I know many of the large AI labs are working on integrating these approaches in an agentic way with the LLMs they’ve trained. I expect this will dominate at least the next 12-24 months of research. There are also a few AI startups out there also working on prototyping these ideas.</div><br/></div></div><div id="40872170" class="c"><input type="checkbox" id="c-40872170" checked=""/><div class="controls bullet"><span class="by">DrMiaow</span><span>|</span><a href="#40871945">prev</a><span>|</span><a href="#40871814">next</a><span>|</span><label class="collapse" for="c-40872170">[-]</label><label class="expand" for="c-40872170">[1 more]</label></div><br/><div class="children"><div class="content">It warms my heart to see program generation getting some light.<p>If you are into this then follow me here. I&#x27;m working on a program synthesis project in my spare time, a fusion of PG and LLMs.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;sqvHjXfbI8o?si=rg6EnqkHtUjs1Cki&amp;t=423" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;sqvHjXfbI8o?si=rg6EnqkHtUjs1Cki&amp;t=423</a></div><br/></div></div><div id="40871814" class="c"><input type="checkbox" id="c-40871814" checked=""/><div class="controls bullet"><span class="by">KhoomeiK</span><span>|</span><a href="#40872170">prev</a><span>|</span><a href="#40871959">next</a><span>|</span><label class="collapse" for="c-40871814">[-]</label><label class="expand" for="c-40871814">[2 more]</label></div><br/><div class="children"><div class="content">Everything relevant in &quot;program synthesis&quot; moved to the new buzzword &quot;codegen&quot;</div><br/><div id="40872118" class="c"><input type="checkbox" id="c-40872118" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#40871814">parent</a><span>|</span><a href="#40871959">next</a><span>|</span><label class="collapse" for="c-40872118">[-]</label><label class="expand" for="c-40872118">[1 more]</label></div><br/><div class="children"><div class="content">Depends on the extent to which you understand the Silicon Valley venture capitalism era as a permanent evolution, as opposed to an unsustainable trend!<p>In my nonacademic opinion, <i>codegen</i> is way, way less meaningful and powerful of a perspective to take on the problem than <i>Program Synthesis</i>. That said, I’m curious - are you mostly referencing commercial and OSS work with this comment, or does this also include institutional textbooks and tutorials and such?<p>FWIW, Program Synthesis is still much more popular in print according to Google Ngram - tho it’s losing ground fast!<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;bhDPzho.jpeg" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;bhDPzho.jpeg</a><p>Is there a similar tool that would accurately measure usage in blogs, manuals, and github pages, I wonder?</div><br/></div></div></div></div><div id="40871959" class="c"><input type="checkbox" id="c-40871959" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#40871814">prev</a><span>|</span><label class="collapse" for="c-40871959">[-]</label><label class="expand" for="c-40871959">[2 more]</label></div><br/><div class="children"><div class="content">Has LLM shaken up this field?</div><br/><div id="40872744" class="c"><input type="checkbox" id="c-40872744" checked=""/><div class="controls bullet"><span class="by">mxsjoberg</span><span>|</span><a href="#40871959">parent</a><span>|</span><label class="collapse" for="c-40872744">[-]</label><label class="expand" for="c-40872744">[1 more]</label></div><br/><div class="children"><div class="content">yes</div><br/></div></div></div></div></div></div></div></div></div></body></html>