<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686733268785" as="style"/><link rel="stylesheet" href="styles.css?v=1686733268785"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/belladoreai/llama-tokenizer-js">Show HN: LLaMA tokenizer that runs in browser</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>belladoreai</span> | <span>16 comments</span></div><br/><div><div id="36322134" class="c"><input type="checkbox" id="c-36322134" checked=""/><div class="controls bullet"><span class="by">szopa</span><span>|</span><a href="#36316562">next</a><span>|</span><label class="collapse" for="c-36322134">[-]</label><label class="expand" for="c-36322134">[1 more]</label></div><br/><div class="children"><div class="content">Tokenizers seem to be a massive pain in the neck if you are just calling into an API to use your model. The algorithm itself is non-trivial, and they need pretty sizable data to function: the vocabulary and the merges, which just sit there, using memory. I&#x27;m writing <a href="https:&#x2F;&#x2F;github.com&#x2F;ryszard&#x2F;agency">https:&#x2F;&#x2F;github.com&#x2F;ryszard&#x2F;agency</a> in Go, and while there&#x27;s a good library for  the OpenAI tokenization, if you want a tokenizer for the HF models the best I found was a library calling HF&#x27;s Rust implementation, which makes it horrible for distribution.<p>However, at some point I realized that I needed not really the tokens, but the <i>token count</i>, as my most important use was implementing a Token Buffer Memory (trim messages from the beginning in such a way that you never exceed a context size number of tokens). And in order to do  that I don&#x27;t need it to be exactly right, just mostly right, if I am ok with slightly suboptimal efficiency (keeping slightly less tokens than the model supports). So, I took files from Project Gutenberg, and compared the ratio of tokens I get using a proper tokenizer and just calling `strings.Split`, and it seems to be remarkably stable for a given model and language (multiply the length of the result of splitting on spaces by 1.55 for OpenAI and 1.7 for Claude, which leaves a tiny safety margin).<p>I&#x27;m not throwing shade at this project – just being able to call the tokenizer would&#x27;ve saved me a lot of time. But I hope that if I&#x27;m wrong about the estimates bring good enough some good person will point out the error of my ways :)</div><br/></div></div><div id="36316562" class="c"><input type="checkbox" id="c-36316562" checked=""/><div class="controls bullet"><span class="by">belladoreai</span><span>|</span><a href="#36322134">prev</a><span>|</span><a href="#36322354">next</a><span>|</span><label class="collapse" for="c-36316562">[-]</label><label class="expand" for="c-36316562">[6 more]</label></div><br/><div class="children"><div class="content">Hi HN! I was looking for a tokenizer that would accurately(!) count tokens in browser, and I couldn&#x27;t find one. So I thought &quot;how hard can it be&quot;, and here we are 2 weeks later...</div><br/><div id="36319039" class="c"><input type="checkbox" id="c-36319039" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#36316562">parent</a><span>|</span><a href="#36317697">next</a><span>|</span><label class="collapse" for="c-36319039">[-]</label><label class="expand" for="c-36319039">[1 more]</label></div><br/><div class="children"><div class="content">Great repo, but there was this for openAI which was bit hard to find: <a href="https:&#x2F;&#x2F;github.com&#x2F;cogentapps&#x2F;chat-with-gpt&#x2F;blob&#x2F;main&#x2F;app&#x2F;src&#x2F;core&#x2F;tokenizer&#x2F;bpe.ts">https:&#x2F;&#x2F;github.com&#x2F;cogentapps&#x2F;chat-with-gpt&#x2F;blob&#x2F;main&#x2F;app&#x2F;sr...</a>.<p>Not completely sure, but I think it will likely work as it is for llama as both are BPE following same rules.</div><br/></div></div><div id="36317697" class="c"><input type="checkbox" id="c-36317697" checked=""/><div class="controls bullet"><span class="by">zerojames</span><span>|</span><a href="#36316562">parent</a><span>|</span><a href="#36319039">prev</a><span>|</span><a href="#36317722">next</a><span>|</span><label class="collapse" for="c-36317697">[-]</label><label class="expand" for="c-36317697">[1 more]</label></div><br/><div class="children"><div class="content">I love this sentiment! Amazing work!</div><br/></div></div><div id="36317722" class="c"><input type="checkbox" id="c-36317722" checked=""/><div class="controls bullet"><span class="by">Solvency</span><span>|</span><a href="#36316562">parent</a><span>|</span><a href="#36317697">prev</a><span>|</span><a href="#36322354">next</a><span>|</span><label class="collapse" for="c-36317722">[-]</label><label class="expand" for="c-36317722">[3 more]</label></div><br/><div class="children"><div class="content">For those who would also think the same thing, what&#x27;re some of the the tldr bulletpoints on why this is more complicated than it&#x27;d seem?</div><br/><div id="36317861" class="c"><input type="checkbox" id="c-36317861" checked=""/><div class="controls bullet"><span class="by">belladoreai</span><span>|</span><a href="#36316562">root</a><span>|</span><a href="#36317722">parent</a><span>|</span><a href="#36322354">next</a><span>|</span><label class="collapse" for="c-36317861">[-]</label><label class="expand" for="c-36317861">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll answer with an example.<p>Consider the input string &quot; grabbed&quot;.<p>If we wanted to map this string to tokens by greedily going from left to right and choosing tokens from the vocabulary with the strategy of minimizing the number of tokens, our algorithm would be very simple. We would end up with the following tokenization: [17229, 2580] == [&quot; grab&quot;, &quot;bed&quot;]<p>Surprisingly, the LLaMA tokenizer does not work this way. It actually finds a &quot;worse&quot; tokenization for this input string: [2646, 1327, 287] == [&quot; gra&quot;, &quot;bb&quot;, &quot;ed&quot;]<p>The tokenizer arrives at this 3 token output by applying &quot;merges&quot; in a priority order. For example, this is a merge: [&quot; g&quot;, &quot;r&quot;] -&gt; &quot; gr&quot;. The trained data contains tens of thousands of these merges. When we apply the merges in the priority order, we end up with 3 tokens.<p>Now you might be thinking, that&#x27;s easy, we&#x27;ll just iterate the list of merges and see if any of them apply. Only problem with that approach is that <i>applying a merge can open up a new opportunity to merge something else that wasn&#x27;t possible before</i>. This right here is the key thing that makes this problem complicated. We can solve this problem by iterating all possible merges from the beginning after every time we apply a merge. This would produce the correct solution. Only problem is: our algorithm is now very slow and takes minutes to run...</div><br/><div id="36319661" class="c"><input type="checkbox" id="c-36319661" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#36316562">root</a><span>|</span><a href="#36317861">parent</a><span>|</span><a href="#36322354">next</a><span>|</span><label class="collapse" for="c-36319661">[-]</label><label class="expand" for="c-36319661">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Only problem is: &#x2F;&#x2F;<p>As a non-programmer this suggests use of a trie? But could you very roughly sketch what you did, or at least give me a keyword or two to lookup? <i>Grazie mille</i>.</div><br/></div></div></div></div></div></div></div></div><div id="36322354" class="c"><input type="checkbox" id="c-36322354" checked=""/><div class="controls bullet"><span class="by">Hedepig</span><span>|</span><a href="#36316562">prev</a><span>|</span><a href="#36319675">next</a><span>|</span><label class="collapse" for="c-36322354">[-]</label><label class="expand" for="c-36322354">[2 more]</label></div><br/><div class="children"><div class="content">Somewhat tangimential, are there any open source attempts to compete with OpenAI&#x27;s embeddings?<p>I know Word2Vec is a thing but I believe that is on a word by word basis, and doesn&#x27;t capture the semantic meaning of whole sentences and paragraphs.<p>They charge so little for embeddings I secretly hope they do open source it. Because if for some reason it is stopped, any search functionality or the like that relies upon the API would cease to function</div><br/><div id="36322918" class="c"><input type="checkbox" id="c-36322918" checked=""/><div class="controls bullet"><span class="by">dhruv_anand</span><span>|</span><a href="#36322354">parent</a><span>|</span><a href="#36319675">next</a><span>|</span><label class="collapse" for="c-36322918">[-]</label><label class="expand" for="c-36322918">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36105660">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36105660</a><p>Models under sentence-transformers are commonly used by people.<p>You can check this leaderboard, where OpenAI&#x27;s embeddings are outperformed by open source ones: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard</a></div><br/></div></div></div></div><div id="36319675" class="c"><input type="checkbox" id="c-36319675" checked=""/><div class="controls bullet"><span class="by">superkuh</span><span>|</span><a href="#36322354">prev</a><span>|</span><a href="#36319042">next</a><span>|</span><label class="collapse" for="c-36319675">[-]</label><label class="expand" for="c-36319675">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been wondering how to use two spaces as a stop token with the llama models for months. Reading the source of this finally clued me in, &quot;__&quot;. Nice. This is significantly easier to comprehend than sentencepiece.</div><br/></div></div><div id="36319042" class="c"><input type="checkbox" id="c-36319042" checked=""/><div class="controls bullet"><span class="by">adroitboss</span><span>|</span><a href="#36319675">prev</a><span>|</span><label class="collapse" for="c-36319042">[-]</label><label class="expand" for="c-36319042">[5 more]</label></div><br/><div class="children"><div class="content">Does anyone know of a chatgpt&#x2F;gpt-4 tokenizer that can run client-side?</div><br/><div id="36322937" class="c"><input type="checkbox" id="c-36322937" checked=""/><div class="controls bullet"><span class="by">WilliamBerglund</span><span>|</span><a href="#36319042">parent</a><span>|</span><a href="#36319142">next</a><span>|</span><label class="collapse" for="c-36322937">[-]</label><label class="expand" for="c-36322937">[1 more]</label></div><br/><div class="children"><div class="content">Yes, tiktoken, here&#x27;s a client side visualizer for it<p><a href="https:&#x2F;&#x2F;github.com&#x2F;functorism&#x2F;gpt4-tokenizer-visualizer">https:&#x2F;&#x2F;github.com&#x2F;functorism&#x2F;gpt4-tokenizer-visualizer</a></div><br/></div></div><div id="36319142" class="c"><input type="checkbox" id="c-36319142" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36319042">parent</a><span>|</span><a href="#36322937">prev</a><span>|</span><a href="#36319096">next</a><span>|</span><label class="collapse" for="c-36319142">[-]</label><label class="expand" for="c-36319142">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer</a> or the official python library tiktoken <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken</a> or this JS port of tiktoken <a href="https:&#x2F;&#x2F;github.com&#x2F;dqbd&#x2F;tiktoken">https:&#x2F;&#x2F;github.com&#x2F;dqbd&#x2F;tiktoken</a></div><br/><div id="36321577" class="c"><input type="checkbox" id="c-36321577" checked=""/><div class="controls bullet"><span class="by">oofsa</span><span>|</span><a href="#36319042">root</a><span>|</span><a href="#36319142">parent</a><span>|</span><a href="#36319096">next</a><span>|</span><label class="collapse" for="c-36321577">[-]</label><label class="expand" for="c-36321577">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer</a> is not for GPT-4 but GPT-3. <a href="https:&#x2F;&#x2F;tiktokenizer.vercel.app&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;tiktokenizer.vercel.app&#x2F;</a> supports GPT-4.</div><br/></div></div></div></div><div id="36319096" class="c"><input type="checkbox" id="c-36319096" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#36319042">parent</a><span>|</span><a href="#36319142">prev</a><span>|</span><label class="collapse" for="c-36319096">[-]</label><label class="expand" for="c-36319096">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;cogentapps&#x2F;chat-with-gpt&#x2F;blob&#x2F;main&#x2F;app&#x2F;src&#x2F;core&#x2F;tokenizer&#x2F;bpe.ts">https:&#x2F;&#x2F;github.com&#x2F;cogentapps&#x2F;chat-with-gpt&#x2F;blob&#x2F;main&#x2F;app&#x2F;sr...</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>