<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734253257894" as="style"/><link rel="stylesheet" href="styles.css?v=1734253257894"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://libc.llvm.org/gpu/using.html">Using Libc for GPUs</a> <span class="domain">(<a href="https://libc.llvm.org">libc.llvm.org</a>)</span></div><div class="subtext"><span>hochmartinez</span> | <span>66 comments</span></div><br/><div><div id="42420255" class="c"><input type="checkbox" id="c-42420255" checked=""/><div class="controls bullet"><span class="by">jhuber6</span><span>|</span><a href="#42419681">next</a><span>|</span><label class="collapse" for="c-42420255">[-]</label><label class="expand" for="c-42420255">[1 more]</label></div><br/><div class="children"><div class="content">Very cool to see my project posted here!<p>The motivation behind a lot of this was to have community LLVM implementations of runtime functions normally provided by the vendor libraries (C math, printf, malloc), but if you implement one function you may as well implement them all.<p>Realistically, the infrastructure behind this project is more relevant than the C library calls themselves. The examples in the linked documentation can be used for any arbitrary C&#x2F;C++ just as well as the LLVM C library, it&#x27;s simply statically linking. This is what allowed me to compile and run more complicated things like libc++ and DOOM on the GPU as well. The RPC interface can also be used to implement custom host services from the GPU, or used to communicate between any two shared memory processes.</div><br/></div></div><div id="42419681" class="c"><input type="checkbox" id="c-42419681" checked=""/><div class="controls bullet"><span class="by">fuhsnn</span><span>|</span><a href="#42420255">prev</a><span>|</span><a href="#42420432">next</a><span>|</span><label class="collapse" for="c-42419681">[-]</label><label class="expand" for="c-42419681">[5 more]</label></div><br/><div class="children"><div class="content">I wonder how GPU is going to access an unknown size NULL terminated string in system RAM, the strchr() source looks like normal C++. In my minimal Vulkan GPGPU experience the data need to be bound to VkDeviceMemory to be accessible through PCI bus with compute shader, is LLVM libc runtime doing similar set-ups in the background, and if so, is it faster than glibc&#x27;s hand-tuned AVX implementation?</div><br/><div id="42419958" class="c"><input type="checkbox" id="c-42419958" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42419681">parent</a><span>|</span><a href="#42420432">next</a><span>|</span><label class="collapse" for="c-42419958">[-]</label><label class="expand" for="c-42419958">[4 more]</label></div><br/><div class="children"><div class="content">This is libc running on the GPU, not a libc spanning CPU and GPU. The primary obstruction to doing that is persuading people to let go of glibc. The spec of &quot;host runs antique glibc, GPU runs some other thing that interops transparently with glibc&quot; is a nightmare of hacks and tragedy.<p>What would be relatively easy to put together is llvm libc running on the host x64 and also llvm libc running on the GPU. There&#x27;s then the option to do things like malloc() on the GPU and free() the same pointer on the CPU. Making it genuinely seamless also involves persuading people to change what function pointers are, do some work on the ABI, and preferably move to APUs because PCIe is unhelpful.<p>There&#x27;s an uphill battle to bring people along on the journey of &quot;program the things differently&quot;. For example, here&#x27;s a thread trying to drum up enthusiasm for making function pointers into integers as that makes passing them between heterogenous architectures far easier <a href="https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;rfc-function-pointers-as-integers-beyond-wasm&#x2F;83208&#x2F;7" rel="nofollow">https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;rfc-function-pointers-as-intege...</a>.</div><br/><div id="42420318" class="c"><input type="checkbox" id="c-42420318" checked=""/><div class="controls bullet"><span class="by">fuhsnn</span><span>|</span><a href="#42419681">root</a><span>|</span><a href="#42419958">parent</a><span>|</span><a href="#42420346">next</a><span>|</span><label class="collapse" for="c-42420318">[-]</label><label class="expand" for="c-42420318">[2 more]</label></div><br/><div class="children"><div class="content">&gt;making function pointers into integers as that makes passing them between heterogenous architectures<p>This is interesting, though function pointers are long expected to be address on binary, C-brained people like me would probably adapt to the concept of &quot;pointer to a heterogeneous lambda object&quot; or &quot;shared id across heterogeneous runtimes&quot; easier.</div><br/><div id="42420602" class="c"><input type="checkbox" id="c-42420602" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42419681">root</a><span>|</span><a href="#42420318">parent</a><span>|</span><a href="#42420346">next</a><span>|</span><label class="collapse" for="c-42420602">[-]</label><label class="expand" for="c-42420602">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I might need to take another angle at the branding &#x2F; sales part, possibly with a prototype in hand.<p>I was hopeful that wasm was sufficient prior art. Whether function pointers are absolute addresses, or relative to the start of text, or resolved through trampolines filled in by the loader, or are offsets into some table is all (nominally) invisible to the language.<p>Integer in [0, k) has the nice feature that multiple GPUs can each index into their own lookup table containing pointers to the local code section. Or for calling into another machine - it&#x27;s essentially a cheap serialisation &#x2F; perfect hash done at linker time. It makes indirect calls slower, but indirect calls are slow anyway so hopefully saleable.</div><br/></div></div></div></div><div id="42420346" class="c"><input type="checkbox" id="c-42420346" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#42419681">root</a><span>|</span><a href="#42419958">parent</a><span>|</span><a href="#42420318">prev</a><span>|</span><a href="#42420432">next</a><span>|</span><label class="collapse" for="c-42420346">[-]</label><label class="expand" for="c-42420346">[1 more]</label></div><br/><div class="children"><div class="content">If the host has an antique glibc, surely it has an antique llvm libc? Does llvm just have a more stable ABI or something?</div><br/></div></div></div></div></div></div><div id="42420432" class="c"><input type="checkbox" id="c-42420432" checked=""/><div class="controls bullet"><span class="by">selimnairb</span><span>|</span><a href="#42419681">prev</a><span>|</span><a href="#42419954">next</a><span>|</span><label class="collapse" for="c-42420432">[-]</label><label class="expand" for="c-42420432">[5 more]</label></div><br/><div class="children"><div class="content">It seems like unified memory has to be the goal. This all just feels like a kludgy workaround until that happens (kind of like segmented memory in the 16-bit era).</div><br/><div id="42420525" class="c"><input type="checkbox" id="c-42420525" checked=""/><div class="controls bullet"><span class="by">LorenDB</span><span>|</span><a href="#42420432">parent</a><span>|</span><a href="#42421133">next</a><span>|</span><label class="collapse" for="c-42420525">[-]</label><label class="expand" for="c-42420525">[2 more]</label></div><br/><div class="children"><div class="content">Is unified memory practical for a &quot;normal&quot; desktop&#x2F;server configuration though? Apple has been doing unified memory, but they also have the GPU on the CPU die. I would be interested to know if a discrete GPU plugged into a PCIe slot would have enough latency to make unified memory impractical.</div><br/><div id="42420574" class="c"><input type="checkbox" id="c-42420574" checked=""/><div class="controls bullet"><span class="by">selimnairb</span><span>|</span><a href="#42420432">root</a><span>|</span><a href="#42420525">parent</a><span>|</span><a href="#42421133">next</a><span>|</span><label class="collapse" for="c-42420574">[-]</label><label class="expand" for="c-42420574">[1 more]</label></div><br/><div class="children"><div class="content">It’s clearly not practical now, but that doesn’t mean it won’t be at some point.</div><br/></div></div></div></div><div id="42421133" class="c"><input type="checkbox" id="c-42421133" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42420432">parent</a><span>|</span><a href="#42420525">prev</a><span>|</span><a href="#42419954">next</a><span>|</span><label class="collapse" for="c-42421133">[-]</label><label class="expand" for="c-42421133">[2 more]</label></div><br/><div class="children"><div class="content">Why is RBAR insufficient?  It&#x27;s been pretty much supported for at least 5 years now.</div><br/><div id="42422386" class="c"><input type="checkbox" id="c-42422386" checked=""/><div class="controls bullet"><span class="by">gavinsyancey</span><span>|</span><a href="#42420432">root</a><span>|</span><a href="#42421133">parent</a><span>|</span><a href="#42419954">next</a><span>|</span><label class="collapse" for="c-42422386">[-]</label><label class="expand" for="c-42422386">[1 more]</label></div><br/><div class="children"><div class="content">GPUs benefit from extremely high memory bandwidth. RBAR helps, but it&#x27;s a lot worse than a fat bus to a bunch of on-card GDDR6X.<p>A PCIe 4.0x16 link gives 32 GB&#x2F;s bandwidth; an RTX 4090 has over 1 TB&#x2F;s bandwidth to its on-card memory.</div><br/></div></div></div></div></div></div><div id="42419954" class="c"><input type="checkbox" id="c-42419954" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42420432">prev</a><span>|</span><a href="#42418654">next</a><span>|</span><label class="collapse" for="c-42419954">[-]</label><label class="expand" for="c-42419954">[3 more]</label></div><br/><div class="children"><div class="content">I am pretty sure this is just a gimmick. I would not call libc code in a GPU kernel. It would mean dragging in a whole bunch of stuff I don&#x27;t want, and cant control or pick-and-choose. That makes sense for regular processes on the CPU; it does _not_ make sense in code you run millions of times in GPU threads.<p>I see people saying they&#x27;ve &quot;dreamed&quot; of this or have waited so long for this to happen... well, my friends, you should not have; and I&#x27;m afraid you&#x27;re in for a disappointment.</div><br/><div id="42420013" class="c"><input type="checkbox" id="c-42420013" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42419954">parent</a><span>|</span><a href="#42418654">next</a><span>|</span><label class="collapse" for="c-42420013">[-]</label><label class="expand" for="c-42420013">[2 more]</label></div><br/><div class="children"><div class="content">It uses a few mb of contiguous shared memory and periodically calling a function from a host thread. Unless you only want sprintf or similar in which case neither is needed. The unused code deadstrips pretty well. Won&#x27;t help compilation time. Generally you don&#x27;t want libc calls in numerical kernels doing useful stuff - the most common request was for printf as a debugging crutch, I mostly wanted mmap.</div><br/><div id="42420678" class="c"><input type="checkbox" id="c-42420678" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42419954">root</a><span>|</span><a href="#42420013">parent</a><span>|</span><a href="#42418654">next</a><span>|</span><label class="collapse" for="c-42420678">[-]</label><label class="expand" for="c-42420678">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It uses a few mb of contiguous shared memory and periodically calling a function from a host thread.<p>Well, if someone wants to shoot themselves in the head, then by all means...<p>&gt; Unless you only want sprintf or similar in which case neither is needed.
&gt; ... Generally you don&#x27;t want libc calls in numerical kernels doing useful
&gt; stuff - the most common request was for printf as a debugging crutch<p>I have actually adapted a library for that particular case:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;printf&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;printf&#x2F;</a><p>I started with a standalone printf-family implementation targetting embedded devices, and (among other things) adapted it for use also with CUDA.<p>&gt;  I mostly wanted mmap.<p>Does it really make sense to make a gazillion mmap calls from the threads of your GPU kernel? I mean, is it really not always better to mmap on the CPU side? At most, I might do it asynchronously using a CUDA callback or some other mechanism. But I will admit I&#x27;ve not had that use-case.</div><br/></div></div></div></div></div></div><div id="42418654" class="c"><input type="checkbox" id="c-42418654" checked=""/><div class="controls bullet"><span class="by">kelsey98765431</span><span>|</span><a href="#42419954">prev</a><span>|</span><a href="#42418590">next</a><span>|</span><label class="collapse" for="c-42418654">[-]</label><label class="expand" for="c-42418654">[42 more]</label></div><br/><div class="children"><div class="content">Running normal c directly on gpu has been the dream for a long time. this looks excellent</div><br/><div id="42418835" class="c"><input type="checkbox" id="c-42418835" checked=""/><div class="controls bullet"><span class="by">C-programmer</span><span>|</span><a href="#42418654">parent</a><span>|</span><a href="#42419090">next</a><span>|</span><label class="collapse" for="c-42418835">[-]</label><label class="expand" for="c-42418835">[35 more]</label></div><br/><div class="children"><div class="content">Genuinely, why?<p>- For new code, all of the functions [here](<a href="https:&#x2F;&#x2F;libc.llvm.org&#x2F;gpu&#x2F;support.html#libc-gpu-support" rel="nofollow">https:&#x2F;&#x2F;libc.llvm.org&#x2F;gpu&#x2F;support.html#libc-gpu-support</a>) you can do without just fine.<p>- For old code:<p><pre><code>  * Your project is large enough that you are likely use using an unsupported libc function somewhere.

  * Your project is small enough that you would benefit from just implementing a new kernel yourself.
</code></pre>
I am biased because I avoid the C standard library even on the CPU, but this seems like a technology that raises the floor not the ceiling of what is possible.</div><br/><div id="42419733" class="c"><input type="checkbox" id="c-42419733" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418835">parent</a><span>|</span><a href="#42419403">next</a><span>|</span><label class="collapse" for="c-42419733">[-]</label><label class="expand" for="c-42419733">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Genuinely, why?<p>&gt; ... this seems like a technology that raises the floor not the ceiling of what is possible.<p>The root cause reason for this project existing is to show that GPU programming is not synonymous with CUDA (or the other offloading languages).<p>It&#x27;s nominally to help people run existing code on GPUs. Disregarding that use case, it shows that GPUs can actually do things like fprintf or open sockets. This is obvious to the implementation but seems largely missed by application developers. Lots of people think GPUs can only do floating point math.<p>Especially on an APU, where the GPU units and the CPU cores can hammer on the same memory, it is a travesty to persist with the &quot;offloading to accelerator&quot; model. Raw C++ isn&#x27;t an especially sensible language to program GPUs in but it&#x27;s workable and I think it&#x27;s better than CUDA.</div><br/><div id="42419806" class="c"><input type="checkbox" id="c-42419806" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419733">parent</a><span>|</span><a href="#42419772">next</a><span>|</span><label class="collapse" for="c-42419806">[-]</label><label class="expand" for="c-42419806">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Disregarding that use case, it shows that GPUs can actually do things like fprintf or open sockets.<p>Can you elaborate on this? My mental model of GPU is basically like a huge vector coprocessor. How would things like printf or sockets work directly from the GPU when they require syscalls to trap into the OS kernel? Given that the kernel code is running on the CPU, that seems to imply that there needs to be a handover at some point. Or conversely even if there was unified memory and the GPU could directly address memory-mapped peripherals, you&#x27;d basically need to reimplement drivers wouldn&#x27;t you?</div><br/><div id="42420113" class="c"><input type="checkbox" id="c-42420113" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419806">parent</a><span>|</span><a href="#42419772">next</a><span>|</span><label class="collapse" for="c-42420113">[-]</label><label class="expand" for="c-42420113">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s mostly terminology and conventions. On the standard system setup, the linux kernel running in a special processor mode does these things. Linux userspace asks the kernel to do stuff using syscall and memory which both kernel and userspace can access. E.g. the io_uring register followed by writing packets into the memory.<p>What the GPU has is read&#x2F;write access to memory that the CPU can also access. And network peripherals etc. You can do things like alternately compare-and-swap on the same page from x64 threads and amdgpu kernels and it works, possibly not quickly on some systems. That&#x27;s also all that the x64 CPU threads have though, modulo the magic syscall instruction to ask the kernel to do stuff.<p>People sometimes get quite cross at my claim that the GPU can do fprintf. Cos <i>actually</i> all it can do is write numbers into shared memory or raise interrupts such that the effect of fprintf is observed. But that&#x27;s also all the userspace x64 threads do, and this is all libc anyway, so I don&#x27;t see what people are so cross about. You&#x27;re writing C, you call `fprintf(stderr, &quot;Got to L42\n&quot;);` or whatever, and you see the message on the console.<p>If fprintf compiles into a load of varargs mangling with a fwrite underneath, and the varargs stuff runs on the GPU silicon and the fwrite goes through a staging buffer before some kernel thread deals with it, that seems fine.<p>I&#x27;m pretty sure you could write to an nvme drive directly from the gpu, no talking to the host kernel at all, at which point you&#x27;ve arguably implemented (part of?) a driver for it. You can definitely write to network cards from them, without using any of this machinery.</div><br/></div></div></div></div><div id="42419772" class="c"><input type="checkbox" id="c-42419772" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419733">parent</a><span>|</span><a href="#42419806">prev</a><span>|</span><a href="#42420009">next</a><span>|</span><label class="collapse" for="c-42419772">[-]</label><label class="expand" for="c-42419772">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Lots of people think GPUs can only do floating point math.<p>IIRC, every Raspberry Pi is brought up by the GPU setting up the system before the CPU is brought out of reset and the bootloader looks for the OS.<p>&gt; it is a travesty to persist with the &quot;offloading to accelerator&quot; model.<p>Operating systems would need to support heterogeneous processors running programs with different ISAs accessing the same pools of memory. I&#x27;d <i>LOVE</i> to see that. It&#x27;d be extremely convenient to have first-class processes running on the GPU MIMD cores.<p>I&#x27;m not sure there is much research done in that space. I believe IBM mainframe OSs have something like that because programmers are exposed to the various hardware assists that run as coprocessors sharing the main memory with the OS and applications.</div><br/><div id="42419952" class="c"><input type="checkbox" id="c-42419952" checked=""/><div class="controls bullet"><span class="by">als0</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419772">parent</a><span>|</span><a href="#42420009">next</a><span>|</span><label class="collapse" for="c-42419952">[-]</label><label class="expand" for="c-42419952">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure there is much research done in that space.<p>There is. And the finest example I can think of is Barrelfish <a href="https:&#x2F;&#x2F;barrelfish.org" rel="nofollow">https:&#x2F;&#x2F;barrelfish.org</a></div><br/><div id="42420301" class="c"><input type="checkbox" id="c-42420301" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419952">parent</a><span>|</span><a href="#42420009">next</a><span>|</span><label class="collapse" for="c-42420301">[-]</label><label class="expand" for="c-42420301">[1 more]</label></div><br/><div class="children"><div class="content">Interesting - it resembles a network of heterogeneous systems that can share a memory space used primarily for explicit data exchange. Not quite what I was imagining, but probably much simpler to implement than a Unix where the kernel can see processes running on different ISAs on a shared memory space.<p>I guess hardware availability is an issue, as there aren&#x27;t many computers with, say, an ARM, a RISC-V, an x86, and an AMD iGPU sharing a common memory pool.<p>OTOH, there are many where a 32-bit ARM shares the memory pool with 64-bit cores. Usually the big cores run applications while the small ARM does housekeeping or other low-latency task.</div><br/></div></div></div></div></div></div><div id="42420009" class="c"><input type="checkbox" id="c-42420009" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419733">parent</a><span>|</span><a href="#42419772">prev</a><span>|</span><a href="#42419403">next</a><span>|</span><label class="collapse" for="c-42420009">[-]</label><label class="expand" for="c-42420009">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The root cause reason for this project existing is to show that GPU
&gt; programming is not synonymous with CUDA (or the other offloading 
&gt; languages).<p>1. The ability to use a particular library does not reflect much on which languages can be used.<p>2. One you have PTX as a backend target for a compiler, obviously you can use all sorts of languages on the frontend - which NVIDIA&#x27;s drivers and libraries won&#x27;t even know about. Or you can just use PTX as your language - making your point that GPU programming is not synonymous with CUDA C++.<p>&gt; It&#x27;s nominally to help people run existing code on GPUs.<p>I&#x27;m worried you might be right. But - we should really not encourage people to run existing CPU-side code on GPUs, that&#x27;s rarely (or maybe never?) a good idea.<p>&gt; Raw C++ isn&#x27;t an especially sensible language to program GPUs in 
&gt; but it&#x27;s workable and I think it&#x27;s better than CUDA.<p>CUDA is an execution ecosystem. The programming language for writing kernel code is &quot;CUDA C++&quot;, which _is_ C++, plus a few builtins functions ... or maybe I&#x27;m misunderstanding this sentence.</div><br/><div id="42420194" class="c"><input type="checkbox" id="c-42420194" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42420009">parent</a><span>|</span><a href="#42419403">next</a><span>|</span><label class="collapse" for="c-42420194">[-]</label><label class="expand" for="c-42420194">[2 more]</label></div><br/><div class="children"><div class="content">GPU offloading languages - cuda, openmp etc - work something like:<p>1. Split the single source into host parts and gpu parts<p>2. Optionally mark up some parts as &quot;kernels&quot;, i.e. have entry points<p>3. Compile them separately, maybe for many architectures<p>4. Emit a bunch of metadata for how they&#x27;re related<p>5. Embed the GPU code in marked up sections of the host executable<p>6. Embed some startup code to find GPUs into the x64 parts<p>7. At runtime, go crawling around the elf section launching kernels<p>This particular library (which happens to be libc) is written in C++, compiled with ffreestanding target=amdgpu, to LLVM bitcode. If you build a test, it compiles to an amdgpu elf file - no x64 code in it, no special metadata, no elf-in-elf structure. The entry point is called _start. There&#x27;s a small &quot;loader&quot; program which initialises hsa (or cuda) and passes it the address of _start.<p>I&#x27;m not convinced by the clever convenience cut-up-and-paste-together style embraced by cuda or openmp. This approach brings the lack of magic to the forefront. It also means we can add it to openmp etc when the reviews go through so users of that suddenly find fopen works.</div><br/><div id="42420644" class="c"><input type="checkbox" id="c-42420644" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42420194">parent</a><span>|</span><a href="#42419403">next</a><span>|</span><label class="collapse" for="c-42420644">[-]</label><label class="expand" for="c-42420644">[1 more]</label></div><br/><div class="children"><div class="content">CUDA C++ _can_ work like that. But I would say that these are mostly kiddie wheels for convenience. And because, in GPU programming, performance is king, most (?) kernel developers are likely to eventually need to drop those wheels. And then:<p>* No single source (although some headers might be shared)<p>* Kernels are compiled and linked at runtime, for the platform you&#x27;re on, but also, in the general case, with extra definitions not known apriori (and which are different for different inputs &#x2F; over the course of running your program), and which have massive effect on the code.<p>* You may or may not use some kind of compiled kernel caching mechanism, but you certainly don&#x27;t have all possible combinations of targets and definitions available, since that would be millions or compiled kernels.<p>It should also be mentioned that OpenCL never included the kiddie wheels to begin with; although I have to admit it makes it less convenient to start working with.</div><br/></div></div></div></div></div></div></div></div><div id="42419403" class="c"><input type="checkbox" id="c-42419403" checked=""/><div class="controls bullet"><span class="by">nickysielicki</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418835">parent</a><span>|</span><a href="#42419733">prev</a><span>|</span><a href="#42418953">next</a><span>|</span><label class="collapse" for="c-42419403">[-]</label><label class="expand" for="c-42419403">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;simplifying-gpu-application-development-with-heterogeneous-memory-management&#x2F;#unified_memory_after_hmm" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;simplifying-gpu-applicatio...</a></div><br/></div></div><div id="42418953" class="c"><input type="checkbox" id="c-42418953" checked=""/><div class="controls bullet"><span class="by">tredre3</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418835">parent</a><span>|</span><a href="#42419403">prev</a><span>|</span><a href="#42419171">next</a><span>|</span><label class="collapse" for="c-42418953">[-]</label><label class="expand" for="c-42418953">[4 more]</label></div><br/><div class="children"><div class="content">&gt; this seems like a technology that raises the floor not the ceiling of what is possible.<p>In your view, how is making GPU programming easier a bad thing?</div><br/><div id="42418999" class="c"><input type="checkbox" id="c-42418999" checked=""/><div class="controls bullet"><span class="by">convolvatron</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418953">parent</a><span>|</span><a href="#42419171">next</a><span>|</span><label class="collapse" for="c-42418999">[-]</label><label class="expand" for="c-42418999">[3 more]</label></div><br/><div class="children"><div class="content">that&#x27;s clearly not a bad thing. however encouraging people to run mutating, procedural code with explicit loops and aliasing maybe isn&#x27;t the right path to get there. particularly if you just drag forward all the weird old baggage with libc and its horrible string conventions.<p>I think any programming environment that treats a gpu as a really slow serial cpu isn&#x27;t really what you want(?)</div><br/><div id="42419400" class="c"><input type="checkbox" id="c-42419400" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418999">parent</a><span>|</span><a href="#42419171">next</a><span>|</span><label class="collapse" for="c-42419400">[-]</label><label class="expand" for="c-42419400">[2 more]</label></div><br/><div class="children"><div class="content">What if it encourages people to write parallel and functional code on CPUs? That&#x27;d be a good thing. Influence works both ways.<p>The bigger problem is that GPUs have various platform features (shared memory, explicit cache residency and invalidation management) that CPUs sadly don&#x27;t yet. Sure, you <i>could</i> expose these facilities via compiler intrinsics, but then you end up code that might be syntactically valid C but is alien both to CPUs and human minds</div><br/></div></div></div></div></div></div><div id="42419171" class="c"><input type="checkbox" id="c-42419171" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42418835">parent</a><span>|</span><a href="#42418953">prev</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419171">[-]</label><label class="expand" for="c-42419171">[19 more]</label></div><br/><div class="children"><div class="content">One thing this gives you is syscall on the gpu. Functions like sprintf are just blobs of userspace code, but others like fopen require support from the operating system (or whatever else the hardware needs you to do). That plumbing was decently annoying to write for the gpu.<p>These aren&#x27;t gpu kernels. They&#x27;re functions to call from kernels.</div><br/><div id="42419278" class="c"><input type="checkbox" id="c-42419278" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419171">parent</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419278">[-]</label><label class="expand" for="c-42419278">[18 more]</label></div><br/><div class="children"><div class="content">&gt; One thing this gives you is syscall on the gpu<p>i wish people in our industry would stop (forever, completely, absolutely) using metaphors&#x2F;allusions. it&#x27;s a complete disservice to anyone that isn&#x27;t in on the trick. it doesn&#x27;t give you syscalls. that&#x27;s impossible because there&#x27;s no sys&#x2F;os on a gpu and your actual os does not (necessarily) have any way to peer into the address space&#x2F;schedular&#x2F;etc of a gpu core.<p>what it gives you is something that&#x27;s working really really hard to pretend be a syscall:<p>&gt; Traditionally, the C library abstracts over several functions that interface with the platform’s operating system through system calls. The GPU however does not provide an operating system that can handle target dependent operations. Instead, we implemented remote procedure calls to interface with the host’s operating system while executing on a GPU.<p><a href="https:&#x2F;&#x2F;libc.llvm.org&#x2F;gpu&#x2F;rpc.html" rel="nofollow">https:&#x2F;&#x2F;libc.llvm.org&#x2F;gpu&#x2F;rpc.html</a>.</div><br/><div id="42419470" class="c"><input type="checkbox" id="c-42419470" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419278">parent</a><span>|</span><a href="#42419369">next</a><span>|</span><label class="collapse" for="c-42419470">[-]</label><label class="expand" for="c-42419470">[8 more]</label></div><br/><div class="children"><div class="content">Well, I called it syscall because it&#x27;s a void function of 8 u64 arguments which your code stumbles into, gets suspended, then restored with new values for those integers. That it&#x27;s a function instead of an instruction doesn&#x27;t change the semantics. My favourite of the uses of that is to pass six of those integers to the x64 syscall operation.<p>This isn&#x27;t misnaming. It&#x27;s a branch into a trampoline that messes about with shared memory to give the effect of the x64 syscall you wanted, or some other thing that you&#x27;d rather do on the cpu.<p>There&#x27;s a gpu thing called trap which is closer in behaviour to what you&#x27;re thinking of but it&#x27;s really annoying to work with.<p>Side note, RPC has a terrible rep for introducing failure modes into APIs, but that&#x27;s completely missing here because pcie either works or your machine is gonna have to reboot. There are no errors on the interface that can be handled by the application.</div><br/><div id="42419687" class="c"><input type="checkbox" id="c-42419687" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419470">parent</a><span>|</span><a href="#42419738">next</a><span>|</span><label class="collapse" for="c-42419687">[-]</label><label class="expand" for="c-42419687">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Well, I called it syscall because it&#x27;s a void function of 8 u64 arguments which your code stumbles into, gets suspended, then restored with new values for those integers<p>I&#x27;m put it really simply: is there a difference (in perf, semantics, whatever) between using this &quot;syscalls&quot; to implement fopen on GPU and using a syscall to implement fopen on CPU? Note that&#x27;s a rhetorical question because we both already know that the answer is yes. So again you&#x27;re just playing slight of hand in calling them syscalls and I&#x27;ll emphasize: this is a slight of hand that the dev himself doesn&#x27;t play (so why would I take your word over his).</div><br/><div id="42419858" class="c"><input type="checkbox" id="c-42419858" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419687">parent</a><span>|</span><a href="#42419980">next</a><span>|</span><label class="collapse" for="c-42419858">[-]</label><label class="expand" for="c-42419858">[4 more]</label></div><br/><div class="children"><div class="content">Wonderfully you don&#x27;t need to trust my words, you&#x27;ve got my code :)<p>If semantics are different, that&#x27;s a bug&#x2F;todo. It&#x27;ll have worse latency than a CPU thread making the same kernel request. Throughput shouldn&#x27;t be way off. The GPU writes some integers to memory that the CPU will need to read, and then write other integers, and then load those again. Plus whatever the x64 syscall itself does. That&#x27;s a bunch of cache line invalidation and reads. It&#x27;s not as fast as if the hardware guys were on board with the strategy but I&#x27;m optimistic it can be useful today and thus help justify changing the hardware&#x2F;driver stack.<p>The whole point of libc is to paper over the syscall interface. If you start from musl, &quot;syscall&quot; can be a table of function pointers or asm. Glibc is more obstructive. This libc open codes a bunch of things, with a rpc.h file dealing with synchronising memcpy of arguments to&#x2F;from threads running on the CPU which get to call into the Linux kernel directly. It&#x27;s mainly carefully placed atomic operations to keep the data accesses well defined.<p>There&#x27;s also nothing in here which random GPU devs can&#x27;t build themselves. The header files are (now) self contained if people would like to use the same mechanism for other functionality and don&#x27;t want to handroll the data structure. The most subtle part is getting this to work correctly under arbitrary warp divergence on volta. It should be an out of the box thing under openmp early next year too.</div><br/><div id="42420323" class="c"><input type="checkbox" id="c-42420323" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419858">parent</a><span>|</span><a href="#42419980">next</a><span>|</span><label class="collapse" for="c-42420323">[-]</label><label class="expand" for="c-42420323">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Wonderfully you don&#x27;t need to trust my words, you&#x27;ve got my code :)<p>My friend it&#x27;s so incredibly bold of you to claim credit for this work when<p>1. Joe presented it<p>2. Joe&#x27;s name is the only name on the git blame<p>3. <i>I know Joe</i> and <i>I know</i> he did the lion&#x27;s share of the work<p>And so I&#x27;ll repeat: Joe himself calls it rpc so I&#x27;m gonna keep calling it rpc and not syscall.</div><br/><div id="42420414" class="c"><input type="checkbox" id="c-42420414" checked=""/><div class="controls bullet"><span class="by">jhuber6</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42420323">parent</a><span>|</span><a href="#42420536">next</a><span>|</span><label class="collapse" for="c-42420414">[-]</label><label class="expand" for="c-42420414">[1 more]</label></div><br/><div class="children"><div class="content">The RPC implementation in LLVM is an adaptation of Jon&#x27;s original state machine (see <a href="https:&#x2F;&#x2F;github.com&#x2F;JonChesterfield&#x2F;hostrpc">https:&#x2F;&#x2F;github.com&#x2F;JonChesterfield&#x2F;hostrpc</a>). It looks very different at this point, but we collaborated on the initial design before I fleshed out everything else. Syscall or not is a bit of a semantic argument, but I lean more towards syscall &#x27;inspired&#x27;.</div><br/></div></div><div id="42420536" class="c"><input type="checkbox" id="c-42420536" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42420323">parent</a><span>|</span><a href="#42420414">prev</a><span>|</span><a href="#42419980">next</a><span>|</span><label class="collapse" for="c-42420536">[-]</label><label class="expand" for="c-42420536">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the algorithm <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3458744.3473357" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3458744.3473357</a>. My paper with Joseph on the implementation is at <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1007&#x2F;978-3-031-40744-4_15" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1007&#x2F;978-3-031-40744-4_15</a>.<p>The syscall layer this runs on was written at <a href="https:&#x2F;&#x2F;github.com&#x2F;JonChesterfield&#x2F;hostrpc">https:&#x2F;&#x2F;github.com&#x2F;JonChesterfield&#x2F;hostrpc</a>, 800 commits from May 2020 until Jan 2023. I deliberately wrote that in the open, false paths and mistakes and all. Took ages for a variety of reasons, not least that this was my side project.<p>You&#x27;ll find the upstream of that scattered across the commits to libc, mostly authored by Joseph (log shows 300 for him, of which I reviewed 40, and 25 for me). You won&#x27;t find the phone calls and offline design discussions. You can find the tricky volta solution at <a href="https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D159276" rel="nofollow">https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D159276</a> and the initial patch to llvm at <a href="https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D145913" rel="nofollow">https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D145913</a>.<p>GPU libc is definitely Joseph&#x27;s baby, not mine, and this wouldn&#x27;t be in trunk if he hadn&#x27;t stubbornly fought through the headwinds to get it there. I&#x27;m excited to see it generating some discussion on here.<p>But yeah, I&#x27;d say the syscall implementation we&#x27;re discussing here has my name adequately written on it to describe it as &quot;my code&quot;.</div><br/></div></div></div></div></div></div><div id="42419980" class="c"><input type="checkbox" id="c-42419980" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419687">parent</a><span>|</span><a href="#42419858">prev</a><span>|</span><a href="#42419738">next</a><span>|</span><label class="collapse" for="c-42419980">[-]</label><label class="expand" for="c-42419980">[1 more]</label></div><br/><div class="children"><div class="content">Why does a perf difference factor into it? There is no requirement for a syscall to be this fast or else it isn&#x27;t a syscall. If you have a hot loop you shouldn&#x27;t be putting a syscall in it, not even on the CPU.</div><br/></div></div></div></div></div></div><div id="42419369" class="c"><input type="checkbox" id="c-42419369" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419278">parent</a><span>|</span><a href="#42419470">prev</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419369">[-]</label><label class="expand" for="c-42419369">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a matter of perspective. If you think of the GPU as a separate computer, you&#x27;re right. If you think of it as a coprocessor, then the use of RPC is just an implementation detail of the system call mechanism, not a semantically different thing.<p>When an old school 486SX delegates a floating point instruction to a physically separate 487DX coprocessor, is it executing an instruction or doing an RPC? If RPC, does the same instruction start being a real instruction when you replace your 486SX with a 486DX, with an integrated GPU? The program can&#x27;t tell the difference!</div><br/><div id="42419424" class="c"><input type="checkbox" id="c-42419424" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419369">parent</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419424">[-]</label><label class="expand" for="c-42419424">[8 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a matter of perspective. If you think of the GPU as a separate computer, you&#x27;re right.<p>this perspective is a function of exactly one thing: do you care about the performance of your program? if not then sure indulge in whatever abstract perspective you want (&quot;it&#x27;s magic, i just press buttons and the lights blink&quot;). but if you don&#x27;t care about perf then why are you using a GPU at all...? so for people that aren&#x27;t just randomly running code on a GPU (for shits and giggles), the distinction is very significant between &quot;syscall&quot; and syscall.<p>people who say these things don&#x27;t program GPUs for a living. there are no abstractions unless you don&#x27;t care about your program&#x27;s performance (in which case why are you using a GPU at all).</div><br/><div id="42419569" class="c"><input type="checkbox" id="c-42419569" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419424">parent</a><span>|</span><a href="#42419456">next</a><span>|</span><label class="collapse" for="c-42419569">[-]</label><label class="expand" for="c-42419569">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;proper syscall&quot; isn&#x27;t a fast thing either. The context switch blows out your caches. Part of why I like the name syscall is it&#x27;s an indication to not put it on the fast path.<p>The implementation behind this puts a lot of emphasis on performance, though the protocol was heavilt simplfied in upstreaming. Running on pcie instead of the APU systems makes things rather laggy too. Design is roughly a mashup of io_uring and occam, made much more annoying by the GPU scheduler constraints.<p>The two authors of this thing probably count as people who program GPUs for a living for what it&#x27;s worth.</div><br/></div></div><div id="42419456" class="c"><input type="checkbox" id="c-42419456" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419424">parent</a><span>|</span><a href="#42419569">prev</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419456">[-]</label><label class="expand" for="c-42419456">[6 more]</label></div><br/><div class="children"><div class="content">Not everything in every program is performance critical. A pattern I&#x27;ve noticed repeatedly among CUDAheads is the idea that &quot;every cycle matters&quot; and therefore we should uglify and optimize even cold parts of our CUDA programs. That&#x27;s as much BS on GPU as it is on CPU. In CPU land, we moved past this sophomoric attitude decades ago. The GPU world might catch up one day.<p>Are you planning on putting fopen() in an inner loop or something? LOL</div><br/><div id="42419636" class="c"><input type="checkbox" id="c-42419636" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419456">parent</a><span>|</span><a href="#42419546">next</a><span>|</span><label class="collapse" for="c-42419636">[-]</label><label class="expand" for="c-42419636">[1 more]</label></div><br/><div class="children"><div class="content">The whole reason CUDA&#x2F;GPUs are fast is that they explicitly don’t match the architecture of CPUs. The truly sophomoric attitude is that all compute devices should work like CPUs. The point of CUDA&#x2F;GPUs is to provide a different set of abstractions than CPUs that enable much higher performance for certain problems. Forcing your GPU to execute CPU-like code is a bad abstraction.<p>Your comment about putting fopen in an inner loop really betrays that. Every thread in your GPU kernel is going to have to wait for your libc call. You’re really confused if you’re talking about hot loops in a GPU kernel.</div><br/></div></div><div id="42419546" class="c"><input type="checkbox" id="c-42419546" checked=""/><div class="controls bullet"><span class="by">nickysielicki</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419456">parent</a><span>|</span><a href="#42419636">prev</a><span>|</span><a href="#42419618">next</a><span>|</span><label class="collapse" for="c-42419546">[-]</label><label class="expand" for="c-42419546">[3 more]</label></div><br/><div class="children"><div class="content">genuinely asking: where else should ML engineers focus their time, if not on looking at datapath bottlenecks in either kernel execution or the networking stack?</div><br/><div id="42420828" class="c"><input type="checkbox" id="c-42420828" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419546">parent</a><span>|</span><a href="#42419618">next</a><span>|</span><label class="collapse" for="c-42420828">[-]</label><label class="expand" for="c-42420828">[2 more]</label></div><br/><div class="children"><div class="content">The point is that you should focus on the bottlenecks, not on making every random piece of code &quot;as fast as possible&quot;. And that sometimes other things (maintainability, comprehensibility, debuggability) are more important than maximum possible performance, even on the GPU.</div><br/><div id="42421026" class="c"><input type="checkbox" id="c-42421026" checked=""/><div class="controls bullet"><span class="by">nickysielicki</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42420828">parent</a><span>|</span><a href="#42419618">next</a><span>|</span><label class="collapse" for="c-42421026">[-]</label><label class="expand" for="c-42421026">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s fair, but I didn&#x27;t understand OP to be claiming above that &quot;cudaheads&quot; aren&#x27;t looking at their performance bottlenecks before driving work, just that they&#x27;re looking at the problem incorrectly (and eg: maybe should prioritize redesigns over squeezing perf out of flawed approaches.)</div><br/></div></div></div></div></div></div><div id="42419618" class="c"><input type="checkbox" id="c-42419618" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419456">parent</a><span>|</span><a href="#42419546">prev</a><span>|</span><a href="#42419583">next</a><span>|</span><label class="collapse" for="c-42419618">[-]</label><label class="expand" for="c-42419618">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A pattern I&#x27;ve noticed repeatedly among CUDAheads is the idea that &quot;every cycle matters&quot; and therefore we should uglify and optimize even cold parts of our CUDA programs<p>I don&#x27;t know what a &quot;cudahead&quot; is but if you&#x27;re gonna build up a strawman just to chop it down have at it. Doesn&#x27;t change anything about my point - these aren&#x27;t syscalls because there&#x27;s no sys. I mean the dev here literally spells it out correctly so I don&#x27;t understand why there&#x27;s any debate.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42419090" class="c"><input type="checkbox" id="c-42419090" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42418654">parent</a><span>|</span><a href="#42418835">prev</a><span>|</span><a href="#42419289">next</a><span>|</span><label class="collapse" for="c-42419090">[-]</label><label class="expand" for="c-42419090">[2 more]</label></div><br/><div class="children"><div class="content">I wonder what C would look like if CPUs would evolve into what GPUs are today.<p>What if a CPU had assembly instructions for everything a GPU can do? Would compiler&#x2F;language designers support them?</div><br/><div id="42419181" class="c"><input type="checkbox" id="c-42419181" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419090">parent</a><span>|</span><a href="#42419289">next</a><span>|</span><label class="collapse" for="c-42419181">[-]</label><label class="expand" for="c-42419181">[1 more]</label></div><br/><div class="children"><div class="content">there is no reason to wonder: <a href="https:&#x2F;&#x2F;ispc.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ispc.github.io&#x2F;</a></div><br/></div></div></div></div><div id="42419289" class="c"><input type="checkbox" id="c-42419289" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#42418654">parent</a><span>|</span><a href="#42419090">prev</a><span>|</span><a href="#42418590">next</a><span>|</span><label class="collapse" for="c-42419289">[-]</label><label class="expand" for="c-42419289">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never understood why people say you &quot;can&#x27;t&quot; do this or that on GPU. A GPU is made of SMs, and each SM is just a CPU with very wide SIMD pipes and very good hyperthreading. You can take one thread of a warp in a SM and do exactly the same things a CPU would do. Would you get 1&#x2F;32 potential performance? Sure. But so what? Years ago, we did plenty of useful work with less than 1&#x2F;32 of a modest CPU, and we can again.<p>One of the more annoying parts of the Nvidia experience is PTX. I. I know perfectly well that your CPU&#x2F;SM&#x2F;whatever has a program counter. Let me manipulate it directly!</div><br/><div id="42419533" class="c"><input type="checkbox" id="c-42419533" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419289">parent</a><span>|</span><a href="#42418590">next</a><span>|</span><label class="collapse" for="c-42419533">[-]</label><label class="expand" for="c-42419533">[3 more]</label></div><br/><div class="children"><div class="content">I think people are just saying it isn’t very cost effective to use a whole GPU as 1&#x2F;32 of a modest (modern?) CPU.</div><br/><div id="42419659" class="c"><input type="checkbox" id="c-42419659" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419533">parent</a><span>|</span><a href="#42418590">next</a><span>|</span><label class="collapse" for="c-42419659">[-]</label><label class="expand" for="c-42419659">[2 more]</label></div><br/><div class="children"><div class="content">Cars are slow and inefficient in reverse gear but a car that couldn&#x27;t drive in reverse would be broken.</div><br/><div id="42419759" class="c"><input type="checkbox" id="c-42419759" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42418654">root</a><span>|</span><a href="#42419659">parent</a><span>|</span><a href="#42418590">next</a><span>|</span><label class="collapse" for="c-42419759">[-]</label><label class="expand" for="c-42419759">[1 more]</label></div><br/><div class="children"><div class="content">You put “can’t” in quotes, so I guess you are quoting somebody, but I don’t see where the quote is from, so I’m not sure what they actually meant.<p>But I suspect they are using “can’t” informally. Like: You can’t run a drag race in reverse. Ok, you technically could, but it would be a silly thing to do.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42418590" class="c"><input type="checkbox" id="c-42418590" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418654">prev</a><span>|</span><a href="#42418680">next</a><span>|</span><label class="collapse" for="c-42418590">[-]</label><label class="expand" for="c-42418590">[1 more]</label></div><br/><div class="children"><div class="content">this was presented at llvm this year <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4TxGWis1mws" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4TxGWis1mws</a> - it was a nice talk.</div><br/></div></div><div id="42418680" class="c"><input type="checkbox" id="c-42418680" checked=""/><div class="controls bullet"><span class="by">Archit3ch</span><span>|</span><a href="#42418590">prev</a><span>|</span><a href="#42418902">next</a><span>|</span><label class="collapse" for="c-42418680">[-]</label><label class="expand" for="c-42418680">[4 more]</label></div><br/><div class="children"><div class="content">No direct Metal target.</div><br/><div id="42419902" class="c"><input type="checkbox" id="c-42419902" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#42418680">parent</a><span>|</span><a href="#42418691">next</a><span>|</span><label class="collapse" for="c-42419902">[-]</label><label class="expand" for="c-42419902">[1 more]</label></div><br/><div class="children"><div class="content">No Intel either. The port would be easy - gpuintrin.h abstracts over the intrinsics, provide an implementation for those, write a loader in terms of opencl or whatever if you want to run the test suite.<p>The protocol needs ordered load&#x2F;store on shared memory but nothing else. I wrote a paper trying to make it clear that load&#x2F;store on shmem was sufficient which doesn&#x27;t seem to be considered persuasive. It&#x27;s specifically designed to tolerate architectures doing slopping things with cache invalidation. It could run much faster with fetch_or &#x2F; fetch_and instructions (as APUs have, but PCIe does not). It could also hang off DMA but that isn&#x27;t implemented (I want to have the GPU push packets over the network without involving the x64 CPU at all).</div><br/></div></div><div id="42418691" class="c"><input type="checkbox" id="c-42418691" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42418680">parent</a><span>|</span><a href="#42419902">prev</a><span>|</span><a href="#42418902">next</a><span>|</span><label class="collapse" for="c-42418691">[-]</label><label class="expand" for="c-42418691">[2 more]</label></div><br/><div class="children"><div class="content">this is an LLVM project... you want this to work on Metal, ask apple to add a Metal backend to LLVM<p><a href="https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;tree&#x2F;main&#x2F;llvm&#x2F;lib&#x2F;Target">https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;tree&#x2F;main&#x2F;llvm&#x2F;lib&#x2F;Targ...</a></div><br/><div id="42419747" class="c"><input type="checkbox" id="c-42419747" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42418680">root</a><span>|</span><a href="#42418691">parent</a><span>|</span><a href="#42418902">next</a><span>|</span><label class="collapse" for="c-42419747">[-]</label><label class="expand" for="c-42419747">[1 more]</label></div><br/><div class="children"><div class="content">I am surprised there isn&#x27;t.</div><br/></div></div></div></div></div></div><div id="42418902" class="c"><input type="checkbox" id="c-42418902" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#42418680">prev</a><span>|</span><a href="#42419045">next</a><span>|</span><label class="collapse" for="c-42418902">[-]</label><label class="expand" for="c-42418902">[1 more]</label></div><br/><div class="children"><div class="content">Nice to see this finally after 15 years.</div><br/></div></div><div id="42419045" class="c"><input type="checkbox" id="c-42419045" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42418902">prev</a><span>|</span><label class="collapse" for="c-42419045">[-]</label><label class="expand" for="c-42419045">[3 more]</label></div><br/><div class="children"><div class="content">I hate libc. It&#x27;s such a common cause of versioning problems on my system.<p>Can&#x27;t they just stop making new versions of it?</div><br/><div id="42419121" class="c"><input type="checkbox" id="c-42419121" checked=""/><div class="controls bullet"><span class="by">wbl</span><span>|</span><a href="#42419045">parent</a><span>|</span><label class="collapse" for="c-42419121">[-]</label><label class="expand" for="c-42419121">[2 more]</label></div><br/><div class="children"><div class="content">Dynamic linking has some benefits, but many detractors.</div><br/><div id="42419741" class="c"><input type="checkbox" id="c-42419741" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42419045">root</a><span>|</span><a href="#42419121">parent</a><span>|</span><label class="collapse" for="c-42419741">[-]</label><label class="expand" for="c-42419741">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s nice not having to recompile all your software because of a CVE impacting libc, or any other fundamental component of the system.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>