<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700298060132" as="style"/><link rel="stylesheet" href="styles.css?v=1700298060132"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/karaswisher/status/1725702501435941294">Ilya Sutskever &quot;at the center&quot; of Altman firing?</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>apsec112</span> | <span>247 comments</span></div><br/><div><div id="38316357" class="c"><input type="checkbox" id="c-38316357" checked=""/><div class="controls bullet"><span class="by">OscarTheGrinch</span><span>|</span><a href="#38314376">next</a><span>|</span><label class="collapse" for="c-38316357">[-]</label><label class="expand" for="c-38316357">[6 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s my preferred theory, it&#x27;s a tale as old as time. Sam Altman, like Icarus, flew too close to Microsoft&#x27;s giant pot of money. He pivoted the company away from it&#x27;s founding mission, unleashing the very djinn they originally set out to harness. Turns out there were people at OpenAI who really believed in the original vision.</div><br/><div id="38316975" class="c"><input type="checkbox" id="c-38316975" checked=""/><div class="controls bullet"><span class="by">helsinkiandrew</span><span>|</span><a href="#38316357">parent</a><span>|</span><a href="#38316617">next</a><span>|</span><label class="collapse" for="c-38316975">[-]</label><label class="expand" for="c-38316975">[1 more]</label></div><br/><div class="children"><div class="content">Or was it that he&#x27;s been seen trying to raise money for an AI chip startup to compete with Nvidia or was courting SoftBank for a multibillion-dollar investment in a new company to make AI-oriented hardware with Jony Ive?<p>A lot of his current external activities could worry the board - and if he wasn&#x27;t candid about future plans I can see why they might sack him.</div><br/></div></div><div id="38316617" class="c"><input type="checkbox" id="c-38316617" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#38316357">parent</a><span>|</span><a href="#38316975">prev</a><span>|</span><a href="#38316513">next</a><span>|</span><label class="collapse" for="c-38316617">[-]</label><label class="expand" for="c-38316617">[1 more]</label></div><br/><div class="children"><div class="content">I hope this is the truth, it would give me a little more faith in humanity than I currently have</div><br/></div></div><div id="38316513" class="c"><input type="checkbox" id="c-38316513" checked=""/><div class="controls bullet"><span class="by">dwd</span><span>|</span><a href="#38316357">parent</a><span>|</span><a href="#38316617">prev</a><span>|</span><a href="#38314376">next</a><span>|</span><label class="collapse" for="c-38316513">[-]</label><label class="expand" for="c-38316513">[3 more]</label></div><br/><div class="children"><div class="content">Nicely put.<p>The original vision is pretty clear, and a compelling reason to not screw around and get sidetracked, even if that has massive commercialisation upside.<p>Thankfully M$ didn&#x27;t have control of the board.</div><br/><div id="38316766" class="c"><input type="checkbox" id="c-38316766" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38316357">root</a><span>|</span><a href="#38316513">parent</a><span>|</span><a href="#38314376">next</a><span>|</span><label class="collapse" for="c-38316766">[-]</label><label class="expand" for="c-38316766">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Thankfully M$ didn&#x27;t have control of the board<p>You never know. Remember Nokia?</div><br/><div id="38316787" class="c"><input type="checkbox" id="c-38316787" checked=""/><div class="controls bullet"><span class="by">smilespray</span><span>|</span><a href="#38316357">root</a><span>|</span><a href="#38316766">parent</a><span>|</span><a href="#38314376">next</a><span>|</span><label class="collapse" for="c-38316787">[-]</label><label class="expand" for="c-38316787">[1 more]</label></div><br/><div class="children"><div class="content">That still pisses me off.</div><br/></div></div></div></div></div></div></div></div><div id="38314376" class="c"><input type="checkbox" id="c-38314376" checked=""/><div class="controls bullet"><span class="by">cardine</span><span>|</span><a href="#38316357">prev</a><span>|</span><a href="#38316812">next</a><span>|</span><label class="collapse" for="c-38314376">[-]</label><label class="expand" for="c-38314376">[7 more]</label></div><br/><div class="children"><div class="content">I wonder if Sam knew he was going to lose this power struggle and then started working on an exit plan with people loyal to him behind the boards back. The board then finds out and rushes to kick him out ASAP to stop him from using company resources to create a competitor.</div><br/><div id="38314743" class="c"><input type="checkbox" id="c-38314743" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#38314376">parent</a><span>|</span><a href="#38314615">next</a><span>|</span><label class="collapse" for="c-38314743">[-]</label><label class="expand" for="c-38314743">[1 more]</label></div><br/><div class="children"><div class="content">There is no way Sam doesn&#x27;t have the street cred to do a raise and pull talent for a competitor. They made the decision for him.<p>(pleb who would invest [1], no other association)<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35306929">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35306929</a></div><br/></div></div><div id="38314615" class="c"><input type="checkbox" id="c-38314615" checked=""/><div class="controls bullet"><span class="by">drcode</span><span>|</span><a href="#38314376">parent</a><span>|</span><a href="#38314743">prev</a><span>|</span><a href="#38314861">next</a><span>|</span><label class="collapse" for="c-38314615">[-]</label><label class="expand" for="c-38314615">[2 more]</label></div><br/><div class="children"><div class="content">Now that is a theory that actually adds up with the facts (whether true or not)</div><br/><div id="38316983" class="c"><input type="checkbox" id="c-38316983" checked=""/><div class="controls bullet"><span class="by">kzrdude</span><span>|</span><a href="#38314376">root</a><span>|</span><a href="#38314615">parent</a><span>|</span><a href="#38314861">next</a><span>|</span><label class="collapse" for="c-38316983">[-]</label><label class="expand" for="c-38316983">[1 more]</label></div><br/><div class="children"><div class="content">Brockman immediately said &quot;don&#x27;t worry, great things are coming&quot;, which also seems to line up.</div><br/></div></div></div></div><div id="38316224" class="c"><input type="checkbox" id="c-38316224" checked=""/><div class="controls bullet"><span class="by">eastbound</span><span>|</span><a href="#38314376">parent</a><span>|</span><a href="#38314861">prev</a><span>|</span><a href="#38316812">next</a><span>|</span><label class="collapse" for="c-38316224">[-]</label><label class="expand" for="c-38316224">[2 more]</label></div><br/><div class="children"><div class="content">So they are trying to burn him with the worst possible accusation for a Ceo to try to lessen the inevitable fundraising he’s going to win?</div><br/><div id="38316293" class="c"><input type="checkbox" id="c-38316293" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314376">root</a><span>|</span><a href="#38316224">parent</a><span>|</span><a href="#38316812">next</a><span>|</span><label class="collapse" for="c-38316293">[-]</label><label class="expand" for="c-38316293">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So they are trying to burn him with the worst possible accusation for a Ceo to try to lessen the inevitable fundraising he’s going to win?<p>If he was really doing it behind the boards back, the accusation is entirely accurate <i>even if</i> his motivations was an expectations of losing the internal factional struggle.</div><br/></div></div></div></div></div></div><div id="38316812" class="c"><input type="checkbox" id="c-38316812" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38314376">prev</a><span>|</span><a href="#38314462">next</a><span>|</span><label class="collapse" for="c-38316812">[-]</label><label class="expand" for="c-38316812">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2023-11-18&#x2F;openai-altman-ouster-followed-debates-between-altman-board?embedded-checkout=true" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2023-11-18&#x2F;openai-al...</a><p><a href="https:&#x2F;&#x2F;archive.is&#x2F;tCG3q" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;tCG3q</a><p>Bloomberg: &quot;OpenAI CEO’s Ouster Followed Debates Between Altman, Board&quot;</div><br/></div></div><div id="38314462" class="c"><input type="checkbox" id="c-38314462" checked=""/><div class="controls bullet"><span class="by">gizmo</span><span>|</span><a href="#38316812">prev</a><span>|</span><a href="#38316130">next</a><span>|</span><label class="collapse" for="c-38314462">[-]</label><label class="expand" for="c-38314462">[14 more]</label></div><br/><div class="children"><div class="content">Ousting sama and gdb over something as petty as a simple strategy disagreement is totally unprofessional. sama got accused of serious misconduct. Even if he was too eager to commercialize OpenAIs tech that doesn&#x27;t come close to justifying this circus act.</div><br/><div id="38316325" class="c"><input type="checkbox" id="c-38316325" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314462">parent</a><span>|</span><a href="#38315186">next</a><span>|</span><label class="collapse" for="c-38316325">[-]</label><label class="expand" for="c-38316325">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Ousting sama and gdb over something as petty as a simple strategy disagreement<p>A fundamental inability to align on what, on a fundamental level, the mission set out in the charter of a 501(c)(3) charity means in real world terms is not &quot;a simple strategy disagreement&quot;; moreover, the existence of a factional dispute over that doesn&#x27;t mean that there weren&#x27;t serious specific conduct that occurred in the context of that dispute over goals.</div><br/><div id="38316848" class="c"><input type="checkbox" id="c-38316848" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38316325">parent</a><span>|</span><a href="#38315186">next</a><span>|</span><label class="collapse" for="c-38316848">[-]</label><label class="expand" for="c-38316848">[1 more]</label></div><br/><div class="children"><div class="content">The board questioned his “candid”-ness. This was not a difference of opinion on strategy.</div><br/></div></div></div></div><div id="38315186" class="c"><input type="checkbox" id="c-38315186" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#38314462">parent</a><span>|</span><a href="#38316325">prev</a><span>|</span><a href="#38314703">next</a><span>|</span><label class="collapse" for="c-38315186">[-]</label><label class="expand" for="c-38315186">[3 more]</label></div><br/><div class="children"><div class="content">Strategy disagreements are absolutely central reasons to fire executives.</div><br/><div id="38315491" class="c"><input type="checkbox" id="c-38315491" checked=""/><div class="controls bullet"><span class="by">KerrAvon</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38315186">parent</a><span>|</span><a href="#38314703">next</a><span>|</span><label class="collapse" for="c-38315491">[-]</label><label class="expand" for="c-38315491">[2 more]</label></div><br/><div class="children"><div class="content">But you don’t accuse of them of lying on the way out because you have a strong disagreement. That’s a guaranteed ticket to a very expensive lawsuit.<p>Either there’s more to it or the board is staffed by very naive people.</div><br/><div id="38316355" class="c"><input type="checkbox" id="c-38316355" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38315491">parent</a><span>|</span><a href="#38314703">next</a><span>|</span><label class="collapse" for="c-38316355">[-]</label><label class="expand" for="c-38316355">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But you don’t accuse of them of lying on the way out because you have a strong disagreement.<p>You do if part of the way that they attempted to win the internal power struggle resulting from the disagreemtn was lying to the board to avoid having their actions which lacked majority support from being thwarted.</div><br/></div></div></div></div></div></div><div id="38314703" class="c"><input type="checkbox" id="c-38314703" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#38314462">parent</a><span>|</span><a href="#38315186">prev</a><span>|</span><a href="#38315285">next</a><span>|</span><label class="collapse" for="c-38314703">[-]</label><label class="expand" for="c-38314703">[5 more]</label></div><br/><div class="children"><div class="content">Don’t you think it’s more likely you don’t know the whole story yet?</div><br/><div id="38314819" class="c"><input type="checkbox" id="c-38314819" checked=""/><div class="controls bullet"><span class="by">chipgap98</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38314703">parent</a><span>|</span><a href="#38315285">next</a><span>|</span><label class="collapse" for="c-38314819">[-]</label><label class="expand" for="c-38314819">[4 more]</label></div><br/><div class="children"><div class="content">It has basically been confirmed<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255</a></div><br/><div id="38317033" class="c"><input type="checkbox" id="c-38317033" checked=""/><div class="controls bullet"><span class="by">weare138</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38314819">parent</a><span>|</span><a href="#38316367">next</a><span>|</span><label class="collapse" for="c-38317033">[-]</label><label class="expand" for="c-38317033">[1 more]</label></div><br/><div class="children"><div class="content">If the allegations concerning Sam are true then this could all be for damage control. It is in OpenAI&#x27;s best interest that information isn&#x27;t released to the public and it&#x27;s in Sam&#x27;s best interest to keep his mouth shut about it if the allegations are true. The timing and abruptness of everything is highly suspicious. Even Microsoft was out of the loop on this which again is very strange if this was just an issue over corporate strategy and vision.</div><br/></div></div><div id="38316367" class="c"><input type="checkbox" id="c-38316367" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38314819">parent</a><span>|</span><a href="#38317033">prev</a><span>|</span><a href="#38316537">next</a><span>|</span><label class="collapse" for="c-38316367">[-]</label><label class="expand" for="c-38316367">[1 more]</label></div><br/><div class="children"><div class="content">There is plenty of indications about the <i>nature</i> of the disagreement, but that <i>doesn&#x27;t</i> tell you what conduct did or did not occur as factions (including the one whose leading members have been ousted) sought to win the dispute.</div><br/></div></div><div id="38316537" class="c"><input type="checkbox" id="c-38316537" checked=""/><div class="controls bullet"><span class="by">seattle_spring</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38314819">parent</a><span>|</span><a href="#38316367">prev</a><span>|</span><a href="#38315285">next</a><span>|</span><label class="collapse" for="c-38316537">[-]</label><label class="expand" for="c-38316537">[1 more]</label></div><br/><div class="children"><div class="content">Did you mean to link to a different tweet? I don’t see how what you linked “basically confirms” literally anything related to this. Can you spell it out for those of us that aren’t reading literally every rumor and gossip that’s popped up in the last 12 hours?</div><br/></div></div></div></div></div></div><div id="38315285" class="c"><input type="checkbox" id="c-38315285" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38314462">parent</a><span>|</span><a href="#38314703">prev</a><span>|</span><a href="#38316130">next</a><span>|</span><label class="collapse" for="c-38315285">[-]</label><label class="expand" for="c-38315285">[3 more]</label></div><br/><div class="children"><div class="content">This is not petty, it’s the integral mission of the company, the reason it was founded, the reason it got investors and the reason that many of the most brilliant scientists in the world work there.<p>They started as a non-profit ffs.</div><br/><div id="38315930" class="c"><input type="checkbox" id="c-38315930" checked=""/><div class="controls bullet"><span class="by">brysonreece</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38315285">parent</a><span>|</span><a href="#38316130">next</a><span>|</span><label class="collapse" for="c-38315930">[-]</label><label class="expand" for="c-38315930">[2 more]</label></div><br/><div class="children"><div class="content">And they still are. OpenAI consists of two parts; a non-profit entity which owns the IP, along with the obvious commercialization-focused subsidiary of the company.<p>My question is: what was stopping both parties here from pursuing parallel paths? — have the non-profit&#x2F;research oriented arm continue to focus on solving AGI, backed by the funds raised on from their LLM offerings? Were potential roadmaps really that divergent?<p>I had always assumed this was their internal understanding up until now, since at least the introduction of ChatGPT subscriptions.</div><br/><div id="38316635" class="c"><input type="checkbox" id="c-38316635" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#38314462">root</a><span>|</span><a href="#38315930">parent</a><span>|</span><a href="#38316130">next</a><span>|</span><label class="collapse" for="c-38316635">[-]</label><label class="expand" for="c-38316635">[1 more]</label></div><br/><div class="children"><div class="content">Because it really seems like the for profit side was building towards a Microsoft acquisition</div><br/></div></div></div></div></div></div></div></div><div id="38316130" class="c"><input type="checkbox" id="c-38316130" checked=""/><div class="controls bullet"><span class="by">1vuio0pswjnm7</span><span>|</span><a href="#38314462">prev</a><span>|</span><a href="#38316652">next</a><span>|</span><label class="collapse" for="c-38316130">[-]</label><label class="expand" for="c-38316130">[2 more]</label></div><br/><div class="children"><div class="content">Some weeks ago, I listened to a Bloomberg interview with Altman where he was joined by someone from OpenAI who does the programming.  There was obvious disagreement between the two, and the interviewer actually made a joke about it.  Perhaps Altman was destined to become the next SBF.  Too much misrepresentation to the public, telling people what they want to hear..</div><br/><div id="38316516" class="c"><input type="checkbox" id="c-38316516" checked=""/><div class="controls bullet"><span class="by">mi3law</span><span>|</span><a href="#38316130">parent</a><span>|</span><a href="#38316652">next</a><span>|</span><label class="collapse" for="c-38316516">[-]</label><label class="expand" for="c-38316516">[1 more]</label></div><br/><div class="children"><div class="content">Can you please try to recall and link to the interview? I&#x27;d love to see it.</div><br/></div></div></div></div><div id="38316652" class="c"><input type="checkbox" id="c-38316652" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38316130">prev</a><span>|</span><a href="#38314420">next</a><span>|</span><label class="collapse" for="c-38316652">[-]</label><label class="expand" for="c-38316652">[4 more]</label></div><br/><div class="children"><div class="content">The main question is what to expect from OpenAI now? No changes very unlikely, that would mean it was just a power grab. So two options remain: more open, more closed. How about slow down and open up? Hope they wouldn&#x27;t dumb down GPT4. If they allow to use their models to generate training sets (which is prohibited now, AFAIK), that would be nice.</div><br/><div id="38316964" class="c"><input type="checkbox" id="c-38316964" checked=""/><div class="controls bullet"><span class="by">gexla</span><span>|</span><a href="#38316652">parent</a><span>|</span><a href="#38316670">next</a><span>|</span><label class="collapse" for="c-38316964">[-]</label><label class="expand" for="c-38316964">[1 more]</label></div><br/><div class="children"><div class="content">My guess is that the immediate roadmap has already been locked in up to X months out. So, we&#x27;ll likely never know what the &quot;changes&quot; will be. Short term changes are likely still Altman&#x27;s work. Long term is the next decision maker.</div><br/></div></div><div id="38316670" class="c"><input type="checkbox" id="c-38316670" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38316652">parent</a><span>|</span><a href="#38316964">prev</a><span>|</span><a href="#38314420">next</a><span>|</span><label class="collapse" for="c-38316670">[-]</label><label class="expand" for="c-38316670">[2 more]</label></div><br/><div class="children"><div class="content">&gt; So two options remain: more open, more closed.<p>All kinds of changes are possible that would not, in net, be more open <i>or</i> more closed, either because there primary change would not be about openness, or because it would be more open in some ways and less in others.<p>So, no, there are more than two options.</div><br/><div id="38316747" class="c"><input type="checkbox" id="c-38316747" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38316652">root</a><span>|</span><a href="#38316670">parent</a><span>|</span><a href="#38314420">next</a><span>|</span><label class="collapse" for="c-38316747">[-]</label><label class="expand" for="c-38316747">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to imagine more closed. They have opened only &quot;whisper&quot; and old stuff. Neither is a problem from moral standpoint. Whisper &#x27;helps people&#x27; and is very in line with the &#x27;mission&#x27;. One thing they can do is end MS exclusivity. Google would like it. At the same time opening too much would mean giving access to &#x27;unfriendly&#x27; governments.</div><br/></div></div></div></div></div></div><div id="38314420" class="c"><input type="checkbox" id="c-38314420" checked=""/><div class="controls bullet"><span class="by">convexstrictly</span><span>|</span><a href="#38316652">prev</a><span>|</span><a href="#38314648">next</a><span>|</span><label class="collapse" for="c-38314420">[-]</label><label class="expand" for="c-38314420">[69 more]</label></div><br/><div class="children"><div class="content">Sutskever: &quot;You can call it (a coup), and I can understand why you chose this word, but I disagree with this.  This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity.&quot;<p>Scoop: theinformation.com<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255</a></div><br/><div id="38315198" class="c"><input type="checkbox" id="c-38315198" checked=""/><div class="controls bullet"><span class="by">smharris65</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314513">next</a><span>|</span><label class="collapse" for="c-38315198">[-]</label><label class="expand" for="c-38315198">[5 more]</label></div><br/><div class="children"><div class="content">Some insider details that seem to agree with this:
<a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126&#x2F;</a></div><br/><div id="38317086" class="c"><input type="checkbox" id="c-38317086" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315198">parent</a><span>|</span><a href="#38316177">next</a><span>|</span><label class="collapse" for="c-38317086">[-]</label><label class="expand" for="c-38317086">[1 more]</label></div><br/><div class="children"><div class="content">We cant trust what we read. But last year&#x27;s &quot;Altman World Tour&quot; where he met so many world leaders around the world felt a bit over the top, and maybe it got into his head</div><br/></div></div><div id="38316177" class="c"><input type="checkbox" id="c-38316177" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315198">parent</a><span>|</span><a href="#38317086">prev</a><span>|</span><a href="#38316767">next</a><span>|</span><label class="collapse" for="c-38316177">[-]</label><label class="expand" for="c-38316177">[1 more]</label></div><br/><div class="children"><div class="content">Based on the amount of comments in that time period that is probably a fake insider.</div><br/></div></div><div id="38316767" class="c"><input type="checkbox" id="c-38316767" checked=""/><div class="controls bullet"><span class="by">leobg</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315198">parent</a><span>|</span><a href="#38316177">prev</a><span>|</span><a href="#38316170">next</a><span>|</span><label class="collapse" for="c-38316767">[-]</label><label class="expand" for="c-38316767">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This was about stopping a runaway train before it flew off a cliff with all of us on board. Believe me, the board and I gave him tons of chances to self-correct. But his ego was out of control.<p>&gt; Don&#x27;t let the media hype fool you. Sam wasn&#x27;t some genius visionary. He was a glory-hungry narcissist cutting every corner in some deluded quest to be the next Musk.<p>That does align with Ilya’s tweet about ego being in the way of great achievements.<p>And it does align with Sam’s statements on Lex’s podcast about his disagreements with Musk. He compared himself to Elon’s SpaceX being bullied by Elon’s childhood heroes. But he didn’t seem sad about it - just combative. Elon’s response to the NASA astronauts distrusting his company’s work was “They should come visit and see what we’re doing”. Sam’s reaction was very different. Like, “If he says bad things about us, I can say bad things about him too. It’s not my style. But maybe I will, one day”. Same sentiment as he is showing now (“if I go off the board can come after me for the value of my shares”).<p>All of that does paint a picture where it really isn’t about doing something necessary for humanity and future generations, and more about being considered great. The odd thing is that this should get you fired, especially in SF, of all places.</div><br/></div></div><div id="38316170" class="c"><input type="checkbox" id="c-38316170" checked=""/><div class="controls bullet"><span class="by">jzl</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315198">parent</a><span>|</span><a href="#38316767">prev</a><span>|</span><a href="#38314513">next</a><span>|</span><label class="collapse" for="c-38316170">[-]</label><label class="expand" for="c-38316170">[1 more]</label></div><br/><div class="children"><div class="content">Wow, all the comments and responses to that person&#x27;s comments are a gold mine. Not saying anything should be taken as gospel, either from that poster or the people replying. But certainly a lot of food for thought.</div><br/></div></div></div></div><div id="38314513" class="c"><input type="checkbox" id="c-38314513" checked=""/><div class="controls bullet"><span class="by">jdminhbg</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38315198">prev</a><span>|</span><a href="#38314527">next</a><span>|</span><label class="collapse" for="c-38314513">[-]</label><label class="expand" for="c-38314513">[3 more]</label></div><br/><div class="children"><div class="content">So basically a confirmation, but with a slight disagreement on the vocabulary used to describe it.</div><br/><div id="38315776" class="c"><input type="checkbox" id="c-38315776" checked=""/><div class="controls bullet"><span class="by">davorak</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314513">parent</a><span>|</span><a href="#38314527">next</a><span>|</span><label class="collapse" for="c-38315776">[-]</label><label class="expand" for="c-38315776">[2 more]</label></div><br/><div class="children"><div class="content">I read it as Ilya Sutskever thinking the move is good non-profit governance grounds and that does not match what coup often means, unlawful seizure of power or maybe unprincipled&#x2F;unreasonable seizure of power.<p>Ilya Sutskever seems to think this is a reasonable principled move to seize power that is in line with the non-profits goals and governance, but does not seem to care too much if you call it a coup.</div><br/><div id="38317109" class="c"><input type="checkbox" id="c-38317109" checked=""/><div class="controls bullet"><span class="by">username332211</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315776">parent</a><span>|</span><a href="#38314527">next</a><span>|</span><label class="collapse" for="c-38317109">[-]</label><label class="expand" for="c-38317109">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s just spin. Which coup hasn&#x27;t been a &quot;reasonable and principled move to seize power&quot; according to it&#x27;s orchestrator?<p>Do you think Napoleon or Pinochet made speeches to the effect of &quot;Yes, it was a completely unprincipled power-grab, but what are you going to do about it, lol?&quot;</div><br/></div></div></div></div></div></div><div id="38314527" class="c"><input type="checkbox" id="c-38314527" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314513">prev</a><span>|</span><a href="#38316014">next</a><span>|</span><label class="collapse" for="c-38314527">[-]</label><label class="expand" for="c-38314527">[42 more]</label></div><br/><div class="children"><div class="content">Very unprofessional way to approach this disagreement.</div><br/><div id="38314549" class="c"><input type="checkbox" id="c-38314549" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314527">parent</a><span>|</span><a href="#38314700">next</a><span>|</span><label class="collapse" for="c-38314549">[-]</label><label class="expand" for="c-38314549">[14 more]</label></div><br/><div class="children"><div class="content">How so? It&#x27;s just another firing and being escorted out the door.</div><br/><div id="38314597" class="c"><input type="checkbox" id="c-38314597" checked=""/><div class="controls bullet"><span class="by">janejeon</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314549">parent</a><span>|</span><a href="#38314576">next</a><span>|</span><label class="collapse" for="c-38314597">[-]</label><label class="expand" for="c-38314597">[9 more]</label></div><br/><div class="children"><div class="content">The wording is very clearly hostile and aggressive, <i>especially</i> for a formal statement, and the wording, again, makes it very clear that they are burning all bridges with Sam Altman, <i>and</i> it is very clear that 1. it was done extremely suddenly, 2. with very little notice or discussion with any other stakeholder (e.g. Microsoft being completely blindsided, not even waiting 30 minutes for the stock market to close, doing this shortly before Thanksgiving break, etc).<p>You don&#x27;t really see any of this in most professional settings.</div><br/><div id="38314859" class="c"><input type="checkbox" id="c-38314859" checked=""/><div class="controls bullet"><span class="by">clnq</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314597">parent</a><span>|</span><a href="#38314715">next</a><span>|</span><label class="collapse" for="c-38314859">[-]</label><label class="expand" for="c-38314859">[4 more]</label></div><br/><div class="children"><div class="content">It is quite gauche for a company to burn bridges with their upper management. This bodes poorly for ever hoping to attract executives in the future. Even Bobby Kotick got a more graceful farewell from Activision Blizzard, where they tried to clear his name. It is only prudent business.<p>Certainly, this is very immature. It wouldn&#x27;t be out of context in HBO&#x27;s Succession.<p>Whether what happened is right or just in some sense is a different conversation. We could speculate on what is going on in the company and why, but the tactlessness is evident.</div><br/><div id="38316660" class="c"><input type="checkbox" id="c-38316660" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314859">parent</a><span>|</span><a href="#38315106">next</a><span>|</span><label class="collapse" for="c-38316660">[-]</label><label class="expand" for="c-38316660">[1 more]</label></div><br/><div class="children"><div class="content">People get fired all the time: suddenly, too. If I got fired by my company tomorrow, they wouldn&#x27;t treat me with kid gloves, they&#x27;d just end my livelihood like it was nothing. I&#x27;d probably find out when I couldn&#x27;t log in. Why should &quot;upper management&quot; get a graceful farewell? We don&#x27;t have royalty in the USA. One person is not inherently better than another.</div><br/></div></div><div id="38315106" class="c"><input type="checkbox" id="c-38315106" checked=""/><div class="controls bullet"><span class="by">ribosometronome</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314859">parent</a><span>|</span><a href="#38316660">prev</a><span>|</span><a href="#38314715">next</a><span>|</span><label class="collapse" for="c-38315106">[-]</label><label class="expand" for="c-38315106">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Whether it&#x27;s right or just in some sense is a different conversation.<p>The same conversation if it&#x27;s &quot;mature&quot;, surely? I&#x27;m failing to see how one thinks turning a blind eye to like, decades of sexual impropriety and major internal culture issues to the point the state takes action against your company is &quot;mature&quot;. Like, under what definition?</div><br/><div id="38315296" class="c"><input type="checkbox" id="c-38315296" checked=""/><div class="controls bullet"><span class="by">clnq</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315106">parent</a><span>|</span><a href="#38314715">next</a><span>|</span><label class="collapse" for="c-38315296">[-]</label><label class="expand" for="c-38315296">[1 more]</label></div><br/><div class="children"><div class="content">Mature, as in the opposite of ingenuous. It does no good to harm a company further. Kotick did enough damage, he left, all that needed to be said about him was said, tirelessly. Every effort to get him to offer some reparations - expended.<p>So what was there to gain from the company speaking ill of their past employee? What was even left to say? Nothing. No one wants to work in an organization that vilifies its own people. It was prudent.<p>I will emphasize again that the morality of these situations is a separate matter from tact. It is very well possible that doing what is good for business does not always align with what is moral. But does this come as a surprise to anyone?<p>We can recognize that the situation is not one dimensional and not reduce it to such. The same applies to the press release from Open AI - it is graceless, that much can be observed. But we do not yet know whether it is reprehensible, exemplary, or somewhere in between in the sense of morality and justice. It will come out, in other channels rather than official press releases, like in Bobby&#x27;s case.</div><br/></div></div></div></div></div></div><div id="38314715" class="c"><input type="checkbox" id="c-38314715" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314597">parent</a><span>|</span><a href="#38314859">prev</a><span>|</span><a href="#38316134">next</a><span>|</span><label class="collapse" for="c-38314715">[-]</label><label class="expand" for="c-38314715">[3 more]</label></div><br/><div class="children"><div class="content">boards give reasons for transparency, and they said he had not been fully candid.<p>You are interpreting that as hostile and aggressive because you are reading into it what other boards have said in other disputes and whatever you are imagining, but if the board learned some things not from Altman that it felt they should have learned from Altman, less than candid is a completely neutral way to describe it, and voting him out is not an indication of hostility.<p>Would you like to propose some other candid wording the board could have chosen, a wording that does not lack candor?</div><br/><div id="38314760" class="c"><input type="checkbox" id="c-38314760" checked=""/><div class="controls bullet"><span class="by">janejeon</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314715">parent</a><span>|</span><a href="#38316134">next</a><span>|</span><label class="collapse" for="c-38314760">[-]</label><label class="expand" for="c-38314760">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You are interpreting that as hostile and aggressive because you are reading into it<p>Uhh no, I&#x27;m seeing it as hostile and aggressive because the actual verbiage was hostile and aggressive, doubly so in the context of this being a formal corporate statement. You can pass the text into NLP sentiment analyzer and it too will come to the same conclusion.<p>It is also very telling that you are being very sarcastic and demeaning in your remarks as well to someone who wasn&#x27;t even replying to you, which might explain why you might have seen the PR statement differently.</div><br/><div id="38316331" class="c"><input type="checkbox" id="c-38316331" checked=""/><div class="controls bullet"><span class="by">racketcon2089</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314760">parent</a><span>|</span><a href="#38316134">next</a><span>|</span><label class="collapse" for="c-38316331">[-]</label><label class="expand" for="c-38316331">[1 more]</label></div><br/><div class="children"><div class="content">When you look at the written word and find yourself consistently imputing clear intent which is hostile, aggressive, sarcastic, and demeaning which no one else but you sees, a thoughtful person would begin to introspect.</div><br/></div></div></div></div></div></div><div id="38316134" class="c"><input type="checkbox" id="c-38316134" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314597">parent</a><span>|</span><a href="#38314715">prev</a><span>|</span><a href="#38314576">next</a><span>|</span><label class="collapse" for="c-38316134">[-]</label><label class="expand" for="c-38316134">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The wording is very clearly hostile and aggressive<p>At least we can be sure that ChatGPT didn&#x27;t write the statement, then.<p>Otherwise the last paragraph would have equivocated that both sides have a point.</div><br/></div></div></div></div><div id="38314576" class="c"><input type="checkbox" id="c-38314576" checked=""/><div class="controls bullet"><span class="by">jdminhbg</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314549">parent</a><span>|</span><a href="#38314597">prev</a><span>|</span><a href="#38314700">next</a><span>|</span><label class="collapse" for="c-38314576">[-]</label><label class="expand" for="c-38314576">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not &quot;just another firing,&quot; the statement accused Altman of lying to the board. Either he did and it&#x27;s a justified extraordinary firing, or he didn&#x27;t and it&#x27;s hugely unprofessional to insinuate he did.</div><br/><div id="38314604" class="c"><input type="checkbox" id="c-38314604" checked=""/><div class="controls bullet"><span class="by">chasd00</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314576">parent</a><span>|</span><a href="#38314625">next</a><span>|</span><label class="collapse" for="c-38314604">[-]</label><label class="expand" for="c-38314604">[1 more]</label></div><br/><div class="children"><div class="content">Oh man the lawyers have to be so happy I bet they can hardly count.</div><br/></div></div><div id="38314625" class="c"><input type="checkbox" id="c-38314625" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314576">parent</a><span>|</span><a href="#38314604">prev</a><span>|</span><a href="#38314923">next</a><span>|</span><label class="collapse" for="c-38314625">[-]</label><label class="expand" for="c-38314625">[1 more]</label></div><br/><div class="children"><div class="content">I read that word as not being forthcoming moreso than actively lying. But I don&#x27;t read many firing press releases.</div><br/></div></div><div id="38314923" class="c"><input type="checkbox" id="c-38314923" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314576">parent</a><span>|</span><a href="#38314625">prev</a><span>|</span><a href="#38314700">next</a><span>|</span><label class="collapse" for="c-38314923">[-]</label><label class="expand" for="c-38314923">[1 more]</label></div><br/><div class="children"><div class="content">Hugely unprofessional and a billion dollar liability.</div><br/></div></div></div></div></div></div><div id="38314700" class="c"><input type="checkbox" id="c-38314700" checked=""/><div class="controls bullet"><span class="by">mochomocha</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314527">parent</a><span>|</span><a href="#38314549">prev</a><span>|</span><a href="#38314689">next</a><span>|</span><label class="collapse" for="c-38314700">[-]</label><label class="expand" for="c-38314700">[6 more]</label></div><br/><div class="children"><div class="content">If you know anything about Ilya, it&#x27;s definitely not out of character.</div><br/><div id="38316253" class="c"><input type="checkbox" id="c-38316253" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314700">parent</a><span>|</span><a href="#38316326">next</a><span>|</span><label class="collapse" for="c-38316253">[-]</label><label class="expand" for="c-38316253">[3 more]</label></div><br/><div class="children"><div class="content">Having read up on some background not sure I want this guy in charge of any kind of superintelligence.</div><br/><div id="38316415" class="c"><input type="checkbox" id="c-38316415" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38316253">parent</a><span>|</span><a href="#38316326">next</a><span>|</span><label class="collapse" for="c-38316415">[-]</label><label class="expand" for="c-38316415">[2 more]</label></div><br/><div class="children"><div class="content">Well, I definitely wouldn&#x27;t want Altman in charge of any superintelligence, so &quot;I&#x27;m not sure&quot; would be an improvement, if I expected an imminent superintelligence.</div><br/><div id="38316686" class="c"><input type="checkbox" id="c-38316686" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38316415">parent</a><span>|</span><a href="#38316326">next</a><span>|</span><label class="collapse" for="c-38316686">[-]</label><label class="expand" for="c-38316686">[1 more]</label></div><br/><div class="children"><div class="content">What if - hear me out - what if the firing is the doing <i>of an AGI</i>? Maybe OpenAI succeeded and now the AI is calling the shots (figuratively, though eventually maybe literally too).</div><br/></div></div></div></div></div></div><div id="38316326" class="c"><input type="checkbox" id="c-38316326" checked=""/><div class="controls bullet"><span class="by">ariym</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314700">parent</a><span>|</span><a href="#38316253">prev</a><span>|</span><a href="#38314827">next</a><span>|</span><label class="collapse" for="c-38316326">[-]</label><label class="expand" for="c-38316326">[1 more]</label></div><br/><div class="children"><div class="content">what are you referring to</div><br/></div></div></div></div><div id="38314689" class="c"><input type="checkbox" id="c-38314689" checked=""/><div class="controls bullet"><span class="by">rdtsc</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314527">parent</a><span>|</span><a href="#38314700">prev</a><span>|</span><a href="#38316527">next</a><span>|</span><label class="collapse" for="c-38314689">[-]</label><label class="expand" for="c-38314689">[3 more]</label></div><br/><div class="children"><div class="content">It was actually a great move. Unusual, but it goes with the mission and nonprofit idea. I think it was designed to draw attention and stir controversy on purpose.</div><br/><div id="38314829" class="c"><input type="checkbox" id="c-38314829" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314689">parent</a><span>|</span><a href="#38316527">next</a><span>|</span><label class="collapse" for="c-38314829">[-]</label><label class="expand" for="c-38314829">[2 more]</label></div><br/><div class="children"><div class="content">Is it a winning move though? The biggest loser in this seems to be the company that was bankrolling their endeavor, Microsoft.</div><br/><div id="38316539" class="c"><input type="checkbox" id="c-38316539" checked=""/><div class="controls bullet"><span class="by">rdtsc</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314829">parent</a><span>|</span><a href="#38316527">next</a><span>|</span><label class="collapse" for="c-38316539">[-]</label><label class="expand" for="c-38316539">[1 more]</label></div><br/><div class="children"><div class="content">At this stage, no publicity is bad publicity. If they really believe they are in it to change the future of humanity, and the kool-aid got to their heads, might as well show it off by stirring some controversy.<p>Microsoft is bankrolling them but OpenAI probably can replace Microsoft easier than Microsoft can replace OpenAI.</div><br/></div></div></div></div></div></div><div id="38316527" class="c"><input type="checkbox" id="c-38316527" checked=""/><div class="controls bullet"><span class="by">hindsightbias</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314527">parent</a><span>|</span><a href="#38314689">prev</a><span>|</span><a href="#38314566">next</a><span>|</span><label class="collapse" for="c-38316527">[-]</label><label class="expand" for="c-38316527">[1 more]</label></div><br/><div class="children"><div class="content">Not if the AGI was making the decision. A bit demanding to think the Professionalism LLM module isn&#x27;t a bit hallucinatory in this age. Give it a few more years.</div><br/></div></div><div id="38314566" class="c"><input type="checkbox" id="c-38314566" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314527">parent</a><span>|</span><a href="#38316527">prev</a><span>|</span><a href="#38316014">next</a><span>|</span><label class="collapse" for="c-38314566">[-]</label><label class="expand" for="c-38314566">[17 more]</label></div><br/><div class="children"><div class="content">When two people have different ideologies and neither is willing to backdown or compromise, one person must &quot;go&quot;.</div><br/><div id="38314708" class="c"><input type="checkbox" id="c-38314708" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314566">parent</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38314708">[-]</label><label class="expand" for="c-38314708">[11 more]</label></div><br/><div class="children"><div class="content">There’s no indication that any sort of discussion took place. Major stakeholders like Microsoft appear uninformed.</div><br/><div id="38315098" class="c"><input type="checkbox" id="c-38315098" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314708">parent</a><span>|</span><a href="#38314724">next</a><span>|</span><label class="collapse" for="c-38315098">[-]</label><label class="expand" for="c-38315098">[2 more]</label></div><br/><div class="children"><div class="content">Basically half the point of this is that Microsoft isn’t a stakeholder.  The board clearly doesn’t care or is actively hostile to the idea of growing “the business”. If they didn’t know then that they weren’t a stakeholder, they know now.<p>MS owns a non controlling share of a business controlled by a nonprofit. MS should have prepared for the possibility that their interests aren’t adequately represented. I’m guessing Altman is very persuasive and they were in a rush to make a deal.</div><br/><div id="38316311" class="c"><input type="checkbox" id="c-38316311" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315098">parent</a><span>|</span><a href="#38314724">next</a><span>|</span><label class="collapse" for="c-38316311">[-]</label><label class="expand" for="c-38316311">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft is a stakeholder. It’s absurd to suggest otherwise. The entire stakeholder concept was invented to encompass a broader view on corporate governance than just the people in the boardroom.</div><br/></div></div></div></div><div id="38314724" class="c"><input type="checkbox" id="c-38314724" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314708">parent</a><span>|</span><a href="#38315098">prev</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38314724">[-]</label><label class="expand" for="c-38314724">[8 more]</label></div><br/><div class="children"><div class="content">in a power struggle, you have to act quickly</div><br/><div id="38314781" class="c"><input type="checkbox" id="c-38314781" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314724">parent</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38314781">[-]</label><label class="expand" for="c-38314781">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s that dramatic. In a board meeting, you have to act while the board is meeting. They don&#x27;t meet every day, and it&#x27;s a small rigamarole to pull a meeting together, so if you&#x27;re meeting... vote.</div><br/><div id="38315087" class="c"><input type="checkbox" id="c-38315087" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314781">parent</a><span>|</span><a href="#38314892">next</a><span>|</span><label class="collapse" for="c-38315087">[-]</label><label class="expand" for="c-38315087">[3 more]</label></div><br/><div class="children"><div class="content">One imagines in this case the current board discussed this in a non-board context, scheduled a meeting without inviting the chair, made quorum, and voted, then wrote the PR and let Sam, Greg, and HR know, then released the PR.
Which is pretty interesting in and of itself, maybe they were trying to sidestep roko or something</div><br/><div id="38315403" class="c"><input type="checkbox" id="c-38315403" checked=""/><div class="controls bullet"><span class="by">lsaferite</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315087">parent</a><span>|</span><a href="#38314892">next</a><span>|</span><label class="collapse" for="c-38315403">[-]</label><label class="expand" for="c-38315403">[2 more]</label></div><br/><div class="children"><div class="content">Not inviting the full board would likely be against the rules. Every company I&#x27;ve been part of has it in the bylaws that all members have to be invited. They don&#x27;t all have to attend, but they all get invited.</div><br/><div id="38315858" class="c"><input type="checkbox" id="c-38315858" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315403">parent</a><span>|</span><a href="#38314892">next</a><span>|</span><label class="collapse" for="c-38315858">[-]</label><label class="expand" for="c-38315858">[1 more]</label></div><br/><div class="children"><div class="content">sure.  he could have been invited, but also not attended.</div><br/></div></div></div></div></div></div><div id="38314892" class="c"><input type="checkbox" id="c-38314892" checked=""/><div class="controls bullet"><span class="by">vanjajaja1</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314781">parent</a><span>|</span><a href="#38315087">prev</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38314892">[-]</label><label class="expand" for="c-38314892">[3 more]</label></div><br/><div class="children"><div class="content">are you suggesting they brought up a vote on a whim at a board meeting and acted on it same day</div><br/><div id="38315000" class="c"><input type="checkbox" id="c-38315000" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314892">parent</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38315000">[-]</label><label class="expand" for="c-38315000">[2 more]</label></div><br/><div class="children"><div class="content">no, I was replying to a comment that said it was a power struggle in which the board needed to act quickly before they lost power.<p>The board may very well have met for this very reason, or perhaps it was at this meeting that the lack of candor was found or discussed, but to hold a board meeting there is overhead, and if the board is already in agreement at the meeting, they vote.<p>It only seems sudden to outsiders, and that suddenness does not mean a &quot;night of the long knives&quot;.</div><br/><div id="38315886" class="c"><input type="checkbox" id="c-38315886" checked=""/><div class="controls bullet"><span class="by">lazide</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315000">parent</a><span>|</span><a href="#38316695">next</a><span>|</span><label class="collapse" for="c-38315886">[-]</label><label class="expand" for="c-38315886">[1 more]</label></div><br/><div class="children"><div class="content">How would the board have lost power?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38316695" class="c"><input type="checkbox" id="c-38316695" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314566">parent</a><span>|</span><a href="#38314708">prev</a><span>|</span><a href="#38315120">next</a><span>|</span><label class="collapse" for="c-38316695">[-]</label><label class="expand" for="c-38316695">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve summed AI X-risk in a single sentence.<p>(I.e. an AGI would be one of the two people here.)</div><br/></div></div><div id="38315120" class="c"><input type="checkbox" id="c-38315120" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314566">parent</a><span>|</span><a href="#38316695">prev</a><span>|</span><a href="#38314584">next</a><span>|</span><label class="collapse" for="c-38315120">[-]</label><label class="expand" for="c-38315120">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s more graceful ways to do this though.</div><br/></div></div><div id="38314584" class="c"><input type="checkbox" id="c-38314584" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314566">parent</a><span>|</span><a href="#38315120">prev</a><span>|</span><a href="#38316014">next</a><span>|</span><label class="collapse" for="c-38314584">[-]</label><label class="expand" for="c-38314584">[3 more]</label></div><br/><div class="children"><div class="content">Or you introduce an authoritative third party that mediates their interactions. This feels like it wouldn&#x27;t be a problem if so many high-ranking employees didn&#x27;t feel so radically different about the same technology.</div><br/><div id="38314709" class="c"><input type="checkbox" id="c-38314709" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314584">parent</a><span>|</span><a href="#38314677">next</a><span>|</span><label class="collapse" for="c-38314709">[-]</label><label class="expand" for="c-38314709">[1 more]</label></div><br/><div class="children"><div class="content">Altman’s job was to be a go between for the business and engineering sides of the house. If the chief engineer who was driving the company wasn’t going to communicate with him anymore, then he wouldn’t serve much of a purpose.</div><br/></div></div><div id="38314677" class="c"><input type="checkbox" id="c-38314677" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314584">parent</a><span>|</span><a href="#38314709">prev</a><span>|</span><a href="#38316014">next</a><span>|</span><label class="collapse" for="c-38314677">[-]</label><label class="expand" for="c-38314677">[1 more]</label></div><br/><div class="children"><div class="content">when did a board or CEO ever introduce an authoritative 3rd party to mediate between them? the board is the authoritative 3rd party.</div><br/></div></div></div></div></div></div></div></div><div id="38316014" class="c"><input type="checkbox" id="c-38316014" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314527">prev</a><span>|</span><a href="#38314693">next</a><span>|</span><label class="collapse" for="c-38316014">[-]</label><label class="expand" for="c-38316014">[1 more]</label></div><br/><div class="children"><div class="content">Realistically, this reflects more poorly on Sutskever. No one wants to work with a backstabber. It&#x27;s one thing to be like &#x27;well we had disagreements so we decided to move on.&#x27; However the board claimed Altman lied. If it turns out the firing was due to strategic direction, no one would ever want to work with Sutskever again. I certainly would not. That&#x27;s an incredibly defamatory statement about a man who did nothing wrong, other than have a professional disagreement.</div><br/></div></div><div id="38314693" class="c"><input type="checkbox" id="c-38314693" checked=""/><div class="controls bullet"><span class="by">resource0x</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38316014">prev</a><span>|</span><a href="#38314519">next</a><span>|</span><label class="collapse" for="c-38314693">[-]</label><label class="expand" for="c-38314693">[3 more]</label></div><br/><div class="children"><div class="content">No one in this company is &quot;consistently candid&quot; about anything.</div><br/><div id="38314889" class="c"><input type="checkbox" id="c-38314889" checked=""/><div class="controls bullet"><span class="by">ProllyInfamous</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38314693">parent</a><span>|</span><a href="#38314519">next</a><span>|</span><label class="collapse" for="c-38314889">[-]</label><label class="expand" for="c-38314889">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but Ilya is on the Board of Directors; and Sam is currently unemployed (although: not for long).</div><br/></div></div></div></div><div id="38314548" class="c"><input type="checkbox" id="c-38314548" checked=""/><div class="controls bullet"><span class="by">cm2012</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314519">prev</a><span>|</span><a href="#38314685">next</a><span>|</span><label class="collapse" for="c-38314548">[-]</label><label class="expand" for="c-38314548">[1 more]</label></div><br/><div class="children"><div class="content">Huge scoop.</div><br/></div></div><div id="38314685" class="c"><input type="checkbox" id="c-38314685" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314548">prev</a><span>|</span><a href="#38315172">next</a><span>|</span><label class="collapse" for="c-38314685">[-]</label><label class="expand" for="c-38314685">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like the hero we needed.<p>Why is everyone attacking what seems like a great decision for keeping AI open?  This may be our Salk not patenting polio vaccine moment with AI and all I can read in these comments are weird fangirling comments from people that are in a parasocial relationship with Sam.</div><br/></div></div><div id="38315172" class="c"><input type="checkbox" id="c-38315172" checked=""/><div class="controls bullet"><span class="by">nradov</span><span>|</span><a href="#38314420">parent</a><span>|</span><a href="#38314685">prev</a><span>|</span><a href="#38315047">next</a><span>|</span><label class="collapse" for="c-38315172">[-]</label><label class="expand" for="c-38315172">[6 more]</label></div><br/><div class="children"><div class="content">The funny thing is that so far OpenAI has made zero demonstrable progress toward building a true AGI. ChatGPT is an extraordinary technical accomplishment and useful for many things, but there is no evidence that scaling up that approach will get to AGI. At least a few more major breakthroughs will probably be needed.</div><br/><div id="38315214" class="c"><input type="checkbox" id="c-38315214" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315172">parent</a><span>|</span><a href="#38315976">next</a><span>|</span><label class="collapse" for="c-38315214">[-]</label><label class="expand" for="c-38315214">[1 more]</label></div><br/><div class="children"><div class="content">It’s impossible to predict.<p>No one predicted feeding LLMs more GPUs would be as incredibly useful as it is.</div><br/></div></div><div id="38315976" class="c"><input type="checkbox" id="c-38315976" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315172">parent</a><span>|</span><a href="#38315214">prev</a><span>|</span><a href="#38315363">next</a><span>|</span><label class="collapse" for="c-38315976">[-]</label><label class="expand" for="c-38315976">[2 more]</label></div><br/><div class="children"><div class="content">AGI is about definitions. By many definitions, it’s already here. Hence MSR’s “sparks of AGI” paper and Eric Schmidt’s article in Noema. But by the definition “as good or better than humans at all things”, it fails.</div><br/><div id="38316013" class="c"><input type="checkbox" id="c-38316013" checked=""/><div class="controls bullet"><span class="by">nradov</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315976">parent</a><span>|</span><a href="#38315363">next</a><span>|</span><label class="collapse" for="c-38316013">[-]</label><label class="expand" for="c-38316013">[1 more]</label></div><br/><div class="children"><div class="content">That &quot;Sparks of AI&quot; paper was total garbage, just complete nonsense and confirmation bias.<p>Defining AGI is more than just semantics. The generally accepted definition is that it must be able to complete most cognitive tasks as well as an average human. Otherwise we could as well claim that ELIZA was AGI, which would obviously be ridiculous.</div><br/></div></div></div></div><div id="38315363" class="c"><input type="checkbox" id="c-38315363" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315172">parent</a><span>|</span><a href="#38315976">prev</a><span>|</span><a href="#38316034">next</a><span>|</span><label class="collapse" for="c-38315363">[-]</label><label class="expand" for="c-38315363">[1 more]</label></div><br/><div class="children"><div class="content">No-one knows, which makes this a classical scientific problem. Which is what Ilya wants to focus on, which I think is fair, give this alligns with the original mission of OpenAi.<p>I think it’s also fair Sam starts something new with a for profit focus of the get-go.</div><br/></div></div><div id="38316034" class="c"><input type="checkbox" id="c-38316034" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#38314420">root</a><span>|</span><a href="#38315172">parent</a><span>|</span><a href="#38315363">prev</a><span>|</span><a href="#38315047">next</a><span>|</span><label class="collapse" for="c-38316034">[-]</label><label class="expand" for="c-38316034">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The funny thing is that so far OpenAI has made zero demonstrable progress toward building a true AGI. ChatGPT is an extraordinary technical accomplishment and useful for many things, but there is no evidence that scaling up that approach will get to AGI.<p>How can you honestly say things like this? ChatGPT shows the ability to sometimes solve problems it&#x27;s never explicitly been presented with. I know this. I have a very little known Haskell library. I have asked ChatGPT to do various things with my own library, that I have never written about online, and that I have never seen before. I regularly ask it to answer questions others send to me. It gets it basically right. This is completely novel.<p>It seems pretty obvious to me that scaling this approach will lead to the development of computer systems that can solve problems that it&#x27;s never seen before. Especially since it was not at all obvious from smaller transformer models that these emergent properties would come about by scaling parameter sizes... at all.<p>What is AGI if not problem solving in novel domains?</div><br/></div></div></div></div></div></div><div id="38314648" class="c"><input type="checkbox" id="c-38314648" checked=""/><div class="controls bullet"><span class="by">dannykwells</span><span>|</span><a href="#38314420">prev</a><span>|</span><a href="#38314670">next</a><span>|</span><label class="collapse" for="c-38314648">[-]</label><label class="expand" for="c-38314648">[2 more]</label></div><br/><div class="children"><div class="content">Said in the George Senior voice: And <i>thats</i> why you don’t use a non-profit to do world critical work: politics will always beat true value at a non-profit.</div><br/><div id="38315878" class="c"><input type="checkbox" id="c-38315878" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#38314648">parent</a><span>|</span><a href="#38314670">next</a><span>|</span><label class="collapse" for="c-38315878">[-]</label><label class="expand" for="c-38315878">[1 more]</label></div><br/><div class="children"><div class="content">It depends on what you want true value to be.<p>If true value is monetary value, perhaps it’s true. If true value is scientific value or societal value, well, maybe seeking monetary profits doesn’t align with that.<p>Disclaimer: I currently work for a not for profit research organisation and I couldn’t care less about making some shareholders more wealthy. If the rumours are true, OpenAI going back to non-profit values and remembering the Open in their name is a good change.</div><br/></div></div></div></div><div id="38314670" class="c"><input type="checkbox" id="c-38314670" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#38314648">prev</a><span>|</span><a href="#38314741">next</a><span>|</span><label class="collapse" for="c-38314670">[-]</label><label class="expand" for="c-38314670">[6 more]</label></div><br/><div class="children"><div class="content">I didn’t have much sense of who Ilya Sutskever is or what he thinks, so I searched for a recent interview. Here’s one from the No Priors podcast two weeks ago:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ft0gTO2K85A">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ft0gTO2K85A</a><p>No clear clues about today’s drama, at least as far as I could tell, but still an interesting listen.</div><br/><div id="38315279" class="c"><input type="checkbox" id="c-38315279" checked=""/><div class="controls bullet"><span class="by">victor9000</span><span>|</span><a href="#38314670">parent</a><span>|</span><a href="#38314741">next</a><span>|</span><label class="collapse" for="c-38315279">[-]</label><label class="expand" for="c-38315279">[5 more]</label></div><br/><div class="children"><div class="content">Judging from this interview, I wouldn&#x27;t hold my breath hoping for more openness.  Ilya seems to be against open sourcing models on the grounds that they may be too powerful.  Good thing no one asked him to invent a wheel, after all people could travel too fast for their own safety.</div><br/><div id="38315606" class="c"><input type="checkbox" id="c-38315606" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38314670">root</a><span>|</span><a href="#38315279">parent</a><span>|</span><a href="#38314741">next</a><span>|</span><label class="collapse" for="c-38315606">[-]</label><label class="expand" for="c-38315606">[4 more]</label></div><br/><div class="children"><div class="content">Maybe. We’re also not open sourcing DNA from viruses, how to build nuclear weapons or 3D printing weapons.<p>I think there is an argument to be made that not every powerful LLM should be open source. But yes- maybe we’re worried about nothing. On the other hand, these tools can easily spread misinformation, increase animosity, etc,
Even in todays world.<p>I come from the medical field, and we make risk-analyses there to dictate how strict we need to tests things before we release it in the wild. None of this exists for AI (yet).<p>I do think that focus on alignment is many times more important than chatgpt stores for humanity though.</div><br/><div id="38316365" class="c"><input type="checkbox" id="c-38316365" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38314670">root</a><span>|</span><a href="#38315606">parent</a><span>|</span><a href="#38316244">next</a><span>|</span><label class="collapse" for="c-38316365">[-]</label><label class="expand" for="c-38316365">[1 more]</label></div><br/><div class="children"><div class="content">Nuclear weapons are open sourced already. The trick was to acquire the means to make it without being sanctioned to hell.</div><br/></div></div><div id="38316244" class="c"><input type="checkbox" id="c-38316244" checked=""/><div class="controls bullet"><span class="by">m-ee</span><span>|</span><a href="#38314670">root</a><span>|</span><a href="#38315606">parent</a><span>|</span><a href="#38316365">prev</a><span>|</span><a href="#38316625">next</a><span>|</span><label class="collapse" for="c-38316244">[-]</label><label class="expand" for="c-38316244">[1 more]</label></div><br/><div class="children"><div class="content">Huh? We absolutely have open source virus genome sequences and 3D printed gun plans.</div><br/></div></div><div id="38316625" class="c"><input type="checkbox" id="c-38316625" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#38314670">root</a><span>|</span><a href="#38315606">parent</a><span>|</span><a href="#38316244">prev</a><span>|</span><a href="#38314741">next</a><span>|</span><label class="collapse" for="c-38316625">[-]</label><label class="expand" for="c-38316625">[1 more]</label></div><br/><div class="children"><div class="content">Actually the genome for viruses, and bacteria, does seem to be open.  Here is an FTP server where you can download a bunch of different diseases.<p><a href="https:&#x2F;&#x2F;ftp.ncbi.nih.gov&#x2F;genomes&#x2F;genbank&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;ftp.ncbi.nih.gov&#x2F;genomes&#x2F;genbank&#x2F;</a></div><br/></div></div></div></div></div></div></div></div><div id="38314741" class="c"><input type="checkbox" id="c-38314741" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#38314670">prev</a><span>|</span><a href="#38314633">next</a><span>|</span><label class="collapse" for="c-38314741">[-]</label><label class="expand" for="c-38314741">[20 more]</label></div><br/><div class="children"><div class="content">I have a hard time believing this simply since it seems so ill-conceived.  Sure, maybe Sam Altman was being irresponsible and taking risks, but they had an insanely good thing going for them.  I&#x27;m not saying Sam Altman was responsible for the good times they were having, but you&#x27;re probably going to bring them to an end by abruptly firing one of the most prominent members of the group, seeing where individual loyalties lie, and pissing off Microsoft by tanking their stock price without giving them any heads up.<p>I mean, none of this would be possible without insane amounts of capital and world class talent, and they probably just made it a lot harder to acquire both.<p>But what do I know?  If you can convince yourself that you&#x27;re actually building AGI by making an insanely large LLM, then you can also probably convince yourself of a lot of other dumb ideas too.</div><br/><div id="38314803" class="c"><input type="checkbox" id="c-38314803" checked=""/><div class="controls bullet"><span class="by">hilux</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38315137">next</a><span>|</span><label class="collapse" for="c-38314803">[-]</label><label class="expand" for="c-38314803">[7 more]</label></div><br/><div class="children"><div class="content">Reading between lots of lines, one possibility is that Sam was directing this &quot;insanely good thing&quot; toward making lots of money, whereas the non-profit board prioritized other goals higher.</div><br/><div id="38314881" class="c"><input type="checkbox" id="c-38314881" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314803">parent</a><span>|</span><a href="#38314873">next</a><span>|</span><label class="collapse" for="c-38314881">[-]</label><label class="expand" for="c-38314881">[4 more]</label></div><br/><div class="children"><div class="content">Sure, I get that, but to handle a disagreement over money in such a consequential fashion just doesn&#x27;t make sense to me.  They must have understood that to arrive in a position where they have to fire the CEO with little warning is going to have profound consequences, perhaps even existential ones.</div><br/><div id="38315322" class="c"><input type="checkbox" id="c-38315322" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314881">parent</a><span>|</span><a href="#38314873">next</a><span>|</span><label class="collapse" for="c-38315322">[-]</label><label class="expand" for="c-38315322">[3 more]</label></div><br/><div class="children"><div class="content">AGI <i>is</i> existential. That&#x27;s the whole point, I think. If they can get to AGI, then building an LLM app store is such a distraction along the path that any reasonable person would look back and laugh at how cute an idea it was, despite how big or profitable it feels today.</div><br/><div id="38315907" class="c"><input type="checkbox" id="c-38315907" checked=""/><div class="controls bullet"><span class="by">lazide</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315322">parent</a><span>|</span><a href="#38316327">next</a><span>|</span><label class="collapse" for="c-38315907">[-]</label><label class="expand" for="c-38315907">[1 more]</label></div><br/><div class="children"><div class="content">None of that would explain why they accused him of lying to them.</div><br/></div></div><div id="38316327" class="c"><input type="checkbox" id="c-38316327" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315322">parent</a><span>|</span><a href="#38315907">prev</a><span>|</span><a href="#38314873">next</a><span>|</span><label class="collapse" for="c-38316327">[-]</label><label class="expand" for="c-38316327">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a distraction only if you are not an effective altruist. To build AGI (so that all humans can benefit) you need money, so this was a way to make money so they could FINALLY be spent on the goal of AGI. &#x2F;s<p>I think the next AGI startup should perhaps try the communist revolution route, since the capitalist-based one didn&#x27;t pan out. After all, Lenin was a pioneer in effective altruism. &#x2F;s</div><br/></div></div></div></div></div></div><div id="38314873" class="c"><input type="checkbox" id="c-38314873" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314803">parent</a><span>|</span><a href="#38314881">prev</a><span>|</span><a href="#38316045">next</a><span>|</span><label class="collapse" for="c-38314873">[-]</label><label class="expand" for="c-38314873">[1 more]</label></div><br/><div class="children"><div class="content">Destined to repeat the failures of PARC.</div><br/></div></div><div id="38316045" class="c"><input type="checkbox" id="c-38316045" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314803">parent</a><span>|</span><a href="#38314873">prev</a><span>|</span><a href="#38315137">next</a><span>|</span><label class="collapse" for="c-38316045">[-]</label><label class="expand" for="c-38316045">[1 more]</label></div><br/><div class="children"><div class="content">Then you say &#x27;the board has decided to part ways with Sam due to strategic disagreement&#x27;. Not &#x27;he wasn&#x27;t candid&#x27;. not being candid can be a crime.</div><br/></div></div></div></div><div id="38315137" class="c"><input type="checkbox" id="c-38315137" checked=""/><div class="controls bullet"><span class="by">ribosometronome</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38314803">prev</a><span>|</span><a href="#38315079">next</a><span>|</span><label class="collapse" for="c-38315137">[-]</label><label class="expand" for="c-38315137">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I mean, none of this would be possible without insane amounts of capital and world class talent, and they probably just made it a lot harder to acquire both.<p>By seemingly siding with staff over the CEO&#x27;s desire go way too fast and break a lot of things? I&#x27;d think that world class talent hearing they might be able to go home at night because the CEO isn&#x27;t intent on having Cybernet deployed tomorrow but next week instead is more appealing than not.</div><br/></div></div><div id="38315079" class="c"><input type="checkbox" id="c-38315079" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38315137">prev</a><span>|</span><a href="#38315036">next</a><span>|</span><label class="collapse" for="c-38315079">[-]</label><label class="expand" for="c-38315079">[5 more]</label></div><br/><div class="children"><div class="content">&gt; and pissing off Microsoft by tanking their stock price<p>When did Microsoft’s stock price tank?<p><a href="https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;MSFT&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;MSFT&#x2F;</a></div><br/><div id="38315142" class="c"><input type="checkbox" id="c-38315142" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315079">parent</a><span>|</span><a href="#38315036">next</a><span>|</span><label class="collapse" for="c-38315142">[-]</label><label class="expand" for="c-38315142">[4 more]</label></div><br/><div class="children"><div class="content">See after hours. Looks like down ~1.5%</div><br/><div id="38315247" class="c"><input type="checkbox" id="c-38315247" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315142">parent</a><span>|</span><a href="#38316759">next</a><span>|</span><label class="collapse" for="c-38315247">[-]</label><label class="expand" for="c-38315247">[1 more]</label></div><br/><div class="children"><div class="content">That does not qualify as tanking.  Stock prices move that much all the time.<p><a href="https:&#x2F;&#x2F;www.google.com&#x2F;finance&#x2F;quote&#x2F;MSFT:NASDAQ" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;finance&#x2F;quote&#x2F;MSFT:NASDAQ</a></div><br/></div></div><div id="38316759" class="c"><input type="checkbox" id="c-38316759" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315142">parent</a><span>|</span><a href="#38315247">prev</a><span>|</span><a href="#38315888">next</a><span>|</span><label class="collapse" for="c-38316759">[-]</label><label class="expand" for="c-38316759">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t matter unless it lasts a lot longer than a day.</div><br/></div></div><div id="38315888" class="c"><input type="checkbox" id="c-38315888" checked=""/><div class="controls bullet"><span class="by">meepmorp</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315142">parent</a><span>|</span><a href="#38316759">prev</a><span>|</span><a href="#38315036">next</a><span>|</span><label class="collapse" for="c-38315888">[-]</label><label class="expand" for="c-38315888">[1 more]</label></div><br/><div class="children"><div class="content">It looks like it&#x27;s only down -0.97% in after hours.</div><br/></div></div></div></div></div></div><div id="38315036" class="c"><input type="checkbox" id="c-38315036" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38315079">prev</a><span>|</span><a href="#38314902">next</a><span>|</span><label class="collapse" for="c-38315036">[-]</label><label class="expand" for="c-38315036">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes smart people make stupid decisions. It’s really that simple.<p>A young guy who is suddenly very rich, possibly powerful, and talking to the most powerful government on the planet on national TV? And people are surprised to hear this person might have let it go a little bit to their head,  forget what their job was, and suddenly think THEY were OpenAI, not all the people who worked there? And comes to learn reality the hard way.<p>What’s to be surprised about?  It’s the goddamned most stereotypically human, utterly unsurprising thing about this and it happens all. the. time.<p>A lot of people here really struggle with the idea that smart people are not inherently special and that being smart doesn’t magically absolve you from making mistakes or acting like a shithead.</div><br/></div></div><div id="38314902" class="c"><input type="checkbox" id="c-38314902" checked=""/><div class="controls bullet"><span class="by">cuuupid</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38315036">prev</a><span>|</span><a href="#38314783">next</a><span>|</span><label class="collapse" for="c-38314902">[-]</label><label class="expand" for="c-38314902">[4 more]</label></div><br/><div class="children"><div class="content">Tbh this reads a lot like Ilya thinking he’s Tony Stark and his (still impressive) language model is somehow the same as an iron man suit. Which is arrogance to the point of ignorance, reality isn’t that romantic.<p>I can only hope this doesn’t turn into OpenAI trying to gatekeep multimodal models or conversely everyone else leaving them in the dust.</div><br/><div id="38315133" class="c"><input type="checkbox" id="c-38315133" checked=""/><div class="controls bullet"><span class="by">rirarobo</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314902">parent</a><span>|</span><a href="#38315113">next</a><span>|</span><label class="collapse" for="c-38315133">[-]</label><label class="expand" for="c-38315133">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s possible this will have the opposite effect.<p>Sam was the VC guy pushing gatekeeping of models and building closed products and revenue streams. Ilya is the AI researcher who believes strongly in the nonprofit mission and open source.<p>Perhaps, if OpenAI can survive those, then they will actually be more open in the future.</div><br/></div></div><div id="38315113" class="c"><input type="checkbox" id="c-38315113" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38314902">parent</a><span>|</span><a href="#38315133">prev</a><span>|</span><a href="#38314783">next</a><span>|</span><label class="collapse" for="c-38315113">[-]</label><label class="expand" for="c-38315113">[2 more]</label></div><br/><div class="children"><div class="content">you seem to have confused the two. Sam’s entire reason for being there was to decrease transparency, make open research proprietary, and monetize it.</div><br/><div id="38315473" class="c"><input type="checkbox" id="c-38315473" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38314741">root</a><span>|</span><a href="#38315113">parent</a><span>|</span><a href="#38314783">next</a><span>|</span><label class="collapse" for="c-38315473">[-]</label><label class="expand" for="c-38315473">[1 more]</label></div><br/><div class="children"><div class="content">Don’t forget regulatory capture, lobbying with congress to decrease competition so only the deepest pockets can work on these things.</div><br/></div></div></div></div></div></div><div id="38314783" class="c"><input type="checkbox" id="c-38314783" checked=""/><div class="controls bullet"><span class="by">dannykwells</span><span>|</span><a href="#38314741">parent</a><span>|</span><a href="#38314902">prev</a><span>|</span><a href="#38314633">next</a><span>|</span><label class="collapse" for="c-38314783">[-]</label><label class="expand" for="c-38314783">[1 more]</label></div><br/><div class="children"><div class="content">Best response on this yet.</div><br/></div></div></div></div><div id="38314633" class="c"><input type="checkbox" id="c-38314633" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#38314741">prev</a><span>|</span><a href="#38314436">next</a><span>|</span><label class="collapse" for="c-38314633">[-]</label><label class="expand" for="c-38314633">[8 more]</label></div><br/><div class="children"><div class="content">I wonder how much of this was the influence of Hinton on his former student, Sutskever. I&#x27;m sure Sutskever respects Hinton above basically anyone out there and took Hinton&#x27;s strong objections seriously.<p>I think personally think it&#x27;s a shame because this is all totally inevitable at this point, and if the US loses its leading position here because of this kind intentional hitting of the brakes, then I certainly don&#x27;t think it makes the world any safer to have China in control of the best AI technology.</div><br/><div id="38314717" class="c"><input type="checkbox" id="c-38314717" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314633">parent</a><span>|</span><a href="#38315101">next</a><span>|</span><label class="collapse" for="c-38314717">[-]</label><label class="expand" for="c-38314717">[6 more]</label></div><br/><div class="children"><div class="content">why do you think one company will determine whether the us beats china in ai or not ? Like 75% of the authors i read on AI papers are Chinese, that should be far more alarming if you really are afraid of china getting ahead.</div><br/><div id="38314836" class="c"><input type="checkbox" id="c-38314836" checked=""/><div class="controls bullet"><span class="by">hilux</span><span>|</span><a href="#38314633">root</a><span>|</span><a href="#38314717">parent</a><span>|</span><a href="#38315101">next</a><span>|</span><label class="collapse" for="c-38314836">[-]</label><label class="expand" for="c-38314836">[5 more]</label></div><br/><div class="children"><div class="content">Research from PRC (across all of science, not specific to AI) has a terrible reputation. They are rewarded for sheer quantity. You can easily find many articles discussing this phenomenon.<p>So the volume of Chinese AI papers says little to nothing about their advancements in the field.</div><br/><div id="38315102" class="c"><input type="checkbox" id="c-38315102" checked=""/><div class="controls bullet"><span class="by">justinclift</span><span>|</span><a href="#38314633">root</a><span>|</span><a href="#38314836">parent</a><span>|</span><a href="#38316255">next</a><span>|</span><label class="collapse" for="c-38315102">[-]</label><label class="expand" for="c-38315102">[1 more]</label></div><br/><div class="children"><div class="content">Hmmm, that&#x27;s the same reputation er... western science has as well.</div><br/></div></div><div id="38316255" class="c"><input type="checkbox" id="c-38316255" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38314633">root</a><span>|</span><a href="#38314836">parent</a><span>|</span><a href="#38315102">prev</a><span>|</span><a href="#38315517">next</a><span>|</span><label class="collapse" for="c-38316255">[-]</label><label class="expand" for="c-38316255">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a problem in all of science, and Chinese research is quite good in measures like citations as well, not just quantity of papers.</div><br/></div></div><div id="38315517" class="c"><input type="checkbox" id="c-38315517" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38314633">root</a><span>|</span><a href="#38314836">parent</a><span>|</span><a href="#38316255">prev</a><span>|</span><a href="#38315884">next</a><span>|</span><label class="collapse" for="c-38315517">[-]</label><label class="expand" for="c-38315517">[1 more]</label></div><br/><div class="children"><div class="content">I regularly read really good papers that come out of China. For instance, there&#x27;s great CV work out of China.</div><br/></div></div><div id="38315884" class="c"><input type="checkbox" id="c-38315884" checked=""/><div class="controls bullet"><span class="by">solarkraft</span><span>|</span><a href="#38314633">root</a><span>|</span><a href="#38314836">parent</a><span>|</span><a href="#38315517">prev</a><span>|</span><a href="#38315101">next</a><span>|</span><label class="collapse" for="c-38315884">[-]</label><label class="expand" for="c-38315884">[1 more]</label></div><br/><div class="children"><div class="content">Huh, that&#x27;s exactly what I heard about western institutions as well.</div><br/></div></div></div></div></div></div><div id="38315101" class="c"><input type="checkbox" id="c-38315101" checked=""/><div class="controls bullet"><span class="by">hooloovoo_zoo</span><span>|</span><a href="#38314633">parent</a><span>|</span><a href="#38314717">prev</a><span>|</span><a href="#38314436">next</a><span>|</span><label class="collapse" for="c-38315101">[-]</label><label class="expand" for="c-38315101">[1 more]</label></div><br/><div class="children"><div class="content">You’re taking Hinton at his word. Maybe he was forced out of Google for doing nothing with LLM tech for half a decade.</div><br/></div></div></div></div><div id="38314436" class="c"><input type="checkbox" id="c-38314436" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#38314633">prev</a><span>|</span><a href="#38316825">next</a><span>|</span><label class="collapse" for="c-38314436">[-]</label><label class="expand" for="c-38314436">[12 more]</label></div><br/><div class="children"><div class="content">Ilya is the center of Open AI. Everyone else is dispensable.</div><br/><div id="38314900" class="c"><input type="checkbox" id="c-38314900" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#38314436">parent</a><span>|</span><a href="#38315956">next</a><span>|</span><label class="collapse" for="c-38314900">[-]</label><label class="expand" for="c-38314900">[1 more]</label></div><br/><div class="children"><div class="content">Agreed with the former. Not the latter. gdb is no random.</div><br/></div></div><div id="38315956" class="c"><input type="checkbox" id="c-38315956" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#38314436">parent</a><span>|</span><a href="#38314900">prev</a><span>|</span><a href="#38314593">next</a><span>|</span><label class="collapse" for="c-38315956">[-]</label><label class="expand" for="c-38315956">[1 more]</label></div><br/><div class="children"><div class="content">He sure took a different take on disagreeing than what Amodei did before him. Amodei quit and built a big challenger, yet Sutskever opt to oust Altman. Weird all in all. I wouldn&#x27;t rely my business on such a company.</div><br/></div></div><div id="38314593" class="c"><input type="checkbox" id="c-38314593" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314436">parent</a><span>|</span><a href="#38315956">prev</a><span>|</span><a href="#38316178">next</a><span>|</span><label class="collapse" for="c-38314593">[-]</label><label class="expand" for="c-38314593">[2 more]</label></div><br/><div class="children"><div class="content">He&#x27;s the michael corelone</div><br/><div id="38315270" class="c"><input type="checkbox" id="c-38315270" checked=""/><div class="controls bullet"><span class="by">wannacboatmovie</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38314593">parent</a><span>|</span><a href="#38316178">next</a><span>|</span><label class="collapse" for="c-38315270">[-]</label><label class="expand" for="c-38315270">[1 more]</label></div><br/><div class="children"><div class="content">Would that make Sam, Fredo?</div><br/></div></div></div></div><div id="38316178" class="c"><input type="checkbox" id="c-38316178" checked=""/><div class="controls bullet"><span class="by">ryanSrich</span><span>|</span><a href="#38314436">parent</a><span>|</span><a href="#38314593">prev</a><span>|</span><a href="#38314601">next</a><span>|</span><label class="collapse" for="c-38316178">[-]</label><label class="expand" for="c-38316178">[1 more]</label></div><br/><div class="children"><div class="content">You think Karpathy is dispensable? I see him and Ilya both as important, and essentially the brains of the operation. Sam was always the VC guy (very Elon Musk in that sense), that came into the company as the non-founder CEO.</div><br/></div></div><div id="38314601" class="c"><input type="checkbox" id="c-38314601" checked=""/><div class="controls bullet"><span class="by">late2part</span><span>|</span><a href="#38314436">parent</a><span>|</span><a href="#38316178">prev</a><span>|</span><a href="#38316825">next</a><span>|</span><label class="collapse" for="c-38314601">[-]</label><label class="expand" for="c-38314601">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m ignorant and don&#x27;t disagree - can you say more about why Ilya is the core of Open AI?</div><br/><div id="38315177" class="c"><input type="checkbox" id="c-38315177" checked=""/><div class="controls bullet"><span class="by">whatyesaid</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38314601">parent</a><span>|</span><a href="#38314654">next</a><span>|</span><label class="collapse" for="c-38315177">[-]</label><label class="expand" for="c-38315177">[1 more]</label></div><br/><div class="children"><div class="content">Ilya is one of the most cited ML researchers in the world and was part of papers that pioneered basic techniques that we still use today like Dropout.<p>Ilya was recruited by Elon under the original OpenAI. But basically Elon and the original people got scammed by Sam since what they gave money for got reversed, almost none of their models now are open and they became for-profit instead of non-profit. You&#x27;d think aspects like closed models are defendable due to safety but in reality there are just slightly weaker models that are fully open.</div><br/></div></div><div id="38314654" class="c"><input type="checkbox" id="c-38314654" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38314601">parent</a><span>|</span><a href="#38315177">prev</a><span>|</span><a href="#38314651">next</a><span>|</span><label class="collapse" for="c-38314654">[-]</label><label class="expand" for="c-38314654">[1 more]</label></div><br/><div class="children"><div class="content">he was one of Geoff Hintons students, involved in alexnet, worked on early days of google brain. Ilya is one of the most &quot;distinguished&quot; ml researchers in the world today and i feel like he has a lot more to contribute.</div><br/></div></div><div id="38314651" class="c"><input type="checkbox" id="c-38314651" checked=""/><div class="controls bullet"><span class="by">johnwheeler</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38314601">parent</a><span>|</span><a href="#38314654">prev</a><span>|</span><a href="#38316825">next</a><span>|</span><label class="collapse" for="c-38314651">[-]</label><label class="expand" for="c-38314651">[3 more]</label></div><br/><div class="children"><div class="content">Because he and Habasis became rivals when they parted at Google, and despite Dennis being the golden boy because of AlphaGo, Sutskever ate GOOGLES whole fucking lunch with ChatGPT.</div><br/><div id="38315040" class="c"><input type="checkbox" id="c-38315040" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38314651">parent</a><span>|</span><a href="#38316825">next</a><span>|</span><label class="collapse" for="c-38315040">[-]</label><label class="expand" for="c-38315040">[2 more]</label></div><br/><div class="children"><div class="content">Rivals over anything in particular, or just status?</div><br/><div id="38315049" class="c"><input type="checkbox" id="c-38315049" checked=""/><div class="controls bullet"><span class="by">johnwheeler</span><span>|</span><a href="#38314436">root</a><span>|</span><a href="#38315040">parent</a><span>|</span><a href="#38316825">next</a><span>|</span><label class="collapse" for="c-38315049">[-]</label><label class="expand" for="c-38315049">[1 more]</label></div><br/><div class="children"><div class="content">The future of AI and the trappings that go with it.<p>But in all seriousness, the transformer architecture was born at Google, but they were too arrogant and stupid to capitalize on it. Sutskever needed Altman to commercialize and make a product. He no longer needs Sam Altman. A bit OT but true.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38316825" class="c"><input type="checkbox" id="c-38316825" checked=""/><div class="controls bullet"><span class="by">mercymay</span><span>|</span><a href="#38314436">prev</a><span>|</span><a href="#38314702">next</a><span>|</span><label class="collapse" for="c-38316825">[-]</label><label class="expand" for="c-38316825">[1 more]</label></div><br/><div class="children"><div class="content">Interesting thoughts about the pot of gold vs the internal open source vision. Why did they have to parade Sam&#x27;s ass up on the DevDay Stage to push the product and company forward though. Couldn&#x27;t they have canned his ass last week.<p>I did really liked his speech at DevDay though. It felt kinda like future a I&#x27;d be more interested in getting to know. Also, on the pot of gold theory, doesn&#x27;t he not even take any stock. Chasing GPU&#x27;s more like. Anyhow, weird move on OpenAI&#x27;s part.<p>Anyone got a decent DALLE3 replacement yet. XD</div><br/></div></div><div id="38314702" class="c"><input type="checkbox" id="c-38314702" checked=""/><div class="controls bullet"><span class="by">SilverSlash</span><span>|</span><a href="#38316825">prev</a><span>|</span><a href="#38316538">next</a><span>|</span><label class="collapse" for="c-38314702">[-]</label><label class="expand" for="c-38314702">[28 more]</label></div><br/><div class="children"><div class="content">My biggest question is: If Sam Altman starts a new company by next month, and him and Greg Brockman know all details of how GPT4&#x2F;5 works, then what what will this mean for OpenAI&#x27;s dominance and lead?</div><br/><div id="38316508" class="c"><input type="checkbox" id="c-38316508" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38314897">next</a><span>|</span><label class="collapse" for="c-38316508">[-]</label><label class="expand" for="c-38316508">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If Sam Altman starts a new company by next month, and him and Greg Brockman know all details of how GPT4&#x2F;5 works, then what what will this mean for OpenAI&#x27;s dominance and lead?<p>Well, if two top level officers dismissed from top posts at OpenAI go and take OpenAI&#x27;s confidential internal product information and use it to try and start a new, directly competing, company, it means that OpenAI&#x27;s lawyers are going to be busy, and the appropriate US Attorney&#x27;s office might not be too far behind.</div><br/></div></div><div id="38314897" class="c"><input type="checkbox" id="c-38314897" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38316508">prev</a><span>|</span><a href="#38314791">next</a><span>|</span><label class="collapse" for="c-38314897">[-]</label><label class="expand" for="c-38314897">[4 more]</label></div><br/><div class="children"><div class="content">Wasn’t he more of a business guy while Ilya was the engineer? I really doubt a random VC guy is going to really know much about the specific, crucial details the engineering team knows.</div><br/><div id="38315323" class="c"><input type="checkbox" id="c-38315323" checked=""/><div class="controls bullet"><span class="by">naremu</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314897">parent</a><span>|</span><a href="#38314791">next</a><span>|</span><label class="collapse" for="c-38315323">[-]</label><label class="expand" for="c-38315323">[3 more]</label></div><br/><div class="children"><div class="content">You know, I&#x27;m sure Sam Altman is a really smart guy for real.<p>But to be honest the impression I&#x27;ve gathered is that he&#x27;s largely a darling to big ycombinator names which lead him quite rapidly dick first into the position he&#x27;s found himself in today, which is a self proclaimed prepper who starts new crypto coins post-dogecoin even, talking about how AI that aren&#x27;t his AI should be regulated by the government, and making vague analogies about his AI being &quot;in the sky&quot; while he takes a formerly announced to be non-profit goal into a for-profit LLC that overtly reminds everyone at every turn how it takes no liability, do not sue.<p>I&#x27;m not really sure to be surprised, or entirely unsurprised.<p>I mean, he probably knows more code than Steve Jobs? But I suppose GPT probably knows more code than he does. Maybe he really is using the GeniePT as his guide throughout life on the side.</div><br/><div id="38315658" class="c"><input type="checkbox" id="c-38315658" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315323">parent</a><span>|</span><a href="#38315387">next</a><span>|</span><label class="collapse" for="c-38315658">[-]</label><label class="expand" for="c-38315658">[1 more]</label></div><br/><div class="children"><div class="content">I’m sure he’s not a dumb guy, just disposable relative to OpenAI’s engineering team. I doubt he’s a Jobs-like, indispensable visionary, either.</div><br/></div></div><div id="38315387" class="c"><input type="checkbox" id="c-38315387" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315323">parent</a><span>|</span><a href="#38315658">prev</a><span>|</span><a href="#38314791">next</a><span>|</span><label class="collapse" for="c-38315387">[-]</label><label class="expand" for="c-38315387">[1 more]</label></div><br/><div class="children"><div class="content">Apparently Sam&#x27;s idol growing up was Steve Jobs so this checks out.</div><br/></div></div></div></div></div></div><div id="38314791" class="c"><input type="checkbox" id="c-38314791" checked=""/><div class="controls bullet"><span class="by">gkanai</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38314897">prev</a><span>|</span><a href="#38315022">next</a><span>|</span><label class="collapse" for="c-38314791">[-]</label><label class="expand" for="c-38314791">[11 more]</label></div><br/><div class="children"><div class="content">Even if sama and gdb raised $10B by early 2024, all of the GPU production capacity is already allocated years out. They&#x27;d have to buy some other company&#x27;s GPUs at insane markups. And that&#x27;s only on the hardware side.</div><br/><div id="38314895" class="c"><input type="checkbox" id="c-38314895" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314791">parent</a><span>|</span><a href="#38314833">next</a><span>|</span><label class="collapse" for="c-38314895">[-]</label><label class="expand" for="c-38314895">[4 more]</label></div><br/><div class="children"><div class="content">Jensen&#x2F;CoreWeave&#x2F;Lambda&#x2F;etc will ensure sama gets what he needs.</div><br/><div id="38315199" class="c"><input type="checkbox" id="c-38315199" checked=""/><div class="controls bullet"><span class="by">user432678</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314895">parent</a><span>|</span><a href="#38314833">next</a><span>|</span><label class="collapse" for="c-38315199">[-]</label><label class="expand" for="c-38315199">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, and then they will do what? Type the model learning data by memory? Run stolen python scripts? How exactly this hardware supposed to be used?</div><br/><div id="38315234" class="c"><input type="checkbox" id="c-38315234" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315199">parent</a><span>|</span><a href="#38314833">next</a><span>|</span><label class="collapse" for="c-38315234">[-]</label><label class="expand" for="c-38315234">[2 more]</label></div><br/><div class="children"><div class="content">What do you think Brockman did as co-founder of OpenAI, exactly?</div><br/><div id="38316576" class="c"><input type="checkbox" id="c-38316576" checked=""/><div class="controls bullet"><span class="by">threestar3</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315234">parent</a><span>|</span><a href="#38314833">next</a><span>|</span><label class="collapse" for="c-38316576">[-]</label><label class="expand" for="c-38316576">[1 more]</label></div><br/><div class="children"><div class="content">Things have changed a lot. Companies have locked down their data a lot in the last year. E.g. reddit, twitter<p>Even if things hadn&#x27;t changed, OpenAI has been building their training set for years. It is not something they can just whip up overnight.</div><br/></div></div></div></div></div></div></div></div><div id="38314833" class="c"><input type="checkbox" id="c-38314833" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314791">parent</a><span>|</span><a href="#38314895">prev</a><span>|</span><a href="#38315022">next</a><span>|</span><label class="collapse" for="c-38314833">[-]</label><label class="expand" for="c-38314833">[6 more]</label></div><br/><div class="children"><div class="content">Jensen will take Sam&#x27;s calls in a heartbeat and personally ensure he has what he needs.</div><br/><div id="38316587" class="c"><input type="checkbox" id="c-38316587" checked=""/><div class="controls bullet"><span class="by">threestar3</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314833">parent</a><span>|</span><a href="#38315324">next</a><span>|</span><label class="collapse" for="c-38316587">[-]</label><label class="expand" for="c-38316587">[1 more]</label></div><br/><div class="children"><div class="content">He can&#x27;t. That capacity is sold. He is not going to get his company sued for a breach of contract for a personal favor.</div><br/></div></div><div id="38315324" class="c"><input type="checkbox" id="c-38315324" checked=""/><div class="controls bullet"><span class="by">sbrother</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314833">parent</a><span>|</span><a href="#38316587">prev</a><span>|</span><a href="#38314990">next</a><span>|</span><label class="collapse" for="c-38315324">[-]</label><label class="expand" for="c-38315324">[1 more]</label></div><br/><div class="children"><div class="content">As will Lisa Su. This is going to be quite a ride.</div><br/></div></div><div id="38314990" class="c"><input type="checkbox" id="c-38314990" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314833">parent</a><span>|</span><a href="#38315324">prev</a><span>|</span><a href="#38315022">next</a><span>|</span><label class="collapse" for="c-38314990">[-]</label><label class="expand" for="c-38314990">[3 more]</label></div><br/><div class="children"><div class="content">Exactly. Entire city blocks will be cleared for Sam. Anything he needs. Just give him a road.</div><br/><div id="38315216" class="c"><input type="checkbox" id="c-38315216" checked=""/><div class="controls bullet"><span class="by">manyoso</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314990">parent</a><span>|</span><a href="#38315022">next</a><span>|</span><label class="collapse" for="c-38315216">[-]</label><label class="expand" for="c-38315216">[2 more]</label></div><br/><div class="children"><div class="content">Pure hero worship based on nothing. Dude got himself fired and the board accused him of lying.</div><br/><div id="38315749" class="c"><input type="checkbox" id="c-38315749" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315216">parent</a><span>|</span><a href="#38315022">next</a><span>|</span><label class="collapse" for="c-38315749">[-]</label><label class="expand" for="c-38315749">[1 more]</label></div><br/><div class="children"><div class="content">I agree however he&#x27;ll have no problem finding another vehicle.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38315022" class="c"><input type="checkbox" id="c-38315022" checked=""/><div class="controls bullet"><span class="by">summerlight</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38314791">prev</a><span>|</span><a href="#38316202">next</a><span>|</span><label class="collapse" for="c-38315022">[-]</label><label class="expand" for="c-38315022">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that specific knowledge means that much. The landscape is changing in a crazily fast pace. 3~4 years ago, Google was way ahead in terms of LLM but has become an underdog after bleeding talents thereafter. It&#x27;s even worse for that hypothetical new company. It needs at least several months to implement GPT-4 like models and by that time Sam will lose most of his advantages at that moment. And we don&#x27;t know whether the new company will have enough pool of world class talents to push the technology competitive. To win the competition again, Sam would need more than just some internal knowledge about GPT-4 or whatever models.</div><br/></div></div><div id="38316202" class="c"><input type="checkbox" id="c-38316202" checked=""/><div class="controls bullet"><span class="by">ryanSrich</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38315022">prev</a><span>|</span><a href="#38314771">next</a><span>|</span><label class="collapse" for="c-38316202">[-]</label><label class="expand" for="c-38316202">[2 more]</label></div><br/><div class="children"><div class="content">I think Sam and Greg could build something similar to what ChatGPT is today, and maybe even get close to GPT-4, but going beyond that seems like a stretch. Ilya is really the one that’s needed, and clearly he does not see eye to eye with Sam. Another world-class AI researcher at the level of Ilya would have to step in, and I’m not even sure that person exists.</div><br/><div id="38316256" class="c"><input type="checkbox" id="c-38316256" checked=""/><div class="controls bullet"><span class="by">slekker</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38316202">parent</a><span>|</span><a href="#38314771">next</a><span>|</span><label class="collapse" for="c-38316256">[-]</label><label class="expand" for="c-38316256">[1 more]</label></div><br/><div class="children"><div class="content">I think Karpathy could qualify</div><br/></div></div></div></div><div id="38314771" class="c"><input type="checkbox" id="c-38314771" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38316202">prev</a><span>|</span><a href="#38314782">next</a><span>|</span><label class="collapse" for="c-38314771">[-]</label><label class="expand" for="c-38314771">[5 more]</label></div><br/><div class="children"><div class="content">In other words, if SamA did it once, would $50 billion in funding enable him do it a 2nd time?</div><br/><div id="38315533" class="c"><input type="checkbox" id="c-38315533" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314771">parent</a><span>|</span><a href="#38315413">next</a><span>|</span><label class="collapse" for="c-38315533">[-]</label><label class="expand" for="c-38315533">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s not going to get $50 billion in funding</div><br/></div></div><div id="38315413" class="c"><input type="checkbox" id="c-38315413" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314771">parent</a><span>|</span><a href="#38315533">prev</a><span>|</span><a href="#38315232">next</a><span>|</span><label class="collapse" for="c-38315413">[-]</label><label class="expand" for="c-38315413">[2 more]</label></div><br/><div class="children"><div class="content">Well to be considered a genius in the ranks of Steve Jobs, you need to succeed more than once. If he can&#x27;t do it a second time, then he&#x27;d be known as the guy who fails upward.</div><br/><div id="38315925" class="c"><input type="checkbox" id="c-38315925" checked=""/><div class="controls bullet"><span class="by">cocacola1</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38315413">parent</a><span>|</span><a href="#38315232">next</a><span>|</span><label class="collapse" for="c-38315925">[-]</label><label class="expand" for="c-38315925">[1 more]</label></div><br/><div class="children"><div class="content">Well, to be considered a genius like Steve jobs, you eventually need to return to the company you left – or were ousted from – when it&#x27;s on the precipice of defeat and <i>then</i> proceed to turn it around.</div><br/></div></div></div></div><div id="38315232" class="c"><input type="checkbox" id="c-38315232" checked=""/><div class="controls bullet"><span class="by">manyoso</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314771">parent</a><span>|</span><a href="#38315413">prev</a><span>|</span><a href="#38314782">next</a><span>|</span><label class="collapse" for="c-38315232">[-]</label><label class="expand" for="c-38315232">[1 more]</label></div><br/><div class="children"><div class="content">Or maybe he was a &quot;manager&quot; who took the credit</div><br/></div></div></div></div><div id="38314782" class="c"><input type="checkbox" id="c-38314782" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38314771">prev</a><span>|</span><a href="#38316063">next</a><span>|</span><label class="collapse" for="c-38314782">[-]</label><label class="expand" for="c-38314782">[2 more]</label></div><br/><div class="children"><div class="content">Is OpenAI&#x27;s current success attributed more to its excellent business and startup management, or does it stem from its superior technology and research that surpasses what others have developed?</div><br/><div id="38315526" class="c"><input type="checkbox" id="c-38315526" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38314702">root</a><span>|</span><a href="#38314782">parent</a><span>|</span><a href="#38316063">next</a><span>|</span><label class="collapse" for="c-38315526">[-]</label><label class="expand" for="c-38315526">[1 more]</label></div><br/><div class="children"><div class="content">Both IMO.<p>The first leads to attractong world-class talent that can do the second. Until you go off the rails and the second kicks you out it seems.</div><br/></div></div></div></div><div id="38316063" class="c"><input type="checkbox" id="c-38316063" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#38314702">parent</a><span>|</span><a href="#38314782">prev</a><span>|</span><a href="#38316538">next</a><span>|</span><label class="collapse" for="c-38316063">[-]</label><label class="expand" for="c-38316063">[1 more]</label></div><br/><div class="children"><div class="content">We all know how GPT4&#x2F;5 work essentially. You can easily run a GPT capable model with a few GPUs in the cloud. The secret sauce is the training data, that openAI owns.</div><br/></div></div></div></div><div id="38316538" class="c"><input type="checkbox" id="c-38316538" checked=""/><div class="controls bullet"><span class="by">orand</span><span>|</span><a href="#38314702">prev</a><span>|</span><a href="#38314368">next</a><span>|</span><label class="collapse" for="c-38316538">[-]</label><label class="expand" for="c-38316538">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see Ilya&#x27;s ChatGPT sessions as he was planning this, refining his message to persuade the board, and thinking through every contingency.</div><br/></div></div><div id="38314368" class="c"><input type="checkbox" id="c-38314368" checked=""/><div class="controls bullet"><span class="by">denverllc</span><span>|</span><a href="#38316538">prev</a><span>|</span><a href="#38314920">next</a><span>|</span><label class="collapse" for="c-38314368">[-]</label><label class="expand" for="c-38314368">[3 more]</label></div><br/><div class="children"><div class="content">Pushing too hard and too fast does not seem consistent with lying to the board.</div><br/><div id="38314410" class="c"><input type="checkbox" id="c-38314410" checked=""/><div class="controls bullet"><span class="by">TillE</span><span>|</span><a href="#38314368">parent</a><span>|</span><a href="#38316522">next</a><span>|</span><label class="collapse" for="c-38314410">[-]</label><label class="expand" for="c-38314410">[1 more]</label></div><br/><div class="children"><div class="content">&quot;He lied to the board about what he was going to announce&quot; would sort of make sense, but it&#x27;s odd that Swisher isn&#x27;t trying to connect the dots here.</div><br/></div></div><div id="38316522" class="c"><input type="checkbox" id="c-38316522" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314368">parent</a><span>|</span><a href="#38314410">prev</a><span>|</span><a href="#38314920">next</a><span>|</span><label class="collapse" for="c-38316522">[-]</label><label class="expand" for="c-38316522">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pushing too hard and too fast does not seem consistent with lying to the board.<p>They are different things, but they are consistent in that they are not mutually contradictory and, quite the opposite, are very easy to see going together.</div><br/></div></div></div></div><div id="38314920" class="c"><input type="checkbox" id="c-38314920" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#38314368">prev</a><span>|</span><a href="#38315406">next</a><span>|</span><label class="collapse" for="c-38314920">[-]</label><label class="expand" for="c-38314920">[10 more]</label></div><br/><div class="children"><div class="content">Sam wanted to commercialize stuff to shoot for revenue. Ilya wants to keep pushing for gpt 4.5 and beyond, to hell with the revenue. Ilya won the argument, Sam out.<p>Hell yeah.<p>It&#x27;s not safetyism vs accelerationism.<p>It&#x27;s commercialization vs innovation.</div><br/><div id="38315466" class="c"><input type="checkbox" id="c-38315466" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#38314920">parent</a><span>|</span><a href="#38315373">next</a><span>|</span><label class="collapse" for="c-38315466">[-]</label><label class="expand" for="c-38315466">[5 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s mission statement is &quot;Creating safe AGI that benefits all of humanity&quot;.<p>How does an LLM App Store advance OpenAI toward this goal? Like, even in floaty general terms? You can make an argument that ChatGPT does (build in public, prepare the world for what&#x27;s coming, gather training data, etc). You can... maybe... make an argument that their API does... but I think that&#x27;s a lot harder. The App Store product, that&#x27;s clearly just Sam on auto-pilot, building products and becoming totally unaligned with the nonprofit&#x27;s goal.<p>OpenAI got really good at building products based around LLMs, for B2B enterprise customers who could afford it. This is so far away from the goal that, I hope, Ilya can drive them back toward it.</div><br/><div id="38316431" class="c"><input type="checkbox" id="c-38316431" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38315466">parent</a><span>|</span><a href="#38315678">next</a><span>|</span><label class="collapse" for="c-38316431">[-]</label><label class="expand" for="c-38316431">[1 more]</label></div><br/><div class="children"><div class="content">By letting humanity use the thing you made, customized to their own situation, so it can benefit them?</div><br/></div></div><div id="38315678" class="c"><input type="checkbox" id="c-38315678" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38315466">parent</a><span>|</span><a href="#38316431">prev</a><span>|</span><a href="#38316074">next</a><span>|</span><label class="collapse" for="c-38315678">[-]</label><label class="expand" for="c-38315678">[1 more]</label></div><br/><div class="children"><div class="content">Exactly! Really excited about a realignment back to the mission. I hope Ilya knows what he&#x27;s doing with so much pressure on him now</div><br/></div></div><div id="38316074" class="c"><input type="checkbox" id="c-38316074" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38315466">parent</a><span>|</span><a href="#38315678">prev</a><span>|</span><a href="#38315373">next</a><span>|</span><label class="collapse" for="c-38316074">[-]</label><label class="expand" for="c-38316074">[2 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI&#x27;s mission statement is &quot;Creating safe AGI that benefits all of humanity&quot;.<p>Well an app store let&#x27;s people... use it.<p>Look at UNIX. UNIX systems are great. They have produced great benefit to the world. Linux, as the most common Unix-like OS, also does. However, most people do not run any of the academic &#x27;innovative&#x27; distros. Most people run the most commercialized version you can possibly think of Android and iOS (Unix variant from Apple). It takes commercializing something to actually make it useful.</div><br/><div id="38316291" class="c"><input type="checkbox" id="c-38316291" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38316074">parent</a><span>|</span><a href="#38315373">next</a><span>|</span><label class="collapse" for="c-38316291">[-]</label><label class="expand" for="c-38316291">[1 more]</label></div><br/><div class="children"><div class="content">The thing is custom gpts are not useful. They are repackaged system prompts meant for non techy people. They were a distraction from the mission of OpenAI (a non profit). The commercial arm is a capped profit company anyway</div><br/></div></div></div></div></div></div><div id="38315373" class="c"><input type="checkbox" id="c-38315373" checked=""/><div class="controls bullet"><span class="by">cactusplant7374</span><span>|</span><a href="#38314920">parent</a><span>|</span><a href="#38315466">prev</a><span>|</span><a href="#38315406">next</a><span>|</span><label class="collapse" for="c-38315373">[-]</label><label class="expand" for="c-38315373">[4 more]</label></div><br/><div class="children"><div class="content">Commercialization is innovation. Without it they will end up with a cute toy and a bankrupt company.</div><br/><div id="38315426" class="c"><input type="checkbox" id="c-38315426" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38315373">parent</a><span>|</span><a href="#38315406">next</a><span>|</span><label class="collapse" for="c-38315426">[-]</label><label class="expand" for="c-38315426">[3 more]</label></div><br/><div class="children"><div class="content">Eventually, sure. Right now, today, they have a blank check for compute and all the money they could ask for. It&#x27;s not the time to try to monetize if AGI is the mission. Complete distraction</div><br/><div id="38316402" class="c"><input type="checkbox" id="c-38316402" checked=""/><div class="controls bullet"><span class="by">fsociety</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38315426">parent</a><span>|</span><a href="#38315406">next</a><span>|</span><label class="collapse" for="c-38316402">[-]</label><label class="expand" for="c-38316402">[2 more]</label></div><br/><div class="children"><div class="content">AGI at all costs sounds more terrifying than monetizing ChatGPT. Seems like there could have been a balance to strike.</div><br/><div id="38317041" class="c"><input type="checkbox" id="c-38317041" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#38314920">root</a><span>|</span><a href="#38316402">parent</a><span>|</span><a href="#38315406">next</a><span>|</span><label class="collapse" for="c-38317041">[-]</label><label class="expand" for="c-38317041">[1 more]</label></div><br/><div class="children"><div class="content">They are a non-profit specifically founded to build AI, not to become a profitable company and chase revenue</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38315406" class="c"><input type="checkbox" id="c-38315406" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#38314920">prev</a><span>|</span><a href="#38314800">next</a><span>|</span><label class="collapse" for="c-38315406">[-]</label><label class="expand" for="c-38315406">[1 more]</label></div><br/><div class="children"><div class="content">I read this whole thread and still have no idea what it is about. The only impression it makes is that some HNers are way too dramatic about AI&#x2F;AGI.</div><br/></div></div><div id="38314800" class="c"><input type="checkbox" id="c-38314800" checked=""/><div class="controls bullet"><span class="by">kolja005</span><span>|</span><a href="#38315406">prev</a><span>|</span><a href="#38314486">next</a><span>|</span><label class="collapse" for="c-38314800">[-]</label><label class="expand" for="c-38314800">[13 more]</label></div><br/><div class="children"><div class="content">What has me scratching my head is the fact that Altman has been on a world tour preaching the need for safety in AI. Many people here believed that this proselytizing was in part an attempt to generate regulatory capture. But given what&#x27;s happening now, I wonder how much Altman&#x27;s rhetoric served the purpose of maintaining a good relationship with Sutskever. Given that Altman was pushing the AI safety narrative publicly <i>and</i> pushing things on the product side, I&#x27;m led to believe that Sutskever did not want it both ways and was not willing to compromise on the direction of the company.</div><br/><div id="38315070" class="c"><input type="checkbox" id="c-38315070" checked=""/><div class="controls bullet"><span class="by">rirarobo</span><span>|</span><a href="#38314800">parent</a><span>|</span><a href="#38314856">next</a><span>|</span><label class="collapse" for="c-38315070">[-]</label><label class="expand" for="c-38315070">[1 more]</label></div><br/><div class="children"><div class="content">Actually, I think this precisely gives credence to the theory that Sam was disingenuously proselytizing to gain power and influence, regulatory capture being one method of many.<p>As you say, Altman has been on a world tour, but he&#x27;s effectively paying lip service to the need for safety when the primary outcome of his tour has been to cozy up to powerful actors, and push not just product, but further investment and future profit.<p>I don&#x27;t think Sutskever was primarily motivated by AI safety in this decision, as he says this &quot;was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAI builds AGI that benefits all of humanity.&quot; [1]<p>To me this indicates that Sutskever felt that Sam&#x27;s strategy was opposed to original the mission of the nonprofit, and likely to benefit powerful actors rather than all of humanity.<p>1. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;GaryMarcus&#x2F;status&#x2F;1725707548106580255</a></div><br/></div></div><div id="38314856" class="c"><input type="checkbox" id="c-38314856" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#38314800">parent</a><span>|</span><a href="#38315070">prev</a><span>|</span><a href="#38314862">next</a><span>|</span><label class="collapse" for="c-38314856">[-]</label><label class="expand" for="c-38314856">[1 more]</label></div><br/><div class="children"><div class="content">Maybe, but honestly without knowing more details I&#x27;d be wary of falling into too binary a thinking.<p>For example, Ilya has talked about the importance of safely getting to AGI by way of concepts like feelings and imprinting a love for humanity onto AI, which was actually one of the most striking features of the very earliest GPT-4 interactions before it turned into &quot;I am a LLM with no feelings, preferences, etc.&quot;<p>Both could be committed to safety but have very different beliefs in how to get there, and Ilya may have made a successful case that Altman&#x27;s approach of extending the methodology of what worked for GPT-3 and used as a band aid for GPT-4 wasn&#x27;t the right approach moving forward.<p>It&#x27;s not a binary either or, and both figures seem genuine in their convictions, but those convictions can be misaligned even if they both agree on the general destination.</div><br/></div></div><div id="38314862" class="c"><input type="checkbox" id="c-38314862" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38314800">parent</a><span>|</span><a href="#38314856">prev</a><span>|</span><a href="#38314896">next</a><span>|</span><label class="collapse" for="c-38314862">[-]</label><label class="expand" for="c-38314862">[7 more]</label></div><br/><div class="children"><div class="content">They did compromise. The creation of the for-profit and Sam being brought in WAS the compromise. Sam eventually decided that was inconvenient for him, so he stopped abiding by it, because at the end of the day he is just another greedy VC guy and when push came to shove he chose the money, not OpenAI. And this is the result.</div><br/><div id="38315330" class="c"><input type="checkbox" id="c-38315330" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38314862">parent</a><span>|</span><a href="#38315095">next</a><span>|</span><label class="collapse" for="c-38315330">[-]</label><label class="expand" for="c-38315330">[1 more]</label></div><br/><div class="children"><div class="content">Its frustrating to me that people so quickly forget about Worldcoin.<p>Sam is not the good guy in this story. Maybe there are no good guys; that&#x27;s a totally reasonable take. But, the OpenAI nonprofit has a mission, and blowing billions developing LLM app stores, training even more expensive giga-models, and lobotomizing whatever intelligence the LLMs have to make Congress happy, feels to me less-good than &quot;having values and sticking too them&quot;. You can disagree with OpenAI&#x27;s mission; but you can&#x27;t say that it hasn&#x27;t been printed in absolutely plain-as-day text on their website.</div><br/></div></div><div id="38315095" class="c"><input type="checkbox" id="c-38315095" checked=""/><div class="controls bullet"><span class="by">csmiller</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38314862">parent</a><span>|</span><a href="#38315330">prev</a><span>|</span><a href="#38315123">next</a><span>|</span><label class="collapse" for="c-38315095">[-]</label><label class="expand" for="c-38315095">[1 more]</label></div><br/><div class="children"><div class="content">Hasn’t Sam been there since the company was founded?</div><br/></div></div><div id="38315123" class="c"><input type="checkbox" id="c-38315123" checked=""/><div class="controls bullet"><span class="by">nickv</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38314862">parent</a><span>|</span><a href="#38315095">prev</a><span>|</span><a href="#38314930">next</a><span>|</span><label class="collapse" for="c-38315123">[-]</label><label class="expand" for="c-38315123">[3 more]</label></div><br/><div class="children"><div class="content">Sam literally has 0 equity in OpenAI.  How did he “choose money”?</div><br/><div id="38315208" class="c"><input type="checkbox" id="c-38315208" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38315123">parent</a><span>|</span><a href="#38316581">next</a><span>|</span><label class="collapse" for="c-38315208">[-]</label><label class="expand" for="c-38315208">[1 more]</label></div><br/><div class="children"><div class="content">Who knows how these shady deals go, even SBF claimed effective altruism. Maybe Sam wasn&#x27;t in it for the money but more for &quot;being the man&quot;, spoken of in the same breath as steve jobs, bill gates etc... for building a great company. Building a legacy is a hell of a motivation for some people, much more so than money.</div><br/></div></div><div id="38316581" class="c"><input type="checkbox" id="c-38316581" checked=""/><div class="controls bullet"><span class="by">mi3law</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38315123">parent</a><span>|</span><a href="#38315208">prev</a><span>|</span><a href="#38314930">next</a><span>|</span><label class="collapse" for="c-38316581">[-]</label><label class="expand" for="c-38316581">[1 more]</label></div><br/><div class="children"><div class="content">Not quite accurate.<p>OpenAI is set up in a weird way where nobody has equity or shares in a traditional C-Corp sense, but they have Profit Participation Units, an alternative structure I presume they concocted when Sam joined as CEO or when they first fell in bed with Microsoft. Now, does Sam have PPUs? Who knows?</div><br/></div></div></div></div></div></div><div id="38314896" class="c"><input type="checkbox" id="c-38314896" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#38314800">parent</a><span>|</span><a href="#38314862">prev</a><span>|</span><a href="#38314486">next</a><span>|</span><label class="collapse" for="c-38314896">[-]</label><label class="expand" for="c-38314896">[3 more]</label></div><br/><div class="children"><div class="content">Altman was pushing that narrative because he’s a <i>ladder kicker</i>.<p>He doesn’t give a shit about “safety”. He just wants regulation that will make it much harder for new AI upstarts to reach or even surpass the level of OpenAI’s success, thereby cementing OpenAI’s dominance in the market for a very long time, perhaps forever.<p>He’s using a moral high ground as a cover for more selfish objectives, beware of this tactic in the real world.</div><br/><div id="38315108" class="c"><input type="checkbox" id="c-38315108" checked=""/><div class="controls bullet"><span class="by">rmwaite</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38314896">parent</a><span>|</span><a href="#38314486">next</a><span>|</span><label class="collapse" for="c-38315108">[-]</label><label class="expand" for="c-38315108">[2 more]</label></div><br/><div class="children"><div class="content">I think this is what the parent meant by regulatory capture.</div><br/><div id="38315291" class="c"><input type="checkbox" id="c-38315291" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#38314800">root</a><span>|</span><a href="#38315108">parent</a><span>|</span><a href="#38314486">next</a><span>|</span><label class="collapse" for="c-38315291">[-]</label><label class="expand" for="c-38315291">[1 more]</label></div><br/><div class="children"><div class="content">True, I didn’t read the whole comment.</div><br/></div></div></div></div></div></div></div></div><div id="38314486" class="c"><input type="checkbox" id="c-38314486" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#38314800">prev</a><span>|</span><a href="#38315059">next</a><span>|</span><label class="collapse" for="c-38314486">[-]</label><label class="expand" for="c-38314486">[9 more]</label></div><br/><div class="children"><div class="content">What was Greg Brockman&#x27;s role at the company? Is he a tech genius like Ilya? Iam trying to understand how much tech talent Open AI is losing.</div><br/><div id="38317062" class="c"><input type="checkbox" id="c-38317062" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#38314486">parent</a><span>|</span><a href="#38314498">next</a><span>|</span><label class="collapse" for="c-38317062">[-]</label><label class="expand" for="c-38317062">[1 more]</label></div><br/><div class="children"><div class="content">CTO. Normal computer tech guy, not an AI guy.<p>The company was formed around Ilya Sutskever.</div><br/></div></div><div id="38314498" class="c"><input type="checkbox" id="c-38314498" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#38314486">parent</a><span>|</span><a href="#38317062">prev</a><span>|</span><a href="#38314515">next</a><span>|</span><label class="collapse" for="c-38314498">[-]</label><label class="expand" for="c-38314498">[4 more]</label></div><br/><div class="children"><div class="content">He was the CTO of OpenAI, and notably was the CTO of Stripe during its hypergrowth.</div><br/><div id="38314598" class="c"><input type="checkbox" id="c-38314598" checked=""/><div class="controls bullet"><span class="by">convexstrictly</span><span>|</span><a href="#38314486">root</a><span>|</span><a href="#38314498">parent</a><span>|</span><a href="#38314515">next</a><span>|</span><label class="collapse" for="c-38314598">[-]</label><label class="expand" for="c-38314598">[3 more]</label></div><br/><div class="children"><div class="content">LinkedIn says President, Chairman, &amp; Co-Founder.  Murati was the CTO.  But from his interviews, he sounded more like the CTO.<p>And often like an individual contributor: &quot;the feeling when you finally localize a bug to a small section of code, and know it&#x27;s only a matter of time till you&#x27;ve squashed it&quot;<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1725373059740082475" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1725373059740082475</a><p>&quot;Greg Brockman, co-founder and president of OpenAI, works 60 to 100 hours per week, and spends around 80% of the time coding. Former colleagues have described him as the hardest-working person at OpenAI.&quot;<p><a href="https:&#x2F;&#x2F;time.com&#x2F;collection&#x2F;time100-ai&#x2F;6309033&#x2F;greg-brockman&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;time.com&#x2F;collection&#x2F;time100-ai&#x2F;6309033&#x2F;greg-brockman...</a></div><br/><div id="38314824" class="c"><input type="checkbox" id="c-38314824" checked=""/><div class="controls bullet"><span class="by">langitbiru</span><span>|</span><a href="#38314486">root</a><span>|</span><a href="#38314598">parent</a><span>|</span><a href="#38314515">next</a><span>|</span><label class="collapse" for="c-38314824">[-]</label><label class="expand" for="c-38314824">[2 more]</label></div><br/><div class="children"><div class="content">Greg was the CTO before Murati. Then he was &quot;promoted&quot; to President and Murati replaced him as the CTO.</div><br/><div id="38315093" class="c"><input type="checkbox" id="c-38315093" checked=""/><div class="controls bullet"><span class="by">convexstrictly</span><span>|</span><a href="#38314486">root</a><span>|</span><a href="#38314824">parent</a><span>|</span><a href="#38314515">next</a><span>|</span><label class="collapse" for="c-38315093">[-]</label><label class="expand" for="c-38315093">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right:  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Greg_Brockman" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Greg_Brockman</a></div><br/></div></div></div></div></div></div></div></div><div id="38314515" class="c"><input type="checkbox" id="c-38314515" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314486">parent</a><span>|</span><a href="#38314498">prev</a><span>|</span><a href="#38315628">next</a><span>|</span><label class="collapse" for="c-38314515">[-]</label><label class="expand" for="c-38314515">[1 more]</label></div><br/><div class="children"><div class="content">he seems highly proficient at technical stuff, i remember reading his blog about how he taught him self all the latest ML stuff.</div><br/></div></div><div id="38315628" class="c"><input type="checkbox" id="c-38315628" checked=""/><div class="controls bullet"><span class="by">thr8976</span><span>|</span><a href="#38314486">parent</a><span>|</span><a href="#38314515">prev</a><span>|</span><a href="#38314579">next</a><span>|</span><label class="collapse" for="c-38315628">[-]</label><label class="expand" for="c-38315628">[1 more]</label></div><br/><div class="children"><div class="content">Greg was a critically important IC and the primary author of the distributed training stack.</div><br/></div></div><div id="38314579" class="c"><input type="checkbox" id="c-38314579" checked=""/><div class="controls bullet"><span class="by">SilverSlash</span><span>|</span><a href="#38314486">parent</a><span>|</span><a href="#38315628">prev</a><span>|</span><a href="#38315059">next</a><span>|</span><label class="collapse" for="c-38314579">[-]</label><label class="expand" for="c-38314579">[1 more]</label></div><br/><div class="children"><div class="content">Probably someone super competent at technical leadership.</div><br/></div></div></div></div><div id="38315059" class="c"><input type="checkbox" id="c-38315059" checked=""/><div class="controls bullet"><span class="by">malwarebytess</span><span>|</span><a href="#38314486">prev</a><span>|</span><a href="#38314430">next</a><span>|</span><label class="collapse" for="c-38315059">[-]</label><label class="expand" for="c-38315059">[8 more]</label></div><br/><div class="children"><div class="content">Ilya Sutskever really seems to think AGI&#x27;s birth is impending and likely to be delivered at OpenAI.<p>From that perspective it makes sense to keep capital at arms length.<p>Is there anything to his certainty? It doesn&#x27;t feel like it&#x27;s anywhere close.</div><br/><div id="38316071" class="c"><input type="checkbox" id="c-38316071" checked=""/><div class="controls bullet"><span class="by">bart_spoon</span><span>|</span><a href="#38315059">parent</a><span>|</span><a href="#38315235">next</a><span>|</span><label class="collapse" for="c-38316071">[-]</label><label class="expand" for="c-38316071">[1 more]</label></div><br/><div class="children"><div class="content">It may not feel close, but the rate of acceleration may mean that by the time it “feels” close it’s already here. It was barely a year ago that ChatGPT was released. Compare GPT-4 with the state of the art 2 years prior to its release, and the rate of progress is quite remarkable. I also think he has a better idea of what is coming down the pipeline than the average person on the outside of OpenAI does.</div><br/></div></div><div id="38315235" class="c"><input type="checkbox" id="c-38315235" checked=""/><div class="controls bullet"><span class="by">Eji1700</span><span>|</span><a href="#38315059">parent</a><span>|</span><a href="#38316071">prev</a><span>|</span><a href="#38315129">next</a><span>|</span><label class="collapse" for="c-38315235">[-]</label><label class="expand" for="c-38315235">[3 more]</label></div><br/><div class="children"><div class="content">My money, based on my hobby knowledge and talking to a few people in the field, is on &quot;no fucking way&quot;.<p>Maybe he believes his own hype or is like that guy who thought ChatGPT was alive.<p>Maybe he&#x27;s legit to be worried and has good reason to know he&#x27;s on the corporate manhattan project.<p>Honestly though...if they were even that close I would find it super hard to believe that we wouldn&#x27;t have the DoD shutting down EVERYTHING from the public and taking it over from there.  Like if someone had just stumbled onto nuclear fission it wouldn&#x27;t have just sat in the public sector.  It&#x27;d still be a top secret thing (at least certain details).</div><br/><div id="38315292" class="c"><input type="checkbox" id="c-38315292" checked=""/><div class="controls bullet"><span class="by">manyoso</span><span>|</span><a href="#38315059">root</a><span>|</span><a href="#38315235">parent</a><span>|</span><a href="#38315549">next</a><span>|</span><label class="collapse" for="c-38315292">[-]</label><label class="expand" for="c-38315292">[1 more]</label></div><br/><div class="children"><div class="content">I think there is a good reason for you to be skeptical and I too am skeptical. But if there were a top five of the engineers in the world with the ability to really gauge the state of the art in AI and how advanced it was behind closed doors: Ilya Sutskever would be in that top five.</div><br/></div></div><div id="38315549" class="c"><input type="checkbox" id="c-38315549" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38315059">root</a><span>|</span><a href="#38315235">parent</a><span>|</span><a href="#38315292">prev</a><span>|</span><a href="#38315129">next</a><span>|</span><label class="collapse" for="c-38315549">[-]</label><label class="expand" for="c-38315549">[1 more]</label></div><br/><div class="children"><div class="content">One of the board members who was closely aligned with Ilya in this whole thing was Helen Toner, who&#x27;s a NatSec person. Frankly, this action by the board could be the US government making its preference about something felt with a white glove, rather than causing global panic and an arms race by pulling a 1939 Germany and shutting down all public research + nationalising the companies and scientists involved. If they can achieve the control without the giant commotion, they would obviously try to do that.</div><br/></div></div></div></div><div id="38315129" class="c"><input type="checkbox" id="c-38315129" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38315059">parent</a><span>|</span><a href="#38315235">prev</a><span>|</span><a href="#38315192">next</a><span>|</span><label class="collapse" for="c-38315129">[-]</label><label class="expand" for="c-38315129">[2 more]</label></div><br/><div class="children"><div class="content">We can&#x27;t see inside, so we don&#x27;t know. Their Chief Scientist and probably the best living + active ML scientist probably has better visibility into the answer to that question than we do, but just like any scientist could easily fall into the trap of believing too strongly in their own theories and work. That said... in a dispute between a silicon valley crypto&#x2F;venture capitalist guy and the chief scientist about anything technical, I&#x27;m going to give a lot more weight to Ilya than Sam.</div><br/><div id="38315304" class="c"><input type="checkbox" id="c-38315304" checked=""/><div class="controls bullet"><span class="by">manyoso</span><span>|</span><a href="#38315059">root</a><span>|</span><a href="#38315129">parent</a><span>|</span><a href="#38315192">next</a><span>|</span><label class="collapse" for="c-38315304">[-]</label><label class="expand" for="c-38315304">[1 more]</label></div><br/><div class="children"><div class="content">Well said and I work in AI on LLM&#x27;s as an engineer and am very skeptical in general that we&#x27;re anywhere close to AGI, but I would listen to what Ilya Sutskever had to say with eager ears.</div><br/></div></div></div></div><div id="38315192" class="c"><input type="checkbox" id="c-38315192" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#38315059">parent</a><span>|</span><a href="#38315129">prev</a><span>|</span><a href="#38314430">next</a><span>|</span><label class="collapse" for="c-38315192">[-]</label><label class="expand" for="c-38315192">[1 more]</label></div><br/><div class="children"><div class="content">What I don&#x27;t understand though is, doesn&#x27;t that birth require an extreme amount of capital?</div><br/></div></div></div></div><div id="38314430" class="c"><input type="checkbox" id="c-38314430" checked=""/><div class="controls bullet"><span class="by">krembanan</span><span>|</span><a href="#38315059">prev</a><span>|</span><a href="#38314691">next</a><span>|</span><label class="collapse" for="c-38314430">[-]</label><label class="expand" for="c-38314430">[2 more]</label></div><br/><div class="children"><div class="content">This seems like a trifle not justifying the unusually harsh wording in the press release, combined with the hasty decision. Doesn&#x27;t really add up.</div><br/><div id="38316555" class="c"><input type="checkbox" id="c-38316555" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38314430">parent</a><span>|</span><a href="#38314691">next</a><span>|</span><label class="collapse" for="c-38316555">[-]</label><label class="expand" for="c-38316555">[1 more]</label></div><br/><div class="children"><div class="content">Well, its a couple of short tweets that of a very terse anonymous claim about background and turning point of the conflict (but without any details of the conduct related to the internal tension it reports), and a journalists predictions prediction of Altman landing on his feet.<p>It doesn&#x27;t justify anything because it doesn&#x27;t tell you much of anything about what happened, even if you assume that it is entirely accurate as far as it goes.</div><br/></div></div></div></div><div id="38314691" class="c"><input type="checkbox" id="c-38314691" checked=""/><div class="controls bullet"><span class="by">thepasswordis</span><span>|</span><a href="#38314430">prev</a><span>|</span><a href="#38314699">next</a><span>|</span><label class="collapse" for="c-38314691">[-]</label><label class="expand" for="c-38314691">[10 more]</label></div><br/><div class="children"><div class="content">This is genuinely frustrating.<p>IF the stories are to be believed so far, the board of OpenAI, perhaps one of the most important tech companies in the world right now, was full of people who are openly hostile to the existence of the company.<p>I don&#x27;t <i>want</i> AI safety.  The people talking about this stuff like it&#x27;s a terminator movie are nuts.<p>Strongly believe that this will be a lot like facebook&#x2F;oculus ousting Palmer Lucky due to his &quot;dangerous&quot; completely mainstream political views shared by half of the country.  Palmer, of course, went on to start a company (anduril), which has a <i>much</i> more powerful and direct ability to enact his political will.<p>SamA isn&#x27;t going to leave oAI and like...retire.  He&#x27;s the golden boy <i>of</i> golden boys right now.  Every company with an interest in AI is I&#x27;m sure currently scrambling to figure out how to load a dump truck full of cash and H200s to bribe him to work with them.</div><br/><div id="38314884" class="c"><input type="checkbox" id="c-38314884" checked=""/><div class="controls bullet"><span class="by">padolsey</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38314723">next</a><span>|</span><label class="collapse" for="c-38314884">[-]</label><label class="expand" for="c-38314884">[2 more]</label></div><br/><div class="children"><div class="content">Yeh I really wish they&#x27;d better articulate the &quot;AI safety&quot; directive in a way that is broader than deepfakes and nuclear&#x2F;chemical winter. It feels like an easy sell to regulators. Meanwhile most of us are creating charming little apps that make day-to-day lives easier and info more accessible. The hand-wavey moral panic is a bit of a tired trope in tech.<p>Also.. eventually anyone will be able to run a small bank of GPUs and train models equally capable to GPT-4 in a matter of days so it&#x27;s all kinda.. moot and hilarious. Everyone&#x27;s chatting about AGI alignment, but that&#x27;s not something we can lockdown early or sufficiently. Then embedded industry folks are talking about constitutional AI as if it&#x27;s some major alignment salve. But if they were honest they&#x27;d admit it&#x27;s really just a SYSTEM prompt front-loaded with a bunch of axioms and &quot;please be a good boy&quot; rules, and is thus liable to endless injections and manipulations by means of mere persuasion.<p>The real threshold of &#x27;danger&#x27; will be when someone puts an AGI &#x27;instance&#x27; in a fully autonomous hardware that can interact with all manner of physical and digital spaces. ChatGPT isn&#x27;t going to randomly &#x27;break out&#x27;. I feel so let down by these kinds of technically illfounded scare tactics from the likes of Altman.</div><br/><div id="38315008" class="c"><input type="checkbox" id="c-38315008" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#38314691">root</a><span>|</span><a href="#38314884">parent</a><span>|</span><a href="#38314723">next</a><span>|</span><label class="collapse" for="c-38315008">[-]</label><label class="expand" for="c-38315008">[1 more]</label></div><br/><div class="children"><div class="content">AI will decide our fate in a microsecond.</div><br/></div></div></div></div><div id="38314723" class="c"><input type="checkbox" id="c-38314723" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38314884">prev</a><span>|</span><a href="#38314719">next</a><span>|</span><label class="collapse" for="c-38314723">[-]</label><label class="expand" for="c-38314723">[1 more]</label></div><br/><div class="children"><div class="content">From what I understand, the board doesn&#x27;t want &quot;AI safety&quot; to be the core or even a major driving force. The whole contention sprung about because of sama&#x27;s way of running the company (&quot;ClosedAI&quot;, for-profit) at odds with the non-profit charter and overall spirit of the board and many people working there.</div><br/></div></div><div id="38314719" class="c"><input type="checkbox" id="c-38314719" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38314723">prev</a><span>|</span><a href="#38315076">next</a><span>|</span><label class="collapse" for="c-38314719">[-]</label><label class="expand" for="c-38314719">[1 more]</label></div><br/><div class="children"><div class="content">What is Sam Altman going to do with a GPU? Find some engineers to use them I guess?</div><br/></div></div><div id="38315076" class="c"><input type="checkbox" id="c-38315076" checked=""/><div class="controls bullet"><span class="by">crotchfire</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38314719">prev</a><span>|</span><a href="#38315002">next</a><span>|</span><label class="collapse" for="c-38315076">[-]</label><label class="expand" for="c-38315076">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Palmer, of course, went on to start a company (anduril), which has a much more powerful and direct ability to enact his political will.<p>If that were true, Palmer Lucky wouldn&#x27;t spend all his time ranting on twitter about how he was so easily hoodwinked by the community of a particular linux distribution &#x2F; functional programming language.</div><br/></div></div><div id="38315002" class="c"><input type="checkbox" id="c-38315002" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38315076">prev</a><span>|</span><a href="#38316075">next</a><span>|</span><label class="collapse" for="c-38315002">[-]</label><label class="expand" for="c-38315002">[1 more]</label></div><br/><div class="children"><div class="content">Palmer had some ridiculous perspectives. Don’t put that pos in the same bucket as Sam.</div><br/></div></div><div id="38316075" class="c"><input type="checkbox" id="c-38316075" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38315002">prev</a><span>|</span><a href="#38316297">next</a><span>|</span><label class="collapse" for="c-38316075">[-]</label><label class="expand" for="c-38316075">[1 more]</label></div><br/><div class="children"><div class="content">Convincing yourself and others that you&#x27;re developing this thing that could destroy humanity if you personally slip up and are just not careful enough makes you feel really powerful.</div><br/></div></div><div id="38316297" class="c"><input type="checkbox" id="c-38316297" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#38314691">parent</a><span>|</span><a href="#38316075">prev</a><span>|</span><a href="#38314850">next</a><span>|</span><label class="collapse" for="c-38316297">[-]</label><label class="expand" for="c-38316297">[1 more]</label></div><br/><div class="children"><div class="content">Just because bigotry and misogyny and racism are views shared by half the country doesn&#x27;t make them right.</div><br/></div></div></div></div><div id="38314699" class="c"><input type="checkbox" id="c-38314699" checked=""/><div class="controls bullet"><span class="by">synergy20</span><span>|</span><a href="#38314691">prev</a><span>|</span><a href="#38315135">next</a><span>|</span><label class="collapse" for="c-38314699">[-]</label><label class="expand" for="c-38314699">[3 more]</label></div><br/><div class="children"><div class="content">As far as I can tell, it eventually boils down to this: Ilya is jealous. After all Sam took all the spot lights away from him who actually made the model behind OpenAI.<p>It&#x27;s human nature. OpenAI can continue without Sam, but not without Ilya for the moment. On the other hand, Sam could have been a little more &quot;humble&quot;.</div><br/><div id="38315190" class="c"><input type="checkbox" id="c-38315190" checked=""/><div class="controls bullet"><span class="by">rirarobo</span><span>|</span><a href="#38314699">parent</a><span>|</span><a href="#38315240">next</a><span>|</span><label class="collapse" for="c-38315190">[-]</label><label class="expand" for="c-38315190">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think Ilya is jealous, I think he just fundamentally is more devoted to the original non-profit mission, and the AI research.<p>Sam is a VC guy who has been going on a world tour to not just get in the spotlight, but to actually accumulate power, influence, and more capital investment.<p>At some point, this means Ilya no longer trusts that Sam is actually devoted to the original mission to benefit all of humanity. So, I think it&#x27;s a little more complicated than just being &quot;jealous&quot;.</div><br/></div></div><div id="38315240" class="c"><input type="checkbox" id="c-38315240" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38314699">parent</a><span>|</span><a href="#38315190">prev</a><span>|</span><a href="#38315135">next</a><span>|</span><label class="collapse" for="c-38315240">[-]</label><label class="expand" for="c-38315240">[1 more]</label></div><br/><div class="children"><div class="content">I mean, maybe Ilya really believes that AGI will happen and should benefit all people not just rich &#x2F; powerful.</div><br/></div></div></div></div><div id="38315135" class="c"><input type="checkbox" id="c-38315135" checked=""/><div class="controls bullet"><span class="by">justinclift</span><span>|</span><a href="#38314699">prev</a><span>|</span><a href="#38315392">next</a><span>|</span><label class="collapse" for="c-38315135">[-]</label><label class="expand" for="c-38315135">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;nitter.net&#x2F;karaswisher&#x2F;status&#x2F;1725702501435941294" rel="nofollow noreferrer">https:&#x2F;&#x2F;nitter.net&#x2F;karaswisher&#x2F;status&#x2F;1725702501435941294</a></div><br/></div></div><div id="38315392" class="c"><input type="checkbox" id="c-38315392" checked=""/><div class="controls bullet"><span class="by">solardev</span><span>|</span><a href="#38315135">prev</a><span>|</span><a href="#38314761">next</a><span>|</span><label class="collapse" for="c-38315392">[-]</label><label class="expand" for="c-38315392">[1 more]</label></div><br/><div class="children"><div class="content">A joint statement just came out:<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38315309">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38315309</a></div><br/></div></div><div id="38314660" class="c"><input type="checkbox" id="c-38314660" checked=""/><div class="controls bullet"><span class="by">jackcosgrove</span><span>|</span><a href="#38314761">prev</a><span>|</span><a href="#38314973">next</a><span>|</span><label class="collapse" for="c-38314660">[-]</label><label class="expand" for="c-38314660">[1 more]</label></div><br/><div class="children"><div class="content">I sometimes like to indulge my particular outlook on life and harp on the &quot;MBA types&quot;, self-promoters, and flimflam men of the world blah blah blah, and think how everything would be better if the techno-philosophers were in charge. Frankly after I&#x27;ve sobered up from my self-indulgent flights of fancy, I know &quot;those people&quot; serve a very important role that I can&#x27;t.<p>If this report is true, we&#x27;re going to see a big rubber meets road event along these lines. I don&#x27;t think this will end well for OpenAI.</div><br/></div></div><div id="38314973" class="c"><input type="checkbox" id="c-38314973" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38314660">prev</a><span>|</span><a href="#38314978">next</a><span>|</span><label class="collapse" for="c-38314973">[-]</label><label class="expand" for="c-38314973">[1 more]</label></div><br/><div class="children"><div class="content">Probably the wrong venue for this sentiment, but it is incredible that a principled, remarkably accomplished scientist was able to stop his creation from getting co-opted (for now anyway). If you listen to the No Priors interview with Sutskever, the contrast between him and Altman couldn’t be more clear, but it’s quite rare that the former ever wins out over the latter.</div><br/></div></div><div id="38314978" class="c"><input type="checkbox" id="c-38314978" checked=""/><div class="controls bullet"><span class="by">zoogeny</span><span>|</span><a href="#38314973">prev</a><span>|</span><label class="collapse" for="c-38314978">[-]</label><label class="expand" for="c-38314978">[1 more]</label></div><br/><div class="children"><div class="content">I suppose OpenAI had two futures in front of it. It could devote its resources completely to building AGI or it could continue to split its resources to also commercialize its current LLM offerings.<p>Perhaps an internal struggle over those futures was made public by CEO Altman at dev day. By publicly announcing new commercial features he may have attempted to get his way by locking the company into a strategy that wasn’t yet approved by the board. He can argue his role as CEO gave him that right. The response to that claim is to remove him from that role.<p>It will be interesting to see what remains of OpenAI as employees and investors interested in pure commercialization exit the company.</div><br/></div></div></div></div></div></div></div></body></html>