<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732957257155" as="style"/><link rel="stylesheet" href="styles.css?v=1732957257155"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.modular.com/blog/understanding-simd-infinite-complexity-of-trivial-problems">Understanding SIMD: Infinite complexity of trivial problems</a> <span class="domain">(<a href="https://www.modular.com">www.modular.com</a>)</span></div><div class="subtext"><span>verdagon</span> | <span>73 comments</span></div><br/><div><div id="42274941" class="c"><input type="checkbox" id="c-42274941" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274935">next</a><span>|</span><label class="collapse" for="c-42274941">[-]</label><label class="expand" for="c-42274941">[18 more]</label></div><br/><div class="children"><div class="content">Intel needs to see what has happened to their AVX instructions and why NVidia has taken over.<p>If you just wrote your SIMD in CUDA 15 years ago, NVidia compilers would have given you maximum performance across all NVidia GPUs rather than being forced to write and rewrite in SSE vs AVX vs AVX512.<p>GPU SIMD is still SIMD. Just... better at it. I think AMD and Intel GPUs can keep up btw. But software advantage and long term benefits of rewriting into CUDA are heavily apparent.<p>Intel ISPC is a great project btw if you need high level code that targets SSE, AVX, AVX512 and even ARM NEON all with one codebase + auto compiling across all the architectures.<p>-------<p>Intels AVX512 is pretty good at a hardware level. But software methodology to interact with SIMD using GPU-like languages should be a priority.<p>Intrinsics are good for maximum performance but they are too hard for mainstream programmers.</div><br/><div id="42275267" class="c"><input type="checkbox" id="c-42275267" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42280152">next</a><span>|</span><label class="collapse" for="c-42275267">[-]</label><label class="expand" for="c-42275267">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Intel ISPC is a great project btw if you need high level code that targets SSE, AVX, AVX512 and even ARM NEON<p>It&#x27;s pretty funny how NEON ended up in there. A former Intel employee decided to implement it for fun and submitted it as a pull request, which Intel quietly ignored for obvious reasons, but then <i>another</i> former Intel employee who still had commit rights merged the PR, and the optics of publicly reverting it would be even worse than stonewalling so Intel begrudgingly let it stand (but they did revoke that devs commit rights).<p><a href="https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;29&#x2F;ispc-retrospective" rel="nofollow">https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;29&#x2F;ispc-retrospective</a></div><br/></div></div><div id="42280152" class="c"><input type="checkbox" id="c-42280152" checked=""/><div class="controls bullet"><span class="by">jabl</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42275267">prev</a><span>|</span><a href="#42275514">next</a><span>|</span><label class="collapse" for="c-42280152">[-]</label><label class="expand" for="c-42280152">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes I wonder about an alternative history scenario where CPU ISA&#x27;s would have chosen a SIMT style model instead of SIMD. &quot;Just&quot; have something like fork&#x2F;join instructions to start&#x2F;stop vector mode, otherwise use the standard scalar instructions in both scalar and vector mode. Would have avoided a lot of combinatorial explosion in instructions. (of course you&#x27;d have to do something for cross-lane operations, and later tensor instructions etc.)</div><br/></div></div><div id="42275514" class="c"><input type="checkbox" id="c-42275514" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42280152">prev</a><span>|</span><a href="#42275980">next</a><span>|</span><label class="collapse" for="c-42275514">[-]</label><label class="expand" for="c-42275514">[4 more]</label></div><br/><div class="children"><div class="content">It is worse than that, given that AVX is the survivor from Larrabee great plan to kill GPUs.<p>Larrabee was going to take over it all, as I enjoyed its presentation at GDCE 2009.</div><br/><div id="42280338" class="c"><input type="checkbox" id="c-42280338" checked=""/><div class="controls bullet"><span class="by">Earw0rm</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275514">parent</a><span>|</span><a href="#42275791">next</a><span>|</span><label class="collapse" for="c-42280338">[-]</label><label class="expand" for="c-42280338">[1 more]</label></div><br/><div class="children"><div class="content">And a few years later, Intel said we&#x27;d get AVX512 on everything by 2016, and that the instruction encoding supported a future extension to 1024.<p>And then the Skylake and Cannon Lake debacle..<p>First they pulled it from the consumer chips a fairly short time before launch. Then the server chips it was present in would downclock aggressively when you did use it, so you could get at best maybe 40% more performance, certainly far from the 2x+ it promised.<p>Ten years on and the AMD 9950X does a pretty good job with it, however.</div><br/></div></div><div id="42275791" class="c"><input type="checkbox" id="c-42275791" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275514">parent</a><span>|</span><a href="#42280338">prev</a><span>|</span><a href="#42275980">next</a><span>|</span><label class="collapse" for="c-42275791">[-]</label><label class="expand" for="c-42275791">[2 more]</label></div><br/><div class="children"><div class="content">I mean, 288-E Core Xeons are about to ship. Xeon 6900 series, right? (Estimated to ship in Q1 2025)<p>So Larrabee lives on for... some reason. These E cores are well known to be modified Intel Atom cores and those were modified Xeon Phi cores which were Larrabee based.<p>Just with.... AVX512 being disabled. (Lost when Xeon Phi turned into Intel Atoms).<p>Intels technical strategy is completely bonkers. In a bad way. Intel invented all this tech 10 to 20 years ago but fails to have a cohesive strategy to bring it to market. There&#x27;s clearly smart people there but somehow all the top level decisions are just awful</div><br/><div id="42278334" class="c"><input type="checkbox" id="c-42278334" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275791">parent</a><span>|</span><a href="#42275980">next</a><span>|</span><label class="collapse" for="c-42278334">[-]</label><label class="expand" for="c-42278334">[1 more]</label></div><br/><div class="children"><div class="content">Yes, a lot of weird decisions were made at Intel.<p>Ironically, AMD waited so long to implement AVX-512, but now has it on both server and mobile chips (natively and 256 bit emulation, respectively). Intel started the whole thing, has a very fragmented stack and is now preparing those E cores with even more new extensions.<p>Most importantly for Search and AI, it adds AVX_VNNI, which can be used for faster 8-bit integer dot-products: <a href="https:&#x2F;&#x2F;github.com&#x2F;ashvardanian&#x2F;SimSIMD&#x2F;blob&#x2F;75c426fb190a9d4286a9e9343925ecce8562abc1&#x2F;include&#x2F;simsimd&#x2F;dot.h#L1815">https:&#x2F;&#x2F;github.com&#x2F;ashvardanian&#x2F;SimSIMD&#x2F;blob&#x2F;75c426fb190a9d4...</a><p>Would be interesting to see how matrix multiplication throughput will differ between AVX-512-capable P cores and a larger quantity of AVX_VNNI-capable E cores!</div><br/></div></div></div></div></div></div><div id="42275980" class="c"><input type="checkbox" id="c-42275980" checked=""/><div class="controls bullet"><span class="by">variadix</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42275514">prev</a><span>|</span><a href="#42279370">next</a><span>|</span><label class="collapse" for="c-42275980">[-]</label><label class="expand" for="c-42275980">[2 more]</label></div><br/><div class="children"><div class="content">How much of this is because CUDA is designed for GPU execution and because the GPU ISA isn’t a stable interface? E.g. new GPU instructions can be utilized by new CUDA compilers for new hardware because the code wasn’t written to a specific ISA? Also, don’t people fine tune GPU kernels per architecture manually (either by hand or via automated optimizers that test combinations in the configuration space)?</div><br/><div id="42276603" class="c"><input type="checkbox" id="c-42276603" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275980">parent</a><span>|</span><a href="#42279370">next</a><span>|</span><label class="collapse" for="c-42276603">[-]</label><label class="expand" for="c-42276603">[1 more]</label></div><br/><div class="children"><div class="content">NVidia PTX is a very stable interface.<p>And the PTX to SASS compiler DOES a degree of automatic fine tuning between architectures. Nothing amazing or anything, but it&#x27;s a minor speed boost that has made PTX just a easier &#x27;assembly-like language&#x27; to build on top of.</div><br/></div></div></div></div><div id="42279370" class="c"><input type="checkbox" id="c-42279370" checked=""/><div class="controls bullet"><span class="by">ip26</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42275980">prev</a><span>|</span><a href="#42278495">next</a><span>|</span><label class="collapse" for="c-42279370">[-]</label><label class="expand" for="c-42279370">[1 more]</label></div><br/><div class="children"><div class="content">Is CUDA not more analogous to using MKL, rather than AVX?</div><br/></div></div><div id="42278495" class="c"><input type="checkbox" id="c-42278495" checked=""/><div class="controls bullet"><span class="by">snihalani</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42279370">prev</a><span>|</span><a href="#42275232">next</a><span>|</span><label class="collapse" for="c-42278495">[-]</label><label class="expand" for="c-42278495">[1 more]</label></div><br/><div class="children"><div class="content">&gt; software methodology to interact with SIMD using GPU-like languages should be a priority.<p>What&#x27;s your opinion on sycl?<p><a href="https:&#x2F;&#x2F;www.khronos.org&#x2F;sycl&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.khronos.org&#x2F;sycl&#x2F;</a></div><br/></div></div><div id="42275232" class="c"><input type="checkbox" id="c-42275232" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#42274941">parent</a><span>|</span><a href="#42278495">prev</a><span>|</span><a href="#42274935">next</a><span>|</span><label class="collapse" for="c-42275232">[-]</label><label class="expand" for="c-42275232">[6 more]</label></div><br/><div class="children"><div class="content">&gt; If you just wrote your SIMD in CUDA 15 years ago, NVidia compilers would have given you maximum performance across all NVidia GPUs<p>That&#x27;s not true. For maximum performance you need to tweak the code to a particular GPU model&#x2F;architecture.<p>Intel has SSE&#x2F;AVX&#x2F;AVX2&#x2F;AVX512, but CUDA has like 10 iterations of this (increasing capabilities). Code written 15 years ago would not use modern capabilities, like more flexible memory access, atomics.</div><br/><div id="42275766" class="c"><input type="checkbox" id="c-42275766" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275232">parent</a><span>|</span><a href="#42274935">next</a><span>|</span><label class="collapse" for="c-42275766">[-]</label><label class="expand" for="c-42275766">[5 more]</label></div><br/><div class="children"><div class="content">Maximum performance? Okay, you&#x27;ll have to upgrade to ballot instructions or whatever and rearchitect your algorithms. (Or other wavefront &#x2F; voting &#x2F; etc. etc. new instructions that have been invented. Especially those 4x4 matrix multiplication AI instructions).<p>But CUDA -&gt; PTX intermediate code has allowed for significantly more flexibility. For crying out loud, the entire machine code (aka SASS) of NVidia GPUs has been cycled out at least 4 times in the past decade (128-bit bundles, changes to instruction formats, acquire&#x2F;release semantics, etc etc)<p>It&#x27;s amazing what backwards compatibility NVidia has achieved in the past 15 years thanks to this architecture. SASS changes so dramatically from generation to generation but the PTX intermediate code has stayed highly competitive.</div><br/><div id="42276022" class="c"><input type="checkbox" id="c-42276022" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42275766">parent</a><span>|</span><a href="#42274935">next</a><span>|</span><label class="collapse" for="c-42276022">[-]</label><label class="expand" for="c-42276022">[4 more]</label></div><br/><div class="children"><div class="content">Intel code from 15 years ago also runs today. But it will not use AVX512.<p>Which is the same with PTX, right? If you didn&#x27;t use the tensor core instructions or wavefront voting in the CUDA code, the PTX generated from it will not either, and NVIDIA will not magically add those capabilities in when compiling to SASS.<p>Maybe it remains competitive because the code is inherently parallel anyway, so it will naturally scale to fill the extra execution units of the GPU, which is where most of the improvement is generation to generation.<p>While AVX code can&#x27;t automatically scale to use the AVX512 units.</div><br/><div id="42276430" class="c"><input type="checkbox" id="c-42276430" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42276022">parent</a><span>|</span><a href="#42274935">next</a><span>|</span><label class="collapse" for="c-42276430">[-]</label><label class="expand" for="c-42276430">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the same. AVX2 instructions haven&#x27;t changed and never will change.<p>In contrast, NVidia can go from 64-bit instruction bundles to 128-bit machine code (96-bit instruction + 32-bit control information) between Pascal (aka PTX Compute Capacity 5) and Voltage (aka PTX Compute Capacity 7) and all the old PTX code just autocompiles to the new assembly instruction format and takes advantage of all the new memory barriers added in Volta.<p>Having a PTX translation later is a MAJOR advantage for the NVidia workflow.</div><br/><div id="42278229" class="c"><input type="checkbox" id="c-42278229" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#42274941">root</a><span>|</span><a href="#42276430">parent</a><span>|</span><a href="#42278137">next</a><span>|</span><label class="collapse" for="c-42278229">[-]</label><label class="expand" for="c-42278229">[1 more]</label></div><br/><div class="children"><div class="content">There is still a lot of similarity between CPU and GPU programming - between AVX and PTX. Different generations of CPU cores handle the same AVX2 instructions differently. The microcode changes and the schedulers change, but the process is transparent for the user, similar to PTX.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42274935" class="c"><input type="checkbox" id="c-42274935" checked=""/><div class="controls bullet"><span class="by">Joker_vD</span><span>|</span><a href="#42274941">prev</a><span>|</span><a href="#42279752">next</a><span>|</span><label class="collapse" for="c-42274935">[-]</label><label class="expand" for="c-42274935">[2 more]</label></div><br/><div class="children"><div class="content">&gt; SIMD instructions are complex, and even Arm is starting to look more “CISCy” than x86!<p>Thank you for saying it out loud. XLAT&#x2F;XLATB of x86 is positively tame compared to e.g. vrgatherei16.vv&#x2F;vrgather.vv.</div><br/></div></div><div id="42279752" class="c"><input type="checkbox" id="c-42279752" checked=""/><div class="controls bullet"><span class="by">rishi_devan</span><span>|</span><a href="#42274935">prev</a><span>|</span><a href="#42276624">next</a><span>|</span><label class="collapse" for="c-42279752">[-]</label><label class="expand" for="c-42279752">[1 more]</label></div><br/><div class="children"><div class="content">Interesting article. The article mentions &quot;...the NumPy implementation illustrates a marked improvement over the naive algorithm...&quot;, but I couldn&#x27;t find a NumPy implementation in the article.</div><br/></div></div><div id="42276624" class="c"><input type="checkbox" id="c-42276624" checked=""/><div class="controls bullet"><span class="by">TinkersW</span><span>|</span><a href="#42279752">prev</a><span>|</span><a href="#42275437">next</a><span>|</span><label class="collapse" for="c-42276624">[-]</label><label class="expand" for="c-42276624">[4 more]</label></div><br/><div class="children"><div class="content">You can simplify the 2x sqrts as sqrt(a*b), overall less operations so perhaps more accurate. It would also let you get rid of the funky lane swivels.<p>As this would only use 1 lane, perhaps if you have multiple of these to normalize, you could vectorize it.</div><br/><div id="42277913" class="c"><input type="checkbox" id="c-42277913" checked=""/><div class="controls bullet"><span class="by">a_gopher</span><span>|</span><a href="#42276624">parent</a><span>|</span><a href="#42275437">next</a><span>|</span><label class="collapse" for="c-42277913">[-]</label><label class="expand" for="c-42277913">[3 more]</label></div><br/><div class="children"><div class="content">my thoughts exactly - crazy to know all these arcane SIMD opcodes but not know basic maths!!</div><br/><div id="42278015" class="c"><input type="checkbox" id="c-42278015" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#42276624">root</a><span>|</span><a href="#42277913">parent</a><span>|</span><a href="#42275437">next</a><span>|</span><label class="collapse" for="c-42278015">[-]</label><label class="expand" for="c-42278015">[2 more]</label></div><br/><div class="children"><div class="content">Square root computation can be tricky, often relying on approximations. These approximations tend to perform best for mid-range values, while accuracy can degrade for very large or very small values. With this in mind, a product of roots is generally more accurate than a root of products.<p>From a SIMD perspective, it’s worth noting that on most platforms, the cost of computing one square root or two is the same. On modern x86 server CPUs, for instance, you can calculate up to 8 double-precision roots in parallel with identical latency. So there’s no additional cost in terms of performance.<p>I hope this sheds some light on the design of my code.<p>PS: In a previous life, I did research in Astro- and Plasma Physics. While I don’t claim to remember all the Math, it’s usually more productive to ask for clarification than to assume ignorance ;)</div><br/><div id="42279991" class="c"><input type="checkbox" id="c-42279991" checked=""/><div class="controls bullet"><span class="by">harry8</span><span>|</span><a href="#42276624">root</a><span>|</span><a href="#42278015">parent</a><span>|</span><a href="#42275437">next</a><span>|</span><label class="collapse" for="c-42279991">[-]</label><label class="expand" for="c-42279991">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it’s usually more productive to ask for clarification than to assume ignorance ;)<p>Good reminder for me and anyone else right there, nicely put.</div><br/></div></div></div></div></div></div></div></div><div id="42275437" class="c"><input type="checkbox" id="c-42275437" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#42276624">prev</a><span>|</span><a href="#42275469">next</a><span>|</span><label class="collapse" for="c-42275437">[-]</label><label class="expand" for="c-42275437">[5 more]</label></div><br/><div class="children"><div class="content">C# vectors do a great job of simplifying those intrinsics in a safe and portable manner.</div><br/><div id="42276164" class="c"><input type="checkbox" id="c-42276164" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#42275437">parent</a><span>|</span><a href="#42275469">next</a><span>|</span><label class="collapse" for="c-42276164">[-]</label><label class="expand" for="c-42276164">[4 more]</label></div><br/><div class="children"><div class="content">There are dozens of libraries, frameworks, and compiler toolchains that try to abstract away SIMD capabilities, but I don&#x27;t think it&#x27;s a great approach.<p>The only 2 approaches that still make sense to me:<p>A. Writing serial vectorization-aware code in a native compiled language, hoping your compiler will auto-vectorize.<p>B. Implementing natively for every hardware platform, as the ISA differences are too big to efficiently abstract away anything beyond 128-register float multiplication and addition.<p>This article, in a way, an attempt to show how big the differences even for simple data-parallel floating-point tasks.</div><br/><div id="42280349" class="c"><input type="checkbox" id="c-42280349" checked=""/><div class="controls bullet"><span class="by">Earw0rm</span><span>|</span><a href="#42275437">root</a><span>|</span><a href="#42276164">parent</a><span>|</span><a href="#42276337">next</a><span>|</span><label class="collapse" for="c-42280349">[-]</label><label class="expand" for="c-42280349">[1 more]</label></div><br/><div class="children"><div class="content">The library approach does a pretty good job in conjunction with a good compiler, and sensible algorithm design.<p>You&#x27;re writing C++ code but as if it was shader code.<p>I&#x27;ve seen impressive results with clang doing this sort of thing.</div><br/></div></div><div id="42276337" class="c"><input type="checkbox" id="c-42276337" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#42275437">root</a><span>|</span><a href="#42276164">parent</a><span>|</span><a href="#42280349">prev</a><span>|</span><a href="#42276411">next</a><span>|</span><label class="collapse" for="c-42276337">[-]</label><label class="expand" for="c-42276337">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s the middle-ground approach of having primarily target-specific operations but with intersecting ones named the same, and allowing easily building custom abstractions on top of such to paper over the differences how best it makes sense for the given application. That&#x27;s the approach <a href="https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;Singeli">https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;Singeli</a> takes.<p>There&#x27;s a good amount of stuff that can clearly utilize SIMD without much platform-specificness, but doesn&#x27;t easily autovectorize - early-exit checks in a loop, packed bit boolean stuff, some data rearranging, probing hashmap checks, some very-short-variable-length-loop things. And while there might often be some parts that do just need to be entirely target-specific, they&#x27;ll usually be surrounded by stuff that doesn&#x27;t (the loop, trip count calculation, loads&#x2F;stores, probably some arithmetic).</div><br/></div></div><div id="42276411" class="c"><input type="checkbox" id="c-42276411" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#42275437">root</a><span>|</span><a href="#42276164">parent</a><span>|</span><a href="#42276337">prev</a><span>|</span><a href="#42275469">next</a><span>|</span><label class="collapse" for="c-42276411">[-]</label><label class="expand" for="c-42276411">[1 more]</label></div><br/><div class="children"><div class="content">Numerics in .NET are not a high-level abstraction and do out of box what many mature vectorized libraries end up doing themselves - there is significant overlap between NEON, SSE* and, if we overlook vector width, AVX2&#x2F;512 and WASMs PackedSIMD.<p>.NET has roughly three vector APIs:<p>- Vector&lt;T&gt; which is platform-defined width vector that exposes common set of operations<p>- Vector64&#x2F;128&#x2F;256&#x2F;512&lt;T&gt; which has wider API than the previous one<p>- Platform intrinsics - basically immintrin.h<p>Notably, platform intrinsics use respective VectorXXX&lt;T&gt; types which allows to write common parts of the algorithm in a portable way and apply platform intrinsics in specific areas where it makes sense. Also some method have &#x27;Unsafe&#x27; and &#x27;Native&#x27; variants to allow for vector to exhibit platform-specific behavior like shuffles since in many situations this is still the desired output for the common case.<p>The .NET&#x27;s compiler produces competitive with GCC and sometimes Clang codegen for these. It&#x27;s gotten particularly good at lowering AVX512.</div><br/></div></div></div></div></div></div><div id="42275469" class="c"><input type="checkbox" id="c-42275469" checked=""/><div class="controls bullet"><span class="by">juancn</span><span>|</span><a href="#42275437">prev</a><span>|</span><a href="#42274850">next</a><span>|</span><label class="collapse" for="c-42275469">[-]</label><label class="expand" for="c-42275469">[5 more]</label></div><br/><div class="children"><div class="content">The main problem is that there are no good abstractions in popular programming languages to take advantage of SIMD extensions.<p>Also, the feature set being all over the place (e.g. integer support is fairly recent) doesn&#x27;t help either.<p>ISPC is a good idea, but execution is meh... it&#x27;s hard to setup and integrate.<p>Ideally you would want to be able to easily use this from other popular languages, like Java, Python, Javascript, without having to resort to linking a library written in C&#x2F;C++.<p>Granted, language extensions may be required to approach something like that in an ergonomic way, but most somehow end up just mimicking what C++ does and expose a pseudo assembler.</div><br/><div id="42275570" class="c"><input type="checkbox" id="c-42275570" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#42275469">parent</a><span>|</span><a href="#42280353">next</a><span>|</span><label class="collapse" for="c-42275570">[-]</label><label class="expand" for="c-42275570">[1 more]</label></div><br/><div class="children"><div class="content">The best is the GPU programming approach, with specialised languages<p>Just like using SQL is much more sane than low level C APIs to handle BTree nodes.<p>The language extensions help, but code still requires too much low level expertise, with algorithms and data structures having to take SIMD&#x2F;MIMD capabilities into account anyway.</div><br/></div></div><div id="42280353" class="c"><input type="checkbox" id="c-42280353" checked=""/><div class="controls bullet"><span class="by">Earw0rm</span><span>|</span><a href="#42275469">parent</a><span>|</span><a href="#42275570">prev</a><span>|</span><a href="#42276197">next</a><span>|</span><label class="collapse" for="c-42280353">[-]</label><label class="expand" for="c-42280353">[1 more]</label></div><br/><div class="children"><div class="content">std::experimental::simd is happening. It should be part of c++26.</div><br/></div></div><div id="42276197" class="c"><input type="checkbox" id="c-42276197" checked=""/><div class="controls bullet"><span class="by">Conscat</span><span>|</span><a href="#42275469">parent</a><span>|</span><a href="#42280353">prev</a><span>|</span><a href="#42277462">next</a><span>|</span><label class="collapse" for="c-42276197">[-]</label><label class="expand" for="c-42276197">[1 more]</label></div><br/><div class="children"><div class="content">I think the EVE library for C++ is a great abstraction. It&#x27;s got an unusual syntax using subscript operator overloading, but that winds up being a very ergonomic and flexible way to program with masked-SIMD.</div><br/></div></div></div></div><div id="42274850" class="c"><input type="checkbox" id="c-42274850" checked=""/><div class="controls bullet"><span class="by">Agingcoder</span><span>|</span><a href="#42275469">prev</a><span>|</span><a href="#42276122">next</a><span>|</span><label class="collapse" for="c-42274850">[-]</label><label class="expand" for="c-42274850">[11 more]</label></div><br/><div class="children"><div class="content">This is the first time I hear ‘hyperscalar’. Is this generally accepted ? ( I’ve been using SIMD since the MMX days  so am a bit surprised )</div><br/><div id="42274919" class="c"><input type="checkbox" id="c-42274919" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274850">parent</a><span>|</span><a href="#42274964">next</a><span>|</span><label class="collapse" for="c-42274919">[-]</label><label class="expand" for="c-42274919">[9 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so.<p>Superscalar is a real term (multiple operations in one clock tick due to parallel pipelines within a core). But hyperscalar is cringe to me. There are tons of words describing SIMD already, it seems unclear why someone would make up a new word to describe an already existing concept.<p>Especially when a similar word (superscalar) already is defined and likely gets confused for this new word.</div><br/><div id="42275162" class="c"><input type="checkbox" id="c-42275162" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42274919">parent</a><span>|</span><a href="#42274964">next</a><span>|</span><label class="collapse" for="c-42275162">[-]</label><label class="expand" for="c-42275162">[8 more]</label></div><br/><div class="children"><div class="content">That may have been my mistake. I use super &amp; hyper interchangeably and don&#x27;t always notice :)<p>PS: Should be an easy patch, will update!</div><br/><div id="42275201" class="c"><input type="checkbox" id="c-42275201" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275162">parent</a><span>|</span><a href="#42274964">next</a><span>|</span><label class="collapse" for="c-42275201">[-]</label><label class="expand" for="c-42275201">[7 more]</label></div><br/><div class="children"><div class="content">Maybe not.<p>Superscalar is when say... Think of the following assembly code.<p><pre><code>   Add r1, r2
   Sub r3, r4
</code></pre>
And the add and subtract both happen on the same clock tick. The important thing is that a modern CPU core (and even GPU core) have multiple parallel ALU pipelines inside of them.<p>Because r1, r2, r3 and r4 are fully independent, a modern CPU can detect the potential parallelism here and act in parallel. After CPUs mastered this trick, the next out of order processors were invented (which not only allowed for super scalar operations, but allowed the subtract to execute first if for some reason the CPU core were waiting on r1 or r2).<p>There are a ton of ways that modern CPUs and GPUs extract parallelism from seemingly nothingness. And because all the techniques are independent, we can have superscalar out-of-order SIMD (like what happens in AVX512 in practice).
SIMD is... SIMD. It&#x27;s one instruction applied to lots of data in parallel. It&#x27;s totally different.<p>You really need to use the correct word for the specific kind of parallelism that you are trying to highlight. I expect that the only word that makes sense in this article is SIMD.</div><br/><div id="42279129" class="c"><input type="checkbox" id="c-42279129" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275201">parent</a><span>|</span><a href="#42275472">next</a><span>|</span><label class="collapse" for="c-42279129">[-]</label><label class="expand" for="c-42279129">[1 more]</label></div><br/><div class="children"><div class="content">Agree with this. Calling SIMD superscalar is a misnomer since it is <i>single instruction</i> (multiple data) with very wide data paths. Superscalar implies multiple <i>different</i> instructions in parallel, such as adding a pair of numbers, while subtracting another pair (or even dividing).</div><br/></div></div><div id="42275472" class="c"><input type="checkbox" id="c-42275472" checked=""/><div class="controls bullet"><span class="by">pyrolistical</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275201">parent</a><span>|</span><a href="#42279129">prev</a><span>|</span><a href="#42274964">next</a><span>|</span><label class="collapse" for="c-42275472">[-]</label><label class="expand" for="c-42275472">[5 more]</label></div><br/><div class="children"><div class="content">I wish hardware exposed an api that allowed us to submit a tree of instructions so the hardware doesn’t need figure out which instructions are independent.<p>Lots of this kind of work can be done during compilation but cannot be communicated to hardware due to code being linear</div><br/><div id="42275709" class="c"><input type="checkbox" id="c-42275709" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275472">parent</a><span>|</span><a href="#42275764">next</a><span>|</span><label class="collapse" for="c-42275709">[-]</label><label class="expand" for="c-42275709">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s called VLIW and Intel Itanium is considered one of the biggest chip failures of all time.<p>There is an argument that today&#x27;s compilers are finally good enough for VLIW to go mainstream, but good luck convincing anyone in today&#x27;s market to go for it.<p>------<p>A big problem with VLIW is that it&#x27;s impossible to predict L1, L2, L3 or DRAM access. Meaning all loads&#x2F;stores are impossible to schedule by the compiler.<p>NVidia has interesting barriers that get compiled into its SASS (a level lower than PTX assembly). These barriers seem to allow the compiler to assist in the dependency management process but ultimately still require a decoder in the NVidia core final level before execution.</div><br/><div id="42277617" class="c"><input type="checkbox" id="c-42277617" checked=""/><div class="controls bullet"><span class="by">neerajsi</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275709">parent</a><span>|</span><a href="#42280062">next</a><span>|</span><label class="collapse" for="c-42277617">[-]</label><label class="expand" for="c-42277617">[1 more]</label></div><br/><div class="children"><div class="content">Vliw is kind of the dual of what pyrolistical was asking for. Vliw lets you bundle instructions that are known to be independent rather than encode instructions to mark known dependencies.<p>The idea pyrolistical mentioned is closer to explicit data graph execution: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Explicit_data_graph_execution" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Explicit_data_graph_executio...</a>.</div><br/></div></div><div id="42280062" class="c"><input type="checkbox" id="c-42280062" checked=""/><div class="controls bullet"><span class="by">creato</span><span>|</span><a href="#42274850">root</a><span>|</span><a href="#42275709">parent</a><span>|</span><a href="#42277617">prev</a><span>|</span><a href="#42275764">next</a><span>|</span><label class="collapse" for="c-42280062">[-]</label><label class="expand" for="c-42280062">[1 more]</label></div><br/><div class="children"><div class="content">VLIW is still in use in multiple DSP products on the market today, and they are good successful products in their niche.<p>They work very well if your code can be written as a loop without branches (or very limited branches) in the body, and a lot of instruction level parallelism in the body.<p>Unfortunately for Intel, most code doesn&#x27;t look like that. But for most workloads that happen to also be a good case for SIMD, it is (can be) great.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42274964" class="c"><input type="checkbox" id="c-42274964" checked=""/><div class="controls bullet"><span class="by">spacemanspiff01</span><span>|</span><a href="#42274850">parent</a><span>|</span><a href="#42274919">prev</a><span>|</span><a href="#42276122">next</a><span>|</span><label class="collapse" for="c-42274964">[-]</label><label class="expand" for="c-42274964">[1 more]</label></div><br/><div class="children"><div class="content">I thought it was referring to this?<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Hyperscale_computing" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Hyperscale_computing</a><p>IE our simd implementation allows you to scale across different architectures&#x2F; CPU revisions without having to rewrite assembly for each CPU processor?<p>Edit:
Rereading, that does not make much sense...</div><br/></div></div></div></div><div id="42276122" class="c"><input type="checkbox" id="c-42276122" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#42274850">prev</a><span>|</span><a href="#42238004">next</a><span>|</span><label class="collapse" for="c-42276122">[-]</label><label class="expand" for="c-42276122">[12 more]</label></div><br/><div class="children"><div class="content">I see a lot of &quot;just use the GPU&quot; and you&#x27;d often be right.<p>SIMD on the CPU is most compelling to me due to the latency characteristics. You are nanoseconds away from the control flow. If the GPU needs some updated state regarding the outside world, it takes significantly longer to propagate this information.<p>For most use cases, the GPU will win the trade off. But, there is a reason you don&#x27;t hear much about systems like order matching engines using them.</div><br/><div id="42276447" class="c"><input type="checkbox" id="c-42276447" checked=""/><div class="controls bullet"><span class="by">dragontamer</span><span>|</span><a href="#42276122">parent</a><span>|</span><a href="#42276176">next</a><span>|</span><label class="collapse" for="c-42276447">[-]</label><label class="expand" for="c-42276447">[1 more]</label></div><br/><div class="children"><div class="content">Despite my &#x27;Use a GPU&#x27; post below, you are absolutely correct.<p>Maximizing performance on a CPU today requires all the steps in the above article, and the article is actually very well written with regards to the &#x27;mindset&#x27; needed to tackle a problem such as this.<p>It&#x27;s a great article for people aiming to maximize the performance on Intel or AMD systems.<p>------<p>CPUs have the memory capacity advantage and will continue to hold said advantage for the foreseeable future (despite NVidias NVLink and other techs to try to bridge the gap).<p>And CPU code remains far easier than learning CUDA, despite how hard these AVX intrinsics are in comparison to CUDA.</div><br/></div></div><div id="42276176" class="c"><input type="checkbox" id="c-42276176" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#42276122">parent</a><span>|</span><a href="#42276447">prev</a><span>|</span><a href="#42276253">next</a><span>|</span><label class="collapse" for="c-42276176">[-]</label><label class="expand" for="c-42276176">[3 more]</label></div><br/><div class="children"><div class="content">You would be surprised. The GPU often loses even for small neural nets given the large latency. Anything that needs high throughput or is sized like an HPC problem should use a GPU, but a lot of code benefits from SIMD on small problems.</div><br/><div id="42276681" class="c"><input type="checkbox" id="c-42276681" checked=""/><div class="controls bullet"><span class="by">gmueckl</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276176">parent</a><span>|</span><a href="#42277862">next</a><span>|</span><label class="collapse" for="c-42276681">[-]</label><label class="expand" for="c-42276681">[1 more]</label></div><br/><div class="children"><div class="content">If you run many small tasks on the GPU, you can increase throughput by overlapping transfers and computation. There may also be other ways to batch problems together, but that depends on the algorithms.<p>The one truly unfixable issue is round-trip latency.</div><br/></div></div><div id="42277862" class="c"><input type="checkbox" id="c-42277862" checked=""/><div class="controls bullet"><span class="by">gopalv</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276176">parent</a><span>|</span><a href="#42276681">prev</a><span>|</span><a href="#42276253">next</a><span>|</span><label class="collapse" for="c-42277862">[-]</label><label class="expand" for="c-42277862">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The GPU often loses even for small neural nets given the large latency<p>Apple&#x27;s neural engine shows that you can live in between those two worlds.<p>As you said, the trouble is the latency, the programming model is still great.</div><br/></div></div></div></div><div id="42276416" class="c"><input type="checkbox" id="c-42276416" checked=""/><div class="controls bullet"><span class="by">moldavi</span><span>|</span><a href="#42276122">parent</a><span>|</span><a href="#42276253">prev</a><span>|</span><a href="#42279946">next</a><span>|</span><label class="collapse" for="c-42276416">[-]</label><label class="expand" for="c-42276416">[5 more]</label></div><br/><div class="children"><div class="content">Do Apple&#x27;s chips (M1 etc) change this at all, since they share memory with the GPU?</div><br/><div id="42280363" class="c"><input type="checkbox" id="c-42280363" checked=""/><div class="controls bullet"><span class="by">Earw0rm</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276416">parent</a><span>|</span><a href="#42276859">next</a><span>|</span><label class="collapse" for="c-42280363">[-]</label><label class="expand" for="c-42280363">[1 more]</label></div><br/><div class="children"><div class="content">Not much. Synchronisation of tasks is still a big overhead.<p>If you&#x27;ve got tens to hundreds of microseconds worth of workload, sure, get the GPU to do it.<p>But bear in mind 1000 clocks at 4GHz is 250ns, there&#x27;s still a sizeable region where tight CPU&#x2F;GPU integration isn&#x27;t tight enough.</div><br/></div></div><div id="42276859" class="c"><input type="checkbox" id="c-42276859" checked=""/><div class="controls bullet"><span class="by">one_even_prime</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276416">parent</a><span>|</span><a href="#42280363">prev</a><span>|</span><a href="#42276831">next</a><span>|</span><label class="collapse" for="c-42276859">[-]</label><label class="expand" for="c-42276859">[2 more]</label></div><br/><div class="children"><div class="content">Apple chips share the same physical memory between the GPU and the CPU. Still, they don&#x27;t have USM&#x2F;UVM (Unified Shared Memory&#x2F;Unified Virtual Memory), that is, the GPU and the CPU can&#x27;t access the same data concurrently and easily. Programs must map&#x2F;unmap pages to control which device accesses it, and that&#x27;s a very expensive operation.</div><br/><div id="42278107" class="c"><input type="checkbox" id="c-42278107" checked=""/><div class="controls bullet"><span class="by">tubs</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276859">parent</a><span>|</span><a href="#42276831">next</a><span>|</span><label class="collapse" for="c-42278107">[-]</label><label class="expand" for="c-42278107">[1 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t need to be unmapped just for the other one to use it. source: I wrote GPU drivers for over 10 years.</div><br/></div></div></div></div><div id="42276831" class="c"><input type="checkbox" id="c-42276831" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#42276122">root</a><span>|</span><a href="#42276416">parent</a><span>|</span><a href="#42276859">prev</a><span>|</span><a href="#42279946">next</a><span>|</span><label class="collapse" for="c-42276831">[-]</label><label class="expand" for="c-42276831">[1 more]</label></div><br/><div class="children"><div class="content">I think an argument could be made depending on the real world timings. How much closer in time is the Apple GPU vs one on a PCIe bus?</div><br/></div></div></div></div></div></div><div id="42276312" class="c"><input type="checkbox" id="c-42276312" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42276158">prev</a><span>|</span><label class="collapse" for="c-42276312">[-]</label><label class="expand" for="c-42276312">[10 more]</label></div><br/><div class="children"><div class="content">Looks like a great use case for AI. Set up the logical specification and constraints and let the AI find the optimal sequence of SIMD operations to fulfill the requirements.</div><br/><div id="42276341" class="c"><input type="checkbox" id="c-42276341" checked=""/><div class="controls bullet"><span class="by">fooblaster</span><span>|</span><a href="#42276312">parent</a><span>|</span><a href="#42276640">next</a><span>|</span><label class="collapse" for="c-42276341">[-]</label><label class="expand" for="c-42276341">[4 more]</label></div><br/><div class="children"><div class="content">No, there are decades of compiler literature for solving this problem.</div><br/><div id="42276453" class="c"><input type="checkbox" id="c-42276453" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276341">parent</a><span>|</span><a href="#42276640">next</a><span>|</span><label class="collapse" for="c-42276453">[-]</label><label class="expand" for="c-42276453">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s even better then. Just let the AI read the literature and write the optimal compiler.</div><br/><div id="42276544" class="c"><input type="checkbox" id="c-42276544" checked=""/><div class="controls bullet"><span class="by">fooblaster</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276453">parent</a><span>|</span><a href="#42276640">next</a><span>|</span><label class="collapse" for="c-42276544">[-]</label><label class="expand" for="c-42276544">[2 more]</label></div><br/><div class="children"><div class="content">It would probably be easier to clone the existing repository than get an llm to regurgitate llvm.</div><br/><div id="42276574" class="c"><input type="checkbox" id="c-42276574" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276544">parent</a><span>|</span><a href="#42276640">next</a><span>|</span><label class="collapse" for="c-42276574">[-]</label><label class="expand" for="c-42276574">[1 more]</label></div><br/><div class="children"><div class="content">The AI would learn from llvm as well.</div><br/></div></div></div></div></div></div></div></div><div id="42276640" class="c"><input type="checkbox" id="c-42276640" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#42276312">parent</a><span>|</span><a href="#42276341">prev</a><span>|</span><label class="collapse" for="c-42276640">[-]</label><label class="expand" for="c-42276640">[5 more]</label></div><br/><div class="children"><div class="content">lol so says every person that has no clue how (NP-hard) combinatorial optimization is.</div><br/><div id="42276717" class="c"><input type="checkbox" id="c-42276717" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276640">parent</a><span>|</span><label class="collapse" for="c-42276717">[-]</label><label class="expand" for="c-42276717">[4 more]</label></div><br/><div class="children"><div class="content">For humans it&#x27;s very hard but it will be a breeze for the AI. I thought HN was a community of builders. This is an obvious startup opportunity.</div><br/><div id="42276956" class="c"><input type="checkbox" id="c-42276956" checked=""/><div class="controls bullet"><span class="by">stouset</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276717">parent</a><span>|</span><label class="collapse" for="c-42276956">[-]</label><label class="expand" for="c-42276956">[3 more]</label></div><br/><div class="children"><div class="content">All we have to do is ascribe magical properties to AI and we can solve anything as if P=NP!</div><br/><div id="42277002" class="c"><input type="checkbox" id="c-42277002" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42276956">parent</a><span>|</span><label class="collapse" for="c-42277002">[-]</label><label class="expand" for="c-42277002">[2 more]</label></div><br/><div class="children"><div class="content">Those distinction are irrelevant for an AI because it is a pure form of intelligence that simply computes answers without worrying about P or NP complexity classes.</div><br/><div id="42277938" class="c"><input type="checkbox" id="c-42277938" checked=""/><div class="controls bullet"><span class="by">ConspiracyFact</span><span>|</span><a href="#42276312">root</a><span>|</span><a href="#42277002">parent</a><span>|</span><label class="collapse" for="c-42277938">[-]</label><label class="expand" for="c-42277938">[1 more]</label></div><br/><div class="children"><div class="content">You had me going.<p>B-</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>