<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720947675952" as="style"/><link rel="stylesheet" href="styles.css?v=1720947675952"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/nicholassm/disruptor-rs">Disruptor-rs: better latency and throughput than crossbeam</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>nicholassm83</span> | <span>36 comments</span></div><br/><div><div id="40954952" class="c"><input type="checkbox" id="c-40954952" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#40954665">next</a><span>|</span><label class="collapse" for="c-40954952">[-]</label><label class="expand" for="c-40954952">[2 more]</label></div><br/><div class="children"><div class="content">I played around with the original (Java) LMAX disruptor which was an interesting and different way to achieve latency&#x2F;throughput. Didn&#x27;t find a whitepaper--here&#x27;s some references[0] which includes a Martin Fowler post[1].<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;wiki&#x2F;Blogs-And-Articles">https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;wiki&#x2F;Blogs-And-Ar...</a><p>[1] <a href="https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html" rel="nofollow">https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html</a></div><br/><div id="40956211" class="c"><input type="checkbox" id="c-40956211" checked=""/><div class="controls bullet"><span class="by">temporarely</span><span>|</span><a href="#40954952">parent</a><span>|</span><a href="#40954665">next</a><span>|</span><label class="collapse" for="c-40956211">[-]</label><label class="expand" for="c-40956211">[1 more]</label></div><br/><div class="children"><div class="content">here you go:<p><i>Disruptor</i>, Thompson, Farley, et al 2011<p><a href="https:&#x2F;&#x2F;lmax-exchange.github.io&#x2F;disruptor&#x2F;files&#x2F;Disruptor-1.0.pdf" rel="nofollow">https:&#x2F;&#x2F;lmax-exchange.github.io&#x2F;disruptor&#x2F;files&#x2F;Disruptor-1....</a></div><br/></div></div></div></div><div id="40954665" class="c"><input type="checkbox" id="c-40954665" checked=""/><div class="controls bullet"><span class="by">bluejekyll</span><span>|</span><a href="#40954952">prev</a><span>|</span><a href="#40956231">next</a><span>|</span><label class="collapse" for="c-40954665">[-]</label><label class="expand" for="c-40954665">[18 more]</label></div><br/><div class="children"><div class="content">This is really cool to see. Is anyone potentially working on an integration with this an Tokio to bring these performance benefits to the async ecosystem? Or maybe I should ask first, would it make sense to look at this as a foundational library for the multi-thread async frameworks in Rust?</div><br/><div id="40955102" class="c"><input type="checkbox" id="c-40955102" checked=""/><div class="controls bullet"><span class="by">pca006132</span><span>|</span><a href="#40954665">parent</a><span>|</span><a href="#40954722">next</a><span>|</span><label class="collapse" for="c-40955102">[-]</label><label class="expand" for="c-40955102">[1 more]</label></div><br/><div class="children"><div class="content">Probably doesn&#x27;t make sense. Busy wait is fast when you can dedicate a core to the task, but this means that you cannot have many tasks in parallel with a small set of physical cores. When you oversubscribe, performance will quickly degrade.<p>Tokio and other libraries such as pthread allows thread to wait for something and wake up that particular thread when the event occurs. This is what allows scheduler to schedule many tasks to a very small set of cores without running useless instructions checking for status.<p>For foundational library, I think you want things that are composable, and low latency stuff are not that composable IMO.<p>Not saying that they are bad, but low latency is something that requires global effort in your system, and using such library without being aware of these limitations will likely cause more harm than good.</div><br/></div></div><div id="40954722" class="c"><input type="checkbox" id="c-40954722" checked=""/><div class="controls bullet"><span class="by">nXqd</span><span>|</span><a href="#40954665">parent</a><span>|</span><a href="#40955102">prev</a><span>|</span><a href="#40955491">next</a><span>|</span><label class="collapse" for="c-40954722">[-]</label><label class="expand" for="c-40954722">[14 more]</label></div><br/><div class="children"><div class="content">Tokio focuses on being high throughput as default, since they mostly use yield_now backoff strategy. It should work with most application.<p>For latency sensitive application, it tends to have different purpose which mainly trade off CPU and RAM usage for higher low latency ( first ) and throughput later.</div><br/><div id="40954832" class="c"><input type="checkbox" id="c-40954832" checked=""/><div class="controls bullet"><span class="by">nicholassm83</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40954722">parent</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40954832">[-]</label><label class="expand" for="c-40954832">[12 more]</label></div><br/><div class="children"><div class="content">I agree, the disruptor is more about low latency. And the cost is very high: a 100% utilized core.
This is a great trade-off if you can make money by being faster such as in e-trading.</div><br/><div id="40954928" class="c"><input type="checkbox" id="c-40954928" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40954832">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40954928">[-]</label><label class="expand" for="c-40954928">[6 more]</label></div><br/><div class="children"><div class="content">Suppose I have trading system built on Tokio. How would I go about using this instead? What parts need replacing?<p>Actually looking at the code a bit, it seems like you could replace the select statements with the various handlers, and hook up some threads to them. It would indeed cook your CPU but that&#x27;s ok for certain use cases.</div><br/><div id="40955392" class="c"><input type="checkbox" id="c-40955392" checked=""/><div class="controls bullet"><span class="by">nicholassm83</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40954928">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40955392">[-]</label><label class="expand" for="c-40955392">[5 more]</label></div><br/><div class="children"><div class="content">I would love to give you a good answer but I&#x27;ve been working on low latency trading systems for a decade so I have never used async&#x2F;actors&#x2F;fibers&#x2F;etc.
I would think it implies a rewrite as async is fundamentally baked into your code if you use Tokio.</div><br/><div id="40955667" class="c"><input type="checkbox" id="c-40955667" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40955392">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40955667">[-]</label><label class="expand" for="c-40955667">[4 more]</label></div><br/><div class="children"><div class="content">Depends on what &quot;fundamental&quot; means. If we&#x27;re talking about how stuff is scheduled, then yes of course you&#x27;re right. Either we suspend stuff and take a hit on when to continue, or we hot-loop and latency is minimized at the cost of cooking a CPU.<p>But there&#x27;s a bunch of stuff that isn&#x27;t that part of the trading system, though. All the code that deals with the format of the incoming exchange might still be useful somehow. All the internal messages as well might just have the same format. The logic of putting events on some sort of queue for some other worker (task&#x2F;thread) to do seems pretty similar to me. You are just handling the messages immediately rather than waking up a thread for it, and that seems to be the tradeoff.</div><br/><div id="40955883" class="c"><input type="checkbox" id="c-40955883" checked=""/><div class="controls bullet"><span class="by">_3u10</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40955667">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40955883">[-]</label><label class="expand" for="c-40955883">[3 more]</label></div><br/><div class="children"><div class="content">These libs are more about hot paths &#x2F; cache coherency and allowing single CPU processing (no cache coherency issues &#x2F; lock contention) than anything else. That is where the performance comes from, referred to as &quot;mechanical sympathy&quot; in the original LMAX paper.<p>Originally computers were expensive, and lots of users wanted to share a system, so a lot of OS thought went into this, LMAX flips the script on this, computers are cheap, and you want the computer doing one thing as fast as possible, which isn&#x27;t a good fit for modern OS&#x27;s that have been designed around the exact opposite idea. This is also why bare metal is many times faster than VMs in practice, because you aren&#x27;t sharing someone else&#x27;s computer with a bunch of other programs polluting the cache.</div><br/><div id="40955921" class="c"><input type="checkbox" id="c-40955921" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40955883">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40955921">[-]</label><label class="expand" for="c-40955921">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I agree. But the ideas of mechanical sympathy carry over into more than one kind of design. You can still be thinking about caches and branch prediction while writing things in async. It&#x27;s just the awareness of it that allows you to make the tradeoffs you care about.</div><br/><div id="40957811" class="c"><input type="checkbox" id="c-40957811" checked=""/><div class="controls bullet"><span class="by">Quekid5</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40955921">parent</a><span>|</span><a href="#40955820">next</a><span>|</span><label class="collapse" for="c-40957811">[-]</label><label class="expand" for="c-40957811">[1 more]</label></div><br/><div class="children"><div class="content">Eh... not really. The main problem is that it becomes incredibly hard to reason about the exact sequencing of things (which matters a lot for mechanical sympathy) in async world.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40955820" class="c"><input type="checkbox" id="c-40955820" checked=""/><div class="controls bullet"><span class="by">_3u10</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40954832">parent</a><span>|</span><a href="#40954928">prev</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40955820">[-]</label><label class="expand" for="c-40955820">[5 more]</label></div><br/><div class="children"><div class="content">High throughput networking does the same thing, it polls the network adapter rather than waiting for interrupts.<p>The cost is not high, it&#x27;s much less expensive to have a CPU operating more efficiently than not processing anything because its syncing caches &#x2F; context switching to handle an interrupt.<p>These libraries are for busy systems, not systems waiting 30 minutes for the next request to come in.<p>Basically, in an under utilized system most of the time you poll there is nothing wasting CPU for the poll, in an high throughput system when you poll there is almost ALWAYS data ready to be read, so interrupts are less efficient when utilization is high.</div><br/><div id="40956362" class="c"><input type="checkbox" id="c-40956362" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40955820">parent</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40956362">[-]</label><label class="expand" for="c-40956362">[4 more]</label></div><br/><div class="children"><div class="content">Running half the cores of an industrial  Xeon or Zen under 100% load implies very serious cooling. I suspect that running them all at 100% load for hours is just infeasible without e.g. water cooling.</div><br/><div id="40956914" class="c"><input type="checkbox" id="c-40956914" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40956362">parent</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40956914">[-]</label><label class="expand" for="c-40956914">[3 more]</label></div><br/><div class="children"><div class="content">Nah, it will just clock down. Server CPUs are designed to support all cores at 100% utilization indefinitely.<p>Of course you can get different numbers if you invent a nonstandard definition of utilization.</div><br/><div id="40957157" class="c"><input type="checkbox" id="c-40957157" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40956914">parent</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40957157">[-]</label><label class="expand" for="c-40957157">[2 more]</label></div><br/><div class="children"><div class="content">Of course server CPUs can run all cores at 100% indefinitely, as long as the cooling can handle it.<p>With 300W to 400W TDP (Xeon Sapphire 9200) and two CPUs per typical 2U case, cooling is a real challenge, hence my mention of water cooling.</div><br/><div id="40957263" class="c"><input type="checkbox" id="c-40957263" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40957157">parent</a><span>|</span><a href="#40955475">next</a><span>|</span><label class="collapse" for="c-40957263">[-]</label><label class="expand" for="c-40957263">[1 more]</label></div><br/><div class="children"><div class="content">I disagree. Air cooling 1 KW per U is a commodity now. It&#x27;s nothing special. (Whether your data center can handle it is another topic.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40955475" class="c"><input type="checkbox" id="c-40955475" checked=""/><div class="controls bullet"><span class="by">kprotty</span><span>|</span><a href="#40954665">root</a><span>|</span><a href="#40954722">parent</a><span>|</span><a href="#40954832">prev</a><span>|</span><a href="#40955491">next</a><span>|</span><label class="collapse" for="c-40955475">[-]</label><label class="expand" for="c-40955475">[1 more]</label></div><br/><div class="children"><div class="content">Tokio&#x27;s focus is on low <i>tail</i>-latencies for networking applications (as mentioned). But it doesn&#x27;t employs yield_now for waiting on a concurrent condition to occur, even as a backoff strategy, as that fundamentally kills tail-latency under the average OS scheduler.</div><br/></div></div></div></div><div id="40955491" class="c"><input type="checkbox" id="c-40955491" checked=""/><div class="controls bullet"><span class="by">andrepd</span><span>|</span><a href="#40954665">parent</a><span>|</span><a href="#40954722">prev</a><span>|</span><a href="#40955793">next</a><span>|</span><label class="collapse" for="c-40955491">[-]</label><label class="expand" for="c-40955491">[1 more]</label></div><br/><div class="children"><div class="content">How would you? These are completely at odds: async is about suspending tasks that are waiting for something so that you can do other stuff in the meantime, and low-latency is about spinning a core at 100% to start working as fast as possible when the stuff you&#x27;re waiting for arrives. You can&#x27;t do both x)</div><br/></div></div><div id="40955793" class="c"><input type="checkbox" id="c-40955793" checked=""/><div class="controls bullet"><span class="by">_3u10</span><span>|</span><a href="#40954665">parent</a><span>|</span><a href="#40955491">prev</a><span>|</span><a href="#40956231">next</a><span>|</span><label class="collapse" for="c-40955793">[-]</label><label class="expand" for="c-40955793">[1 more]</label></div><br/><div class="children"><div class="content">No, not really, this is for synchronous processing, the events get overwritten so by the time you async handler fires you&#x27;re processing an item that has mutated.<p>What you&#x27;re looking for is io_uring on Linux or IOCP on Windows, I don&#x27;t think osx has something similar, maybe kqueue.</div><br/></div></div></div></div><div id="40956231" class="c"><input type="checkbox" id="c-40956231" checked=""/><div class="controls bullet"><span class="by">BrokrnAlgorithm</span><span>|</span><a href="#40954665">prev</a><span>|</span><a href="#40956921">next</a><span>|</span><label class="collapse" for="c-40956231">[-]</label><label class="expand" for="c-40956231">[2 more]</label></div><br/><div class="children"><div class="content">Is there also a decent c++ implementation of the disruptor out there?</div><br/><div id="40958165" class="c"><input type="checkbox" id="c-40958165" checked=""/><div class="controls bullet"><span class="by">msaltz</span><span>|</span><a href="#40956231">parent</a><span>|</span><a href="#40956921">next</a><span>|</span><label class="collapse" for="c-40958165">[-]</label><label class="expand" for="c-40958165">[1 more]</label></div><br/><div class="children"><div class="content">Here’s one I’ve actually used&#x2F;played with (though never measured performance of): <a href="https:&#x2F;&#x2F;github.com&#x2F;lewissbaker&#x2F;disruptorplus">https:&#x2F;&#x2F;github.com&#x2F;lewissbaker&#x2F;disruptorplus</a><p>And here’s one I saw linked on HN recently: <a href="https:&#x2F;&#x2F;github.com&#x2F;0burak&#x2F;imperial_hft&#x2F;tree&#x2F;main&#x2F;distuptor">https:&#x2F;&#x2F;github.com&#x2F;0burak&#x2F;imperial_hft&#x2F;tree&#x2F;main&#x2F;distuptor</a></div><br/></div></div></div></div><div id="40956921" class="c"><input type="checkbox" id="c-40956921" checked=""/><div class="controls bullet"><span class="by">LtdJorge</span><span>|</span><a href="#40956231">prev</a><span>|</span><a href="#40954105">next</a><span>|</span><label class="collapse" for="c-40956921">[-]</label><label class="expand" for="c-40956921">[1 more]</label></div><br/><div class="children"><div class="content">So nice, that I was just reading about the disruptor, since I had an idea of using ring buffers with atomic operations to back Rust channels with lower latency for intra-thread communication without locks, and now I see this. Gonna take a read!</div><br/></div></div><div id="40955747" class="c"><input type="checkbox" id="c-40955747" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40954105">prev</a><span>|</span><a href="#40954297">next</a><span>|</span><label class="collapse" for="c-40955747">[-]</label><label class="expand" for="c-40955747">[10 more]</label></div><br/><div class="children"><div class="content">Is there anything specific to Rust that this library does which modern C++ can’t match in performance? I’d be very interested to understand if there is.</div><br/><div id="40956492" class="c"><input type="checkbox" id="c-40956492" checked=""/><div class="controls bullet"><span class="by">pornel</span><span>|</span><a href="#40955747">parent</a><span>|</span><a href="#40955762">next</a><span>|</span><label class="collapse" for="c-40956492">[-]</label><label class="expand" for="c-40956492">[4 more]</label></div><br/><div class="children"><div class="content">For Rust users there&#x27;s a significant difference:<p>* it&#x27;s a Cargo package, which is trivial to add to a project. Pure-Rust projects are easier to build cross-platform.<p>* It exports a safe Rust interface. It has configurable levels of thread safety, which are protected from misuse at compile time.<p>The point isn&#x27;t that C++ can match performance, but that you don&#x27;t have to use C++, and still get the performance, plus other niceties.<p>This is &quot;is there anything specific to C++ that assembly can&#x27;t match in performance?&quot; one step removed.</div><br/><div id="40957085" class="c"><input type="checkbox" id="c-40957085" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40956492">parent</a><span>|</span><a href="#40955762">next</a><span>|</span><label class="collapse" for="c-40957085">[-]</label><label class="expand" for="c-40957085">[3 more]</label></div><br/><div class="children"><div class="content">I had expected that’s true. You just never know if perhaps Rust compilers have some more advanced&#x2F;modern tricks that can only be accessed easily by writing in Rust without writing assembly directly.</div><br/><div id="40957501" class="c"><input type="checkbox" id="c-40957501" checked=""/><div class="controls bullet"><span class="by">pornel</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40957085">parent</a><span>|</span><a href="#40955762">next</a><span>|</span><label class="collapse" for="c-40957501">[-]</label><label class="expand" for="c-40957501">[2 more]</label></div><br/><div class="children"><div class="content">There is a trick in truly exclusive references (marked noalias in LLVM). C++ doesn&#x27;t even have the lesser form of C restrict pointers. However, a truly performance focused C or C++ library would tweak the code to get the desired optimizations one way or another.<p>A more nebulous Rust perf thing is  ability rely on the compiler to check lifetimes and immutability&#x2F;exclusivity of pointers. This allows using fine-grained multithreading, even with 3rd party code, without the worry it&#x27;s going to cause heisenbugs. It allows library APIs to work with temporary complex references that would be footguns otherwise (e.g. prefer string_view instead of string. Don&#x27;t copy inputs defensively, because it&#x27;s known they can&#x27;t be mutated or freed even by a broken caller).</div><br/><div id="40957921" class="c"><input type="checkbox" id="c-40957921" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40957501">parent</a><span>|</span><a href="#40955762">next</a><span>|</span><label class="collapse" for="c-40957921">[-]</label><label class="expand" for="c-40957921">[1 more]</label></div><br/><div class="children"><div class="content">&gt; C++ doesn&#x27;t even have the lesser form of C restrict pointers.<p>Standard C++ doesn&#x27;t but `noalias` is available in basically every major compiler (including the more niche embedded toolchains).</div><br/></div></div></div></div></div></div></div></div><div id="40955762" class="c"><input type="checkbox" id="c-40955762" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#40955747">parent</a><span>|</span><a href="#40956492">prev</a><span>|</span><a href="#40954297">next</a><span>|</span><label class="collapse" for="c-40955762">[-]</label><label class="expand" for="c-40955762">[5 more]</label></div><br/><div class="children"><div class="content">No, there shouldn’t be.<p>Rust is not magic and you can compile both with llvm (clang++).<p>If you specify that the pointers don’t alias, and don’t use any language sugar that adds overhead on either side, the performance will be very similar.</div><br/><div id="40955801" class="c"><input type="checkbox" id="c-40955801" checked=""/><div class="controls bullet"><span class="by">nicholassm83</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40955762">parent</a><span>|</span><a href="#40954297">next</a><span>|</span><label class="collapse" for="c-40955801">[-]</label><label class="expand" for="c-40955801">[4 more]</label></div><br/><div class="children"><div class="content">I agree.<p>The Rust implementation even needs to use a few unsafe blocks (to work with UnsafeCells internally) but is mostly safe code. Other than that you can achieve the same in C++.
But I think the real benefit is that you can write the rest of your code in safe Rust.</div><br/><div id="40955950" class="c"><input type="checkbox" id="c-40955950" checked=""/><div class="controls bullet"><span class="by">bluejekyll</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40955801">parent</a><span>|</span><a href="#40955930">next</a><span>|</span><label class="collapse" for="c-40955950">[-]</label><label class="expand" for="c-40955950">[2 more]</label></div><br/><div class="children"><div class="content">While you’re not explicitly saying this, C++ in Rust’s terms, is all unsafe. In a multi-threading context like this, that’s even more important.</div><br/><div id="40956035" class="c"><input type="checkbox" id="c-40956035" checked=""/><div class="controls bullet"><span class="by">nicholassm83</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40955950">parent</a><span>|</span><a href="#40955930">next</a><span>|</span><label class="collapse" for="c-40956035">[-]</label><label class="expand" for="c-40956035">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m trying to be polite. :-)
And there is a lot of great C++ code and developers out there - especially in the e-trading&#x2F;HFT space.</div><br/></div></div></div></div><div id="40955930" class="c"><input type="checkbox" id="c-40955930" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40955747">root</a><span>|</span><a href="#40955801">parent</a><span>|</span><a href="#40955950">prev</a><span>|</span><a href="#40954297">next</a><span>|</span><label class="collapse" for="c-40955930">[-]</label><label class="expand" for="c-40955930">[1 more]</label></div><br/><div class="children"><div class="content">Unless the rest of your code is already in C++ and you’re interested in this new better disrupter implementation, that’s probably a common situation for people interested in this topic. Any recommendations for those in that situation? perhaps existing C++ implementations already match this idk.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>