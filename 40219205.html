<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714554069589" as="style"/><link rel="stylesheet" href="styles.css?v=1714554069589"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/KindXiaoming/pykan">Kolmogorov-Arnold Networks</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>sumo43</span> | <span>22 comments</span></div><br/><div><div id="40220240" class="c"><input type="checkbox" id="c-40220240" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#40220203">next</a><span>|</span><label class="collapse" for="c-40220240">[-]</label><label class="expand" for="c-40220240">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve spent some time playing with their Jupyter notebooks. The most useful (to me, anyway) is their Example_3_classfication.ipynb ([1]).<p>It works as advertised with the parameters selected by the authors, but if we modified the network shape in the second half of the tutorial (Classification formulation) from (2, 2) to (2, 2, 2), it fails to generalize. The training loss gets down to 1e-9, while test loss stays around 3e-1. Getting to larger network sizes does not help either.<p>I would really like to see a bigger example with many more parameters and more data complexity and if it could be trained at all. MNIST would be a good start.<p>Update: I increased the training dataset size 100x, and that helps with the overfitting, but now I can&#x27;t get training loss below 1e-2. Still iterating on it; a GPU acceleration would really help - right now, my progress is limited by the speed of my CPU.<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;KindXiaoming&#x2F;pykan&#x2F;blob&#x2F;master&#x2F;tutorials&#x2F;Example_3_classfication.ipynb">https:&#x2F;&#x2F;github.com&#x2F;KindXiaoming&#x2F;pykan&#x2F;blob&#x2F;master&#x2F;tutorials&#x2F;...</a></div><br/><div id="40220925" class="c"><input type="checkbox" id="c-40220925" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#40220240">parent</a><span>|</span><a href="#40220203">next</a><span>|</span><label class="collapse" for="c-40220925">[-]</label><label class="expand" for="c-40220925">[1 more]</label></div><br/><div class="children"><div class="content">Update2: got it to 100% training accuracy, 99% test accuracy with (2, 2, 2) shape.<p>Changes:<p>1. Increased the training set from 1000 to 100k samples. This solved overfitting.<p>2. In the dataset generation, slightly reduced noise (0.1 -&gt; 0.07) so that classes don&#x27;t overlap. With an overlap, naturally, it&#x27;s impossible to hit 100%.<p>3. Most important &amp; specific to KANs: train for 30 steps with grid=5 (5 segments for each activation function), then 30 steps with grid=10 (and initializing from the previous model), and then 30 steps with grid=20. This is idiomatic to KANs and covered in the Example_1_function_fitting.ipynb: <a href="https:&#x2F;&#x2F;github.com&#x2F;KindXiaoming&#x2F;pykan&#x2F;blob&#x2F;master&#x2F;tutorials&#x2F;Example_1_function_fitting.ipynb">https:&#x2F;&#x2F;github.com&#x2F;KindXiaoming&#x2F;pykan&#x2F;blob&#x2F;master&#x2F;tutorials&#x2F;...</a><p>Overall, my impressions are:<p>- it works!<p>- the reference implementation is very slow. A GPU implementation is dearly needed.<p>- it feels like it&#x27;s a bit too non-linear and training is not as stable as it&#x27;s with MLP + ReLU.<p>- Scaling is not guaranteed to work well. Really need to see if MNIST is possible to solve with this approach.<p>I will definitely keep an eye on this development.</div><br/></div></div></div></div><div id="40220203" class="c"><input type="checkbox" id="c-40220203" checked=""/><div class="controls bullet"><span class="by">mxwsn</span><span>|</span><a href="#40220240">prev</a><span>|</span><a href="#40220706">next</a><span>|</span><label class="collapse" for="c-40220203">[-]</label><label class="expand" for="c-40220203">[1 more]</label></div><br/><div class="children"><div class="content">From the preprint - 100 input dimensions is considered &quot;high&quot;, and most problems considered have 5 or fewer input dimensions. This is typical of physics-inspired settings I&#x27;ve seen considered in ML. The next step would be demonstrating them on MNIST, which, at 784 dimensions is tiny by modern standards.</div><br/></div></div><div id="40220706" class="c"><input type="checkbox" id="c-40220706" checked=""/><div class="controls bullet"><span class="by">montebicyclelo</span><span>|</span><a href="#40220203">prev</a><span>|</span><a href="#40219890">next</a><span>|</span><label class="collapse" for="c-40220706">[-]</label><label class="expand" for="c-40220706">[2 more]</label></div><br/><div class="children"><div class="content">The success we&#x27;re seeing with neural networks is tightly coupled with the ability to scale - the algorithm itself works at scale (more layers), but it also scales well with hardware, (neural nets mostly consist of matrix multiplications, and GPUs have specialised matrix multiplication acceleration) - one of the most impactful neural network papers, AlexNet, was impactful because it showed that NNs could be put on the GPU, scaled and accelerated, to great effect.<p>It&#x27;s not clear from the paper how well this algorithm will scale, both in terms of the algorithm itself (does it still train well with more layers?), and ability to make use of hardware acceleration, (e.g. it&#x27;s not clear to me that the structure, with its per-weight activation functions, can make use of fast matmul acceleration).<p>It&#x27;s an interesting idea, that seems to work well and have nice properties on a smaller scale; but whether it&#x27;s a good architecture for imagenet, LLMs, etc. is not clear at this stage.</div><br/><div id="40220823" class="c"><input type="checkbox" id="c-40220823" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#40220706">parent</a><span>|</span><a href="#40219890">next</a><span>|</span><label class="collapse" for="c-40220823">[-]</label><label class="expand" for="c-40220823">[1 more]</label></div><br/><div class="children"><div class="content">&gt; with its per-weight activation functions<p>Sounds like something which could be approximated by a DCT (discrete cosine transform). JPEG compression does this, and there are hardware accelerations for it.<p>&gt; can make use of fast matmul acceleration<p>Maybe not, but matmul acceleration was done in hardware because it&#x27;s useful for some problems (graphics initially).<p>So if these per weight activations functions really work, people will be quick to figure out how to run them in hardware.</div><br/></div></div></div></div><div id="40219890" class="c"><input type="checkbox" id="c-40219890" checked=""/><div class="controls bullet"><span class="by">cbsmith</span><span>|</span><a href="#40220706">prev</a><span>|</span><a href="#40220702">next</a><span>|</span><label class="collapse" for="c-40219890">[-]</label><label class="expand" for="c-40219890">[1 more]</label></div><br/><div class="children"><div class="content">Feels like someone stuffed splines into decision trees.</div><br/></div></div><div id="40220702" class="c"><input type="checkbox" id="c-40220702" checked=""/><div class="controls bullet"><span class="by">arianvanp</span><span>|</span><a href="#40219890">prev</a><span>|</span><a href="#40219640">next</a><span>|</span><label class="collapse" for="c-40220702">[-]</label><label class="expand" for="c-40220702">[1 more]</label></div><br/><div class="children"><div class="content">This really reminds me of petrinets but an analog version? But instead of places and discrete tokens we have activation functions and signals. You can only trigger a transition if an activation function (place) has the right signal (tokens).</div><br/></div></div><div id="40219640" class="c"><input type="checkbox" id="c-40219640" checked=""/><div class="controls bullet"><span class="by">diwank</span><span>|</span><a href="#40220702">prev</a><span>|</span><a href="#40220742">next</a><span>|</span><label class="collapse" for="c-40219640">[-]</label><label class="expand" for="c-40219640">[3 more]</label></div><br/><div class="children"><div class="content">It’d be really cool to see a transformer with the MLP layers swapped for KANs and then compare its scaling properties with vanilla transformers</div><br/><div id="40220987" class="c"><input type="checkbox" id="c-40220987" checked=""/><div class="controls bullet"><span class="by">mp187</span><span>|</span><a href="#40219640">parent</a><span>|</span><a href="#40219995">next</a><span>|</span><label class="collapse" for="c-40220987">[-]</label><label class="expand" for="c-40220987">[1 more]</label></div><br/><div class="children"><div class="content">Why was this your first thought? Is a limiting factor to transformers the MLP layer? I thought the bottleneck was in the renormalization part.</div><br/></div></div><div id="40219995" class="c"><input type="checkbox" id="c-40219995" checked=""/><div class="controls bullet"><span class="by">gautam5669</span><span>|</span><a href="#40219640">parent</a><span>|</span><a href="#40220987">prev</a><span>|</span><a href="#40220742">next</a><span>|</span><label class="collapse" for="c-40219995">[-]</label><label class="expand" for="c-40219995">[1 more]</label></div><br/><div class="children"><div class="content">This is the first thought came to my mind too.<p>Given its sparse, Will this be just replacement for MoE.</div><br/></div></div></div></div><div id="40220742" class="c"><input type="checkbox" id="c-40220742" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#40219640">prev</a><span>|</span><a href="#40219548">next</a><span>|</span><label class="collapse" for="c-40220742">[-]</label><label class="expand" for="c-40220742">[1 more]</label></div><br/><div class="children"><div class="content">Looks very interesting, but my guess would be that this would run into the problem of exploding&#x2F;vanishing gradients at larger depths, just like TanH or sigmoid networks do.</div><br/></div></div><div id="40219548" class="c"><input type="checkbox" id="c-40219548" checked=""/><div class="controls bullet"><span class="by">Maro</span><span>|</span><a href="#40220742">prev</a><span>|</span><a href="#40219546">next</a><span>|</span><label class="collapse" for="c-40219548">[-]</label><label class="expand" for="c-40219548">[2 more]</label></div><br/><div class="children"><div class="content">Interesting!<p>Would this approach (with non-linear learning) still be able to utilize GPUs to speed up training?</div><br/><div id="40219635" class="c"><input type="checkbox" id="c-40219635" checked=""/><div class="controls bullet"><span class="by">diwank</span><span>|</span><a href="#40219548">parent</a><span>|</span><a href="#40219546">next</a><span>|</span><label class="collapse" for="c-40219635">[-]</label><label class="expand" for="c-40219635">[1 more]</label></div><br/><div class="children"><div class="content">Seconded. I’m guessing you could create an implementation that is able to do that and then write optimised triton&#x2F;cuda kernels to accelerate them but need to investigate further</div><br/></div></div></div></div><div id="40219546" class="c"><input type="checkbox" id="c-40219546" checked=""/><div class="controls bullet"><span class="by">nico</span><span>|</span><a href="#40219548">prev</a><span>|</span><a href="#40219935">next</a><span>|</span><label class="collapse" for="c-40219546">[-]</label><label class="expand" for="c-40219546">[1 more]</label></div><br/><div class="children"><div class="content">Looks super interesting<p>I wonder how many more new architectures are going to be found in the next few years</div><br/></div></div><div id="40219935" class="c"><input type="checkbox" id="c-40219935" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#40219546">prev</a><span>|</span><label class="collapse" for="c-40219935">[-]</label><label class="expand" for="c-40219935">[7 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t assess this, but I do worry that overnight some algorithmic advance will enhance LLMs by orders of magnitude and the next big model to get trained is suddenly 10,000x better than GPT-4 and nobody&#x27;s ready for it.</div><br/><div id="40220191" class="c"><input type="checkbox" id="c-40220191" checked=""/><div class="controls bullet"><span class="by">6mian</span><span>|</span><a href="#40219935">parent</a><span>|</span><a href="#40220169">next</a><span>|</span><label class="collapse" for="c-40220191">[-]</label><label class="expand" for="c-40220191">[4 more]</label></div><br/><div class="children"><div class="content">What to be worried about? Technical progress will happen, sometimes by sudden jumps. Some company will become a leader, competitors will catch up after a while.</div><br/><div id="40220310" class="c"><input type="checkbox" id="c-40220310" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#40219935">root</a><span>|</span><a href="#40220191">parent</a><span>|</span><a href="#40220169">next</a><span>|</span><label class="collapse" for="c-40220310">[-]</label><label class="expand" for="c-40220310">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Technical progress&quot; has been destroying our habitat for centuries, causing lots of other species to go extinct. Pretty much the entire planet surface has been &#x27;technically progressed&#x27;, spreading plastics, climate change and whatnot over the entirety of it.<p>Are you assuming that this particular &quot;progress&quot; would be relatively innocent?</div><br/><div id="40220549" class="c"><input type="checkbox" id="c-40220549" checked=""/><div class="controls bullet"><span class="by">6mian</span><span>|</span><a href="#40219935">root</a><span>|</span><a href="#40220310">parent</a><span>|</span><a href="#40220169">next</a><span>|</span><label class="collapse" for="c-40220549">[-]</label><label class="expand" for="c-40220549">[2 more]</label></div><br/><div class="children"><div class="content">On the other hand, the same &quot;technical progress&quot; (if we&#x27;re putting machine learning, deforestation, and mining in the same bag) gave you medicine, which turns many otherwise deadly diseases into inconveniences and allows you to work less than 12 hrs&#x2F;7 days per week to not die from hunger in a large portion of the world. A few hundred years ago, unless you were born into the lucky 0.01% of the ruling population, working from dawn to sunset was the norm for a lot more people than now.<p>I&#x27;m not assuming that something 10k x better than GPT-4 will be good or bad; I don&#x27;t know. I was just curious what exactly to be worried about. I think in the current state, LLMs are already advanced enough for bad uses like article generation for SEO, spam, scams, etc., and I wonder if an order of magnitude better model would allow for something worse.</div><br/><div id="40220778" class="c"><input type="checkbox" id="c-40220778" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#40219935">root</a><span>|</span><a href="#40220549">parent</a><span>|</span><a href="#40220169">next</a><span>|</span><label class="collapse" for="c-40220778">[-]</label><label class="expand" for="c-40220778">[1 more]</label></div><br/><div class="children"><div class="content">Where did you learn that history?<p>What do you mean by &quot;better&quot;?</div><br/></div></div></div></div></div></div></div></div><div id="40220169" class="c"><input type="checkbox" id="c-40220169" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40219935">parent</a><span>|</span><a href="#40220191">prev</a><span>|</span><label class="collapse" for="c-40220169">[-]</label><label class="expand" for="c-40220169">[2 more]</label></div><br/><div class="children"><div class="content">&gt;some algorithmic advance will enhance LLMs by orders of magnitude<p>I would worry if I&#x27;d own Nvidia shares.</div><br/><div id="40220564" class="c"><input type="checkbox" id="c-40220564" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#40219935">root</a><span>|</span><a href="#40220169">parent</a><span>|</span><label class="collapse" for="c-40220564">[-]</label><label class="expand" for="c-40220564">[1 more]</label></div><br/><div class="children"><div class="content">Actually, that would be fantastic for NVIDIA shares;<p>1. A new architecture would make all&#x2F;most of these upcoming Transformer accelerators obsolete =&gt; back to GPUs.<p>2. Higher performance LLMs on GPUs =&gt; we can speed up LLMs with 1T+ parameters. So, LLMs become more useful, so more of GPUs would be purchased.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>