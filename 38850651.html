<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1704272454178" as="style"/><link rel="stylesheet" href="styles.css?v=1704272454178"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/attractivechaos/plb2">Benchmarking 20 programming languages on N-queens and matrix multiplication</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>attractivechaos</span> | <span>77 comments</span></div><br/><div><div id="38851414" class="c"><input type="checkbox" id="c-38851414" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#38851002">next</a><span>|</span><label class="collapse" for="c-38851414">[-]</label><label class="expand" for="c-38851414">[1 more]</label></div><br/><div class="children"><div class="content">I love a good benchmark, thanks for putting this together! However, I have a bit of feedback.<p>First, the graph is misleading, stacking times with languages that have half the implementation, they appear faster, until you dig in. I&#x27;d suggest producing an alternate graph that shows only the implemented puzzles in every language, or make a unique graph for every language:puzzle.<p>Second, the examples are taken from rosetta code and are not necessarily what would be the best implementation, or even close to the best implementation, for benchmarking purposes.<p>Finally, those examples should be reproduced across various hardware platforms, I&#x27;m on arm64 Darwin myself, but you might find different results on Intel platforms due to the various compiler optimizations available based on the hardware.<p>More benchmarks would be interesting to see, such as actual real world operations, e.g. opening a file, reading it, parsing json, opening a socket server, etc.</div><br/></div></div><div id="38851002" class="c"><input type="checkbox" id="c-38851002" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38851414">prev</a><span>|</span><a href="#38851700">next</a><span>|</span><label class="collapse" for="c-38851002">[-]</label><label class="expand" for="c-38851002">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It is obvious that c[i], b[k] and a[i][k] can be moved out of the inner loop to reduce the frequency of matrix access. [...] However, most other languages cannot optimize this nested loop. If we manually move a[i][k] to the loop above it, we can often improve their performance.<p>This is only true when three matrices are independent of each other, and also why C has a `restrict` qualifier that enables this assumption. The benchmark itself has no such assumption because all three variables are defined as `double **`, and it can be verified by assembly outputs. Clang&#x27;s excellent performance in matmul is probably much more due to autovectorization.</div><br/><div id="38851882" class="c"><input type="checkbox" id="c-38851882" checked=""/><div class="controls bullet"><span class="by">yxhuvud</span><span>|</span><a href="#38851002">parent</a><span>|</span><a href="#38851700">next</a><span>|</span><label class="collapse" for="c-38851882">[-]</label><label class="expand" for="c-38851882">[1 more]</label></div><br/><div class="children"><div class="content">In some cases there are other reasons for housing the dereference too. For example, Crystal will check if the array access is out of bounds and by hoisting variables that will be done a lot less seldom, which can have huge effects for code that does a lot of that, like matmul.</div><br/></div></div></div></div><div id="38851700" class="c"><input type="checkbox" id="c-38851700" checked=""/><div class="controls bullet"><span class="by">hyperman1</span><span>|</span><a href="#38851002">prev</a><span>|</span><a href="#38851038">next</a><span>|</span><label class="collapse" for="c-38851700">[-]</label><label class="expand" for="c-38851700">[4 more]</label></div><br/><div class="children"><div class="content">I wondered why rust is so far behind C&#x2F;nim&#x2F;zig, they should have similar behaviour.<p>The difference is mostly in matmul.<p>I see how C, for an n x n matrix, does 2 allocations, while rust does n+1.  C&#x27;s matrix rows are right next to each other, rusts are probably all over the place.  Didn&#x27;t look at nim or zig.<p>Maybe a slice of slice of double would perform better than a vec of vec of double?  Then again, an argument can be made that rust pushes you to vec, so this impl is more honest for how a beginner would do it. Otoh, C has the optimization so why doesn&#x27;t rust?</div><br/><div id="38851754" class="c"><input type="checkbox" id="c-38851754" checked=""/><div class="controls bullet"><span class="by">nrabulinski</span><span>|</span><a href="#38851700">parent</a><span>|</span><a href="#38851802">next</a><span>|</span><label class="collapse" for="c-38851754">[-]</label><label class="expand" for="c-38851754">[2 more]</label></div><br/><div class="children"><div class="content">The rust code is very unidiomatic, not only because of the Vec of Vecs which I’d say, even if it’s the obvious naive approach, no one experienced wouldn’t choose over a flat slice, the implementation itself is very naive and unidiomatic.</div><br/><div id="38851947" class="c"><input type="checkbox" id="c-38851947" checked=""/><div class="controls bullet"><span class="by">hgomersall</span><span>|</span><a href="#38851700">root</a><span>|</span><a href="#38851754">parent</a><span>|</span><a href="#38851802">next</a><span>|</span><label class="collapse" for="c-38851947">[-]</label><label class="expand" for="c-38851947">[1 more]</label></div><br/><div class="children"><div class="content">Also it&#x27;s using checked indexing, which apart from being not idiomatic, is also going to slow things down. A fairer comparison would be to use the unchecked indexing variants.</div><br/></div></div></div></div><div id="38851802" class="c"><input type="checkbox" id="c-38851802" checked=""/><div class="controls bullet"><span class="by">tiehuis</span><span>|</span><a href="#38851700">parent</a><span>|</span><a href="#38851754">prev</a><span>|</span><a href="#38851038">next</a><span>|</span><label class="collapse" for="c-38851802">[-]</label><label class="expand" for="c-38851802">[1 more]</label></div><br/><div class="children"><div class="content">Zig had a similar issue which I made an MR to fix. I didn&#x27;t actually notice Rust had the same issue but that&#x27;s probably just my forgotten knowledge with how the vec! macros expand when nested.</div><br/></div></div></div></div><div id="38851038" class="c"><input type="checkbox" id="c-38851038" checked=""/><div class="controls bullet"><span class="by">jodrellblank</span><span>|</span><a href="#38851700">prev</a><span>|</span><a href="#38851120">next</a><span>|</span><label class="collapse" for="c-38851038">[-]</label><label class="expand" for="c-38851038">[1 more]</label></div><br/><div class="children"><div class="content">Doesn’t include Prolog which has decent constraint solver answers for n-queens and sudoku, which are pretty fast but I don’t know how they would compare in benchmarks:<p><a href="https:&#x2F;&#x2F;www.metalevel.at&#x2F;queens&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.metalevel.at&#x2F;queens&#x2F;</a><p><a href="https:&#x2F;&#x2F;www.metalevel.at&#x2F;sudoku&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.metalevel.at&#x2F;sudoku&#x2F;</a></div><br/></div></div><div id="38851120" class="c"><input type="checkbox" id="c-38851120" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#38851038">prev</a><span>|</span><a href="#38851263">next</a><span>|</span><label class="collapse" for="c-38851120">[-]</label><label class="expand" for="c-38851120">[7 more]</label></div><br/><div class="children"><div class="content">Aren’t JIT languages at a disadvantage since they are benchmarked through the CLI rather than using a benchmarking library to allow JIT to warmup?</div><br/><div id="38851703" class="c"><input type="checkbox" id="c-38851703" checked=""/><div class="controls bullet"><span class="by">brabel</span><span>|</span><a href="#38851120">parent</a><span>|</span><a href="#38851353">next</a><span>|</span><label class="collapse" for="c-38851703">[-]</label><label class="expand" for="c-38851703">[1 more]</label></div><br/><div class="children"><div class="content">For one-time problem runs, the JIT languages in practice will not be given time to warm up. All that matters for a user is how fast the application is in practice. It&#x27;s not about &quot;making it fair&quot; for languages, it&#x27;s about measuring how fast they go from nothing to results.<p>It doesn&#x27;t make sense to allow &quot;warmup&quot; time for them unless your expected application is a server which for most of the time will be running &quot;warm&quot; (and even then with scalable containers that assumption may not even be true in some cases). For servers, however, what matters is mostly how fast its HTTP library is and how good the async IO is... check Techempower benchmarks for that: <a href="https:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;#hw=ph&amp;test=fortune&amp;section=data-r22" rel="nofollow">https:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;#hw=ph&amp;test=fortune&amp;s...</a></div><br/></div></div><div id="38851353" class="c"><input type="checkbox" id="c-38851353" checked=""/><div class="controls bullet"><span class="by">jakobnissen</span><span>|</span><a href="#38851120">parent</a><span>|</span><a href="#38851703">prev</a><span>|</span><a href="#38851305">next</a><span>|</span><label class="collapse" for="c-38851353">[-]</label><label class="expand" for="c-38851353">[3 more]</label></div><br/><div class="children"><div class="content">Yes, but the author claims the longest JIT warmup is 0.3 seconds, so it&#x27;s not an important issue in these benchmarks that take several seconds.</div><br/><div id="38851378" class="c"><input type="checkbox" id="c-38851378" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38851120">root</a><span>|</span><a href="#38851353">parent</a><span>|</span><a href="#38851305">next</a><span>|</span><label class="collapse" for="c-38851378">[-]</label><label class="expand" for="c-38851378">[2 more]</label></div><br/><div class="children"><div class="content">I strongly suspect that the author may have confused the JIT warmup (hard to measure, as you need to ensure that the performance figure have reached the stable point) from the startup overhead (easy to measure).</div><br/><div id="38851620" class="c"><input type="checkbox" id="c-38851620" checked=""/><div class="controls bullet"><span class="by">vkazanov</span><span>|</span><a href="#38851120">root</a><span>|</span><a href="#38851378">parent</a><span>|</span><a href="#38851305">next</a><span>|</span><label class="collapse" for="c-38851620">[-]</label><label class="expand" for="c-38851620">[1 more]</label></div><br/><div class="children"><div class="content">...and many jitted vms do not even reach a stable point at all, there was a big paper on this a couple of years ago.</div><br/></div></div></div></div></div></div><div id="38851305" class="c"><input type="checkbox" id="c-38851305" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#38851120">parent</a><span>|</span><a href="#38851353">prev</a><span>|</span><a href="#38851263">next</a><span>|</span><label class="collapse" for="c-38851305">[-]</label><label class="expand" for="c-38851305">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s CLI?</div><br/><div id="38851674" class="c"><input type="checkbox" id="c-38851674" checked=""/><div class="controls bullet"><span class="by">zogrodea</span><span>|</span><a href="#38851120">root</a><span>|</span><a href="#38851305">parent</a><span>|</span><a href="#38851263">next</a><span>|</span><label class="collapse" for="c-38851674">[-]</label><label class="expand" for="c-38851674">[1 more]</label></div><br/><div class="children"><div class="content">Presumably command line interface&#x2F;terminal. I can type `dotnet run` in the terminal and provide some options to runa .NET program for example.</div><br/></div></div></div></div></div></div><div id="38851263" class="c"><input type="checkbox" id="c-38851263" checked=""/><div class="controls bullet"><span class="by">jakobnissen</span><span>|</span><a href="#38851120">prev</a><span>|</span><a href="#38851954">next</a><span>|</span><label class="collapse" for="c-38851263">[-]</label><label class="expand" for="c-38851263">[1 more]</label></div><br/><div class="children"><div class="content">Neat!<p>The Julia matmul implementation has its rows and columns flipped though - unlike C, Julia uses row-major matrices. This has large implications for speed.<p>Also, the code may be much faster if you enable SIMD in the function, which is disabled in the code because a) the code unnecessarily checks bounds at every index instead of at the top of the function, and b) float SIMD is opt-in since SIMD changes the rounding</div><br/></div></div><div id="38851954" class="c"><input type="checkbox" id="c-38851954" checked=""/><div class="controls bullet"><span class="by">_giorgio_</span><span>|</span><a href="#38851263">prev</a><span>|</span><a href="#38851060">next</a><span>|</span><label class="collapse" for="c-38851954">[-]</label><label class="expand" for="c-38851954">[1 more]</label></div><br/><div class="children"><div class="content">Given the times we&#x27;re in, it would be interesting to test some libraries too, like numpy and pytorch</div><br/></div></div><div id="38851060" class="c"><input type="checkbox" id="c-38851060" checked=""/><div class="controls bullet"><span class="by">alberth</span><span>|</span><a href="#38851954">prev</a><span>|</span><a href="#38851575">next</a><span>|</span><label class="collapse" for="c-38851060">[-]</label><label class="expand" for="c-38851060">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>” Timing on Apple M1 Macbook Pro”</i><p>Given that its become increasingly more common for CPUs to have both Performance &amp; Efficency cores … how do benchmarks ensure they are only being run on the P-cores?</div><br/><div id="38851466" class="c"><input type="checkbox" id="c-38851466" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38851060">parent</a><span>|</span><a href="#38851575">next</a><span>|</span><label class="collapse" for="c-38851466">[-]</label><label class="expand" for="c-38851466">[1 more]</label></div><br/><div class="children"><div class="content">It actually takes a bit of effort to run on the efficiency cores.<p>I believe Game Mode will push the processes to e cores to keep a consistent game play without thermal throttling.</div><br/></div></div></div></div><div id="38851575" class="c"><input type="checkbox" id="c-38851575" checked=""/><div class="controls bullet"><span class="by">naet</span><span>|</span><a href="#38851060">prev</a><span>|</span><a href="#38851623">next</a><span>|</span><label class="collapse" for="c-38851575">[-]</label><label class="expand" for="c-38851575">[2 more]</label></div><br/><div class="children"><div class="content">Surprised how well JS (node and others) seem to come out when I&#x27;ve had firsthand experience of switching from JS to Go to speed up an algorithm type question and had the Go version crank through a bruteforce much much faster.<p>Maybe I made an accidental optimization in my language translation, or maybe there are some operations that are much slower in JS and these benchmarks didn&#x27;t hit any of them.</div><br/><div id="38851627" class="c"><input type="checkbox" id="c-38851627" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38851575">parent</a><span>|</span><a href="#38851623">next</a><span>|</span><label class="collapse" for="c-38851627">[-]</label><label class="expand" for="c-38851627">[1 more]</label></div><br/><div class="children"><div class="content">Go&#x27;s AOT compiler is actually not that sophiscated (comparable to -O1 in most C compilers, possibly even worse). Was your program running only for a fraction of a second? Then the JIT may haven&#x27;t fully warmed up and even a basic AOT compiler has a better chance to win.</div><br/></div></div></div></div><div id="38851623" class="c"><input type="checkbox" id="c-38851623" checked=""/><div class="controls bullet"><span class="by">nnx</span><span>|</span><a href="#38851575">prev</a><span>|</span><a href="#38851239">next</a><span>|</span><label class="collapse" for="c-38851623">[-]</label><label class="expand" for="c-38851623">[1 more]</label></div><br/><div class="children"><div class="content">Nice to see Go performing well.
Would be interesting to see the results with PGO enabled.</div><br/></div></div><div id="38851239" class="c"><input type="checkbox" id="c-38851239" checked=""/><div class="controls bullet"><span class="by">latenightcoding</span><span>|</span><a href="#38851623">prev</a><span>|</span><a href="#38850957">next</a><span>|</span><label class="collapse" for="c-38851239">[-]</label><label class="expand" for="c-38851239">[2 more]</label></div><br/><div class="children"><div class="content">These are not the best benchmarks, but Python is indeed as slow as Perl, which I find insane considering that Python has 100-1000 more people working on the interpreter and performance has been a big emphasis the last few years.</div><br/><div id="38851810" class="c"><input type="checkbox" id="c-38851810" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#38851239">parent</a><span>|</span><a href="#38850957">next</a><span>|</span><label class="collapse" for="c-38851810">[-]</label><label class="expand" for="c-38851810">[1 more]</label></div><br/><div class="children"><div class="content">The benchmark is not representative of how Python is actually used in practice. It ignores the existence of libraries (explicitly). For example, If numpy, pytorch were used for matmul, the results would be completely different.</div><br/></div></div></div></div><div id="38850957" class="c"><input type="checkbox" id="c-38850957" checked=""/><div class="controls bullet"><span class="by">theteapot</span><span>|</span><a href="#38851239">prev</a><span>|</span><a href="#38851491">next</a><span>|</span><label class="collapse" for="c-38850957">[-]</label><label class="expand" for="c-38850957">[5 more]</label></div><br/><div class="children"><div class="content">PHP results: I was stupid enough to write some scientific code in PHP once so know how slow it can be - mostly around array access and manipulation. But if your going to try, use the HHVM interpreter. It&#x27;s much faster and is a drop in replacement for the PHP interpreter. Hack (<a href="https:&#x2F;&#x2F;hacklang.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hacklang.org&#x2F;</a>) uses that under the hood by default.</div><br/><div id="38851763" class="c"><input type="checkbox" id="c-38851763" checked=""/><div class="controls bullet"><span class="by">geek_at</span><span>|</span><a href="#38850957">parent</a><span>|</span><a href="#38851058">next</a><span>|</span><label class="collapse" for="c-38851763">[-]</label><label class="expand" for="c-38851763">[1 more]</label></div><br/><div class="children"><div class="content">Also since PHP was built for web requests it builds The cache on the First run. would be interesting to see All languages of the benchmark with a second run</div><br/></div></div><div id="38851058" class="c"><input type="checkbox" id="c-38851058" checked=""/><div class="controls bullet"><span class="by">habibur</span><span>|</span><a href="#38850957">parent</a><span>|</span><a href="#38851763">prev</a><span>|</span><a href="#38851491">next</a><span>|</span><label class="collapse" for="c-38851058">[-]</label><label class="expand" for="c-38851058">[3 more]</label></div><br/><div class="children"><div class="content">I put the pure math codes in C extension of PHP. Building C extension for PHP is easier than most of the other high level languages. And then things get blazingly fast.</div><br/><div id="38851375" class="c"><input type="checkbox" id="c-38851375" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#38850957">root</a><span>|</span><a href="#38851058">parent</a><span>|</span><a href="#38851491">next</a><span>|</span><label class="collapse" for="c-38851375">[-]</label><label class="expand" for="c-38851375">[2 more]</label></div><br/><div class="children"><div class="content">doesn&#x27;t look that easy... zend_parse_parameters? pre-baked configure + make scripts?<p>check out how a modern language deals with this stuff <a href="https:&#x2F;&#x2F;bun.sh&#x2F;docs&#x2F;api&#x2F;ffi#usage" rel="nofollow">https:&#x2F;&#x2F;bun.sh&#x2F;docs&#x2F;api&#x2F;ffi#usage</a></div><br/><div id="38851998" class="c"><input type="checkbox" id="c-38851998" checked=""/><div class="controls bullet"><span class="by">rafark</span><span>|</span><a href="#38850957">root</a><span>|</span><a href="#38851375">parent</a><span>|</span><a href="#38851491">next</a><span>|</span><label class="collapse" for="c-38851998">[-]</label><label class="expand" for="c-38851998">[1 more]</label></div><br/><div class="children"><div class="content">Checkout what? PHP also has support for FFI. Or am I missing something?</div><br/></div></div></div></div></div></div></div></div><div id="38851491" class="c"><input type="checkbox" id="c-38851491" checked=""/><div class="controls bullet"><span class="by">account-5</span><span>|</span><a href="#38850957">prev</a><span>|</span><a href="#38851230">next</a><span>|</span><label class="collapse" for="c-38851491">[-]</label><label class="expand" for="c-38851491">[2 more]</label></div><br/><div class="children"><div class="content">Glad to see dart in there, it&#x27;s normally overlooked. Not a bad result. I wonder what speed it would be if it had been AOT compiled instead of JIT.</div><br/><div id="38851554" class="c"><input type="checkbox" id="c-38851554" checked=""/><div class="controls bullet"><span class="by">adamredwoods</span><span>|</span><a href="#38851491">parent</a><span>|</span><a href="#38851230">next</a><span>|</span><label class="collapse" for="c-38851554">[-]</label><label class="expand" for="c-38851554">[1 more]</label></div><br/><div class="children"><div class="content">And LuaJit surprised me quite a bit!</div><br/></div></div></div></div><div id="38851230" class="c"><input type="checkbox" id="c-38851230" checked=""/><div class="controls bullet"><span class="by">metaltyphoon</span><span>|</span><a href="#38851491">prev</a><span>|</span><a href="#38851169">next</a><span>|</span><label class="collapse" for="c-38851230">[-]</label><label class="expand" for="c-38851230">[5 more]</label></div><br/><div class="children"><div class="content">Why not run C# as AOT? It’s a one line change.</div><br/><div id="38851794" class="c"><input type="checkbox" id="c-38851794" checked=""/><div class="controls bullet"><span class="by">xnorswap</span><span>|</span><a href="#38851230">parent</a><span>|</span><a href="#38851315">next</a><span>|</span><label class="collapse" for="c-38851794">[-]</label><label class="expand" for="c-38851794">[1 more]</label></div><br/><div class="children"><div class="content">Or use BenchmarkDotNet which, among other things to get an accurate benchmark, does JIT warmup outside of measurement.<p>( <a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;BenchmarkDotNet">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;BenchmarkDotNet</a> ).</div><br/></div></div><div id="38851315" class="c"><input type="checkbox" id="c-38851315" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#38851230">parent</a><span>|</span><a href="#38851794">prev</a><span>|</span><a href="#38851169">next</a><span>|</span><label class="collapse" for="c-38851315">[-]</label><label class="expand" for="c-38851315">[3 more]</label></div><br/><div class="children"><div class="content">Do people usually run C# code AOT compiled?</div><br/><div id="38851390" class="c"><input type="checkbox" id="c-38851390" checked=""/><div class="controls bullet"><span class="by">romanovcode</span><span>|</span><a href="#38851230">root</a><span>|</span><a href="#38851315">parent</a><span>|</span><a href="#38851776">next</a><span>|</span><label class="collapse" for="c-38851390">[-]</label><label class="expand" for="c-38851390">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s for something stupid like benchmark comparison - yes.</div><br/></div></div><div id="38851776" class="c"><input type="checkbox" id="c-38851776" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#38851230">root</a><span>|</span><a href="#38851315">parent</a><span>|</span><a href="#38851390">prev</a><span>|</span><a href="#38851169">next</a><span>|</span><label class="collapse" for="c-38851776">[-]</label><label class="expand" for="c-38851776">[1 more]</label></div><br/><div class="children"><div class="content">It’s gaining popularity for CLI and serverless, some people use it to replace C++ for writing native libraries and plugins as well.</div><br/></div></div></div></div></div></div><div id="38851169" class="c"><input type="checkbox" id="c-38851169" checked=""/><div class="controls bullet"><span class="by">daxfohl</span><span>|</span><a href="#38851230">prev</a><span>|</span><a href="#38851055">next</a><span>|</span><label class="collapse" for="c-38851169">[-]</label><label class="expand" for="c-38851169">[3 more]</label></div><br/><div class="children"><div class="content">Odd that nqueens and sudoku have a high correlation but matmul seems to be largely doing its own thing.<p>nqueen vs. sudoku: 0.531<p>matmul vs. sudoku: 0.362<p>matmul vs. nqueen: 0.127</div><br/><div id="38851396" class="c"><input type="checkbox" id="c-38851396" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#38851169">parent</a><span>|</span><a href="#38851055">next</a><span>|</span><label class="collapse" for="c-38851396">[-]</label><label class="expand" for="c-38851396">[2 more]</label></div><br/><div class="children"><div class="content">matmul is old and useful -- there&#x27;s a lot of hardware on a chip that makes it run much faster (prefetch, vectorization, instruction parallelism) and some of these languages have optimizations to expose those things automatically.</div><br/><div id="38851943" class="c"><input type="checkbox" id="c-38851943" checked=""/><div class="controls bullet"><span class="by">yxhuvud</span><span>|</span><a href="#38851169">root</a><span>|</span><a href="#38851396">parent</a><span>|</span><a href="#38851055">next</a><span>|</span><label class="collapse" for="c-38851943">[-]</label><label class="expand" for="c-38851943">[1 more]</label></div><br/><div class="children"><div class="content">And some languages that perform array bounds check on each array deindex operation, which basically stops some of the above even if the optimizer can do all of it. Crystal is an example of that, where it would be possible and quite straightforward to write a specialized matrix class instead of the very generic dynamic array implementation.</div><br/></div></div></div></div></div></div><div id="38851055" class="c"><input type="checkbox" id="c-38851055" checked=""/><div class="controls bullet"><span class="by">shpx</span><span>|</span><a href="#38851169">prev</a><span>|</span><a href="#38851102">next</a><span>|</span><label class="collapse" for="c-38851055">[-]</label><label class="expand" for="c-38851055">[5 more]</label></div><br/><div class="children"><div class="content">You should add a chart of the number of gzip&#x27;d bytes of source code.</div><br/><div id="38851116" class="c"><input type="checkbox" id="c-38851116" checked=""/><div class="controls bullet"><span class="by">morepedantic</span><span>|</span><a href="#38851055">parent</a><span>|</span><a href="#38851102">next</a><span>|</span><label class="collapse" for="c-38851116">[-]</label><label class="expand" for="c-38851116">[4 more]</label></div><br/><div class="children"><div class="content">IMO, uncompressed bytes is a better representation, because it can be used to compare relative expressive power for the particular problem. I&#x27;d bet Python cleans house here, but the write-only languages are a wild card.</div><br/><div id="38851285" class="c"><input type="checkbox" id="c-38851285" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38851055">root</a><span>|</span><a href="#38851116">parent</a><span>|</span><a href="#38851208">next</a><span>|</span><label class="collapse" for="c-38851285">[-]</label><label class="expand" for="c-38851285">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Expressive power&quot; is a very subjective term, and uncompressed size is a bad proxy as it includes too many variables specific to coding conventions. Compressed size with a stupid enough algorithm (here gzip) is meant to reduce these variables. The true Kolmogorov complexity in comparison can&#x27;t be computed, and too smart algorithms can start to infer enough about the language itself.</div><br/></div></div><div id="38851208" class="c"><input type="checkbox" id="c-38851208" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#38851055">root</a><span>|</span><a href="#38851116">parent</a><span>|</span><a href="#38851285">prev</a><span>|</span><a href="#38851102">next</a><span>|</span><label class="collapse" for="c-38851208">[-]</label><label class="expand" for="c-38851208">[2 more]</label></div><br/><div class="children"><div class="content">Why would uncompressed bytes be better? Using a good compression algorithm better approximates the statistical entropy of the code which is at least correlated with e.g., Kolmogorov complexity.</div><br/><div id="38851659" class="c"><input type="checkbox" id="c-38851659" checked=""/><div class="controls bullet"><span class="by">iopq</span><span>|</span><a href="#38851055">root</a><span>|</span><a href="#38851208">parent</a><span>|</span><a href="#38851102">next</a><span>|</span><label class="collapse" for="c-38851659">[-]</label><label class="expand" for="c-38851659">[1 more]</label></div><br/><div class="children"><div class="content">because it often sits uncompressed on the drive</div><br/></div></div></div></div></div></div></div></div><div id="38851102" class="c"><input type="checkbox" id="c-38851102" checked=""/><div class="controls bullet"><span class="by">sakras</span><span>|</span><a href="#38851055">prev</a><span>|</span><a href="#38851517">next</a><span>|</span><label class="collapse" for="c-38851102">[-]</label><label class="expand" for="c-38851102">[1 more]</label></div><br/><div class="children"><div class="content">How come not all benchmarks appear on all languages? For example, Zig&#x27;s bar appears to be lower than C&#x27;s by virtue of sudoku and bedconv being missing.</div><br/></div></div><div id="38851517" class="c"><input type="checkbox" id="c-38851517" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#38851102">prev</a><span>|</span><a href="#38851323">next</a><span>|</span><label class="collapse" for="c-38851517">[-]</label><label class="expand" for="c-38851517">[1 more]</label></div><br/><div class="children"><div class="content">C# code should be using an official package for GEMM which is System.Numerics.Tensors, it is pure C# but runs at max hw efficiency (it is also idiomatic). Or at least use Vector&lt;T&gt; instead of scalar operations. I’d expect this applies to most other popular languages here too.</div><br/></div></div><div id="38851323" class="c"><input type="checkbox" id="c-38851323" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#38851517">prev</a><span>|</span><a href="#38851625">next</a><span>|</span><label class="collapse" for="c-38851323">[-]</label><label class="expand" for="c-38851323">[1 more]</label></div><br/><div class="children"><div class="content">N-queens and matrix benchmark without Fortran and Wolfram Mathematica?</div><br/></div></div><div id="38851625" class="c"><input type="checkbox" id="c-38851625" checked=""/><div class="controls bullet"><span class="by">1letterunixname</span><span>|</span><a href="#38851323">prev</a><span>|</span><a href="#38850997">next</a><span>|</span><label class="collapse" for="c-38851625">[-]</label><label class="expand" for="c-38851625">[1 more]</label></div><br/><div class="children"><div class="content">For the love of god, log graph tiny values with large values please. :)</div><br/></div></div><div id="38850997" class="c"><input type="checkbox" id="c-38850997" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#38851625">prev</a><span>|</span><a href="#38850948">next</a><span>|</span><label class="collapse" for="c-38850997">[-]</label><label class="expand" for="c-38850997">[23 more]</label></div><br/><div class="children"><div class="content">What is this supposed to demonstrate?<p>There appears to be roughly the same code structure, ported to every language, while for some languages, arbitrary optimizations are introduced (such as using `array` instead of `list` in Python).<p>But nobody working in Python uses matrix multiplication code written in Python. They use NumPy, which is a <i>de facto</i> standard library for people working in the relevant fields. It&#x27;s as much part of &quot;Python&quot; as list comprehensions.<p>Without taking such real-world conventions into account, such comparisons say essentially nothing about the languages involved (and their all-important ecosystems).</div><br/><div id="38851373" class="c"><input type="checkbox" id="c-38851373" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#38850997">parent</a><span>|</span><a href="#38851875">next</a><span>|</span><label class="collapse" for="c-38851373">[-]</label><label class="expand" for="c-38851373">[7 more]</label></div><br/><div class="children"><div class="content">Generally, the point of language benchmarks is to show how the languages compare at solving the same problem, without external libraries. Including external libraries is pointless since any language can call any library, ultimately, so at best you&#x27;d be comparing the FFI overhead.<p>So this shouldn&#x27;t be taken as &quot;how fast does a real-world Python program do at matrix multiplication&quot;, since of course no one writes real-world programs doing matrix multiplication in pure Python. But it can show the relative speed of pure Python at purely computational tasks.</div><br/><div id="38851408" class="c"><input type="checkbox" id="c-38851408" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851373">parent</a><span>|</span><a href="#38851410">next</a><span>|</span><label class="collapse" for="c-38851408">[-]</label><label class="expand" for="c-38851408">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But it can show the relative speed of pure Python at purely computational tasks.<p>But that&#x27;s irrelevant if nobody uses &quot;pure Python&quot; for computational tasks.<p>It&#x27;s like asking &quot;how well do these languages run on a Lisp machine from 1979?&quot;. It simply has no relevance to real-world considerations today.</div><br/><div id="38851433" class="c"><input type="checkbox" id="c-38851433" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851408">parent</a><span>|</span><a href="#38851556">next</a><span>|</span><label class="collapse" for="c-38851433">[-]</label><label class="expand" for="c-38851433">[2 more]</label></div><br/><div class="children"><div class="content">Everyone uses pure python for purely computational tasks. numpy or pytorch has far too few operation to even count as all the computational task. e.g. most of the operations of pandas is written in pure python, and at times I found using specialised libraries could give 10x improvement but with blow to developer experience compared to python.</div><br/><div id="38851847" class="c"><input type="checkbox" id="c-38851847" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851433">parent</a><span>|</span><a href="#38851556">next</a><span>|</span><label class="collapse" for="c-38851847">[-]</label><label class="expand" for="c-38851847">[1 more]</label></div><br/><div class="children"><div class="content">Pandas&#x2F;Numpy uses a lot of C and Scipy a lot of Fortran</div><br/></div></div></div></div><div id="38851556" class="c"><input type="checkbox" id="c-38851556" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851408">parent</a><span>|</span><a href="#38851433">prev</a><span>|</span><a href="#38851410">next</a><span>|</span><label class="collapse" for="c-38851556">[-]</label><label class="expand" for="c-38851556">[1 more]</label></div><br/><div class="children"><div class="content">Every time you use a for loop, addition or multiplication operators, array indexing, assingment to numerical variable in Python, you are using exactly what is benchmarked in matmul.</div><br/></div></div></div></div><div id="38851410" class="c"><input type="checkbox" id="c-38851410" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851373">parent</a><span>|</span><a href="#38851408">prev</a><span>|</span><a href="#38851875">next</a><span>|</span><label class="collapse" for="c-38851410">[-]</label><label class="expand" for="c-38851410">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Generally, the point of language benchmarks is to show how the languages compare at solving the same problem, without external libraries.<p>If this were the only concern, it should be valid to create a blob of binary and call that function for the optimal performance. (Python&#x27;s ctypes makes this very easy, for example.) So you want an <i>idiomatic</i> solution instead, and Numpy for matrix computation is considered idiomatic in Python, even more than the pure Python code.</div><br/><div id="38852008" class="c"><input type="checkbox" id="c-38852008" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851410">parent</a><span>|</span><a href="#38851875">next</a><span>|</span><label class="collapse" for="c-38852008">[-]</label><label class="expand" for="c-38852008">[1 more]</label></div><br/><div class="children"><div class="content">No, creating a binary blob is not a realistic option, and it&#x27;s still not a Python&#x2F;Java&#x2F;C++ whatever solution. It would be handwritten assembly that you use the FFI facilities to call into. So, it&#x27;s not fair game in any honest benchmark.<p>And even if using a C library is idiomatic Python, it still has no place in a language benchmark. It&#x27;s a C library, not a Python implementation.</div><br/></div></div></div></div></div></div><div id="38851875" class="c"><input type="checkbox" id="c-38851875" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#38850997">parent</a><span>|</span><a href="#38851373">prev</a><span>|</span><a href="#38851096">next</a><span>|</span><label class="collapse" for="c-38851875">[-]</label><label class="expand" for="c-38851875">[1 more]</label></div><br/><div class="children"><div class="content">So you&#x27;d be measuring the speed of loops over out calls to c or Fortran (nag library) or their vectorisation and only testing the cost of data representation changes</div><br/></div></div><div id="38851096" class="c"><input type="checkbox" id="c-38851096" checked=""/><div class="controls bullet"><span class="by">morepedantic</span><span>|</span><a href="#38850997">parent</a><span>|</span><a href="#38851875">prev</a><span>|</span><a href="#38851549">next</a><span>|</span><label class="collapse" for="c-38851096">[-]</label><label class="expand" for="c-38851096">[13 more]</label></div><br/><div class="children"><div class="content">It demonstrates that Python needs libraries like NumPy. Few problems are more heavily optimized than matrix multiplication in practice, so comparing matrix multiplication benchmarks across languages with NumPy is not representative of real-world performance for most programming use cases.<p>It also means that adding performance to an existing Python program requires dropping into a different language, which is not only complicated, but also requires engineers capable in both Python and C (or similar).</div><br/><div id="38851284" class="c"><input type="checkbox" id="c-38851284" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851096">parent</a><span>|</span><a href="#38851202">next</a><span>|</span><label class="collapse" for="c-38851284">[-]</label><label class="expand" for="c-38851284">[7 more]</label></div><br/><div class="children"><div class="content">&gt; It demonstrates that Python needs libraries like NumPy.<p>People use matrix multiplication libraries (often written in Assembly) from every language if they really care about performance. That&#x27;s because such libraries incorporate 100 PhD theses&#x27; worth of tricks that no individual can hope to reinvent in the course of solving another problem. There is absolutely nothing special about Python in this context.<p>&gt; It also means that adding performance to an existing Python program requires dropping into a different language<p>As stated above, this applies to all languages. BLAS routines used for serious numerical work are hand-vectorized Assembly fine-tuned for each processor architecture, written by a few hyper-experts who do nothing else.<p>Nobody who needs performant matrix multiplication from C thinks &quot;hey, let me just write two nested loops&quot;.</div><br/><div id="38851868" class="c"><input type="checkbox" id="c-38851868" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851284">parent</a><span>|</span><a href="#38851344">next</a><span>|</span><label class="collapse" for="c-38851868">[-]</label><label class="expand" for="c-38851868">[1 more]</label></div><br/><div class="children"><div class="content">&gt; People use matrix multiplication libraries (often written in Assembly) from every language if they really care about performance. That&#x27;s because such libraries incorporate 100 PhD theses&#x27; worth of tricks that no individual can hope to reinvent in the course of solving another problem. There is absolutely nothing special about Python in this context.<p>You don&#x27;t have to use Assembly.<p>Case in point, this is as fast as OpenBLAS: <a href="https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;weave&#x2F;tree&#x2F;master&#x2F;benchmarks&#x2F;matmul_gemm_blas&#x2F;gemm_pure_nim">https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;weave&#x2F;tree&#x2F;master&#x2F;benchmarks&#x2F;matm...</a></div><br/></div></div><div id="38851344" class="c"><input type="checkbox" id="c-38851344" checked=""/><div class="controls bullet"><span class="by">dsharlet</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851284">parent</a><span>|</span><a href="#38851868">prev</a><span>|</span><a href="#38851202">next</a><span>|</span><label class="collapse" for="c-38851344">[-]</label><label class="expand" for="c-38851344">[5 more]</label></div><br/><div class="children"><div class="content">This is really overstating how hard it is to compete with matrix multiply libraries. The main reason those libraries are so big and have had so much work invested in them is their generality: they&#x27;re reasonably fast for almost any kind of inputs.<p>If you have a specific problem with constraints you can exploit (e.g. known fixed dimensions, sparsity patterns, data layouts, type conversions, etc.), it&#x27;s not hard at all to beat MKL, etc... <i>if</i> you are using a language like C++. If you are using python, you have no chance.<p>It isn&#x27;t even necessarily that different from a few nested loops. Clang is pretty damn good at autovectorizing, you just have to be a little careful about how you write the code.</div><br/><div id="38851386" class="c"><input type="checkbox" id="c-38851386" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851344">parent</a><span>|</span><a href="#38851500">next</a><span>|</span><label class="collapse" for="c-38851386">[-]</label><label class="expand" for="c-38851386">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you are using python, you have no chance.<p>Of course you do. Every special-case multiplication algorithm you might need already has an optimized implementation that you can just `pip install`, and move on with what you&#x27;re actually working on.<p>The whole scientific computing world runs on Python. Straightforward numerics code using NumPy tends to <i>murder</i> C&#x2F;C++ code in regard to performance, unless that code is written by people who make a living hand-optimizing computational routines.</div><br/><div id="38851482" class="c"><input type="checkbox" id="c-38851482" checked=""/><div class="controls bullet"><span class="by">SideQuark</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851386">parent</a><span>|</span><a href="#38851500">next</a><span>|</span><label class="collapse" for="c-38851482">[-]</label><label class="expand" for="c-38851482">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The whole scientific computing world runs on Python<p>If you ignore the majority of scientific code running on supercomputers doing most of science in C++ and Fortran.<p>Even in areas where python is used, the majority of the compute runs on C&#x2F;C++&#x2F;Fortran, with a little python as glue.<p>If you think numpy (written in c&#x2F;c++) murders c&#x2F;c++ code, you should learn about HPC, where really high performance happens. They don&#x27;t use numpy.</div><br/></div></div></div></div><div id="38851500" class="c"><input type="checkbox" id="c-38851500" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851344">parent</a><span>|</span><a href="#38851386">prev</a><span>|</span><a href="#38851367">next</a><span>|</span><label class="collapse" for="c-38851500">[-]</label><label class="expand" for="c-38851500">[1 more]</label></div><br/><div class="children"><div class="content">If you need a really fast compiled inner loop then you can often implement it in Python using Numba. Using that you can easily implement something like sparse matrix multiplication in Python.</div><br/></div></div><div id="38851367" class="c"><input type="checkbox" id="c-38851367" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851344">parent</a><span>|</span><a href="#38851500">prev</a><span>|</span><a href="#38851202">next</a><span>|</span><label class="collapse" for="c-38851367">[-]</label><label class="expand" for="c-38851367">[1 more]</label></div><br/><div class="children"><div class="content">You need to have enough experience to be able to be a little careful though. This is generally true for most languages, loop unrolling works even better in Python for example, but many Python programmers aren&#x27;t even aware of this possibility.</div><br/></div></div></div></div></div></div><div id="38851202" class="c"><input type="checkbox" id="c-38851202" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851096">parent</a><span>|</span><a href="#38851284">prev</a><span>|</span><a href="#38851209">next</a><span>|</span><label class="collapse" for="c-38851202">[-]</label><label class="expand" for="c-38851202">[3 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need any C knowledge to use numpy. In fact, its conceptual similarity with Matlab is possibly the single most important reason for its popularity. Many other problems do need specialized treatments that would indeed require other languages, but numpy is not a good counterexample.</div><br/><div id="38851316" class="c"><input type="checkbox" id="c-38851316" checked=""/><div class="controls bullet"><span class="by">jakobnissen</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851202">parent</a><span>|</span><a href="#38851209">next</a><span>|</span><label class="collapse" for="c-38851316">[-]</label><label class="expand" for="c-38851316">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re missing the point. The point is that, for any application, Python needs an underlying C library to be fast. So if you need to solve problems where no such library exists, Python is slow.<p>In other words, Python IS slow, but it can call fast code written in other languages.</div><br/><div id="38851339" class="c"><input type="checkbox" id="c-38851339" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851316">parent</a><span>|</span><a href="#38851209">next</a><span>|</span><label class="collapse" for="c-38851339">[-]</label><label class="expand" for="c-38851339">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true but irrelevant here, especially given the original claim:<p>&gt; adding performance to an existing Python program requires dropping into a different language<p>...is demonstrably false for a significant class of programs that can be rewritten into the array paradigm. The benchmark should have picked other numerical problem to avoid this issue. The Computer Language Benchmarks Game, for example, uses the `n-body` problem for this purpose.</div><br/></div></div></div></div></div></div><div id="38851209" class="c"><input type="checkbox" id="c-38851209" checked=""/><div class="controls bullet"><span class="by">doix</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851096">parent</a><span>|</span><a href="#38851202">prev</a><span>|</span><a href="#38851312">next</a><span>|</span><label class="collapse" for="c-38851209">[-]</label><label class="expand" for="c-38851209">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It also means that adding performance to an existing Python program requires dropping into a different language, which is not only complicated, but also requires engineers capable in both Python and C (or similar).<p>It&#x27;s actually not that bad. I think it&#x27;s part of the reason Python became so popular, it&#x27;s fairly easy to write C code and expose it via python.</div><br/></div></div><div id="38851312" class="c"><input type="checkbox" id="c-38851312" checked=""/><div class="controls bullet"><span class="by">RHSeeger</span><span>|</span><a href="#38850997">root</a><span>|</span><a href="#38851096">parent</a><span>|</span><a href="#38851209">prev</a><span>|</span><a href="#38851549">next</a><span>|</span><label class="collapse" for="c-38851312">[-]</label><label class="expand" for="c-38851312">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It demonstrates that Python needs libraries like NumPy.<p>You need libraries to do _anything_ in Python. It&#x27;s interpreted, so literally any call you make in Python will eventually make it back to something written in a compiled language (like a call to NumPy commands).</div><br/></div></div></div></div></div></div><div id="38850948" class="c"><input type="checkbox" id="c-38850948" checked=""/><div class="controls bullet"><span class="by">raister</span><span>|</span><a href="#38850997">prev</a><span>|</span><a href="#38851210">next</a><span>|</span><label class="collapse" for="c-38850948">[-]</label><label class="expand" for="c-38850948">[2 more]</label></div><br/><div class="children"><div class="content">I would expect Mojo to perform better in these settings.</div><br/><div id="38850953" class="c"><input type="checkbox" id="c-38850953" checked=""/><div class="controls bullet"><span class="by">jorgelopes</span><span>|</span><a href="#38850948">parent</a><span>|</span><a href="#38851210">next</a><span>|</span><label class="collapse" for="c-38850953">[-]</label><label class="expand" for="c-38850953">[1 more]</label></div><br/><div class="children"><div class="content">Mojo is on the list and performed well. Have a look</div><br/></div></div></div></div><div id="38851210" class="c"><input type="checkbox" id="c-38851210" checked=""/><div class="controls bullet"><span class="by">quelsolaar</span><span>|</span><a href="#38850948">prev</a><span>|</span><a href="#38851325">next</a><span>|</span><label class="collapse" for="c-38851210">[-]</label><label class="expand" for="c-38851210">[1 more]</label></div><br/><div class="children"><div class="content">Great post: Id be interested to see the difference between different C compilers, and to see what the difference is if the C code is compiled with a C++ compilers, if possible.</div><br/></div></div><div id="38851325" class="c"><input type="checkbox" id="c-38851325" checked=""/><div class="controls bullet"><span class="by">daxfohl</span><span>|</span><a href="#38851210">prev</a><span>|</span><label class="collapse" for="c-38851325">[-]</label><label class="expand" for="c-38851325">[2 more]</label></div><br/><div class="children"><div class="content">I give it six months before we can ask chatgpt to do this, it&#x27;ll ask you for an AWS token, check out a VM and do it all for you with best practices on measuring these things.</div><br/><div id="38851481" class="c"><input type="checkbox" id="c-38851481" checked=""/><div class="controls bullet"><span class="by">sa46</span><span>|</span><a href="#38851325">parent</a><span>|</span><label class="collapse" for="c-38851481">[-]</label><label class="expand" for="c-38851481">[1 more]</label></div><br/><div class="children"><div class="content">Reliably benchmarking optimizing  VMs like Java and JavaScript is a research problem.<p>See “Virtual machine warmup blows hot and cold”. The authors run a variety of benchmarks (with a pristine methodology) and find 43% of them provide “bad inconsistent” results.<p>Paper summary: <a href="https:&#x2F;&#x2F;blog.acolyer.org&#x2F;2017&#x2F;11&#x2F;07&#x2F;virtual-machine-warmup-blows-hot-and-cold&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.acolyer.org&#x2F;2017&#x2F;11&#x2F;07&#x2F;virtual-machine-warmup-b...</a><p>Paper: <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;3133876" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;3133876</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>