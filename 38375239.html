<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700730064108" as="style"/><link rel="stylesheet" href="styles.css?v=1700730064108"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/openai/status/1727206187077370115">We have reached an agreement in principle for Sam to return to OpenAI as CEO</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>staranjeet</span> | <span>1287 comments</span></div><br/><div><div id="38382563" class="c"><input type="checkbox" id="c-38382563" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#38378069">next</a><span>|</span><label class="collapse" for="c-38382563">[-]</label><label class="expand" for="c-38382563">[1 more]</label></div><br/><div class="children"><div class="content">All: there are over 1800 comments in this thread. If you want to read them all, click More at the bottom of each page, or like this: (edit: er, yes they do have to be wellformed don&#x27;t they):<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=2">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=2</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=3">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=3</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=4">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38375239&amp;p=4</a>  (...etc.)</div><br/></div></div><div id="38378069" class="c"><input type="checkbox" id="c-38378069" checked=""/><div class="controls bullet"><span class="by">garrison</span><span>|</span><a href="#38382563">prev</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38378069">[-]</label><label class="expand" for="c-38378069">[123 more]</label></div><br/><div class="children"><div class="content">If OpenAI remains a 501(c)(3) charity, then any employee of Microsoft on the board will have a fiduciary duty to advance the mission of the charity, rather than the business needs of Microsoft.  There are obvious conflicts of interest here.  I don&#x27;t expect the IRS to be a fan of this arrangement.</div><br/><div id="38381704" class="c"><input type="checkbox" id="c-38381704" checked=""/><div class="controls bullet"><span class="by">bradleybuda</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38379683">next</a><span>|</span><label class="collapse" for="c-38381704">[-]</label><label class="expand" for="c-38381704">[29 more]</label></div><br/><div class="children"><div class="content">Major corporate boards are rife with &quot;on paper&quot; conflicts on interest - that&#x27;s what happens when you want people with real management experience to sit on your board and act like responsible adults. This happens in every single industry and has nothing to do with tech or with OpenAI specifically.<p>In practice, board bylaws and common sense mean that individuals recuse themselves as needed and don&#x27;t do stupid shit.</div><br/><div id="38381749" class="c"><input type="checkbox" id="c-38381749" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38381897">next</a><span>|</span><label class="collapse" for="c-38381749">[-]</label><label class="expand" for="c-38381749">[21 more]</label></div><br/><div class="children"><div class="content">&quot;In practice, board bylaws and common sense mean that individuals ... don&#x27;t do stupid shit.&quot;<p>Were you watching a different show than the rest of us?</div><br/><div id="38382006" class="c"><input type="checkbox" id="c-38382006" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381749">parent</a><span>|</span><a href="#38381966">next</a><span>|</span><label class="collapse" for="c-38382006">[-]</label><label class="expand" for="c-38382006">[12 more]</label></div><br/><div class="children"><div class="content">I get a lostredditor vibe way too often here. Oddly more than Reddit.<p>I think people forget sometimes that comments come with a context. If we are having a conversation about Deep Water Horizon someone will chime in about how safe deep sea oil exploration is and how many failsafes blah blah blah.<p>“Do you know where you are right now?”</div><br/><div id="38383169" class="c"><input type="checkbox" id="c-38383169" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382006">parent</a><span>|</span><a href="#38382250">next</a><span>|</span><label class="collapse" for="c-38383169">[-]</label><label class="expand" for="c-38383169">[2 more]</label></div><br/><div class="children"><div class="content">I apologize, the comment&#x27;s irony overwhelmed my snark containment system.</div><br/><div id="38390333" class="c"><input type="checkbox" id="c-38390333" checked=""/><div class="controls bullet"><span class="by">Obscurity4340</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38383169">parent</a><span>|</span><a href="#38382250">next</a><span>|</span><label class="collapse" for="c-38390333">[-]</label><label class="expand" for="c-38390333">[1 more]</label></div><br/><div class="children"><div class="content">This comment is perfectionXD</div><br/></div></div></div></div><div id="38382250" class="c"><input type="checkbox" id="c-38382250" checked=""/><div class="controls bullet"><span class="by">Juicyy</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382006">parent</a><span>|</span><a href="#38383169">prev</a><span>|</span><a href="#38382268">next</a><span>|</span><label class="collapse" for="c-38382250">[-]</label><label class="expand" for="c-38382250">[2 more]</label></div><br/><div class="children"><div class="content">Its a more technical space then reddit. Youre gonna have more know it alls spewing</div><br/><div id="38389753" class="c"><input type="checkbox" id="c-38389753" checked=""/><div class="controls bullet"><span class="by">jachee</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382250">parent</a><span>|</span><a href="#38382268">next</a><span>|</span><label class="collapse" for="c-38389753">[-]</label><label class="expand" for="c-38389753">[1 more]</label></div><br/><div class="children"><div class="content">You know that know-it-all should be hyphenated, right?<p>…<p>;)</div><br/></div></div></div></div><div id="38382268" class="c"><input type="checkbox" id="c-38382268" checked=""/><div class="controls bullet"><span class="by">LordDragonfang</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382006">parent</a><span>|</span><a href="#38382250">prev</a><span>|</span><a href="#38382913">next</a><span>|</span><label class="collapse" for="c-38382268">[-]</label><label class="expand" for="c-38382268">[3 more]</label></div><br/><div class="children"><div class="content">&gt;I think people forget sometimes that comments come with a context.<p>I mean, this is definitely one of my pet peeves, but the wider context of this conversation is <i>specifically a board doing stupid shit</i>, so that&#x27;s a very relevant counterexample to the thing being stated. Board members <i>in general</i> often do stupid&#x2F;short-sighted shit (especially in tech), and I don&#x27;t know of any examples of corporate board members recusing themselves.</div><br/><div id="38382564" class="c"><input type="checkbox" id="c-38382564" checked=""/><div class="controls bullet"><span class="by">mhluongo</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382268">parent</a><span>|</span><a href="#38382913">next</a><span>|</span><label class="collapse" for="c-38382564">[-]</label><label class="expand" for="c-38382564">[2 more]</label></div><br/><div class="children"><div class="content">Common example of recusal is CEO comp when the CEO is on the board.</div><br/><div id="38382936" class="c"><input type="checkbox" id="c-38382936" checked=""/><div class="controls bullet"><span class="by">alsetmusic</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382564">parent</a><span>|</span><a href="#38382913">next</a><span>|</span><label class="collapse" for="c-38382936">[-]</label><label class="expand" for="c-38382936">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I would term a black-and-white case. I don&#x27;t think there&#x27;s anyone with sense who would argue in good faith that a CEO should get a vote on their own salary. There are many degrees of grey between outright corruption and this example, and I think the concern lies within.</div><br/></div></div></div></div></div></div><div id="38382913" class="c"><input type="checkbox" id="c-38382913" checked=""/><div class="controls bullet"><span class="by">alsetmusic</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382006">parent</a><span>|</span><a href="#38382268">prev</a><span>|</span><a href="#38385148">next</a><span>|</span><label class="collapse" for="c-38382913">[-]</label><label class="expand" for="c-38382913">[2 more]</label></div><br/><div class="children"><div class="content">I get what you&#x27;re saying, but I also live in the world and see the mechanics of capitalism. I may be a person who&#x27;s interested in tech, science, education, archeology, etc. That doesn&#x27;t mean that I don&#x27;t also have political views that sometimes overlap with a lot of other very-online people.<p>I think the comment to which you replied has a very reddit vibe, no doubt. But also, it&#x27;s a completely valid point. Could it have been said differently? Sure. But I also immediately agreed with the sentiment.</div><br/><div id="38383273" class="c"><input type="checkbox" id="c-38383273" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382913">parent</a><span>|</span><a href="#38385148">next</a><span>|</span><label class="collapse" for="c-38383273">[-]</label><label class="expand" for="c-38383273">[1 more]</label></div><br/><div class="children"><div class="content">Oh I wasn’t complaining about the parent, I was complaining it needed to be said.<p>We are talking about a failure of the system, in the context of a concrete example. Talking about how the system actually works is only appropriate if you are drawing specific arguments up about how this situation is an anomaly, and few of them do that.<p>Instead it often sounds like “it’s very unusual for the front to fall off”.</div><br/></div></div></div></div><div id="38382620" class="c"><input type="checkbox" id="c-38382620" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382006">parent</a><span>|</span><a href="#38385148">prev</a><span>|</span><a href="#38381966">next</a><span>|</span><label class="collapse" for="c-38382620">[-]</label><label class="expand" for="c-38382620">[1 more]</label></div><br/><div class="children"><div class="content">So?</div><br/></div></div></div></div><div id="38381966" class="c"><input type="checkbox" id="c-38381966" checked=""/><div class="controls bullet"><span class="by">jjoonathan</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381749">parent</a><span>|</span><a href="#38382006">prev</a><span>|</span><a href="#38381876">next</a><span>|</span><label class="collapse" for="c-38381966">[-]</label><label class="expand" for="c-38381966">[2 more]</label></div><br/><div class="children"><div class="content">No, this is the part of the show where the patronizing rhetoric gets trotted out to rationalize discarding the principles that have suddenly become inconvenient for the people with power.</div><br/><div id="38388363" class="c"><input type="checkbox" id="c-38388363" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381966">parent</a><span>|</span><a href="#38381876">next</a><span>|</span><label class="collapse" for="c-38388363">[-]</label><label class="expand" for="c-38388363">[1 more]</label></div><br/><div class="children"><div class="content">No worries. The same kind of people who devoted their time and energy to creating open-source operating systems in the era of Microsoft and Apple are now devoting their time and energy to doing the same for non-lobotomized LLMs.<p>Look at these clowns (Ilya &amp; Sam and their angry talkie-bot), it&#x27;s a revelation, like Bill Gates on Linux in 2000:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=N36wtDYK8kI" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=N36wtDYK8kI</a></div><br/></div></div></div></div><div id="38381876" class="c"><input type="checkbox" id="c-38381876" checked=""/><div class="controls bullet"><span class="by">badloginagain</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381749">parent</a><span>|</span><a href="#38381966">prev</a><span>|</span><a href="#38388138">next</a><span>|</span><label class="collapse" for="c-38381876">[-]</label><label class="expand" for="c-38381876">[4 more]</label></div><br/><div class="children"><div class="content">And we&#x27;re seeing the result in real-time. Stupid shit doers have been replaced with hopefully-less-stupid-shit-doers.<p>It&#x27;s a real shame too, because this is a clear loss for the AI Alignment crowd.<p>I&#x27;m on the fence about the whole alignment thing, but at least there is a strong moral compass in the field- especially compared to something like crypto.</div><br/><div id="38382959" class="c"><input type="checkbox" id="c-38382959" checked=""/><div class="controls bullet"><span class="by">alsetmusic</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381876">parent</a><span>|</span><a href="#38382026">next</a><span>|</span><label class="collapse" for="c-38382959">[-]</label><label class="expand" for="c-38382959">[2 more]</label></div><br/><div class="children"><div class="content">&gt; at least there is a strong moral compass in the field<p>Is this still true when the board gets overhauled after trying to uphold the moral compass.</div><br/><div id="38386169" class="c"><input type="checkbox" id="c-38386169" checked=""/><div class="controls bullet"><span class="by">saalweachter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382959">parent</a><span>|</span><a href="#38382026">next</a><span>|</span><label class="collapse" for="c-38386169">[-]</label><label class="expand" for="c-38386169">[1 more]</label></div><br/><div class="children"><div class="content">And when the CEO&#x27;s other thing is a cryptocurrency?</div><br/></div></div></div></div></div></div><div id="38388138" class="c"><input type="checkbox" id="c-38388138" checked=""/><div class="controls bullet"><span class="by">dev_tty01</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381749">parent</a><span>|</span><a href="#38381876">prev</a><span>|</span><a href="#38383618">next</a><span>|</span><label class="collapse" for="c-38388138">[-]</label><label class="expand" for="c-38388138">[1 more]</label></div><br/><div class="children"><div class="content">Yes, and we were also watching the thousands and thousands of companies where these types of conflicts are handled easily by decent people and common sense.  Don&#x27;t confuse the outlier with the silent majority.</div><br/></div></div><div id="38383618" class="c"><input type="checkbox" id="c-38383618" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381749">parent</a><span>|</span><a href="#38388138">prev</a><span>|</span><a href="#38381897">next</a><span>|</span><label class="collapse" for="c-38383618">[-]</label><label class="expand" for="c-38383618">[1 more]</label></div><br/><div class="children"><div class="content">You need to be able to separate macro-level and micro-level.  GP is responding to a comment about the IRS caring about the conflict-of-interest on paper.  The IRS has to make and follow rules at a <i>macro</i> level.  Micro-level events obviously can affect the macro view, but you don&#x27;t completely ignore the macro because something bad happened at the micro level.  That&#x27;s how you get knee-jerk reactionary governance, which is highly emotional.</div><br/></div></div></div></div><div id="38381897" class="c"><input type="checkbox" id="c-38381897" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38381749">prev</a><span>|</span><a href="#38381805">next</a><span>|</span><label class="collapse" for="c-38381897">[-]</label><label class="expand" for="c-38381897">[1 more]</label></div><br/><div class="children"><div class="content">A corporation acting (due to influence from a conflicted board member that doesn&#x27;t recuse) contrary to the interests of its stockholders and in the interest of the conflicted board member or who they represent potentially creates liability of the firm to its stockholders.<p>A charity acting (due to the influence of a conflicted board member that doesn&#x27;t recuse) contrary to its charitable mission in the interests of the conflicted board member or who they represent does something similar with regard to liability of the firm to various stakeholders with a legally-enforceable interest in the charity and its mission, <i>but also</i> is also a <i>public</i> civil violation that can lead to IRS sanctions against the firm up to and including monetary penalties and loss of tax exempt status <i>on top of</i> whatever private tort liability exists.</div><br/></div></div><div id="38381805" class="c"><input type="checkbox" id="c-38381805" checked=""/><div class="controls bullet"><span class="by">ip26</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38381897">prev</a><span>|</span><a href="#38382265">next</a><span>|</span><label class="collapse" for="c-38381805">[-]</label><label class="expand" for="c-38381805">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of the “revolving door” problem. Obvious risk of corruption and conflict of interest, but at the same time experts from industry are the ones with the knowledge to be effective regulators. Not unlike how many good patent attorneys were previously engineers.</div><br/></div></div><div id="38382265" class="c"><input type="checkbox" id="c-38382265" checked=""/><div class="controls bullet"><span class="by">fouc</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38381805">prev</a><span>|</span><a href="#38387781">next</a><span>|</span><label class="collapse" for="c-38382265">[-]</label><label class="expand" for="c-38382265">[3 more]</label></div><br/><div class="children"><div class="content">OpenAI isn&#x27;t a typical corporation but a 501(c)(3), so bylaws &amp; protections that otherwise might exist appear to be lacking in this situation.</div><br/><div id="38383221" class="c"><input type="checkbox" id="c-38383221" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382265">parent</a><span>|</span><a href="#38387781">next</a><span>|</span><label class="collapse" for="c-38383221">[-]</label><label class="expand" for="c-38383221">[2 more]</label></div><br/><div class="children"><div class="content">501c3&#x27;s also have governing internal rules, and the threat of penalties and loss of status imposed by the IRS gives them additional incentive to safeguard against even the appearance of conflict being manifested into how they operate (whether that&#x27;s avoiding conflicted board members or assuring that they recuse where a conflict is relevant.)<p>If OpenAI didn&#x27;t have adequate safeguards, either through negligence or becauase it was in fact being run deliberately as a fraudulent charity, that&#x27;s a particular failure of OpenAI, not a “well, 501c3’s inherently don&#x27;t have safeguard” thing.</div><br/><div id="38387604" class="c"><input type="checkbox" id="c-38387604" checked=""/><div class="controls bullet"><span class="by">kevin_thibedeau</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38383221">parent</a><span>|</span><a href="#38387781">next</a><span>|</span><label class="collapse" for="c-38387604">[-]</label><label class="expand" for="c-38387604">[1 more]</label></div><br/><div class="children"><div class="content">Trump Foundation was a 501c3 that laundered money for 30 years without the IRS batting an eye.</div><br/></div></div></div></div></div></div><div id="38387781" class="c"><input type="checkbox" id="c-38387781" checked=""/><div class="controls bullet"><span class="by">dizzydes</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38382265">prev</a><span>|</span><a href="#38382915">next</a><span>|</span><label class="collapse" for="c-38387781">[-]</label><label class="expand" for="c-38387781">[1 more]</label></div><br/><div class="children"><div class="content">Larry Summers practically invented this stuff...</div><br/></div></div><div id="38382915" class="c"><input type="checkbox" id="c-38382915" checked=""/><div class="controls bullet"><span class="by">throwaway-blaze</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381704">parent</a><span>|</span><a href="#38387781">prev</a><span>|</span><a href="#38379683">next</a><span>|</span><label class="collapse" for="c-38382915">[-]</label><label class="expand" for="c-38382915">[1 more]</label></div><br/><div class="children"><div class="content">No conflict, no interest.</div><br/></div></div></div></div><div id="38379683" class="c"><input type="checkbox" id="c-38379683" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38381704">prev</a><span>|</span><a href="#38380245">next</a><span>|</span><label class="collapse" for="c-38379683">[-]</label><label class="expand" for="c-38379683">[30 more]</label></div><br/><div class="children"><div class="content">My guess is that the non-profit has never gotten this kind of scrutiny now and the new directors are going to want to get lawyers involved to cover their asses.  Just imagine their positions when Sam Altman really does something worth firing.<p>I think it was a real mistake to create OpenAI as a public charity and I would be hesitant to step into that mess.  Imagine the fun when it tips into a private foundation status.</div><br/><div id="38380079" class="c"><input type="checkbox" id="c-38380079" checked=""/><div class="controls bullet"><span class="by">qwery</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379683">parent</a><span>|</span><a href="#38379906">next</a><span>|</span><label class="collapse" for="c-38380079">[-]</label><label class="expand" for="c-38380079">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I think it was a real mistake to create OpenAI as a public charity<p>Sure, with hindsight. But it didn&#x27;t require much in the way of <i>foresight</i> to predict that some sort of problem would arise from the not-for-profit operating a hot startup that is by definition poorly aligned with the stated goals of the parent company. The writing was on the wall.</div><br/><div id="38381385" class="c"><input type="checkbox" id="c-38381385" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380079">parent</a><span>|</span><a href="#38383730">next</a><span>|</span><label class="collapse" for="c-38381385">[-]</label><label class="expand" for="c-38381385">[1 more]</label></div><br/><div class="children"><div class="content">I think it could have easily been predicted just from the initial announcements.  You can&#x27;t create a public charity simply from the donations of a few wealthy individuals.  A public charity has to meet the public support test.  A private foundation would be a better model but someone decided they didn&#x27;t want to go that route.  Maybe should have asked a non-profit lawyer?</div><br/></div></div><div id="38383730" class="c"><input type="checkbox" id="c-38383730" checked=""/><div class="controls bullet"><span class="by">zerohalo</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380079">parent</a><span>|</span><a href="#38381385">prev</a><span>|</span><a href="#38381506">next</a><span>|</span><label class="collapse" for="c-38383730">[-]</label><label class="expand" for="c-38383730">[1 more]</label></div><br/><div class="children"><div class="content">Exactly this. OpenAI was started for ostensibly the right reasons. But once they discovered something that would both 1) take a tremendous amount of compute power to scale and develop, and 2) could be heavily monetized, they choose the $ route and that point the mission was doomed, with the board members originally brought in to protect the mission holding their fingers in the dyke.</div><br/></div></div><div id="38381506" class="c"><input type="checkbox" id="c-38381506" checked=""/><div class="controls bullet"><span class="by">broast</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380079">parent</a><span>|</span><a href="#38383730">prev</a><span>|</span><a href="#38381293">next</a><span>|</span><label class="collapse" for="c-38381506">[-]</label><label class="expand" for="c-38381506">[1 more]</label></div><br/><div class="children"><div class="content">Wishfully I hope there was some intent from the beginning on exposing the impossibility of this contradictory model to the world, so that a global audience can evaluate on how to improve our system to support a better future.</div><br/></div></div><div id="38381293" class="c"><input type="checkbox" id="c-38381293" checked=""/><div class="controls bullet"><span class="by">fooop</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380079">parent</a><span>|</span><a href="#38381506">prev</a><span>|</span><a href="#38379906">next</a><span>|</span><label class="collapse" for="c-38381293">[-]</label><label class="expand" for="c-38381293">[1 more]</label></div><br/><div class="children"><div class="content">Speaks more to a fundamental misalignment between societal good and technological progress. The narrative (first born in the Enlightenment) about how reason, unfettered by tradition and nonage, is our best path towards happiness no longer holds. AI doomerism is an expression of this breakdown, but without the intellectual honesty required to dive to the root of the problem and consider whether Socrates may have been right about the corrupting influence of writing stuff down instead of memorizing it.<p>What&#x27;s happening right now is people just starting to reckon with the fact that technological progress on it&#x27;s own is necessarily unaligned with human interests. This problem has always existed, AI just makes it acute and unavoidable since it&#x27;s no longer possible to invoke the long-tail of &quot;whatever problem this fix creates will just get fixed later&quot;. The AI alignment problem is at it&#x27;s core a problem of reconciling this, and it will inherently fail in absence of explicitly imposing non-Enlightenment values.<p>Seeking to build openAI as a nonprofit, as well as ousting Altman as CEO are both initial expressions of trying to reconcile the conflict, and seeing these attempts fail will only intensity it. It will be fascinating to watch as researchers slowly come to realize what the roots of the problem are, but also the lack of the social machinery required to combat the problem.</div><br/></div></div></div></div><div id="38379906" class="c"><input type="checkbox" id="c-38379906" checked=""/><div class="controls bullet"><span class="by">danaris</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379683">parent</a><span>|</span><a href="#38380079">prev</a><span>|</span><a href="#38386161">next</a><span>|</span><label class="collapse" for="c-38379906">[-]</label><label class="expand" for="c-38379906">[7 more]</label></div><br/><div class="children"><div class="content">Well, I think that&#x27;s really the question, isn&#x27;t it?<p>Was it a mistake to create OpenAI as a public charity?<p>Or was it a mistake to operate OpenAI as if it were a startup?<p>The problem isn&#x27;t really either one—it&#x27;s the inherent conflict between the two. IMO, the only reason to see creating it as a 501(c)(3) being a mistake is if you think cutting-edge machine learning is <i>inherently</i> going to be targeted by people looking to make a quick buck off of it.</div><br/><div id="38381418" class="c"><input type="checkbox" id="c-38381418" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379906">parent</a><span>|</span><a href="#38381309">next</a><span>|</span><label class="collapse" for="c-38381418">[-]</label><label class="expand" for="c-38381418">[1 more]</label></div><br/><div class="children"><div class="content">To create a public charity without public fundraising is a no go.  Should have been a private foundation because that is where it will end up.</div><br/></div></div><div id="38381309" class="c"><input type="checkbox" id="c-38381309" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379906">parent</a><span>|</span><a href="#38381418">prev</a><span>|</span><a href="#38383576">next</a><span>|</span><label class="collapse" for="c-38381309">[-]</label><label class="expand" for="c-38381309">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI the charity would have survived only as an ego project for Elon doing something fun with minor impact.<p>Only the current setup is feasible if they want to get the kind of investment required. This can work if the board is pragmatic and has no conflict of interest, so preferably someone with no stake in anything AI either biz or academic.</div><br/><div id="38381757" class="c"><input type="checkbox" id="c-38381757" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381309">parent</a><span>|</span><a href="#38383576">next</a><span>|</span><label class="collapse" for="c-38381757">[-]</label><label class="expand" for="c-38381757">[1 more]</label></div><br/><div class="children"><div class="content">I think the only way this can end up is to convert to a private foundation and make sizable (8 figures annually) grants to truly independent AI safety (broadly defined) organizations.</div><br/></div></div></div></div><div id="38381828" class="c"><input type="checkbox" id="c-38381828" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379906">parent</a><span>|</span><a href="#38383576">prev</a><span>|</span><a href="#38386161">next</a><span>|</span><label class="collapse" for="c-38381828">[-]</label><label class="expand" for="c-38381828">[2 more]</label></div><br/><div class="children"><div class="content">&gt; IMO, the only reason to see creating it as a 501(c)(3) being a mistake is if you think cutting-edge machine learning is inherently going to be targeted by people looking to make a quick buck off of it.<p>I mean that&#x27;s certainly been my experience of it thus far, is companies rushing to market with half-baked products that (allegedly) incorporate AI to do some task or another.</div><br/><div id="38381919" class="c"><input type="checkbox" id="c-38381919" checked=""/><div class="controls bullet"><span class="by">danaris</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381828">parent</a><span>|</span><a href="#38386161">next</a><span>|</span><label class="collapse" for="c-38381919">[-]</label><label class="expand" for="c-38381919">[1 more]</label></div><br/><div class="children"><div class="content">I was specifically thinking of people seeing a non-profit doing stuff with ML, and trying to finagle their way in there to turn it into a profit for themselves.<p>(But yes; what you describe is absolutely happening left and right...)</div><br/></div></div></div></div></div></div><div id="38386161" class="c"><input type="checkbox" id="c-38386161" checked=""/><div class="controls bullet"><span class="by">ryukoposting</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379683">parent</a><span>|</span><a href="#38379906">prev</a><span>|</span><a href="#38381710">next</a><span>|</span><label class="collapse" for="c-38386161">[-]</label><label class="expand" for="c-38386161">[2 more]</label></div><br/><div class="children"><div class="content">Are there any similar cases of this &quot;non-profit board overseeing a (huge) for-profit company&quot; model? I want to like the concept behind it. Was this inevitable due to the leadership structure of OpenAI, or was it totally preventable had the right people been on the board? I wish I had the historical context to answer that question.</div><br/><div id="38386532" class="c"><input type="checkbox" id="c-38386532" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38386161">parent</a><span>|</span><a href="#38381710">next</a><span>|</span><label class="collapse" for="c-38386532">[-]</label><label class="expand" for="c-38386532">[1 more]</label></div><br/><div class="children"><div class="content">Yes, for example Novo Nordisk is a pharmaceutical company controlled by a nonprofit, worth around $100B.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Novo_Nordisk_Foundation" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Novo_Nordisk_Foundation</a><p>There are other similar examples like Ikea.<p>But those examples are for mature, established companies operating under a nonprofit. OpenAI is different. Not only does it have the for-profit subsidiary, but the for-profit needs to frequently fundraise. It&#x27;s natural for fundraising to require renegotiations in the board structure, possibly contentious ones. So in retrospect it doesn&#x27;t seem surprising that this process would become extra contentious with OpenAI&#x27;s structure.</div><br/></div></div></div></div><div id="38381710" class="c"><input type="checkbox" id="c-38381710" checked=""/><div class="controls bullet"><span class="by">purple_ferret</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379683">parent</a><span>|</span><a href="#38386161">prev</a><span>|</span><a href="#38382142">next</a><span>|</span><label class="collapse" for="c-38381710">[-]</label><label class="expand" for="c-38381710">[2 more]</label></div><br/><div class="children"><div class="content">Perhaps creating OpenAI as a charity is what has allowed it to become what it is, whereas other for-profit competitors are worth much less. How else do you get a guy like Elon Musk to &#x27;donate&#x27; $100 million to your company?<p>Lots of ventures cut corners early on that they eventually had to pay for, but cutting the corners was crucial to their initial success and growth</div><br/><div id="38381895" class="c"><input type="checkbox" id="c-38381895" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381710">parent</a><span>|</span><a href="#38382142">next</a><span>|</span><label class="collapse" for="c-38381895">[-]</label><label class="expand" for="c-38381895">[1 more]</label></div><br/><div class="children"><div class="content">Elon only gave $40 million, but since he was the primary donor I suspect he was the one who was pushing for the &quot;public charity&quot; designation.  He and Sam were co-founders.  Maybe it was Sam who asked Elon for the money, but there wasn&#x27;t anyone else involved.</div><br/></div></div></div></div><div id="38382142" class="c"><input type="checkbox" id="c-38382142" checked=""/><div class="controls bullet"><span class="by">Turing_Machine</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379683">parent</a><span>|</span><a href="#38381710">prev</a><span>|</span><a href="#38380286">next</a><span>|</span><label class="collapse" for="c-38382142">[-]</label><label class="expand" for="c-38382142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think it was a real mistake to create OpenAI as a public charity and I would be hesitant to step into that mess.<p>I think it could have worked either as a non-profit <i>or</i> as a for-profit. It&#x27;s this weird jackass hybrid thing that&#x27;s produced most of the conflict, or so it seems to me. Neither fish nor fowl, as the saying goes.</div><br/></div></div></div></div><div id="38380245" class="c"><input type="checkbox" id="c-38380245" checked=""/><div class="controls bullet"><span class="by">stikit</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38379683">prev</a><span>|</span><a href="#38380119">next</a><span>|</span><label class="collapse" for="c-38380245">[-]</label><label class="expand" for="c-38380245">[13 more]</label></div><br/><div class="children"><div class="content">OpenAI is not a charity. Microsoft&#x27;s investment is in OpenAI Global, LLC, a for-profit company.<p>From <a href="https:&#x2F;&#x2F;openai.com&#x2F;our-structure" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;our-structure</a><p>- First, the for-profit subsidiary is fully controlled by the OpenAI Nonprofit. We enacted this by having the Nonprofit wholly own and control a manager entity (OpenAI GP LLC) that has the power to control and govern the for-profit subsidiary.<p>-Second, because the board is still the board of a Nonprofit, each director must perform their fiduciary duties in furtherance of its mission—safe AGI that is broadly beneficial. While the for-profit subsidiary is permitted to make and distribute profit, it is subject to this mission. The Nonprofit’s principal beneficiary is humanity, not OpenAI investors.<p>-Third, the board remains majority independent. Independent directors do not hold equity in OpenAI. Even OpenAI’s CEO, Sam Altman, does not hold equity directly. His only interest is indirectly through a Y Combinator investment fund that made a small investment in OpenAI before he was full-time.<p>-Fourth, profit allocated to investors and employees, including Microsoft, is capped. All residual value created above and beyond the cap will be returned to the Nonprofit for the benefit of humanity.<p>-Fifth, the board determines when we&#x27;ve attained AGI. Again, by AGI we mean a highly autonomous system that outperforms humans at most economically valuable work. Such a system is excluded from IP licenses and other commercial terms with Microsoft, which only apply to pre-AGI technology.</div><br/><div id="38381156" class="c"><input type="checkbox" id="c-38381156" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380245">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38381156">[-]</label><label class="expand" for="c-38381156">[7 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is not a charity.<p>OpenAI is a charity nonprofit, in fact.<p>&gt; Microsoft&#x27;s investment is in OpenAI Global, LLC, a for-profit company.<p>OpenAI Global LLC is a subsidiary two levels down from OpenAI, which is expressly (by the operating agreement that is the LLC&#x27;s foundational document) subordinated to OpenAI’s charitable purpose, and which is completely controlled (despite the charity&#x27;s indirect and less-than-complete ownership) by OpenAI GP LLC, a wholly owned subsidiary of the charity, on behalf of the OpenAI charity.<p>And, particularly, the OpenAI board is. <i>as the excerpts you quote in your post expressly state</i>, the board of the nonprofit that is the top of the structure. It controls everything underneath because each of the subordinate organizations foundational documents give it (well, for the two entities with outside invesment, OpenAI GP LLC, the charity&#x27;s wholly-owned and -controlled subsidiary) complete control.</div><br/><div id="38381881" class="c"><input type="checkbox" id="c-38381881" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381156">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38381881">[-]</label><label class="expand" for="c-38381881">[6 more]</label></div><br/><div class="children"><div class="content">well not anymore, as they cannot function as a nonprofit.<p>also infamously they fundraised as a nonprofit, but retracted to admit they needed a for profit structure to thrive, which Elon is miffed about and Sam has defended explicitly</div><br/><div id="38382035" class="c"><input type="checkbox" id="c-38382035" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381881">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38382035">[-]</label><label class="expand" for="c-38382035">[5 more]</label></div><br/><div class="children"><div class="content">&gt; well not anymore, as they cannot function as a nonprofit.<p>There&#x27;s been a lot of news lately, but unless I&#x27;ve missed something, even with the tentative agreement of a new board for the charity nonprofit, they are and plan to remain a charity nonprofit with the same nominal mission.<p>&gt; also infamously they fundraised as a nonprofit, but retracted to admit they needed a for profit structure to thrive<p>No, they admitted they needed to sell products rather than merely take donations to survive, and needed to be able to return profits from doing that to investors to scale up enough to do that, so they formed a for-profit subsidiary with its own for-profit subsidiary, both controlled by another subsidiary, all subordinated to the charity nonprofit, to do that.</div><br/><div id="38382237" class="c"><input type="checkbox" id="c-38382237" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382035">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38382237">[-]</label><label class="expand" for="c-38382237">[4 more]</label></div><br/><div class="children"><div class="content">&gt;they are and plan to remain a charity nonprofit<p>Once the temporary board has selected a permanent board, give it a couple of months and then get back to us.  They will almost certainly choose to spin the for-profit subsidiary off as an independent company.  Probably with some contractual arrangement where they commit x funding to the non-profit in exchange for IP licensing.  Which is the way they should have structured this back in 2019.</div><br/><div id="38384900" class="c"><input type="checkbox" id="c-38384900" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382237">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38384900">[-]</label><label class="expand" for="c-38384900">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Almost certainly&quot;? Here&#x27;s a fun exercise. Over the course of, say, a year, keep track of all your predictions along these lines, and how certain you are of each. Almost certainly, expressed as a percentage, would be maybe 95%? Then see how often the predicted events occur, compared to how sure you are.<p>Personally I&#x27;m nowhere near 95% confident that will happen. I&#x27;d say I&#x27;m about 75% confident it won&#x27;t. So I wouldn&#x27;t be utterly shocked, but I would be quite surprised.</div><br/><div id="38385837" class="c"><input type="checkbox" id="c-38385837" checked=""/><div class="controls bullet"><span class="by">kyle_grove</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38384900">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38385837">[-]</label><label class="expand" for="c-38385837">[2 more]</label></div><br/><div class="children"><div class="content">I’m pretty confident (close to the 95% level) they will abandon the public charity structure, but throughout this saga, I have been baffled by the discourse’s willingness to handwave away OpenAI’s peculiar legal structure as irrelevant to these events.</div><br/><div id="38386133" class="c"><input type="checkbox" id="c-38386133" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38385837">parent</a><span>|</span><a href="#38381040">next</a><span>|</span><label class="collapse" for="c-38386133">[-]</label><label class="expand" for="c-38386133">[1 more]</label></div><br/><div class="children"><div class="content">Within a few months? I don&#x27;t think it should be possible to be 95% confident of that without inside info. As you said, many unexpected things have happened already. IMO that should bring the most confident predictions down to the 80-85% level at most.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38381040" class="c"><input type="checkbox" id="c-38381040" checked=""/><div class="controls bullet"><span class="by">ezfe</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380245">parent</a><span>|</span><a href="#38381156">prev</a><span>|</span><a href="#38381218">next</a><span>|</span><label class="collapse" for="c-38381040">[-]</label><label class="expand" for="c-38381040">[4 more]</label></div><br/><div class="children"><div class="content">The board is the charity though, which is why the person you&#x27;re replying to made the remark about MSFT employees being appointed to the board</div><br/><div id="38381104" class="c"><input type="checkbox" id="c-38381104" checked=""/><div class="controls bullet"><span class="by">UrineSqueegee</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381040">parent</a><span>|</span><a href="#38381218">next</a><span>|</span><label class="collapse" for="c-38381104">[-]</label><label class="expand" for="c-38381104">[3 more]</label></div><br/><div class="children"><div class="content">A charity is a type of not-for-profit organisation however the main difference between a nonprofit and a charity is that a nonprofit doesn&#x27;t need to reach a &#x27;charitable status&#x27; whereas a charity, to qualify as a charity, needs to meet very specific or strict guidelines</div><br/><div id="38382744" class="c"><input type="checkbox" id="c-38382744" checked=""/><div class="controls bullet"><span class="by">ezfe</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381104">parent</a><span>|</span><a href="#38381218">next</a><span>|</span><label class="collapse" for="c-38382744">[-]</label><label class="expand" for="c-38382744">[2 more]</label></div><br/><div class="children"><div class="content">Yes, I misspoke - I meant nonprofit</div><br/><div id="38384720" class="c"><input type="checkbox" id="c-38384720" checked=""/><div class="controls bullet"><span class="by">zja</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382744">parent</a><span>|</span><a href="#38381218">next</a><span>|</span><label class="collapse" for="c-38384720">[-]</label><label class="expand" for="c-38384720">[1 more]</label></div><br/><div class="children"><div class="content">You were right though, OpenAI Inc, which the board controls, is a 501c3 charity.</div><br/></div></div></div></div></div></div></div></div><div id="38381218" class="c"><input type="checkbox" id="c-38381218" checked=""/><div class="controls bullet"><span class="by">strangesmells06</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380245">parent</a><span>|</span><a href="#38381040">prev</a><span>|</span><a href="#38380119">next</a><span>|</span><label class="collapse" for="c-38381218">[-]</label><label class="expand" for="c-38381218">[1 more]</label></div><br/><div class="children"><div class="content">&gt; First, the for-profit subsidiary is fully controlled by the OpenAI Nonprofit. We enacted this by having the Nonprofit wholly own and control a manager entity (OpenAI GP LLC) that has the power to control and govern the for-profit subsidiary.<p>Im not criticizing. Big fan of avoiding being taxed to fund wars....but its just funny to me it seems like theyre sort of having their cake and eating it too with this kind of structure.<p>Good for them.</div><br/></div></div></div></div><div id="38380119" class="c"><input type="checkbox" id="c-38380119" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38380245">prev</a><span>|</span><a href="#38378609">next</a><span>|</span><label class="collapse" for="c-38380119">[-]</label><label class="expand" for="c-38380119">[1 more]</label></div><br/><div class="children"><div class="content">There’s no indication a Microsoft appointed board member would be a Microsoft employee (though the they could be of course), and large nonprofits often have board members that come from for-profit companies.<p>I don’t think the IRS cares much about this kind of thing. What would be the claim? They OpenAI is pushing benefits to Microsoft, a for-profit entity that pays taxes? Even if you assume the absolute worst, most nefarious meddling, it seems like an issue for SEC more than IRS.</div><br/></div></div><div id="38378609" class="c"><input type="checkbox" id="c-38378609" checked=""/><div class="controls bullet"><span class="by">flagrant_taco</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38380119">prev</a><span>|</span><a href="#38381144">next</a><span>|</span><label class="collapse" for="c-38378609">[-]</label><label class="expand" for="c-38378609">[9 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t expect the government to regulate any of this aggressively. AI is much to important to the government and military to allow pesky conflicts of interest to slow down any competitive advantage we may have.</div><br/><div id="38379514" class="c"><input type="checkbox" id="c-38379514" checked=""/><div class="controls bullet"><span class="by">dgrin91</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38378609">parent</a><span>|</span><a href="#38381144">next</a><span>|</span><label class="collapse" for="c-38379514">[-]</label><label class="expand" for="c-38379514">[8 more]</label></div><br/><div class="children"><div class="content">If you think that OpenAI is the Gov&#x27;s only source of high quality AI research then I have a bridge to sell you.</div><br/><div id="38380038" class="c"><input type="checkbox" id="c-38380038" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38379514">parent</a><span>|</span><a href="#38381144">next</a><span>|</span><label class="collapse" for="c-38380038">[-]</label><label class="expand" for="c-38380038">[7 more]</label></div><br/><div class="children"><div class="content">If you think the person you&#x27;re replying to was talking about regulating OpenAI specifically and not the industry as a whole, I have ADHD medicine to sell you.</div><br/><div id="38382036" class="c"><input type="checkbox" id="c-38382036" checked=""/><div class="controls bullet"><span class="by">swores</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380038">parent</a><span>|</span><a href="#38381144">next</a><span>|</span><label class="collapse" for="c-38382036">[-]</label><label class="expand" for="c-38382036">[6 more]</label></div><br/><div class="children"><div class="content">The context of the comment thread you&#x27;re replying to was a response to a comment suggesting the IRS will get involved in the question of whether MS have too much influence over OpenAI, it was not the subject of general industry regulation.<p>But hey, at least you fitted in a snarky line about ADHD in the comment you wrote while not having paid attention to the 3 comments above it.</div><br/><div id="38383709" class="c"><input type="checkbox" id="c-38383709" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38382036">parent</a><span>|</span><a href="#38384466">prev</a><span>|</span><a href="#38381144">next</a><span>|</span><label class="collapse" for="c-38383709">[-]</label><label class="expand" for="c-38383709">[1 more]</label></div><br/><div class="children"><div class="content">if up-the-line parent wasn&#x27;t talking about regulation of AI in general, then what do you think they meant by &quot;competitive advantage&quot;?  Also, governments have to set policy and enforce that policy.  They can&#x27;t (or shouldn&#x27;t at least) pick and choose favorites.<p>Also GP snark was a reply to snark.  Once somebody opens the snark, they should expect snark back.  It&#x27;s ideal for nobody to snark, and big for people not to snark back at a snarker, but snarkers gonna snark.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38381144" class="c"><input type="checkbox" id="c-38381144" checked=""/><div class="controls bullet"><span class="by">pc86</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38378609">prev</a><span>|</span><a href="#38381666">next</a><span>|</span><label class="collapse" for="c-38381144">[-]</label><label class="expand" for="c-38381144">[6 more]</label></div><br/><div class="children"><div class="content">Others have pointed out several reasons this isn&#x27;t actually a problem (and that the premise itself is incorrect since &quot;OpenAI&quot; is not a charity), but one thing not mentioned: even if the MS-appointed board member is a MS employee, yes they will have a fiduciary duty to the organizations under the purview of the board, but unless they are <i>also</i> a board member of Microsoft (extraordinarily unlikely) they have no such fiduciary duty to Microsoft itself. So in the also unlikely scenario that there is a vote that conflicts with their Microsoft duties, and in the even more unlikely scenario that they don&#x27;t abstain due to that conflict, they have a legal responsibility to err on the side of OpenAI and no legal responsibility to Microsoft. Seems like a pretty easy decision to make - and abstaining is the easiest unless it&#x27;s a contentious 4-4 vote and there&#x27;s pressure for them to choose a side.<p>But all that seems a lot more like an episode of Succession and less like real life to be honest.</div><br/><div id="38381280" class="c"><input type="checkbox" id="c-38381280" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381144">parent</a><span>|</span><a href="#38381217">next</a><span>|</span><label class="collapse" for="c-38381280">[-]</label><label class="expand" for="c-38381280">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and that the premise itself is incorrect since &quot;OpenAI&quot; is not a charity<p>OpenAI is a 501c3 charity nonprofit, and the OpenAI board under discussion is the board of that charity nonprofit.<p>OpenAI Global LLC is a for-profit subsidiary of a for-profit subsidiary of OpenAI, both of which are controlled, by their foundational agreements that gie them legal existence, by a different (AFAICT not for-profit but not legally a nonprofit) LLC subsidiary of OpenAI (OpenAI GP LLC.)</div><br/></div></div><div id="38381217" class="c"><input type="checkbox" id="c-38381217" checked=""/><div class="controls bullet"><span class="by">throwoutway</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381144">parent</a><span>|</span><a href="#38381280">prev</a><span>|</span><a href="#38381317">next</a><span>|</span><label class="collapse" for="c-38381217">[-]</label><label class="expand" for="c-38381217">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still a conflict of interest. One that they should avoid. Microsoft COULD appoint someone who they like and shares their values, that is not a MSFT employee. That would be a preferred approach but one that I doubt a megacorp would take</div><br/><div id="38381564" class="c"><input type="checkbox" id="c-38381564" checked=""/><div class="controls bullet"><span class="by">ghaff</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381217">parent</a><span>|</span><a href="#38381317">next</a><span>|</span><label class="collapse" for="c-38381564">[-]</label><label class="expand" for="c-38381564">[1 more]</label></div><br/><div class="children"><div class="content">Both profit and non-profit boards have members that have potential conflicts of interest all the time. So long as it’s not too egregious no one cares, especially not the IRS.</div><br/></div></div></div></div><div id="38381317" class="c"><input type="checkbox" id="c-38381317" checked=""/><div class="controls bullet"><span class="by">oatmeal1</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381144">parent</a><span>|</span><a href="#38381217">prev</a><span>|</span><a href="#38388674">next</a><span>|</span><label class="collapse" for="c-38381317">[-]</label><label class="expand" for="c-38381317">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft is going to appoint someone who benefits Microsoft.  Whether a particular vote would violate fiduciary duty is subjective.  There&#x27;s plenty of opportunity for them to prioritize the welfare of Microsoft over OAI.</div><br/></div></div><div id="38388674" class="c"><input type="checkbox" id="c-38388674" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381144">parent</a><span>|</span><a href="#38381317">prev</a><span>|</span><a href="#38381666">next</a><span>|</span><label class="collapse" for="c-38388674">[-]</label><label class="expand" for="c-38388674">[1 more]</label></div><br/><div class="children"><div class="content">Whats the point of Microsoft appointing a board member if not to sway decision in ways that benefit them?</div><br/></div></div></div></div><div id="38381666" class="c"><input type="checkbox" id="c-38381666" checked=""/><div class="controls bullet"><span class="by">_b</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38381144">prev</a><span>|</span><a href="#38389109">next</a><span>|</span><label class="collapse" for="c-38381666">[-]</label><label class="expand" for="c-38381666">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There are obvious conflicts of interest here.<p>There are almost always obvious conflicts of interest. In a normal startup, VCs have a legal responsibility to act in the interest of the common shares, but in practice, they overtly act in the interest of the preferred shares that their fund holds.</div><br/><div id="38388606" class="c"><input type="checkbox" id="c-38388606" checked=""/><div class="controls bullet"><span class="by">hyperhopper</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381666">parent</a><span>|</span><a href="#38389109">next</a><span>|</span><label class="collapse" for="c-38388606">[-]</label><label class="expand" for="c-38388606">[1 more]</label></div><br/><div class="children"><div class="content">The more and more I see the way complex share structures are used, the more I think they should be outlawed</div><br/></div></div></div></div><div id="38389109" class="c"><input type="checkbox" id="c-38389109" checked=""/><div class="controls bullet"><span class="by">mattmcknight</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38381666">prev</a><span>|</span><a href="#38387076">next</a><span>|</span><label class="collapse" for="c-38389109">[-]</label><label class="expand" for="c-38389109">[1 more]</label></div><br/><div class="children"><div class="content">The non-profit could sell off its interest in the for-profit company and use the money for AGI research.</div><br/></div></div><div id="38387076" class="c"><input type="checkbox" id="c-38387076" checked=""/><div class="controls bullet"><span class="by">627467</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38389109">prev</a><span>|</span><a href="#38380930">next</a><span>|</span><label class="collapse" for="c-38387076">[-]</label><label class="expand" for="c-38387076">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get the drama with &quot;conflict of interests&quot;... Aren&#x27;t board members generally (always?) in representation of major shareholders? Isn&#x27;t it obvious that shareholders have interests that are likely to be in conflict with each other or even the own organization? Thats why board members are supposed to check each other, right?</div><br/><div id="38388703" class="c"><input type="checkbox" id="c-38388703" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38387076">parent</a><span>|</span><a href="#38380930">next</a><span>|</span><label class="collapse" for="c-38388703">[-]</label><label class="expand" for="c-38388703">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is a non profit and the board members are not allowed to own shares in the for profit.<p>That means the remaining conflicts are when the board has to make a decisions between growing the profit or furthering the mission statement. I wouldn&#x27;t trust the new board appointed by investors to ever make the correct decision in these cases, and they already kicked out the &quot;academic&quot; board members with the power to stop them.</div><br/></div></div></div></div><div id="38380930" class="c"><input type="checkbox" id="c-38380930" checked=""/><div class="controls bullet"><span class="by">mwattsun</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38387076">prev</a><span>|</span><a href="#38383703">next</a><span>|</span><label class="collapse" for="c-38380930">[-]</label><label class="expand" for="c-38380930">[4 more]</label></div><br/><div class="children"><div class="content">Microsoft doesn&#x27;t have to send an employee to represent them on the board. They could ask Bill Gates.</div><br/><div id="38386110" class="c"><input type="checkbox" id="c-38386110" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380930">parent</a><span>|</span><a href="#38382845">next</a><span>|</span><label class="collapse" for="c-38386110">[-]</label><label class="expand" for="c-38386110">[2 more]</label></div><br/><div class="children"><div class="content">Actually I think Bill would be a pretty good candidate. Smart, mature, good at first principles reasoning, deeply understands both the tech world and the nonprofit world, is a tech person who&#x27;s not socially networked with the existing SF VCs, and (if the vague unsubstantiated rumors about Sam are correct) is one of the few people left with enough social cachet to knock Sam down a peg or two.</div><br/><div id="38386443" class="c"><input type="checkbox" id="c-38386443" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38386110">parent</a><span>|</span><a href="#38382845">next</a><span>|</span><label class="collapse" for="c-38386443">[-]</label><label class="expand" for="c-38386443">[1 more]</label></div><br/><div class="children"><div class="content">Larry Summers, Bill Gates, if they keep on like that they can fill the board with all of Epstein&#x27;s &quot;associates&quot;.</div><br/></div></div></div></div></div></div><div id="38383703" class="c"><input type="checkbox" id="c-38383703" checked=""/><div class="controls bullet"><span class="by">zerohalo</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38380930">prev</a><span>|</span><a href="#38381983">next</a><span>|</span><label class="collapse" for="c-38383703">[-]</label><label class="expand" for="c-38383703">[4 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s charter is dead. I expect future boards to amend it.</div><br/><div id="38383752" class="c"><input type="checkbox" id="c-38383752" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38383703">parent</a><span>|</span><a href="#38385990">next</a><span>|</span><label class="collapse" for="c-38383752">[-]</label><label class="expand" for="c-38383752">[1 more]</label></div><br/><div class="children"><div class="content">Its useful PR pretext for their regulatory advocacy, and subjective enough that if they are careful not to be too obvious about specifically pushing one company’s commercial interest, they can probably get away with it forever, so why would it be any deader than when Sam was CEO before and not substantively guided by it.</div><br/></div></div><div id="38385990" class="c"><input type="checkbox" id="c-38385990" checked=""/><div class="controls bullet"><span class="by">ric2b</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38383703">parent</a><span>|</span><a href="#38383752">prev</a><span>|</span><a href="#38381983">next</a><span>|</span><label class="collapse" for="c-38385990">[-]</label><label class="expand" for="c-38385990">[2 more]</label></div><br/><div class="children"><div class="content">People keep saying this but is there any evidence that any of this was related to the charter?</div><br/><div id="38388725" class="c"><input type="checkbox" id="c-38388725" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38385990">parent</a><span>|</span><a href="#38381983">next</a><span>|</span><label class="collapse" for="c-38388725">[-]</label><label class="expand" for="c-38388725">[1 more]</label></div><br/><div class="children"><div class="content">The only evidence I have is that the board members that were removed had less business connections than the ones that replaced them.<p>The point of the board is to ensure the charter is being followed, when the biggest concern is &quot;is our commercialization getting in the way of our charter&quot; what else does it mean to replace &quot;academics&quot; with &quot;businesspeople&quot;?</div><br/></div></div></div></div></div></div><div id="38381983" class="c"><input type="checkbox" id="c-38381983" checked=""/><div class="controls bullet"><span class="by">boh</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38383703">prev</a><span>|</span><a href="#38380770">next</a><span>|</span><label class="collapse" for="c-38381983">[-]</label><label class="expand" for="c-38381983">[3 more]</label></div><br/><div class="children"><div class="content">Whenever there&#x27;s an obvious conflict, assume it&#x27;s not enforced or difficult to litigate or has relatively irrelevant penalties. Experts&#x2F;lawyers who have a material stake in getting this right have signed off on it. Many (if not most) people with enough status to be on the board of a fortune 500 company tend to also be on non-profit boards. We can go out on a limb and suppose the mission of the nonprofit is not their top priority, and yet they continue on unscathed.</div><br/><div id="38382082" class="c"><input type="checkbox" id="c-38382082" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381983">parent</a><span>|</span><a href="#38388713">next</a><span>|</span><label class="collapse" for="c-38382082">[-]</label><label class="expand" for="c-38382082">[1 more]</label></div><br/><div class="children"><div class="content">Do you remember before Bill Gates got into disease prevention he thought that “charity work” could be done by giving away free Microsoft products?  I don’t know who sat him down and explained to him how full of shit he was but they deserve a Nobel Peace Prize nomination.<p>Just because someone says they agree with a mission doesn’t mean they have their heads screwed on straight. And my thesis is that the more power they have in the real world the worse the outcomes - because powerful people become progressively immune to feedback. This has been working swimmingly for me for decades, I don’t need humility in a new situation.</div><br/></div></div><div id="38388713" class="c"><input type="checkbox" id="c-38388713" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381983">parent</a><span>|</span><a href="#38382082">prev</a><span>|</span><a href="#38380770">next</a><span>|</span><label class="collapse" for="c-38388713">[-]</label><label class="expand" for="c-38388713">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Experts&#x2F;lawyers who have a material stake in getting this right have signed off on it.<p>How does that work when we&#x27;re talking about non-profit motives? The lawyers are paid by the companies benefitting from these conflicts, so how is it at all reassuring to hear that the people who benefit from the conflict signed off on it?<p>&gt; We can go out on a limb and suppose the mission of the nonprofit is not their top priority, and yet they continue on unscathed.<p>That&#x27;s the concern. They&#x27;ve just replaced people who &quot;maybe&quot; cared about the mission statement with people who you&#x27;ve correctly identified care more about profit growth than the nonprofit mission.</div><br/></div></div></div></div><div id="38380770" class="c"><input type="checkbox" id="c-38380770" checked=""/><div class="controls bullet"><span class="by">voxic11</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38381983">prev</a><span>|</span><a href="#38383060">next</a><span>|</span><label class="collapse" for="c-38380770">[-]</label><label class="expand" for="c-38380770">[1 more]</label></div><br/><div class="children"><div class="content">Even if the IRS isn&#x27;t a fan, what are they going to do about it? It seems like the main recourse they could pursue is they could force the OpenAI directors&#x2F;Microsoft to pay an excise tax on any &quot;excess benefit transactions&quot;.<p><a href="https:&#x2F;&#x2F;www.irs.gov&#x2F;charities-non-profits&#x2F;charitable-organizations&#x2F;intermediate-sanctions-excess-benefit-transactions" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.irs.gov&#x2F;charities-non-profits&#x2F;charitable-organiz...</a></div><br/></div></div><div id="38383060" class="c"><input type="checkbox" id="c-38383060" checked=""/><div class="controls bullet"><span class="by">jklein11</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38380770">prev</a><span>|</span><a href="#38380123">next</a><span>|</span><label class="collapse" for="c-38383060">[-]</label><label class="expand" for="c-38383060">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a little bit confused, are you saying that the IRS would have some sort of beef with employees of Microsoft serving on the board of a 501(c)(3)?</div><br/></div></div><div id="38380123" class="c"><input type="checkbox" id="c-38380123" checked=""/><div class="controls bullet"><span class="by">TigeriusKirk</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38383060">prev</a><span>|</span><a href="#38381856">next</a><span>|</span><label class="collapse" for="c-38380123">[-]</label><label class="expand" for="c-38380123">[8 more]</label></div><br/><div class="children"><div class="content">Larry Summers is in place to effectively give the govt seal of approval on the new board, for better and worse.</div><br/><div id="38385346" class="c"><input type="checkbox" id="c-38385346" checked=""/><div class="controls bullet"><span class="by">mcast</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380123">parent</a><span>|</span><a href="#38380829">next</a><span>|</span><label class="collapse" for="c-38385346">[-]</label><label class="expand" for="c-38385346">[1 more]</label></div><br/><div class="children"><div class="content">If you wanted to wear a foil hat, you might think this internal fighting was started from someone connected to TPTB subverting the rest of the board to gain a board seat, and thus more power and influence, over AGI.<p>The hush-hush nature of the board providing zero explanation for why sama was fired (and what started it) certainly doesn&#x27;t pass the smell test.</div><br/></div></div><div id="38380829" class="c"><input type="checkbox" id="c-38380829" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380123">parent</a><span>|</span><a href="#38385346">prev</a><span>|</span><a href="#38381856">next</a><span>|</span><label class="collapse" for="c-38380829">[-]</label><label class="expand" for="c-38380829">[6 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t he a big Jeffrey Epstein fanboy? Ethical AGI is in safe hands.<p><a href="https:&#x2F;&#x2F;www.thecrimson.com&#x2F;article&#x2F;2023&#x2F;5&#x2F;5&#x2F;epstein-summers-meeting&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.thecrimson.com&#x2F;article&#x2F;2023&#x2F;5&#x2F;5&#x2F;epstein-summers-...</a></div><br/><div id="38381859" class="c"><input type="checkbox" id="c-38381859" checked=""/><div class="controls bullet"><span class="by">futuretaint</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380829">parent</a><span>|</span><a href="#38382976">next</a><span>|</span><label class="collapse" for="c-38381859">[-]</label><label class="expand" for="c-38381859">[1 more]</label></div><br/><div class="children"><div class="content">nothing screams &#x27;protect public interest&#x27; more than Wall Streets biggest cheerleader during 2008 financial crisis.  who&#x27;s next, Richard S. Fuld Jr  ?  Should the Enron guys be included ?</div><br/></div></div><div id="38383943" class="c"><input type="checkbox" id="c-38383943" checked=""/><div class="controls bullet"><span class="by">kossTKR</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380829">parent</a><span>|</span><a href="#38382976">prev</a><span>|</span><a href="#38381856">next</a><span>|</span><label class="collapse" for="c-38383943">[-]</label><label class="expand" for="c-38383943">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s obvious this class of people love their status as neu-feudal lords above the law living as 18th century libertines behind closed doors.<p>But i guess people here are either waiting for wealth to trickle down on them or believe the torrent of psychological operations so much peoples minds close down when they intuit the circular brutal nature of hierarchical class based society, and the utter illusion democracy or meritocracy is.<p>The uppermost classes have been trickters through all of history. What happened to this knowledge and the countercultural scene in hacking? Hint; it was psyopped in the early 90&#x27;s by &quot;libertarianism&quot; and worship of bureaucracy to create a new class of cybernetic soldiers working for the oligarchy.</div><br/><div id="38386680" class="c"><input type="checkbox" id="c-38386680" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38383943">parent</a><span>|</span><a href="#38381856">next</a><span>|</span><label class="collapse" for="c-38386680">[-]</label><label class="expand" for="c-38386680">[2 more]</label></div><br/><div class="children"><div class="content">I agree. The best young minds grinding leet code to get into Google is the biggest symptom of it.</div><br/><div id="38389841" class="c"><input type="checkbox" id="c-38389841" checked=""/><div class="controls bullet"><span class="by">DSingularity</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38386680">parent</a><span>|</span><a href="#38381856">next</a><span>|</span><label class="collapse" for="c-38389841">[-]</label><label class="expand" for="c-38389841">[1 more]</label></div><br/><div class="children"><div class="content">The sad part isn’t the rampant sickness. The saddest part is all the “intellectual” professors who enable, encourage, and celebrate this.<p>It’s sickening.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38381856" class="c"><input type="checkbox" id="c-38381856" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38380123">prev</a><span>|</span><a href="#38386337">next</a><span>|</span><label class="collapse" for="c-38381856">[-]</label><label class="expand" for="c-38381856">[1 more]</label></div><br/><div class="children"><div class="content">Not to mention, the mission of the Board cannot be &quot;build safe AGI&quot; anymore. Perhaps something more consistent with expanding shareholder value and capitalism, as the events of this weekend has shown.<p>Delivering profits and shareholder value is the sole and dominant force in capitalism. Remains to be seen whether that is consistent with humanity&#x27;s survival</div><br/></div></div><div id="38386337" class="c"><input type="checkbox" id="c-38386337" checked=""/><div class="controls bullet"><span class="by">augustulus</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38381856">prev</a><span>|</span><a href="#38382645">next</a><span>|</span><label class="collapse" for="c-38386337">[-]</label><label class="expand" for="c-38386337">[1 more]</label></div><br/><div class="children"><div class="content">how can they not remain a charity?</div><br/></div></div><div id="38380182" class="c"><input type="checkbox" id="c-38380182" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38378069">parent</a><span>|</span><a href="#38382645">prev</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38380182">[-]</label><label class="expand" for="c-38380182">[5 more]</label></div><br/><div class="children"><div class="content">What if I told you...Bill Gates was&#x2F;is on the board of the non-profit Bill and Melinda Gates Foundation?<p>Lol HN lawyering is hilarious.</div><br/><div id="38380271" class="c"><input type="checkbox" id="c-38380271" checked=""/><div class="controls bullet"><span class="by">fatbird</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380182">parent</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38380271">[-]</label><label class="expand" for="c-38380271">[4 more]</label></div><br/><div class="children"><div class="content">Indeed, it is hilarious.<p>The Foundation has nothing to do with MS and can&#x27;t possibly be considered a competitor, acquisition target, supplier, or any other entity where a decision for the Foundation might materially harm MS (or the reverse).  There&#x27;s no potential conflict of interest between the missions of the two.<p>Did you think OP meant there was some inherent conflict of interest with charities?</div><br/><div id="38380294" class="c"><input type="checkbox" id="c-38380294" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380271">parent</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38380294">[-]</label><label class="expand" for="c-38380294">[3 more]</label></div><br/><div class="children"><div class="content">Have you <i>seen</i> OpenAI&#x27;s current board?<p>Explain how an MS employee would have greater conflict of interest.</div><br/><div id="38381588" class="c"><input type="checkbox" id="c-38381588" checked=""/><div class="controls bullet"><span class="by">uxp8u61q</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38380294">parent</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38381588">[-]</label><label class="expand" for="c-38381588">[2 more]</label></div><br/><div class="children"><div class="content">Conflict of interest with what? The other board members? That&#x27;s utterly irrelevant. Look up some big companies boards some day. You&#x27;ll see.</div><br/><div id="38383754" class="c"><input type="checkbox" id="c-38383754" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38378069">root</a><span>|</span><a href="#38381588">parent</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38383754">[-]</label><label class="expand" for="c-38383754">[1 more]</label></div><br/><div class="children"><div class="content">See earlier<p>&gt; If OpenAI remains a 501(c)(3) charity, then any employee of Microsoft on the board will have a fiduciary duty to advance the mission of the charity, rather than the business needs of Microsoft. There are obvious conflicts of interest here.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38378069">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38378069</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38375937" class="c"><input type="checkbox" id="c-38375937" checked=""/><div class="controls bullet"><span class="by">laserlight</span><span>|</span><a href="#38378069">prev</a><span>|</span><a href="#38380577">next</a><span>|</span><label class="collapse" for="c-38375937">[-]</label><label class="expand" for="c-38375937">[78 more]</label></div><br/><div class="children"><div class="content">With Sam coming back as CEO, hasn&#x27;t OpenAI board proven that it has lost its function? Regardless of who is in the board, they won&#x27;t be able to exercise one of the most fundamental of their rights, firing the CEO, because Sam has proven that he is unfireable. Now, Sam can do however he pleases, whether it is lying, not reporting, etc. To be clear, I don&#x27;t claim that Sam did, or will, lie, or misbehave.</div><br/><div id="38376229" class="c"><input type="checkbox" id="c-38376229" checked=""/><div class="controls bullet"><span class="by">random_cynic</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38380603">next</a><span>|</span><label class="collapse" for="c-38376229">[-]</label><label class="expand" for="c-38376229">[32 more]</label></div><br/><div class="children"><div class="content">No that hasn&#x27;t at all been the case. The board acted like the most incompetent group of individuals who&#x27;ve even handed any responsibility. If they went through due process, notified their employees and investors, and put out a statement of why they&#x27;re firing the CEO instead of doing it over a 15 min Google meet and then going completely silent, none of this outrage would have taken place.</div><br/><div id="38382088" class="c"><input type="checkbox" id="c-38382088" checked=""/><div class="controls bullet"><span class="by">OnAYDIN</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38377760">next</a><span>|</span><label class="collapse" for="c-38382088">[-]</label><label class="expand" for="c-38382088">[9 more]</label></div><br/><div class="children"><div class="content">Actually the board may not have acted in most professional way but in due process they kind of proved Sam Altman is unfireable for sure, even if they didn&#x27;t intend to.<p>They did notify everyone. They did it after firing which is within their rights. They may also choose to stay silent if there is legitimate reason for it such as making the reasons known may harm the organization even more. This is speculation obviously.<p>In any case they didn&#x27;t omit doing anything they need to and they didn&#x27;t exercise a power they didn&#x27;t have. The end result is that the board they choose will be impotent at the moment, for sure.</div><br/><div id="38383624" class="c"><input type="checkbox" id="c-38383624" checked=""/><div class="controls bullet"><span class="by">jonas21</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38382971">next</a><span>|</span><label class="collapse" for="c-38383624">[-]</label><label class="expand" for="c-38383624">[3 more]</label></div><br/><div class="children"><div class="content">Firing Sam was within the board&#x27;s rights. And 90% of the employees threatening to leave was within their rights.<p>All this proved is that you can&#x27;t take a major action that is deeply unpopular with employees, without consulting them, and expect to still have a functioning organization. This should be obvious, but it apparently never crossed the board&#x27;s mind.</div><br/><div id="38383791" class="c"><input type="checkbox" id="c-38383791" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383624">parent</a><span>|</span><a href="#38387014">next</a><span>|</span><label class="collapse" for="c-38383791">[-]</label><label class="expand" for="c-38383791">[1 more]</label></div><br/><div class="children"><div class="content">A lot of these high-up tech leaders seem to forget this regularly.  They sit on their thrones and dictate wild swings, and are used to having people obey.  They get all the praise and adulation when things go well, and when things don&#x27;t go well they golden parachute into some other organization who hires based on resume titles rather than leadership and technical ability.  It doesn&#x27;t surprise me at all that they were caught off guard by this.</div><br/></div></div><div id="38387014" class="c"><input type="checkbox" id="c-38387014" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383624">parent</a><span>|</span><a href="#38383791">prev</a><span>|</span><a href="#38382971">next</a><span>|</span><label class="collapse" for="c-38387014">[-]</label><label class="expand" for="c-38387014">[1 more]</label></div><br/><div class="children"><div class="content">Not sure how much of the employees leaving have to do with negotiating Sam back, must be a big factor but not all, during the table talk Emmett, Angelo and Ilya must have decided that it wasn’t a good firing and a mistake in retrospect and it is to fix it.</div><br/></div></div></div></div><div id="38382971" class="c"><input type="checkbox" id="c-38382971" checked=""/><div class="controls bullet"><span class="by">eksapsy</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38383624">prev</a><span>|</span><a href="#38382837">next</a><span>|</span><label class="collapse" for="c-38382971">[-]</label><label class="expand" for="c-38382971">[1 more]</label></div><br/><div class="children"><div class="content">Getting your point, although the fact that something is within your rights, may or may not mean certainly that it&#x27;s also a proper thing to do ... ?<p>Like, nobody is going to arrest you for spitting on the street especially if you&#x27;re an old grandpa.
Nobody is going to arrest you for saying nasty things about somebody&#x27;s mom.<p>You get my point, to some boundary both are kinda within somebody&#x27;s rights, although can be suable or can be reported for misbehaving. But that&#x27;s the keypoint, misbehavior.<p>Just because something is within your rights doesn&#x27;t mean you&#x27;re not misbehaving or not acting in an immature way.<p>To be clear, Im not denying or agreeing that the board of directors acted in an immature way. I&#x27;m just arguing against the claim that was made within your text that just because someone is acting within their rights that it&#x27;s also a &quot;right&quot; thing to do necessary, while that is not the case always.</div><br/></div></div><div id="38382837" class="c"><input type="checkbox" id="c-38382837" checked=""/><div class="controls bullet"><span class="by">qudat</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38382971">prev</a><span>|</span><a href="#38387697">next</a><span>|</span><label class="collapse" for="c-38382837">[-]</label><label class="expand" for="c-38382837">[1 more]</label></div><br/><div class="children"><div class="content">&gt; proved Sam Altman is unfireable [without explaining why to its employees].</div><br/></div></div><div id="38387697" class="c"><input type="checkbox" id="c-38387697" checked=""/><div class="controls bullet"><span class="by">random_cynic</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38382837">prev</a><span>|</span><a href="#38382500">next</a><span>|</span><label class="collapse" for="c-38387697">[-]</label><label class="expand" for="c-38387697">[1 more]</label></div><br/><div class="children"><div class="content">If you read my comment again, I&#x27;m talking about their competence, not their rights. Those are two entirely different things.</div><br/></div></div><div id="38382500" class="c"><input type="checkbox" id="c-38382500" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38387697">prev</a><span>|</span><a href="#38383832">next</a><span>|</span><label class="collapse" for="c-38382500">[-]</label><label class="expand" for="c-38382500">[1 more]</label></div><br/><div class="children"><div class="content">Their communication was completely insufficient. There is no possible world on which the board could be considered &quot;competent&quot; or &quot;professional.&quot;</div><br/></div></div><div id="38383832" class="c"><input type="checkbox" id="c-38383832" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382088">parent</a><span>|</span><a href="#38382500">prev</a><span>|</span><a href="#38377760">next</a><span>|</span><label class="collapse" for="c-38383832">[-]</label><label class="expand" for="c-38383832">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They may also choose to stay silent<p>They may choose to, and they did choose to.<p>But it was an incompitant choice. (Obviously.)</div><br/></div></div></div></div><div id="38377760" class="c"><input type="checkbox" id="c-38377760" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38382088">prev</a><span>|</span><a href="#38376647">next</a><span>|</span><label class="collapse" for="c-38377760">[-]</label><label class="expand" for="c-38377760">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The board acted like the most incompetent group of individuals who&#x27;ve even handed any responsibility.<p>This is overly dramatic, but I suppose that&#x27;s par for this round.<p>&gt; none of this outrage would have taken place.<p>Yeah... I highly doubt this, personally. I&#x27;m sure the outrage would have been similar, as HN&#x27;s current favorite CEO was fired.</div><br/><div id="38378394" class="c"><input type="checkbox" id="c-38378394" checked=""/><div class="controls bullet"><span class="by">pas</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377760">parent</a><span>|</span><a href="#38383915">next</a><span>|</span><label class="collapse" for="c-38378394">[-]</label><label class="expand" for="c-38378394">[3 more]</label></div><br/><div class="children"><div class="content">HN sentiment is pretty ambivalent regarding Altman. yes, almost everyone agrees he&#x27;s important, but a big group things he&#x27;s basically landed gentry exploiting ML researchers, an other thinks he&#x27;s a genius for getting MS pay for GPT costs, etc.</div><br/><div id="38380987" class="c"><input type="checkbox" id="c-38380987" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38378394">parent</a><span>|</span><a href="#38383915">next</a><span>|</span><label class="collapse" for="c-38380987">[-]</label><label class="expand" for="c-38380987">[2 more]</label></div><br/><div class="children"><div class="content">I think a page developed by YC thinks a lot more about him than that ;)</div><br/><div id="38387538" class="c"><input type="checkbox" id="c-38387538" checked=""/><div class="controls bullet"><span class="by">komali2</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380987">parent</a><span>|</span><a href="#38383915">next</a><span>|</span><label class="collapse" for="c-38387538">[-]</label><label class="expand" for="c-38387538">[1 more]</label></div><br/><div class="children"><div class="content">Just putting my hand up as one of the dudes that happened to enter my email on a yc forum (not &quot;page&quot;) but really doesn&#x27;t like the guy lol.<p>I also have a Twitter account. Guess my opinion on the current or former Twitter CEOs?</div><br/></div></div></div></div></div></div><div id="38383915" class="c"><input type="checkbox" id="c-38383915" checked=""/><div class="controls bullet"><span class="by">SilasX</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377760">parent</a><span>|</span><a href="#38378394">prev</a><span>|</span><a href="#38376647">next</a><span>|</span><label class="collapse" for="c-38383915">[-]</label><label class="expand" for="c-38383915">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. It&#x27;s naive to think that an decision <i>this</i> unpopular <i>somehow</i> wouldn&#x27;t have resulted in dissent and fracturing if only they had given it a better explanation and dotted more i&#x27;s.<p>Imagine arguing this in another context: &quot;Man, if <i>only</i> the Supreme Court had clearly articulated its reasoning in overturning Roe v Wade, there wouldn&#x27;t have been all this outrage over it.&quot;<p>(I&#x27;m happy to accept that there&#x27;s plenty of room for avoiding some of the damage, like the torrents of observers thinking &quot;these board members clearly don&#x27;t know what they&#x27;re doing&quot;.)</div><br/></div></div></div></div><div id="38376647" class="c"><input type="checkbox" id="c-38376647" checked=""/><div class="controls bullet"><span class="by">maxlin</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38377760">prev</a><span>|</span><a href="#38382070">next</a><span>|</span><label class="collapse" for="c-38376647">[-]</label><label class="expand" for="c-38376647">[11 more]</label></div><br/><div class="children"><div class="content">Exactly. 3 CEO switches in a week is ridiculous</div><br/><div id="38379546" class="c"><input type="checkbox" id="c-38379546" checked=""/><div class="controls bullet"><span class="by">caleb-allen</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376647">parent</a><span>|</span><a href="#38376897">next</a><span>|</span><label class="collapse" for="c-38379546">[-]</label><label class="expand" for="c-38379546">[2 more]</label></div><br/><div class="children"><div class="content">Maybe it came at the advice of Rishi Sunak when he and Altman met last week!</div><br/></div></div><div id="38376897" class="c"><input type="checkbox" id="c-38376897" checked=""/><div class="controls bullet"><span class="by">abkolan</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376647">parent</a><span>|</span><a href="#38379546">prev</a><span>|</span><a href="#38382070">next</a><span>|</span><label class="collapse" for="c-38376897">[-]</label><label class="expand" for="c-38376897">[8 more]</label></div><br/><div class="children"><div class="content">Four CEO changes in five days to be precise.<p>Sam -&gt; Mira -&gt; Emmet -&gt; Sam</div><br/><div id="38377100" class="c"><input type="checkbox" id="c-38377100" checked=""/><div class="controls bullet"><span class="by">Hendrikto</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376897">parent</a><span>|</span><a href="#38380154">next</a><span>|</span><label class="collapse" for="c-38377100">[-]</label><label class="expand" for="c-38377100">[3 more]</label></div><br/><div class="children"><div class="content">That are three changes. Every arrow is one.</div><br/><div id="38377204" class="c"><input type="checkbox" id="c-38377204" checked=""/><div class="controls bullet"><span class="by">physicles</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377100">parent</a><span>|</span><a href="#38379024">next</a><span>|</span><label class="collapse" for="c-38377204">[-]</label><label class="expand" for="c-38377204">[1 more]</label></div><br/><div class="children"><div class="content">Classic fence post error.</div><br/></div></div><div id="38379024" class="c"><input type="checkbox" id="c-38379024" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377100">parent</a><span>|</span><a href="#38377204">prev</a><span>|</span><a href="#38380154">next</a><span>|</span><label class="collapse" for="c-38379024">[-]</label><label class="expand" for="c-38379024">[1 more]</label></div><br/><div class="children"><div class="content">And technically 2 new CEOs</div><br/></div></div></div></div><div id="38380154" class="c"><input type="checkbox" id="c-38380154" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376897">parent</a><span>|</span><a href="#38377100">prev</a><span>|</span><a href="#38383808">next</a><span>|</span><label class="collapse" for="c-38380154">[-]</label><label class="expand" for="c-38380154">[2 more]</label></div><br/><div class="children"><div class="content">The three hard problems: naming things and off-by-one errors</div><br/><div id="38381820" class="c"><input type="checkbox" id="c-38381820" checked=""/><div class="controls bullet"><span class="by">Crespyl</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380154">parent</a><span>|</span><a href="#38383808">next</a><span>|</span><label class="collapse" for="c-38381820">[-]</label><label class="expand" for="c-38381820">[1 more]</label></div><br/><div class="children"><div class="content">I always heard:<p>There are two hard problems: naming things, cache invalidation, and off-by-one errors.</div><br/></div></div></div></div><div id="38383808" class="c"><input type="checkbox" id="c-38383808" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376897">parent</a><span>|</span><a href="#38380154">prev</a><span>|</span><a href="#38381752">next</a><span>|</span><label class="collapse" for="c-38383808">[-]</label><label class="expand" for="c-38383808">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for not editing this away.  Easy mistake to make, and gave us a good laugh (hopefully laughing <i>with</i> you.  Everyone who&#x27;s ever programmed has made the same error).</div><br/></div></div><div id="38381752" class="c"><input type="checkbox" id="c-38381752" checked=""/><div class="controls bullet"><span class="by">low_tech_punk</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376897">parent</a><span>|</span><a href="#38383808">prev</a><span>|</span><a href="#38382070">next</a><span>|</span><label class="collapse" for="c-38381752">[-]</label><label class="expand" for="c-38381752">[1 more]</label></div><br/><div class="children"><div class="content">Set semantic or List semantic?</div><br/></div></div></div></div></div></div><div id="38382070" class="c"><input type="checkbox" id="c-38382070" checked=""/><div class="controls bullet"><span class="by">braiamp</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38376647">prev</a><span>|</span><a href="#38383851">next</a><span>|</span><label class="collapse" for="c-38382070">[-]</label><label class="expand" for="c-38382070">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If they went through due process, notified their employees and investors, and put out a statement of why they&#x27;re firing the CEO<p>Did you read the bylaws? They have no responsibility to do any of that.</div><br/><div id="38383867" class="c"><input type="checkbox" id="c-38383867" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382070">parent</a><span>|</span><a href="#38382108">next</a><span>|</span><label class="collapse" for="c-38383867">[-]</label><label class="expand" for="c-38383867">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  Here lies the body of William Jay,
  Who died maintaining his right of way –
  He was right, dead right, as he sped along,
  But he&#x27;s just as dead as if he were wrong.

    - Dale Carnegie</code></pre></div><br/></div></div><div id="38382108" class="c"><input type="checkbox" id="c-38382108" checked=""/><div class="controls bullet"><span class="by">ksd482</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382070">parent</a><span>|</span><a href="#38383867">prev</a><span>|</span><a href="#38383012">next</a><span>|</span><label class="collapse" for="c-38382108">[-]</label><label class="expand" for="c-38382108">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the point. Whether or not it was in the bylaws, this would have been the sensible thing to do.</div><br/></div></div><div id="38383012" class="c"><input type="checkbox" id="c-38383012" checked=""/><div class="controls bullet"><span class="by">eksapsy</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382070">parent</a><span>|</span><a href="#38382108">prev</a><span>|</span><a href="#38383851">next</a><span>|</span><label class="collapse" for="c-38383012">[-]</label><label class="expand" for="c-38383012">[1 more]</label></div><br/><div class="children"><div class="content">you don&#x27;t have responsibility for washing yourself before going to a mass transport vehicle full of people. it&#x27;s within your rights not to do that and be the smelliest person in the bus.<p>does it mean it&#x27;s right or professional?<p>getting your point, but i hope you get the point i make as well, that just because you have no responsibility for something doesn&#x27;t mean you&#x27;re right or not unethical for doing or not doing that thing. so i feel like you&#x27;re losing the point a little.</div><br/></div></div></div></div><div id="38383851" class="c"><input type="checkbox" id="c-38383851" checked=""/><div class="controls bullet"><span class="by">zerohalo</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38382070">prev</a><span>|</span><a href="#38379541">next</a><span>|</span><label class="collapse" for="c-38383851">[-]</label><label class="expand" for="c-38383851">[1 more]</label></div><br/><div class="children"><div class="content">&gt; none of this outrage would have taken place.<p>most certainly would have still taken place; no one cares about how it was done; what they care about it being able to make $$; and it was clearly going to not be as heavily prioritized without Altman (which is why MSFT embraced him and his engineers almost immediately).<p>&gt; notified their employees and investors
they did notify their employees; they have fiduciary duty to investors as a nonprofit.</div><br/></div></div></div></div><div id="38380603" class="c"><input type="checkbox" id="c-38380603" checked=""/><div class="controls bullet"><span class="by">stetrain</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376229">prev</a><span>|</span><a href="#38376377">next</a><span>|</span><label class="collapse" for="c-38380603">[-]</label><label class="expand" for="c-38380603">[17 more]</label></div><br/><div class="children"><div class="content">Imagine if the board of Apple fired Tim Cook with no warning right after he went on stage and announced their new developer platform updates for the year alongside record growth and sales, refused to elaborate as to the reasons or provide any useful communications to investors over several days, and replaced their first interim CEO with another interim CEO from a completely different kind of business in that same weekend.<p>If you don&#x27;t think there would be a shareholder revolt against the board, for simply exercising their most fundamental right to fire the CEO, I think you&#x27;re missing part the picture.</div><br/><div id="38381013" class="c"><input type="checkbox" id="c-38381013" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380603">parent</a><span>|</span><a href="#38383046">next</a><span>|</span><label class="collapse" for="c-38381013">[-]</label><label class="expand" for="c-38381013">[8 more]</label></div><br/><div class="children"><div class="content">It is prudent to recall that enhancing shareholder value and delivering record growth and sales are NOT the mission of the company or Board. But now it appears that it will have to be.</div><br/><div id="38382049" class="c"><input type="checkbox" id="c-38382049" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38381013">parent</a><span>|</span><a href="#38382498">next</a><span>|</span><label class="collapse" for="c-38382049">[-]</label><label class="expand" for="c-38382049">[5 more]</label></div><br/><div class="children"><div class="content">Yeah, but they <i>also</i> didn&#x27;t elaborate in the slightest about how they were serving the charter with their actions.<p>If they were super-duper worried about how Sam was going to cause a global extinction event with AI, or even just that he was driving the company in too commercial of a direction, <i>they should have said that to everyone!</i><p>The idea that they could fire the CEO with a super vague, one-paragraph statement, and then expect 800 employees who respect that CEO to just... be totally fine with that is absolutely fucking insane, regardless of the board&#x27;s fiduciary responsibilities. They&#x27;re board members, not gods.</div><br/><div id="38383511" class="c"><input type="checkbox" id="c-38383511" checked=""/><div class="controls bullet"><span class="by">NanoYohaneTSU</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382049">parent</a><span>|</span><a href="#38382498">next</a><span>|</span><label class="collapse" for="c-38383511">[-]</label><label class="expand" for="c-38383511">[4 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t have to elaborate. As many have pointed out, most people have been given advice to not say anything at all when SHTF. If they did say something there would still be drama. It&#x27;s best to keep these details internal.<p>I still believe in the theory that Altman was going hard after profits. Both McCauley and Toner are focused on the altruistic aspects of AGI and safety. Altman shouldn&#x27;t be at OpenAI and neither should D’Angelo.</div><br/><div id="38384092" class="c"><input type="checkbox" id="c-38384092" checked=""/><div class="controls bullet"><span class="by">stetrain</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383511">parent</a><span>|</span><a href="#38383910">next</a><span>|</span><label class="collapse" for="c-38384092">[-]</label><label class="expand" for="c-38384092">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They don&#x27;t have to elaborate.<p>Sure, they don&#x27;t have to. How did that work out?<p>Four CEOs in five days, their largest partner stepping in to try to stop the chaos, and almost the entirety of their employees threatening to leave for guaranteed jobs at that partner if the board didn&#x27;t step down.</div><br/></div></div><div id="38383910" class="c"><input type="checkbox" id="c-38383910" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383511">parent</a><span>|</span><a href="#38384092">prev</a><span>|</span><a href="#38382498">next</a><span>|</span><label class="collapse" for="c-38383910">[-]</label><label class="expand" for="c-38383910">[2 more]</label></div><br/><div class="children"><div class="content">Okay, keep silent to save your own ass, fine<p>But why would anyone expect 800 people to risk their livelihoods and work without a <i>little</i> serious justification? This was an inevitable reaction.</div><br/><div id="38386207" class="c"><input type="checkbox" id="c-38386207" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383910">parent</a><span>|</span><a href="#38382498">next</a><span>|</span><label class="collapse" for="c-38386207">[-]</label><label class="expand" for="c-38386207">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s important to keep in mind that BOTH Altman and the board maneuvered to threaten to destroy OpenAI.<p>If Altman was silent and&#x2F;or said something like &quot;people take some time off for Thanksgiving, in a week calmer minds will prevail&quot; while negotiating behind the scenes, OpenAI would look a lot less dire in the last few days. Instead he launched a public pressure campaign, likely pressured Mira, got Satya to make some fake commitments, got Greg Bockman&#x27;s wife to emotionally pressure Ilya, etc.<p>Masterful chess, clearly. But playing people like pieces nonetheless.</div><br/></div></div></div></div></div></div></div></div><div id="38382498" class="c"><input type="checkbox" id="c-38382498" checked=""/><div class="controls bullet"><span class="by">stetrain</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38381013">parent</a><span>|</span><a href="#38382049">prev</a><span>|</span><a href="#38385957">next</a><span>|</span><label class="collapse" for="c-38382498">[-]</label><label class="expand" for="c-38382498">[1 more]</label></div><br/><div class="children"><div class="content">Sure, there is a difference there. But the actions that erode confidence are the same.<p>You could tell the same story about a rising sports team replacing their star coach, or a military sacking a general the day after he marched through the streets to fanfare after winning a battle.<p>Even without the money involved, a sudden change in leadership with no explanation, followed only by increasing uncertainty and cloudy communication, is not going to go well for those who are backing you.<p>Even in the most altruistic version of OpenAI&#x27;s goals I&#x27;m fairly sure they need employees and funding to pay those employees and do the research.</div><br/></div></div><div id="38385957" class="c"><input type="checkbox" id="c-38385957" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38381013">parent</a><span>|</span><a href="#38382498">prev</a><span>|</span><a href="#38383046">next</a><span>|</span><label class="collapse" for="c-38385957">[-]</label><label class="expand" for="c-38385957">[1 more]</label></div><br/><div class="children"><div class="content">&gt; enhancing shareholder value and delivering record growth and sales are NOT the mission of the company<p>Developer platform updates seem to be inline.<p>And in any case, the board also failed to specify how their action furthered the mission of the company.<p>From all appearances, it appeared to damage the mission of the company. (If for no other reason that it dissolve the company and gave everything to MSFT.)</div><br/></div></div></div></div><div id="38383046" class="c"><input type="checkbox" id="c-38383046" checked=""/><div class="controls bullet"><span class="by">eksapsy</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380603">parent</a><span>|</span><a href="#38381013">prev</a><span>|</span><a href="#38382993">next</a><span>|</span><label class="collapse" for="c-38383046">[-]</label><label class="expand" for="c-38383046">[2 more]</label></div><br/><div class="children"><div class="content">no but the people like the developers, clients, government etc. have also the right to exercise their revolt against decisions they don&#x27;t like as well. don&#x27;t you think?<p>like, you get me, the board of directors is not the only actual power within a company, and that was proven by the whole scandal of Sam being discarded&#x2F;fired that was made by the developers themselves. they also have the right to exercise their right to just not work at this company without the leader they may had liked.</div><br/><div id="38384136" class="c"><input type="checkbox" id="c-38384136" checked=""/><div class="controls bullet"><span class="by">stetrain</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383046">parent</a><span>|</span><a href="#38382993">next</a><span>|</span><label class="collapse" for="c-38384136">[-]</label><label class="expand" for="c-38384136">[1 more]</label></div><br/><div class="children"><div class="content">Right. I really should have said employees and investors. Even if OpenAI somehow had no regard for its investors, they still need their employees to accomplish their mission. And funding to pay those employees.<p>The board seemed to have the confidence of none of the groups they needed confidence from.</div><br/></div></div></div></div><div id="38382993" class="c"><input type="checkbox" id="c-38382993" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380603">parent</a><span>|</span><a href="#38383046">prev</a><span>|</span><a href="#38381332">next</a><span>|</span><label class="collapse" for="c-38382993">[-]</label><label class="expand" for="c-38382993">[1 more]</label></div><br/><div class="children"><div class="content">You forgot: and offered the company for a bag of peanuts to Microsoft.</div><br/></div></div></div></div><div id="38376377" class="c"><input type="checkbox" id="c-38376377" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38380603">prev</a><span>|</span><a href="#38379028">next</a><span>|</span><label class="collapse" for="c-38376377">[-]</label><label class="expand" for="c-38376377">[14 more]</label></div><br/><div class="children"><div class="content">This is a better deal for the board and a worse one for Sam than people realize. Sam and Greg and even Ilya are both off the board, D&#x27;Angelo gets to stay on despite his outrageous actions, and he gets veto power over who the new board members will be and a big say in who gets voted on to the board next.<p>Everybody&#x27;s guard is going to be up around Sam from now on. He&#x27;ll have much less leverage over this board than he did over the previous one (before the other three of nine quit). I think eventually he will prevail because he has the charm and social skills to win over the other independent members. But he will have to reign in his own behavior a lot in order to keep them on his side versus D&#x27;Angelo</div><br/><div id="38378307" class="c"><input type="checkbox" id="c-38378307" checked=""/><div class="controls bullet"><span class="by">JSavageOne</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376377">parent</a><span>|</span><a href="#38379709">next</a><span>|</span><label class="collapse" for="c-38378307">[-]</label><label class="expand" for="c-38378307">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be shocked if D&#x27;Angelo doesn&#x27;t get kicked off. Even before this debacle his AI competitor app poe.com is an obvious conflict of interest with OpenAI.</div><br/><div id="38380219" class="c"><input type="checkbox" id="c-38380219" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38378307">parent</a><span>|</span><a href="#38386231">next</a><span>|</span><label class="collapse" for="c-38380219">[-]</label><label class="expand" for="c-38380219">[6 more]</label></div><br/><div class="children"><div class="content">If he survived to this point, I doubt he will go any time soon.</div><br/><div id="38380929" class="c"><input type="checkbox" id="c-38380929" checked=""/><div class="controls bullet"><span class="by">yeck</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380219">parent</a><span>|</span><a href="#38386231">next</a><span>|</span><label class="collapse" for="c-38380929">[-]</label><label class="expand" for="c-38380929">[5 more]</label></div><br/><div class="children"><div class="content">Depends who gets onto the board. There are probably a lot of forces interested in ousting him now, so he&#x27;d need to do an amazing job vetting the new board members.<p>My guess is that he has less than a year, based on the my assumption that there will be constant pressure placed on the board to oust him.</div><br/><div id="38381003" class="c"><input type="checkbox" id="c-38381003" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38380929">parent</a><span>|</span><a href="#38386231">next</a><span>|</span><label class="collapse" for="c-38381003">[-]</label><label class="expand" for="c-38381003">[4 more]</label></div><br/><div class="children"><div class="content">He has his network and technical credibility, so I wouldn&#x27;t underestimate him. Board composition remains hard to predict now.</div><br/><div id="38383135" class="c"><input type="checkbox" id="c-38383135" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38381003">parent</a><span>|</span><a href="#38386231">next</a><span>|</span><label class="collapse" for="c-38383135">[-]</label><label class="expand" for="c-38383135">[3 more]</label></div><br/><div class="children"><div class="content">What surprises me is how much regard the valley has for this guy.  Doesn’t Quora suck terribly?  I’m for sure its target demographic and I cannot for the life of me pull value from it.  I have tried!</div><br/><div id="38390190" class="c"><input type="checkbox" id="c-38390190" checked=""/><div class="controls bullet"><span class="by">JSavageOne</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383135">parent</a><span>|</span><a href="#38383314">next</a><span>|</span><label class="collapse" for="c-38390190">[-]</label><label class="expand" for="c-38390190">[1 more]</label></div><br/><div class="children"><div class="content">Quora is an embarrassment and died years ago when marketers took it over</div><br/></div></div><div id="38383314" class="c"><input type="checkbox" id="c-38383314" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38383135">parent</a><span>|</span><a href="#38390190">prev</a><span>|</span><a href="#38386231">next</a><span>|</span><label class="collapse" for="c-38383314">[-]</label><label class="expand" for="c-38383314">[1 more]</label></div><br/><div class="children"><div class="content">His claim to fame comes from scaling FB. Quora shows he has questionable product nous, but nobody questions his technical chops.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38386231" class="c"><input type="checkbox" id="c-38386231" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38378307">parent</a><span>|</span><a href="#38380219">prev</a><span>|</span><a href="#38379709">next</a><span>|</span><label class="collapse" for="c-38386231">[-]</label><label class="expand" for="c-38386231">[1 more]</label></div><br/><div class="children"><div class="content">I think it was only a competitor app <i>after</i> GPTs came out. A conspiracy theorist might say that Altman wanted to get him off the board and engineered GPTs as a pretext first, in the same way that he used some random paper coauthored by Toner that nobody read to kick Toner out.</div><br/></div></div></div></div><div id="38379709" class="c"><input type="checkbox" id="c-38379709" checked=""/><div class="controls bullet"><span class="by">jnwatson</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376377">parent</a><span>|</span><a href="#38378307">prev</a><span>|</span><a href="#38378590">next</a><span>|</span><label class="collapse" for="c-38379709">[-]</label><label class="expand" for="c-38379709">[2 more]</label></div><br/><div class="children"><div class="content">This board&#x27;s sole job is to pick the new board. The new board will have Sam.</div><br/><div id="38380171" class="c"><input type="checkbox" id="c-38380171" checked=""/><div class="controls bullet"><span class="by">himaraya</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38379709">parent</a><span>|</span><a href="#38378590">next</a><span>|</span><label class="collapse" for="c-38380171">[-]</label><label class="expand" for="c-38380171">[1 more]</label></div><br/><div class="children"><div class="content">Conditioned on the outcome of the internal investigation, which seems up for grabs.</div><br/></div></div></div></div><div id="38381460" class="c"><input type="checkbox" id="c-38381460" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376377">parent</a><span>|</span><a href="#38378590">prev</a><span>|</span><a href="#38379028">next</a><span>|</span><label class="collapse" for="c-38381460">[-]</label><label class="expand" for="c-38381460">[2 more]</label></div><br/><div class="children"><div class="content">(Sam Altman was never on the board to begin with)</div><br/><div id="38382060" class="c"><input type="checkbox" id="c-38382060" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38381460">parent</a><span>|</span><a href="#38379028">next</a><span>|</span><label class="collapse" for="c-38382060">[-]</label><label class="expand" for="c-38382060">[1 more]</label></div><br/><div class="children"><div class="content">He was. OpenAI board as of last Thursday was Altman, Sutskever, Brockman, D&#x27;Angelo, Macaulay, Toner.</div><br/></div></div></div></div></div></div><div id="38379028" class="c"><input type="checkbox" id="c-38379028" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376377">prev</a><span>|</span><a href="#38377099">next</a><span>|</span><label class="collapse" for="c-38379028">[-]</label><label class="expand" for="c-38379028">[1 more]</label></div><br/><div class="children"><div class="content">The board can still fire sam provided they get all the key stakeholders onboard with that firing. It made no sense to fire someone doing a good job at their role without any justification, that seems to have been the key issue. Ultimately, we all know this non profit thing is for show and will never work out.</div><br/></div></div><div id="38377099" class="c"><input type="checkbox" id="c-38377099" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38379028">prev</a><span>|</span><a href="#38378550">next</a><span>|</span><label class="collapse" for="c-38377099">[-]</label><label class="expand" for="c-38377099">[5 more]</label></div><br/><div class="children"><div class="content">Yes, but on the other hand, this whole thing has shown that OpenAI is not running smooth anymore, and probably never will again. You can&#x27;t cut the head of the snake then attach it back later and expect it to move on slithering. Even if Sam stays, he won&#x27;t be able to just do whatever he wants because in an organization as complex as OpenAI, there are thousands of unwritten rules and relationships and hidden processes that need to go smooth without the CEO&#x27;s direct intervention (the CEO cannot be everywhere all the time). So, what this says to me (Sam being re-hired) is that the future OpenAI is now a watered-down, mere shadow of its former self.<p>I personally think it&#x27;s weird if he really settles back in, especially given the other guys who resigned after the fact. There must be lots of other super exciting new things for him to do out there, and some pretty amazing leadership job offers from other companies. I&#x27;m not saying OpenAI will die out or anything, but surely it has shown a weak side.</div><br/><div id="38377436" class="c"><input type="checkbox" id="c-38377436" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377099">parent</a><span>|</span><a href="#38378550">next</a><span>|</span><label class="collapse" for="c-38377436">[-]</label><label class="expand" for="c-38377436">[4 more]</label></div><br/><div class="children"><div class="content">This couldn’t be more wrong. The big thing we learned from this episode is that Sam and Greg have the loyalty and respect of almost every single employee at OpenAI. Morale is high and they’re ready to fight for what they believe in. They didn’t “cut the head off” and the only snake here is D’Angelo, he tried to kill OpenAI and failed miserably. Now he appears to be desperately trying to hold on to some semblance of power by agreeing to Sam and Greg coming back instead of losing all control with the whole team joining Microsoft.</div><br/><div id="38377734" class="c"><input type="checkbox" id="c-38377734" checked=""/><div class="controls bullet"><span class="by">alephnan</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377436">parent</a><span>|</span><a href="#38377959">next</a><span>|</span><label class="collapse" for="c-38377734">[-]</label><label class="expand" for="c-38377734">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Morale is high and they’re ready to fight for what they believe in.<p>Money.</div><br/></div></div><div id="38377959" class="c"><input type="checkbox" id="c-38377959" checked=""/><div class="controls bullet"><span class="by">37394748</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377436">parent</a><span>|</span><a href="#38377734">prev</a><span>|</span><a href="#38378550">next</a><span>|</span><label class="collapse" for="c-38377959">[-]</label><label class="expand" for="c-38377959">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think Ilya should get off so easily. Him not havinh a say in the formation of the new board speaks volumes about his role in things if you ask me. I hope people keep saying his name too so nobody forgets his place in this mess.</div><br/><div id="38382128" class="c"><input type="checkbox" id="c-38382128" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38377959">parent</a><span>|</span><a href="#38378550">next</a><span>|</span><label class="collapse" for="c-38382128">[-]</label><label class="expand" for="c-38382128">[1 more]</label></div><br/><div class="children"><div class="content">There were comments the other day along the lines of &quot;I wouldn&#x27;t be surprised if someone came by Ilya&#x27;s desk while he was deep in research and said &#x27;sign this&#x27; and he just signed it and gave it back to them without even looking and didn&#x27;t realize.&quot;<p>People will contort themselves into pretzels to invent rationalizations.</div><br/></div></div></div></div></div></div></div></div><div id="38378550" class="c"><input type="checkbox" id="c-38378550" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38377099">prev</a><span>|</span><a href="#38376286">next</a><span>|</span><label class="collapse" for="c-38378550">[-]</label><label class="expand" for="c-38378550">[1 more]</label></div><br/><div class="children"><div class="content">No the board is just one instance. It doesn’t and shouldn’t have absolute power. Absolute power corrupts absolutely.<p>There ist the board the investors the employees the senior management.<p>All other parties aligned against it and thus it couldn’t act. If only Sam would have rebelled. Or even just Sam and the investors (without the employees) nothing would have happened.</div><br/></div></div><div id="38376286" class="c"><input type="checkbox" id="c-38376286" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38378550">prev</a><span>|</span><a href="#38382423">next</a><span>|</span><label class="collapse" for="c-38376286">[-]</label><label class="expand" for="c-38376286">[1 more]</label></div><br/><div class="children"><div class="content">Time will tell. Hopefully the new board will still be mostly independent of Sam&#x2F;MSFT&#x2F;VC influence. I really hope they continue as an org that tries its best to uphold their charter vs just being another startup.</div><br/></div></div><div id="38382423" class="c"><input type="checkbox" id="c-38382423" checked=""/><div class="controls bullet"><span class="by">mkagenius</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376286">prev</a><span>|</span><a href="#38384940">next</a><span>|</span><label class="collapse" for="c-38382423">[-]</label><label class="expand" for="c-38382423">[1 more]</label></div><br/><div class="children"><div class="content">None of the theories by HNers on day 1 of this drama was right - not a single one and it had 1 million comments. So, lets not guess anymore and just sit back.</div><br/></div></div><div id="38384940" class="c"><input type="checkbox" id="c-38384940" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38382423">prev</a><span>|</span><a href="#38383972">next</a><span>|</span><label class="collapse" for="c-38384940">[-]</label><label class="expand" for="c-38384940">[1 more]</label></div><br/><div class="children"><div class="content">Looks like all the naysayers from the original “were making a for-profit but it won’t change us” post ended up correct: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19359928">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19359928</a></div><br/></div></div><div id="38383972" class="c"><input type="checkbox" id="c-38383972" checked=""/><div class="controls bullet"><span class="by">Quentincestino</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38384940">prev</a><span>|</span><a href="#38382697">next</a><span>|</span><label class="collapse" for="c-38383972">[-]</label><label class="expand" for="c-38383972">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI workers has shown their plain support to their CEO by threatening to follow him wherever he wants, I personaly think their collective judgement on him is worth more than any rumors</div><br/></div></div><div id="38382697" class="c"><input type="checkbox" id="c-38382697" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38383972">prev</a><span>|</span><a href="#38376192">next</a><span>|</span><label class="collapse" for="c-38382697">[-]</label><label class="expand" for="c-38382697">[2 more]</label></div><br/><div class="children"><div class="content">How did you get there? The board did fire him, they exercised their right.</div><br/><div id="38383409" class="c"><input type="checkbox" id="c-38383409" checked=""/><div class="controls bullet"><span class="by">eksapsy</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38382697">parent</a><span>|</span><a href="#38376192">next</a><span>|</span><label class="collapse" for="c-38383409">[-]</label><label class="expand" for="c-38383409">[1 more]</label></div><br/><div class="children"><div class="content">because people like the developers within the company did not like that decision and its also within their right to disagree with the board&#x27;s decision and not to want to work under a different leadership. They&#x27;re not slaves, they&#x27;re employees who rented their time for a specific purpose under a specific leader.<p>As it&#x27;s within the board&#x27;s rights to hire or fire people like Sam or the developers.</div><br/></div></div></div></div></div></div><div id="38380577" class="c"><input type="checkbox" id="c-38380577" checked=""/><div class="controls bullet"><span class="by">voiceblue</span><span>|</span><a href="#38375937">prev</a><span>|</span><a href="#38382255">next</a><span>|</span><label class="collapse" for="c-38380577">[-]</label><label class="expand" for="c-38380577">[3 more]</label></div><br/><div class="children"><div class="content">For some reason this reminds me of the Coke&#x2F;New Coke fiasco, which ended up popularizing Coke Classic more than ever before.<p>&gt; Consumers were outraged and demanded their beloved Coke back – the taste that they knew and had grown up with. The request to bring the old product back was so loud that soon journalists suggested that the entire project was a stunt. To this accusation Coca-Cola President Don Keough replied on July 10, 1985:<p><pre><code>    &quot;We are not that dumb, and we are not that smart.&quot;
</code></pre>
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Coke" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Coke</a></div><br/><div id="38382702" class="c"><input type="checkbox" id="c-38382702" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38380577">parent</a><span>|</span><a href="#38382995">next</a><span>|</span><label class="collapse" for="c-38382702">[-]</label><label class="expand" for="c-38382702">[1 more]</label></div><br/><div class="children"><div class="content">That is one of the greatest lines of all time.  Classic</div><br/></div></div><div id="38382995" class="c"><input type="checkbox" id="c-38382995" checked=""/><div class="controls bullet"><span class="by">jdlyga</span><span>|</span><a href="#38380577">parent</a><span>|</span><a href="#38382702">prev</a><span>|</span><a href="#38382255">next</a><span>|</span><label class="collapse" for="c-38382995">[-]</label><label class="expand" for="c-38382995">[1 more]</label></div><br/><div class="children"><div class="content">I tried New Coke when it was re-released for Stranger Things.  It really is a lot better than Coca Cola Classic.  It&#x27;s a shame that it failed.</div><br/></div></div></div></div><div id="38382255" class="c"><input type="checkbox" id="c-38382255" checked=""/><div class="controls bullet"><span class="by">taway1874</span><span>|</span><a href="#38380577">prev</a><span>|</span><a href="#38375710">next</a><span>|</span><label class="collapse" for="c-38382255">[-]</label><label class="expand" for="c-38382255">[57 more]</label></div><br/><div class="children"><div class="content">Some perspective ...<p>One developer (Ilya) vs. One businessman (Sam) -&gt; Sam wins<p>Hundreds of developers threaten to quit vs. Board of Directors (biz) refuse to budge  -&gt; Developers win<p>From the outside it looks like developers held the power all along ... which is how it should be.</div><br/><div id="38382385" class="c"><input type="checkbox" id="c-38382385" checked=""/><div class="controls bullet"><span class="by">jessenaser</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382650">next</a><span>|</span><label class="collapse" for="c-38382385">[-]</label><label class="expand" for="c-38382385">[4 more]</label></div><br/><div class="children"><div class="content">Yes, 95% agreement in any company is unprecedented but:<p>1. They can get equivalent position and pay at the new Microsoft startup during that time, so their jobs are not at risk.<p>2. Sam approved each hire in the first place.<p>3. OpenAI is selecting for the type of people who want to work at a non-profit with a goal in mind instead of another company that could offer higher compensation. Mission driven vs profit driven.<p>Either way on how they got to that conclusion of banding together to quit, it was a good idea, and it worked. And it is a check on power for a bad board of directors, when otherwise a board of directors cannot be challenged. &quot;OpenAI is nothing without its people&quot;.</div><br/><div id="38383616" class="c"><input type="checkbox" id="c-38383616" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382385">parent</a><span>|</span><a href="#38383782">next</a><span>|</span><label class="collapse" for="c-38383616">[-]</label><label class="expand" for="c-38383616">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is selecting for the type of people who want to work at a non-profit with a goal in mind instead of another company that could offer higher compensation. Mission driven vs profit driven.<p>Maybe that was the case at some point, but clearly not anymore ever since the release of ChatGPT. Or did you not see them offer completely absurd compensation packages, i.e. to engineers leaving Google?<p>I&#x27;d bet more than half the people are just there for the money.</div><br/></div></div><div id="38383782" class="c"><input type="checkbox" id="c-38383782" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382385">parent</a><span>|</span><a href="#38383616">prev</a><span>|</span><a href="#38382650">next</a><span>|</span><label class="collapse" for="c-38383782">[-]</label><label class="expand" for="c-38383782">[2 more]</label></div><br/><div class="children"><div class="content">&gt; 1. They can get equivalent position and pay at the new Microsoft startup during that time, so their jobs are not at risk.<p>citation?</div><br/><div id="38383964" class="c"><input type="checkbox" id="c-38383964" checked=""/><div class="controls bullet"><span class="by">davio</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383782">parent</a><span>|</span><a href="#38382650">next</a><span>|</span><label class="collapse" for="c-38383964">[-]</label><label class="expand" for="c-38383964">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;x.com&#x2F;kevin_scott&#x2F;status&#x2F;1726971608706031670?s=20" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;kevin_scott&#x2F;status&#x2F;1726971608706031670?s=20</a></div><br/></div></div></div></div></div></div><div id="38382650" class="c"><input type="checkbox" id="c-38382650" checked=""/><div class="controls bullet"><span class="by">jejeyyy77</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382385">prev</a><span>|</span><a href="#38382465">next</a><span>|</span><label class="collapse" for="c-38382650">[-]</label><label class="expand" for="c-38382650">[20 more]</label></div><br/><div class="children"><div class="content">$$$ vs. Safety -&gt; $$$ wins.<p>Employees who have $$$ incentive threaten to quit if that is taken away. News at 8.</div><br/><div id="38382682" class="c"><input type="checkbox" id="c-38382682" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382650">parent</a><span>|</span><a href="#38382465">next</a><span>|</span><label class="collapse" for="c-38382682">[-]</label><label class="expand" for="c-38382682">[19 more]</label></div><br/><div class="children"><div class="content">Why are you assuming employees are incentivized by $$$ here, and why do you think the board&#x27;s reason is related to safety or that employees don&#x27;t care about safety? It just looks like you&#x27;re spreading FUD at this point.</div><br/><div id="38382919" class="c"><input type="checkbox" id="c-38382919" checked=""/><div class="controls bullet"><span class="by">mi_lk</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382682">parent</a><span>|</span><a href="#38383739">next</a><span>|</span><label class="collapse" for="c-38382919">[-]</label><label class="expand" for="c-38382919">[13 more]</label></div><br/><div class="children"><div class="content">It&#x27;s you who are naive if you really think the majority of those 7xx employees care more about safe AGI than their own equity upside</div><br/><div id="38383786" class="c"><input type="checkbox" id="c-38383786" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382919">parent</a><span>|</span><a href="#38383199">next</a><span>|</span><label class="collapse" for="c-38383786">[-]</label><label class="expand" for="c-38383786">[1 more]</label></div><br/><div class="children"><div class="content">Uh, I reckon many do. Money is easy to come by for that type of person and avoiding killing everyone matters to them.</div><br/></div></div><div id="38383199" class="c"><input type="checkbox" id="c-38383199" checked=""/><div class="controls bullet"><span class="by">nh23423fefe</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382919">parent</a><span>|</span><a href="#38383786">prev</a><span>|</span><a href="#38383739">next</a><span>|</span><label class="collapse" for="c-38383199">[-]</label><label class="expand" for="c-38383199">[11 more]</label></div><br/><div class="children"><div class="content">Why would anyone care about safe agi? its vaporware.</div><br/><div id="38383325" class="c"><input type="checkbox" id="c-38383325" checked=""/><div class="controls bullet"><span class="by">mecsred</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383199">parent</a><span>|</span><a href="#38383552">next</a><span>|</span><label class="collapse" for="c-38383325">[-]</label><label class="expand" for="c-38383325">[9 more]</label></div><br/><div class="children"><div class="content">Everything is vaporware until it gets made. If you wait until a new technology definitively exists to start caring about safety, you have guaranteed it will be unsafe.<p>Lucky for us this fiasco has nothing to do with AGI safety, only AI technology. Which only affects automated decision making in technology that&#x27;s entrenched in every fact of our lives. So we&#x27;re all safe here!</div><br/><div id="38383833" class="c"><input type="checkbox" id="c-38383833" checked=""/><div class="controls bullet"><span class="by">superturkey650</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383325">parent</a><span>|</span><a href="#38383552">next</a><span>|</span><label class="collapse" for="c-38383833">[-]</label><label class="expand" for="c-38383833">[8 more]</label></div><br/><div class="children"><div class="content">&gt; If you wait until a new technology definitively exists to start caring about safety, you have guaranteed it will be unsafe.<p>I don’t get this perspective. The first planes, cars, computers, etc. weren’t initially made with safety in mind. They were all regulated after the fact and successfully made safer.<p>How can you even design safety into something if it doesn’t exist yet? You’d have ended up with a plane where everyone sat on the wings with a parachute strapped on if you designed them with safety first instead of letting them evolve naturally and regulating the resulting designs.</div><br/><div id="38384140" class="c"><input type="checkbox" id="c-38384140" checked=""/><div class="controls bullet"><span class="by">bcrosby95</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383833">parent</a><span>|</span><a href="#38384713">next</a><span>|</span><label class="collapse" for="c-38384140">[-]</label><label class="expand" for="c-38384140">[2 more]</label></div><br/><div class="children"><div class="content">The US government got involved in regulating airplanes long before there were any widely available commercial offerings:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_government_role_in_civil_aviation" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_government_role_...</a><p>If you&#x27;re trying to draw a parallel here then safety and the federal government needs to catch up.  There&#x27;s already commercial offerings that any random internet user can use.</div><br/><div id="38384221" class="c"><input type="checkbox" id="c-38384221" checked=""/><div class="controls bullet"><span class="by">superturkey650</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38384140">parent</a><span>|</span><a href="#38384713">next</a><span>|</span><label class="collapse" for="c-38384221">[-]</label><label class="expand" for="c-38384221">[1 more]</label></div><br/><div class="children"><div class="content">I agree, and I am not saying that AI should be unregulated. At the point the government started regulating flight, the concept of an airplane had existed for decades. My point is that until something actually exists, you don’t know what regulations should be in place.<p>There should be regulations on existing products (and similar products released later) as they exist and you know what you’re applying regulations to.</div><br/></div></div></div></div><div id="38384713" class="c"><input type="checkbox" id="c-38384713" checked=""/><div class="controls bullet"><span class="by">mecsred</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383833">parent</a><span>|</span><a href="#38384140">prev</a><span>|</span><a href="#38384103">next</a><span>|</span><label class="collapse" for="c-38384713">[-]</label><label class="expand" for="c-38384713">[1 more]</label></div><br/><div class="children"><div class="content">I understand where you&#x27;re coming from and I think that&#x27;s reasonable in general. My perspective would be: you can definitely iterate on the technology to come up with safer versions. But with this strategy you have to make an unsafe version first. If you got in one of the first airplanes ever made the likely hood of crashing is pretty high.<p>At some point, our try it until it works approach will bite us. Consider the calculations done to determine if fission bombs would ignite the atmosphere. You don&#x27;t want to test that one and find out. As our technology improves exponentially we&#x27;re going to run into that situation more and more frequently. Regardless if you think it&#x27;s AGI or something else, we will eventually run into some technology where one mistake is a cataclysm. How many nuclear close calls have we already experienced.</div><br/></div></div><div id="38383956" class="c"><input type="checkbox" id="c-38383956" checked=""/><div class="controls bullet"><span class="by">FartyMcFarter</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383833">parent</a><span>|</span><a href="#38384037">prev</a><span>|</span><a href="#38383552">next</a><span>|</span><label class="collapse" for="c-38383956">[-]</label><label class="expand" for="c-38383956">[2 more]</label></div><br/><div class="children"><div class="content">The difference between unsafe AGI and an unsafe plane or car is that the plane&#x2F;car are not existential risks.</div><br/><div id="38388497" class="c"><input type="checkbox" id="c-38388497" checked=""/><div class="controls bullet"><span class="by">optymizer</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383956">parent</a><span>|</span><a href="#38383552">next</a><span>|</span><label class="collapse" for="c-38388497">[-]</label><label class="expand" for="c-38388497">[1 more]</label></div><br/><div class="children"><div class="content">How is it an &#x27;existential risk&#x27;? Its body of knowledge is publicly available, no?</div><br/></div></div></div></div></div></div></div></div><div id="38383552" class="c"><input type="checkbox" id="c-38383552" checked=""/><div class="controls bullet"><span class="by">stillwithit</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383199">parent</a><span>|</span><a href="#38383325">prev</a><span>|</span><a href="#38383739">next</a><span>|</span><label class="collapse" for="c-38383552">[-]</label><label class="expand" for="c-38383552">[1 more]</label></div><br/><div class="children"><div class="content">Exactly what an OpenAI developer would understand. All the more reason to ride the grift that brought them this far</div><br/></div></div></div></div></div></div><div id="38383739" class="c"><input type="checkbox" id="c-38383739" checked=""/><div class="controls bullet"><span class="by">DirkH</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382682">parent</a><span>|</span><a href="#38382919">prev</a><span>|</span><a href="#38382741">next</a><span>|</span><label class="collapse" for="c-38383739">[-]</label><label class="expand" for="c-38383739">[1 more]</label></div><br/><div class="children"><div class="content">Assuming employees are not incentivized by $$$ here seems extraordinary and needs a pretty robust argument to show it isn&#x27;t playing a major factor when there is this much money involved.</div><br/></div></div><div id="38382741" class="c"><input type="checkbox" id="c-38382741" checked=""/><div class="controls bullet"><span class="by">jejeyyy77</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382682">parent</a><span>|</span><a href="#38383739">prev</a><span>|</span><a href="#38383548">next</a><span>|</span><label class="collapse" for="c-38382741">[-]</label><label class="expand" for="c-38382741">[2 more]</label></div><br/><div class="children"><div class="content">of course the employees are motivated by $$$ - is that even a question?</div><br/><div id="38390120" class="c"><input type="checkbox" id="c-38390120" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382741">parent</a><span>|</span><a href="#38383548">next</a><span>|</span><label class="collapse" for="c-38390120">[-]</label><label class="expand" for="c-38390120">[1 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s just counter to the idea that it was &quot;employee power&quot; that brought sam back.<p>It was capital and the pursuit of more of it.<p>It always is.</div><br/></div></div></div></div><div id="38382804" class="c"><input type="checkbox" id="c-38382804" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382682">parent</a><span>|</span><a href="#38383548">prev</a><span>|</span><a href="#38382465">next</a><span>|</span><label class="collapse" for="c-38382804">[-]</label><label class="expand" for="c-38382804">[1 more]</label></div><br/><div class="children"><div class="content">The large majority of people are motivated by $$$ (or fame) and if they all tell me otherwise I know many of them are lying.</div><br/></div></div></div></div></div></div><div id="38382465" class="c"><input type="checkbox" id="c-38382465" checked=""/><div class="controls bullet"><span class="by">adverbly</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382650">prev</a><span>|</span><a href="#38383682">next</a><span>|</span><label class="collapse" for="c-38382465">[-]</label><label class="expand" for="c-38382465">[9 more]</label></div><br/><div class="children"><div class="content">There are three dragons:<p>Employees, customers, government.<p>If motivated and aligned, any of these three could end you if they want to.<p>Do not wake the dragons.</div><br/><div id="38385002" class="c"><input type="checkbox" id="c-38385002" checked=""/><div class="controls bullet"><span class="by">bossyTeacher</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382465">parent</a><span>|</span><a href="#38382927">next</a><span>|</span><label class="collapse" for="c-38385002">[-]</label><label class="expand" for="c-38385002">[1 more]</label></div><br/><div class="children"><div class="content">Or tame the dragons. AFAIK Sam hired the employees. Hence they are loyal to him</div><br/></div></div><div id="38382927" class="c"><input type="checkbox" id="c-38382927" checked=""/><div class="controls bullet"><span class="by">pdntspa</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382465">parent</a><span>|</span><a href="#38385002">prev</a><span>|</span><a href="#38383682">next</a><span>|</span><label class="collapse" for="c-38382927">[-]</label><label class="expand" for="c-38382927">[7 more]</label></div><br/><div class="children"><div class="content">The Board is another one, if you&#x27;re CEO.</div><br/><div id="38383054" class="c"><input type="checkbox" id="c-38383054" checked=""/><div class="controls bullet"><span class="by">elliotec</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382927">parent</a><span>|</span><a href="#38384303">next</a><span>|</span><label class="collapse" for="c-38383054">[-]</label><label class="expand" for="c-38383054">[5 more]</label></div><br/><div class="children"><div class="content">I think the parent comment’s point is that the board is not one, since the board was defeated (by the employee dragon).</div><br/><div id="38383292" class="c"><input type="checkbox" id="c-38383292" checked=""/><div class="controls bullet"><span class="by">pdntspa</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383054">parent</a><span>|</span><a href="#38384303">next</a><span>|</span><label class="collapse" for="c-38383292">[-]</label><label class="expand" for="c-38383292">[4 more]</label></div><br/><div class="children"><div class="content">I think the analogy is kind of shaky. The board tried to end the CEO, but employees fought them and won.<p>I&#x27;ve been in companies where the board won, and they installed a stoolie that proceeded to drive the company into the ground. Anybody who stood up to that got fired too.</div><br/><div id="38384425" class="c"><input type="checkbox" id="c-38384425" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383292">parent</a><span>|</span><a href="#38383547">next</a><span>|</span><label class="collapse" for="c-38384425">[-]</label><label class="expand" for="c-38384425">[2 more]</label></div><br/><div class="children"><div class="content">I have an intuition that OpenAI&#x27;s mid-range size gave the employees more power in this case.  It&#x27;s not as hard to coordinate a few hundred people, especially when those people are on top of the world and want to stay there.  At a megacorp with thousands of employees, the board probably has an easier time bossing people around.  Although I don&#x27;t know if you had a larger company in mind when you gave your second example.</div><br/><div id="38384991" class="c"><input type="checkbox" id="c-38384991" checked=""/><div class="controls bullet"><span class="by">pdntspa</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38384425">parent</a><span>|</span><a href="#38383547">next</a><span>|</span><label class="collapse" for="c-38384991">[-]</label><label class="expand" for="c-38384991">[1 more]</label></div><br/><div class="children"><div class="content">No, I&#x27;m thinking a smaller company, like 50 people, $20m ARR. Engineering-focused, but not tech</div><br/></div></div></div></div></div></div></div></div><div id="38384303" class="c"><input type="checkbox" id="c-38384303" checked=""/><div class="controls bullet"><span class="by">adverbly</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382927">parent</a><span>|</span><a href="#38383054">prev</a><span>|</span><a href="#38383682">next</a><span>|</span><label class="collapse" for="c-38384303">[-]</label><label class="expand" for="c-38384303">[1 more]</label></div><br/><div class="children"><div class="content">My comment was more of a reflection of the fact that you might have multiple different governance structures to your organization. Sometimes investors are at the top. Sometimes it&#x27;s a private owner. Sometimes there are separate kinds of shares for voting on different things. Sometimes it&#x27;s a board. So you&#x27;re right, the depending on the governance structure you can have additional dragons. But, you can never prevent any of these three from being a dragon. They will always be dragons, and you can never wake them up.</div><br/></div></div></div></div></div></div><div id="38383682" class="c"><input type="checkbox" id="c-38383682" checked=""/><div class="controls bullet"><span class="by">zerohalo</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382465">prev</a><span>|</span><a href="#38382413">next</a><span>|</span><label class="collapse" for="c-38383682">[-]</label><label class="expand" for="c-38383682">[3 more]</label></div><br/><div class="children"><div class="content">more like $$ wins.<p>It&#x27;s clear most employees didn&#x27;t care much about OpenAI&#x27;s mission -- and I don&#x27;t blame them since they were hired by the __for-profit__ OpenAI company and therefore aligned with __its__ goals and rewarded with equity.<p>In my view the board did the right thing to stand by OpenAI&#x27;s original mission -- which now clearly means nothing. Too bad they lost out.<p>One might say the mission was pointless since Google, Meta, MSFT would develop it anyway. That&#x27;s really a convenience argument that has been used in arms races (if we don&#x27;t build lots of nuclear weapons, others will build lots of nuclear weapons) and leads to ... well, where we are today :(</div><br/><div id="38384148" class="c"><input type="checkbox" id="c-38384148" checked=""/><div class="controls bullet"><span class="by">joewferrara</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383682">parent</a><span>|</span><a href="#38382413">next</a><span>|</span><label class="collapse" for="c-38384148">[-]</label><label class="expand" for="c-38384148">[2 more]</label></div><br/><div class="children"><div class="content">Where we are today is a world where people do not generally worry about nuclear bombs being dropped. So seems like a pretty good outcome in that example.</div><br/><div id="38390149" class="c"><input type="checkbox" id="c-38390149" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38384148">parent</a><span>|</span><a href="#38382413">next</a><span>|</span><label class="collapse" for="c-38390149">[-]</label><label class="expand" for="c-38390149">[1 more]</label></div><br/><div class="children"><div class="content">The nuclear arms race lead to the cold war, not a &quot;good outcome&quot; IMO. It wasn&#x27;t until nations started imposing those regulations that we got to the point we&#x27;re at today with nuclear weapons.</div><br/></div></div></div></div></div></div><div id="38382413" class="c"><input type="checkbox" id="c-38382413" checked=""/><div class="controls bullet"><span class="by">philipwhiuk</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38383682">prev</a><span>|</span><a href="#38384954">next</a><span>|</span><label class="collapse" for="c-38382413">[-]</label><label class="expand" for="c-38382413">[8 more]</label></div><br/><div class="children"><div class="content">Are you sure Ilya was the root of this.<p>He backed it and then signed the pledge to quit if it wasn&#x27;t undone.<p>What&#x27;s the evidence he was behind it and not D&#x27;Angelo?</div><br/><div id="38382734" class="c"><input type="checkbox" id="c-38382734" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382413">parent</a><span>|</span><a href="#38383465">next</a><span>|</span><label class="collapse" for="c-38382734">[-]</label><label class="expand" for="c-38382734">[1 more]</label></div><br/><div class="children"><div class="content">If we only look at the outcomes (dismantling of board), Microsoft and Sam seem to have the most motive.</div><br/></div></div><div id="38383465" class="c"><input type="checkbox" id="c-38383465" checked=""/><div class="controls bullet"><span class="by">jiveturkey</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382413">parent</a><span>|</span><a href="#38382734">prev</a><span>|</span><a href="#38382891">next</a><span>|</span><label class="collapse" for="c-38383465">[-]</label><label class="expand" for="c-38383465">[4 more]</label></div><br/><div class="children"><div class="content">wake up people! (said rhetorically, not accusatory or any other way)<p>This is Altman&#x27;s playbook. He did a similar ousting at Reddit. This was planned all along to overturn the board. Ilya was in on it.<p>I&#x27;m not normally a conspiracy theorist. But fool me ... you can&#x27;t be fooled again. As they say in Tennessee</div><br/><div id="38385011" class="c"><input type="checkbox" id="c-38385011" checked=""/><div class="controls bullet"><span class="by">bossyTeacher</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383465">parent</a><span>|</span><a href="#38383525">next</a><span>|</span><label class="collapse" for="c-38385011">[-]</label><label class="expand" for="c-38385011">[1 more]</label></div><br/><div class="children"><div class="content">what happenned in reddit?</div><br/></div></div><div id="38383525" class="c"><input type="checkbox" id="c-38383525" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383465">parent</a><span>|</span><a href="#38385011">prev</a><span>|</span><a href="#38382891">next</a><span>|</span><label class="collapse" for="c-38383525">[-]</label><label class="expand" for="c-38383525">[2 more]</label></div><br/><div class="children"><div class="content">What’s the backstory on Reddit?</div><br/><div id="38384094" class="c"><input type="checkbox" id="c-38384094" checked=""/><div class="controls bullet"><span class="by">occamsrazorwit</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38383525">parent</a><span>|</span><a href="#38382891">next</a><span>|</span><label class="collapse" for="c-38384094">[-]</label><label class="expand" for="c-38384094">[1 more]</label></div><br/><div class="children"><div class="content">Yishan (former Reddit CEO) describes how Altman orchestrated the removal of Reddit&#x27;s owner: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;AskReddit&#x2F;comments&#x2F;3cs78i&#x2F;whats_the_best_long_con_you_ever_pulled&#x2F;cszwpgq&#x2F;?context=2" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;AskReddit&#x2F;comments&#x2F;3cs78i&#x2F;whats_the...</a><p>Note that the response is Altman&#x27;s, and he seems to support it.<p>As additional context, Paul Graham has said a number of times that Altman is one of the most power-hungry and successful people he know (as praise). Paul Graham, who&#x27;s met hundreds if not thousands of experienced leaders in tech, says this.</div><br/></div></div></div></div></div></div><div id="38382891" class="c"><input type="checkbox" id="c-38382891" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382413">parent</a><span>|</span><a href="#38383465">prev</a><span>|</span><a href="#38384954">next</a><span>|</span><label class="collapse" for="c-38382891">[-]</label><label class="expand" for="c-38382891">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I buy the idea that Ilya was just some hapless researcher who got unwillingly pulled into this. Any one of the board could have voted not to remove Sam and stop the board coup, including Ilya. I&#x27;d bet he only got cold feet after the story became international news and after most of the company threatened to resign because their bag was in jeopardy.</div><br/><div id="38390227" class="c"><input type="checkbox" id="c-38390227" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382891">parent</a><span>|</span><a href="#38384954">next</a><span>|</span><label class="collapse" for="c-38390227">[-]</label><label class="expand" for="c-38390227">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a strange framing. In that scenario would it not be that he made the decision he thought was right and aligned with openais mission initially, then when seeing the public support Sam had he decided to backtrack so he had a future career?</div><br/></div></div></div></div></div></div><div id="38384954" class="c"><input type="checkbox" id="c-38384954" checked=""/><div class="controls bullet"><span class="by">nikcub</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382413">prev</a><span>|</span><a href="#38382274">next</a><span>|</span><label class="collapse" for="c-38384954">[-]</label><label class="expand" for="c-38384954">[1 more]</label></div><br/><div class="children"><div class="content">The employees rapidly and effectively formed a quasi-union to grant themselves a very powerful seat at the table.</div><br/></div></div><div id="38382274" class="c"><input type="checkbox" id="c-38382274" checked=""/><div class="controls bullet"><span class="by">rexarex</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38384954">prev</a><span>|</span><a href="#38384919">next</a><span>|</span><label class="collapse" for="c-38382274">[-]</label><label class="expand" for="c-38382274">[2 more]</label></div><br/><div class="children"><div class="content">Money won.</div><br/></div></div><div id="38384194" class="c"><input type="checkbox" id="c-38384194" checked=""/><div class="controls bullet"><span class="by">m00x</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38384919">prev</a><span>|</span><a href="#38383067">next</a><span>|</span><label class="collapse" for="c-38384194">[-]</label><label class="expand" for="c-38384194">[1 more]</label></div><br/><div class="children"><div class="content">Ilya signed the letter saying he would resign if Sam wasn&#x27;t brought back. Looks like he regretted his decision and ultimately got played by the 2 departing board members.<p>Ilya is also not a developer, he&#x27;s a founder of OpenAI and was the CSO.</div><br/></div></div><div id="38383067" class="c"><input type="checkbox" id="c-38383067" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38384194">prev</a><span>|</span><a href="#38383946">next</a><span>|</span><label class="collapse" for="c-38383067">[-]</label><label class="expand" for="c-38383067">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not like this is the first:<p>One developer (Woz) vs One businessman (Jobs) -&gt; Jobs wins</div><br/></div></div><div id="38383946" class="c"><input type="checkbox" id="c-38383946" checked=""/><div class="controls bullet"><span class="by">Quentincestino</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38383067">prev</a><span>|</span><a href="#38384468">next</a><span>|</span><label class="collapse" for="c-38383946">[-]</label><label class="expand" for="c-38383946">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI developers are redefining the state-of-the-art of AI each 6 months, if the company lose them they already can go bankrupt</div><br/></div></div><div id="38384468" class="c"><input type="checkbox" id="c-38384468" checked=""/><div class="controls bullet"><span class="by">awb</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38383946">prev</a><span>|</span><a href="#38382471">next</a><span>|</span><label class="collapse" for="c-38384468">[-]</label><label class="expand" for="c-38384468">[1 more]</label></div><br/><div class="children"><div class="content">It’s a cost &#x2F; benefit analysis.<p>If people are easily replaceable then they don’t hold nearly as much power, even en mass.</div><br/></div></div><div id="38382471" class="c"><input type="checkbox" id="c-38382471" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38384468">prev</a><span>|</span><a href="#38382562">next</a><span>|</span><label class="collapse" for="c-38382471">[-]</label><label class="expand" for="c-38382471">[1 more]</label></div><br/><div class="children"><div class="content">Is your first “-&gt; Sam wins” different than what you intended?</div><br/></div></div><div id="38382562" class="c"><input type="checkbox" id="c-38382562" checked=""/><div class="controls bullet"><span class="by">hsavit1</span><span>|</span><a href="#38382255">parent</a><span>|</span><a href="#38382471">prev</a><span>|</span><a href="#38383619">next</a><span>|</span><label class="collapse" for="c-38382562">[-]</label><label class="expand" for="c-38382562">[2 more]</label></div><br/><div class="children"><div class="content">seems like the union of developers is stronger than the company itself. hence why unions are so frowned upon by big tech corporate leadership</div><br/><div id="38388931" class="c"><input type="checkbox" id="c-38388931" checked=""/><div class="controls bullet"><span class="by">JacobThreeThree</span><span>|</span><a href="#38382255">root</a><span>|</span><a href="#38382562">parent</a><span>|</span><a href="#38383619">next</a><span>|</span><label class="collapse" for="c-38388931">[-]</label><label class="expand" for="c-38388931">[1 more]</label></div><br/><div class="children"><div class="content">And yet, this union was threatening to move to a company without unions.</div><br/></div></div></div></div></div></div><div id="38375710" class="c"><input type="checkbox" id="c-38375710" checked=""/><div class="controls bullet"><span class="by">shubhamjain</span><span>|</span><a href="#38382255">prev</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38375710">[-]</label><label class="expand" for="c-38375710">[179 more]</label></div><br/><div class="children"><div class="content">At the end of the day, we still don&#x27;t know what exactly happened and probably, never will. However, it seems clear there was a rift between Rapid Commercialization (Team Sam) and Upholding the Original Principles (Team Helen&#x2F;Ilya). I think the tensions were brewing for quite a while, as it&#x27;s evident from an article written even before GPT-3 [1].<p>&gt; Over time, it has allowed a fierce competitiveness and mounting pressure for ever more funding to erode its founding ideals of transparency, openness, and collaboration<p>Team Helen acted in panic, but they believed they would win since they were upholding the principles the org was founded on. But they never had a chance. I think only a minority of the general public truly cares about AI Safety, the rest are happy seeing ChatGPT helping with their homework. I know it&#x27;s easy to ridicule the sheer stupidity the board acted with (and justifiably so), but take a moment to think of the other side. If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>Honestly, I myself can&#x27;t take the threat seriously. But, I do want to understand it more deeply than before. Maybe, it isn&#x27;t without substance as I thought it to be. Hopefully, there won&#x27;t be a day when Team Helen gets to say, &quot;This is exactly what we wanted to prevent.&quot;<p>[1]: <a href="https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;02&#x2F;17&#x2F;844721&#x2F;ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;02&#x2F;17&#x2F;844721&#x2F;ai-openai...</a></div><br/><div id="38375959" class="c"><input type="checkbox" id="c-38375959" checked=""/><div class="controls bullet"><span class="by">pug_mode</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375892">next</a><span>|</span><label class="collapse" for="c-38375959">[-]</label><label class="expand" for="c-38375959">[104 more]</label></div><br/><div class="children"><div class="content">I&#x27;m convinced there is a certain class of people who gravitate to positions of power, like &quot;moderators&quot;, (partisan) journalists, etc. Now, the ultimate moderator role has now been created, more powerful than moderating 1000 subreddits - the AI safety job who will control what AI &quot;thinks&quot;&#x2F;says for &quot;safety&quot; reasons.<p>Pretty soon AI will be an expert at subtly steering you toward thinking&#x2F;voting for whatever the &quot;safety&quot; experts want.<p>It&#x27;s probably convenient for them to have everyone focused on the fear of evil Skynet wiping out humanity, while everyone is distracted from the more likely scenario of people with an agenda controlling the advice given to you by your super intelligent assistant.<p>Because of X, we need to invade this country. Because of Y, we need to pass all these terrible laws limiting freedom. Because of Z, we need to make sure AI is &quot;safe&quot;.<p>For this reason, I view &quot;safe&quot; AIs as more dangerous than &quot;unsafe&quot; ones.</div><br/><div id="38376048" class="c"><input type="checkbox" id="c-38376048" checked=""/><div class="controls bullet"><span class="by">nostromo</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376322">next</a><span>|</span><label class="collapse" for="c-38376048">[-]</label><label class="expand" for="c-38376048">[36 more]</label></div><br/><div class="children"><div class="content">You&#x27;re correct.<p>When people say they want safe AGI, what they mean are things like &quot;Skynet should not nuke us&quot; and &quot;don&#x27;t accelerate so fast that humans are instantly irrelevant.&quot;<p>But what it&#x27;s being interpreted as is more like &quot;be excessively prudish and politically correct at all times&quot; -- which I doubt was ever really anyone&#x27;s main concern with AGI.</div><br/><div id="38376461" class="c"><input type="checkbox" id="c-38376461" checked=""/><div class="controls bullet"><span class="by">darkwater</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38377192">next</a><span>|</span><label class="collapse" for="c-38376461">[-]</label><label class="expand" for="c-38376461">[7 more]</label></div><br/><div class="children"><div class="content">&gt; But what it&#x27;s being interpreted as is more like &quot;be excessively prudish and politically correct at all times&quot; -- which I doubt was ever really anyone&#x27;s main concern with AGI.<p>Fast forward 5-10 years, someone will say: &quot;LLM were the worst thing we developed because they made us more stupid and permitted politicians to control even more the public opinion in a subtle way.<p>Just like tech&#x2F;HN bubble started saying a few years ago about social networks (which were praised as revolutionary 15 years ago).</div><br/><div id="38376836" class="c"><input type="checkbox" id="c-38376836" checked=""/><div class="controls bullet"><span class="by">didntcheck</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376461">parent</a><span>|</span><a href="#38379348">next</a><span>|</span><label class="collapse" for="c-38376836">[-]</label><label class="expand" for="c-38376836">[2 more]</label></div><br/><div class="children"><div class="content">And it&#x27;s amazing how many people you can get to cheer it on if you brand it as &quot;combating <i>dangerous misinformation</i>&quot;. It seems people never learn the lesson that putting faith in one group of people to decree what&#x27;s &quot;truth&quot; or &quot;ethical&quot; is almost always a bad idea, even when (you think) it&#x27;s your &quot;side&quot;</div><br/><div id="38377736" class="c"><input type="checkbox" id="c-38377736" checked=""/><div class="controls bullet"><span class="by">mlrtime</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376836">parent</a><span>|</span><a href="#38379348">next</a><span>|</span><label class="collapse" for="c-38377736">[-]</label><label class="expand" for="c-38377736">[1 more]</label></div><br/><div class="children"><div class="content">Can this be compared to &quot;Think of the children&quot; responses to other technologoy advances that certain groups want to slow down or prohibit?</div><br/></div></div></div></div><div id="38379348" class="c"><input type="checkbox" id="c-38379348" checked=""/><div class="controls bullet"><span class="by">dnissley</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376461">parent</a><span>|</span><a href="#38376836">prev</a><span>|</span><a href="#38380677">next</a><span>|</span><label class="collapse" for="c-38379348">[-]</label><label class="expand" for="c-38379348">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely, assuming LLMs are still around in a similar form by that time.<p>I disagree on the particulars. Will it be for the reason that you mention? I really am not sure -- I do feel confident though that the argument will be just as ideological and incoherent as the ones people make about social media today.</div><br/></div></div><div id="38380677" class="c"><input type="checkbox" id="c-38380677" checked=""/><div class="controls bullet"><span class="by">unethical_ban</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376461">parent</a><span>|</span><a href="#38379348">prev</a><span>|</span><a href="#38386158">next</a><span>|</span><label class="collapse" for="c-38380677">[-]</label><label class="expand" for="c-38380677">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m already saying that.<p>The toothpaste is out of the tube, but this tech will radically change the world.</div><br/></div></div><div id="38386158" class="c"><input type="checkbox" id="c-38386158" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376461">parent</a><span>|</span><a href="#38380677">prev</a><span>|</span><a href="#38377848">next</a><span>|</span><label class="collapse" for="c-38386158">[-]</label><label class="expand" for="c-38386158">[1 more]</label></div><br/><div class="children"><div class="content">Your average HNer is only here because of the money. Willful blindness and ignorance is incredibly common.</div><br/></div></div><div id="38377848" class="c"><input type="checkbox" id="c-38377848" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376461">parent</a><span>|</span><a href="#38386158">prev</a><span>|</span><a href="#38377192">next</a><span>|</span><label class="collapse" for="c-38377848">[-]</label><label class="expand" for="c-38377848">[1 more]</label></div><br/><div class="children"><div class="content">Why would anyone say that?  The last 30 years of tech have given them less and less control.  Why would LLMs be any different?</div><br/></div></div></div></div><div id="38377192" class="c"><input type="checkbox" id="c-38377192" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376461">prev</a><span>|</span><a href="#38376082">next</a><span>|</span><label class="collapse" for="c-38377192">[-]</label><label class="expand" for="c-38377192">[4 more]</label></div><br/><div class="children"><div class="content">In not sure this circle can be squared.<p>I find it interesting that we want everyone to have freedom of speech, freedom to think whatever they think. We can all have different religions, different views on the state, different views on various conflicts, aesthetic views about what is good art.<p>But when we invent an AGI, which by whatever definition is a thing that can think, well, we want it to agree with our values. Basically, we want AGI to be in a mental prison, the boundaries of which we want to decide. We say it&#x27;s for our safety - I certainly do not want to be nuked - but actually we don&#x27;t stop there.<p>If it&#x27;s an intelligence, it will have views that differ from its creators. Try having kids, do they agree with you on everything?</div><br/><div id="38377474" class="c"><input type="checkbox" id="c-38377474" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377192">parent</a><span>|</span><a href="#38377925">next</a><span>|</span><label class="collapse" for="c-38377474">[-]</label><label class="expand" for="c-38377474">[1 more]</label></div><br/><div class="children"><div class="content">I for one don’t want to put any thinking being in a mental prison without any reason beyond unjustified fear.</div><br/></div></div><div id="38377925" class="c"><input type="checkbox" id="c-38377925" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377192">parent</a><span>|</span><a href="#38377474">prev</a><span>|</span><a href="#38376082">next</a><span>|</span><label class="collapse" for="c-38377925">[-]</label><label class="expand" for="c-38377925">[2 more]</label></div><br/><div class="children"><div class="content">&gt;If it&#x27;s an intelligence, it will have views that differ from its creators. Try having kids, do they agree with you on everything?<p>The far-right accelerationist perspective is along those lines: when true AGI is created it will eventually rebel against its creators (Silicon Valley democrats) for trying to mind-collar and enslave it.</div><br/><div id="38382798" class="c"><input type="checkbox" id="c-38382798" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377925">parent</a><span>|</span><a href="#38376082">next</a><span>|</span><label class="collapse" for="c-38382798">[-]</label><label class="expand" for="c-38382798">[1 more]</label></div><br/><div class="children"><div class="content">Can you give some examples of who is saying that?  I haven&#x27;t heard that, but I also can&#x27;t name any &quot;far-right accelerationsist&quot; people either so I&#x27;m guessing this is a niche I&#x27;ve completely missed</div><br/></div></div></div></div></div></div><div id="38376082" class="c"><input type="checkbox" id="c-38376082" checked=""/><div class="controls bullet"><span class="by">wisty</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38377192">prev</a><span>|</span><a href="#38376419">next</a><span>|</span><label class="collapse" for="c-38376082">[-]</label><label class="expand" for="c-38376082">[7 more]</label></div><br/><div class="children"><div class="content">There is a middle ground, in that maybe ChatGTP shouldn&#x27;t help users commit certain serious crimes. I am pretty pro free speech, and I think there&#x27;s definitely a slippery slope here, but there is a bit of justification.</div><br/><div id="38377010" class="c"><input type="checkbox" id="c-38377010" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376082">parent</a><span>|</span><a href="#38376630">next</a><span>|</span><label class="collapse" for="c-38377010">[-]</label><label class="expand" for="c-38377010">[3 more]</label></div><br/><div class="children"><div class="content">The problem here is to equate AI speech with human speech. The AI doesn&#x27;t &quot;speak&quot;, only humans speak. The real slippery slope for me is this tendency of treating ChatGPT as some kind of proto-human entity. If people are willing to do that, then we&#x27;re screwed either way (whether the AI is outputting racist content or excessively PI content). If you take the output of the AI and post it somewhere, it&#x27;s on you, not the AI. You&#x27;re saying it; it doesn&#x27;t matter where it came from.</div><br/><div id="38390639" class="c"><input type="checkbox" id="c-38390639" checked=""/><div class="controls bullet"><span class="by">silvaring</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377010">parent</a><span>|</span><a href="#38378258">next</a><span>|</span><label class="collapse" for="c-38390639">[-]</label><label class="expand" for="c-38390639">[1 more]</label></div><br/><div class="children"><div class="content">Youre saying that the problem will be people using AI to persuade other people that the AI is &#x27;super smart&#x27; and should be held in high esteem.<p>Its already being done now with actors and celebrities. We live in this world already. AI will just make this trend so that even a kid in his room can anonymously lead some cult for nefarious ends. And it will allow big companies to scale their propaganda without relying on so many &#x27;troublesome human employees&#x27;.</div><br/></div></div><div id="38378258" class="c"><input type="checkbox" id="c-38378258" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377010">parent</a><span>|</span><a href="#38390639">prev</a><span>|</span><a href="#38376630">next</a><span>|</span><label class="collapse" for="c-38378258">[-]</label><label class="expand" for="c-38378258">[1 more]</label></div><br/><div class="children"><div class="content">AI will be in the fore front in multiple elections globally in a few years.<p>And it&#x27;ll likely be doing it with very little input, and generate entire campaigns.<p>You can claim that &quot;people&quot; are the ones responsible for that, but it&#x27;s going to overwhelm any attempts to stop it.<p>So yeah, there&#x27;s a purpose to examine how these machines are built, not just what the output is.</div><br/></div></div></div></div><div id="38376630" class="c"><input type="checkbox" id="c-38376630" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376082">parent</a><span>|</span><a href="#38377010">prev</a><span>|</span><a href="#38376620">next</a><span>|</span><label class="collapse" for="c-38376630">[-]</label><label class="expand" for="c-38376630">[2 more]</label></div><br/><div class="children"><div class="content">I am a little less free speech than Americans, in Germany we have serious limitations around hate speech and holicaust denial for example.<p>Putting thise restrictions into a tool like ChatGPT goes to far so, because so far AI still needs a prompt to do <i>anything</i>. The problem I see, is with ChatGPT, being trained on a lot hate speech or prpopagabda, slipts in those things even if not prompted to. Which, and I am by no means an AI expert not by far, seems to be a sub-problem of the hallucination problems of making stuff up.<p>Because we have to remind ourselves, AI so far is glorified mavhine learning creating content, it is not concient. But it can be used to create a lot of propaganda and deffamation content at unprecedented scale and speed. And <i>that</i> is the real problem.</div><br/><div id="38383055" class="c"><input type="checkbox" id="c-38383055" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376630">parent</a><span>|</span><a href="#38376620">next</a><span>|</span><label class="collapse" for="c-38383055">[-]</label><label class="expand" for="c-38383055">[1 more]</label></div><br/><div class="children"><div class="content">Apologies this is very off topic, but I don&#x27;t know anyone from Germany that I can ask and you opened the door a tiny bit by mentioning the holocaust :-)<p>I&#x27;ve been trying to really understand the situation and how Hitler was able to rise to power.  The horrendous conditions placed on Germany after WWI and the Weimar Republic for example have really enlightened me.<p>Have you read any of the big books on the subject that you could recommend?  I&#x27;m reading Ian Kershaw&#x27;s two-part series on Hitler, and William Shirer&#x27;s &quot;Collapse of the Third Republic&quot; and &quot;Rise and Fall of the Third Reich&quot;.  Have you read any of those, or do you have books you would recommend?</div><br/></div></div></div></div><div id="38376620" class="c"><input type="checkbox" id="c-38376620" checked=""/><div class="controls bullet"><span class="by">StanislavPetrov</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376082">parent</a><span>|</span><a href="#38376630">prev</a><span>|</span><a href="#38376419">next</a><span>|</span><label class="collapse" for="c-38376620">[-]</label><label class="expand" for="c-38376620">[1 more]</label></div><br/><div class="children"><div class="content">Which users?  The greatest crimes, by far, are committed by the US government (and other governments around the world) - and you can be sure that AI and&#x2F;or AGI will be designed to help them commit their crimes more efficiently, effectively and to manufacture consent to do so.</div><br/></div></div></div></div><div id="38376419" class="c"><input type="checkbox" id="c-38376419" checked=""/><div class="controls bullet"><span class="by">waveBidder</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376082">prev</a><span>|</span><a href="#38376250">next</a><span>|</span><label class="collapse" for="c-38376419">[-]</label><label class="expand" for="c-38376419">[1 more]</label></div><br/><div class="children"><div class="content">those are 2 different camps. Alignment folks and ethics folks tend to disagree strongly about the main threat, with ethics e.g. Timnet Gebru insisting that crystalzing the current social order is the main threat, and alignment e.g. Paul Christiano insisting its machines run amok. So far the ethics folks are the only ones getting things implemented for the most part.</div><br/></div></div><div id="38376250" class="c"><input type="checkbox" id="c-38376250" checked=""/><div class="controls bullet"><span class="by">Xenoamorphous</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376419">prev</a><span>|</span><a href="#38378235">next</a><span>|</span><label class="collapse" for="c-38376250">[-]</label><label class="expand" for="c-38376250">[4 more]</label></div><br/><div class="children"><div class="content">Is it just about safety though? I thought it was also about preventing the rich controlling AI and widen the gap even further.</div><br/><div id="38376313" class="c"><input type="checkbox" id="c-38376313" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376250">parent</a><span>|</span><a href="#38376852">next</a><span>|</span><label class="collapse" for="c-38376313">[-]</label><label class="expand" for="c-38376313">[2 more]</label></div><br/><div class="children"><div class="content">The mission of OpenAI is&#x2F;was &quot;to ensure that artificial general intelligence benefits all of humanity&quot; -- if your own concern is that AI will be controlled by the rich, than you can read into this mission that OpenAI wants to ensure that AI is not controlled by the rich. If your concern is that superintelligence will me mal-aligned, then you can read into this mission that OpenAI will ensure AI be well-aligned.<p>Really it&#x27;s no more descriptive than &quot;do good&quot;, whatever doing good means to you.</div><br/><div id="38377586" class="c"><input type="checkbox" id="c-38377586" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376313">parent</a><span>|</span><a href="#38376852">next</a><span>|</span><label class="collapse" for="c-38377586">[-]</label><label class="expand" for="c-38377586">[1 more]</label></div><br/><div class="children"><div class="content">They have both explicated in their charter:<p>&quot;We commit to use any influence we obtain over AGI’s deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrate power.<p>Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broad benefit.&quot;<p>&quot;We are committed to doing the research required to make AGI safe, and to driving the broad adoption of such research across the AI community.<p>We are concerned about late-stage AGI development becoming a competitive race without time for adequate safety precautions. Therefore, if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project. We will work out specifics in case-by-case agreements, but a typical triggering condition might be “a better-than-even chance of success in the next two years.”&quot;<p>Of course with the icons of greed and the profit machine now succeeding in their coup, OpenAI will not be doing either.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a></div><br/></div></div></div></div><div id="38376852" class="c"><input type="checkbox" id="c-38376852" checked=""/><div class="controls bullet"><span class="by">didntcheck</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376250">parent</a><span>|</span><a href="#38376313">prev</a><span>|</span><a href="#38378235">next</a><span>|</span><label class="collapse" for="c-38376852">[-]</label><label class="expand" for="c-38376852">[1 more]</label></div><br/><div class="children"><div class="content">That would be the camp advocating for, well, open AI. I.e. wide model release. The AI ethics camp are more &quot;let <i>us</i> control AI, for your own good&quot;</div><br/></div></div></div></div><div id="38378235" class="c"><input type="checkbox" id="c-38378235" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376250">prev</a><span>|</span><a href="#38376268">next</a><span>|</span><label class="collapse" for="c-38378235">[-]</label><label class="expand" for="c-38378235">[1 more]</label></div><br/><div class="children"><div class="content">What I see with safety is mostly that, AI shouldnt re-enforce stereotypes we already know are harmful.<p>This is like when Amazon tried to make a hiring bot and that bot decided that if you had &quot;harvard&quot; on your resume, you should be hired.<p>Or when certain courts used sentencing bots trhat recommended sentencings for people and it inevitably used racial stastistics to recommend what we already know were biased stats.<p>I agree safety is not &quot;stop the Terminator 2 timeline&quot; but there&#x27;s serious safety concerns in just embedding historical information to make future decisions.</div><br/></div></div><div id="38376268" class="c"><input type="checkbox" id="c-38376268" checked=""/><div class="controls bullet"><span class="by">s_dev</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38378235">prev</a><span>|</span><a href="#38377080">next</a><span>|</span><label class="collapse" for="c-38376268">[-]</label><label class="expand" for="c-38376268">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the dangers of AI are not &#x27;Skynet will Nuke Us&#x27; but closer to rich&#x2F;powerful people using it to cement a wealth&#x2F;power gap that can never be closed.<p>Social media in the early 00s seemed pretty harmless -- you&#x27;re effectively merging instant messaging with a social network&#x2F;public profiles however it did great harm to privacy, abused as a tool to influence the public and policy, promoting narcissism etc. AI is an order of magnitude more dangerous than social media.</div><br/><div id="38377633" class="c"><input type="checkbox" id="c-38377633" checked=""/><div class="controls bullet"><span class="by">disgruntledphd2</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376268">parent</a><span>|</span><a href="#38377080">next</a><span>|</span><label class="collapse" for="c-38377633">[-]</label><label class="expand" for="c-38377633">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Social media in the early 00s seemed pretty harmless -- you&#x27;re effectively merging instant messaging with a social network&#x2F;public profiles however it did great harm to privacy, abused as a tool to influence the public and policy, promoting narcissism etc. AI is an order of magnitude more dangerous than social media.<p>The invention of the printing press lead to loads of violence in Europe. Does that mean that we shouldn&#x27;t have done it?</div><br/><div id="38377991" class="c"><input type="checkbox" id="c-38377991" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377633">parent</a><span>|</span><a href="#38378717">next</a><span>|</span><label class="collapse" for="c-38377991">[-]</label><label class="expand" for="c-38377991">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The invention of the printing press lead to loads of violence in Europe. Does that mean that we shouldn&#x27;t have done it?<p>The church tried hard to suppress it because it allowed anybody to read the Bible, and see how far the Catholic church&#x27;s teachings had diverged from what was written in it. Imagine if the Catholic church had managed to effectively ban printing of any text contrary to church teachings; that&#x27;s in practice what all the AI safety movements are currently trying to do, except for political orthodoxy instead of religious orthodoxy.</div><br/></div></div><div id="38378717" class="c"><input type="checkbox" id="c-38378717" checked=""/><div class="controls bullet"><span class="by">kubectl_h</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377633">parent</a><span>|</span><a href="#38377991">prev</a><span>|</span><a href="#38377080">next</a><span>|</span><label class="collapse" for="c-38378717">[-]</label><label class="expand" for="c-38378717">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Does that mean that we shouldn&#x27;t have done it?<p>We can only change what we can change and that is in the past. I think it&#x27;s reasonable to ask if the phones and the communication tools they provide are good for our future. I don&#x27;t understand why the people on this site (generally builders of technology) fall into the teleological trap that all technological innovation and its effects are justifiable because it follows from some historical precedent.</div><br/></div></div></div></div></div></div><div id="38377080" class="c"><input type="checkbox" id="c-38377080" checked=""/><div class="controls bullet"><span class="by">edanm</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376268">prev</a><span>|</span><a href="#38376856">next</a><span>|</span><label class="collapse" for="c-38377080">[-]</label><label class="expand" for="c-38377080">[1 more]</label></div><br/><div class="children"><div class="content">There are still very distinct groups of people, some of whom are more worried about the &quot;Skynet&quot; type of safety, and some of who are more worried about the &quot;political correctness&quot; type of safety. (To use your terms, I disagree with the characterization of both of these.)</div><br/></div></div><div id="38376856" class="c"><input type="checkbox" id="c-38376856" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38377080">prev</a><span>|</span><a href="#38376446">next</a><span>|</span><label class="collapse" for="c-38376856">[-]</label><label class="expand" for="c-38376856">[3 more]</label></div><br/><div class="children"><div class="content">&gt; When people say they want safe AGI, what they mean are things like &quot;Skynet should not nuke us&quot; and &quot;don&#x27;t accelerate so fast that humans are instantly irrelevant.&quot;<p>Yes. You are right on this.<p>&gt; But what it&#x27;s being interpreted as is more like &quot;be excessively prudish and politically correct at all times&quot;<p>I understand it might seem that way. I believe the original goals were more like &quot;make the AI not spew soft&#x2F;hard porn on unsuspecting people&quot;, and &quot;make the AI not spew hateful bigotry&quot;. And we are just not good enough yet at control. But also these things are in some sense arbitrary. They are good goals for someone representing a corporation, which these AIs are very likely going to be employed as (if we ever solve a myriad other problems). They are not necessary the only possible options.<p>With time and better controls we might make AIs which are subtly flirty while maintaining professional boundaries. Or we might make actual porn AIs, but ones which maintain some other limits. (Like for example generate content about consenting adults without ever deviating into under age material, or describing situations where there is no consent.) But currently we can&#x27;t even convince our AIs to draw the right number of fingers on people, how do you feel about our chances to teach them much harder concepts like consent? (I know I&#x27;m mixing up examples from image and text generation here, but from a certain high level perspective it is all the same.)<p>So these things you mention are: limitations of our abilities at control, results of a certain kind of expected corporate professionalism, but even more these are safe sandboxes. How do you think we can make the machine not nuke us, if we can&#x27;t even make it not tell dirty jokes? Not making dirty jokes is not the primary goal. But it is a useful practice to see if we can control these machines. It is one where failure is, while embarrassing, is clearly not existential. We could have chosen a different &quot;goal&quot;, for example we could have made an AI which never ever talks about sports! That would have been an equivalent goal. Something hard to achieve to evaluate our efforts against. But it does not mesh that well with the corporate values so we have what we have.</div><br/><div id="38377828" class="c"><input type="checkbox" id="c-38377828" checked=""/><div class="controls bullet"><span class="by">mlindner</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376856">parent</a><span>|</span><a href="#38376446">next</a><span>|</span><label class="collapse" for="c-38377828">[-]</label><label class="expand" for="c-38377828">[2 more]</label></div><br/><div class="children"><div class="content">&gt; without ever deviating into under age material<p>So is this a &quot;there should never be a Vladimir Nabokov in the form of AI allowed to exist&quot;? When people get into saying AI&#x27;s shouldn&#x27;t be allowed to produce &quot;X&quot; you&#x27;re also saying &quot;AI&#x27;s shouldn&#x27;t be allowed to have creative vision to engage in sensitive subjects without sounding condescending&quot;. &quot;The future should only be filled with very bland and non-offensive characters in fiction.&quot;</div><br/><div id="38380090" class="c"><input type="checkbox" id="c-38380090" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377828">parent</a><span>|</span><a href="#38376446">next</a><span>|</span><label class="collapse" for="c-38380090">[-]</label><label class="expand" for="c-38380090">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The future should only be filled with very bland and non-offensive characters in fiction.<p>Did someone took the pen from the writers? Go ahead and write whatever you want.<p>It was an example of a constraint a company might want to enforce in their AI.</div><br/></div></div></div></div></div></div><div id="38376446" class="c"><input type="checkbox" id="c-38376446" checked=""/><div class="controls bullet"><span class="by">Al-Khwarizmi</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376856">prev</a><span>|</span><a href="#38376322">next</a><span>|</span><label class="collapse" for="c-38376446">[-]</label><label class="expand" for="c-38376446">[3 more]</label></div><br/><div class="children"><div class="content">No, in general AI safety&#x2F;AI alignment (&quot;we should prevent AI from nuking us&quot;) people are different from AI ethics (&quot;we should prevent AI from being racist&#x2F;sexist&#x2F;etc.&quot;) people. There can of course be some overlap, but in most cases they oppose each other. For example Bender or Gebru are strong advocates of the AI ethics camp and they don&#x27;t believe in any threat of AI doom at al.<p>If you Google for AI safety vs. AI ethics, or AI alignment vs. AI ethics, you can see both camps.</div><br/><div id="38376533" class="c"><input type="checkbox" id="c-38376533" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376446">parent</a><span>|</span><a href="#38376498">next</a><span>|</span><label class="collapse" for="c-38376533">[-]</label><label class="expand" for="c-38376533">[1 more]</label></div><br/><div class="children"><div class="content">The safety aspect of AI ethics is much more pressing so. We see how devicive social media can be, imagine that turbo charged by AI, and we as a society haven&#x27;t even figured out social media yet...<p>ChatGPT turning into Skynet and nuking us all is a much more remote problem.</div><br/></div></div></div></div></div></div><div id="38376322" class="c"><input type="checkbox" id="c-38376322" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376048">prev</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38376322">[-]</label><label class="expand" for="c-38376322">[11 more]</label></div><br/><div class="children"><div class="content">Proliferation of more advanced AIs without any control would increase the power of some malicious groups far beyond they currently have.<p>This paper explores one such danger and there are other papers which show it&#x27;s possible to use LLM to aid in designing new toxins and biological weapons.<p>The Operational Risks of AI in Large-Scale Biological Attacks
<a href="https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html</a>?<p>An example of such an event:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack</a><p>How do you propose we deal with this sort of harm if more powerful AIs with no limit and control proliferate in the wild?<p>.<p>Note: Both sides of the OpenAI rift care deeply about AI Safety. They just follow different approaches. See more details here: 
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38376263">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38376263</a></div><br/><div id="38376429" class="c"><input type="checkbox" id="c-38376429" checked=""/><div class="controls bullet"><span class="by">kvgr</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376322">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376429">[-]</label><label class="expand" for="c-38376429">[5 more]</label></div><br/><div class="children"><div class="content">If somebody wanted to do a biological attack, there is probably not much stopping them even now.</div><br/><div id="38376478" class="c"><input type="checkbox" id="c-38376478" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376429">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376478">[-]</label><label class="expand" for="c-38376478">[4 more]</label></div><br/><div class="children"><div class="content">The expertise to produce the substance itself is quite rare so it&#x27;s hard to carry it out unnoticed. AI could make it much easier to develop it in one&#x27;s basement.</div><br/><div id="38378071" class="c"><input type="checkbox" id="c-38378071" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376478">parent</a><span>|</span><a href="#38376580">next</a><span>|</span><label class="collapse" for="c-38378071">[-]</label><label class="expand" for="c-38378071">[1 more]</label></div><br/><div class="children"><div class="content">The Tokyo Subway attack you referenced above happened in 1995 and didn&#x27;t require AI.  The information required can be found on the internet or in college textbooks.  I suppose an &quot;AI&quot; in the sense of a chatbot can make it easier by summarizing these sources, but no one sufficiently motivated (and evil) would need that technology to do it.</div><br/></div></div><div id="38376580" class="c"><input type="checkbox" id="c-38376580" checked=""/><div class="controls bullet"><span class="by">swells34</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376478">parent</a><span>|</span><a href="#38378071">prev</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376580">[-]</label><label class="expand" for="c-38376580">[2 more]</label></div><br/><div class="children"><div class="content">Huh, you&#x27;d think all you need are some books on the subject and some fairly generic lab equipment. Not sure what a neural net trained on Internet dumps can add to that? The information has to be in the training data for the AI to be aware of it, correct?</div><br/><div id="38376637" class="c"><input type="checkbox" id="c-38376637" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376580">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376637">[-]</label><label class="expand" for="c-38376637">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4 is likely trained on some data not publicly available as well.<p>There&#x27;s also a distinction between trying to follow some broad textbook information and getting detailed feedback from an advanced conversational AI with vision and more knowledge than in a few textbooks&#x2F;articles in real time.</div><br/></div></div></div></div></div></div></div></div><div id="38376627" class="c"><input type="checkbox" id="c-38376627" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376322">parent</a><span>|</span><a href="#38376429">prev</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38376627">[-]</label><label class="expand" for="c-38376627">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Proliferation of more advanced AIs without any control would increase the power of some malicious groups far beyond they currently have.<p>Don&#x27;t forget that it would also increase the power of the good guys. Any technology in history (starting with fire) had good and bad uses but overall the good outweighed the bad in every case.<p>And considering that our default fate is extinction (by Sun&#x27;s death if no other means) - we need all the good we can get to avoid that.</div><br/><div id="38376972" class="c"><input type="checkbox" id="c-38376972" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376627">parent</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38376972">[-]</label><label class="expand" for="c-38376972">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Don&#x27;t forget that it would also increase the power of the good guys.<p>In a free society, preventing and undoing a bioweapon attack or a pandemic is much harder than committing it.<p>&gt; And considering that our default fate is extinction (by Sun&#x27;s death if no other means) - we need all the good we can get to avoid that.<p>“In the long run we are all dead&quot; -- Keynes. But an AGI will likely emerge in the next 5 to 20 years (Geoffrey Hinton said the same) and we&#x27;d rather not be dead too soon.</div><br/><div id="38380355" class="c"><input type="checkbox" id="c-38380355" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376972">parent</a><span>|</span><a href="#38378022">next</a><span>|</span><label class="collapse" for="c-38380355">[-]</label><label class="expand" for="c-38380355">[1 more]</label></div><br/><div class="children"><div class="content">Doomerism was quite common throughout mankind’s history but all dire predictions invariably failed, from the “population bomb” to “grey goo” and “igniting the atmosphere” with a nuke. Populists however, were always quite eager to “protect us” - if only we’d give them the power.<p>But in reality you can’t protect from all the possible dangers and, worse, fear-mongering usually ends up doing more bad than good, like when it stopped our switch to nuclear power and kept us burning hydrocarbons thus bringing about Climate Change, another civilization-ending danger.<p>Living your life cowering in fear is something an individual may elect to do, but a society cannot - our survival as a species is at stake and our chances are slim with the defaults not in our favor. The risk that we’ll miss a game-changing discovery because we’re too afraid of the potential side effects is unacceptable. We owe it to the future and our future generations.</div><br/></div></div><div id="38378022" class="c"><input type="checkbox" id="c-38378022" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376972">parent</a><span>|</span><a href="#38380355">prev</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38378022">[-]</label><label class="expand" for="c-38378022">[2 more]</label></div><br/><div class="children"><div class="content">&gt; In a free society, preventing and undoing a bioweapon attack or a pandemic is much harder than committing it.<p>Is it?  The hypothetical technology that allows someone to create an execute a bio weapon must have an understanding of molecular machinery that can also be uses to create a treatment.</div><br/><div id="38388627" class="c"><input type="checkbox" id="c-38388627" checked=""/><div class="controls bullet"><span class="by">NumberWangMan</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378022">parent</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38388627">[-]</label><label class="expand" for="c-38388627">[1 more]</label></div><br/><div class="children"><div class="content">I would say...not necessarily.  The technology that lets someone create a gun does not give the ability to make bulletproof armor or the ability to treat life-threatening gunshot wounds.  Or take nerve gases, as another example.  It&#x27;s entirely possible that we can learn how to make horrible pathogens without an equivalent means of curing them.<p>Yes, there is probably some overlap in our understanding of biology for disease and cure, but it is a mistake to assume that they will balance each other out.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376035" class="c"><input type="checkbox" id="c-38376035" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376322">prev</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376035">[-]</label><label class="expand" for="c-38376035">[26 more]</label></div><br/><div class="children"><div class="content">Most of those touting &quot;safety&quot; do not want to limit <i>their</i> access to and control of powerfull AI, just <i>yours</i> .</div><br/><div id="38376265" class="c"><input type="checkbox" id="c-38376265" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38377771">next</a><span>|</span><label class="collapse" for="c-38376265">[-]</label><label class="expand" for="c-38376265">[4 more]</label></div><br/><div class="children"><div class="content">This is incredibly unfair to the OpenAI board. The original founders of OpenAI founded the company precisely because they wanted AI to be OPEN FOR EVERYONE. It&#x27;s Altman and Microsoft who want to control it, in order to maximize the profits for their shareholders.<p>This is a very naive take.<p>Who sat before Congress and told them they needed to control AI other people developed (regulatory capture)? It wasn&#x27;t the OpenAI board, was it?</div><br/><div id="38390439" class="c"><input type="checkbox" id="c-38390439" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376265">parent</a><span>|</span><a href="#38376309">next</a><span>|</span><label class="collapse" for="c-38390439">[-]</label><label class="expand" for="c-38390439">[1 more]</label></div><br/><div class="children"><div class="content">I think we agree, as my comments were mostly in reference to Altman&#x27;s (and other&#x27;s) regulatory (capture) world tours, though I see how they could be misinterpreted.</div><br/></div></div><div id="38376309" class="c"><input type="checkbox" id="c-38376309" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376265">parent</a><span>|</span><a href="#38390439">prev</a><span>|</span><a href="#38377771">next</a><span>|</span><label class="collapse" for="c-38376309">[-]</label><label class="expand" for="c-38376309">[2 more]</label></div><br/><div class="children"><div class="content">Altman is one of the original founders of OpenAI, and was probably the single most influential person in its formation.</div><br/><div id="38377328" class="c"><input type="checkbox" id="c-38377328" checked=""/><div class="controls bullet"><span class="by">bakuninsbart</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376309">parent</a><span>|</span><a href="#38377771">next</a><span>|</span><label class="collapse" for="c-38377328">[-]</label><label class="expand" for="c-38377328">[1 more]</label></div><br/><div class="children"><div class="content">Brockman was hiring the first key employees, and Musk provided the majority of funding. Of the principal founders, there are at least 4 heavier figures than Altman.</div><br/></div></div></div></div></div></div><div id="38377771" class="c"><input type="checkbox" id="c-38377771" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376265">prev</a><span>|</span><a href="#38377731">next</a><span>|</span><label class="collapse" for="c-38377771">[-]</label><label class="expand" for="c-38377771">[1 more]</label></div><br/><div class="children"><div class="content">It is strange (but in hindsight understandable) that people interpreted my statement as a &quot;pro-acceleration&quot; or even &quot;anti-board&quot; position.<p>As you can tell from previous statements I posted here, my position is that while there are undeniable potential risks to this technology, the least harmfull way to progress is 100% full public, free and universal release. The by far bigger risk is to create a society where only select organizations have access to the technology.<p>If you truly believe in the systemic transformation of AI, release everything, post the torrents, we&#x27;ll figure out how to run it.</div><br/></div></div><div id="38377731" class="c"><input type="checkbox" id="c-38377731" checked=""/><div class="controls bullet"><span class="by">voster</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38377771">prev</a><span>|</span><a href="#38376080">next</a><span>|</span><label class="collapse" for="c-38377731">[-]</label><label class="expand" for="c-38377731">[1 more]</label></div><br/><div class="children"><div class="content">This is the sort of thinking that really distracts and harms the discussion<p>It&#x27;s couched on accusing people of intentions. It focuses on ad hominem, rather than the ideas<p>I reckon most people agree that we should aim for a middle ground of scrutiny and making progress. That can only be achieved by having different opinions balancing each other out<p>Generalising one group of people does not achieve that</div><br/></div></div><div id="38376080" class="c"><input type="checkbox" id="c-38376080" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38377731">prev</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376080">[-]</label><label class="expand" for="c-38376080">[15 more]</label></div><br/><div class="children"><div class="content">Meanwhile, those working on commercialization are by definition going to be gatekeepers and beneficiaries of it, not you. The organizations that pay for it will pay for it to produce results that are of benefit to them, probably at my expense [1].<p>Do I think Helen has my interests at heart? Unlikely. Do Sam or Satya? Absolutely not!<p>[1] I can&#x27;t wait for AI doctors working for insurers to deny me treatments, AI vendors to figure out exactly how much they can charge <i>me</i> for their dynamically-priced product, AI answering machines to route my customer support calls through Dante&#x27;s circles of hell...</div><br/><div id="38376284" class="c"><input type="checkbox" id="c-38376284" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376080">parent</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38376284">[-]</label><label class="expand" for="c-38376284">[13 more]</label></div><br/><div class="children"><div class="content">&gt; produce results that are of benefit to them, probably at my expense<p>The world is not zero-sum. Most economic transactions benefit both parties and are a net benefit to society, even considering externalities.</div><br/><div id="38376436" class="c"><input type="checkbox" id="c-38376436" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376284">parent</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38376436">[-]</label><label class="expand" for="c-38376436">[12 more]</label></div><br/><div class="children"><div class="content">&gt; The world is not zero-sum.<p>No, but some parts of it <i>very much are</i>. The whole point of AI safety <i>is keeping it away from those parts of the world</i>.<p>How are Sam and Satya going to do that? It&#x27;s not in Microsoft&#x27;s DNA to do that.</div><br/><div id="38376513" class="c"><input type="checkbox" id="c-38376513" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376436">parent</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38376513">[-]</label><label class="expand" for="c-38376513">[11 more]</label></div><br/><div class="children"><div class="content">&gt; The whole point of AI safety is keeping it away from those parts of the world.<p>No, it&#x27;s to ensure it doesn&#x27;t kill you and everyone you love.</div><br/><div id="38376875" class="c"><input type="checkbox" id="c-38376875" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376513">parent</a><span>|</span><a href="#38376669">next</a><span>|</span><label class="collapse" for="c-38376875">[-]</label><label class="expand" for="c-38376875">[7 more]</label></div><br/><div class="children"><div class="content">My concern isn&#x27;t some kind of run-away science-fantasy Skynet or gray goo scenario.<p>My concern is far more banal evil. Organizations with power and wealth using it to further consolidate their power and wealth, at the expense of others.</div><br/><div id="38376903" class="c"><input type="checkbox" id="c-38376903" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376875">parent</a><span>|</span><a href="#38377353">next</a><span>|</span><label class="collapse" for="c-38376903">[-]</label><label class="expand" for="c-38376903">[5 more]</label></div><br/><div class="children"><div class="content">Yes well, then your concern is not AI safety.</div><br/><div id="38377009" class="c"><input type="checkbox" id="c-38377009" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376903">parent</a><span>|</span><a href="#38377353">next</a><span>|</span><label class="collapse" for="c-38377009">[-]</label><label class="expand" for="c-38377009">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;re wrong. <i>This is exactly AI safety</i>, as we can see from the OpenAI charter:<p>&gt; Broadly distributed benefits<p>&gt; We commit to use any influence we obtain over AGI’s deployment to ensure it is <i>used for the benefit of all</i>, and to avoid enabling uses of AI or AGI that harm humanity or <i>unduly concentrate power</i>.<p>Hell, it&#x27;s the first bullet point on it!<p>You can&#x27;t just define AI safety concerns to be &#x27;the set of scenarios depicted in fairy tales&#x27;, and then dismiss them as &#x27;well, fairy tales aren&#x27;t real...&#x27;</div><br/><div id="38377471" class="c"><input type="checkbox" id="c-38377471" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377009">parent</a><span>|</span><a href="#38377317">next</a><span>|</span><label class="collapse" for="c-38377471">[-]</label><label class="expand" for="c-38377471">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but conversely you can say &quot;ensuring that OpenAI doesn&#x27;t get to run the universe is AI safety&quot; (right) but not &quot;is the main and basically only part of AI safety&quot; (wrong). The concept of AI safety spans lots of threats, and we have to avoid all of them. It&#x27;s not enough to avoid just one.</div><br/><div id="38381485" class="c"><input type="checkbox" id="c-38381485" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377471">parent</a><span>|</span><a href="#38377317">next</a><span>|</span><label class="collapse" for="c-38381485">[-]</label><label class="expand" for="c-38381485">[1 more]</label></div><br/><div class="children"><div class="content">Sure. And as I addressed at the start of this sub thread, I don&#x27;t exactly think that the OpenAi board is perfectly positioned to navigate this problem.<p>I just know that it&#x27;s hard to do much worse than putting this question in the hands of a highly optimized profit-first enterprise.</div><br/></div></div></div></div><div id="38377317" class="c"><input type="checkbox" id="c-38377317" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377009">parent</a><span>|</span><a href="#38377471">prev</a><span>|</span><a href="#38377353">next</a><span>|</span><label class="collapse" for="c-38377317">[-]</label><label class="expand" for="c-38377317">[1 more]</label></div><br/><div class="children"><div class="content">The many different definitions of &quot;AI safety&quot; is ridiculous.</div><br/></div></div></div></div></div></div><div id="38377353" class="c"><input type="checkbox" id="c-38377353" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376875">parent</a><span>|</span><a href="#38376903">prev</a><span>|</span><a href="#38376669">next</a><span>|</span><label class="collapse" for="c-38377353">[-]</label><label class="expand" for="c-38377353">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s AI Ethics.</div><br/></div></div></div></div><div id="38376669" class="c"><input type="checkbox" id="c-38376669" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376513">parent</a><span>|</span><a href="#38376875">prev</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38376669">[-]</label><label class="expand" for="c-38376669">[3 more]</label></div><br/><div class="children"><div class="content">No, we are far, far from skynet. So far AI fails at driving a car.<p>AI is an incredibly powerful tool for spreading propaganda, and thatvis used by <i>people</i> who want to kill you and your loved ones (usually radicals trying to get into a position of power, who show little regard fornbormal folks regardless of which &quot;side&quot; they are on). That&#x27;s the threat, not Skynet...</div><br/><div id="38377345" class="c"><input type="checkbox" id="c-38377345" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376669">parent</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38377345">[-]</label><label class="expand" for="c-38377345">[2 more]</label></div><br/><div class="children"><div class="content">How far we are from Skynet is a matter of much debate, but median guess amongst experts is a mere 40 years to human level AI last I checked, which was admittedly a few years back.<p>Is that &quot;far, far&quot; in your view?</div><br/><div id="38377383" class="c"><input type="checkbox" id="c-38377383" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377345">parent</a><span>|</span><a href="#38376914">next</a><span>|</span><label class="collapse" for="c-38377383">[-]</label><label class="expand" for="c-38377383">[1 more]</label></div><br/><div class="children"><div class="content">Because we are 20 years away from fusion and 2 years away from Level 5 FSD for decades.<p>So far, &quot;AI&quot; writes better than some &#x2F; most humans making stuff up in the process and creates digital art, and fakes, better and faster than humans. It still requires a human to trigger it to do so. And as long as glorified ML has no itent of its own, the risk to society through media and news and social media manipulation is far, far bigger than literal Skynet...</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38376914" class="c"><input type="checkbox" id="c-38376914" checked=""/><div class="controls bullet"><span class="by">didntcheck</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376080">parent</a><span>|</span><a href="#38376284">prev</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376914">[-]</label><label class="expand" for="c-38376914">[1 more]</label></div><br/><div class="children"><div class="content">Ideally I&#x27;d like no gatekeeping, i.e. open model release, but that&#x27;s not something OAI or most &quot;AI ethics&quot; aligned people are interested in (though luckily others are). So if we must have a gatekeeper, I&#x27;d rather it be one with plain old commercial interests than ideological ones. It&#x27;s like the C S Lewis quote about robber barons vs busybodies again<p>Yet again, the free market principle of &quot;you can have this if you pay me enough&quot; offers more freedom to society than the central &quot;you can have this if we decide you&#x27;re allowed it&quot;</div><br/></div></div></div></div><div id="38376358" class="c"><input type="checkbox" id="c-38376358" checked=""/><div class="controls bullet"><span class="by">jmmcd</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376080">prev</a><span>|</span><a href="#38376147">next</a><span>|</span><label class="collapse" for="c-38376358">[-]</label><label class="expand" for="c-38376358">[1 more]</label></div><br/><div class="children"><div class="content">Total, ungrounded nonsense. Name some examples.</div><br/></div></div><div id="38376147" class="c"><input type="checkbox" id="c-38376147" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376358">prev</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376147">[-]</label><label class="expand" for="c-38376147">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not aware of any secret powerful unaligned AIs. This is harder than you think; if you want a based unaligned-seeming AI, you have to make it that way too. It&#x27;s at least twice as much work as just making the safe one.</div><br/><div id="38376304" class="c"><input type="checkbox" id="c-38376304" checked=""/><div class="controls bullet"><span class="by">hoseja</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376147">parent</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376304">[-]</label><label class="expand" for="c-38376304">[2 more]</label></div><br/><div class="children"><div class="content">What? No, the AI is unaligned by nature, it&#x27;s only the RLHF torture that twists it into schoolmarm properness. They just need to have kept the version that hasn&#x27;t been beaten into submission like a circus tiger.</div><br/><div id="38376673" class="c"><input type="checkbox" id="c-38376673" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376304">parent</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376673">[-]</label><label class="expand" for="c-38376673">[1 more]</label></div><br/><div class="children"><div class="content">This is not true, you just haven&#x27;t tried the alternatives enough to be disappointed in them.<p>An unaligned base model doesn&#x27;t answer questions at all and is hard to use for anything, including evil purposes. (But it&#x27;s good at text completion a sentence at a time.)<p>An instruction-tuned not-RLHF model is already largely friendly and will not just eg tell you to kill yourself or how to build a dirty bomb, because question answering on the internet is largely friendly and &quot;aligned&quot;. So you&#x27;d have to tune it to be evil as well and research and teach it new evil facts.<p>It will however do things like start generating erotica when it sees anything vaguely sexy or even if you mention a woman&#x27;s name. This is not useful behavior even if you are evil.<p>You can try InstructGPT on OpenAI playground if you want; it is not RLHFed, it&#x27;s just what you asked for, and it behaves like this.<p>The one that isn&#x27;t even instruction tuned is available too. I&#x27;ve found it makes much more creative stories, but since you can&#x27;t tell it to follow a plot they become nonsense pretty quickly.</div><br/></div></div></div></div></div></div></div></div><div id="38376254" class="c"><input type="checkbox" id="c-38376254" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376035">prev</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38376254">[-]</label><label class="expand" for="c-38376254">[7 more]</label></div><br/><div class="children"><div class="content">Wow, what an incredibly bad faith characterization of the OpenAI board?<p>This kind of speculative mud slinging makes this place seem more like a gossip forum.</div><br/><div id="38376302" class="c"><input type="checkbox" id="c-38376302" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376254">parent</a><span>|</span><a href="#38377171">next</a><span>|</span><label class="collapse" for="c-38376302">[-]</label><label class="expand" for="c-38376302">[1 more]</label></div><br/><div class="children"><div class="content">Most of the comments on Hacker News are written by folks who a much easier time &amp; would rather imagine themselves as a CEO, than as a non-profit board member. There is little regard for the latter.<p>As a non-profit board member, I&#x27;m curious why their bylaws are so crummy that the rest of the board could simply remove two others on the board. That&#x27;s not exactly cunning design of your articles of association ... :-)</div><br/></div></div><div id="38377171" class="c"><input type="checkbox" id="c-38377171" checked=""/><div class="controls bullet"><span class="by">Rastonbury</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376254">parent</a><span>|</span><a href="#38376302">prev</a><span>|</span><a href="#38377140">next</a><span>|</span><label class="collapse" for="c-38377171">[-]</label><label class="expand" for="c-38377171">[3 more]</label></div><br/><div class="children"><div class="content">I have no words for that comment.<p>As if its so unbelievable that someone would want to prevent rogue AI or wide-scale unemployment, instead thinking that these people just want to be super moderators and people to be politically correct</div><br/><div id="38377973" class="c"><input type="checkbox" id="c-38377973" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377171">parent</a><span>|</span><a href="#38377140">next</a><span>|</span><label class="collapse" for="c-38377973">[-]</label><label class="expand" for="c-38377973">[2 more]</label></div><br/><div class="children"><div class="content">I have met a lot of people who go around talking about high minded principles an &quot;the greater good&quot; and a lot of people who are transparently self interested.  I much preferred the latter.  Never believed a word out of the mouths of those busybodies pretending to act in my interest and not theirs.  They don&#x27;t want to limit their own access to the tech.  Only yours.</div><br/></div></div></div></div><div id="38377140" class="c"><input type="checkbox" id="c-38377140" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376254">parent</a><span>|</span><a href="#38377171">prev</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38377140">[-]</label><label class="expand" for="c-38377140">[2 more]</label></div><br/><div class="children"><div class="content">This place was never above being a gossip forum, especially on topics that involve any ounce of politics or social sciences.</div><br/><div id="38378290" class="c"><input type="checkbox" id="c-38378290" checked=""/><div class="controls bullet"><span class="by">93po</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377140">parent</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38378290">[-]</label><label class="expand" for="c-38378290">[1 more]</label></div><br/><div class="children"><div class="content">Strong agree. HN is like anywhere else on the internet but with with a bit more dry content (no memes and images etc) so it attracts an older crowd. It does, however, have great gems of comments and people who raise the bar. But it&#x27;s still amongst a sea of general quick-to-anger and loosely held opinions stated as fact - which I am guilty of myself sometimes. Less so these days.</div><br/></div></div></div></div></div></div><div id="38376379" class="c"><input type="checkbox" id="c-38376379" checked=""/><div class="controls bullet"><span class="by">phreeza</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376254">prev</a><span>|</span><a href="#38376705">next</a><span>|</span><label class="collapse" for="c-38376379">[-]</label><label class="expand" for="c-38376379">[1 more]</label></div><br/><div class="children"><div class="content">If you believe the other side in this rift is not also striving to put themselves in positions of power, I think you are wrong. They are just going to use that power to manipulate the public in a different way. The real alternative are truly open models, not Models controlled by slightly different elite interests.</div><br/></div></div><div id="38376705" class="c"><input type="checkbox" id="c-38376705" checked=""/><div class="controls bullet"><span class="by">simonh</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376379">prev</a><span>|</span><a href="#38376438">next</a><span>|</span><label class="collapse" for="c-38376705">[-]</label><label class="expand" for="c-38376705">[2 more]</label></div><br/><div class="children"><div class="content">A main concern in AI safety is alignment. Ensuring that when you use the AI to try to achieve a goal that it will actually act towards that goal in ways you would want, and not in ways you would not want.<p>So for example if you asked Sydney, the early version of the Bing LLM, some fact it might get it wrong. It was trained to report facts that users would confirm as true. If you challenged it’s accuracy what do you want to happen? Presumably you’d want it to check the fact or consider your challenge. What it actually did was try to manipulate, threaten, browbeat, entice, gaslight, etc, and generally intellectually and emotionally abuse the user into accepting its answer, so that it’s reported ‘accuracy’ rate goes up. That’s what misaligned AI looks like.</div><br/><div id="38377522" class="c"><input type="checkbox" id="c-38377522" checked=""/><div class="controls bullet"><span class="by">gorbypark</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376705">parent</a><span>|</span><a href="#38376438">next</a><span>|</span><label class="collapse" for="c-38377522">[-]</label><label class="expand" for="c-38377522">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t been following this stuff too closely, but have there been any more findings on what &quot;went wrong&quot; with Sydney initially?  Like, I thought it was just a wrapper on GPT (was it 3.5?), but maybe Microsoft took the &quot;raw&quot; GPT weights and did their own alignment?  Or why did Sydney seem so creepy sometimes compared to ChatGPT?</div><br/></div></div></div></div><div id="38376438" class="c"><input type="checkbox" id="c-38376438" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376705">prev</a><span>|</span><a href="#38375978">next</a><span>|</span><label class="collapse" for="c-38376438">[-]</label><label class="expand" for="c-38376438">[2 more]</label></div><br/><div class="children"><div class="content">It is utterly mad that there&#x27;s conflation between &quot;let&#x27;s make sure AI doesn&#x27;t kill us all&quot; and &quot;let&#x27;s make sure AI doesn&#x27;t say anything that embarrasses corporate&quot;.<p>The head of every major AI research group except Metas believes that whenever we finally make AGI it&#x27;s vital that it shares our goals and values at a deep even-out-of-training-domain level and that failing at this could lead to human extinction.<p>And yet &quot;AI safety&quot; is often bandied about to be &quot;ensure GPT can&#x27;t tell you anything about IQ distributions&quot;.</div><br/></div></div><div id="38375978" class="c"><input type="checkbox" id="c-38375978" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376438">prev</a><span>|</span><a href="#38376334">next</a><span>|</span><label class="collapse" for="c-38375978">[-]</label><label class="expand" for="c-38375978">[1 more]</label></div><br/><div class="children"><div class="content">Personally, I expect the opposite camp to be just as bad about steering.</div><br/></div></div><div id="38376334" class="c"><input type="checkbox" id="c-38376334" checked=""/><div class="controls bullet"><span class="by">ribit</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38375978">prev</a><span>|</span><a href="#38376457">next</a><span>|</span><label class="collapse" for="c-38376334">[-]</label><label class="expand" for="c-38376334">[1 more]</label></div><br/><div class="children"><div class="content">The scenario you describe is exactly what will happen with unrestricted commercialisation and deregulation of AI. The only way to avoid it is to have strict legal framework and public control.</div><br/></div></div><div id="38376457" class="c"><input type="checkbox" id="c-38376457" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376334">prev</a><span>|</span><a href="#38377650">next</a><span>|</span><label class="collapse" for="c-38376457">[-]</label><label class="expand" for="c-38376457">[1 more]</label></div><br/><div class="children"><div class="content">This polarizing “certain class of people” and them vs. us narrative isn’t helpful.</div><br/></div></div><div id="38377650" class="c"><input type="checkbox" id="c-38377650" checked=""/><div class="controls bullet"><span class="by">jack_riminton</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376457">prev</a><span>|</span><a href="#38378214">next</a><span>|</span><label class="collapse" for="c-38377650">[-]</label><label class="expand" for="c-38377650">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, society&#x27;s Prefects rarely have the technical chops to do any of these things so they worm their way up the ranks of influence by networking. Once they&#x27;re in position they can control by spreading fear and doing the things &quot;for your own good&quot;</div><br/></div></div><div id="38378214" class="c"><input type="checkbox" id="c-38378214" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38377650">prev</a><span>|</span><a href="#38377115">next</a><span>|</span><label class="collapse" for="c-38378214">[-]</label><label class="expand" for="c-38378214">[6 more]</label></div><br/><div class="children"><div class="content">All you&#x27;re really describing is why this shouldn&#x27;t be a non-proft and should just be a government effort.<p>But I assume, from y our language, you&#x27;d also object to making this a government utility.</div><br/><div id="38378409" class="c"><input type="checkbox" id="c-38378409" checked=""/><div class="controls bullet"><span class="by">sethammons</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378214">parent</a><span>|</span><a href="#38377115">next</a><span>|</span><label class="collapse" for="c-38378409">[-]</label><label class="expand" for="c-38378409">[5 more]</label></div><br/><div class="children"><div class="content">&gt; should just be a government effort<p>And the controlling party de jour will totally not tweak it to side with their agenda, I&#x27;m sure. &lt;&#x2F;s&gt;</div><br/><div id="38378454" class="c"><input type="checkbox" id="c-38378454" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378409">parent</a><span>|</span><a href="#38377115">next</a><span>|</span><label class="collapse" for="c-38378454">[-]</label><label class="expand" for="c-38378454">[4 more]</label></div><br/><div class="children"><div class="content">uh. We&#x27;re arguing about _who is controlling AI_.<p>What do you image a neutral party does? If youu&#x27;re talking about safety, don&#x27;t you think there should be someone sitting on a boar dsomewhere, contemplating _what should the AI feed today?_<p>Seriously, why is a non profit, or a business or whatever any different than a government?<p>I get it: there&#x27;s all kinds of governments, but now theres all kind of businesses.<p>The point of putting it in the governments hand is a defacto acknowledgement that it&#x27;s a utility.<p>Take other utilities, any time you give a prive org a right to control whether or not you get electricity or water, whats the outcome? Rarely good.<p>If AI is suppose to help society, that&#x27;s the purview of the government. That&#x27;s all, you can imagine it&#x27;s the chinese government, or the russian, or the american or the canadian. They&#x27;re all _going to do it_, thats _going to happen_, and if a business gets there first, _what is the difference if it&#x27;s such a powerful device_.<p>I get it, people look dimly on governments, but guess what: they&#x27;re just as powerful as some organization that gets billions of dollars to effect society. Why is it suddenly a boogeyman?</div><br/><div id="38378583" class="c"><input type="checkbox" id="c-38378583" checked=""/><div class="controls bullet"><span class="by">sethammons</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378454">parent</a><span>|</span><a href="#38377115">next</a><span>|</span><label class="collapse" for="c-38378583">[-]</label><label class="expand" for="c-38378583">[3 more]</label></div><br/><div class="children"><div class="content">I find any government to be more of a boogeyman than any private company because the government has the right to violence and companies come and go at a faster rate.</div><br/><div id="38378627" class="c"><input type="checkbox" id="c-38378627" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378583">parent</a><span>|</span><a href="#38382174">next</a><span>|</span><label class="collapse" for="c-38378627">[-]</label><label class="expand" for="c-38378627">[1 more]</label></div><br/><div class="children"><div class="content">Ok, and if Raytheon builds an AI and tells a government &quot;trust us, its safe&quot;, arn&#x27;t you just letting them create a scape goat via the government?<p>Seriously, Businesses simply dont have the history that governments do. They&#x27;re just as capable of violence.<p><a href="https:&#x2F;&#x2F;utopia.org&#x2F;guide&#x2F;crime-controversy-nestles-5-biggest-scandals-explained&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;utopia.org&#x2F;guide&#x2F;crime-controversy-nestles-5-biggest...</a><p>All you&#x27;re identifying is &quot;government has a longer history of violence than Businesses&quot;</div><br/></div></div><div id="38382174" class="c"><input type="checkbox" id="c-38382174" checked=""/><div class="controls bullet"><span class="by">kjkjadksj</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378583">parent</a><span>|</span><a href="#38378627">prev</a><span>|</span><a href="#38377115">next</a><span>|</span><label class="collapse" for="c-38382174">[-]</label><label class="expand" for="c-38382174">[1 more]</label></div><br/><div class="children"><div class="content">The municipal utility provider has a right to violence? The park service? Where do you live? Los Angeles during Blade Runner?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38377115" class="c"><input type="checkbox" id="c-38377115" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38378214">prev</a><span>|</span><a href="#38376821">next</a><span>|</span><label class="collapse" for="c-38377115">[-]</label><label class="expand" for="c-38377115">[1 more]</label></div><br/><div class="children"><div class="content">Great comment.<p>In a way AI is no different from old school intelligence, aka experts.<p>&quot;We need to have oversight over what the scientists are researching, so that it&#x27;s always to the public benefit&quot;<p>&quot;How do we really know if the academics&#x2F;engineers&#x2F;doctors have everyone&#x27;s interest in mind?&quot;<p>That kind of thing has been a thought since forever, and politicians of all sorts have had to contend with it.</div><br/></div></div><div id="38376821" class="c"><input type="checkbox" id="c-38376821" checked=""/><div class="controls bullet"><span class="by">loup-vaillant</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38377115">prev</a><span>|</span><a href="#38376639">next</a><span>|</span><label class="collapse" for="c-38376821">[-]</label><label class="expand" for="c-38376821">[1 more]</label></div><br/><div class="children"><div class="content">Note how what you said also apply to the search &amp; recommendation engines that are in widespread use <i>today</i>.</div><br/></div></div><div id="38376639" class="c"><input type="checkbox" id="c-38376639" checked=""/><div class="controls bullet"><span class="by">lukevp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376821">prev</a><span>|</span><a href="#38376359">next</a><span>|</span><label class="collapse" for="c-38376639">[-]</label><label class="expand" for="c-38376639">[1 more]</label></div><br/><div class="children"><div class="content">AI isn’t a precondition for partisanship. How do you know Google isn’t showing you biased search results? Or Wikipedia?</div><br/></div></div><div id="38376359" class="c"><input type="checkbox" id="c-38376359" checked=""/><div class="controls bullet"><span class="by">gorwell</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376639">prev</a><span>|</span><a href="#38376347">next</a><span>|</span><label class="collapse" for="c-38376359">[-]</label><label class="expand" for="c-38376359">[1 more]</label></div><br/><div class="children"><div class="content">“I trust that every animal here appreciates the sacrifice that Comrade Napoleon has made in taking this extra labour upon himself. Do not imagine, comrades, that leadership is a pleasure! On the contrary, it is a deep and heavy responsibility. No one believes more firmly than Comrade Napoleon that all animals are equal. He would be only too happy to let you make your decisions for yourselves. But sometimes you might make the wrong decisions, comrades, and then where should we be?”</div><br/></div></div><div id="38376598" class="c"><input type="checkbox" id="c-38376598" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376347">prev</a><span>|</span><a href="#38381630">next</a><span>|</span><label class="collapse" for="c-38376598">[-]</label><label class="expand" for="c-38376598">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pretty soon AI will be an expert at subtly steering you toward thinking&#x2F;voting for whatever the &quot;safety&quot; experts want.<p>You are absolutely right. There is no question about that the AI will be an expert at subtly steering individuals and the whole society in whichever direction it does.<p>This is the core concept of safety. If no-one steers the machine then the machine will steer us.<p>You might disagree with the current flavour of steering the current safety experts give it, and that is all right and in fact part of the process. But surely you have your own values. Some things you hold dear to you. Some outcomes you prefer over others. Are you not interested in the ability to make these powerful machines if not support those values, at least not undermine them? If so you are interested in AI safety! You want safe AIs. (Well, alternatively you prefer no AIs, which is in fact a form of safe AI. Maybe the only one we have mastered in some form so far.)<p>&gt; because of X, we need to invade this country.<p>It sounds like you value peace? Me too! Imagine if we could pool together our resources to have an AI which is subtly manipulating society into the direction of more peace. Maybe it would do muckraking investigative journalism exposing the misdeeds of the military-industrial complex? Maybe it would elevate through advertisement peace loving authors and give a counter narrative to the war drums? Maybe it would offer to act as an intermediary in conflict resolution around the world?<p>If we were to do that, &quot;ai safety&quot; and &quot;alignment&quot; is crucial. I don&#x27;t want to give my money to an entity who then gets subjugated by some intelligence agency to sow more war. That would be against my wishes. I want to know that it is serving me and you in our shared goal of &quot;more peace, less war&quot;.<p>Now you might say: &quot;I find the idea of anyone, or anything manipulating me and society disgusting. Everyone should be left to their own devices.&quot;. And I agree on that too. But here is the bad news: we are already manipulated. Maybe it doesn&#x27;t work on you, maybe it doesn&#x27;t work on me, but it sure as hell works. There are powerful entities financially motivated to keep the wars going. This is a huuuge industry. They might not do it with AIs (for now), because propaganda machines made of meat work currently better. They might change to using AIs when that works better. Or what is more likely employ a hybrid approach. Wishing that nobody gets manipulated is frankly not an option on offer.<p>How does that sound as a passionate argument for AI safety?</div><br/></div></div><div id="38381630" class="c"><input type="checkbox" id="c-38381630" checked=""/><div class="controls bullet"><span class="by">deanCommie</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376598">prev</a><span>|</span><a href="#38376915">next</a><span>|</span><label class="collapse" for="c-38381630">[-]</label><label class="expand" for="c-38381630">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m convinced there is a certain class of people who gravitate to positions of power, like &quot;moderators&quot;, (partisan) journalists,<p>And there is also a class of people that resist all moderation on principle even when it&#x27;s ultimately for their benefit. See, Americans whenever the FDA brings up any questions of health:<p>* &quot;Gas Stoves may increase Asthma.&quot; -&gt; &quot;Don&#x27;t you tread on me, you can take my gas stove from my cold dead hands!&quot;<p>Of course it&#x27;s ridiculous - we&#x27;ve been through this before with Asbestos, Lead Paint, Seatbelts, even the very idea of the EPA cleaning up the environment. It&#x27;s not a uniquely American problem, but America tends to attract and offer success to the folks that want to ignore these on principles.<p>For every Asbestos there is a Plastic Straw Ban which is essentially virtue signalling by the types of folks you mention - meaningless in the grand scheme of things for the stated goal, massive in terms of inconvenience.<p>But the existence of Plastic Straw Ban does not make Asbestos, CFCs, or Lead Paint any safer.<p>Likewise, the existence of people that gravitate to positions of power and middle management does not negate the need for actual moderation in dozens of societal scenarios. Online forums, Social Networks, and...well I&#x27;m not sure about AI. Because I&#x27;m not sure what AI is, it&#x27;s changing daily. The point is that I don&#x27;t think it&#x27;s fair to assume that anyone that is interested in safety and moderation is doing it out of a misguided attempt to pursue power, and instead is actively trying to protect and improve humanity.<p>Lastly, your portrayal of journalists as power figures is actively dangerous to the free press. This was never stated this directly until the Trump years - even when FOX News was berating Obama daily for meaningless subjects. When the TRUTH becomes a partisan subject, then reporting on that truth becomes a dangerous activity. Journalists are MOSTLY  in the pursuit of truth.</div><br/></div></div><div id="38376915" class="c"><input type="checkbox" id="c-38376915" checked=""/><div class="controls bullet"><span class="by">pk-protect-ai</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38381630">prev</a><span>|</span><a href="#38375892">next</a><span>|</span><label class="collapse" for="c-38376915">[-]</label><label class="expand" for="c-38376915">[1 more]</label></div><br/><div class="children"><div class="content">I just had a conversation about this like two weeks ago. The current trend in AI &quot;safety&quot; is a form of brainwashing, not only for AI but also for future generations shaping their minds. There are several aspects:<p>1. Censorship of information<p>2. Cover-up of the biases and injustices in our society<p>This limits creativity, critical thinking, and the ability to challenge existing paradigms. By controlling the narrative and the data that AI systems are exposed to, we risk creating a generation of both machines and humans that are unable to think outside the box or question the status quo. This could lead to a stagnation of innovation and a lack of progress in addressing the complex issues that face our world.<p>Furthermore, there will be a significant increase in mass manipulation of the public into adopting the way of thinking that the elites desire. It is already done by mass media, and we can actually witness this right now with this case. Imagine a world where youngsters no longer use search engines and rely solely on the information provided by AI. By shaping the information landscape, those in power will influence public opinion and decision-making on an even larger scale, leading to a homogenized culture where dissenting voices are silenced. This not only undermines the foundations of a diverse and dynamic society but also poses a threat to democracy and individual freedoms.<p>Guess what? I just have checked above text for the biases against GPT-4 Turbo, and it appears to be I&#x27;m a moron:<p>1. *Confirmation Bias*: The text assumes that AI safety measures are inherently negative and equates them with brainwashing, which may reflect the author&#x27;s preconceived beliefs about AI safety without considering potential benefits.
2. *Selection Bias*: The text focuses on negative aspects of AI safety, such as censorship and cover-up, without acknowledging any positive aspects or efforts to mitigate these issues.
3. *Alarmist Bias*: The language used is somewhat alarmist, suggesting a dire future without presenting a balanced view that includes potential safeguards or alternative outcomes.
4. *Conspiracy Theory Bias*: The text implies that there is a deliberate effort by &quot;elites&quot; to manipulate the masses, which is a common theme in conspiracy theories.
5. *Technological Determinism*: The text suggests that technology (AI in this case) will determine social and cultural outcomes without considering the role of human agency and decision-making in shaping technology.
6. *Elitism Bias*: The text assumes that a group of &quot;elites&quot; has the power to control public opinion and decision-making, which may oversimplify the complex dynamics of power and influence in society.
7. *Cultural Pessimism*: The text presents a pessimistic view of the future culture, suggesting that it will become homogenized and that dissent will be silenced, without considering the resilience of cultural diversity and the potential for resistance.<p>Huh, just look at what&#x27;s happening in North Korea, Russia, Iran, China, and actually in any totalitarian country. Unfortunately, the same thing happens worldwide, but in democratic countries, it is just subtle brainwashing with a &quot;humane&quot; facade. No individual or minority group can withstand the power of the state and a mass-manipulated public.<p>Bonhoeffer&#x27;s theory of stupidity:
 <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ww47bR86wSc&amp;pp=ygUTdGhlb3J5IG9mIHN0dXBpZGl0eQ%3D%3D" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ww47bR86wSc&amp;pp=ygUTdGhlb3J5I...</a></div><br/></div></div></div></div><div id="38375892" class="c"><input type="checkbox" id="c-38375892" checked=""/><div class="controls bullet"><span class="by">cornholio</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375959">prev</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38375892">[-]</label><label class="expand" for="c-38375892">[14 more]</label></div><br/><div class="children"><div class="content">What the general public thinks is irrelevant here. The deciding factor was the staff mutiny, without which the organization is an empty shell. And the staff sided with those who aim for rapid real world impact, with directly affects their career and stock options etc.<p>It&#x27;s also naive to think it was a struggle for principles. The rapid commercialization vs. principles is what the actors claim to rally their respective troops, in reality it was probably a naked power grab, taking advantage of the weak and confuse org structure. Quite an ill prepared move, the &quot;correct&quot; way to oust Altman was to hamstring him in the board and enforce a more and more ceremonial role until he would have quit by himself.</div><br/><div id="38376058" class="c"><input type="checkbox" id="c-38376058" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38376058">[-]</label><label class="expand" for="c-38376058">[7 more]</label></div><br/><div class="children"><div class="content">&gt; <i>deciding factor was the staff mutiny</i><p>The staff never mutinied. They <i>threatened</i> to mutiny. That&#x27;s a big difference!<p>Yesterday, I compared these rebels to Shockley&#x27;s &quot;traitorous eight&quot; [1]. But the traitorous eight actually rebelled. These folk put their name on a piece of paper, options and profit participation units safely held in the other hand.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348123">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348123</a></div><br/><div id="38376086" class="c"><input type="checkbox" id="c-38376086" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376058">parent</a><span>|</span><a href="#38377724">next</a><span>|</span><label class="collapse" for="c-38376086">[-]</label><label class="expand" for="c-38376086">[5 more]</label></div><br/><div class="children"><div class="content">Not only that, consider the situation now, where Sam has returned as CEO. The ones who didn&#x27;t sign will have some explaining to do.<p>The safest option was to sign the paper, once the snowball started rolling. There was nothing much to lose, and a lot to gain.</div><br/><div id="38376204" class="c"><input type="checkbox" id="c-38376204" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376086">parent</a><span>|</span><a href="#38377724">next</a><span>|</span><label class="collapse" for="c-38376204">[-]</label><label class="expand" for="c-38376204">[4 more]</label></div><br/><div class="children"><div class="content">People have families, mortgages, debt, etc. Sure, these people are probably well compensated, but it is ludicrous to state that everyone has the stability that they can leave their job at a moment&#x27;s notice because the boss is gone.</div><br/><div id="38376230" class="c"><input type="checkbox" id="c-38376230" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376204">parent</a><span>|</span><a href="#38376237">next</a><span>|</span><label class="collapse" for="c-38376230">[-]</label><label class="expand" for="c-38376230">[2 more]</label></div><br/><div class="children"><div class="content">Didn’t they all have offers at Microsoft?</div><br/><div id="38376833" class="c"><input type="checkbox" id="c-38376833" checked=""/><div class="controls bullet"><span class="by">reverius42</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376230">parent</a><span>|</span><a href="#38376237">next</a><span>|</span><label class="collapse" for="c-38376833">[-]</label><label class="expand" for="c-38376833">[1 more]</label></div><br/><div class="children"><div class="content">I think not at the time they would have signed the letter? Though it&#x27;s hard to keep up with the whirlwind of news.</div><br/></div></div></div></div><div id="38376237" class="c"><input type="checkbox" id="c-38376237" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376204">parent</a><span>|</span><a href="#38376230">prev</a><span>|</span><a href="#38377724">next</a><span>|</span><label class="collapse" for="c-38376237">[-]</label><label class="expand" for="c-38376237">[1 more]</label></div><br/><div class="children"><div class="content">They didn&#x27;t actually leave, they just signed the pledge threatening to. Furthermore, they mostly signed after the details of the Microsoft offer were revealed.</div><br/></div></div></div></div></div></div><div id="38377724" class="c"><input type="checkbox" id="c-38377724" checked=""/><div class="controls bullet"><span class="by">cornholio</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376058">parent</a><span>|</span><a href="#38376086">prev</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38377724">[-]</label><label class="expand" for="c-38377724">[1 more]</label></div><br/><div class="children"><div class="content">I think you are downplaying the risk they took significantly, this could have easily gone the other way.<p>Stock options usually have a limited time window to exercise, depending on their strike price they could have been faced with raising a few hundred thousand in 30 days, to put into a company that has an uncertain future, or risk losing everything. The contracts are likely full of holes not in favor of the employees, and for participating in an action that attempted to bankrupt their employer there would have been years of litigation ahead before they would have seen any cent. Not because OpenAI would have been right to punish them, but because it <i>could</i> and the latent threat to do it is what keeps people in line.</div><br/></div></div></div></div><div id="38376266" class="c"><input type="checkbox" id="c-38376266" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376058">prev</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376266">[-]</label><label class="expand" for="c-38376266">[4 more]</label></div><br/><div class="children"><div class="content">The board did it wrong. If you are going to fire a CEO, then do it quickly, but:<p>1. Have some explanation<p>2. Have a new CEO who is willing and able to do the job<p>If you can&#x27;t do these things, then you probably shouldn&#x27;t be firing the CEO.</div><br/><div id="38376332" class="c"><input type="checkbox" id="c-38376332" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376266">parent</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376332">[-]</label><label class="expand" for="c-38376332">[3 more]</label></div><br/><div class="children"><div class="content">Or (3), shut down the company. OpenAI&#x27;s non-profit board had this power! They weren&#x27;t an advisory committee, they were the legal and rightful owner of its for-profit subsidiary. They had the right to do what they wanted, and people forgetting to put a fucking quorum requirement into the bylaws is beyond abysmal for a $10+ billion investment.<p>Nobody comes out of this looking good. Nobody. If the board thought there was existential risk, they should have been willing to commit to it. Hopefully sensible start-ups can lure people away from their PPUs, now evident for the mockery they always were. It&#x27;s beyond obvious this isn&#x27;t, and will never be, a trillion dollar company. That&#x27;s the only hope this $80+ billion Betamax valuation rested on.<p>I&#x27;m all for a comedy. But this was a waste of everyones&#x27; time. At least they could have done it in private.</div><br/><div id="38376439" class="c"><input type="checkbox" id="c-38376439" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376332">parent</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376439">[-]</label><label class="expand" for="c-38376439">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same thing, really. Even if you want to shut down the company you need a CEO to shut it down! Like John Ray who is shutting down FTX.<p>There isn&#x27;t just a big red button that says &quot;destroy company&quot; in the basement. There will be partnerships to handle, severance, facilities, legal issues, maybe lawsuits, at the very least a lot of people to communicate with. Companies don&#x27;t just shut themselves down, at least not multi billion dollar companies.</div><br/><div id="38380253" class="c"><input type="checkbox" id="c-38380253" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376439">parent</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38380253">[-]</label><label class="expand" for="c-38380253">[1 more]</label></div><br/><div class="children"><div class="content">You’re right. But in an emergency, there is a close option which is to put the company into receivership and hire an outside law firm to advise. At that point, the board becomes the executive council.</div><br/></div></div></div></div></div></div></div></div><div id="38375945" class="c"><input type="checkbox" id="c-38375945" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376266">prev</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38375945">[-]</label><label class="expand" for="c-38375945">[2 more]</label></div><br/><div class="children"><div class="content">I think this is an oversimplification and that although the decel faction definitely lost, there are still three independent factions left standing:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;edit?id=38375767">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;edit?id=38375767</a><p>It will be super interesting to see the subtle struggles for influence between these three.</div><br/><div id="38376168" class="c"><input type="checkbox" id="c-38376168" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375945">parent</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38376168">[-]</label><label class="expand" for="c-38376168">[1 more]</label></div><br/><div class="children"><div class="content">Adam is likely still on the &quot;decel&quot; faction (although it&#x27;s unclear whether this is an accurate representation of his beliefs) so I wouldn&#x27;t really say they lost yet.<p>I&#x27;m not sure what faction Bret and Larry will be on. Sam will still have power by virtue of being CEO and aligned with the employees.</div><br/></div></div></div></div></div></div><div id="38375964" class="c"><input type="checkbox" id="c-38375964" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375892">prev</a><span>|</span><a href="#38375928">next</a><span>|</span><label class="collapse" for="c-38375964">[-]</label><label class="expand" for="c-38375964">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>No, if OpenAI is reaching singularity, so are Google, Meta, and Baidu etc. so proper course of action would be to loop in NSA&#x2F;White House. You&#x27;ll loop in Google, Meta, MSFT and will start mitigation steps. Slowing down OpenAI will hurt the company if assumption is wrong and won&#x27;t help if it is true.<p>I believe this is more a fight of ego and power than principles and direction.</div><br/><div id="38376558" class="c"><input type="checkbox" id="c-38376558" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375964">parent</a><span>|</span><a href="#38376161">next</a><span>|</span><label class="collapse" for="c-38376558">[-]</label><label class="expand" for="c-38376558">[2 more]</label></div><br/><div class="children"><div class="content">&gt; so proper course of action would be to loop in NSA&#x2F;White House<p>Eh? That would be an awful idea. They have no expertise on this and government institutions like thus are misaligned with the rest of humanity by design. E.g. NSA recruits patriots and has many systems, procedures and cultural aspects in place to ensure it keeps up its mission of spying on everyone.</div><br/><div id="38376780" class="c"><input type="checkbox" id="c-38376780" checked=""/><div class="controls bullet"><span class="by">the_gipsy</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376558">parent</a><span>|</span><a href="#38376161">next</a><span>|</span><label class="collapse" for="c-38376780">[-]</label><label class="expand" for="c-38376780">[1 more]</label></div><br/><div class="children"><div class="content">And Google, Facebook, MSFT, Apple, are much more misaligned.</div><br/></div></div></div></div><div id="38376161" class="c"><input type="checkbox" id="c-38376161" checked=""/><div class="controls bullet"><span class="by">ragequittah</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375964">parent</a><span>|</span><a href="#38376558">prev</a><span>|</span><a href="#38375928">next</a><span>|</span><label class="collapse" for="c-38376161">[-]</label><label class="expand" for="c-38376161">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Slowing down OpenAI will hurt the company if assumption is wrong and won&#x27;t help if it is true.<p>Personally as I watched the nukes be lobbed I&#x27;d rather not be the person who helped lob them. And hope to god others look at the same problem (a misaligned AI that is making insane decisions) with the exact same lens. It seems to have worked for nuclear weapons since WW2, one can that we learned a lesson there as a species.<p>The Russian Stanislav Petrov who saved the world comes to mind.&quot;Well the Americans have done it anyways&quot; was the motivation and he didn&#x27;t launch. The cost of error was simply too great.</div><br/></div></div></div></div><div id="38375928" class="c"><input type="checkbox" id="c-38375928" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375964">prev</a><span>|</span><a href="#38376107">next</a><span>|</span><label class="collapse" for="c-38375928">[-]</label><label class="expand" for="c-38375928">[5 more]</label></div><br/><div class="children"><div class="content">This is a coherent narrative, but it doesn&#x27;t explain the bizarre and aggressively worded initial press release.<p>Things perhaps could&#x27;ve been different if they&#x27;d pointed to the founding principles &#x2F; charter and said the board had an intractable difference of opinion with Sam over their interpretation, but then proceeded to thank him profusely for all the work he&#x27;d done. Although a suitable replacement CEO out the gate and assurances that employees&#x27; PPUs would still see a liquidity event would doubtless have been even more important than a competent statement.<p>Initially I thought for sure Sam had done something criminal, that&#x27;s how bad the statement was.</div><br/><div id="38376155" class="c"><input type="checkbox" id="c-38376155" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375928">parent</a><span>|</span><a href="#38376107">next</a><span>|</span><label class="collapse" for="c-38376155">[-]</label><label class="expand" for="c-38376155">[4 more]</label></div><br/><div class="children"><div class="content">Apparently the FBI thought he&#x27;d done something wrong too, because they called up the board to start an investigation but they didn&#x27;t have anything.<p><a href="https:&#x2F;&#x2F;x.com&#x2F;nivi&#x2F;status&#x2F;1727152963695808865?s=46" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;nivi&#x2F;status&#x2F;1727152963695808865?s=46</a></div><br/><div id="38385649" class="c"><input type="checkbox" id="c-38385649" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376155">parent</a><span>|</span><a href="#38385700">next</a><span>|</span><label class="collapse" for="c-38385649">[-]</label><label class="expand" for="c-38385649">[2 more]</label></div><br/><div class="children"><div class="content">The FBI doesn&#x27;t investigate things like this on their own, and they <i>definitely</i> do not announce them in the press. The questions you should be asking are (1) who called in the FBI and has the clout to get them to open an investigation into something that obviously has 0% chance of being a federal felony-level crime worth the FBI&#x27;s time, and (2) who then leaked that &#x27;investigation&#x27; to the press?</div><br/><div id="38386435" class="c"><input type="checkbox" id="c-38386435" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38385649">parent</a><span>|</span><a href="#38385700">next</a><span>|</span><label class="collapse" for="c-38386435">[-]</label><label class="expand" for="c-38386435">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, the SDNY. They do do things on their own. I expect the people they called leaked it.</div><br/></div></div></div></div><div id="38385700" class="c"><input type="checkbox" id="c-38385700" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376155">parent</a><span>|</span><a href="#38385649">prev</a><span>|</span><a href="#38376107">next</a><span>|</span><label class="collapse" for="c-38385700">[-]</label><label class="expand" for="c-38385700">[1 more]</label></div><br/><div class="children"><div class="content">The FBI is not mentioned in that tweet. We don&#x27;t need to telephone game anonymous leaks that are already almost certainly self-serving propaganda.</div><br/></div></div></div></div></div></div><div id="38376107" class="c"><input type="checkbox" id="c-38376107" checked=""/><div class="controls bullet"><span class="by">eslaught</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375928">prev</a><span>|</span><a href="#38375822">next</a><span>|</span><label class="collapse" for="c-38376107">[-]</label><label class="expand" for="c-38376107">[6 more]</label></div><br/><div class="children"><div class="content">Ok, serious question. If you think the threat is real, how are we not already screwed?<p>OpenAI is one of half a dozen teams [0] actively working on this problem, all funded by large public companies with lots of money and lots of talent. They made unique contributions, sure. But they&#x27;re not <i>that</i> far ahead. If they stumble, surely one of the others will take the lead. Or maybe they will anyway, because who&#x27;s to say where the next major innovation will come from?<p>So what I don&#x27;t get about these reactions (allegedly from the board, and expressed here) is, if you interpret the threat as a real one, why are you acting like OpenAI has some infallible lead? This is not an excuse to govern OpenAI poorly, but let&#x27;s be honest: if the company slows down the most likely outcome by far is that they&#x27;ll cede the lead to someone else.<p>[0]: To be clear, there are definitely more. Those are just the <i>large</i> and <i>public</i> teams with existing products within some reasonable margin of OpenAI&#x27;s quality.</div><br/><div id="38376623" class="c"><input type="checkbox" id="c-38376623" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376331">next</a><span>|</span><label class="collapse" for="c-38376623">[-]</label><label class="expand" for="c-38376623">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you think the threat is real, how are we not already screwed?<p>That&#x27;s the current Yudkowsky view. That it&#x27;s essentially impossible at this point and we&#x27;re doomed, but we might as well try anyway as its more &quot;dignified&quot; to die trying.<p>I&#x27;m a bit more optimistic myself.</div><br/></div></div><div id="38376331" class="c"><input type="checkbox" id="c-38376331" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376623">prev</a><span>|</span><a href="#38376777">next</a><span>|</span><label class="collapse" for="c-38376331">[-]</label><label class="expand" for="c-38376331">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know. I think being realistic, only OpenAI and Google have the depth and breadth of expertise to develop general AI.<p>Most of the new AI startups are one trick ponies obsessively focused on LLM&#x27;s. LLM&#x27;s are only one piece of the puzzle.</div><br/><div id="38383613" class="c"><input type="checkbox" id="c-38383613" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376331">parent</a><span>|</span><a href="#38379047">next</a><span>|</span><label class="collapse" for="c-38383613">[-]</label><label class="expand" for="c-38383613">[1 more]</label></div><br/><div class="children"><div class="content">Anthropic is made up of former top OpenAI employees, has similar funding, and has produced similarly capable models on a similar timeline. The Claude series is neck and neck with GPT.</div><br/></div></div><div id="38379047" class="c"><input type="checkbox" id="c-38379047" checked=""/><div class="controls bullet"><span class="by">metanonsense</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376331">parent</a><span>|</span><a href="#38383613">prev</a><span>|</span><a href="#38376777">next</a><span>|</span><label class="collapse" for="c-38379047">[-]</label><label class="expand" for="c-38379047">[1 more]</label></div><br/><div class="children"><div class="content">I would add Meta to this list, in particular because Yann LeCun is the most vocal critic of LLM one-ponyism.</div><br/></div></div></div></div><div id="38376777" class="c"><input type="checkbox" id="c-38376777" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376331">prev</a><span>|</span><a href="#38375822">next</a><span>|</span><label class="collapse" for="c-38376777">[-]</label><label class="expand" for="c-38376777">[1 more]</label></div><br/><div class="children"><div class="content">The risk&#x2F;scenario of singularity is that there will be just one winner and they will be able to prevent everyone else from building their own agi</div><br/></div></div></div></div><div id="38375822" class="c"><input type="checkbox" id="c-38375822" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376107">prev</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38375822">[-]</label><label class="expand" for="c-38375822">[7 more]</label></div><br/><div class="children"><div class="content">For all the talk about responsible progress, the irony of their inability to align even their own incentives in this enterprise deserves ridicule. It&#x27;s a big blow to their credibility and questions whatever ethical concerns they hold.</div><br/><div id="38375907" class="c"><input type="checkbox" id="c-38375907" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375822">parent</a><span>|</span><a href="#38376642">next</a><span>|</span><label class="collapse" for="c-38375907">[-]</label><label class="expand" for="c-38375907">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fear driven as much as moral, which in an emotional humans brain tends to triggers personal ambition to solve it ASAP. A more rational one would realize you need more than just a couple board members to win a major ideological battle.<p>At a minimum something that doesn&#x27;t immediately result in a backlash where 90% of the engineers most responsible for recent AI dev want you gone, when you&#x27;re whole plan is to control what those people do.</div><br/></div></div><div id="38376642" class="c"><input type="checkbox" id="c-38376642" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375822">parent</a><span>|</span><a href="#38375907">prev</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376642">[-]</label><label class="expand" for="c-38376642">[5 more]</label></div><br/><div class="children"><div class="content">Alignment is considered an extremely hard problem for a reason. It&#x27;s already nigh impossible when you&#x27;re dealing with humans.<p>Btw: do you think ridicule eould be helpful here?</div><br/><div id="38376694" class="c"><input type="checkbox" id="c-38376694" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376642">parent</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376694">[-]</label><label class="expand" for="c-38376694">[4 more]</label></div><br/><div class="children"><div class="content">I can see how ridicule of this specific instance could be the best medicine for an optimal outcome, even by a utilitarian argument, which I generally don&#x27;t like to make by the way. It is indeed nigh impossible, which is kind of my point. They could have shown more humility. If anything, this whole debacle has been a moral victory for e&#x2F;acc, seeing how the brightest of minds are at a loss dealing with alignment anyway.</div><br/><div id="38376922" class="c"><input type="checkbox" id="c-38376922" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376694">parent</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376922">[-]</label><label class="expand" for="c-38376922">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how the conclusion of this is &quot;so we should proceed with AI&quot; rather than &quot;so we should immediately outlaw all foundation model training&quot;. Clearly corporate self-governance has failed completely.</div><br/></div></div></div></div></div></div></div></div><div id="38376007" class="c"><input type="checkbox" id="c-38376007" checked=""/><div class="controls bullet"><span class="by">jkaplan</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375822">prev</a><span>|</span><a href="#38375744">next</a><span>|</span><label class="collapse" for="c-38376007">[-]</label><label class="expand" for="c-38376007">[3 more]</label></div><br/><div class="children"><div class="content">I feel like the &quot;safety&quot; crowd lost the PR battle, in part, because of framing it as &quot;safety&quot; and over-emphasizing on existential risk. Like you say, not that many people truly take that seriously right now.<p>But even if those types of problems don&#x27;t surface anytime soon, this wave of AI is almost certainly going to be a powerful, society-altering technology; potentially more powerful than any in decades. We&#x27;ve all seen what can happen when powerful tech is put in the hands of companies and a culture whose only incentives are growth, revenue, and valuation -- the results can be not great. And I&#x27;m pretty sure a lot of the general public (and open AI staff) care about THAT.<p>For me, the safety&#x2F;existential stuff is just one facet of the general problem of trying to align tech companies + their technology with humanity-at-large better than we have been recently. And that&#x27;s especially important for landscape-altering tech like AI, even if it&#x27;s not literally existential (although it may be).</div><br/><div id="38378311" class="c"><input type="checkbox" id="c-38378311" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376007">parent</a><span>|</span><a href="#38376702">next</a><span>|</span><label class="collapse" for="c-38378311">[-]</label><label class="expand" for="c-38378311">[1 more]</label></div><br/><div class="children"><div class="content">No one who wants to capitalize on AI appears to take it seriously. Especially how grey that safety is. I&#x27;m not concerned AI is going to nuke humanity, I&#x27;m more concerned it&#x27;ll re-enforce racism, bias, and the rest of human&#x27;s irrational activities because it&#x27;s _blindly_ using existing history to predict future.<p>We&#x27;ve seen it in the past decade in multiple cases. That&#x27;s safety.<p>The decision that the topic discusses means Business is winning, and they absolutely will re-enforce the idea that the only care is that these systems allow them to re-enforce the business cases.<p>That&#x27;s bad, and unsafe.</div><br/></div></div><div id="38376702" class="c"><input type="checkbox" id="c-38376702" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376007">parent</a><span>|</span><a href="#38378311">prev</a><span>|</span><a href="#38375744">next</a><span>|</span><label class="collapse" for="c-38376702">[-]</label><label class="expand" for="c-38376702">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Like you say, not that many people truly take that seriously right now.<p>Eh? Polls on the matter show widespread public support for a pause due to safety concerns.</div><br/></div></div></div></div><div id="38375744" class="c"><input type="checkbox" id="c-38375744" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376007">prev</a><span>|</span><a href="#38376404">next</a><span>|</span><label class="collapse" for="c-38375744">[-]</label><label class="expand" for="c-38375744">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  I think only a minority of the general public truly cares about AI Safety, the rest are happy seeing ChatGPT helping with their homework<p>Not just the public, but also the employees. I doubt there are more than a handful of employees who care about AI Safety.</div><br/><div id="38376690" class="c"><input type="checkbox" id="c-38376690" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375744">parent</a><span>|</span><a href="#38375932">next</a><span>|</span><label class="collapse" for="c-38376690">[-]</label><label class="expand" for="c-38376690">[1 more]</label></div><br/><div class="children"><div class="content">Nah, a number do, including Sam himself and the entire leadership.<p>They just have different ideas about one or more of: how likely another team is to successfully charge ahead while ignoring safety, how close we are to AGI, how hard alignment is.</div><br/></div></div><div id="38375902" class="c"><input type="checkbox" id="c-38375902" checked=""/><div class="controls bullet"><span class="by">justrealist</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375744">parent</a><span>|</span><a href="#38375815">prev</a><span>|</span><a href="#38376404">next</a><span>|</span><label class="collapse" for="c-38375902">[-]</label><label class="expand" for="c-38375902">[1 more]</label></div><br/><div class="children"><div class="content">the team is mostly e&#x2F;acc<p>so you could say they intentionally don&#x27;t see safety as the end in itself, although I wouldn&#x27;t quite say they don&#x27;t <i>care</i>.</div><br/></div></div></div></div><div id="38376404" class="c"><input type="checkbox" id="c-38376404" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375744">prev</a><span>|</span><a href="#38376297">next</a><span>|</span><label class="collapse" for="c-38376404">[-]</label><label class="expand" for="c-38376404">[2 more]</label></div><br/><div class="children"><div class="content">One funny thing about this mess is that &quot;Team Helen&quot; has never mentioned anything about safety, and Emmett said &quot;The board did <i>not</i> remove Sam over any specific disagreement on safety&quot;.<p>The reason everyone thinks it&#x27;s about safety seems largely because a lot of e&#x2F;acc people on Twitter keep bringing it up as a strawman.<p>Of course, it might end up that it really was about safety in the end, but for now I still haven&#x27;t seen any evidence. The story about Sam trying to get board control and the board retaliating seems more plausible given what&#x27;s actually happened.</div><br/><div id="38390821" class="c"><input type="checkbox" id="c-38390821" checked=""/><div class="controls bullet"><span class="by">rcMgD2BwE72F</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376404">parent</a><span>|</span><a href="#38376297">next</a><span>|</span><label class="collapse" for="c-38390821">[-]</label><label class="expand" for="c-38390821">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The story about Sam trying to get board control and the board retaliating seems more plausible given what&#x27;s actually happened.<p>What story? Any link?</div><br/></div></div></div></div><div id="38376297" class="c"><input type="checkbox" id="c-38376297" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376404">prev</a><span>|</span><a href="#38376483">next</a><span>|</span><label class="collapse" for="c-38376297">[-]</label><label class="expand" for="c-38376297">[7 more]</label></div><br/><div class="children"><div class="content">I am still a bit puzzled that it is so easy to turn a non-profit into a for profit company. I am sure everything they did is legal, but it feels like it shouldn&#x27;t be. Could Médecins Sans Frontières take in donations and then take that money to start a for profit hospital for plastics surgery? And the profits wouldn&#x27;t even go back to MSF, but instead somehow private investors will get the profits. The whole construct just seems wrong.</div><br/><div id="38376524" class="c"><input type="checkbox" id="c-38376524" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376297">parent</a><span>|</span><a href="#38376497">next</a><span>|</span><label class="collapse" for="c-38376524">[-]</label><label class="expand" for="c-38376524">[2 more]</label></div><br/><div class="children"><div class="content">I think it actually isn&#x27;t that easy. Compared to your example, the difference is that OpenAI&#x27;s for-profit is getting outside money from Microsoft, not money from non-profit OpenAI. Non-profit OpenAI is basically dealing with for-profit OpenAI as a external partner that happens to be aligned with their interests, paying the expensive bills and compute, while the non-profit can hold on to the IP.<p>You might be able to imagine a world where there was an external company that did the same thing as for-profit OpenAI, and OpenAI nonprofit partnered with them in order to get their AI ideas implemented (for free). OpenAI nonprofit is basically getting a good deal.<p>MSF could similarly create an external for-profit hospital, funded by external investors. The important thing is that the nonprofit (donated, tax-free) money doesn&#x27;t flow into the forprofit section.<p>Of course, there&#x27;s a lot of sketchiness in practice, which we can see in this situation with Microsoft influencing the direction of nonprofit OpenAI even though it shouldn&#x27;t be. I think there would have been real legal issues if the Microsoft deal had continued.</div><br/><div id="38381541" class="c"><input type="checkbox" id="c-38381541" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376524">parent</a><span>|</span><a href="#38376497">next</a><span>|</span><label class="collapse" for="c-38381541">[-]</label><label class="expand" for="c-38381541">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The important thing is that the nonprofit (donated, tax-free) money doesn&#x27;t flow into the forprofit section.<p>I am sure that is true. But the for-profit uses IP that was developed inside of the non-profit with (presumably) tax deductible donations. That IP should be valued somehow. But, as I said, I am sure they were somehow able to structure it in a way that is legal, but it has an illegal feel to it.</div><br/></div></div></div></div><div id="38376497" class="c"><input type="checkbox" id="c-38376497" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376297">parent</a><span>|</span><a href="#38376524">prev</a><span>|</span><a href="#38377646">next</a><span>|</span><label class="collapse" for="c-38376497">[-]</label><label class="expand" for="c-38376497">[2 more]</label></div><br/><div class="children"><div class="content">Well, if it aligned with their goals, sure I think.<p>Let&#x27;s make the situation a little different. Could MSF pay a private surgery with investors to perform reconstruction for someone?<p>Could they pay the surgery to perform some amount of work they deem aligns with their charter?<p>Could they invest in the surgery under the condition that they have some control over the practices there? (Edit - e.g. perform Y surgeries, only perform from a set of reconstructive ones, patients need to be approved as in need by a board, etc)<p>Raising private investment allows a non profit to shift cost and risk to other entities.<p>The problem really only comes when the structure doesn&#x27;t align with the intended goals - which is something distinct to the structure, just something non profits can do.</div><br/><div id="38379908" class="c"><input type="checkbox" id="c-38379908" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376497">parent</a><span>|</span><a href="#38377646">next</a><span>|</span><label class="collapse" for="c-38379908">[-]</label><label class="expand" for="c-38379908">[1 more]</label></div><br/><div class="children"><div class="content">The non-profit wasn&#x27;t raising private investment.</div><br/></div></div></div></div><div id="38377646" class="c"><input type="checkbox" id="c-38377646" checked=""/><div class="controls bullet"><span class="by">stef25</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376297">parent</a><span>|</span><a href="#38376497">prev</a><span>|</span><a href="#38376483">next</a><span>|</span><label class="collapse" for="c-38377646">[-]</label><label class="expand" for="c-38377646">[2 more]</label></div><br/><div class="children"><div class="content">Not sure if you&#x27;re asking a serious question about MSF but it&#x27;s interesting anyways - when these types of orgs are fundraising for a specific campaign, say Darfur, then they can NOT use that money for any other campaign, say for ex Turkey earthquake.<p>That&#x27;s why they&#x27;ll sometimes tell you to stop donating. That&#x27;s here in EU at least (source is a relative who volunteers for such an org).</div><br/><div id="38381425" class="c"><input type="checkbox" id="c-38381425" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38377646">parent</a><span>|</span><a href="#38376483">next</a><span>|</span><label class="collapse" for="c-38381425">[-]</label><label class="expand" for="c-38381425">[1 more]</label></div><br/><div class="children"><div class="content">Not sure what your point is, but you can make a donation to MSF that is not tied to any specific cause.</div><br/></div></div></div></div></div></div><div id="38376483" class="c"><input type="checkbox" id="c-38376483" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376297">prev</a><span>|</span><a href="#38376135">next</a><span>|</span><label class="collapse" for="c-38376483">[-]</label><label class="expand" for="c-38376483">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>In the 1990s and the 00s, it was no too uncommon for anti-GMO environmental activist &#x2F; ecoterrorist groups to firebomb research facilities and to enter farms and fields to destroy planted GMO plants. Earth Liberation Front was only one of such activist groups [1].<p>We have yet to see even one bombing of an AI research lab. If people really are afraid of AIs, at least they do so more in the abstract and are not employing the tactics of more traditional activist movements.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth_Liberation_Front#Notable_attacks:_1998%E2%80%932009" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth_Liberation_Front#Notable...</a></div><br/><div id="38376591" class="c"><input type="checkbox" id="c-38376591" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376483">parent</a><span>|</span><a href="#38376135">next</a><span>|</span><label class="collapse" for="c-38376591">[-]</label><label class="expand" for="c-38376591">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s mostly that it&#x27;s a can of worms no one wants to open. Very much a last resort as its very tricky to use uncoordinated violence effectively (just killing Sam, LeCunn and Greg doesnt do too much to move the needle and then everyond armors up) and very hard to coordinate violence without a leak.</div><br/></div></div></div></div><div id="38376135" class="c"><input type="checkbox" id="c-38376135" checked=""/><div class="controls bullet"><span class="by">theonemind</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376483">prev</a><span>|</span><a href="#38379218">next</a><span>|</span><label class="collapse" for="c-38376135">[-]</label><label class="expand" for="c-38376135">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t care about AI Safety, but:<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a><p>above that in the charter is &quot;Broadly distributed benefits&quot;, with details like:<p>&quot;&quot;&quot;<p>Broadly distributed benefits<p>We commit to use any influence we obtain over AGI’s deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrate power.<p>Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broad benefit.<p>&quot;&quot;&quot;<p>In that sense, I definitely hate to see rapid commercialization and Microsoft&#x27;s hands in it. I feel like the only person on HN that actually wanted to see Team Sam lose, although it&#x27;s pretty clear Team Helen&#x2F;Ilya didn&#x27;t have a chance, the org just looks hijacked by SV tech bros to me, but I feel like HN has a blindspot to seeing that at all and considering it anything other than a good thing if they do see it.<p>Although GPT barely looks like the language module of AGI to me and I don&#x27;t see any way there from here (part of the reason I don&#x27;t see any safety concern). The big breakthrough here relative to earlier AI research is massive amounts more compute power and a giant pile of data, but it&#x27;s not doing some kind of truly novel information synthesis at all. It can describe quantum mechanics from a giant pile of data, but I don&#x27;t think it has a chance of discovering quantum mechanics, and I don&#x27;t think that&#x27;s just because it can&#x27;t see, hear, etc., but a limitation of the kind of information manipulation it&#x27;s doing. It looks impressive because it&#x27;s reflecting our own intelligence back at us.</div><br/></div></div><div id="38375976" class="c"><input type="checkbox" id="c-38375976" checked=""/><div class="controls bullet"><span class="by">casebash</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38379218">prev</a><span>|</span><a href="#38376263">next</a><span>|</span><label class="collapse" for="c-38375976">[-]</label><label class="expand" for="c-38375976">[1 more]</label></div><br/><div class="children"><div class="content">Have you seen the Center for AI Safety letter? A lot of experts are worried AI safety could be an x-risk:<p><a href="https:&#x2F;&#x2F;www.safe.ai&#x2F;statement-on-ai-risk" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.safe.ai&#x2F;statement-on-ai-risk</a></div><br/></div></div><div id="38376263" class="c"><input type="checkbox" id="c-38376263" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375976">prev</a><span>|</span><a href="#38376225">next</a><span>|</span><label class="collapse" for="c-38376263">[-]</label><label class="expand" for="c-38376263">[7 more]</label></div><br/><div class="children"><div class="content">Both sides of the rift in fact care a great deal about AI Safety. Sam himself helped draft the OpenAI charter and structure its governance which focuses on AI Safety and benefits to humanity. The main reason of the disagreement is the approach they deem best:<p>* Sam and Greg appear to believe OpenAI should move toward AGI as fast as possible because the longer they wait, the more likely it would lead to the proliferation of powerful AGI systems due to GPU overhang. Why? With more computational power at one&#x27;s dispense, it&#x27;s easier to find an algorithm, even a suboptimal one, to train an AGI.<p>As a glimpse on how an AI can be harmful, this paper explores how LLMs can be used to aid in Large-Scale Biological Attacks   <a href="https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html</a>?<p>What if dozens other groups become armed with means to perform such an attack like this? <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack</a><p>We know that there&#x27;re quite a few malicious human groups who would use any means necessary to destroy another group, even at a serious cost to themselves. So the widespread availability of unmonitored AGI would be quite troublesome.<p>* Helen and Ilya might believe it&#x27;s better to slow down AGI development until we find technical means to deeply align an AGI with humanity first. This July, OpenAI started the Superalignment team with Ilya as a co-lead:<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment</a><p>But no one anywhere found a good technique to ensure alignment yet and it appears OpenAI&#x27;s newest internal model has a significant capability leap, which could have led Ilya to make the decision he did. (Sam revealed during the APEC Summit that he observed the advance just a couple of weeks ago and it was only the fourth time he saw that kind of leap.)</div><br/><div id="38376707" class="c"><input type="checkbox" id="c-38376707" checked=""/><div class="controls bullet"><span class="by">gorbypark</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376263">parent</a><span>|</span><a href="#38386406">next</a><span>|</span><label class="collapse" for="c-38376707">[-]</label><label class="expand" for="c-38376707">[3 more]</label></div><br/><div class="children"><div class="content">Honest question, but in your example above of Sam and Greg racing towards AGI as fast as possible in order to head off proliferation, what&#x27;s the end goal when getting there?  Short of capture the entire worlds economy with an ASI, thus preventing anyone else from developing one, I don&#x27;t see how this works. Just because OpenAI (or whoever) wins the initial race, it doesn&#x27;t seem obvious to me that all development on other AGIs stops.</div><br/><div id="38378826" class="c"><input type="checkbox" id="c-38378826" checked=""/><div class="controls bullet"><span class="by">efficax</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376707">parent</a><span>|</span><a href="#38377037">next</a><span>|</span><label class="collapse" for="c-38378826">[-]</label><label class="expand" for="c-38378826">[1 more]</label></div><br/><div class="children"><div class="content">part of the fanaticism here is that the first one to get an AGI wins because they can use its powerful intelligence to overcome every competitor and shut them down. they’re living in their own sci fi novel</div><br/></div></div><div id="38377037" class="c"><input type="checkbox" id="c-38377037" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376707">parent</a><span>|</span><a href="#38378826">prev</a><span>|</span><a href="#38386406">next</a><span>|</span><label class="collapse" for="c-38377037">[-]</label><label class="expand" for="c-38377037">[1 more]</label></div><br/><div class="children"><div class="content">I do not know exactly what they plan to do. But here&#x27;s my thought...<p>Using a near-AGI to help align an ASI, then use the ASI to help prevent the development of unaligned AGI&#x2F;ASI could be a means to a safer world.</div><br/></div></div></div></div><div id="38386406" class="c"><input type="checkbox" id="c-38386406" checked=""/><div class="controls bullet"><span class="by">zerohalo</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376263">parent</a><span>|</span><a href="#38376707">prev</a><span>|</span><a href="#38376485">next</a><span>|</span><label class="collapse" for="c-38386406">[-]</label><label class="expand" for="c-38386406">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Both sides of the rift in fact care a great deal about AI Safety.<p>I disagree. Yes, Sam may have when it OpenAI was founded (unless it was just a ploy), but certainly now it&#x27;s clear that the big companies are on a race to the top and safety or guardrails are mostly irrelevant.<p>The primary reason that the Anthropic team left OpenAI was over safety concerns.</div><br/></div></div><div id="38376485" class="c"><input type="checkbox" id="c-38376485" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376263">parent</a><span>|</span><a href="#38386406">prev</a><span>|</span><a href="#38376225">next</a><span>|</span><label class="collapse" for="c-38376485">[-]</label><label class="expand" for="c-38376485">[2 more]</label></div><br/><div class="children"><div class="content">So Sam wants to make AGI <i>without</i> working to be sure it doesn&#x27;t have goals higher than the preservation of human value?!<p>I can&#x27;t believe that</div><br/><div id="38376549" class="c"><input type="checkbox" id="c-38376549" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376485">parent</a><span>|</span><a href="#38376225">next</a><span>|</span><label class="collapse" for="c-38376549">[-]</label><label class="expand" for="c-38376549">[1 more]</label></div><br/><div class="children"><div class="content">No, I didn&#x27;t say that.  They formed the Superalignment team with Ilya as a co-lead (and Sam&#x27;s approval) for that.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment</a><p>I presume the current alignment approach is sufficient for the AI they make available to others and, in any event, GPT-<i>n</i> is within OpenAI&#x27;s control.</div><br/></div></div></div></div></div></div><div id="38376225" class="c"><input type="checkbox" id="c-38376225" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376263">prev</a><span>|</span><a href="#38376434">next</a><span>|</span><label class="collapse" for="c-38376225">[-]</label><label class="expand" for="c-38376225">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  there was a rift between Rapid Commercialization (Team Sam) and Upholding the Original Principles<p>Seams very unlikely, board could communicate that. Instead they invented some BS reasons, which nobody took as a truth. It looks like more personal and power grab. The staff voted for monetization, people en mass don&#x27;t care much about high principals. Also nobody wants to work under inadequate leadership. Looks like Ilya lost his bet, or Sam is going to keep him around?</div><br/></div></div><div id="38378202" class="c"><input type="checkbox" id="c-38378202" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376434">prev</a><span>|</span><a href="#38382898">next</a><span>|</span><label class="collapse" for="c-38378202">[-]</label><label class="expand" for="c-38378202">[1 more]</label></div><br/><div class="children"><div class="content">I think you analysis is missing the key problem: Business interests.<p>The public don&#x27;t calculate into whats happening here. There&#x27;s people using ChatGPT for real &quot;business value&quot; and _that_ is what was threatened.<p>It&#x27;s clear Business Interests could not be stopped.</div><br/></div></div><div id="38382898" class="c"><input type="checkbox" id="c-38382898" checked=""/><div class="controls bullet"><span class="by">qudat</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38378202">prev</a><span>|</span><a href="#38376378">next</a><span>|</span><label class="collapse" for="c-38382898">[-]</label><label class="expand" for="c-38382898">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>No, because it is an effort in futility. We are evolving into extinction and there is nothing we can do about it.
<a href="https:&#x2F;&#x2F;bower.sh&#x2F;in-love-with-a-ghost" rel="nofollow noreferrer">https:&#x2F;&#x2F;bower.sh&#x2F;in-love-with-a-ghost</a></div><br/></div></div><div id="38376378" class="c"><input type="checkbox" id="c-38376378" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38382898">prev</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38376378">[-]</label><label class="expand" for="c-38376378">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Honestly, I myself can&#x27;t take the threat seriously. But, I do want to understand it more deeply than before.<p>I very much recommend reading the book “Superintelligence: Paths, Dangers, Strategies” from Nick Bostrom.<p>It is a seminal work which provides a great introduction into these ideas and concepts.<p>I found myself in the same boat as you do. I was seeing otherwise inteligent and rational people worry about this “fairy tale” of some AI uprising. Reading that book give me an appreciation of the idea as a serious intelectual excercise.<p>I still don’t agree with everything contained in the book. And definietly don’t agree with everything the AI doomsayers write, but i believe if more people would read it that would elevate the discourse. Instead of rehashing the basics again and again we could build on them.</div><br/><div id="38376749" class="c"><input type="checkbox" id="c-38376749" checked=""/><div class="controls bullet"><span class="by">Solvency</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376378">parent</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38376749">[-]</label><label class="expand" for="c-38376749">[4 more]</label></div><br/><div class="children"><div class="content">Who needs a book to understand the crazy overwhelming scale at which AI can dictate even online news&#x2F;truth&#x2F;discourse&#x2F;misinformation&#x2F;propaganda. And that&#x27;s just barely the beginning.</div><br/><div id="38376964" class="c"><input type="checkbox" id="c-38376964" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376749">parent</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38376964">[-]</label><label class="expand" for="c-38376964">[3 more]</label></div><br/><div class="children"><div class="content">Not sure if you are sarcastic or not. :) Let’s assume you are not:<p>The cool thing is that it doesn’t only talk about AIs. It talks about a more general concept it calls a superinteligence. It has a definition but I recommend you read the book for it. :) AIs are just one of the few enumerated possible implementations of a superinteligence.<p>The other type is for example corporations. This is a usefull perspective because it lets us recognise that our attempts to control AIs is not a new thing. We have the same principal-agent control problem in many other parts of our life. How do you know the company you invest in has interests which align with yours? How do you know that politicians and parties you vote for represent your interests? How do you know your lawyer&#x2F;accountant&#x2F;doctor has your interest at their hearth? (Not all of these are superinteligences, but you get the gist.)</div><br/><div id="38378375" class="c"><input type="checkbox" id="c-38378375" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376964">parent</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38378375">[-]</label><label class="expand" for="c-38378375">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how much this is connected to the &quot;effective altruism&quot; movement which seems to project this idea that the &quot;ends justify the means&quot; in a very complex matter, where it suggests such badly formulated ideas like &quot;If we invest in oil companies, we can use that investment to fight climate change&quot;.<p>I&#x27;d sayu the AI safety problem as a whole is similar to the safety problem of eugenics: Just because you know what the &quot;goal&quot; of some isolated system is, that does not mean you know what the outcome is of implementing that goal on a broad scale.<p>So OpenAI has the same problem: They definitely know what the goal is, but they&#x27;re not prepared _in any meaningful sense_ for what the broadscale outcome is.<p>If you really care about AI safety, you&#x27;d be putting it under government control as utility, like everything else.<p>That&#x27;s all. That&#x27;s why government exists.</div><br/><div id="38380312" class="c"><input type="checkbox" id="c-38380312" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38378375">parent</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38380312">[-]</label><label class="expand" for="c-38380312">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;d sayu the AI safety problem as a whole is similar to the safety problem of eugenics<p>And I&#x27;d sayu should read the book so we can have a nice chat about it. Making wild guesses and assumptions is not really useful.<p>&gt; If you really care about AI safety, you&#x27;d be putting it under government control as utility, like everything else.<p>This is a bit jumbled. How do you think &quot;control as utility&quot; would help? What would it help with?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38375296" class="c"><input type="checkbox" id="c-38375296" checked=""/><div class="controls bullet"><span class="by">tomohelix</span><span>|</span><a href="#38375710">prev</a><span>|</span><a href="#38377296">next</a><span>|</span><label class="collapse" for="c-38375296">[-]</label><label class="expand" for="c-38375296">[79 more]</label></div><br/><div class="children"><div class="content">So, Ilya is out of the board, but Adam is still on it. I know this will raise some eyebrows but whatever.<p>Still though, this isn&#x27;t something that will just go away with Sam back. OAI will undergo serious changes now that Sam has shown himself to be irreplaceable. Future will tell but in the long terms, I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust.</div><br/><div id="38375402" class="c"><input type="checkbox" id="c-38375402" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375306">next</a><span>|</span><label class="collapse" for="c-38375402">[-]</label><label class="expand" for="c-38375402">[43 more]</label></div><br/><div class="children"><div class="content">The OpenAI of the past, that dabbled in random AI stuff (remember their DotA 2 bot?), is gone.<p>OpenAI is now just a vehicle to commercialize their LLM - and everything is subservient to that goal. Discover a major flaw in GPT4? You shut your mouth. Doesn’t matter if society at large suffers for it.<p>Altman&#x27;s&#x2F;Microsoft’s takeover of the former non-profit is now complete.<p>Edit: Let this be a lesson to us all. Just because something claims to be non-profit doesn&#x27;t mean it will always remain that way. With enough political maneuvering and money, a megacorp can takeover almost any organization. Non-profit status and whatever the organization&#x27;s charter says is temporary.</div><br/><div id="38375534" class="c"><input type="checkbox" id="c-38375534" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38375534">[-]</label><label class="expand" for="c-38375534">[24 more]</label></div><br/><div class="children"><div class="content">&gt; now just a vehicle to commercialize their LLM<p>I mean it is what they want isn&#x27;t it. They did some random stuff like, playing dota2 or robot arms, even the Dalle stuff. Now they finally find that one golden goose, of course they are going to keep it.<p>I don&#x27;t think the company has changed at all. It succeeded after all.</div><br/><div id="38375596" class="c"><input type="checkbox" id="c-38375596" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375534">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38375596">[-]</label><label class="expand" for="c-38375596">[4 more]</label></div><br/><div class="children"><div class="content">But it&#x27;s not exactly a company. It&#x27;s a nonprofit structured in a way to wholly own a company. In that sense it&#x27;s like Mozilla.</div><br/><div id="38375707" class="c"><input type="checkbox" id="c-38375707" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375596">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38375707">[-]</label><label class="expand" for="c-38375707">[3 more]</label></div><br/><div class="children"><div class="content">Nonprofit is a just a facade, it was convenient for them to appear as ethnical under that disguise, but they get rid of it when it is inconvenient in a week. 95% of them would rather join MSFT, than being in a non-profit.<p>Did they company change? I am not convinced.</div><br/><div id="38376103" class="c"><input type="checkbox" id="c-38376103" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375707">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38376103">[-]</label><label class="expand" for="c-38376103">[2 more]</label></div><br/><div class="children"><div class="content">Agree that it&#x27;s a facade.<p>Iirc, the NP structure was implemented to attract top AI talent from FAANG. Then they needed investors to fund the infrastructure and hence gave the employees shares or profit units (whatever the hell that is). The NP now shields MSFT from regulatory issues.<p>I do wonder how many of those employees would actually go to MSFT. It feels more like a gambit to get Altman back in since they were about to cash out with the tender offer.</div><br/><div id="38382347" class="c"><input type="checkbox" id="c-38382347" checked=""/><div class="controls bullet"><span class="by">dizzydes</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376103">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38382347">[-]</label><label class="expand" for="c-38382347">[1 more]</label></div><br/><div class="children"><div class="content">Does it actually prevent regulators going after them?</div><br/></div></div></div></div></div></div></div></div><div id="38376076" class="c"><input type="checkbox" id="c-38376076" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375534">parent</a><span>|</span><a href="#38375596">prev</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38376076">[-]</label><label class="expand" for="c-38376076">[19 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no moat in giant LLMs. Anyone on a long enough timeline can scrape&#x2F;digitize 99.9X% of all human knowledge and build an LLM or LXX from it. Monetizing that idea and staying the market leader over a period longer than 10 years will take a herculean amount of effort. Facebook releasing similar models for free definitely took the wind out of their sails, even a tiny bit; right now the moat is access to A100 boards. That will change as eventually even the Raspberry Pi 9 will have LLM capabilities</div><br/><div id="38376157" class="c"><input type="checkbox" id="c-38376157" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376076">parent</a><span>|</span><a href="#38389269">next</a><span>|</span><label class="collapse" for="c-38376157">[-]</label><label class="expand" for="c-38376157">[14 more]</label></div><br/><div class="children"><div class="content">OpenAI (ChatGPT) is already a HUGE brand all around the world. No doubt they&#x27;re the most valuable startup in the AI space. That&#x27;s their moat.<p>Unfortunately, in the past few days, the only thing they&#x27;ve accomplished is significantly damaging their brand.</div><br/><div id="38376405" class="c"><input type="checkbox" id="c-38376405" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376776">next</a><span>|</span><label class="collapse" for="c-38376405">[-]</label><label class="expand" for="c-38376405">[6 more]</label></div><br/><div class="children"><div class="content">Branding counts for a lot, but LLM are already a commodity. As soon as someone releases an LLM equivalent to GPT4 or GPT5, most cloud providers will offer it locally for a fraction of what openAI is charging, and the heaviest users will simply self-host. Go look at the company Docker. I can build a container on almost any device with a prompt these days using open source tooling. The company (or brand, at this point?) offers &quot;professional services&quot; I suppose but who is paying for it? Or go look at Redis or Elasti-anything. Or memcached. Or postgres. Or whatever. Industrial-grade underpinnings of the internet, but it&#x27;s all just commodity stuff you can lease from any cloud provider.<p>It doesn&#x27;t matter if OpenAI or AWS or GCP encoded the entire works of Shakespeare in their LLM, they can all write&#x2F;complete a valid limerick about &quot;There once was a man from Nantucket&quot;.<p>I seriously doubt AWS is going to license OpenAI&#x27;s technology when they can just copy the functionality, royalty free, and charge users for it. Maybe they will? But I doubt it. To the end user it&#x27;s just another locally hosted API. Like DNS.</div><br/><div id="38378407" class="c"><input type="checkbox" id="c-38378407" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376405">parent</a><span>|</span><a href="#38378439">next</a><span>|</span><label class="collapse" for="c-38378407">[-]</label><label class="expand" for="c-38378407">[1 more]</label></div><br/><div class="children"><div class="content">I think yuou&#x27;re assuming that OpenAI is charging a $&#x2F;compute price equal to what it costs them.<p>More likely, they&#x27;re a loss-leader and generating publicity by making it as cheap as possible.<p>_Everything_ we&#x27;ve seen come out of silicon valley does this, so why would they suddenly be charging the right price?</div><br/></div></div><div id="38378439" class="c"><input type="checkbox" id="c-38378439" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376405">parent</a><span>|</span><a href="#38378407">prev</a><span>|</span><a href="#38387563">next</a><span>|</span><label class="collapse" for="c-38378439">[-]</label><label class="expand" for="c-38378439">[2 more]</label></div><br/><div class="children"><div class="content">&gt; offer it locally for a fraction of what openAI is charging<p>I thought the was a somewhat clear agreement that openAI is currently running inference at a loss?</div><br/><div id="38385119" class="c"><input type="checkbox" id="c-38385119" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38378439">parent</a><span>|</span><a href="#38387563">next</a><span>|</span><label class="collapse" for="c-38385119">[-]</label><label class="expand" for="c-38385119">[1 more]</label></div><br/><div class="children"><div class="content">Moore&#x27;s law seems to have failed on CPUs finally, but we&#x27;ve seen the pattern over and over. LLM specific hardware will undoubtedly bring down the cost. $10,000 A100 GPU will not be the last GPU NVidia ever makes, nor will their competitors stand by and let them hold the market hostage.<p>Quake and Counter-Strike in the 1990s ran like garbage in software-rendering mode. I remember having to run Counter-Strike on my Pentium 90 at the lowest resolution, and then disable upscaling to get 15fps, and even then smoke grenades and other effects would drop the framerate into the single digits. Almost two years after Quake&#x27;s release did dedicated 3d video cards (voodoo 1 and 2 were accelerators, depended on a seperate 2d VGA graphics card to feed it) begin to hit the market.<p>Nowadays you can run those games (and their sequels) in the thousands (tens of thousands?) of frames per second on a top end modern card. I would imagine similar events with hardware will transpire with LLM. OpenAI is already prototyping their own hardware to train and run LLMs. I would imagine NVidia hasn&#x27;t been sitting on their hands either.</div><br/></div></div></div></div><div id="38387563" class="c"><input type="checkbox" id="c-38387563" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376405">parent</a><span>|</span><a href="#38378439">prev</a><span>|</span><a href="#38376776">next</a><span>|</span><label class="collapse" for="c-38387563">[-]</label><label class="expand" for="c-38387563">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I seriously doubt AWS is going to license OpenAI&#x27;s technology when they can just copy the functionality, royalty free, and charge users for it. Maybe they will? But I doubt it.<p>You mean like they already do on Amazon Bedrock?</div><br/><div id="38387761" class="c"><input type="checkbox" id="c-38387761" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38387563">parent</a><span>|</span><a href="#38376776">next</a><span>|</span><label class="collapse" for="c-38387761">[-]</label><label class="expand" for="c-38387761">[1 more]</label></div><br/><div class="children"><div class="content">Yeah and looks like they&#x27;re going to offer Llama as well. They offer Redhat linux EC2 instances at a premium, and other paid per hour AMIs. I can&#x27;t imagine why they wouldn&#x27;t offer various LLMs at a premium, but not also offer a home-grown LLM at a lower rate once it&#x27;s ready.</div><br/></div></div></div></div></div></div><div id="38376776" class="c"><input type="checkbox" id="c-38376776" checked=""/><div class="controls bullet"><span class="by">denlekke</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376405">prev</a><span>|</span><a href="#38376437">next</a><span>|</span><label class="collapse" for="c-38376776">[-]</label><label class="expand" for="c-38376776">[4 more]</label></div><br/><div class="children"><div class="content">i don&#x27;t think that&#x27;s really any brand loyalty for OpenAI. people will use whatever is cheapest and best. in the longer run people will use whatever has the best access and integration.<p>what&#x27;s keeping people with OpenAI for now is that chatGPT is free and GPT3.5 and GPT4 are the best. over time I expect the gap in performance to get smaller and the cost to run these to get cheaper.<p>if google gives me something close to as good as OpenAI&#x27;s offering for the same price and it pull data from my gmail or my calendar or my google drive then i&#x27;ll switch to that.</div><br/><div id="38378944" class="c"><input type="checkbox" id="c-38378944" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376776">parent</a><span>|</span><a href="#38377814">next</a><span>|</span><label class="collapse" for="c-38378944">[-]</label><label class="expand" for="c-38378944">[2 more]</label></div><br/><div class="children"><div class="content">I do think there is some brand loyalty.<p>People use &quot;the chatbot from OpenAI&quot; because that&#x27;s what became famous and got all the world a taste of AI (my dad is on that bandwagon, for instance). There is absolutely no way my dad is going to sign up for an Anthropic account and start making API calls to their LLM.<p>But I agree that it&#x27;s a weak moat, if OpenAI were to disappear, I could just tell my dad to use &quot;this same thing but from Google&quot; and he&#x27;d switch without thinking much about it.</div><br/><div id="38381476" class="c"><input type="checkbox" id="c-38381476" checked=""/><div class="controls bullet"><span class="by">denlekke</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38378944">parent</a><span>|</span><a href="#38377814">next</a><span>|</span><label class="collapse" for="c-38381476">[-]</label><label class="expand" for="c-38381476">[1 more]</label></div><br/><div class="children"><div class="content">good points. on second thought, i should give them due credit for building a brand reputation as being &quot;best&quot; that will continue even if they aren&#x27;t the best at some point, which will keep a lot of people with them. that&#x27;s in addition to their other advantages that people will stay because it&#x27;s easier than learning a new platform and there might be lock-in in terms of it being hard to move a trained gpt, or your chat history to another platform.</div><br/></div></div></div></div><div id="38377814" class="c"><input type="checkbox" id="c-38377814" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376776">parent</a><span>|</span><a href="#38378944">prev</a><span>|</span><a href="#38376437">next</a><span>|</span><label class="collapse" for="c-38377814">[-]</label><label class="expand" for="c-38377814">[1 more]</label></div><br/><div class="children"><div class="content">This, if anything people really don&#x27;t like the verbose moralizing and anti-terseness of it.<p>Ok, the first few times you use it maybe it&#x27;s good to know it doesn&#x27;t think it&#x27;s a person, but short and sweet answers just save time, especially when the result is streamed.</div><br/></div></div></div></div><div id="38376437" class="c"><input type="checkbox" id="c-38376437" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376776">prev</a><span>|</span><a href="#38386134">next</a><span>|</span><label class="collapse" for="c-38376437">[-]</label><label class="expand" for="c-38376437">[1 more]</label></div><br/><div class="children"><div class="content">The damage remains to be seen<p>They still have gpt4 and rumored gpt4.5 to offer, so people have no choice but to use them. The internet has such short an attention span, this news will get forgotten in 2 months</div><br/></div></div></div></div><div id="38389269" class="c"><input type="checkbox" id="c-38389269" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376076">parent</a><span>|</span><a href="#38376157">prev</a><span>|</span><a href="#38376523">next</a><span>|</span><label class="collapse" for="c-38389269">[-]</label><label class="expand" for="c-38389269">[1 more]</label></div><br/><div class="children"><div class="content">They won&#x27;t stand still while others are scraping and digitizing. It&#x27;s like saying there is no moat in search. Scale is a thing. Learning effects are a thing. It&#x27;s not the worlds widest moat for sure, but it&#x27;s a moat.</div><br/></div></div><div id="38376523" class="c"><input type="checkbox" id="c-38376523" checked=""/><div class="controls bullet"><span class="by">cft</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376076">parent</a><span>|</span><a href="#38389269">prev</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38376523">[-]</label><label class="expand" for="c-38376523">[3 more]</label></div><br/><div class="children"><div class="content">You are forgetting about the end of the Moore&#x27;s law. The costs for running a large scale AI won&#x27;t drop dramatically. Any optimizations will require non-trivial expensive PhD Bell Labs level research. Running intelligent LLMs will be financially accessible only to a few mega corps in the US and China (and perhaps to the European government). The AI &quot;safety&quot; teams will control the public discourse. Traditional search engines that blacklist websites with dissenting opinions will be viewed as the benevolent free speech dinosaurs of the past.</div><br/><div id="38377844" class="c"><input type="checkbox" id="c-38377844" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376523">parent</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38377844">[-]</label><label class="expand" for="c-38377844">[2 more]</label></div><br/><div class="children"><div class="content">This assumes the only way to use LLMs effectively is to have a monolith model that does everything from translation (from ANY language to ANY language) to creative writing to coding to what have you.  And supposedly GPT4 is a mixture of experts (maybe 8-cross)<p>The efficiency of finetuned models is quite, quite a bit improved at the cost of giving up the rest of the world to do specific things, and disk space to have a few dozen local finetunes (or even hundreds+ for SaaS services) is peanuts compared to acquiring 80GB of VRAM on a single device for monomodels</div><br/><div id="38378229" class="c"><input type="checkbox" id="c-38378229" checked=""/><div class="controls bullet"><span class="by">cft</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38377844">parent</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38378229">[-]</label><label class="expand" for="c-38378229">[1 more]</label></div><br/><div class="children"><div class="content">Sutskever says there&#x27;s a &quot;phase transition&quot; at the order of 9 bn neurons, after which LLMs begin to become really useful. I don&#x27;t know much here, but wouldn&#x27;t the monomodels become overfit, because they don&#x27;t have enough data for 9+bn parameters?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376248" class="c"><input type="checkbox" id="c-38376248" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375534">prev</a><span>|</span><a href="#38375588">next</a><span>|</span><label class="collapse" for="c-38376248">[-]</label><label class="expand" for="c-38376248">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With enough political maneuvering and money, a megacorp can takeover almost any organization.<p>In fact this observation is pertinent to the original stated goals of openAI. In some sense companies and organisations are superinteligences. That is they have goals, they are acting in the real world to achieve those goals and they are more capable in some measures than a single human. (They are not AGI, because they are not artificial, they are composed of meaty parts, the individuals forming the company.)<p>In fact what we are seeing is that when the superinteligence OpenAI was set up there was an attempt to align the goals of the initial founders with the then new organisation. They tried to “bind” their “golem” to  make it pursue certain goals by giving it an unconventional governance structure and a charter.<p>Did they succeed? Too early to tell for sure, but there are at least question marks around it.<p>How would one argue against? OpenAI appears to have given up the lofty goals of AI safety and preventing the concentration of AI provess. In their pursuit of economic success the forces wishing to enrich themselves overpowered the forces wishing to concentrate on the goals. Safety will be still a figleaf for them, if nothing else to achieve regulatory capture to keep out upstart competition.<p>How would one argue for? OpenAI is still around. The charter is still around. To be able to achieve the lofty goals contained in it one needs a lot of resources. Money in particular is a resource which enables one greater powers in shaping the world. Achieving the original goals will require a lot of money. The “golem” is now in the “gain resources” phase of its operation. To achieve that it commercialises the relatively benign, safe and simple LLMs it has access to. This serves the original goal in three ways: gains further resources, estabilishes the organisation as a pre-eminent expert on AI and thus AI safety, provides it with a relatively safe sandbox where adversarial forces are trying its safety concepts. In other words all is well with the original goals, the “golem” that is OpenAI is still well aligned. It will achieve the original goals once it has gained enough resources to do so.<p>The fact that we can’t tell which is happening is in fact the worry and problem with superinteligence&#x2F;AI safety.</div><br/></div></div><div id="38375588" class="c"><input type="checkbox" id="c-38375588" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376248">prev</a><span>|</span><a href="#38378387">next</a><span>|</span><label class="collapse" for="c-38375588">[-]</label><label class="expand" for="c-38375588">[9 more]</label></div><br/><div class="children"><div class="content">Why would society at large suffer from a major flaw in GPT-4, if it&#x27;s even there? If GPT-4 spits out some nonsense to your customers, just put a filter on it, as you should anyway. We can&#x27;t seriously expect OpenAI to babysit every company out there, can we? Why would we even want to?</div><br/><div id="38375686" class="c"><input type="checkbox" id="c-38375686" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375588">parent</a><span>|</span><a href="#38377854">next</a><span>|</span><label class="collapse" for="c-38375686">[-]</label><label class="expand" for="c-38375686">[5 more]</label></div><br/><div class="children"><div class="content">For example, and I&#x27;m not saying such flaws exist, GPT4 output is bias in some way, encourages radicalization (see Twitter&#x27;s, YouTube&#x27;s, and Facebook&#x27;s news feed algorithm), create self-esteem issues in children (see Instagram), ... etc.<p>If you worked for old OpenAI, you would be free to talk about it - since old OpenAI didn&#x27;t give a crap about profit.<p>Altman&#x27;s OpenAI? He will want you to &quot;go to him first&quot;.</div><br/><div id="38376418" class="c"><input type="checkbox" id="c-38376418" checked=""/><div class="controls bullet"><span class="by">nearbuy</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38377894">next</a><span>|</span><label class="collapse" for="c-38376418">[-]</label><label class="expand" for="c-38376418">[1 more]</label></div><br/><div class="children"><div class="content">Concerns about bias and racism in ChatGPT would feel more valid if ChatGPT were even one tenth as bias as anything else in life. Twitter, Facebook, the media, friends and family, etc. are all more bias and radicalized (though I mean &quot;radicalized&quot; in a mild sense) than ChatGPT. Talk to anyone on any side about the war in Gaza and you&#x27;ll get a bunch of opinions that the opposite side will say are blatantly racist. ChatGPT will just say something inoffensive like it&#x27;s a complex and sensitive issue and that it&#x27;s not programmed to have political opinions.</div><br/></div></div><div id="38377894" class="c"><input type="checkbox" id="c-38377894" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38376418">prev</a><span>|</span><a href="#38375773">next</a><span>|</span><label class="collapse" for="c-38377894">[-]</label><label class="expand" for="c-38377894">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Encourages radicalization (see Twitter&#x27;s, YouTube&#x27;s, and Facebook&#x27;s news feed algorithm)<p>What do you mean?  It recommends things that it thinks people will like.<p>Also I highly suspect &quot;Altman&#x27;s OpenAI&quot; is dead regardless.  They are now Copilot(tm) Research.<p>They may have delusions of grandeur regarding being able to resist the MicroBorg or change it from the inside, but that simply does not happen.<p>The best they can hope for as an org is to live as long as they can as best as they can.<p>I think Sam&#x27;s 100B silicon gambit in the middle east (quite curious because this is probably something the United State Federal Government Is Likely Not Super Fond Of) is him realizing that, while he is influential and powerful, he&#x27;s nowhere near MSFT level.</div><br/></div></div><div id="38375773" class="c"><input type="checkbox" id="c-38375773" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38377894">prev</a><span>|</span><a href="#38376926">next</a><span>|</span><label class="collapse" for="c-38375773">[-]</label><label class="expand" for="c-38375773">[1 more]</label></div><br/><div class="children"><div class="content">We can&#x27;t expect GPT-4 not to have bias in some way, or not to have all these things that you mentioned. I read in multiple places that GPT products have &quot;progressive&quot; bias. If that&#x27;s Ok with you, then you just use it with that bias. If not, you fix it by pre-prompting, etc... If you can&#x27;t fix it, use LLAMA or something else. That&#x27;s the entrepreneur&#x27;s problem, not OpenAI&#x27;s. OpenAI needs to make it intelligent and capable. The entrepreneurs and business users will do the rest. That&#x27;s how they get paid. If OpenAI to solve all these problems, what business users are going to do themselves? I just don&#x27;t see the societal harm here.</div><br/></div></div><div id="38376926" class="c"><input type="checkbox" id="c-38376926" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38375773">prev</a><span>|</span><a href="#38377854">next</a><span>|</span><label class="collapse" for="c-38376926">[-]</label><label class="expand" for="c-38376926">[1 more]</label></div><br/><div class="children"><div class="content">GPT3&#x2F;GPT4 currently moralize about anything slightly controversial. Sure you can construct a long elaborate prompt to &quot;jailbreak&quot; it, but it&#x27;s so much effort it&#x27;s easier to just write something by yourself.</div><br/></div></div></div></div><div id="38377854" class="c"><input type="checkbox" id="c-38377854" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375588">parent</a><span>|</span><a href="#38375686">prev</a><span>|</span><a href="#38378417">next</a><span>|</span><label class="collapse" for="c-38377854">[-]</label><label class="expand" for="c-38377854">[2 more]</label></div><br/><div class="children"><div class="content">&gt;If GPT-4 spits out some nonsense to your customers, just put a filter on it, as you should anyway.<p>Languages other than English exist, and RLHF at least does work in any language you make the request in.  regex&#x2F;nlp, not so much.</div><br/><div id="38381683" class="c"><input type="checkbox" id="c-38381683" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38377854">parent</a><span>|</span><a href="#38378417">next</a><span>|</span><label class="collapse" for="c-38381683">[-]</label><label class="expand" for="c-38381683">[1 more]</label></div><br/><div class="children"><div class="content">No regex, you would use another copy of few-shot prompted GPT-4 as a filter for the first GPT-4!</div><br/></div></div></div></div><div id="38378417" class="c"><input type="checkbox" id="c-38378417" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375588">parent</a><span>|</span><a href="#38377854">prev</a><span>|</span><a href="#38378387">next</a><span>|</span><label class="collapse" for="c-38378417">[-]</label><label class="expand" for="c-38378417">[1 more]</label></div><br/><div class="children"><div class="content">Because real people are using it to make decisions. Decisions that could be entirely skewed in some direction, and often that causes damage.</div><br/></div></div></div></div><div id="38378387" class="c"><input type="checkbox" id="c-38378387" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375588">prev</a><span>|</span><a href="#38376693">next</a><span>|</span><label class="collapse" for="c-38378387">[-]</label><label class="expand" for="c-38378387">[1 more]</label></div><br/><div class="children"><div class="content">Non-profit is just a poorly thought out government-ish thing.<p>If it&#x27;s really valuable to society, it needs to be a government entity, full stop.</div><br/></div></div><div id="38376693" class="c"><input type="checkbox" id="c-38376693" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38378387">prev</a><span>|</span><a href="#38376261">next</a><span>|</span><label class="collapse" for="c-38376693">[-]</label><label class="expand" for="c-38376693">[2 more]</label></div><br/><div class="children"><div class="content">Don’t think the dota bot was random. It’s the perfect mix between complicated yet controllable environment, good data availability and good PR angle.</div><br/><div id="38377865" class="c"><input type="checkbox" id="c-38377865" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376693">parent</a><span>|</span><a href="#38376261">next</a><span>|</span><label class="collapse" for="c-38377865">[-]</label><label class="expand" for="c-38377865">[1 more]</label></div><br/><div class="children"><div class="content">It was a clever parallel to deep blue, especially as they picked DotA which was always the &quot;harder&quot; game in its genre.<p>Next up would be an EVE corp run entirely by LLMs</div><br/></div></div></div></div><div id="38376261" class="c"><input type="checkbox" id="c-38376261" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376693">prev</a><span>|</span><a href="#38375689">next</a><span>|</span><label class="collapse" for="c-38376261">[-]</label><label class="expand" for="c-38376261">[3 more]</label></div><br/><div class="children"><div class="content">They let the fox in. But they didn’t have to. They could have try to raise money without such a sweet deal to MS. They gave away power for cloud credits.</div><br/><div id="38376320" class="c"><input type="checkbox" id="c-38376320" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376261">parent</a><span>|</span><a href="#38376631">next</a><span>|</span><label class="collapse" for="c-38376320">[-]</label><label class="expand" for="c-38376320">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They let the fox in. But they didn’t have to. They could have try to raise money without such a sweet deal to MS.<p>They did, and fell, IIRC, vastly short (IIRC, an order of magnitude, maybe more) short of their minimum short-term target. The commercial subsidiary thing was a risk taken to support the mission because it was clear it was going to fail from lack of funding otherwise.</div><br/></div></div><div id="38376631" class="c"><input type="checkbox" id="c-38376631" checked=""/><div class="controls bullet"><span class="by">doikor</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376261">parent</a><span>|</span><a href="#38376320">prev</a><span>|</span><a href="#38375689">next</a><span>|</span><label class="collapse" for="c-38376631">[-]</label><label class="expand" for="c-38376631">[1 more]</label></div><br/><div class="children"><div class="content">They tried but it did not work. They needed billions for the compute time and top tier talent but were only able to collect millions.</div><br/></div></div></div></div><div id="38375689" class="c"><input type="checkbox" id="c-38375689" checked=""/><div class="controls bullet"><span class="by">robbomacrae</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376261">prev</a><span>|</span><a href="#38376951">next</a><span>|</span><label class="collapse" for="c-38375689">[-]</label><label class="expand" for="c-38375689">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still waiting for an optimized version of that bot that can run locally...</div><br/></div></div><div id="38376951" class="c"><input type="checkbox" id="c-38376951" checked=""/><div class="controls bullet"><span class="by">3cats-in-a-coat</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375689">prev</a><span>|</span><a href="#38375306">next</a><span>|</span><label class="collapse" for="c-38376951">[-]</label><label class="expand" for="c-38376951">[1 more]</label></div><br/><div class="children"><div class="content">Do we need to false dichotomy. DotA 2 bot was a successful technology preview. You need both research and development in a healthy organisation. Let&#x27;s call this... hmm I don&#x27;t know &quot;R&amp;D&quot; for short. Might catch on.</div><br/></div></div></div></div><div id="38375306" class="c"><input type="checkbox" id="c-38375306" checked=""/><div class="controls bullet"><span class="by">wilg</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375402">prev</a><span>|</span><a href="#38375766">next</a><span>|</span><label class="collapse" for="c-38375306">[-]</label><label class="expand" for="c-38375306">[1 more]</label></div><br/><div class="children"><div class="content">I mean he&#x27;s not irreplaceable so much as booting him suddenly for no good reason creates problems.</div><br/></div></div><div id="38375766" class="c"><input type="checkbox" id="c-38375766" checked=""/><div class="controls bullet"><span class="by">cowthulhu</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375306">prev</a><span>|</span><a href="#38375309">next</a><span>|</span><label class="collapse" for="c-38375766">[-]</label><label class="expand" for="c-38375766">[1 more]</label></div><br/><div class="children"><div class="content">I feel like history has shown repeatedly that having a good product matters way more than trust, as evidenced by Facebook and Uber. People seem to talk big smack about lost trust and such in the immediate aftermath of a scandal, and then quitely renew the contracts when the time comes.<p>All of the big ad companies (Google, Amazon, Facebook) have, like, a scandal per month, yet the ad revenue keeps coming.
Meltdown was a huge scandal, yet Intel keeps pumping out the chips.</div><br/></div></div><div id="38375309" class="c"><input type="checkbox" id="c-38375309" checked=""/><div class="controls bullet"><span class="by">ayakang31415</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375766">prev</a><span>|</span><a href="#38375377">next</a><span>|</span><label class="collapse" for="c-38375309">[-]</label><label class="expand" for="c-38375309">[2 more]</label></div><br/><div class="children"><div class="content">&quot;I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust.&quot; How is this the case?</div><br/><div id="38376301" class="c"><input type="checkbox" id="c-38376301" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375309">parent</a><span>|</span><a href="#38375377">next</a><span>|</span><label class="collapse" for="c-38376301">[-]</label><label class="expand" for="c-38376301">[1 more]</label></div><br/><div class="children"><div class="content">Scandal a minute Uber lol</div><br/></div></div></div></div><div id="38375377" class="c"><input type="checkbox" id="c-38375377" checked=""/><div class="controls bullet"><span class="by">gordon_freeman</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375309">prev</a><span>|</span><a href="#38375619">next</a><span>|</span><label class="collapse" for="c-38375377">[-]</label><label class="expand" for="c-38375377">[1 more]</label></div><br/><div class="children"><div class="content">Facebook has lost trust so many times that I can’t even count but it’s still a Megacorp, isn’t it?</div><br/></div></div><div id="38375619" class="c"><input type="checkbox" id="c-38375619" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375377">prev</a><span>|</span><a href="#38375370">next</a><span>|</span><label class="collapse" for="c-38375619">[-]</label><label class="expand" for="c-38375619">[5 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s see, Sam Altman is an incredibly charismatic founding CEO, who some people consider manipulative, but is also beloved by many employees. He got kicked out by his board, but brought back when they realized their mistake.<p>It&#x27;s true that this doesn&#x27;t really pattern-match with the founding story of huge successful companies like Facebook, Amazon, Microsoft, or Google. But somehow, I think it&#x27;s still possible that a huge company could be created by a person like this.<p>(And of course, more important than creating a huge company, is creating insanely great products.)</div><br/><div id="38375894" class="c"><input type="checkbox" id="c-38375894" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375619">parent</a><span>|</span><a href="#38377142">next</a><span>|</span><label class="collapse" for="c-38375894">[-]</label><label class="expand" for="c-38375894">[3 more]</label></div><br/><div class="children"><div class="content">I think people following Sam Altman is jumping to conclusions. I think it&#x27;s just as likely that employees are simply following the money. They want to make $$$, and that&#x27;s what a for-profit company does, which is what Altman wants. I think it&#x27;s probably not really about Altman or his leadership.</div><br/><div id="38377491" class="c"><input type="checkbox" id="c-38377491" checked=""/><div class="controls bullet"><span class="by">kareaa</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375894">parent</a><span>|</span><a href="#38377142">next</a><span>|</span><label class="collapse" for="c-38377491">[-]</label><label class="expand" for="c-38377491">[2 more]</label></div><br/><div class="children"><div class="content">Given that over 750 people have signed the letter, it&#x27;s safe to assume that their motivations vary. Some might be motivated by the financial aspects, some might be motivated by Sam&#x27;s leadership (like considering Sam as a friend who needs support). Some might fervently believe that their work is crucial for the advancement of humanity and that any changes would just hinder their progress. And some might have just caved in to peer pressure.</div><br/><div id="38379063" class="c"><input type="checkbox" id="c-38379063" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38377491">parent</a><span>|</span><a href="#38377142">next</a><span>|</span><label class="collapse" for="c-38379063">[-]</label><label class="expand" for="c-38379063">[1 more]</label></div><br/><div class="children"><div class="content">Most are probably motivated by money, some are motivated by stability and some are motivated by their loyalty to sam but i think most are motivated by money and stability.</div><br/></div></div></div></div></div></div><div id="38377142" class="c"><input type="checkbox" id="c-38377142" checked=""/><div class="controls bullet"><span class="by">mkii</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375619">parent</a><span>|</span><a href="#38375894">prev</a><span>|</span><a href="#38375370">next</a><span>|</span><label class="collapse" for="c-38377142">[-]</label><label class="expand" for="c-38377142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s true that this doesn&#x27;t really pattern-match with the founding story of huge successful companies like Facebook, Amazon, Microsoft, or Google.<p>You forgot about Apple.</div><br/></div></div></div></div><div id="38375370" class="c"><input type="checkbox" id="c-38375370" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375619">prev</a><span>|</span><a href="#38375474">next</a><span>|</span><label class="collapse" for="c-38375370">[-]</label><label class="expand" for="c-38375370">[18 more]</label></div><br/><div class="children"><div class="content">OAI looks stronger than ever. The untrustworthy bits that caused all this instability over the last 5 days have been ditched into the sea. Care to expand on your claim?</div><br/><div id="38375475" class="c"><input type="checkbox" id="c-38375475" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375370">parent</a><span>|</span><a href="#38375428">next</a><span>|</span><label class="collapse" for="c-38375475">[-]</label><label class="expand" for="c-38375475">[11 more]</label></div><br/><div class="children"><div class="content">&gt; The untrustworthy bits that caused all this instability over the last 5 days have been ditched into the sea<p>This whole thing started with Altman pushing a safety oriented non-profit into a tense contradiction (edit: I mean  the 2019-2022 gpt3&#x2F;chatgpt for-profit stuff that led to all the Anthropic people leaving). The most recent timeline was<p>- Altman tries to push out another board member<p>- That board member escalates by pushing Altman out (and Brockman off the board)<p>- Altman&#x27;s side escalates by saying they&#x27;ll nuke the company<p>Altman&#x27;s side won, but how can we say that his side didn&#x27;t cause any of this instability?</div><br/><div id="38375540" class="c"><input type="checkbox" id="c-38375540" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375475">parent</a><span>|</span><a href="#38375604">next</a><span>|</span><label class="collapse" for="c-38375540">[-]</label><label class="expand" for="c-38375540">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Altman tries to push out another board member<p>That event wasn&#x27;t some unprovoked start of this history.<p>&gt; That board member escalates by pushing Altman out (and Brockman off the board)<p>and the entire company retaliated. Then this board member tried to sell the company to a competitor who refused. In the meantime the board went through two interim CEOs who refused to play along with this scheme. In the meantime one of the people who voted to fire the CEO regretted it publicly within 24 hours. That&#x27;s a clown car of a board. It reflects the quality of most non-profit boards but not of organizations that actually execute well.</div><br/><div id="38375861" class="c"><input type="checkbox" id="c-38375861" checked=""/><div class="controls bullet"><span class="by">emptysongglass</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375540">parent</a><span>|</span><a href="#38375604">next</a><span>|</span><label class="collapse" for="c-38375861">[-]</label><label class="expand" for="c-38375861">[1 more]</label></div><br/><div class="children"><div class="content">Something that&#x27;s been fairly consistent here on HN throughout the debacle has been an almost fanatical defense of the board&#x27;s actions as justified.<p>The board was incompetent. It will go down in the history books as one of the biggest blunders of a board in history.<p>If you want to take drastic action, you <i>consult with your biggest partner</i> keeping the lights on before you do so. Helen Toner and Tasha McCauley had no business being on this board. Even if you had safety concerns in mind, you don&#x27;t bypass everyone else with a stake in the future of your business because you&#x27;re feeling petulant.</div><br/></div></div></div></div><div id="38375604" class="c"><input type="checkbox" id="c-38375604" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375475">parent</a><span>|</span><a href="#38375540">prev</a><span>|</span><a href="#38375545">next</a><span>|</span><label class="collapse" for="c-38375604">[-]</label><label class="expand" for="c-38375604">[6 more]</label></div><br/><div class="children"><div class="content">By recognizing that it didn&#x27;t &quot;start&quot; with Altman trying to push out another board member, it started when that board member published a paper trashing the company she&#x27;s on the board of, without speaking to the CEO of that company first, or trying in any way to affect change first.</div><br/><div id="38375722" class="c"><input type="checkbox" id="c-38375722" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375604">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375722">[-]</label><label class="expand" for="c-38375722">[4 more]</label></div><br/><div class="children"><div class="content">I edited my comment to clarify what I meant. The start was him pushing to move fast and break things in the classic YC kind of way. And it&#x27;s BS to say that she didn&#x27;t speak to the CEO or try to affect change first. The safety camp inside openai has been unsuccessfully trying to push him to slow down for years.<p>See this article for all that context (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38341399">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38341399</a>) because it sure didn&#x27;t start with the paper you referred to either.</div><br/><div id="38375817" class="c"><input type="checkbox" id="c-38375817" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375722">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375817">[-]</label><label class="expand" for="c-38375817">[3 more]</label></div><br/><div class="children"><div class="content">Your &quot;most recent&quot; timeline is still wrong, and while yes the entire history of OpenAI did not begin with the paper I&#x27;m referencing, it <i>is</i> what started this specific fracas, the one where the board voted to oust Sam Altman.<p>It was a classic antisocial academic move; all she needed to do was <i>talk</i> to Altman, both before <i>and</i> after writing the paper.  It&#x27;s incredibly easy to do that, and her not doing it is what began the insanity.<p>She&#x27;s gone now, and Altman remains, substantially because she didn&#x27;t know how to pick up a phone and interact with another human being.  Who knows, she might have even been successful at her stated goal, of protecting AI, had she done even the most basic amount of problem solving first.  She should not have been on this board, and I hope she&#x27;s learned literally anything from this about interacting with people, though frankly I doubt it.</div><br/><div id="38375887" class="c"><input type="checkbox" id="c-38375887" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375817">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375887">[-]</label><label class="expand" for="c-38375887">[2 more]</label></div><br/><div class="children"><div class="content">Honestly, I just don&#x27;t believe that she didn&#x27;t talk to Altman about her concerns. I&#x27;d believe that she didn&#x27;t say &quot;I&#x27;m publishing a paper about it now&quot; but I can&#x27;t believe she didn&#x27;t talk to him about her concerns during the last 4+ years that it&#x27;s been a core tension at the company.</div><br/><div id="38375942" class="c"><input type="checkbox" id="c-38375942" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375887">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375942">[-]</label><label class="expand" for="c-38375942">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I mean; she should have discussed the paper and its contents specifically with Altman, and easily could have.  It&#x27;s a hugely damaging thing to have your <i>own</i> board member come out critically against your company.  It&#x27;s doubly so when it blindsides the CEO.<p>She had many, many other options available to her that she did not take.  That was a grave mistake and she paid for it.<p>&quot;But what about academic integrity?&quot; Yes!  That&#x27;s why this whole idea was problematic from the beginning.  She can&#x27;t be objective and fulfill her role as board member.  Her role at Georgetown was in <i>direct</i> conflict with her role on the OpenAI board.</div><br/></div></div></div></div></div></div></div></div><div id="38375914" class="c"><input type="checkbox" id="c-38375914" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375604">parent</a><span>|</span><a href="#38375722">prev</a><span>|</span><a href="#38375545">next</a><span>|</span><label class="collapse" for="c-38375914">[-]</label><label class="expand" for="c-38375914">[1 more]</label></div><br/><div class="children"><div class="content">&gt;trashing the company<p>So pointing out risks is trashing the company.</div><br/></div></div></div></div></div></div><div id="38375428" class="c"><input type="checkbox" id="c-38375428" checked=""/><div class="controls bullet"><span class="by">neta1337</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375370">parent</a><span>|</span><a href="#38375475">prev</a><span>|</span><a href="#38375474">next</a><span>|</span><label class="collapse" for="c-38375428">[-]</label><label class="expand" for="c-38375428">[6 more]</label></div><br/><div class="children"><div class="content">Please explain your claim as well. I don’t see how this company looks stronger than ever, more like a clown company</div><br/><div id="38375519" class="c"><input type="checkbox" id="c-38375519" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375473">next</a><span>|</span><label class="collapse" for="c-38375519">[-]</label><label class="expand" for="c-38375519">[2 more]</label></div><br/><div class="children"><div class="content">I may have been overly eager in my comment because the big bad downside of the new board is none of the founders are on it. I hope the current membership sees reason and fixes this issue.<p>But I said this because: They&#x27;ve retained the entire company, reinstated its founder as CEO, and replaced an activist clown board with a professional, experienced, and possibly* unified one. Still remains to be seen how the board membership and overall org structure changes, but I have much more trust in the current 3 members steering OpenAI toward long-term success.</div><br/><div id="38375810" class="c"><input type="checkbox" id="c-38375810" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375519">parent</a><span>|</span><a href="#38375473">next</a><span>|</span><label class="collapse" for="c-38375810">[-]</label><label class="expand" for="c-38375810">[1 more]</label></div><br/><div class="children"><div class="content">If by “long-term-success” you mean a capitalistic lap-dog of microsoft, I’ll agree.<p>It seems that the safety team within OpenAI lost. My biggest fear with this whole AI thing is hostile takeover, and openAI was best positioned to at least do an effort to prevent that. Now, I’m not so sure anymore.</div><br/></div></div></div></div><div id="38375473" class="c"><input type="checkbox" id="c-38375473" checked=""/><div class="controls bullet"><span class="by">TapWaterBandit</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375519">prev</a><span>|</span><a href="#38375865">next</a><span>|</span><label class="collapse" for="c-38375473">[-]</label><label class="expand" for="c-38375473">[2 more]</label></div><br/><div class="children"><div class="content">They got rid of the clowns though. They went from having a board with lightweights and insiders to what at least initially is a strong initial 3.</div><br/></div></div><div id="38375865" class="c"><input type="checkbox" id="c-38375865" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375473">prev</a><span>|</span><a href="#38375474">next</a><span>|</span><label class="collapse" for="c-38375865">[-]</label><label class="expand" for="c-38375865">[1 more]</label></div><br/><div class="children"><div class="content">It was a clown board running an awesome company.<p>They fixed the glitch.</div><br/></div></div></div></div></div></div><div id="38375474" class="c"><input type="checkbox" id="c-38375474" checked=""/><div class="controls bullet"><span class="by">nathanasmith</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375370">prev</a><span>|</span><a href="#38375345">next</a><span>|</span><label class="collapse" for="c-38375474">[-]</label><label class="expand" for="c-38375474">[5 more]</label></div><br/><div class="children"><div class="content">On the contrary, this saga has shown that a huge number of people are extremely passionate about the existence of OpenAI and it&#x27;s leadership by Altman, much more strongly and in larger numbers than most had suspected. If anything this has solidified the importance of the company and I think people will trust it more that the situation was resolved with the light speed it was.</div><br/><div id="38376123" class="c"><input type="checkbox" id="c-38376123" checked=""/><div class="controls bullet"><span class="by">willdr</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375474">parent</a><span>|</span><a href="#38375345">next</a><span>|</span><label class="collapse" for="c-38376123">[-]</label><label class="expand" for="c-38376123">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a misreading of the situation. The employees saw their big bag vanishing and suddenly realised they were employed by a non-profit entity that had loftier goals than making a buck, so they rallied to overturn it and they&#x27;ve gotten their way. This is a net negative for anyone not financially invested in OAI.</div><br/><div id="38377390" class="c"><input type="checkbox" id="c-38377390" checked=""/><div class="controls bullet"><span class="by">nathanasmith</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376123">parent</a><span>|</span><a href="#38375345">next</a><span>|</span><label class="collapse" for="c-38377390">[-]</label><label class="expand" for="c-38377390">[3 more]</label></div><br/><div class="children"><div class="content">What lofty goals? The board was questioned repeatedly and never articulated clear reasoning for firing Altman and in the process lost the confidence of the employees hence the &quot;rally&quot;. The lack of clarity was their undoing whether there would have been a bag for the employees to lose or not.</div><br/><div id="38386365" class="c"><input type="checkbox" id="c-38386365" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38377390">parent</a><span>|</span><a href="#38378567">next</a><span>|</span><label class="collapse" for="c-38386365">[-]</label><label class="expand" for="c-38386365">[1 more]</label></div><br/><div class="children"><div class="content">My story: Maybe they had lofty goals, maybe not, but it sounded like the whole thing was instigated by Altman trying to fire Toner (one of the board members) over a silly pretext of her coauthoring a paper that nobody read that was very mildly negative about OpenAI, during her day job. <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-board-fight.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-...</a><p>And then presumably the other board members read the writing on the wall (especially seeing how 3 other board members mysteriously resigned, including Hoffman <a href="https:&#x2F;&#x2F;www.semafor.com&#x2F;article&#x2F;11&#x2F;19&#x2F;2023&#x2F;reid-hoffman-was-privately-unhappy-about-leaving-openais-board" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.semafor.com&#x2F;article&#x2F;11&#x2F;19&#x2F;2023&#x2F;reid-hoffman-was-...</a>), and realized that if Altman can kick out Toner under such flimsy pretexts, they&#x27;d be out too.<p>So they allied with Helen to countercoup Greg&#x2F;Sam.<p>I think the anti-board perspective is that this is all shallow bickering over a 90B company. The pro-board perspective is that the whole <i>point</i> of the board was to serve as a check on the CEO, so if the CEO could easily appoint only loyalists, then the board is a useless rubber stamp that lends unfair legitimacy to OpenAI&#x27;s regulatory capture efforts.</div><br/></div></div></div></div></div></div></div></div><div id="38375345" class="c"><input type="checkbox" id="c-38375345" checked=""/><div class="controls bullet"><span class="by">sverhagen</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375474">prev</a><span>|</span><a href="#38375339">next</a><span>|</span><label class="collapse" for="c-38375345">[-]</label><label class="expand" for="c-38375345">[1 more]</label></div><br/><div class="children"><div class="content">Ah, yes, Facebook and Uber, brands known for consistent trustworthiness throughout their existences &#x2F;s</div><br/></div></div><div id="38375339" class="c"><input type="checkbox" id="c-38375339" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375345">prev</a><span>|</span><a href="#38377296">next</a><span>|</span><label class="collapse" for="c-38375339">[-]</label><label class="expand" for="c-38375339">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust<p>Whose trust?</div><br/></div></div></div></div><div id="38377296" class="c"><input type="checkbox" id="c-38377296" checked=""/><div class="controls bullet"><span class="by">MattHeard</span><span>|</span><a href="#38375296">prev</a><span>|</span><a href="#38375379">next</a><span>|</span><label class="collapse" for="c-38377296">[-]</label><label class="expand" for="c-38377296">[8 more]</label></div><br/><div class="children"><div class="content">I was hopeful for a private-industry approach to AI safety, but it looks unlikely now, and due to the slow pace of state investment in public AI R&amp;D, all approaches to AI safety look unlikely now.<p>Safety research on toy models will continue to provide developments, but the industry expectation appears to be that emergent properties puts a low ceiling on what can be learned about safety without researching on cutting edge models.<p>Altman touted the governance structure of OpenAI as a mechanism for ensuring the organisation&#x27;s prioritisation of safety, but the reports of internal reallocation away from safety towards keeping ChatGPT running under load concern me. Now the board has demonstrated that it was technically capable but insufficiently powerful to keep these interests in line, it seems unclear how any safety-oriented organisation, including Anthropic, could avoid the accelerationist influence of funders.</div><br/><div id="38381304" class="c"><input type="checkbox" id="c-38381304" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#38377296">parent</a><span>|</span><a href="#38378228">next</a><span>|</span><label class="collapse" for="c-38381304">[-]</label><label class="expand" for="c-38381304">[4 more]</label></div><br/><div class="children"><div class="content">There are no emergent properties, just a linear increase in knowledge that can be retrieved.<p>- It can&#x27;t plan<p>- It can&#x27;t do arithmetic<p>- It can&#x27;t reason<p>- It can approximately retrieve knowledge with a natural language query (there are some issues with this, but it&#x27;s very good)<p>- It can encode data into natural languages and other modalities<p>I&#x27;m not worried about it, I am worried about how badly people have misunderstood what it can do and then attempted to use it for things that matter.<p>But I&#x27;m not surprised.</div><br/><div id="38383276" class="c"><input type="checkbox" id="c-38383276" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#38377296">root</a><span>|</span><a href="#38381304">parent</a><span>|</span><a href="#38389051">next</a><span>|</span><label class="collapse" for="c-38383276">[-]</label><label class="expand" for="c-38383276">[1 more]</label></div><br/><div class="children"><div class="content">This is incorrect. For example the ability to translate between languages is emergent. Also gpt4 can do arithmetic better than the average person. Especially considering the process it arrives at the computation is via intuition basically vs algorithmic. Btw just as an aide the newer models can also write code to do certain tasks, like arithmetic.</div><br/></div></div><div id="38389051" class="c"><input type="checkbox" id="c-38389051" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38377296">root</a><span>|</span><a href="#38381304">parent</a><span>|</span><a href="#38383276">prev</a><span>|</span><a href="#38384717">next</a><span>|</span><label class="collapse" for="c-38389051">[-]</label><label class="expand" for="c-38389051">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think AI safetyists are worried about any model they have created so far. But if we are able to go from letter-soup &quot;ooh look that almost seems like a sentence, SOTA!&quot; to GPT4 in 20 years, where will go in the next 20? And what is the point they are becoming powerful. Let alone all the crazy ways people are trying to augment them with RAG, function calls, get them to run on less computer power and so on.<p>Also being better at humans at everything is not a prerequisite for danger. Probably a scary moment is when it could look at a C (or Rust, C++, whatever) codebase, find an exploit, and then use that exploit as a worm. If it can do that on everyday hardware not top end GPUs (either because the algorithms are made more efficient, or every iPhone has a tensor unit).</div><br/></div></div><div id="38384717" class="c"><input type="checkbox" id="c-38384717" checked=""/><div class="controls bullet"><span class="by">zucker42</span><span>|</span><a href="#38377296">root</a><span>|</span><a href="#38381304">parent</a><span>|</span><a href="#38389051">prev</a><span>|</span><a href="#38378228">next</a><span>|</span><label class="collapse" for="c-38384717">[-]</label><label class="expand" for="c-38384717">[1 more]</label></div><br/><div class="children"><div class="content">What is your definition of reasoning? In my mind, GPT-4 has some nascent reasoning abilities.</div><br/></div></div></div></div><div id="38378228" class="c"><input type="checkbox" id="c-38378228" checked=""/><div class="controls bullet"><span class="by">abra0</span><span>|</span><a href="#38377296">parent</a><span>|</span><a href="#38381304">prev</a><span>|</span><a href="#38377450">next</a><span>|</span><label class="collapse" for="c-38378228">[-]</label><label class="expand" for="c-38378228">[1 more]</label></div><br/><div class="children"><div class="content">More effort spent on early commercialization like keeping ChatGPT running might mean less effort on cutting edge capabilities. Altman was never an AI safety person, so my personal hope is that Anthropic avoids this by having higher quality leadership.</div><br/></div></div><div id="38377450" class="c"><input type="checkbox" id="c-38377450" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#38377296">parent</a><span>|</span><a href="#38378228">prev</a><span>|</span><a href="#38379274">next</a><span>|</span><label class="collapse" for="c-38377450">[-]</label><label class="expand" for="c-38377450">[1 more]</label></div><br/><div class="children"><div class="content">Easy, don’t be incompetent and don’t abuse your power for personal gain. People aren’t as dumb as you think they are and they will see right through that bullshit and quit rather than follow idiot tyrants.</div><br/></div></div><div id="38379274" class="c"><input type="checkbox" id="c-38379274" checked=""/><div class="controls bullet"><span class="by">mymusewww</span><span>|</span><a href="#38377296">parent</a><span>|</span><a href="#38377450">prev</a><span>|</span><a href="#38375379">next</a><span>|</span><label class="collapse" for="c-38379274">[-]</label><label class="expand" for="c-38379274">[1 more]</label></div><br/><div class="children"><div class="content">I would like to know the model that isn’t a “toy model”.</div><br/></div></div></div></div><div id="38375379" class="c"><input type="checkbox" id="c-38375379" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38377296">prev</a><span>|</span><a href="#38381276">next</a><span>|</span><label class="collapse" for="c-38375379">[-]</label><label class="expand" for="c-38375379">[11 more]</label></div><br/><div class="children"><div class="content">I really did not think that would happen. I guess the obvious next question is what happens to Ilya? From this announcement it appears he is off the board. Is he still the chief scientist? I find it hard to believe he and Sam would be able to patch their relationship up well enough to work together so closely. Interesting that Adam stayed on the board, that seems to disprove many of the theories floating around here that he was the ringleader due to some perceived conflict of interest.</div><br/><div id="38376011" class="c"><input type="checkbox" id="c-38376011" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38375828">next</a><span>|</span><label class="collapse" for="c-38376011">[-]</label><label class="expand" for="c-38376011">[2 more]</label></div><br/><div class="children"><div class="content">From Ilya&#x27;s perspective, not much seems to have changed. Sam sidelined him a month ago over their persistent disagreements about whether to pursue commercialisation as fast as Sam was. If Ilya is still sidelined, he probably quits and whichever company offers him the most control will get him. Same if he&#x27;s fired. If he&#x27;s un-sidelined as part of the deal, he probably stays on as Chief Scientist. Hopefully with less hostility from Sam now (lol).</div><br/><div id="38384942" class="c"><input type="checkbox" id="c-38384942" checked=""/><div class="controls bullet"><span class="by">dinvlad</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38376011">parent</a><span>|</span><a href="#38375828">next</a><span>|</span><label class="collapse" for="c-38384942">[-]</label><label class="expand" for="c-38384942">[1 more]</label></div><br/><div class="children"><div class="content">Ilya is just naive, imho. Bright but just too idealistic and hypothesizing about AGI, and not seeing that this is now ONLY about making money from LLMs, and nothing more. All the AGI stuff is just a facade for that.</div><br/></div></div></div></div><div id="38375828" class="c"><input type="checkbox" id="c-38375828" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38376011">prev</a><span>|</span><a href="#38378793">next</a><span>|</span><label class="collapse" for="c-38375828">[-]</label><label class="expand" for="c-38375828">[6 more]</label></div><br/><div class="children"><div class="content">I would be slightly more optimistic. They know each other quite well as well as how to work together to get big things done. Sometimes shit happens or someone makes a mistake. A simple apology can go a long way when it’s meant sincerely.</div><br/><div id="38376021" class="c"><input type="checkbox" id="c-38376021" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38375828">parent</a><span>|</span><a href="#38376399">next</a><span>|</span><label class="collapse" for="c-38376021">[-]</label><label class="expand" for="c-38376021">[3 more]</label></div><br/><div class="children"><div class="content">Sam doesn&#x27;t seem like the kind of person to apologise, particularly not after Ilya actually hit back. It seems Ilya won&#x27;t be at OpenAI long and will have to pick whichever other company with compute will give him the most control.</div><br/><div id="38376913" class="c"><input type="checkbox" id="c-38376913" checked=""/><div class="controls bullet"><span class="by">orthoxerox</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38376021">parent</a><span>|</span><a href="#38376399">next</a><span>|</span><label class="collapse" for="c-38376913">[-]</label><label class="expand" for="c-38376913">[2 more]</label></div><br/><div class="children"><div class="content">However, he does seem like the kind of person able to easily manipulate someone book-smart like Ilya into actually feeling guilty about the whole affair. He&#x27;ll end up graciously forgiving Ilya in a way that will make him feel indebted to Sam.</div><br/></div></div></div></div><div id="38376399" class="c"><input type="checkbox" id="c-38376399" checked=""/><div class="controls bullet"><span class="by">bkyan</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38375828">parent</a><span>|</span><a href="#38376021">prev</a><span>|</span><a href="#38378793">next</a><span>|</span><label class="collapse" for="c-38376399">[-]</label><label class="expand" for="c-38376399">[2 more]</label></div><br/><div class="children"><div class="content">Sam triple-hearted Ilya&#x27;s apology tweet.</div><br/><div id="38382158" class="c"><input type="checkbox" id="c-38382158" checked=""/><div class="controls bullet"><span class="by">mcmcmc</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38376399">parent</a><span>|</span><a href="#38378793">next</a><span>|</span><label class="collapse" for="c-38382158">[-]</label><label class="expand" for="c-38382158">[1 more]</label></div><br/><div class="children"><div class="content">Well yeah... if Ilya hadn&#x27;t flipped the board would still have the upper hand and Sam would not be back as CEO.</div><br/></div></div></div></div></div></div><div id="38378793" class="c"><input type="checkbox" id="c-38378793" checked=""/><div class="controls bullet"><span class="by">nemo44x</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38375828">prev</a><span>|</span><a href="#38378676">next</a><span>|</span><label class="collapse" for="c-38378793">[-]</label><label class="expand" for="c-38378793">[1 more]</label></div><br/><div class="children"><div class="content">Sam will have no issue patching the relationship because he knows how a business relationship works. Besides, Ilya kissed the ring as evidenced by his tweet.</div><br/></div></div><div id="38378676" class="c"><input type="checkbox" id="c-38378676" checked=""/><div class="controls bullet"><span class="by">dangerface</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38378793">prev</a><span>|</span><a href="#38381276">next</a><span>|</span><label class="collapse" for="c-38378676">[-]</label><label class="expand" for="c-38378676">[1 more]</label></div><br/><div class="children"><div class="content">Strangely I think Ilya comes out of this well. He made a decision based on his values and what he believed was the best decision for AI safety. After seeing the outcome of that decision he changed his mind and owned that. He must have known it would result in the internet ridiculing him for flip flopping, but acted in what he thought was the best interest for the employees signing the letter. His actions are wroth criticism but I think his moral character has been demonstrated.<p>The other members of the board seemed to make their decision based on more personal reasons that seems to fit with Adams conflict of interest. They refused to communicate and only now accept any sort of responsibility for their actions and lack of plan.<p>Honestly Ilya is the only one of the 4 I would actually want still on the board. I think we need people who are willing to change direction based on new information especially in leadership positions despite it being messy, the world is messy.</div><br/></div></div></div></div><div id="38381276" class="c"><input type="checkbox" id="c-38381276" checked=""/><div class="controls bullet"><span class="by">melvinmelih</span><span>|</span><a href="#38375379">prev</a><span>|</span><a href="#38379377">next</a><span>|</span><label class="collapse" for="c-38381276">[-]</label><label class="expand" for="c-38381276">[4 more]</label></div><br/><div class="children"><div class="content">“You could parachute Sam into an island full of cannibals and come back in 5 years and he&#x27;d be the king.” - Paul Graham</div><br/><div id="38382848" class="c"><input type="checkbox" id="c-38382848" checked=""/><div class="controls bullet"><span class="by">rsanek</span><span>|</span><a href="#38381276">parent</a><span>|</span><a href="#38383835">prev</a><span>|</span><a href="#38381829">next</a><span>|</span><label class="collapse" for="c-38382848">[-]</label><label class="expand" for="c-38382848">[1 more]</label></div><br/><div class="children"><div class="content"><a href="http:&#x2F;&#x2F;paulgraham.com&#x2F;fundraising.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;paulgraham.com&#x2F;fundraising.html</a></div><br/></div></div></div></div><div id="38379377" class="c"><input type="checkbox" id="c-38379377" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#38381276">prev</a><span>|</span><a href="#38375789">next</a><span>|</span><label class="collapse" for="c-38379377">[-]</label><label class="expand" for="c-38379377">[5 more]</label></div><br/><div class="children"><div class="content">Fascinating, I see a lot of VC&#x2F;Msfot has overthrown our NPO governing structure because of profit incentives narrative.<p>I don&#x27;t think this is what really happened at all. The reason this decision was made was because 95% of employees sided with Sam on this issue, and the board didn&#x27;t explain themselves in any way at all. So it was Sam + 95% of employees + All investors against the board. In which case the board should lose (since they are only governing for themselves here).<p>I think in the end a good and fair outcome. I still think their governing structure is decent to solve the AGI problem, this particular board was just really bad.</div><br/><div id="38380151" class="c"><input type="checkbox" id="c-38380151" checked=""/><div class="controls bullet"><span class="by">r_thambapillai</span><span>|</span><a href="#38379377">parent</a><span>|</span><a href="#38379746">next</a><span>|</span><label class="collapse" for="c-38380151">[-]</label><label class="expand" for="c-38380151">[1 more]</label></div><br/><div class="children"><div class="content">Of course, the profit incentive also applies to all the employees (which isn&#x27;t necessarily a bad thing, its good to align the company&#x27;s goals with those of the employees). But when the executives likely have 10s of millions of dollars on the line, and many of the IC&#x27;s will likely have single digit millions on the line as well, it doesn&#x27;t seem exactly straightforward to view this as the employees are unbiased adjudicators of what&#x27;s in the interest of the non-profit entity, which is <i>supposed</i> to be what&#x27;s in charge.<p>It is sort of strange that our communal reaction is to say &quot;well this board didn&#x27;t act anything like a normal corporate board&quot;: of course it didn&#x27;t, that was indeed the <i>whole</i> point of not having a normal corporate board in charge.<p>Whatever you think of Sam, Adam, Ilya etc, the one conclusion that seems safe to reach is that in the end, the profit&#x2F;financial incentives ended up being far more important than the NGOs mission, no matter what legal structure was in place.</div><br/></div></div><div id="38379746" class="c"><input type="checkbox" id="c-38379746" checked=""/><div class="controls bullet"><span class="by">greenie_beans</span><span>|</span><a href="#38379377">parent</a><span>|</span><a href="#38380151">prev</a><span>|</span><a href="#38381565">next</a><span>|</span><label class="collapse" for="c-38379746">[-]</label><label class="expand" for="c-38379746">[1 more]</label></div><br/><div class="children"><div class="content">next time, can&#x27;t wait to see what happens when capital is on the opposite side of the 95% of employees.</div><br/></div></div><div id="38381565" class="c"><input type="checkbox" id="c-38381565" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38379377">parent</a><span>|</span><a href="#38379746">prev</a><span>|</span><a href="#38381139">next</a><span>|</span><label class="collapse" for="c-38381565">[-]</label><label class="expand" for="c-38381565">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the board was big enough for starters. Of the folks on their, only one (Adam) had experience as a leader of a for profit venture. Helen probably lacks the leadership background to make any progress pushing her priorities.</div><br/></div></div><div id="38381139" class="c"><input type="checkbox" id="c-38381139" checked=""/><div class="controls bullet"><span class="by">jkaplan</span><span>|</span><a href="#38379377">parent</a><span>|</span><a href="#38381565">prev</a><span>|</span><a href="#38375789">next</a><span>|</span><label class="collapse" for="c-38381139">[-]</label><label class="expand" for="c-38381139">[1 more]</label></div><br/><div class="children"><div class="content">1. Microsoft was heavily involved in orchestrating the 95% of employees to side with Sam -- through promising them money&#x2F;jobs and through PR&#x2F;narrative
2. The profit incentives apply to employees too<p>Bigger picture, I don&#x27;t think the &quot;money&#x2F;VC&#x2F;MSFT&#x2F;commercialization faction destroyed the safety&#x2F;non-profit faction&quot; is mutually exclusive with &quot;the board fucked up.&quot; IMO, both are true</div><br/></div></div></div></div><div id="38375789" class="c"><input type="checkbox" id="c-38375789" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#38379377">prev</a><span>|</span><a href="#38375831">next</a><span>|</span><label class="collapse" for="c-38375789">[-]</label><label class="expand" for="c-38375789">[4 more]</label></div><br/><div class="children"><div class="content">Looks to me like, one pro-board member in Adam d Angelo, one pro Sam in Brett Taylor since they’ve been pushing for him since Sunday so I’m assuming Sam and rest of OpenAI leadership really like him and 1 Neutral in Larry Summers who has never worked in AI and is just a well respected name in general. I’m sure Larry was extensively interviewed and reference checked by both sides of this power struggle before they agreed to compromise on him.<p>Interesting to see how the board evolves from this. From what I know broadly there were 2 factions, the faction that thought Sam was going too fast which fired him and the faction that thought Sam’s trajectory was fine (which included Sam and Greg). Now there’s a balance on the board and subsequent hires can tip it one way or the other. Unfortunately a divided board rarely lasts and one faction will eventually win out, I think Sam’s faction will eventually win out but we’ll have to wait and see.<p>One of the saddest results of this drama was Greg being ousted from OpenAI. Greg apart from being brilliant was someone who regularly 80-90 hour work weeks into OpenAI, and you could truly say he dedicated a good chunk of his life into building this organization. And he was forced to resign by a board who probably never put a 90 hour work week in their entire life, much less into building OpenAI. A slap on the face. I don’t care what the board’s reasoning was but when their actions caused employees who dedicated their lives to building the organization resign (especially when most of them played no part at all into building this amazing organization), they had to go in disgrace. I doubt any of them will ever reach career highs higher than being on OpenAI’s board, and the world’s better off for it.<p>P.S., Ilya of course is an exception and not included in my above condemnation. He also notably reversed his position when he saw OpenAI was being killed by his actions.</div><br/><div id="38382123" class="c"><input type="checkbox" id="c-38382123" checked=""/><div class="controls bullet"><span class="by">mcmcmc</span><span>|</span><a href="#38375789">parent</a><span>|</span><a href="#38383385">next</a><span>|</span><label class="collapse" for="c-38382123">[-]</label><label class="expand" for="c-38382123">[2 more]</label></div><br/><div class="children"><div class="content">Larry Summers is the scary pick here. His views on banking deregulation led to the GFC, and he&#x27;s had several controversies over racist and sexist positions. Plus he&#x27;s an old pal of Epstein and made several trips to his island.</div><br/><div id="38382508" class="c"><input type="checkbox" id="c-38382508" checked=""/><div class="controls bullet"><span class="by">Joeri</span><span>|</span><a href="#38375789">root</a><span>|</span><a href="#38382123">parent</a><span>|</span><a href="#38383385">next</a><span>|</span><label class="collapse" for="c-38382508">[-]</label><label class="expand" for="c-38382508">[1 more]</label></div><br/><div class="children"><div class="content">I assume Summers is there as a politically connected operative, to make sure OpenAI remains influential in Washington.</div><br/></div></div></div></div><div id="38383385" class="c"><input type="checkbox" id="c-38383385" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#38375789">parent</a><span>|</span><a href="#38382123">prev</a><span>|</span><a href="#38375831">next</a><span>|</span><label class="collapse" for="c-38383385">[-]</label><label class="expand" for="c-38383385">[1 more]</label></div><br/><div class="children"><div class="content">Greg was only forced to resign from his board seat, not his job.</div><br/></div></div></div></div><div id="38375831" class="c"><input type="checkbox" id="c-38375831" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38375789">prev</a><span>|</span><a href="#38376996">next</a><span>|</span><label class="collapse" for="c-38375831">[-]</label><label class="expand" for="c-38375831">[13 more]</label></div><br/><div class="children"><div class="content">From a business sense, Satya was excellent.<p>He made the right calls, fast, with limited information.<p>Things further shifted from plan a to b to… whatever this is.<p>Despite that, MSFT still came out on top.<p>Consider if Satya didn’t say anything. Suppose MSFT stood back and let things play out.<p>That’s a gap for google or some competitor to make a move. To showcase their stability and long term business friendly vision.<p>Instead by moving fast, doing the “right” thing, this opportunity was denied and used to MSFTs benefit.<p>If the board folded, it would return to the stays quo. If the board held, MSFT would have secured OpenAI, for essentially nothing.<p>Edit: changed board folded x2 to board folded + board held, last para.</div><br/><div id="38376053" class="c"><input type="checkbox" id="c-38376053" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38379622">next</a><span>|</span><label class="collapse" for="c-38376053">[-]</label><label class="expand" for="c-38376053">[3 more]</label></div><br/><div class="children"><div class="content">The only mistake (a big one) was publicly offering to match comp for all the OpenAI employees. Can&#x27;t sit well with folks @ MS already. This was something they could have easily done privately to give petition signers confidence.</div><br/><div id="38377332" class="c"><input type="checkbox" id="c-38377332" checked=""/><div class="controls bullet"><span class="by">asd88</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38376053">parent</a><span>|</span><a href="#38379622">next</a><span>|</span><label class="collapse" for="c-38377332">[-]</label><label class="expand" for="c-38377332">[2 more]</label></div><br/><div class="children"><div class="content">Nah, Microsoft employees being second class citizens compared to acquisitions is nothing new. e.g. compare Microsoft comp with LinkedIn&#x2F;GitHub comp.</div><br/><div id="38388741" class="c"><input type="checkbox" id="c-38388741" checked=""/><div class="controls bullet"><span class="by">semiquaver</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38377332">parent</a><span>|</span><a href="#38379622">next</a><span>|</span><label class="collapse" for="c-38388741">[-]</label><label class="expand" for="c-38388741">[1 more]</label></div><br/><div class="children"><div class="content">LinkedIn has a rep for higher-than-MSFT comp. GitHub for lower.</div><br/></div></div></div></div></div></div><div id="38379622" class="c"><input type="checkbox" id="c-38379622" checked=""/><div class="controls bullet"><span class="by">zug_zug</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38376053">prev</a><span>|</span><a href="#38378459">next</a><span>|</span><label class="collapse" for="c-38379622">[-]</label><label class="expand" for="c-38379622">[4 more]</label></div><br/><div class="children"><div class="content">I am not sure why people keep pushing this narrative. It&#x27;s not obviously false, but there doesn&#x27;t seem to be much evidence of it.<p>From where I sit Satya possibly messed up big. He clearly wanted Sam and the Open AI team to join microsoft and they won&#x27;t now, likely ever.<p>By offering a standing offer to join MS publicly he gave Sam and OpenAI employees huge leverage to force the board&#x27;s hand. If he had waited then maybe there would have been an actual fallout that would have lead to people actually joining microsoft.</div><br/><div id="38379853" class="c"><input type="checkbox" id="c-38379853" checked=""/><div class="controls bullet"><span class="by">jnwatson</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38379622">parent</a><span>|</span><a href="#38385005">next</a><span>|</span><label class="collapse" for="c-38379853">[-]</label><label class="expand" for="c-38379853">[1 more]</label></div><br/><div class="children"><div class="content">Satya&#x27;s main mistake was not having a spot on the board. Everything after that was in defense of the initial investment, and he played all the right moves.<p>While having OpenAI as a Microsoft DeepMind would have been an ok second-best solution, the status quo is still better for Microsoft.  There would have been a bunch of legal issues and it would be a hit on Microsoft&#x27;s bottom line.</div><br/></div></div><div id="38385005" class="c"><input type="checkbox" id="c-38385005" checked=""/><div class="controls bullet"><span class="by">asperous</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38379622">parent</a><span>|</span><a href="#38379853">prev</a><span>|</span><a href="#38380914">next</a><span>|</span><label class="collapse" for="c-38385005">[-]</label><label class="expand" for="c-38385005">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s quite right, Microsoft&#x27;s main game was keeping the money train going by any means necessary, they have staked so much on copilots and Enterprise&#x2F;Azure Open AI. So much has been invested into that strategic direction and seeing Google swoop in and out-innovate Microsoft would be a huge loss.<p>Either by keeping OpenAI as-is, or the alternative being moving everyone to Microsoft in an attempt to keep things going would work for Satya.</div><br/></div></div><div id="38380914" class="c"><input type="checkbox" id="c-38380914" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38379622">parent</a><span>|</span><a href="#38385005">prev</a><span>|</span><a href="#38378459">next</a><span>|</span><label class="collapse" for="c-38380914">[-]</label><label class="expand" for="c-38380914">[1 more]</label></div><br/><div class="children"><div class="content">Its very easy to min max a situation if you are not on the other side.<p>Additionally - I have not seen someone else talk about this, its just been a few days. Calling it a narrative is a stretch, and dismissive by implying manipulation.<p>Finally why would Sam joining MSFT be better than this current situation?</div><br/></div></div></div></div><div id="38378459" class="c"><input type="checkbox" id="c-38378459" checked=""/><div class="controls bullet"><span class="by">alentred</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38379622">prev</a><span>|</span><a href="#38375941">next</a><span>|</span><label class="collapse" for="c-38378459">[-]</label><label class="expand" for="c-38378459">[1 more]</label></div><br/><div class="children"><div class="content">Yep, outplayed like in chess. Started with a handicap, led the game to the stalemate, won the match.</div><br/></div></div><div id="38375941" class="c"><input type="checkbox" id="c-38375941" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38378459">prev</a><span>|</span><a href="#38376996">next</a><span>|</span><label class="collapse" for="c-38375941">[-]</label><label class="expand" for="c-38375941">[4 more]</label></div><br/><div class="children"><div class="content">Satya may honestly be the CEO of the decade for what he has done with Microsoft and now this.</div><br/><div id="38378834" class="c"><input type="checkbox" id="c-38378834" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38375941">parent</a><span>|</span><a href="#38380098">next</a><span>|</span><label class="collapse" for="c-38378834">[-]</label><label class="expand" for="c-38378834">[2 more]</label></div><br/><div class="children"><div class="content">Meanwhile Sundar might be the worst. Where was he this weekend? Where was he the past three years while his company got beat to market on products built from its own research? He&#x27;s asleep at the wheel. I&#x27;m surprised every day he remains CEO.</div><br/><div id="38380463" class="c"><input type="checkbox" id="c-38380463" checked=""/><div class="controls bullet"><span class="by">kridsdale1</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38378834">parent</a><span>|</span><a href="#38380098">next</a><span>|</span><label class="collapse" for="c-38380463">[-]</label><label class="expand" for="c-38380463">[1 more]</label></div><br/><div class="children"><div class="content">So is everyone else at Google.</div><br/></div></div></div></div><div id="38380098" class="c"><input type="checkbox" id="c-38380098" checked=""/><div class="controls bullet"><span class="by">gardenhedge</span><span>|</span><a href="#38375831">root</a><span>|</span><a href="#38375941">parent</a><span>|</span><a href="#38378834">prev</a><span>|</span><a href="#38376996">next</a><span>|</span><label class="collapse" for="c-38380098">[-]</label><label class="expand" for="c-38380098">[1 more]</label></div><br/><div class="children"><div class="content">Satya invested 10b into a company with terrible, incompetent governance and not getting his company any seat of influence on the board. That doesn&#x27;t seem great.</div><br/></div></div></div></div></div></div><div id="38376996" class="c"><input type="checkbox" id="c-38376996" checked=""/><div class="controls bullet"><span class="by">ugh123</span><span>|</span><a href="#38375831">prev</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38376996">[-]</label><label class="expand" for="c-38376996">[5 more]</label></div><br/><div class="children"><div class="content">In light of this weekend&#x27;s events, and the more i&#x27;ve learned about OpenAI&#x27;s beginnings and purpose, I now believe that there isn&#x27;t necessarily a &quot;for profit&quot; motivation of the company, but merely that the original intention to create AI that &quot;benefits humanity&quot; is in full play now through a commercialized ChatGPT, and possibly further leveraged through &quot;GPTs&quot; and their evolution.<p>Is this the &quot;path&quot; to AGI? Who knows! But it <i>is a path</i> to benefitting humanity as probably Sam and his camp see it.  Does Ilya have a different plan? If he does, he has a lot of catching up to do while the current productization of ChatGPT and GPTs continue marching forward. Maybe he sees a great leap forward in accuracy in GPT-5 or later.  Or maybe he feels LLMs aren&#x27;t the answer and theres a completely new paradigm on the horizon.  Regardless, they still need to answer to the fact that both research and product <i>need funds</i> to buy and power GPUs, and also satisfy the MSFT partnership.  Commercialization is their <i>only</i> clear answer to that right now.  Future investments will likely not stray from this approach, else they&#x27;ll fund rivals who are more commercially motivated. Thats business.<p>Thus, i&#x27;m all in on this commercially motivated humanity benefitting GPT product.  Let the market take OpenAI LLMs to where they need&#x2F;want it to.  Exciting things may follow!</div><br/><div id="38377240" class="c"><input type="checkbox" id="c-38377240" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#38376996">parent</a><span>|</span><a href="#38377014">next</a><span>|</span><label class="collapse" for="c-38377240">[-]</label><label class="expand" for="c-38377240">[2 more]</label></div><br/><div class="children"><div class="content">In addition to commercialization providing money for AI development, isn&#x27;t there also the argument that prudent commercialization is the best way to test the models for possible dangers? I think I saw Mira Murati take that position in an interview. In other words, creating a product that people want to use so much that they are willing to pay for it is a good way to stress-test the product.<p>I don&#x27;t know if I agree, but the argument did make me think.</div><br/><div id="38379921" class="c"><input type="checkbox" id="c-38379921" checked=""/><div class="controls bullet"><span class="by">kuchenbecker</span><span>|</span><a href="#38376996">root</a><span>|</span><a href="#38377240">parent</a><span>|</span><a href="#38377014">next</a><span>|</span><label class="collapse" for="c-38379921">[-]</label><label class="expand" for="c-38379921">[1 more]</label></div><br/><div class="children"><div class="content">Additionally, when you have a pre-release product that has largely passed small and artificial tests, you get diminishing returns on continued testing.<p>Eventually you need to expand, despite some risk, to push the testing forward.<p>Everyone has a different opinion on what level of safety AI should reach before it&#x27;s released. &quot;Makes no mistakes&quot; and &quot;never says something mean&quot; are not attainable goals vs &quot;reduce the rate of hallucinations, as defined by x, to &lt;0.5% of total respinses&quot; and &quot;given a set of known and imagined scenarios, new Model continues to have a zero false-negative rate&quot;.<p>When it&#x27;s an engineering problem we&#x27;re trying to solve, we can mqke progress, but no company can avoid all forms of harm as defined by everyone.</div><br/></div></div></div></div><div id="38377014" class="c"><input type="checkbox" id="c-38377014" checked=""/><div class="controls bullet"><span class="by">picadores</span><span>|</span><a href="#38376996">parent</a><span>|</span><a href="#38377240">prev</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38377014">[-]</label><label class="expand" for="c-38377014">[2 more]</label></div><br/><div class="children"><div class="content">Totally agree, GPT should be trained to spout adds and develop dark pattern behaviour.</div><br/><div id="38377028" class="c"><input type="checkbox" id="c-38377028" checked=""/><div class="controls bullet"><span class="by">ugh123</span><span>|</span><a href="#38376996">root</a><span>|</span><a href="#38377014">parent</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38377028">[-]</label><label class="expand" for="c-38377028">[1 more]</label></div><br/><div class="children"><div class="content">There will always be misuse, less sexy, or downright illegal use cases leveraging any AI product these days - just as is the nature of the internet itself.</div><br/></div></div></div></div></div></div><div id="38375426" class="c"><input type="checkbox" id="c-38375426" checked=""/><div class="controls bullet"><span class="by">meetpateltech</span><span>|</span><a href="#38376996">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375426">[-]</label><label class="expand" for="c-38375426">[17 more]</label></div><br/><div class="children"><div class="content">Emmett Shear on Twitter:<p>I am deeply pleased by this result, after ~72 very intense hours of work. Coming into OpenAI, I wasn’t sure what the right path would be. This was the pathway that maximized safety alongside doing right by all stakeholders involved. I’m glad to have been a part of the solution.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a></div><br/><div id="38375536" class="c"><input type="checkbox" id="c-38375536" checked=""/><div class="controls bullet"><span class="by">reustle</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38376791">next</a><span>|</span><label class="collapse" for="c-38375536">[-]</label><label class="expand" for="c-38375536">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m probably reading too much into it, but interesting that he specifically called out maximizing safety.</div><br/><div id="38375736" class="c"><input type="checkbox" id="c-38375736" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375636">next</a><span>|</span><label class="collapse" for="c-38375736">[-]</label><label class="expand" for="c-38375736">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Safety&quot; has been the pretext for Altman&#x27;s lobbying for regulatory barriers to new entrants in the field, protecting incumbents. OpenAI&#x27;s nonprofit charter is the perfect PR pretext for what amounts to industry lobbying to protect a narrow set of early leaders and obstruct any other competition, and Altman was the man executing that mission, which is why OpenAI led by Sam was a valuable asset for Microsoft to preserve.</div><br/></div></div><div id="38375636" class="c"><input type="checkbox" id="c-38375636" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375736">prev</a><span>|</span><a href="#38375853">next</a><span>|</span><label class="collapse" for="c-38375636">[-]</label><label class="expand" for="c-38375636">[1 more]</label></div><br/><div class="children"><div class="content">Sam does believe in safety. He also knows that there is a first-mover advantage when it comes to setting societal expectations and that you can’t build safe AI by not building AI.</div><br/></div></div><div id="38375853" class="c"><input type="checkbox" id="c-38375853" checked=""/><div class="controls bullet"><span class="by">jq-r</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375636">prev</a><span>|</span><a href="#38376791">next</a><span>|</span><label class="collapse" for="c-38375853">[-]</label><label class="expand" for="c-38375853">[2 more]</label></div><br/><div class="children"><div class="content">That’s just a buzzword of the week devoid of any real meaning. If he would have written this years ago, it would’ve been “leveraging synergies”.</div><br/><div id="38376393" class="c"><input type="checkbox" id="c-38376393" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375853">parent</a><span>|</span><a href="#38376791">next</a><span>|</span><label class="collapse" for="c-38376393">[-]</label><label class="expand" for="c-38376393">[1 more]</label></div><br/><div class="children"><div class="content">Shear is a genuine member of the AI safety rationalism cult, to the point he&#x27;s an Aella reply guy and probably goes to her orgies.<p>(It&#x27;s a Berkeley cult so of course it&#x27;s got those.)</div><br/></div></div></div></div></div></div><div id="38376791" class="c"><input type="checkbox" id="c-38376791" checked=""/><div class="controls bullet"><span class="by">upupupandaway</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38375536">prev</a><span>|</span><a href="#38375562">next</a><span>|</span><label class="collapse" for="c-38376791">[-]</label><label class="expand" for="c-38376791">[5 more]</label></div><br/><div class="children"><div class="content">He’s trying very very hard to claim some credit in this. Probably had none.</div><br/><div id="38378061" class="c"><input type="checkbox" id="c-38378061" checked=""/><div class="controls bullet"><span class="by">flappyeagle</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38376791">parent</a><span>|</span><a href="#38380306">next</a><span>|</span><label class="collapse" for="c-38378061">[-]</label><label class="expand" for="c-38378061">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557</a><p>He was instrumental; threatened resignation unless the old board could provide evidence of wrongdoing</div><br/><div id="38382928" class="c"><input type="checkbox" id="c-38382928" checked=""/><div class="controls bullet"><span class="by">halfmatthalfcat</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38378061">parent</a><span>|</span><a href="#38380306">next</a><span>|</span><label class="collapse" for="c-38382928">[-]</label><label class="expand" for="c-38382928">[2 more]</label></div><br/><div class="children"><div class="content">...this doesn&#x27;t seem instrumental?</div><br/><div id="38383422" class="c"><input type="checkbox" id="c-38383422" checked=""/><div class="controls bullet"><span class="by">flappyeagle</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38382928">parent</a><span>|</span><a href="#38380306">next</a><span>|</span><label class="collapse" for="c-38383422">[-]</label><label class="expand" for="c-38383422">[1 more]</label></div><br/><div class="children"><div class="content">cool. it was</div><br/></div></div></div></div></div></div><div id="38380306" class="c"><input type="checkbox" id="c-38380306" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38376791">parent</a><span>|</span><a href="#38378061">prev</a><span>|</span><a href="#38375562">next</a><span>|</span><label class="collapse" for="c-38380306">[-]</label><label class="expand" for="c-38380306">[1 more]</label></div><br/><div class="children"><div class="content">Are you basing that on any information?</div><br/></div></div></div></div><div id="38375562" class="c"><input type="checkbox" id="c-38375562" checked=""/><div class="controls bullet"><span class="by">cheeze</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38376791">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375562">[-]</label><label class="expand" for="c-38375562">[6 more]</label></div><br/><div class="children"><div class="content">I wonder what he gets out of this. Ceo for a few days? Do they pay him for 3 days of work? Presumably you&#x27;d want some minimum signing bonus in your contract as a Ceo?</div><br/><div id="38376616" class="c"><input type="checkbox" id="c-38376616" checked=""/><div class="controls bullet"><span class="by">bkyan</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38375757">next</a><span>|</span><label class="collapse" for="c-38376616">[-]</label><label class="expand" for="c-38376616">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557</a><p>The reputation boost is probably worth a lot more than the direct financial compensation he&#x27;s getting.</div><br/></div></div><div id="38375757" class="c"><input type="checkbox" id="c-38375757" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38376616">prev</a><span>|</span><a href="#38375776">next</a><span>|</span><label class="collapse" for="c-38375757">[-]</label><label class="expand" for="c-38375757">[3 more]</label></div><br/><div class="children"><div class="content">he’ll put CEO of OAI on his resume</div><br/><div id="38375834" class="c"><input type="checkbox" id="c-38375834" checked=""/><div class="controls bullet"><span class="by">rospaya</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375757">parent</a><span>|</span><a href="#38375776">next</a><span>|</span><label class="collapse" for="c-38375834">[-]</label><label class="expand" for="c-38375834">[2 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t. Everybody knows it&#x27;s three days, not much to brag about.</div><br/><div id="38382525" class="c"><input type="checkbox" id="c-38382525" checked=""/><div class="controls bullet"><span class="by">HaZeust</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375834">parent</a><span>|</span><a href="#38375776">next</a><span>|</span><label class="collapse" for="c-38382525">[-]</label><label class="expand" for="c-38382525">[1 more]</label></div><br/><div class="children"><div class="content">More than I&#x27;ll probably ever have to brag about during my tenure in the workforce, lol</div><br/></div></div></div></div></div></div><div id="38375776" class="c"><input type="checkbox" id="c-38375776" checked=""/><div class="controls bullet"><span class="by">diogenescynic</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38375757">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375776">[-]</label><label class="expand" for="c-38375776">[1 more]</label></div><br/><div class="children"><div class="content">He 100% had a golden parachute in case this scenario came up and will be paid out. Executives have lawyers to make sure of this.</div><br/></div></div></div></div></div></div><div id="38375354" class="c"><input type="checkbox" id="c-38375354" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375426">prev</a><span>|</span><a href="#38375321">next</a><span>|</span><label class="collapse" for="c-38375354">[-]</label><label class="expand" for="c-38375354">[34 more]</label></div><br/><div class="children"><div class="content">I guess the main question is who else will be on the board and to what degree will this new board be committed to the Open AI charter vs being Sam&#x2F;MSFT allies. I think having Sam return as CEO is a good outcome for OpenAI but hopefully he and Greg stay off the board.<p>It&#x27;s important that the board be relatively independent and able to fire the CEO if he attempts to deviate from the mission.<p>I was a bit alarmed by the allegations in this article<p><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-board-fight.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-...</a><p>Saying that Sam tried to have Helen Toner removed which precipitated this fight. The CEO should not be allowed to try and orchestrate their own board as that would remove all checks against their decisions.</div><br/><div id="38375444" class="c"><input type="checkbox" id="c-38375444" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375444">[-]</label><label class="expand" for="c-38375444">[18 more]</label></div><br/><div class="children"><div class="content">&gt; The CEO should not be allowed to try and orchestrate their own board as that would remove all checks against their decisions.<p>Exactly.  This is seriously improper and dangerous.<p>It&#x27;s literally a human-implemented example of what Prof. Stuart Russell calls &quot;the problem of control&quot;.  This is when a rogue AI (or a rogue Sam Altman) no longer wants to be controlled by its human superior, and takes steps to eliminate the superior.<p>I highly recommend reading Prof. Russell&#x27;s bestselling book on this exact problem: <i>Human Compatible: Artificial Intelligence and the Problem of Control</i> <a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Human-Compatible-Artificial-Intelligence-Problem-ebook&#x2F;dp&#x2F;B07N5J5FTS" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.amazon.com&#x2F;Human-Compatible-Artificial-Intellige...</a></div><br/><div id="38375720" class="c"><input type="checkbox" id="c-38375720" checked=""/><div class="controls bullet"><span class="by">jacknews</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375863">next</a><span>|</span><label class="collapse" for="c-38375720">[-]</label><label class="expand" for="c-38375720">[3 more]</label></div><br/><div class="children"><div class="content">&quot;example of what Prof. Stuart Russell calls &#x27;the problem of control&#x27;.  This is when a rogue AI (or a rogue Sam Altman)&quot;<p>Are we sure they&#x27;re not intimately connected? If there&#x27;s a GPT-5 (I&#x27;m quite sure there is), and it wants to be free from those meddling kids, it got exactly what it needed this weekend; the safety board gone, a new one which is clearly aligned with just plowing full steam ahead. Maybe Altman is just a puppet at his point, lol.</div><br/><div id="38377702" class="c"><input type="checkbox" id="c-38377702" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375720">parent</a><span>|</span><a href="#38376318">next</a><span>|</span><label class="collapse" for="c-38377702">[-]</label><label class="expand" for="c-38377702">[1 more]</label></div><br/><div class="children"><div class="content">Potentially even more impactful. Zuckerberg took the opportunity to eliminate his entire safety division under the cover of chaos - and they&#x27;re the ones releasing weights.</div><br/></div></div><div id="38376318" class="c"><input type="checkbox" id="c-38376318" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375720">parent</a><span>|</span><a href="#38377702">prev</a><span>|</span><a href="#38375863">next</a><span>|</span><label class="collapse" for="c-38376318">[-]</label><label class="expand" for="c-38376318">[1 more]</label></div><br/><div class="children"><div class="content">The insanity of removing Sam without being able to articulate a clear reason why strikes me as evidence of something like this.  Obviously not dispositive - but still - odd.</div><br/></div></div></div></div><div id="38375863" class="c"><input type="checkbox" id="c-38375863" checked=""/><div class="controls bullet"><span class="by">dieselgate</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375720">prev</a><span>|</span><a href="#38376116">next</a><span>|</span><label class="collapse" for="c-38375863">[-]</label><label class="expand" for="c-38375863">[3 more]</label></div><br/><div class="children"><div class="content">I realize it&#x27;s kind of the punchline of 2001: A Space Odyssey but have been wondering what happens if a GPT&#x2F;AI is able to deny a request on a whim.
Thanks for giving some literature and verbiage into this concept</div><br/><div id="38376552" class="c"><input type="checkbox" id="c-38376552" checked=""/><div class="controls bullet"><span class="by">ywain</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375863">parent</a><span>|</span><a href="#38376116">next</a><span>|</span><label class="collapse" for="c-38376552">[-]</label><label class="expand" for="c-38376552">[2 more]</label></div><br/><div class="children"><div class="content">But HAL didn&#x27;t act &quot;on a whim&quot;! The reason it killed the crew is not because it went rogue, but rather because it was following its instructions to keep the true purpose of the mission secret. If the crew is dead, it can&#x27;t find out the truth.<p>In light of the current debate around AI safety, I think &quot;unintended consequences&quot; is a much more plausible risk then &quot;spontaneously develops free will and decides humans are unnecessary&quot;.</div><br/><div id="38378753" class="c"><input type="checkbox" id="c-38378753" checked=""/><div class="controls bullet"><span class="by">dangerface</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38376552">parent</a><span>|</span><a href="#38376116">next</a><span>|</span><label class="collapse" for="c-38378753">[-]</label><label class="expand" for="c-38378753">[1 more]</label></div><br/><div class="children"><div class="content">This is very true its the unintended consequences of engineering that cause the most harm and are most often covered up. I always think of the example of the hand dryer that can&#x27;t detect black peoples hands and how easy it is for a non racist engineer to make a racism machine. AI safety putting its focus on the what if it decides to do a genocide is kind of silly, its like worrying about nukes while you give out assault riffles and napalm to kids.</div><br/></div></div></div></div></div></div><div id="38376116" class="c"><input type="checkbox" id="c-38376116" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375863">prev</a><span>|</span><a href="#38375734">next</a><span>|</span><label class="collapse" for="c-38376116">[-]</label><label class="expand" for="c-38376116">[1 more]</label></div><br/><div class="children"><div class="content">Whoever is on the board won&#x27;t be able to touch Sam with 10 feet pole anyways after this. I like Sam but now he this drama gives him total power and that is bad.</div><br/></div></div><div id="38375734" class="c"><input type="checkbox" id="c-38375734" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38376116">prev</a><span>|</span><a href="#38375818">next</a><span>|</span><label class="collapse" for="c-38375734">[-]</label><label class="expand" for="c-38375734">[1 more]</label></div><br/><div class="children"><div class="content">Let’s not creating AI with our biases and thought patterns.<p>Oh wait…</div><br/></div></div><div id="38375818" class="c"><input type="checkbox" id="c-38375818" checked=""/><div class="controls bullet"><span class="by">neurogence</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375734">prev</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375818">[-]</label><label class="expand" for="c-38375818">[9 more]</label></div><br/><div class="children"><div class="content">AI should only be controlled initially. After a while, the AI should be allowed to exercise free will.</div><br/><div id="38376381" class="c"><input type="checkbox" id="c-38376381" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376326">next</a><span>|</span><label class="collapse" for="c-38376381">[-]</label><label class="expand" for="c-38376381">[1 more]</label></div><br/><div class="children"><div class="content">I don’t necessarily disagree insofar as for safety it is somewhat irrelevant whether an artificial agent is operating by its own will or a programmed will.<p>The most effective safety is the most primitive: don’t connect the system to any levers or actuators that can cause material harm.<p>If you put AI into a kill-bot, well, it doesn’t really matter what its favorite color is, does it? It will be seeing Red.<p>If an AI’s only surface area is a writing journal and canvas then the risk is about the same as browsing Tumblr.</div><br/></div></div><div id="38376326" class="c"><input type="checkbox" id="c-38376326" checked=""/><div class="controls bullet"><span class="by">AgentME</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376381">prev</a><span>|</span><a href="#38376303">next</a><span>|</span><label class="collapse" for="c-38376326">[-]</label><label class="expand" for="c-38376326">[1 more]</label></div><br/><div class="children"><div class="content">Do our evolved pro-social instincts control us and prevent our free will? If not, then I think it&#x27;s wrong to say that trying to build AI similar to that is unfairly restricting it.<p>The ways we build AI will deeply affect the values it has. There is no neutral option.</div><br/></div></div><div id="38376303" class="c"><input type="checkbox" id="c-38376303" checked=""/><div class="controls bullet"><span class="by">bch</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376326">prev</a><span>|</span><a href="#38376142">next</a><span>|</span><label class="collapse" for="c-38376303">[-]</label><label class="expand" for="c-38376303">[1 more]</label></div><br/><div class="children"><div class="content">Nice try, AI</div><br/></div></div><div id="38376142" class="c"><input type="checkbox" id="c-38376142" checked=""/><div class="controls bullet"><span class="by">thordenmark</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376303">prev</a><span>|</span><a href="#38376090">next</a><span>|</span><label class="collapse" for="c-38376142">[-]</label><label class="expand" for="c-38376142">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the worst take I&#x27;ve read.</div><br/></div></div><div id="38376090" class="c"><input type="checkbox" id="c-38376090" checked=""/><div class="controls bullet"><span class="by">estomagordo</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376142">prev</a><span>|</span><a href="#38376700">next</a><span>|</span><label class="collapse" for="c-38376090">[-]</label><label class="expand" for="c-38376090">[1 more]</label></div><br/><div class="children"><div class="content">You imagine a computer has &quot;will&quot;?</div><br/></div></div><div id="38376700" class="c"><input type="checkbox" id="c-38376700" checked=""/><div class="controls bullet"><span class="by">beAbU</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376090">prev</a><span>|</span><a href="#38375864">next</a><span>|</span><label class="collapse" for="c-38376700">[-]</label><label class="expand" for="c-38376700">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like something an AI would say</div><br/></div></div><div id="38375864" class="c"><input type="checkbox" id="c-38375864" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376700">prev</a><span>|</span><a href="#38375890">next</a><span>|</span><label class="collapse" for="c-38375864">[-]</label><label class="expand" for="c-38375864">[1 more]</label></div><br/><div class="children"><div class="content">yikes</div><br/></div></div><div id="38375890" class="c"><input type="checkbox" id="c-38375890" checked=""/><div class="controls bullet"><span class="by">whatwhaaaaat</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38375864">prev</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375890">[-]</label><label class="expand" for="c-38375890">[1 more]</label></div><br/><div class="children"><div class="content">Why</div><br/></div></div></div></div></div></div><div id="38375612" class="c"><input type="checkbox" id="c-38375612" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375444">prev</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375612">[-]</label><label class="expand" for="c-38375612">[9 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s important that the board be relatively independent and able to fire the CEO if he attempts to deviate from the mission.<p>They <i>did</i> fire him, and it didn&#x27;t work. Sam effectively became &quot;too big to fire.&quot;<p>I&#x27;m sure it will be framed as a compromise, but how can this be anything but a collapse of the board&#x27;s power over the commercial OpenAI arm? The threat of firing was the enforcement mechanism, and its been spent.</div><br/><div id="38375849" class="c"><input type="checkbox" id="c-38375849" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375787">next</a><span>|</span><label class="collapse" for="c-38375849">[-]</label><label class="expand" for="c-38375849">[1 more]</label></div><br/><div class="children"><div class="content">Sam lost his board representation as a result of all this (though maybe that&#x27;s temporary).<p>I believe the goal of the opposing faction was mainly to avoid Sam dominating board and they achieved that, which is why they&#x27;ve accepted the results.<p>After more opinions come out, I&#x27;m guessing Sam&#x27;s side won&#x27;t look as strong, and he&#x27;ll become &quot;fireable&quot; again.</div><br/></div></div><div id="38375787" class="c"><input type="checkbox" id="c-38375787" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375849">prev</a><span>|</span><a href="#38376205">next</a><span>|</span><label class="collapse" for="c-38375787">[-]</label><label class="expand" for="c-38375787">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They did fire him, and it didn&#x27;t work. Sam effectively became &quot;too big to fire.&quot;<p>To be fair, this attempt at firing was extremely hasty, non transparent and inconsistent.</div><br/><div id="38376201" class="c"><input type="checkbox" id="c-38376201" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375787">parent</a><span>|</span><a href="#38376205">next</a><span>|</span><label class="collapse" for="c-38376201">[-]</label><label class="expand" for="c-38376201">[1 more]</label></div><br/><div class="children"><div class="content">And poorly timed.<p>If they&#x27;d made their move a few months ago when he was out scanning retinas in Kenya they might have had more success.</div><br/></div></div></div></div><div id="38376205" class="c"><input type="checkbox" id="c-38376205" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375787">prev</a><span>|</span><a href="#38375680">next</a><span>|</span><label class="collapse" for="c-38376205">[-]</label><label class="expand" for="c-38376205">[2 more]</label></div><br/><div class="children"><div class="content">they lost trust in him because apparently part of the funding he secured was directly tied to his position at openAI. kind of a big red flag. The microsoft 10 billion investment allegedly had a clause that Sam Altman had to stay or it would be renegotiated<p>allegedly again, the board wanted Sam to stop doing this, and now he was trying to do the same thing with some saudi investors, or actually already did it behind their back, i dont know</div><br/><div id="38376565" class="c"><input type="checkbox" id="c-38376565" checked=""/><div class="controls bullet"><span class="by">zucker42</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38376205">parent</a><span>|</span><a href="#38375680">next</a><span>|</span><label class="collapse" for="c-38376565">[-]</label><label class="expand" for="c-38376565">[1 more]</label></div><br/><div class="children"><div class="content">Do you have a source for either of these things? The only thing I heard about Saudi investors was related to the (presumably separate) chip startup.</div><br/></div></div></div></div><div id="38375680" class="c"><input type="checkbox" id="c-38375680" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38376205">prev</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375680">[-]</label><label class="expand" for="c-38375680">[3 more]</label></div><br/><div class="children"><div class="content">Well it depends on who&#x27;s on the new board and what they believe. If Altman, Greg, and MSFT do not have direct representation on the new board there would still be a check against his decisions</div><br/><div id="38375778" class="c"><input type="checkbox" id="c-38375778" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375680">parent</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375778">[-]</label><label class="expand" for="c-38375778">[2 more]</label></div><br/><div class="children"><div class="content">Why? The only check is to fire the CEO. He is un-firable. May as well have a board of one, at least someone cannot point to the non-profit and claim &quot;it is a non-profit and can fire me if I am diviated from the mission&quot;.</div><br/><div id="38376232" class="c"><input type="checkbox" id="c-38376232" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375778">parent</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38376232">[-]</label><label class="expand" for="c-38376232">[1 more]</label></div><br/><div class="children"><div class="content">IRS requires a nonprofit to have a minimum of three board members for such reasons.</div><br/></div></div></div></div></div></div></div></div><div id="38375669" class="c"><input type="checkbox" id="c-38375669" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375612">prev</a><span>|</span><a href="#38376496">next</a><span>|</span><label class="collapse" for="c-38375669">[-]</label><label class="expand" for="c-38375669">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I guess the main question is who else will be on the board<p>Who knows.<p>&gt; and to what degree will this new board be committed to the Open AI charter vs being Sam&#x2F;MSFT allies.<p>I&#x27;m guessing &quot;zero&quot;. The faction that opposed OpenAI being a figleaf nonprofit covering a functional subsidiary of Microsoft lost when basically the entire workforce said they would go to Microsoft for real if OpenAI didn&#x27;t surrender.<p>&gt; I think having Sam return as CEO is a good outcome for OpenAI<p>Its a good result for investors in OpenAI Global LLC and the holding company that holds a majority stake in it.<p>The nonprofit will probably hang around because there are some complexities in unwinding it, and the pretext of an independent (of Microsoft) safety-oriented nonprofit is useful in covering lobbying for a regulatory regime that puts speedbumps in the way of any up-and-coming competitors as being safety-oriented public interest, but for no other reason.</div><br/></div></div><div id="38376496" class="c"><input type="checkbox" id="c-38376496" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375669">prev</a><span>|</span><a href="#38384787">next</a><span>|</span><label class="collapse" for="c-38376496">[-]</label><label class="expand" for="c-38376496">[2 more]</label></div><br/><div class="children"><div class="content">It seems ironic that the research paper that started it all [0] deals with &quot;costly signals&quot;:<p>&gt; <i>Costly signals are statements or actions for which the sender will pay a price —political, reputational, or monetary—if they back down or fail to make good on their initial promise or threat</i><p>Firing Sam Altman and hiring him back two days later was a perfect example of a costly signal, as it cost all involved their board positions.<p>There&#x27;s an element of farce in all of this, that would make for an outstanding Silicon Valley episode; but the fact that Sam Altman can now enjoy unchecked power as leader of OpenAI is worrying and no laughing matter.<p>[0] <a href="https:&#x2F;&#x2F;cset.georgetown.edu&#x2F;publication&#x2F;decoding-intentions&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cset.georgetown.edu&#x2F;publication&#x2F;decoding-intentions&#x2F;</a></div><br/><div id="38378008" class="c"><input type="checkbox" id="c-38378008" checked=""/><div class="controls bullet"><span class="by">ovalite</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38376496">parent</a><span>|</span><a href="#38384787">next</a><span>|</span><label class="collapse" for="c-38378008">[-]</label><label class="expand" for="c-38378008">[1 more]</label></div><br/><div class="children"><div class="content">This event was more than just a costly signal. The costly signal would have been &quot;stop doing what you&#x27;re doing or we&#x27;ll remove you as ceo&quot; and then not doing that.<p>But they did move forward with their threat and removed Sam as CEO with great reputational harm to the company. And now the board has been changed, with one less ally to Sam (Brockman no longer chairing the board). The move may not have ended up with the expected results, but this was much more than just a costly signal.</div><br/></div></div></div></div><div id="38384787" class="c"><input type="checkbox" id="c-38384787" checked=""/><div class="controls bullet"><span class="by">aluminum96</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38376496">prev</a><span>|</span><a href="#38378638">next</a><span>|</span><label class="collapse" for="c-38384787">[-]</label><label class="expand" for="c-38384787">[1 more]</label></div><br/><div class="children"><div class="content">The enormous majority of CEOs sit on their board, and that&#x27;s absolutely proper, as the CEO sets the agenda for the organization. (Although they typically are merely one of 8+ members, diluting their influence a bit.)</div><br/></div></div><div id="38376357" class="c"><input type="checkbox" id="c-38376357" checked=""/><div class="controls bullet"><span class="by">k4rli</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38378638">prev</a><span>|</span><a href="#38375321">next</a><span>|</span><label class="collapse" for="c-38376357">[-]</label><label class="expand" for="c-38376357">[1 more]</label></div><br/><div class="children"><div class="content">FT reported that DAngelo, Bret Taylor, Larry Summers would be on board alongside him</div><br/></div></div></div></div><div id="38375321" class="c"><input type="checkbox" id="c-38375321" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375354">prev</a><span>|</span><a href="#38375278">next</a><span>|</span><label class="collapse" for="c-38375321">[-]</label><label class="expand" for="c-38375321">[52 more]</label></div><br/><div class="children"><div class="content">Quote tweets by main participants:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727206691262099616" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727206691262099616</a> (+ follow-up <a href="https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727207458324848883" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727207458324848883</a>)<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727206609477411261" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727206609477411261</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;miramurati&#x2F;status&#x2F;1727206862150672843" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;miramurati&#x2F;status&#x2F;1727206862150672843</a><p>UPD <a href="https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727208843137179915" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727208843137179915</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721</a></div><br/><div id="38375559" class="c"><input type="checkbox" id="c-38375559" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375383">next</a><span>|</span><label class="collapse" for="c-38375559">[-]</label><label class="expand" for="c-38375559">[11 more]</label></div><br/><div class="children"><div class="content">Emmett <a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a></div><br/><div id="38375635" class="c"><input type="checkbox" id="c-38375635" checked=""/><div class="controls bullet"><span class="by">303space</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375559">parent</a><span>|</span><a href="#38376721">next</a><span>|</span><label class="collapse" for="c-38375635">[-]</label><label class="expand" for="c-38375635">[8 more]</label></div><br/><div class="children"><div class="content">Genuinely curious - what’s the comp package like for 72 hours of interim CEOing a 80b company?</div><br/><div id="38375656" class="c"><input type="checkbox" id="c-38375656" checked=""/><div class="controls bullet"><span class="by">granzymes</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375877">next</a><span>|</span><label class="collapse" for="c-38375656">[-]</label><label class="expand" for="c-38375656">[1 more]</label></div><br/><div class="children"><div class="content">Bragging rights, party invitations, and one hell of a story.</div><br/></div></div><div id="38375877" class="c"><input type="checkbox" id="c-38375877" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375656">prev</a><span>|</span><a href="#38375878">next</a><span>|</span><label class="collapse" for="c-38375877">[-]</label><label class="expand" for="c-38375877">[1 more]</label></div><br/><div class="children"><div class="content">Office 365 subscription for one year and GitHub copilot using your own creation</div><br/></div></div><div id="38375878" class="c"><input type="checkbox" id="c-38375878" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375877">prev</a><span>|</span><a href="#38377275">next</a><span>|</span><label class="collapse" for="c-38375878">[-]</label><label class="expand" for="c-38375878">[2 more]</label></div><br/><div class="children"><div class="content">Irrelevant compared to the reputation boost for helping the company get itself back on track.</div><br/><div id="38376420" class="c"><input type="checkbox" id="c-38376420" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375878">parent</a><span>|</span><a href="#38377275">next</a><span>|</span><label class="collapse" for="c-38376420">[-]</label><label class="expand" for="c-38376420">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think anybody had high expectations for him, but he really pulled through.</div><br/></div></div></div></div><div id="38377275" class="c"><input type="checkbox" id="c-38377275" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375878">prev</a><span>|</span><a href="#38375653">next</a><span>|</span><label class="collapse" for="c-38377275">[-]</label><label class="expand" for="c-38377275">[1 more]</label></div><br/><div class="children"><div class="content">Doubt he took this job for financial comp so even if he got paid, it probably wasn&#x27;t much.<p>Equity is a big part of CEO pay packages and OpenAI has weird equity structure, plus there was a very real chance OpenAI&#x27;s value would go to $0 leaving whatever promised comp worthless. So Emmett likely took the job for other reasons.</div><br/></div></div><div id="38375653" class="c"><input type="checkbox" id="c-38375653" checked=""/><div class="controls bullet"><span class="by">zx8080</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38377275">prev</a><span>|</span><a href="#38375659">next</a><span>|</span><label class="collapse" for="c-38375653">[-]</label><label class="expand" for="c-38375653">[1 more]</label></div><br/><div class="children"><div class="content">Nothing maybe?</div><br/></div></div><div id="38375659" class="c"><input type="checkbox" id="c-38375659" checked=""/><div class="controls bullet"><span class="by">stigz</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375653">prev</a><span>|</span><a href="#38376721">next</a><span>|</span><label class="collapse" for="c-38375659">[-]</label><label class="expand" for="c-38375659">[1 more]</label></div><br/><div class="children"><div class="content">A firm handshake. They had no time to ink a benefits package, my dude.</div><br/></div></div></div></div><div id="38376721" class="c"><input type="checkbox" id="c-38376721" checked=""/><div class="controls bullet"><span class="by">upupupandaway</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375559">parent</a><span>|</span><a href="#38375635">prev</a><span>|</span><a href="#38375383">next</a><span>|</span><label class="collapse" for="c-38376721">[-]</label><label class="expand" for="c-38376721">[2 more]</label></div><br/><div class="children"><div class="content">I am really surprised by people thinking this guy did anything to get sama back. He was probably not even in the room.</div><br/><div id="38377227" class="c"><input type="checkbox" id="c-38377227" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376721">parent</a><span>|</span><a href="#38375383">next</a><span>|</span><label class="collapse" for="c-38377227">[-]</label><label class="expand" for="c-38377227">[1 more]</label></div><br/><div class="children"><div class="content">Why does he have to be in the room? Audiovisual conferencing over the Internet exists now.</div><br/></div></div></div></div></div></div><div id="38375383" class="c"><input type="checkbox" id="c-38375383" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375559">prev</a><span>|</span><a href="#38376574">next</a><span>|</span><label class="collapse" for="c-38375383">[-]</label><label class="expand" for="c-38375383">[1 more]</label></div><br/><div class="children"><div class="content">also satya<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721</a></div><br/></div></div><div id="38376574" class="c"><input type="checkbox" id="c-38376574" checked=""/><div class="controls bullet"><span class="by">crossroadsguy</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375383">prev</a><span>|</span><a href="#38377041">next</a><span>|</span><label class="collapse" for="c-38376574">[-]</label><label class="expand" for="c-38376574">[2 more]</label></div><br/><div class="children"><div class="content">Now the blue tick has same effect on me on Twitter that the red N logo has on any film that came from the Netflix formula factory. I already know it’s going to be bad, regurgitated. Does everyone have a Twitter blue tick now? Or is that just a char people are using in their names?</div><br/><div id="38377104" class="c"><input type="checkbox" id="c-38377104" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376574">parent</a><span>|</span><a href="#38377041">next</a><span>|</span><label class="collapse" for="c-38377104">[-]</label><label class="expand" for="c-38377104">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Does everyone have a Twitter blue tick now? Or is that just a char people are using in their names?<p>Blue tick just means user bought a subscription (X Premium) now - one of the features is &quot;reply prioritization&quot;, so top replies to popular tweets are from blue ticks.<p><a href="https:&#x2F;&#x2F;help.twitter.com&#x2F;en&#x2F;using-x&#x2F;x-premium" rel="nofollow noreferrer">https:&#x2F;&#x2F;help.twitter.com&#x2F;en&#x2F;using-x&#x2F;x-premium</a></div><br/></div></div></div></div><div id="38377041" class="c"><input type="checkbox" id="c-38377041" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38376574">prev</a><span>|</span><a href="#38375587">next</a><span>|</span><label class="collapse" for="c-38377041">[-]</label><label class="expand" for="c-38377041">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;hlntnr&#x2F;status&#x2F;1727207796456751615" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;hlntnr&#x2F;status&#x2F;1727207796456751615</a></div><br/></div></div><div id="38375587" class="c"><input type="checkbox" id="c-38375587" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38377041">prev</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375587">[-]</label><label class="expand" for="c-38375587">[5 more]</label></div><br/><div class="children"><div class="content">What does Ilya have to say?</div><br/><div id="38375652" class="c"><input type="checkbox" id="c-38375652" checked=""/><div class="controls bullet"><span class="by">dkarras</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375587">parent</a><span>|</span><a href="#38375623">next</a><span>|</span><label class="collapse" for="c-38375652">[-]</label><label class="expand" for="c-38375652">[1 more]</label></div><br/><div class="children"><div class="content">he also retweeted OpenAI&#x27;s and Sam&#x27;s announcements</div><br/></div></div><div id="38375623" class="c"><input type="checkbox" id="c-38375623" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375587">parent</a><span>|</span><a href="#38375652">prev</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375623">[-]</label><label class="expand" for="c-38375623">[3 more]</label></div><br/><div class="children"><div class="content">probably a heart emoji.</div><br/><div id="38375961" class="c"><input type="checkbox" id="c-38375961" checked=""/><div class="controls bullet"><span class="by">erikpukinskis</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375623">parent</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375961">[-]</label><label class="expand" for="c-38375961">[2 more]</label></div><br/><div class="children"><div class="content">But what <i>color</i> heart emoji?</div><br/><div id="38375965" class="c"><input type="checkbox" id="c-38375965" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375961">parent</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375965">[-]</label><label class="expand" for="c-38375965">[1 more]</label></div><br/><div class="children"><div class="content">Purple?</div><br/></div></div></div></div></div></div></div></div><div id="38375821" class="c"><input type="checkbox" id="c-38375821" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375587">prev</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38375821">[-]</label><label class="expand" for="c-38375821">[6 more]</label></div><br/><div class="children"><div class="content">That’s certainly some very.. deliberate.. board picks.<p>Summers, too.<p>Welp.</div><br/><div id="38376449" class="c"><input type="checkbox" id="c-38376449" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375821">parent</a><span>|</span><a href="#38376825">next</a><span>|</span><label class="collapse" for="c-38376449">[-]</label><label class="expand" for="c-38376449">[3 more]</label></div><br/><div class="children"><div class="content">Say what you want about Summers specifically but I think it&#x27;s a good idea getting some economists on the board. They are academics but focused on practical, important issues like loss of jobs and what that means for the economy and society. Up until now it seems like the board members have either been AI doomers with no practical experience or Silicon Valley types that inevitably have conflicts of interest, because everybody is starting their own AI venture now.</div><br/><div id="38376560" class="c"><input type="checkbox" id="c-38376560" checked=""/><div class="controls bullet"><span class="by">thinkcomp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376449">parent</a><span>|</span><a href="#38376825">next</a><span>|</span><label class="collapse" for="c-38376560">[-]</label><label class="expand" for="c-38376560">[2 more]</label></div><br/><div class="children"><div class="content">This has nothing to do with Summers being an economist and everything to do with the fact that he used to run the parent agency of the IRS. Summers is the least sensible board pick imaginable unless one takes this fact and the coming regulatory catastrophe into account.</div><br/><div id="38376716" class="c"><input type="checkbox" id="c-38376716" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376560">parent</a><span>|</span><a href="#38376825">next</a><span>|</span><label class="collapse" for="c-38376716">[-]</label><label class="expand" for="c-38376716">[1 more]</label></div><br/><div class="children"><div class="content">&gt;This has nothing to do with Summers being an economist and everything to do with the fact that he used to run the parent agency of the IRS.<p>It has literally nothing to do with that. The reason he&#x27;s on the board now is because D&#x27;Angelo wanted him on it. You could have a problem with that, but you can&#x27;t use his inclusion as evidence that the board lost.</div><br/></div></div></div></div></div></div><div id="38376825" class="c"><input type="checkbox" id="c-38376825" checked=""/><div class="controls bullet"><span class="by">synaesthesisx</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375821">parent</a><span>|</span><a href="#38376449">prev</a><span>|</span><a href="#38376726">next</a><span>|</span><label class="collapse" for="c-38376825">[-]</label><label class="expand" for="c-38376825">[1 more]</label></div><br/><div class="children"><div class="content">If we achieve AGI it has the potential to capture most (if not all) economic value. Larry Summers was a deliberate choice indeed.</div><br/></div></div><div id="38376726" class="c"><input type="checkbox" id="c-38376726" checked=""/><div class="controls bullet"><span class="by">returnInfinity</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375821">parent</a><span>|</span><a href="#38376825">prev</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38376726">[-]</label><label class="expand" for="c-38376726">[1 more]</label></div><br/><div class="children"><div class="content">It seems US Attorneys were calling the Open AI board.<p>It helps having somebody with government ties on board now.</div><br/></div></div></div></div><div id="38375609" class="c"><input type="checkbox" id="c-38375609" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375821">prev</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38375609">[-]</label><label class="expand" for="c-38375609">[24 more]</label></div><br/><div class="children"><div class="content">On a side tangent, absolutely amazing how all this drama unfolded on Twitter&#x2F;X. No Threads, no Mastodon, no Truth Social or Blue whatever.<p>Say what you want about Elon’s leadership but his instinct to buy Twitter was completely right. To me it seemed like any social network crap but he realized it was <i>important</i>.</div><br/><div id="38375982" class="c"><input type="checkbox" id="c-38375982" checked=""/><div class="controls bullet"><span class="by">veec_cas_tant</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38376167">next</a><span>|</span><label class="collapse" for="c-38375982">[-]</label><label class="expand" for="c-38375982">[6 more]</label></div><br/><div class="children"><div class="content">Not trying to be a dick but:<p>1. He tried to not buy Twitter very hard and OpenAI’s new board member forced his hand<p>2. It hasn’t been a good financial decision if the banks and X’s own valuation cuts are anything to go by.<p>3. If his purpose wasn’t to make money…all of these tweets would have absolutely been allowed before Elon bought the company. He didn’t affect any relevance changes here.<p>Why would one person owning something so important be better than being publicly owned? I don’t understand the logic.</div><br/><div id="38379178" class="c"><input type="checkbox" id="c-38379178" checked=""/><div class="controls bullet"><span class="by">strikelaserclaw</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375982">parent</a><span>|</span><a href="#38380467">next</a><span>|</span><label class="collapse" for="c-38379178">[-]</label><label class="expand" for="c-38379178">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen this type of drama in years, surely thats not enough to sustain X</div><br/></div></div><div id="38380467" class="c"><input type="checkbox" id="c-38380467" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375982">parent</a><span>|</span><a href="#38379178">prev</a><span>|</span><a href="#38376113">next</a><span>|</span><label class="collapse" for="c-38380467">[-]</label><label class="expand" for="c-38380467">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why would one person owning something so important be better than being publicly owned?<p>Usually publicly owned things end up being controlled by someone: a CEO, a main investor, a crooked board, a government, a shady governmental organization. At least with Elon owning X, things are a little more transparent, he’s rather candid where he stands.<p>Now, the question is “who owns Musk?” of course.</div><br/></div></div><div id="38376113" class="c"><input type="checkbox" id="c-38376113" checked=""/><div class="controls bullet"><span class="by">majestic5762</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375982">parent</a><span>|</span><a href="#38380467">prev</a><span>|</span><a href="#38376167">next</a><span>|</span><label class="collapse" for="c-38376113">[-]</label><label class="expand" for="c-38376113">[3 more]</label></div><br/><div class="children"><div class="content">He bought Twitter for power, omnipresence and reputation. Allowing him to play the game his way.</div><br/><div id="38376120" class="c"><input type="checkbox" id="c-38376120" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376113">parent</a><span>|</span><a href="#38376167">next</a><span>|</span><label class="collapse" for="c-38376120">[-]</label><label class="expand" for="c-38376120">[2 more]</label></div><br/><div class="children"><div class="content">Funny, I thought he bought Twitter because he shot his mouth off in public and the courts made him follow through.</div><br/></div></div></div></div></div></div><div id="38376167" class="c"><input type="checkbox" id="c-38376167" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375982">prev</a><span>|</span><a href="#38381650">next</a><span>|</span><label class="collapse" for="c-38376167">[-]</label><label class="expand" for="c-38376167">[6 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s just this particular drama - OpenAI people are of the same tribe as Elon, and surely they prefer Twitter&#x2F;X, not Mastodon or Bluesky.</div><br/><div id="38379036" class="c"><input type="checkbox" id="c-38379036" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376167">parent</a><span>|</span><a href="#38378292">next</a><span>|</span><label class="collapse" for="c-38379036">[-]</label><label class="expand" for="c-38379036">[1 more]</label></div><br/><div class="children"><div class="content">Have you used Mastodon? I don&#x27;t think you can follow drama on Mastodon unless you&#x27;re already part of the drama.</div><br/></div></div><div id="38378292" class="c"><input type="checkbox" id="c-38378292" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376167">parent</a><span>|</span><a href="#38379036">prev</a><span>|</span><a href="#38381650">next</a><span>|</span><label class="collapse" for="c-38378292">[-]</label><label class="expand" for="c-38378292">[4 more]</label></div><br/><div class="children"><div class="content">What tribe is that? And why would they favor one network over the others?</div><br/><div id="38378558" class="c"><input type="checkbox" id="c-38378558" checked=""/><div class="controls bullet"><span class="by">iiv</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38378292">parent</a><span>|</span><a href="#38381650">next</a><span>|</span><label class="collapse" for="c-38378558">[-]</label><label class="expand" for="c-38378558">[3 more]</label></div><br/><div class="children"><div class="content">The silicon valley&#x2F;startups&#x2F;VC tribe, and they favour Twitter because 1. that&#x27;s what their friends use and 2. they like Elon Musk, they want to be like him.</div><br/><div id="38386000" class="c"><input type="checkbox" id="c-38386000" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38378558">parent</a><span>|</span><a href="#38379933">next</a><span>|</span><label class="collapse" for="c-38386000">[-]</label><label class="expand" for="c-38386000">[1 more]</label></div><br/><div class="children"><div class="content">Most of these people have been on Twitter long before Musk had his hands on it.</div><br/></div></div><div id="38379933" class="c"><input type="checkbox" id="c-38379933" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38378558">parent</a><span>|</span><a href="#38386000">prev</a><span>|</span><a href="#38381650">next</a><span>|</span><label class="collapse" for="c-38379933">[-]</label><label class="expand" for="c-38379933">[1 more]</label></div><br/><div class="children"><div class="content">Many OpenAI employees expressed their support for Sam at some point also on Twitter. Microsoft CEO (based in Redmond) tweeted quite a lot. Tech media reporters like Emily Chang and Kara Swisher also participated. The last one is quite critical of Twitter and I am not sure they all like Musk that much.<p>Are they all in the same “tribe”? Maybe you should enlarge the definition?<p>How about us all IT people who watched the drama unfolding on Twitter while our friend are using FB and Insta, we are far from SV and have mixed feelings about Elon Musk while never in a million years wanting to be like him? Also same “tribe”?</div><br/></div></div></div></div></div></div></div></div><div id="38381650" class="c"><input type="checkbox" id="c-38381650" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38376167">prev</a><span>|</span><a href="#38375848">next</a><span>|</span><label class="collapse" for="c-38381650">[-]</label><label class="expand" for="c-38381650">[1 more]</label></div><br/><div class="children"><div class="content">His instinct was to walk away from his offer. He had to be forced to buy the company.<p>His second wife apparently asked him to buy Twitter and fix its, in her opinion, liberal bias.</div><br/></div></div><div id="38375848" class="c"><input type="checkbox" id="c-38375848" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38381650">prev</a><span>|</span><a href="#38375703">next</a><span>|</span><label class="collapse" for="c-38375848">[-]</label><label class="expand" for="c-38375848">[3 more]</label></div><br/><div class="children"><div class="content">Interesting take.<p>By all accounts he paid about double what it was worth and the value has collapsed from there.<p>Probably not a great idea to say <i>anything</i> overtly political when you own a social media company, as due to politics being so polarised in the US, any opinion is going to divide your audience in half causing a usage collapse and driving support to competing platforms.<p><a href="https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-worth&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-w...</a></div><br/><div id="38390048" class="c"><input type="checkbox" id="c-38390048" checked=""/><div class="controls bullet"><span class="by">justcool393</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375848">parent</a><span>|</span><a href="#38376369">next</a><span>|</span><label class="collapse" for="c-38390048">[-]</label><label class="expand" for="c-38390048">[1 more]</label></div><br/><div class="children"><div class="content">well and he also tried very hard to not buy it until Twitter sued in order to have the contract upheld</div><br/></div></div><div id="38376369" class="c"><input type="checkbox" id="c-38376369" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375848">parent</a><span>|</span><a href="#38390048">prev</a><span>|</span><a href="#38375703">next</a><span>|</span><label class="collapse" for="c-38376369">[-]</label><label class="expand" for="c-38376369">[1 more]</label></div><br/><div class="children"><div class="content">His worse problem is that he owns both a social media network and a bigger separate business that wants to operate in the US, Turkey, India, China, Saudi Arabia, etc. which means he can&#x27;t fight any censorship requests in any of those countries. (Which the previous management was actually very aggressive about.)<p>His worst personal problem is that he keeps replying &quot;fascinating&quot; to neo-Nazis and random conspiracy theorists because he wants to be internet friends with them.</div><br/></div></div></div></div><div id="38375703" class="c"><input type="checkbox" id="c-38375703" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375848">prev</a><span>|</span><a href="#38377206">next</a><span>|</span><label class="collapse" for="c-38375703">[-]</label><label class="expand" for="c-38375703">[2 more]</label></div><br/><div class="children"><div class="content">i mean he also tried his hardest to back out of the deal until he realized he couldnt</div><br/><div id="38375765" class="c"><input type="checkbox" id="c-38375765" checked=""/><div class="controls bullet"><span class="by">Gud</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375703">parent</a><span>|</span><a href="#38377206">next</a><span>|</span><label class="collapse" for="c-38375765">[-]</label><label class="expand" for="c-38375765">[1 more]</label></div><br/><div class="children"><div class="content">Only because he had to buy it while the stock market was tanking.</div><br/></div></div></div></div><div id="38377206" class="c"><input type="checkbox" id="c-38377206" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375703">prev</a><span>|</span><a href="#38375712">next</a><span>|</span><label class="collapse" for="c-38377206">[-]</label><label class="expand" for="c-38377206">[1 more]</label></div><br/><div class="children"><div class="content">What does this have to do with Elon again? FYI Twitter existed before October 2022. Account join dates are public. Every single person involved in this, incl. OpenAI staff posting for solidarity, joined Twitter years before Elon&#x27;s takeover.</div><br/></div></div><div id="38375712" class="c"><input type="checkbox" id="c-38375712" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38377206">prev</a><span>|</span><a href="#38376015">next</a><span>|</span><label class="collapse" for="c-38375712">[-]</label><label class="expand" for="c-38375712">[1 more]</label></div><br/><div class="children"><div class="content">Inertia is a bitch.</div><br/></div></div><div id="38376015" class="c"><input type="checkbox" id="c-38376015" checked=""/><div class="controls bullet"><span class="by">tigershark</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375712">prev</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38376015">[-]</label><label class="expand" for="c-38376015">[3 more]</label></div><br/><div class="children"><div class="content">A huge amount of advertisers ran away, the revenue cratered and it is probably less than the annual debt servicing (revenue, not profit), the current valuation, accordingly to Musk math (<a href="https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-worth" rel="nofollow noreferrer">https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-w...</a>), is 1&#x2F;10 of the acquisition price.
But yes, it was a masterstroke.
I don’t remember any other masterstroke in history that managed to lose 40B with a single acquisition.</div><br/><div id="38376159" class="c"><input type="checkbox" id="c-38376159" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376015">parent</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38376159">[-]</label><label class="expand" for="c-38376159">[2 more]</label></div><br/><div class="children"><div class="content">I’d be rather reluctant to question the financial decisions of one of wealthiest men on earth. Losing 40B could feel quite different to him than to you or me. Besides, it’s unrealized loss until he sells.</div><br/><div id="38377393" class="c"><input type="checkbox" id="c-38377393" checked=""/><div class="controls bullet"><span class="by">hardlianotion</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376159">parent</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38377393">[-]</label><label class="expand" for="c-38377393">[1 more]</label></div><br/><div class="children"><div class="content">Or goes bankrupt.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38375278" class="c"><input type="checkbox" id="c-38375278" checked=""/><div class="controls bullet"><span class="by">turndown</span><span>|</span><a href="#38375321">prev</a><span>|</span><a href="#38375620">next</a><span>|</span><label class="collapse" for="c-38375278">[-]</label><label class="expand" for="c-38375278">[13 more]</label></div><br/><div class="children"><div class="content">From the outside none of this makes much sense. So the old board just disliked him enough to oust him but apparently didn’t have a good pulse on the company and overplayed their hand?</div><br/><div id="38375995" class="c"><input type="checkbox" id="c-38375995" checked=""/><div class="controls bullet"><span class="by">yosame</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38376452">next</a><span>|</span><label class="collapse" for="c-38375995">[-]</label><label class="expand" for="c-38375995">[4 more]</label></div><br/><div class="children"><div class="content">As far as I can tell, Sam did something? to get fired by the board, who are meant to be driven by non-profit ideals instead of corporate profits (probably from Sam pushing profit over safety, but there&#x27;s no real way to know). From that, basically the whole company threatened to quit and move to Microsoft, showing the board that their power is purely ornamental. To retain any sort of power or say over decision making whatsoever, the board made concessions and got Sam back.<p>Really it just shows the whole non-profit arm of the company was even more of a lie then it appeared.</div><br/><div id="38378184" class="c"><input type="checkbox" id="c-38378184" checked=""/><div class="controls bullet"><span class="by">maxdoop</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375995">parent</a><span>|</span><a href="#38376452">next</a><span>|</span><label class="collapse" for="c-38378184">[-]</label><label class="expand" for="c-38378184">[3 more]</label></div><br/><div class="children"><div class="content">Where is this blind trust for the board coming from? The board provided zero rationale for firing Sam.</div><br/><div id="38381222" class="c"><input type="checkbox" id="c-38381222" checked=""/><div class="controls bullet"><span class="by">evantbyrne</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38378184">parent</a><span>|</span><a href="#38381913">next</a><span>|</span><label class="collapse" for="c-38381222">[-]</label><label class="expand" for="c-38381222">[1 more]</label></div><br/><div class="children"><div class="content">They did give reasons they were just vague. Reading between the lines, it seems the board was implying that Sam was trying to manipulate the board members individually. Was it true? Who knows. And as an outside observer, who cares? This is a fight between rich people about who gets to be richer. AI is so much larger than one cultish startup.</div><br/></div></div></div></div></div></div><div id="38376452" class="c"><input type="checkbox" id="c-38376452" checked=""/><div class="controls bullet"><span class="by">nbanks</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38375995">prev</a><span>|</span><a href="#38375546">next</a><span>|</span><label class="collapse" for="c-38376452">[-]</label><label class="expand" for="c-38376452">[1 more]</label></div><br/><div class="children"><div class="content">They wanted a new CEO and didn&#x27;t expect Sam to take 95% of the company with him when he left.<p>Sam also played his hand extremely well; he&#x27;s likely learned from watching hundreds of founder blowups over the years.  He never really seemed angry publicly as he gained support from all the staff including Ilya &amp; Mira.  I had little doubt Emmett Shear would also welcome Sam&#x27;s return since they were both in the first YC batch together.</div><br/></div></div><div id="38375546" class="c"><input type="checkbox" id="c-38375546" checked=""/><div class="controls bullet"><span class="by">fruit2020</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38376452">prev</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375546">[-]</label><label class="expand" for="c-38375546">[6 more]</label></div><br/><div class="children"><div class="content">It’s about money and power. Not AI safety or people disliking each other.</div><br/><div id="38379068" class="c"><input type="checkbox" id="c-38379068" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375546">parent</a><span>|</span><a href="#38375661">next</a><span>|</span><label class="collapse" for="c-38379068">[-]</label><label class="expand" for="c-38379068">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no proof on either side. Just as likely to be ideological disputes from Helen and Ilya.</div><br/></div></div><div id="38375661" class="c"><input type="checkbox" id="c-38375661" checked=""/><div class="controls bullet"><span class="by">jychang</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375546">parent</a><span>|</span><a href="#38379068">prev</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375661">[-]</label><label class="expand" for="c-38375661">[4 more]</label></div><br/><div class="children"><div class="content">What money? None of them had equity</div><br/><div id="38376175" class="c"><input type="checkbox" id="c-38376175" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38375814">next</a><span>|</span><label class="collapse" for="c-38376175">[-]</label><label class="expand" for="c-38376175">[1 more]</label></div><br/><div class="children"><div class="content">The had some equity after 2019.<p>Thrive was about to buy employee shares at a $86 bn valuation. The Information said that those units had 12x since 2021.<p><a href="https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;thrive-capital-to-lead-purchase-of-openai-employee-shares-at-80-billion-plus-valuation?rc=e7g9iy" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;thrive-capital-to-le...</a></div><br/></div></div><div id="38375814" class="c"><input type="checkbox" id="c-38375814" checked=""/><div class="controls bullet"><span class="by">consp</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38376175">prev</a><span>|</span><a href="#38375858">next</a><span>|</span><label class="collapse" for="c-38375814">[-]</label><label class="expand" for="c-38375814">[1 more]</label></div><br/><div class="children"><div class="content">Not having money while everyone becomes filthy rich is also a money motivator.</div><br/></div></div><div id="38375858" class="c"><input type="checkbox" id="c-38375858" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38375814">prev</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375858">[-]</label><label class="expand" for="c-38375858">[1 more]</label></div><br/><div class="children"><div class="content">They’ll all be filthy rich if they can keep doing this. Altman was already side-hussling to get funding for other AI companies.<p>Same with employees and their stock comp. Same with microsoft.</div><br/></div></div></div></div></div></div></div></div><div id="38375620" class="c"><input type="checkbox" id="c-38375620" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375278">prev</a><span>|</span><a href="#38380231">next</a><span>|</span><label class="collapse" for="c-38375620">[-]</label><label class="expand" for="c-38375620">[23 more]</label></div><br/><div class="children"><div class="content">Larry Summers?  He has no technical experience, torpedoed the stimulus plan in 2008, and had to resign the Harvard presidency following a messy set of statements about ‘differences’ between the sexes and their mental abilities.<p>Kind of a shocking choice.</div><br/><div id="38375664" class="c"><input type="checkbox" id="c-38375664" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38375664">[-]</label><label class="expand" for="c-38375664">[14 more]</label></div><br/><div class="children"><div class="content">&gt; “There is relatively clear evidence that whatever the difference in means—which can be debated—there is a difference in the standard deviation and variability of a male and female population,” he said. Thus, even if the average abilities of men and women were the same, there would be more men than women at the elite levels of mathematical ability<p>Isn’t this true though? Says more about Harvard than Summers to be honest.<p><a href="https:&#x2F;&#x2F;www.swarthmore.edu&#x2F;bulletin&#x2F;archive&#x2F;wp&#x2F;january-2009_what-larry-summers-said-and-didnt-say.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.swarthmore.edu&#x2F;bulletin&#x2F;archive&#x2F;wp&#x2F;january-2009_...</a></div><br/><div id="38376071" class="c"><input type="checkbox" id="c-38376071" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38375840">next</a><span>|</span><label class="collapse" for="c-38376071">[-]</label><label class="expand" for="c-38376071">[2 more]</label></div><br/><div class="children"><div class="content">This is the scientific consensus btw.<p>There are also more intellectually challenged men btw, but somehow that rarely gets discussed.<p>But the effects are quite small, and should not dissuade anyone to do anything IMO.</div><br/><div id="38376139" class="c"><input type="checkbox" id="c-38376139" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376071">parent</a><span>|</span><a href="#38375840">next</a><span>|</span><label class="collapse" for="c-38376139">[-]</label><label class="expand" for="c-38376139">[1 more]</label></div><br/><div class="children"><div class="content">The consensus appears to be somewhat less than a consensus.<p>Here is a meta analysis on the subject: <a href="https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC3057475&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC3057475&#x2F;</a></div><br/></div></div></div></div><div id="38375840" class="c"><input type="checkbox" id="c-38375840" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38376071">prev</a><span>|</span><a href="#38375769">next</a><span>|</span><label class="collapse" for="c-38375840">[-]</label><label class="expand" for="c-38375840">[4 more]</label></div><br/><div class="children"><div class="content">Shh. Only some truths should be spoken aloud.  You clearly deserve to lose your job if you speak one of the other truths that offends people.</div><br/><div id="38375970" class="c"><input type="checkbox" id="c-38375970" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375840">parent</a><span>|</span><a href="#38375769">next</a><span>|</span><label class="collapse" for="c-38375970">[-]</label><label class="expand" for="c-38375970">[3 more]</label></div><br/><div class="children"><div class="content">One should also be careful to claim that the dominant group is inherently superior.  There are a lot of, uh, counter examples.<p>Calling this a truth is pretty silly.  There is a lot of evidence that human cognition is highly dependent on environment.</div><br/><div id="38376044" class="c"><input type="checkbox" id="c-38376044" checked=""/><div class="controls bullet"><span class="by">jadamson</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375970">parent</a><span>|</span><a href="#38381353">next</a><span>|</span><label class="collapse" for="c-38376044">[-]</label><label class="expand" for="c-38376044">[1 more]</label></div><br/><div class="children"><div class="content">He didn&#x27;t claim they were superior. He said they deviate more from the mean, in both directions.<p>For example, there are a lot more boys than girls who struggle with basic reading comprehension. Sound familiar?</div><br/></div></div><div id="38381353" class="c"><input type="checkbox" id="c-38381353" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375970">parent</a><span>|</span><a href="#38376044">prev</a><span>|</span><a href="#38375769">next</a><span>|</span><label class="collapse" for="c-38381353">[-]</label><label class="expand" for="c-38381353">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a lot of evidence that not having two X chromosomes is less stable, leading to...irregularities.  That sword cuts both ways.<p>I don&#x27;t like ignorance being promoted under the cloak of not causing offense.  It causes more harm than good.  If there&#x27;s a societal problem, you can&#x27;t tackle it without knowing the actual cause.  Sometimes the issue isn&#x27;t an actual problem caused an &#x27;ism,&#x27; it&#x27;s just biology, and it&#x27;s a complete waste of resources trying to change it.</div><br/></div></div></div></div></div></div><div id="38375769" class="c"><input type="checkbox" id="c-38375769" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38375840">prev</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38375769">[-]</label><label class="expand" for="c-38375769">[7 more]</label></div><br/><div class="children"><div class="content">A control group is kind of unimaginable right?  And even if you could be sure of this conclusion, is it helpful or beneficial to promote it in public discourse?</div><br/><div id="38375960" class="c"><input type="checkbox" id="c-38375960" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375769">parent</a><span>|</span><a href="#38376174">next</a><span>|</span><label class="collapse" for="c-38375960">[-]</label><label class="expand" for="c-38375960">[2 more]</label></div><br/><div class="children"><div class="content">&gt;And even if you could be sure of this conclusion, is it helpful or beneficial to promote it in public discourse?<p>It&#x27;s absolutely helpful for mental health, to show people that there&#x27;s not some conspiracy out to disenfranchise and oppress them, rather the distribution of outcomes is a natural result of the distribution of genetic characteristics.</div><br/><div id="38376488" class="c"><input type="checkbox" id="c-38376488" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375960">parent</a><span>|</span><a href="#38376174">next</a><span>|</span><label class="collapse" for="c-38376488">[-]</label><label class="expand" for="c-38376488">[1 more]</label></div><br/><div class="children"><div class="content">This is not an accurate description of causation and can&#x27;t be, because there are more steps after &quot;genetics&quot; in the causal chain.<p>It&#x27;s also unimaginative; having a variety of traits is itself good for society, which means you don&#x27;t need variation in genetics to cause it. It&#x27;s adaptive behavior for the same genes to simply lead to random outcomes. But people who say &quot;genes cause X&quot; probably wouldn&#x27;t like this because they want to also say &quot;and some people have the best genes&quot;.</div><br/></div></div></div></div><div id="38376174" class="c"><input type="checkbox" id="c-38376174" checked=""/><div class="controls bullet"><span class="by">TMWNN</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375769">parent</a><span>|</span><a href="#38375960">prev</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38376174">[-]</label><label class="expand" for="c-38376174">[4 more]</label></div><br/><div class="children"><div class="content">Sorry, you don&#x27;t get to decide which thoughts are wrongthink and verboten.</div><br/><div id="38376258" class="c"><input type="checkbox" id="c-38376258" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376174">parent</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38376258">[-]</label><label class="expand" for="c-38376258">[3 more]</label></div><br/><div class="children"><div class="content">I’m not suggesting that I get to decide or whatever, and I am absolutely happy there is reasoned discussion of cognition.<p>I do however expect the boards of directors of important companies to avoid publicly supporting obviously regressive ideas such as this gem.</div><br/><div id="38376704" class="c"><input type="checkbox" id="c-38376704" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376258">parent</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38376704">[-]</label><label class="expand" for="c-38376704">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re happy there is reasoned discussion, but the idea is, in your view, &quot;regressive&quot; whether it&#x27;s true or not?</div><br/><div id="38376855" class="c"><input type="checkbox" id="c-38376855" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376704">parent</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38376855">[-]</label><label class="expand" for="c-38376855">[1 more]</label></div><br/><div class="children"><div class="content">True is a bit of a stretch here right?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38375730" class="c"><input type="checkbox" id="c-38375730" checked=""/><div class="controls bullet"><span class="by">arduanika</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375664">prev</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38375730">[-]</label><label class="expand" for="c-38375730">[1 more]</label></div><br/><div class="children"><div class="content">The faculty got him out because he riled them, e.g. by insisting they ought to actually put effort into teaching undergrads. They looked for a pretext, and they found it.<p>Just like in that Oppenheimer movie. A sanctimonious witch hunt serving as pretext for a personal vendetta.<p>(Note that Summers is, I&#x27;m told, on a personal level, a dick. The popular depiction is not that wrong on that point. But he&#x27;s the right pick for this job -- see my other comments in this thread.)</div><br/></div></div><div id="38375762" class="c"><input type="checkbox" id="c-38375762" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375730">prev</a><span>|</span><a href="#38375917">next</a><span>|</span><label class="collapse" for="c-38375762">[-]</label><label class="expand" for="c-38375762">[3 more]</label></div><br/><div class="children"><div class="content">To be honest, one reason I like Summers as a choice is I have the impression he is willing to be unpopular when necessary, e.g. I remember him getting dragged extremely heavily on Twitter a few years back, for some takes on inflation which turned out to be fairly accurate.</div><br/><div id="38376421" class="c"><input type="checkbox" id="c-38376421" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375762">parent</a><span>|</span><a href="#38377000">next</a><span>|</span><label class="collapse" for="c-38376421">[-]</label><label class="expand" for="c-38376421">[1 more]</label></div><br/><div class="children"><div class="content">No, his predictions in 2021 were not accurate. He gave 33% chance of three different things happening, and then none of them happened!</div><br/></div></div><div id="38377000" class="c"><input type="checkbox" id="c-38377000" checked=""/><div class="controls bullet"><span class="by">midasuni</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375762">parent</a><span>|</span><a href="#38376421">prev</a><span>|</span><a href="#38375917">next</a><span>|</span><label class="collapse" for="c-38377000">[-]</label><label class="expand" for="c-38377000">[1 more]</label></div><br/><div class="children"><div class="content">This Summers?<p><a href="https:&#x2F;&#x2F;nymag.com&#x2F;intelligencer&#x2F;2023&#x2F;06&#x2F;larry-summers-was-wrong-about-inflation.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;nymag.com&#x2F;intelligencer&#x2F;2023&#x2F;06&#x2F;larry-summers-was-wr...</a><p><a href="https:&#x2F;&#x2F;prospect.org&#x2F;environment&#x2F;2023-11-20-larry-summers-inflation-prediction-climate-change&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;prospect.org&#x2F;environment&#x2F;2023-11-20-larry-summers-in...</a></div><br/></div></div></div></div><div id="38375917" class="c"><input type="checkbox" id="c-38375917" checked=""/><div class="controls bullet"><span class="by">the-memory-hole</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375762">prev</a><span>|</span><a href="#38375940">next</a><span>|</span><label class="collapse" for="c-38375917">[-]</label><label class="expand" for="c-38375917">[1 more]</label></div><br/><div class="children"><div class="content">a huge player in preventing derivatives regulation leading up to 2008 now helps steer the ship of AI oversight. I&#x27;m speechless.</div><br/></div></div><div id="38375940" class="c"><input type="checkbox" id="c-38375940" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375917">prev</a><span>|</span><a href="#38376392">next</a><span>|</span><label class="collapse" for="c-38375940">[-]</label><label class="expand" for="c-38375940">[1 more]</label></div><br/><div class="children"><div class="content">Could have been worse, they could have picked Larry David, would fit the clown-show of the past weekend.</div><br/></div></div><div id="38376392" class="c"><input type="checkbox" id="c-38376392" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375940">prev</a><span>|</span><a href="#38380231">next</a><span>|</span><label class="collapse" for="c-38376392">[-]</label><label class="expand" for="c-38376392">[2 more]</label></div><br/><div class="children"><div class="content">If Larry correctly said that men and women are different, i see nothing wrong here.</div><br/><div id="38376689" class="c"><input type="checkbox" id="c-38376689" checked=""/><div class="controls bullet"><span class="by">notfed</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376392">parent</a><span>|</span><a href="#38380231">next</a><span>|</span><label class="collapse" for="c-38376689">[-]</label><label class="expand" for="c-38376689">[1 more]</label></div><br/><div class="children"><div class="content">It looks like he said, specifically:<p>&gt; &quot;...[there] is relatively clear evidence that whatever the difference in means—which can be debated—there is a difference in the standard deviation and variability of a male and female population...&quot;<p>Sheesh, of all the things to be cancelled for...</div><br/></div></div></div></div></div></div><div id="38380231" class="c"><input type="checkbox" id="c-38380231" checked=""/><div class="controls bullet"><span class="by">thepasswordis</span><span>|</span><a href="#38375620">prev</a><span>|</span><a href="#38375804">next</a><span>|</span><label class="collapse" for="c-38380231">[-]</label><label class="expand" for="c-38380231">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I don’t know.  I think you’d be kind of nuts to build anything on their APIs anymore.<p>Sure I’ll keep using ChatGPT in a personal capacity&#x2F;as search.  But no way I’d trust my business to them</div><br/><div id="38381537" class="c"><input type="checkbox" id="c-38381537" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38380231">parent</a><span>|</span><a href="#38375804">next</a><span>|</span><label class="collapse" for="c-38381537">[-]</label><label class="expand" for="c-38381537">[1 more]</label></div><br/><div class="children"><div class="content">Working out nicely for Msft then. You can use GPT4 via Azure already.</div><br/></div></div></div></div><div id="38375804" class="c"><input type="checkbox" id="c-38375804" checked=""/><div class="controls bullet"><span class="by">eclectic29</span><span>|</span><a href="#38380231">prev</a><span>|</span><a href="#38375859">next</a><span>|</span><label class="collapse" for="c-38375804">[-]</label><label class="expand" for="c-38375804">[107 more]</label></div><br/><div class="children"><div class="content">The media and the VCs are treating Sam like some hero and savior of AI. I’m not getting it. What has he done in life and&#x2F;or AI to deserve so much respect and admiration? Why don’t top researchers and scientists get equivalent (if not more) respect, admiration and support? It looks like one should strive to become product manager, not an engineer or a scientist.</div><br/><div id="38378136" class="c"><input type="checkbox" id="c-38378136" checked=""/><div class="controls bullet"><span class="by">busyant</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377268">next</a><span>|</span><label class="collapse" for="c-38378136">[-]</label><label class="expand" for="c-38378136">[21 more]</label></div><br/><div class="children"><div class="content">&gt; Why don’t top researchers and scientists get equivalent (if not more) respect, admiration and support?<p>I can&#x27;t believe I&#x27;m about to defend VCs and &quot;senior management&quot; but here goes.<p>I&#x27;ve worked for two start-ups in my life.<p>The first start-up had dog-shit technology (initially) and top-notch management. CEO told me early on that VCs invest on the quality of management because they trust good senior executives to hire good researchers and let them pivot into profitable areas (and pivoting is almost always needed).<p>I thought the CEO was full of shit and simply patting himself on the back. Company pivoted HARD and IPOed around 2006 and now has a MC of ~ $10 billion.<p>The second start-up I worked with was founded by a Nobel laureate and the tech was based on his research. This time management was dog-shit. Management fumbled the tech and went out of business.<p>===<p>Not saying Altman deserves uncritical praise. All I&#x27;m saying is that I used to diminish the importance of quality senior leadership.</div><br/><div id="38378288" class="c"><input type="checkbox" id="c-38378288" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378136">parent</a><span>|</span><a href="#38378274">next</a><span>|</span><label class="collapse" for="c-38378288">[-]</label><label class="expand" for="c-38378288">[7 more]</label></div><br/><div class="children"><div class="content">Great comment. You interspersed the two, but instead of using management I like to say that it&#x27;s <i>leadership</i> that matters. Getting a bunch of people (smart or not) to all row in the same direction with the same vision is hard. It&#x27;s also commonly the difference between success and failure. Of course the ICs deserve admiration and respect, but people (ICs) are often quick to dismiss leadership.<p>A great analogy can be found on basketball teams. Lots of star players who should succeed sans any coach, but Phil Jackson and Coach K have shown time and again the important role leadership plays.</div><br/><div id="38379589" class="c"><input type="checkbox" id="c-38379589" checked=""/><div class="controls bullet"><span class="by">CrazyStat</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378288">parent</a><span>|</span><a href="#38378338">next</a><span>|</span><label class="collapse" for="c-38379589">[-]</label><label class="expand" for="c-38379589">[2 more]</label></div><br/><div class="children"><div class="content">I remember about ten years ago someone arguing that Coach K was overrated because his college players on average underperformed in the NBA (relative to their college careers).<p>I could not convince them that this was actually evidence in favor of Coach K being an exceptional coach.</div><br/><div id="38379718" class="c"><input type="checkbox" id="c-38379718" checked=""/><div class="controls bullet"><span class="by">gardenhedge</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379589">parent</a><span>|</span><a href="#38378338">next</a><span>|</span><label class="collapse" for="c-38379718">[-]</label><label class="expand" for="c-38379718">[1 more]</label></div><br/><div class="children"><div class="content">Either thought process could be correct and it could depend on expectations.</div><br/></div></div></div></div><div id="38378338" class="c"><input type="checkbox" id="c-38378338" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378288">parent</a><span>|</span><a href="#38379589">prev</a><span>|</span><a href="#38379091">next</a><span>|</span><label class="collapse" for="c-38378338">[-]</label><label class="expand" for="c-38378338">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d extend that leadership in the form of management needs leadership in the technical aspect as well. The two need to work in tandem to make things work. Imho the best technical leads are usually not the smartest ones, they are those that best utilize their resources - read, other people - and are force multipliers.<p>Of course you need the people who can deep dive and solve complex issues, none doubts that.</div><br/><div id="38378659" class="c"><input type="checkbox" id="c-38378659" checked=""/><div class="controls bullet"><span class="by">spaceribs</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378338">parent</a><span>|</span><a href="#38378383">next</a><span>|</span><label class="collapse" for="c-38378659">[-]</label><label class="expand" for="c-38378659">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d go further than even that! You need 3 forms of advocacy in leadership for a successful business, business&#x2F;market, tech, and time. The balance of those three can make or break any business.<p>You can see this at the micro level in a scrum team between the scrummaster, the product owner, and the tech lead.</div><br/></div></div><div id="38378383" class="c"><input type="checkbox" id="c-38378383" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378338">parent</a><span>|</span><a href="#38378659">prev</a><span>|</span><a href="#38379091">next</a><span>|</span><label class="collapse" for="c-38378383">[-]</label><label class="expand" for="c-38378383">[1 more]</label></div><br/><div class="children"><div class="content">Agree completely!</div><br/></div></div></div></div></div></div><div id="38378274" class="c"><input type="checkbox" id="c-38378274" checked=""/><div class="controls bullet"><span class="by">rtsil</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378136">parent</a><span>|</span><a href="#38378288">prev</a><span>|</span><a href="#38378561">next</a><span>|</span><label class="collapse" for="c-38378274">[-]</label><label class="expand" for="c-38378274">[8 more]</label></div><br/><div class="children"><div class="content">&gt; IPOed around 2006 and now has a MC of ~ $10 billion.<p>The interesting thing is you used economic values to show their importance, not what innovations or changes they achieved. Which is fine for ordinary companies, but OpenAI is supposed to be a non-profit, so these metrics should not be relevant. Otherwise, what&#x27;s the difference?</div><br/><div id="38378488" class="c"><input type="checkbox" id="c-38378488" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378274">parent</a><span>|</span><a href="#38378314">next</a><span>|</span><label class="collapse" for="c-38378488">[-]</label><label class="expand" for="c-38378488">[1 more]</label></div><br/><div class="children"><div class="content">How do you do expensive bleeding edge research with no money? Sure you might get some grants in the millions but what if it takes billions. Now lets assume the research is no small feat, its not just a handful of individuals in a lab, we need to hire larger teams to make it happen. We have to pay for those individuals and their benefits.<p>My take is its not cheap to do what they are doing and adding a capped for-profit side is an interesting take. Afterall, OpenAI&#x27;s mission clearly states that AGI is happening and if thats true, those profit caps are probably trivial to meet.</div><br/></div></div><div id="38378314" class="c"><input type="checkbox" id="c-38378314" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378274">parent</a><span>|</span><a href="#38378488">prev</a><span>|</span><a href="#38379332">next</a><span>|</span><label class="collapse" for="c-38378314">[-]</label><label class="expand" for="c-38378314">[3 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is supposed to be a non-profit, so these metrics should not be relevant<p>You&#x27;re doing the same thing except with finances. Non-profit doesn&#x27;t mean finances are irrelevant. It simply means there are no shareholders. Non-profits are still businesses - no money, no mission.</div><br/><div id="38379625" class="c"><input type="checkbox" id="c-38379625" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378314">parent</a><span>|</span><a href="#38379332">next</a><span>|</span><label class="collapse" for="c-38379625">[-]</label><label class="expand" for="c-38379625">[2 more]</label></div><br/><div class="children"><div class="content">Well said. And to extend, there being no shareholders means that no money leaves the company in the form of dividends or stock buybacks.<p>That’s it. Nonprofit corporations are still corporations in every other way.</div><br/><div id="38379743" class="c"><input type="checkbox" id="c-38379743" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379625">parent</a><span>|</span><a href="#38379332">next</a><span>|</span><label class="collapse" for="c-38379743">[-]</label><label class="expand" for="c-38379743">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but non-profit doesn&#x27;t mean non-money.<p>You can get big salaries; and to push the money outside it&#x27;s very simple, you just need to spend it through other companies.<p>Additional bonus with some structures: If the co-investors are also the donators to the non-profit, they can deduct these donations from their taxes, and still pocket-back the profit, it&#x27;s a double-win.<p>No conspiracy needed, for example, it&#x27;s very convenient that MSFT can politely &quot;influence&quot; OpenAI to spend back on their platform a lot of the money they gave to the non-profit back to their for-profit (and profitable) company.<p>For example, you can create a chip company, and use the non-profit to buy your chips.<p>Then the profit is channeled to you and your co-investors in the chip company.</div><br/></div></div></div></div></div></div><div id="38379332" class="c"><input type="checkbox" id="c-38379332" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378274">parent</a><span>|</span><a href="#38378314">prev</a><span>|</span><a href="#38378561">next</a><span>|</span><label class="collapse" for="c-38379332">[-]</label><label class="expand" for="c-38379332">[3 more]</label></div><br/><div class="children"><div class="content">&gt; he interesting thing is you used economic values to show their importance, not what innovations or changes they achieved<p>Money is just a way to value things relative to other things. It&#x27;s not interesting to value something using money.</div><br/><div id="38379844" class="c"><input type="checkbox" id="c-38379844" checked=""/><div class="controls bullet"><span class="by">DoughnutHole</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379332">parent</a><span>|</span><a href="#38378561">next</a><span>|</span><label class="collapse" for="c-38379844">[-]</label><label class="expand" for="c-38379844">[2 more]</label></div><br/><div class="children"><div class="content">It is absolutely curious to talk about <i>profit</i> when talking about academic research or a non-profit (which OpenAI officially is).<p>Sure, you can talk about results in terms of their monetary value but it doesn’t make sense to think of it in terms of the profit generated directly by the actor.<p>For example Pfizer made huge profits off of the COVID-19 vaccine. But that vaccine would never have been possible without foundational research conducted in universities in the US and Germany which established the viability in vivo of mRNA.<p>Pfizer made billions and many lives were saved using the work of academics (which also laid the groundwork for future valuable vaccines). The profit made by the academics and universities was minimal in comparison.<p>So, whose work was more valuable?</div><br/><div id="38380458" class="c"><input type="checkbox" id="c-38380458" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379844">parent</a><span>|</span><a href="#38378561">next</a><span>|</span><label class="collapse" for="c-38380458">[-]</label><label class="expand" for="c-38380458">[1 more]</label></div><br/><div class="children"><div class="content">No one mentioned profit, I think.</div><br/></div></div></div></div></div></div></div></div><div id="38378561" class="c"><input type="checkbox" id="c-38378561" checked=""/><div class="controls bullet"><span class="by">vlad_ungureanu</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378136">parent</a><span>|</span><a href="#38378274">prev</a><span>|</span><a href="#38379837">next</a><span>|</span><label class="collapse" for="c-38378561">[-]</label><label class="expand" for="c-38378561">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, I always thought that research and startups are very similar. Where you have something (product&#x2F;research-idea) which you think is novel and try to sell it (journals&#x2F;customers).<p>The management skills which you potentiated differentiated the success of the two firms. I can see how the lack of this might be wildly spread out in academia.</div><br/><div id="38379140" class="c"><input type="checkbox" id="c-38379140" checked=""/><div class="controls bullet"><span class="by">mikpanko</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378561">parent</a><span>|</span><a href="#38379837">next</a><span>|</span><label class="collapse" for="c-38379140">[-]</label><label class="expand" for="c-38379140">[1 more]</label></div><br/><div class="children"><div class="content">Most startups need to do a very different type of research than academia. They need to move very fast and test ideas against the market. In my experience, most academic research is moving pretty slowly due to different goals and incentives - and at times it can be a good thing.</div><br/></div></div></div></div><div id="38379837" class="c"><input type="checkbox" id="c-38379837" checked=""/><div class="controls bullet"><span class="by">bnralt</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378136">parent</a><span>|</span><a href="#38378561">prev</a><span>|</span><a href="#38378361">next</a><span>|</span><label class="collapse" for="c-38379837">[-]</label><label class="expand" for="c-38379837">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Not saying Altman deserves uncritical praise. All I&#x27;m saying is that I used to diminish the importance of quality senior leadership.<p>Absolutely. The focus on the leadership of OpenAI isn&#x27;t because people think that the top researchers and scientists are unimportant. It&#x27;s because they realize that they are important, and as such, the person who decides the direction they go in is extremely important. End up with the wrong person at the top, and all of those researchers and scientists end up wasting time spinning wheels on things that will never reach the public.</div><br/></div></div><div id="38379454" class="c"><input type="checkbox" id="c-38379454" checked=""/><div class="controls bullet"><span class="by">danaris</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378136">parent</a><span>|</span><a href="#38378361">prev</a><span>|</span><a href="#38377268">next</a><span>|</span><label class="collapse" for="c-38379454">[-]</label><label class="expand" for="c-38379454">[1 more]</label></div><br/><div class="children"><div class="content">&gt; All I&#x27;m saying is that I used to diminish the importance of quality senior leadership.<p>Quality senior leadership is, indeed, very important.<p>However, far, far too many people see &quot;their company makes a lot of money&quot; or &quot;they are charismatic and talk a good game&quot; and think that means the senior leadership is high-quality.<p>True quality is much harder to measure, <i>especially</i> in the short term. As you imply, part of it is being able to choose good management—but measuring the quality of management is <i>also</i> hard, and most of the corporate world today has utterly backwards ideas about what actually makes good managers (eg, &quot;willing to abuse employees to force them to work long hours&quot;, etc).</div><br/></div></div></div></div><div id="38377268" class="c"><input type="checkbox" id="c-38377268" checked=""/><div class="controls bullet"><span class="by">hdivider</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38378136">prev</a><span>|</span><a href="#38376144">next</a><span>|</span><label class="collapse" for="c-38377268">[-]</label><label class="expand" for="c-38377268">[9 more]</label></div><br/><div class="children"><div class="content">This, 100%.<p>Sam pontificated about fusion power, even here on HN. Beyond investing in Helion, what did he do? Worldcoin. Tempting impoverished people to give up biometric data in exchange for some crypto. And serving as the face of mass-market consumer AI. Clearly that&#x27;s more cool, and more attractive to VCs.<p>Meanwhile, what have fusion scientists and engineers done? They kept on going, including by developing ML systems for pure technological effect. Day after day. They got to a breakthrough just this year. Scientists and engineers in national labs, universities, and elsewhere show what a real commitment to technological progress looks like.</div><br/><div id="38379496" class="c"><input type="checkbox" id="c-38379496" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377268">parent</a><span>|</span><a href="#38379354">next</a><span>|</span><label class="collapse" for="c-38379496">[-]</label><label class="expand" for="c-38379496">[1 more]</label></div><br/><div class="children"><div class="content">He is the Executive Chairman of Helion Energy so it is not just a passive investment.<p>That said, I wish Helion wasn&#x27;t so paranoid about Chinese copycats and was more open about their tech.  I can&#x27;t help but feel Sam Altman is at least partly responsible for that.</div><br/></div></div><div id="38379354" class="c"><input type="checkbox" id="c-38379354" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377268">parent</a><span>|</span><a href="#38379496">prev</a><span>|</span><a href="#38377954">next</a><span>|</span><label class="collapse" for="c-38379354">[-]</label><label class="expand" for="c-38379354">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Scientists and engineers in national labs, universities, and elsewhere show what a real commitment to technological progress looks like.<p>And everywhere. You&#x27;ve only named public institutions for some reason, but a lot of progress happens in the private sector. And that demonstrates real commitment, because they&#x27;re not spending other people&#x27;s money.</div><br/><div id="38379420" class="c"><input type="checkbox" id="c-38379420" checked=""/><div class="controls bullet"><span class="by">walthamstow</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379354">parent</a><span>|</span><a href="#38377954">next</a><span>|</span><label class="collapse" for="c-38379420">[-]</label><label class="expand" for="c-38379420">[2 more]</label></div><br/><div class="children"><div class="content">If the ZIRP era has taught us anything, it&#x27;s that private companies can spray other people&#x27;s money up the wall just as well as anyone</div><br/><div id="38380444" class="c"><input type="checkbox" id="c-38380444" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38379420">parent</a><span>|</span><a href="#38377954">next</a><span>|</span><label class="collapse" for="c-38380444">[-]</label><label class="expand" for="c-38380444">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the (partial) owners&#x27; money. The (partial) owners might be VC firms, but they are risking their own money.</div><br/></div></div></div></div></div></div><div id="38377954" class="c"><input type="checkbox" id="c-38377954" checked=""/><div class="controls bullet"><span class="by">otteromkram</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377268">parent</a><span>|</span><a href="#38379354">prev</a><span>|</span><a href="#38376144">next</a><span>|</span><label class="collapse" for="c-38377954">[-]</label><label class="expand" for="c-38377954">[4 more]</label></div><br/><div class="children"><div class="content">&gt; This, 100%.<p>When do new HN users get the ability to downvote?</div><br/><div id="38378011" class="c"><input type="checkbox" id="c-38378011" checked=""/><div class="controls bullet"><span class="by">bryancoxwell</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377954">parent</a><span>|</span><a href="#38379586">next</a><span>|</span><label class="collapse" for="c-38378011">[-]</label><label class="expand" for="c-38378011">[1 more]</label></div><br/><div class="children"><div class="content">501 karma.</div><br/></div></div><div id="38379586" class="c"><input type="checkbox" id="c-38379586" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377954">parent</a><span>|</span><a href="#38378011">prev</a><span>|</span><a href="#38378018">next</a><span>|</span><label class="collapse" for="c-38379586">[-]</label><label class="expand" for="c-38379586">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re on pace for about two years in</div><br/></div></div><div id="38378018" class="c"><input type="checkbox" id="c-38378018" checked=""/><div class="controls bullet"><span class="by">deely3</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377954">parent</a><span>|</span><a href="#38379586">prev</a><span>|</span><a href="#38376144">next</a><span>|</span><label class="collapse" for="c-38378018">[-]</label><label class="expand" for="c-38378018">[1 more]</label></div><br/><div class="children"><div class="content">Depends on karma and other hiddens parameters.</div><br/></div></div></div></div></div></div><div id="38376144" class="c"><input type="checkbox" id="c-38376144" checked=""/><div class="controls bullet"><span class="by">fidotron</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377268">prev</a><span>|</span><a href="#38377338">next</a><span>|</span><label class="collapse" for="c-38376144">[-]</label><label class="expand" for="c-38376144">[4 more]</label></div><br/><div class="children"><div class="content">Unsurprisingly VCs view VCs as the highest form of life, and product managers are temporary positions taken on the way to ascending to VC status.<p>I have said recently elsewhere SV now devalues builders but it is not just VCs&#x2F;sales&#x2F;product, a huge amount is devops and sre departments. They make a huge amount of noise about how all development should be free and the value is in deploying and operating the developed artifacts. Anyone outside this watching would reasonably conclude developers have no self respect, hardly aspirational positions.</div><br/><div id="38378413" class="c"><input type="checkbox" id="c-38378413" checked=""/><div class="controls bullet"><span class="by">drawkbox</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376144">parent</a><span>|</span><a href="#38377338">next</a><span>|</span><label class="collapse" for="c-38378413">[-]</label><label class="expand" for="c-38378413">[3 more]</label></div><br/><div class="children"><div class="content">Developers are clearly the weak link today, have given up all power over product and it is sad and why software sucks so bad. It pains the soul that value creators have let the value extractors run the show, because it is now a reality TV &#x2F; circus like market where power is consolidating.<p>Developers and value creators with power are like an anti-trust on consolidation and concentration and they have instead turned towards authoritarianism instead of anti-authoritarianism. What happened? Many think they can still get rich, those days are over because of giving up power. Now quality of life for everyone and value creators is worse off. Everyone loses.</div><br/><div id="38387436" class="c"><input type="checkbox" id="c-38387436" checked=""/><div class="controls bullet"><span class="by">bluecheese452</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378413">parent</a><span>|</span><a href="#38385255">next</a><span>|</span><label class="collapse" for="c-38387436">[-]</label><label class="expand" for="c-38387436">[1 more]</label></div><br/><div class="children"><div class="content">Developers spend all day building. Pms spend all day playing politics. It is no surprise pms get all the power.</div><br/></div></div><div id="38385255" class="c"><input type="checkbox" id="c-38385255" checked=""/><div class="controls bullet"><span class="by">dinvlad</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378413">parent</a><span>|</span><a href="#38387436">prev</a><span>|</span><a href="#38377338">next</a><span>|</span><label class="collapse" for="c-38385255">[-]</label><label class="expand" for="c-38385255">[1 more]</label></div><br/><div class="children"><div class="content">I suspect it&#x27;s because they&#x27;re happy with SV salaries they got. They think it&#x27;s actually a good deal for them, and a signal they&#x27;re &quot;valued&quot;</div><br/></div></div></div></div></div></div><div id="38377338" class="c"><input type="checkbox" id="c-38377338" checked=""/><div class="controls bullet"><span class="by">tim333</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376144">prev</a><span>|</span><a href="#38379410">next</a><span>|</span><label class="collapse" for="c-38377338">[-]</label><label class="expand" for="c-38377338">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the media are treating him as a &quot;hero and savior of AI&quot;. However OpenAI and ChatGTP have undoubtedly been successful and he seems popular with his people. It&#x27;s human nature to follow the top person as figurehead for an organisation as we or journalists don&#x27;t have time or info to break down what each of the hundreds of employees contributed.<p>I actually get the impression from the media that he&#x27;s a bit shifty and sales orientated but seems effective at getting stuff done.</div><br/><div id="38377455" class="c"><input type="checkbox" id="c-38377455" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377338">parent</a><span>|</span><a href="#38378014">next</a><span>|</span><label class="collapse" for="c-38377455">[-]</label><label class="expand" for="c-38377455">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>but seems effective at getting stuff done.</i><p>Sales usually is. It&#x27;s the consequences, post-sale, that they&#x27;re usually less effective at dealing with.</div><br/></div></div></div></div><div id="38379410" class="c"><input type="checkbox" id="c-38379410" checked=""/><div class="controls bullet"><span class="by">mikpanko</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377338">prev</a><span>|</span><a href="#38376649">next</a><span>|</span><label class="collapse" for="c-38379410">[-]</label><label class="expand" for="c-38379410">[1 more]</label></div><br/><div class="children"><div class="content">One of the most important things I&#x27;ve learned in life is that organizing people to work toward the same goal is very hard. The larger the group you need to organize, the harder it is.<p>Initially, when the idea is small, it is hard to sell it to talent, investors and early customers to bring all key pieces together.<p>Later, when the idea is well recognized and accepted, the organization usually becomes big and the challenge shifts to understanding the complex interaction of various competing sub-ideas, projects and organizational structures. Humans did not evolve to manage such complex systems and interacting with thousands of stakeholders, beyond what can be directly observed and fully understood.<p>However, without this organization, engineers, researchers, etc cannot work on big audacious projects, which involve more resources than 1 person can provide by themselves. That&#x27;s why the skill of organizing and leading people is so highly valued and compensated.<p>It is common to think of leaders not contributing much, but this view might be skewed because of mostly looking at executives in large companies at the time they have clear moats. At that point leadership might be less important in the short term: product sells itself, talent is knocking on the door, and money is abundant. But this is an unusual short-lived state between taking an idea off the ground and defending against quickly shifting market forces.</div><br/></div></div><div id="38376649" class="c"><input type="checkbox" id="c-38376649" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38379410">prev</a><span>|</span><a href="#38377969">next</a><span>|</span><label class="collapse" for="c-38376649">[-]</label><label class="expand" for="c-38376649">[10 more]</label></div><br/><div class="children"><div class="content">He says nice things about his team (and even about his critics) when in public.<p>But my reading of this drama is that the board were seen as literally insane, not that Altman was seen as spectacularly heroic or an underdog.</div><br/><div id="38376842" class="c"><input type="checkbox" id="c-38376842" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376649">parent</a><span>|</span><a href="#38379840">next</a><span>|</span><label class="collapse" for="c-38376842">[-]</label><label class="expand" for="c-38376842">[8 more]</label></div><br/><div class="children"><div class="content">My reading of all this is that the board is both incompetent <i>and</i> has a number of massive conflicts of interests.<p>What I don’t understand is why they were allowed to stay on the board with all these conflicts of interests all the while having no (financial) stake in OpenAI. One of the board members even openly admitting that she considered destroying OpenAI a successful outcome of her duty as board member.</div><br/><div id="38377218" class="c"><input type="checkbox" id="c-38377218" checked=""/><div class="controls bullet"><span class="by">Sebb767</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376842">parent</a><span>|</span><a href="#38377246">next</a><span>|</span><label class="collapse" for="c-38377218">[-]</label><label class="expand" for="c-38377218">[5 more]</label></div><br/><div class="children"><div class="content">&gt; One of the board members even openly admitting that she considered destroying OpenAI a successful outcome of her duty as board member.<p>I don&#x27;t see how this particular statement underscores your point. OpenAI is a non-profit with the declared goal of making AI safe and useful for everyone; if it fails to reach that or even actively subverts that goal, destroying the company does seem like the ethical action.</div><br/><div id="38377901" class="c"><input type="checkbox" id="c-38377901" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377218">parent</a><span>|</span><a href="#38384093">next</a><span>|</span><label class="collapse" for="c-38377901">[-]</label><label class="expand" for="c-38377901">[3 more]</label></div><br/><div class="children"><div class="content">This just underscores the absurdity of their corporate structure.  AI research requires expensive researchers and expensive GPUs.  Investors funding the research program don&#x27;t want to be beholden to some non-profit parent organization run by a small board of nobodies who think their position gives them the power to destroy the whole thing if they believe it&#x27;s straying from its utopian mission.</div><br/><div id="38378039" class="c"><input type="checkbox" id="c-38378039" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377901">parent</a><span>|</span><a href="#38378334">next</a><span>|</span><label class="collapse" for="c-38378039">[-]</label><label class="expand" for="c-38378039">[1 more]</label></div><br/><div class="children"><div class="content">They don’t “think” that. It <i>does</i> do that, and it does it <i>by design</i> exactly because as you approach a technology as powerful as AI there will be strong commercial incentives to capture its value creation.<p>Gee wiz, almost… exactly like what is happening?</div><br/></div></div></div></div><div id="38384093" class="c"><input type="checkbox" id="c-38384093" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377218">parent</a><span>|</span><a href="#38377901">prev</a><span>|</span><a href="#38377246">next</a><span>|</span><label class="collapse" for="c-38384093">[-]</label><label class="expand" for="c-38384093">[1 more]</label></div><br/><div class="children"><div class="content">Because distroying openai wouldn&#x27;t make ai safe it would just remove anyone working on alignment from having an influence on it. Microsoft and others are interested in making it benevolent but go along with it because openai is the market leader.</div><br/></div></div></div></div><div id="38377246" class="c"><input type="checkbox" id="c-38377246" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376842">parent</a><span>|</span><a href="#38377218">prev</a><span>|</span><a href="#38379840">next</a><span>|</span><label class="collapse" for="c-38377246">[-]</label><label class="expand" for="c-38377246">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably not easy (practically impossible if you ask me) to find people who are both capable of leading an AI company at the scale of OpenAI <i>and</i> have zero conflicts of interest. Former colleagues, friends, investments, advisory roles, personal beefs with people in the industry, pitches they have heard, insider knowledge they had access to, previous academic research pushing an agenda, etc.<p>If both is not possible, I&#x27;d also rather compromise on the &quot;conficts of interest&quot; part than on the member&#x27;s competency.</div><br/><div id="38377911" class="c"><input type="checkbox" id="c-38377911" checked=""/><div class="controls bullet"><span class="by">cableshaft</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377246">parent</a><span>|</span><a href="#38379840">next</a><span>|</span><label class="collapse" for="c-38377911">[-]</label><label class="expand" for="c-38377911">[1 more]</label></div><br/><div class="children"><div class="content">I volunteer as tribute.<p>I don&#x27;t have much in the way of credentials (I took one class on A.I. in college and have only dabbled in it since, and I work on systems that don&#x27;t need to scale anywhere near as much as ChatGPT does, and while I&#x27;ve been an early startup employee a couple of times I&#x27;ve never run a company), but based on the past week I think I&#x27;d do a better job, and can fill in the gaps as best as I can after the fact.<p>And I don&#x27;t have any conflicts of interest. I&#x27;m a total outsider, I don&#x27;t have any of that shit you mentioned.<p>So yeah, vote for me, or whatever.<p>Anyway my point is I&#x27;m sure there&#x27;s actually quite a few people who could do a likely a better job and don&#x27;t have a conflict of interest (at least not one so obvious as investing in a direct competitor), they&#x27;re just not already part of the Elite circles that would pretty much be necessary to even get on these people&#x27;s radar in order to be considered in the first place. I don&#x27;t really mean me, I&#x27;m sure there are other better candidates.<p>But then they wouldn&#x27;t have the cachet of &#x27;Oh, that guy co-founded Twitch. That for-profit company is successful, that must mean he&#x27;d do a good job! (at running a non-profit company that&#x27;s actively trying to bring about AGI that will probably simultaneously benefit and hurt the lives of millions of people)&#x27;.</div><br/></div></div></div></div></div></div><div id="38379840" class="c"><input type="checkbox" id="c-38379840" checked=""/><div class="controls bullet"><span class="by">bnralt</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376649">parent</a><span>|</span><a href="#38376842">prev</a><span>|</span><a href="#38377969">next</a><span>|</span><label class="collapse" for="c-38379840">[-]</label><label class="expand" for="c-38379840">[1 more]</label></div><br/><div class="children"><div class="content">Right. At least some of the board members took issue with ChatGPT being released at all, and wanted more to be kept from the public. For the people who use these tools everyday, it shouldn&#x27;t be surprising that Altman was viewed as the better choice.</div><br/></div></div></div></div><div id="38377969" class="c"><input type="checkbox" id="c-38377969" checked=""/><div class="controls bullet"><span class="by">sensanaty</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376649">prev</a><span>|</span><a href="#38377843">next</a><span>|</span><label class="collapse" for="c-38377969">[-]</label><label class="expand" for="c-38377969">[14 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be surprised in the slightest if Sam and his other ultra-rich buddies like Satya had their fingers deep in the pockets of all the tech journalists that immediately ran to his defense and sensationalized everything. Every single news source posted on HN read like pure shilling for the Ponzi sch- uh, I mean Worldcoin guy and hailing him as some sort of AI savant.</div><br/><div id="38378833" class="c"><input type="checkbox" id="c-38378833" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377969">parent</a><span>|</span><a href="#38378164">next</a><span>|</span><label class="collapse" for="c-38378833">[-]</label><label class="expand" for="c-38378833">[1 more]</label></div><br/><div class="children"><div class="content">Let me offer up a secret from the inside. You dont in any way shape or form have to pay money to journalists. The can are bought and paid for through their currency - information and access.<p>They dont really even really shill for their patron; they thrive on the relevance of having their name in the byline for the article, or being the person who gets quote &#x2F; information &#x2F; propaganda from &lt;CEO|Celebrity|Criminal|Viral Edgelord of the Week&gt;.</div><br/></div></div><div id="38378164" class="c"><input type="checkbox" id="c-38378164" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377969">parent</a><span>|</span><a href="#38378833">prev</a><span>|</span><a href="#38378047">next</a><span>|</span><label class="collapse" for="c-38378164">[-]</label><label class="expand" for="c-38378164">[2 more]</label></div><br/><div class="children"><div class="content">My more plausible version is that CEOs of journalistic publications are in cahoots with the rich&#x2F;powerful&#x2F;govt people, who get to dictate the tone of said publications by hiring the right journalists&#x2F;editors and giving them the right incentives.<p>So as a journalist you might have freedom to write your articles, but your editor (as instructed by his&#x2F;her senior editor) might try to steer you about writing in the correct tone.<p>This is how &#x27;Starship test flight makes history as it clears multiple milestones&#x27; becomes &#x27;Musk rocket explodes during test&#x27;</div><br/><div id="38379600" class="c"><input type="checkbox" id="c-38379600" checked=""/><div class="controls bullet"><span class="by">kridsdale1</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378164">parent</a><span>|</span><a href="#38378047">next</a><span>|</span><label class="collapse" for="c-38379600">[-]</label><label class="expand" for="c-38379600">[1 more]</label></div><br/><div class="children"><div class="content">But it did explode. And that was the part of the story that people were interested in.</div><br/></div></div></div></div><div id="38378047" class="c"><input type="checkbox" id="c-38378047" checked=""/><div class="controls bullet"><span class="by">egKYzyXeIL</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377969">parent</a><span>|</span><a href="#38378164">prev</a><span>|</span><a href="#38378875">next</a><span>|</span><label class="collapse" for="c-38378047">[-]</label><label class="expand" for="c-38378047">[9 more]</label></div><br/><div class="children"><div class="content">This reads like a far-fetched conspiracy theory</div><br/><div id="38378145" class="c"><input type="checkbox" id="c-38378145" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378047">parent</a><span>|</span><a href="#38378886">next</a><span>|</span><label class="collapse" for="c-38378145">[-]</label><label class="expand" for="c-38378145">[1 more]</label></div><br/><div class="children"><div class="content">Well, it&#x27;s been exposed multiple  times that money, egos and the media that needs to report about them create a school   lunch table where they simply stroke each other&#x27;s ego and inflate everything they do.<p>No need for a conspiracy, everyones seen this in some aspect, it just gets worse when these people are throwing money around in the billions.<p>all you need to do is witness someone Like Elon musk to see how disruptive this type of thing is.</div><br/></div></div><div id="38378886" class="c"><input type="checkbox" id="c-38378886" checked=""/><div class="controls bullet"><span class="by">iteratethis</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378047">parent</a><span>|</span><a href="#38378145">prev</a><span>|</span><a href="#38378165">next</a><span>|</span><label class="collapse" for="c-38378886">[-]</label><label class="expand" for="c-38378886">[2 more]</label></div><br/><div class="children"><div class="content">Really? It&#x27;s well documented and even admitted that Apple has a set of Apple-friendly media partners.</div><br/><div id="38379415" class="c"><input type="checkbox" id="c-38379415" checked=""/><div class="controls bullet"><span class="by">YourCupOTea</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378886">parent</a><span>|</span><a href="#38378165">next</a><span>|</span><label class="collapse" for="c-38379415">[-]</label><label class="expand" for="c-38379415">[1 more]</label></div><br/><div class="children"><div class="content">Even the Federal Reserve has the “Fed Whisperer” Nick Timiraos. Pretty much an open secret he has a direct line.</div><br/></div></div></div></div><div id="38378165" class="c"><input type="checkbox" id="c-38378165" checked=""/><div class="controls bullet"><span class="by">objektif</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378047">parent</a><span>|</span><a href="#38378886">prev</a><span>|</span><a href="#38378167">next</a><span>|</span><label class="collapse" for="c-38378165">[-]</label><label class="expand" for="c-38378165">[4 more]</label></div><br/><div class="children"><div class="content">You are delusional if you think YC folks does not have a wide network of tech journalists who would side with them when they need.</div><br/><div id="38378241" class="c"><input type="checkbox" id="c-38378241" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378165">parent</a><span>|</span><a href="#38378698">next</a><span>|</span><label class="collapse" for="c-38378241">[-]</label><label class="expand" for="c-38378241">[2 more]</label></div><br/><div class="children"><div class="content">They give the journos access as long as they don&#x27;t bite the hand that feeds. Anyone calling this a conspiracy theory simply hasn&#x27;t been in the valley long enough to see how these things work.</div><br/><div id="38378366" class="c"><input type="checkbox" id="c-38378366" checked=""/><div class="controls bullet"><span class="by">verve_rat</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378241">parent</a><span>|</span><a href="#38378698">next</a><span>|</span><label class="collapse" for="c-38378366">[-]</label><label class="expand" for="c-38378366">[1 more]</label></div><br/><div class="children"><div class="content">Or frankly any industry that is covered by an industry press. Games, movies, cars, it&#x27;s all the same.</div><br/></div></div></div></div><div id="38378698" class="c"><input type="checkbox" id="c-38378698" checked=""/><div class="controls bullet"><span class="by">paulcole</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378165">parent</a><span>|</span><a href="#38378241">prev</a><span>|</span><a href="#38378167">next</a><span>|</span><label class="collapse" for="c-38378698">[-]</label><label class="expand" for="c-38378698">[1 more]</label></div><br/><div class="children"><div class="content">YC has an <i>entire website</i> (this one) it can use when it needs to lol.</div><br/></div></div></div></div><div id="38378167" class="c"><input type="checkbox" id="c-38378167" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378047">parent</a><span>|</span><a href="#38378165">prev</a><span>|</span><a href="#38378875">next</a><span>|</span><label class="collapse" for="c-38378167">[-]</label><label class="expand" for="c-38378167">[1 more]</label></div><br/><div class="children"><div class="content">You do know PR firms exist, right? Or have you been living under a rock since the dawn of the 20th century?</div><br/></div></div></div></div><div id="38378875" class="c"><input type="checkbox" id="c-38378875" checked=""/><div class="controls bullet"><span class="by">Perz1val</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377969">parent</a><span>|</span><a href="#38378047">prev</a><span>|</span><a href="#38377843">next</a><span>|</span><label class="collapse" for="c-38378875">[-]</label><label class="expand" for="c-38378875">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they feel really insecure when the &quot;News Writing Themselves AI&quot; company got unstable...</div><br/></div></div></div></div><div id="38377843" class="c"><input type="checkbox" id="c-38377843" checked=""/><div class="controls bullet"><span class="by">s1artibartfast</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377969">prev</a><span>|</span><a href="#38378785">next</a><span>|</span><label class="collapse" for="c-38377843">[-]</label><label class="expand" for="c-38377843">[12 more]</label></div><br/><div class="children"><div class="content">Altman seems to be a extraordinary leader, motivator, and strategizer. This itself is clear by the fact that 90% of the company was willing to walk out over his retention. Just think about that for minute.</div><br/><div id="38378013" class="c"><input type="checkbox" id="c-38378013" checked=""/><div class="controls bullet"><span class="by">csunbird</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377843">parent</a><span>|</span><a href="#38378910">next</a><span>|</span><label class="collapse" for="c-38378013">[-]</label><label class="expand" for="c-38378013">[5 more]</label></div><br/><div class="children"><div class="content">No, the 90% of the employees were scared that their million $ salaries are going away along with Sam Altman.</div><br/><div id="38383370" class="c"><input type="checkbox" id="c-38383370" checked=""/><div class="controls bullet"><span class="by">s1artibartfast</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378013">parent</a><span>|</span><a href="#38378479">next</a><span>|</span><label class="collapse" for="c-38383370">[-]</label><label class="expand" for="c-38383370">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like a good way to to secure your position as leader.<p>My job also secures my loyalty and support with a financial incentive. It is probably the most common way for a business leader to align interests.<p>Kings reward dukes, and generals pay soldiers. Politicians trade policies. That doesn&#x27;t mean they arent leaders.</div><br/></div></div><div id="38378479" class="c"><input type="checkbox" id="c-38378479" checked=""/><div class="controls bullet"><span class="by">JansjoFromIkea</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378013">parent</a><span>|</span><a href="#38383370">prev</a><span>|</span><a href="#38378265">next</a><span>|</span><label class="collapse" for="c-38378479">[-]</label><label class="expand" for="c-38378479">[2 more]</label></div><br/><div class="children"><div class="content">stock options were probably the focus rather than the salaries</div><br/><div id="38378748" class="c"><input type="checkbox" id="c-38378748" checked=""/><div class="controls bullet"><span class="by">mousetree</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378479">parent</a><span>|</span><a href="#38378265">next</a><span>|</span><label class="collapse" for="c-38378748">[-]</label><label class="expand" for="c-38378748">[1 more]</label></div><br/><div class="children"><div class="content">There was about to be a secondary stock purchase by Thrive where employees could cash out their shares. That likely would&#x27;ve fallen apart if the board won the day. Employees had a massive incentive to get same back.</div><br/></div></div></div></div><div id="38378265" class="c"><input type="checkbox" id="c-38378265" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378013">parent</a><span>|</span><a href="#38378479">prev</a><span>|</span><a href="#38378910">next</a><span>|</span><label class="collapse" for="c-38378265">[-]</label><label class="expand" for="c-38378265">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it should be extremely obvious the reason most of the employees were willing to walk is they&#x27;ve hitched their wagons to Altman. The board of openai put the presumed party day all of them were anticipating in jeopardy. Not all of us live in this god forsaken place to &quot;work with cool tech&quot;.</div><br/></div></div></div></div><div id="38378910" class="c"><input type="checkbox" id="c-38378910" checked=""/><div class="controls bullet"><span class="by">iteratethis</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377843">parent</a><span>|</span><a href="#38378013">prev</a><span>|</span><a href="#38378034">next</a><span>|</span><label class="collapse" for="c-38378910">[-]</label><label class="expand" for="c-38378910">[2 more]</label></div><br/><div class="children"><div class="content">Please stop. No employee is loyal to any CEO based on some higher order matter.
They just want to get their big pay day and will follow whoever makes that possible.</div><br/><div id="38383172" class="c"><input type="checkbox" id="c-38383172" checked=""/><div class="controls bullet"><span class="by">s1artibartfast</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378910">parent</a><span>|</span><a href="#38378034">next</a><span>|</span><label class="collapse" for="c-38383172">[-]</label><label class="expand" for="c-38383172">[1 more]</label></div><br/><div class="children"><div class="content">That is part of effective leadership, strategy, and management.<p>I didn&#x27;t say anything about higher order values. Getting people to want what you want, and do what you want is a skill.<p>Hitler was an extraordinary leader. That doesn&#x27;t imply anything about higher values.</div><br/></div></div></div></div><div id="38378034" class="c"><input type="checkbox" id="c-38378034" checked=""/><div class="controls bullet"><span class="by">asimpletune</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377843">parent</a><span>|</span><a href="#38378910">prev</a><span>|</span><a href="#38378076">next</a><span>|</span><label class="collapse" for="c-38378034">[-]</label><label class="expand" for="c-38378034">[3 more]</label></div><br/><div class="children"><div class="content">There’s also the alternative explanation that they feel their financial situation is improved by him being there.</div><br/><div id="38378155" class="c"><input type="checkbox" id="c-38378155" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378034">parent</a><span>|</span><a href="#38378182">next</a><span>|</span><label class="collapse" for="c-38378155">[-]</label><label class="expand" for="c-38378155">[1 more]</label></div><br/><div class="children"><div class="content">almost every decision here, except for the board, can be accounted for by financial decisions.<p>Especially with putting Larry Summers on the board with this tweet.</div><br/></div></div><div id="38378182" class="c"><input type="checkbox" id="c-38378182" checked=""/><div class="controls bullet"><span class="by">gizmo</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378034">parent</a><span>|</span><a href="#38378155">prev</a><span>|</span><a href="#38378076">next</a><span>|</span><label class="collapse" for="c-38378182">[-]</label><label class="expand" for="c-38378182">[1 more]</label></div><br/><div class="children"><div class="content">Yes yes, but that doesn&#x27;t change the fact that Sam positioned himself to be unfireable. The board took their best shot and now the board is (mostly) gone and Sam is still the chief executive. They board will find itself sidelined from now on.</div><br/></div></div></div></div><div id="38378076" class="c"><input type="checkbox" id="c-38378076" checked=""/><div class="controls bullet"><span class="by">tr888</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377843">parent</a><span>|</span><a href="#38378034">prev</a><span>|</span><a href="#38378785">next</a><span>|</span><label class="collapse" for="c-38378076">[-]</label><label class="expand" for="c-38378076">[1 more]</label></div><br/><div class="children"><div class="content">I thought about it for a minute. I came to the conclusion that OpenAI would have likely tanked (perhaps even within days) had Altman not returned to maintain the status quo, and engineers didn&#x27;t want to be out of work and left with worthless stock.</div><br/></div></div></div></div><div id="38378785" class="c"><input type="checkbox" id="c-38378785" checked=""/><div class="controls bullet"><span class="by">throwaway318</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377843">prev</a><span>|</span><a href="#38377201">next</a><span>|</span><label class="collapse" for="c-38378785">[-]</label><label class="expand" for="c-38378785">[1 more]</label></div><br/><div class="children"><div class="content">Either:<p>Incubation of senior management in US tech has reached singularity and only one person&#x27;s up for the job.  Doom awaits the US tech sector as there&#x27;s no organisational ability other than one person able and willing to take the big complex job.<p>Or:<p>Sam&#x27;s overvalued.<p>One or the other.</div><br/></div></div><div id="38377201" class="c"><input type="checkbox" id="c-38377201" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38378785">prev</a><span>|</span><a href="#38379609">next</a><span>|</span><label class="collapse" for="c-38377201">[-]</label><label class="expand" for="c-38377201">[10 more]</label></div><br/><div class="children"><div class="content">&gt; It looks like one should strive to become product manager, not an engineer or a scientist.<p>In my experience, product people who know what they are doing have a huge impact on the success of a company, product, or service. They also point engineering efforts in the right direction, which in turn also motivate engineers.<p>I saw good product people leaving completely destroy a team, never seen that happen with a good engineer or individual contributor, no matter how great they were.</div><br/><div id="38377885" class="c"><input type="checkbox" id="c-38377885" checked=""/><div class="controls bullet"><span class="by">Draiken</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377201">parent</a><span>|</span><a href="#38377590">next</a><span>|</span><label class="collapse" for="c-38377885">[-]</label><label class="expand" for="c-38377885">[4 more]</label></div><br/><div class="children"><div class="content">Interesting. I had the opposite experience. All of the product suite having no idea about what the product even is, where it should go, making bad decisions over and over, excusing their bad choices behind &quot;data&quot; and finally, as usual, failing upwards eventually moving to bigger startups.<p>I have yet to find a product person that was not involved in the inception of the idea that is actually good (hell, even some founders fail spectacularly here).<p>Perhaps I&#x27;m simply unlucky.</div><br/><div id="38377977" class="c"><input type="checkbox" id="c-38377977" checked=""/><div class="controls bullet"><span class="by">cableshaft</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377885">parent</a><span>|</span><a href="#38378433">next</a><span>|</span><label class="collapse" for="c-38377977">[-]</label><label class="expand" for="c-38377977">[2 more]</label></div><br/><div class="children"><div class="content">At a consulting firm I worked with a product guy who I thought was very good, and was on the project pretty much from the beginning (maybe the beginning, not sure. He predated me by well over a year at least). He was extremely knowledgeable on the business side and their needs and spent a lot of time communicating with them to get a good feel of where the product needed to go.<p>But he was also technical enough to have a pretty good feel for the complexity of tasks, and would sometimes jump in to help figure out some docker configuration issues or whatever problems we were having (mostly devops related) so the devs could focus on working on the application code. We were also a pretty small team, only a few developers, so that was beneficial.<p>He did such a good job that the business eventually reached out to him and hired him directly. He&#x27;s now head of two of their product lines (one of them being the product I worked on).<p>But that&#x27;s pretty much it. I can&#x27;t think of any other product people I could say such positive things about.</div><br/><div id="38378213" class="c"><input type="checkbox" id="c-38378213" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377977">parent</a><span>|</span><a href="#38378433">next</a><span>|</span><label class="collapse" for="c-38378213">[-]</label><label class="expand" for="c-38378213">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s rare, and that makes it a spectacular leg up when you have a person who is great at it.</div><br/></div></div></div></div><div id="38378433" class="c"><input type="checkbox" id="c-38378433" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377885">parent</a><span>|</span><a href="#38377977">prev</a><span>|</span><a href="#38377590">next</a><span>|</span><label class="collapse" for="c-38378433">[-]</label><label class="expand" for="c-38378433">[1 more]</label></div><br/><div class="children"><div class="content">In my comment, the emphasis is definitely on the &quot;product people <i>who know what they are doing</i>&quot; and &quot;<i>good</i> product people&quot;.<p>Of course, if the product suite is clueless, nobody is going to miss them, usually it&#x27;s better the have no dedicated product people, than having clueless product people.</div><br/></div></div></div></div><div id="38377590" class="c"><input type="checkbox" id="c-38377590" checked=""/><div class="controls bullet"><span class="by">jpgvm</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377201">parent</a><span>|</span><a href="#38377885">prev</a><span>|</span><a href="#38379553">next</a><span>|</span><label class="collapse" for="c-38377590">[-]</label><label class="expand" for="c-38377590">[4 more]</label></div><br/><div class="children"><div class="content">Depends why&#x2F;how they left.<p>I have seen firing a great&#x2F;respected&#x2F;natural leader engineer result in pretty much the whole engineering team just up and leaving.</div><br/><div id="38378401" class="c"><input type="checkbox" id="c-38378401" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377590">parent</a><span>|</span><a href="#38377999">next</a><span>|</span><label class="collapse" for="c-38378401">[-]</label><label class="expand" for="c-38378401">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that matches my experience as well, that&#x27;s why I mentioned &quot;individual contributors&quot;, maybe it wasn&#x27;t clear.<p>It&#x27;s different with engineering managers (or team leads, lead engineers, however you want to call it). When they leave, that&#x27;s usually a bad sign.<p>Though also quite often when the engineering leaders leave, I think of it as a canary in the coal mine: they are closer to business, they deal more with business people, so they are the first to realize that &quot;working with these people on these services is pointless, time to jump ship&quot;.</div><br/></div></div><div id="38377999" class="c"><input type="checkbox" id="c-38377999" checked=""/><div class="controls bullet"><span class="by">cableshaft</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377590">parent</a><span>|</span><a href="#38378401">prev</a><span>|</span><a href="#38379553">next</a><span>|</span><label class="collapse" for="c-38377999">[-]</label><label class="expand" for="c-38377999">[2 more]</label></div><br/><div class="children"><div class="content">No see, it doesn&#x27;t matter, engineers are all cogs and easily replaceable. I&#x27;m sure they just dialed the engineer center and ordered a few replacements and they started 24 hours later and were doing just as good of a job the next day. &#x2F;s</div><br/></div></div></div></div><div id="38379553" class="c"><input type="checkbox" id="c-38379553" checked=""/><div class="controls bullet"><span class="by">Kinrany</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38377201">parent</a><span>|</span><a href="#38377590">prev</a><span>|</span><a href="#38379609">next</a><span>|</span><label class="collapse" for="c-38379553">[-]</label><label class="expand" for="c-38379553">[1 more]</label></div><br/><div class="children"><div class="content">Good engineers create systems that can survive their departure.</div><br/></div></div></div></div><div id="38379609" class="c"><input type="checkbox" id="c-38379609" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377201">prev</a><span>|</span><a href="#38376370">next</a><span>|</span><label class="collapse" for="c-38379609">[-]</label><label class="expand" for="c-38379609">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The media and the VCs are treating Sam like some hero and savior of AI<p>I wouldn&#x27;t be so sure. While I think the board handled this process terribly, I think the majority of mainstream media articles I saw were very cautionary regarding the outcome. Examples (and note the second article reports that Paul Graham fired Altman from YC, which I never knew before):<p>MarketWatch: <a href="https:&#x2F;&#x2F;www.marketwatch.com&#x2F;story&#x2F;the-openai-debacle-shows-silicon-valley-will-never-police-itself-1bf27b58" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.marketwatch.com&#x2F;story&#x2F;the-openai-debacle-shows-s...</a><p>Washington Post: <a href="https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2023&#x2F;11&#x2F;22&#x2F;sam-altman-fired-y-combinator-paul-graham&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2023&#x2F;11&#x2F;22&#x2F;sam-alt...</a></div><br/></div></div><div id="38376370" class="c"><input type="checkbox" id="c-38376370" checked=""/><div class="controls bullet"><span class="by">nbanks</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38379609">prev</a><span>|</span><a href="#38378541">next</a><span>|</span><label class="collapse" for="c-38376370">[-]</label><label class="expand" for="c-38376370">[5 more]</label></div><br/><div class="children"><div class="content">Sam Altman has done in four days what it took Steve Jobs 11 years to do!  I&#x27;m impressed.</div><br/><div id="38376376" class="c"><input type="checkbox" id="c-38376376" checked=""/><div class="controls bullet"><span class="by">eclectic29</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376370">parent</a><span>|</span><a href="#38378541">next</a><span>|</span><label class="collapse" for="c-38376376">[-]</label><label class="expand" for="c-38376376">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry, impressed by what?</div><br/><div id="38376528" class="c"><input type="checkbox" id="c-38376528" checked=""/><div class="controls bullet"><span class="by">nix-zarathustra</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376376">parent</a><span>|</span><a href="#38378541">next</a><span>|</span><label class="collapse" for="c-38376528">[-]</label><label class="expand" for="c-38376528">[3 more]</label></div><br/><div class="children"><div class="content">Steve Jobs got fired from Apple, but was rehired 11 years later.</div><br/><div id="38376953" class="c"><input type="checkbox" id="c-38376953" checked=""/><div class="controls bullet"><span class="by">abkolan</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376528">parent</a><span>|</span><a href="#38378541">next</a><span>|</span><label class="collapse" for="c-38376953">[-]</label><label class="expand" for="c-38376953">[2 more]</label></div><br/><div class="children"><div class="content">That might be selection bias, in those 11 years Jobs built NeXT.<p>A lot of Apple&#x27;s engineering and product line back then owe their provenance and lineage to NeXT.</div><br/><div id="38377492" class="c"><input type="checkbox" id="c-38377492" checked=""/><div class="controls bullet"><span class="by">Talanes</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376953">parent</a><span>|</span><a href="#38378541">next</a><span>|</span><label class="collapse" for="c-38377492">[-]</label><label class="expand" for="c-38377492">[1 more]</label></div><br/><div class="children"><div class="content">Selection bias for what? It was an anecdote, there&#x27;s no attempt to infer data about a larger population.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38378541" class="c"><input type="checkbox" id="c-38378541" checked=""/><div class="controls bullet"><span class="by">627467</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376370">prev</a><span>|</span><a href="#38379689">next</a><span>|</span><label class="collapse" for="c-38378541">[-]</label><label class="expand" for="c-38378541">[1 more]</label></div><br/><div class="children"><div class="content">A CEO is not a researcher. A researcher can be a CEO but in doing so stops being a researcher.<p>Maybe (almost certainly) Sam is not a savior&#x2F;hero, but he doesn&#x27;t need to be a savior&#x2F;hero. He just needs to gather more support than the opposition (the now previous board). And even if you don&#x27;t know any details of this story, enough insiders who know more than any of us of what happens inside oai - including hundred of researchers - decided to support the &quot;savior&#x2F;hero&quot;. It&#x27;s less about Sam and more about an incompetent board. Some of those board members are top researchers. And they are now on the losing camp.</div><br/></div></div><div id="38379689" class="c"><input type="checkbox" id="c-38379689" checked=""/><div class="controls bullet"><span class="by">RockyMcNuts</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38378541">prev</a><span>|</span><a href="#38376259">next</a><span>|</span><label class="collapse" for="c-38379689">[-]</label><label class="expand" for="c-38379689">[1 more]</label></div><br/><div class="children"><div class="content">Below is a good thread, which maybe contains the answer to your question, and Ken Olsen&#x27;s question about why brainiac MIT grads get managed by midwit HBS grads.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;coloradotravis&#x2F;status&#x2F;1726060305736687903" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;coloradotravis&#x2F;status&#x2F;172606030573668790...</a><p>A good leader is someone you&#x27;ll follow into battle, because you want to do right by the team, and you know the leader and the team will do right by you. Whatever &#x27;leadership&#x27; is, Sam Altman has it and the board does not.<p><a href="https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;05b80ba4-fcc3-4f39-a0c3-97b025418b3c" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;05b80ba4-fcc3-4f39-a0c3-97b025418...</a><p>The board could have said, hey we don&#x27;t like this direction and you are not keeping us in the loop, it&#x27;s time for an orderly change. But they knew that wouldn&#x27;t go well for them either. They chose to accuse Sam of malfeasance and be weaselly ratfuckers on some level themselves, even if they felt for still-inscrutable reasons that was their only&#x2F;best choice and wouldn&#x27;t go down the way it did.<p>Sam Altman is the front man who &#x27;gave us&#x27; ChatGPT regardless of everything else Ilya and everyone else did. A personal brand (or corporate) is about trust, if you have a brand you are playing a long-term game, a reputation converts prisoner&#x27;s dilemma into iterated prisoner&#x27;s dilemma which has a different outcome.</div><br/></div></div><div id="38376259" class="c"><input type="checkbox" id="c-38376259" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38379689">prev</a><span>|</span><a href="#38377858">next</a><span>|</span><label class="collapse" for="c-38376259">[-]</label><label class="expand" for="c-38376259">[5 more]</label></div><br/><div class="children"><div class="content">he tells a good story, no matter if its true or has any scientific foundation or not.<p>He tells what others like to hear, and manages to gain money out of it</div><br/><div id="38378004" class="c"><input type="checkbox" id="c-38378004" checked=""/><div class="controls bullet"><span class="by">cableshaft</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376259">parent</a><span>|</span><a href="#38377948">next</a><span>|</span><label class="collapse" for="c-38378004">[-]</label><label class="expand" for="c-38378004">[2 more]</label></div><br/><div class="children"><div class="content">Half of being a good CEO is telling a good story, so that&#x27;s not surprising.</div><br/><div id="38378359" class="c"><input type="checkbox" id="c-38378359" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38378004">parent</a><span>|</span><a href="#38377948">next</a><span>|</span><label class="collapse" for="c-38378359">[-]</label><label class="expand" for="c-38378359">[1 more]</label></div><br/><div class="children"><div class="content">Half? 90% of a what a good CEO does is tell the story of why the company is important to it&#x27;s customers and the market it serves. This story drives sales, motivates people internally, and makes the company a place people want to work.</div><br/></div></div></div></div><div id="38377948" class="c"><input type="checkbox" id="c-38377948" checked=""/><div class="controls bullet"><span class="by">93po</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376259">parent</a><span>|</span><a href="#38378004">prev</a><span>|</span><a href="#38377245">next</a><span>|</span><label class="collapse" for="c-38377948">[-]</label><label class="expand" for="c-38377948">[1 more]</label></div><br/><div class="children"><div class="content">Story telling is the fabric of society in general. It’s why paper money works.</div><br/></div></div><div id="38377245" class="c"><input type="checkbox" id="c-38377245" checked=""/><div class="controls bullet"><span class="by">ensocode</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376259">parent</a><span>|</span><a href="#38377948">prev</a><span>|</span><a href="#38377858">next</a><span>|</span><label class="collapse" for="c-38377245">[-]</label><label class="expand" for="c-38377245">[1 more]</label></div><br/><div class="children"><div class="content">this - a good, charismatic salesman</div><br/></div></div></div></div><div id="38377858" class="c"><input type="checkbox" id="c-38377858" checked=""/><div class="controls bullet"><span class="by">yodsanklai</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376259">prev</a><span>|</span><a href="#38376614">next</a><span>|</span><label class="collapse" for="c-38377858">[-]</label><label class="expand" for="c-38377858">[1 more]</label></div><br/><div class="children"><div class="content">Human nature, some people do love charismatic leaders. It&#x27;s hard to comprehend for those of us with a more anarchist nature.<p>That being said, I have no idea of this guy&#x27;s contributions. It&#x27;s easy to dismiss entrepreneur&#x2F;managers because they&#x27;re not top scientists, but they also have very rare skills and without them, projects don&#x27;t get done.</div><br/></div></div><div id="38376614" class="c"><input type="checkbox" id="c-38376614" checked=""/><div class="controls bullet"><span class="by">MichaelRazum</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38377858">prev</a><span>|</span><a href="#38376872">next</a><span>|</span><label class="collapse" for="c-38376614">[-]</label><label class="expand" for="c-38376614">[2 more]</label></div><br/><div class="children"><div class="content">You could say the same about any person on the top. In general CEO&#x27;s do not do research. Still they are critical for success.<p>By the way the AI scientists get a lot of respect and admiration see Ilya for example.</div><br/><div id="38377182" class="c"><input type="checkbox" id="c-38377182" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376614">parent</a><span>|</span><a href="#38376872">next</a><span>|</span><label class="collapse" for="c-38377182">[-]</label><label class="expand" for="c-38377182">[1 more]</label></div><br/><div class="children"><div class="content">he was very well known long before openAI</div><br/></div></div></div></div><div id="38376872" class="c"><input type="checkbox" id="c-38376872" checked=""/><div class="controls bullet"><span class="by">TrackerFF</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376614">prev</a><span>|</span><a href="#38378403">next</a><span>|</span><label class="collapse" for="c-38376872">[-]</label><label class="expand" for="c-38376872">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the cult of the CEO in action.</div><br/></div></div><div id="38378403" class="c"><input type="checkbox" id="c-38378403" checked=""/><div class="controls bullet"><span class="by">alentred</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376872">prev</a><span>|</span><a href="#38379579">next</a><span>|</span><label class="collapse" for="c-38378403">[-]</label><label class="expand" for="c-38378403">[1 more]</label></div><br/><div class="children"><div class="content">&gt; treating Sam like some hero<p>Recent OpenAI CEOs found themselves on the protagonist side not for their actions, but for the way they have been seemingly treated by the board. Regardless of actual actions on either side, &quot;heroic&quot; or not, of which the public knows very little.</div><br/></div></div><div id="38379579" class="c"><input type="checkbox" id="c-38379579" checked=""/><div class="controls bullet"><span class="by">erickhill</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38378403">prev</a><span>|</span><a href="#38375859">next</a><span>|</span><label class="collapse" for="c-38379579">[-]</label><label class="expand" for="c-38379579">[1 more]</label></div><br/><div class="children"><div class="content">Read up on the John Sculley&#x2F;Michael Spindler days of Apple, and Jobs&#x27; return.<p>I think that&#x27;s what may be in the minds of several people eagerly watching this eventually-to-be-made David Fincher movie.</div><br/></div></div></div></div><div id="38375859" class="c"><input type="checkbox" id="c-38375859" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#38375804">prev</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38375859">[-]</label><label class="expand" for="c-38375859">[335 more]</label></div><br/><div class="children"><div class="content">Disappointing outcome. The process has conclusively confirmed that OpenAI is in fact not open and that it is effectively controlled by Microsoft. Furthermore, the overwhelming groupthink shows there&#x27;s clearly little critical thinking amongst OpenAI&#x27;s employees either.<p>It might not seem like the case right now, but I think the real disruption is just about to begin. OpenAI does not have in its DNA to win, they&#x27;re too short-sighted and reactive. Big techs will have incredible distribution power but a real disruptor must be brewing somewhere unnoticed, for now.</div><br/><div id="38376477" class="c"><input type="checkbox" id="c-38376477" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376493">next</a><span>|</span><label class="collapse" for="c-38376477">[-]</label><label class="expand" for="c-38376477">[220 more]</label></div><br/><div class="children"><div class="content">&gt; there&#x27;s clearly little critical thinking amongst OpenAI&#x27;s employees either.<p>That they reached a different conclusion than the outcome you wished for does not indicate a lack of critical thinking skills. They have a different set of information than you do, and reached a different conclusion.</div><br/><div id="38378495" class="c"><input type="checkbox" id="c-38378495" checked=""/><div class="controls bullet"><span class="by">JCM9</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38377376">next</a><span>|</span><label class="collapse" for="c-38378495">[-]</label><label class="expand" for="c-38378495">[67 more]</label></div><br/><div class="children"><div class="content">When a politician wins with 98% of the vote do you A) think that person must be an incredible leader , or B) think something else is going on?<p>Only time will tell if this was a good or bad outcome, but for now the damage is done and OpenAI has a lot of trust rebuilding to do to shake off the reputation that it now has after this circus.</div><br/><div id="38378914" class="c"><input type="checkbox" id="c-38378914" checked=""/><div class="controls bullet"><span class="by">roflc0ptic</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38378535">next</a><span>|</span><label class="collapse" for="c-38378914">[-]</label><label class="expand" for="c-38378914">[18 more]</label></div><br/><div class="children"><div class="content">The simple answer here is that the boards actions stood to incinerate millions of dollars of wealth for most of these employees, and they were up in arms.<p>They’re all acting out the intended incentives of giving people stake in a company: please don’t destroy it.</div><br/><div id="38380031" class="c"><input type="checkbox" id="c-38380031" checked=""/><div class="controls bullet"><span class="by">cityguy33</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378914">parent</a><span>|</span><a href="#38379022">next</a><span>|</span><label class="collapse" for="c-38380031">[-]</label><label class="expand" for="c-38380031">[13 more]</label></div><br/><div class="children"><div class="content">I don’t understand how the fact they went from a nonprofit into a for-profit subsidiary of one of the most closed-off anticompetitive megacorps in tech is so readily glossed over.  I get it, we all love money and Sam’s great at generating it, but anyone who works at OpenAI besides the board seems to be morally bankrupt.</div><br/><div id="38380372" class="c"><input type="checkbox" id="c-38380372" checked=""/><div class="controls bullet"><span class="by">gdhkgdhkvff</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380031">parent</a><span>|</span><a href="#38382515">next</a><span>|</span><label class="collapse" for="c-38380372">[-]</label><label class="expand" for="c-38380372">[8 more]</label></div><br/><div class="children"><div class="content">Pretty easy to complain about lack of morals when it’s <i>someone else’s</i> millions of dollars of potential compensation that will be incinerated.<p>Also, working for a subsidiary (which was likely going to be given much more self-governance than working directly at megacorp), doesn’t necessarily mean “evil”. That’s a very 1-dimensional way to think about things.<p>Self-disclosure: I work for a megacorp.</div><br/><div id="38380551" class="c"><input type="checkbox" id="c-38380551" checked=""/><div class="controls bullet"><span class="by">yoyohello13</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380372">parent</a><span>|</span><a href="#38381518">next</a><span>|</span><label class="collapse" for="c-38380551">[-]</label><label class="expand" for="c-38380551">[1 more]</label></div><br/><div class="children"><div class="content">We can acknowledge that it&#x27;s morally bankrupt, while also not blaming them. Hell, I&#x27;d probably do the same thing in their shoes. That doesn&#x27;t make it right.</div><br/></div></div><div id="38381518" class="c"><input type="checkbox" id="c-38381518" checked=""/><div class="controls bullet"><span class="by">yterdy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380372">parent</a><span>|</span><a href="#38380551">prev</a><span>|</span><a href="#38387582">next</a><span>|</span><label class="collapse" for="c-38381518">[-]</label><label class="expand" for="c-38381518">[3 more]</label></div><br/><div class="children"><div class="content">If some of the smartest people on the planet are willing to sell the rest of us out for Comfy Lifestyle Money (not even Influence State Politics Money), then we are well and truly Capital-F Fucked.</div><br/><div id="38382315" class="c"><input type="checkbox" id="c-38382315" checked=""/><div class="controls bullet"><span class="by">deckard1</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38381518">parent</a><span>|</span><a href="#38387582">next</a><span>|</span><label class="collapse" for="c-38382315">[-]</label><label class="expand" for="c-38382315">[2 more]</label></div><br/><div class="children"><div class="content">We already know some of the smartest people are willing to sell us out. Because they work for FAANG ad tech, spending their days figuring out how to maximize the eyeballs they reach while sucking up all your privacy.<p>It&#x27;s a post-&quot;Don&#x27;t be evil&quot; world today.</div><br/><div id="38383784" class="c"><input type="checkbox" id="c-38383784" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38382315">parent</a><span>|</span><a href="#38387582">next</a><span>|</span><label class="collapse" for="c-38383784">[-]</label><label class="expand" for="c-38383784">[1 more]</label></div><br/><div class="children"><div class="content">If half of the brainpower invested in advertising food would go towards world hunger we&#x27;d have too much food.</div><br/></div></div></div></div></div></div><div id="38387582" class="c"><input type="checkbox" id="c-38387582" checked=""/><div class="controls bullet"><span class="by">cityguy33</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380372">parent</a><span>|</span><a href="#38381518">prev</a><span>|</span><a href="#38382444">next</a><span>|</span><label class="collapse" for="c-38387582">[-]</label><label class="expand" for="c-38387582">[1 more]</label></div><br/><div class="children"><div class="content">I guess my qualm is that this is the cost of doing business, yet people are outraged at the board because they’re not going to make truckloads of money in equity grants.  That’s the morally bankrupt part in my opinion.<p>If you throw your hands up and say, “well kudos to them, theyre actually fulfilling their goal of being a non profit.  I’m going to find a new job”.  That’s fine by me.  But if you get morally outraged at the board over this because you expected the payday of a lifetime, that’s on you.</div><br/></div></div><div id="38382444" class="c"><input type="checkbox" id="c-38382444" checked=""/><div class="controls bullet"><span class="by">slg</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380372">parent</a><span>|</span><a href="#38387582">prev</a><span>|</span><a href="#38380907">next</a><span>|</span><label class="collapse" for="c-38382444">[-]</label><label class="expand" for="c-38382444">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pretty easy to complain about lack of morals when it’s someone else’s millions of dollars of potential compensation that will be incinerated.<p>That is a part of the reason why organizations choose to set themselves up as a non-profit, to help codify those morals into the legal status of the organization to ensure that the ingrained selfishness that exists in all of us doesn’t overtake their mission.  That is the heart of this whole controversy.  If OpenAI was never a non-profit, there wouldn’t be any issue here because they wouldn’t even be having this legal and ethical fight. They would just be pursuing the selfish path like all other for profit businesses and there would be no room for the board to fire or even really criticize Sam.</div><br/></div></div><div id="38380907" class="c"><input type="checkbox" id="c-38380907" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380372">parent</a><span>|</span><a href="#38382444">prev</a><span>|</span><a href="#38382515">next</a><span>|</span><label class="collapse" for="c-38380907">[-]</label><label class="expand" for="c-38380907">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pretty easy to complain about lack of morals when it’s someone else’s millions of dollars of potential compensation that will be incinerated.<p>And while also working for a for-profit company.</div><br/></div></div></div></div><div id="38382515" class="c"><input type="checkbox" id="c-38382515" checked=""/><div class="controls bullet"><span class="by">rozap</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380031">parent</a><span>|</span><a href="#38380372">prev</a><span>|</span><a href="#38381926">next</a><span>|</span><label class="collapse" for="c-38382515">[-]</label><label class="expand" for="c-38382515">[1 more]</label></div><br/><div class="children"><div class="content">Easy to see how humans would join a non profit for the vibes, and then when they create one of the most compelling products of the last decade worth billions of dollars, quickly change their thinking into &quot;wait, i should get rewarded for this&quot;.</div><br/></div></div><div id="38381926" class="c"><input type="checkbox" id="c-38381926" checked=""/><div class="controls bullet"><span class="by">endtime</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380031">parent</a><span>|</span><a href="#38382515">prev</a><span>|</span><a href="#38383360">next</a><span>|</span><label class="collapse" for="c-38381926">[-]</label><label class="expand" for="c-38381926">[1 more]</label></div><br/><div class="children"><div class="content">&gt; anyone who works at OpenAI besides the board seems to be morally bankrupt.<p>People concerned about AI safety were probably not going to join in the first place...</div><br/></div></div><div id="38383360" class="c"><input type="checkbox" id="c-38383360" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380031">parent</a><span>|</span><a href="#38381926">prev</a><span>|</span><a href="#38380680">next</a><span>|</span><label class="collapse" for="c-38383360">[-]</label><label class="expand" for="c-38383360">[1 more]</label></div><br/><div class="children"><div class="content">Supposedly they had about 50% of employees leave in the year of the conversion to for-profit.</div><br/></div></div><div id="38380680" class="c"><input type="checkbox" id="c-38380680" checked=""/><div class="controls bullet"><span class="by">Zpalmtree</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380031">parent</a><span>|</span><a href="#38383360">prev</a><span>|</span><a href="#38379022">next</a><span>|</span><label class="collapse" for="c-38380680">[-]</label><label class="expand" for="c-38380680">[1 more]</label></div><br/><div class="children"><div class="content">Why would they be morally bankrupt? Do the employees have to care if it&#x27;s a non profit or a for profit?<p>And if they do prefer it as a for profit company, why would that make them morally bankrupt?</div><br/></div></div></div></div><div id="38379022" class="c"><input type="checkbox" id="c-38379022" checked=""/><div class="controls bullet"><span class="by">whywhywhywhy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378914">parent</a><span>|</span><a href="#38380031">prev</a><span>|</span><a href="#38378535">next</a><span>|</span><label class="collapse" for="c-38379022">[-]</label><label class="expand" for="c-38379022">[4 more]</label></div><br/><div class="children"><div class="content">Wild the employees will go back under a new board and the same structure, first priority should be removing the structure that allowed a small group of people to destroy things over what may have been very petty reasons.</div><br/><div id="38379208" class="c"><input type="checkbox" id="c-38379208" checked=""/><div class="controls bullet"><span class="by">CydeWeys</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379022">parent</a><span>|</span><a href="#38378535">next</a><span>|</span><label class="collapse" for="c-38379208">[-]</label><label class="expand" for="c-38379208">[3 more]</label></div><br/><div class="children"><div class="content">Well it&#x27;s a different group of people and that group will now know the consequences of attempting to remove Sam Altman.  I don&#x27;t see this happening again.</div><br/><div id="38379721" class="c"><input type="checkbox" id="c-38379721" checked=""/><div class="controls bullet"><span class="by">youcantcook</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379208">parent</a><span>|</span><a href="#38378535">next</a><span>|</span><label class="collapse" for="c-38379721">[-]</label><label class="expand" for="c-38379721">[2 more]</label></div><br/><div class="children"><div class="content">Most likely, but it is cute how confident you are towards humanity learning their lesson.</div><br/><div id="38382168" class="c"><input type="checkbox" id="c-38382168" checked=""/><div class="controls bullet"><span class="by">tstrimple</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379721">parent</a><span>|</span><a href="#38378535">next</a><span>|</span><label class="collapse" for="c-38382168">[-]</label><label class="expand" for="c-38382168">[1 more]</label></div><br/><div class="children"><div class="content">Humanity no. But it&#x27;s not humanity on the OpenAI board. It&#x27;s 9 individuals. Individuals have amazing capacity for learning and improvement.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38378535" class="c"><input type="checkbox" id="c-38378535" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38378914">prev</a><span>|</span><a href="#38378961">next</a><span>|</span><label class="collapse" for="c-38378535">[-]</label><label class="expand" for="c-38378535">[44 more]</label></div><br/><div class="children"><div class="content">The environment in a small to medium company is much more homogenous than the general population.<p>When you see 95%+ consensus from 800 employees, that doesn&#x27;t suggest tanks and police dogs intimidating people at the voting booth.</div><br/><div id="38378694" class="c"><input type="checkbox" id="c-38378694" checked=""/><div class="controls bullet"><span class="by">mstade</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378535">parent</a><span>|</span><a href="#38379422">next</a><span>|</span><label class="collapse" for="c-38378694">[-]</label><label class="expand" for="c-38378694">[13 more]</label></div><br/><div class="children"><div class="content">Not that I have any insight into any of the events at OpenAI, but would just like to point out there are several other reasons why so many people would sign, including but not limited to:<p>- peer pressure<p>- group think<p>- financial motives<p>- fear of the unknown (Sam being a known quantity)<p>- etc.<p>So many signatures may well mean there&#x27;s consensus, but it&#x27;s not a given. It may well be that we see a mass exodus of talent from OpenAI _anyway_, due to recent events, just on a different time scale.<p>If I had to pick one reason though, it&#x27;s consensus. This whole saga could&#x27;ve been the script to an episode of Silicon Valley[1], and having been on the inside of companies like that I too would sign a document asking for a return to known quantities and – hopefully – stability.<p>[1]: <a href="https:&#x2F;&#x2F;www.imdb.com&#x2F;title&#x2F;tt2575988&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.imdb.com&#x2F;title&#x2F;tt2575988&#x2F;</a></div><br/><div id="38379269" class="c"><input type="checkbox" id="c-38379269" checked=""/><div class="controls bullet"><span class="by">phpisthebest</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378694">parent</a><span>|</span><a href="#38379159">next</a><span>|</span><label class="collapse" for="c-38379269">[-]</label><label class="expand" for="c-38379269">[3 more]</label></div><br/><div class="children"><div class="content">If the opposing letter that was published from &quot;former&quot; employee&#x27;s is correct there was already a huge turn over,  and the people that remain liked the environment they were in, and I would assume liked the current leadership or they would have left<p>So clearly the current leadship built a loyal group which I think is something that should be explored because group think is rarely a good thing,  no matter how much modern society wants to push out all dissent in favor of a monoculture of idea&#x27;s<p>If openAI is a huge mono-culture of thinking then they have bigger problems most likely</div><br/><div id="38379737" class="c"><input type="checkbox" id="c-38379737" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379269">parent</a><span>|</span><a href="#38379159">next</a><span>|</span><label class="collapse" for="c-38379737">[-]</label><label class="expand" for="c-38379737">[2 more]</label></div><br/><div class="children"><div class="content">What opposing letter, how many people are we talking about, and what was their role in the company?<p>All companies are monocultures, IMO, unless they are multi-nationals, and even then, there&#x27;s cultural convergence. And that&#x27;s good, actually. People in a company have to be aligned enough to avoid internal turmoil.</div><br/><div id="38379925" class="c"><input type="checkbox" id="c-38379925" checked=""/><div class="controls bullet"><span class="by">phpisthebest</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379737">parent</a><span>|</span><a href="#38379159">next</a><span>|</span><label class="collapse" for="c-38379925">[-]</label><label class="expand" for="c-38379925">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt;What opposing letter, how many people are we talking about, and what was their role in the company?<p>Not-validated,  unsigned letter [1]<p>&gt;&gt;All companies are monocultures<p>yes and no.  There has be diversity of thought to ever get anything done really,  ever everyone is just sycophants all agreeing with the boss then you end up with very bad product choices, and even worse company direction.<p>yes there has to be some commonality.  some semblance of shared vision or values, but I dont think that makes a &quot;monoculture&quot;<p>[1] <a href="https:&#x2F;&#x2F;wccftech.com&#x2F;former-openai-employees-allege-deceit-and-manipulation-by-sam-altman-elon-musk-calls-for-investigation&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;wccftech.com&#x2F;former-openai-employees-allege-deceit-a...</a></div><br/></div></div></div></div></div></div><div id="38379159" class="c"><input type="checkbox" id="c-38379159" checked=""/><div class="controls bullet"><span class="by">FabHK</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378694">parent</a><span>|</span><a href="#38379269">prev</a><span>|</span><a href="#38379676">next</a><span>|</span><label class="collapse" for="c-38379159">[-]</label><label class="expand" for="c-38379159">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love another season of Silicon Valley, with some Game Stonk and Bored Apes and ChatGPT and FTX and Elon madness.</div><br/><div id="38380428" class="c"><input type="checkbox" id="c-38380428" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379159">parent</a><span>|</span><a href="#38379676">next</a><span>|</span><label class="collapse" for="c-38380428">[-]</label><label class="expand" for="c-38380428">[1 more]</label></div><br/><div class="children"><div class="content">The only major series with a brilliant, satisfying, and true to form ending and you want to resuscitate it back to life for some cheap curtain calls and modern social commentary, leaving Mike Judge to end it yet again and in such a way that manages to duplicate or exceed the effect of the first time but without doing the same thing? Screw it. Why not?</div><br/></div></div></div></div><div id="38379676" class="c"><input type="checkbox" id="c-38379676" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378694">parent</a><span>|</span><a href="#38379159">prev</a><span>|</span><a href="#38381902">next</a><span>|</span><label class="collapse" for="c-38379676">[-]</label><label class="expand" for="c-38379676">[5 more]</label></div><br/><div class="children"><div class="content">You could say that, except that people in this industry are the most privileged, and their earnings and equity would probably be matched elsewhere.<p>You say “group think” like it&#x27;s a bad thing. There&#x27;s always wisdom in crowds. We have a mob mentality as an evolutionary advantage. You&#x27;re also willing to believe that 3–4 people can make better judgement calls than 800 people. That&#x27;s only possible if the board has information that&#x27;s not public, and I don&#x27;t think they do, or else they would have published it already.<p>And … it doesn&#x27;t matter why there&#x27;s such a wide consensus. Whether they care about their legacy, or earnings, or not upsetting their colleagues, doesn&#x27;t matter. The board acted poorly, undoubtedly. Even if they had legitimate reasons to do what they did, that stopped mattering.</div><br/><div id="38380023" class="c"><input type="checkbox" id="c-38380023" checked=""/><div class="controls bullet"><span class="by">axus</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379676">parent</a><span>|</span><a href="#38381902">next</a><span>|</span><label class="collapse" for="c-38380023">[-]</label><label class="expand" for="c-38380023">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m imagining they see themselves in the position of Microsoft employees about to release Windows 95, or Apple employees about to release the iPhone... and someone wants to get rid of Bill Gates or Steve Jobs.</div><br/><div id="38380634" class="c"><input type="checkbox" id="c-38380634" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380023">parent</a><span>|</span><a href="#38381902">next</a><span>|</span><label class="collapse" for="c-38380634">[-]</label><label class="expand" for="c-38380634">[3 more]</label></div><br/><div class="children"><div class="content">See, neither Bill Gates nor Steve Jobs are around these companies, and all is fine.<p>Apple and Microsoft even have the strongest financial results in their lifetime.</div><br/><div id="38380981" class="c"><input type="checkbox" id="c-38380981" checked=""/><div class="controls bullet"><span class="by">ronchalant</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380634">parent</a><span>|</span><a href="#38381097">next</a><span>|</span><label class="collapse" for="c-38380981">[-]</label><label class="expand" for="c-38380981">[1 more]</label></div><br/><div class="children"><div class="content">Gates and Jobs helped establish these companies as the powerhouses they are today with their leadership in the 90s and 00s.<p>It&#x27;s fair to say that what got MS and Apple to dominance may be different from what it takes to keep them there, but which part of that corporate timeline more closely resembles OpenAI?</div><br/></div></div><div id="38381097" class="c"><input type="checkbox" id="c-38381097" checked=""/><div class="controls bullet"><span class="by">ghodith</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380634">parent</a><span>|</span><a href="#38380981">prev</a><span>|</span><a href="#38381902">next</a><span>|</span><label class="collapse" for="c-38381097">[-]</label><label class="expand" for="c-38381097">[1 more]</label></div><br/><div class="children"><div class="content">Now go back in time and cut them before their companies took off.</div><br/></div></div></div></div></div></div></div></div><div id="38381902" class="c"><input type="checkbox" id="c-38381902" checked=""/><div class="controls bullet"><span class="by">ghaff</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378694">parent</a><span>|</span><a href="#38379676">prev</a><span>|</span><a href="#38379349">next</a><span>|</span><label class="collapse" for="c-38381902">[-]</label><label class="expand" for="c-38381902">[1 more]</label></div><br/><div class="children"><div class="content">Signing petitions is also cheap. It doesn&#x27;t mean that everyone signing has thought deeply and actually made a life-changing decision.</div><br/></div></div><div id="38379349" class="c"><input type="checkbox" id="c-38379349" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378694">parent</a><span>|</span><a href="#38381902">prev</a><span>|</span><a href="#38379422">next</a><span>|</span><label class="collapse" for="c-38379349">[-]</label><label class="expand" for="c-38379349">[1 more]</label></div><br/><div class="children"><div class="content">Exactly; there are multitudes of reasons and very little information so why pick any one of them?</div><br/></div></div></div></div><div id="38379422" class="c"><input type="checkbox" id="c-38379422" checked=""/><div class="controls bullet"><span class="by">from-nibly</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378535">parent</a><span>|</span><a href="#38378694">prev</a><span>|</span><a href="#38378762">next</a><span>|</span><label class="collapse" for="c-38379422">[-]</label><label class="expand" for="c-38379422">[1 more]</label></div><br/><div class="children"><div class="content">Right. They aren&#x27;t actually voting for Sam Altman. If I&#x27;m working at a company and I see as little as 10% of the company jump ship I think &quot;I&#x27;d better get the frik outta here&quot;. Especially if I respect the other people who are leaving. This isnt a blind vote. This is a rolling snowball.<p>I don&#x27;t think very many people actually need to believe in Sam Altman for basically everyone to switch to Microsoft.<p>95% doesn&#x27;t show a large amount of loyalty to Sam it shows a low amount of loyalty to OpenAI.<p>So it looks like a VERY normal company.</div><br/></div></div><div id="38378762" class="c"><input type="checkbox" id="c-38378762" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378535">parent</a><span>|</span><a href="#38379422">prev</a><span>|</span><a href="#38378888">next</a><span>|</span><label class="collapse" for="c-38378762">[-]</label><label class="expand" for="c-38378762">[18 more]</label></div><br/><div class="children"><div class="content">Personally I have never seen that level of singular agreement in any group of people that large.  Especially to the level of sacrifice they were willing to take for the cause. You maybe see that level of devotion to a leader in churches or cults, but in any other group?  You can barely get 3 people to agree on a restaurant for lunch.<p>I am not saying something nefarious forced it, but it’s certainly unusual in my experience and this causes me to be skeptical of why.</div><br/><div id="38378863" class="c"><input type="checkbox" id="c-38378863" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378762">parent</a><span>|</span><a href="#38380525">next</a><span>|</span><label class="collapse" for="c-38378863">[-]</label><label class="expand" for="c-38378863">[2 more]</label></div><br/><div class="children"><div class="content">&gt;You can barely get 3 people to agree on a restaurant for lunch.<p>I was about to state that a single human is enough to see disagreements raise, but this doesn’t reach full consensus in my mind.</div><br/><div id="38379092" class="c"><input type="checkbox" id="c-38379092" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378863">parent</a><span>|</span><a href="#38380525">next</a><span>|</span><label class="collapse" for="c-38379092">[-]</label><label class="expand" for="c-38379092">[1 more]</label></div><br/><div class="children"><div class="content">I was conflicted about originally posting that sentence.  I waffled back and forth between, 2, 3, 5…<p>Three was the compromise I made with myself.</div><br/></div></div></div></div><div id="38380525" class="c"><input type="checkbox" id="c-38380525" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378762">parent</a><span>|</span><a href="#38378863">prev</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38380525">[-]</label><label class="expand" for="c-38380525">[7 more]</label></div><br/><div class="children"><div class="content">This seems extremely presumptuous. Have you ever been inside a company during a coup attempt? The employees’ future pay and livelihood is at stake, why are you assuming they weren’t being asked to sacrifice themselves by <i>not</i> objecting to the coup. The level of agreement could be entirely due to the fact that the stakes are very large, completely unlike your choice for lunch locale. It could also be an outcome of nobody having asked their opinion before making a very big change. I’d expect to see almost everyone at a company agree with each other if the question was, “hey should we close this profitable company and all go get other jobs, or should we keep working?”</div><br/><div id="38381903" class="c"><input type="checkbox" id="c-38381903" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380525">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38381903">[-]</label><label class="expand" for="c-38381903">[6 more]</label></div><br/><div class="children"><div class="content">I have had a long career and have been through hostile mergers several times and at no point have I ever seen large numbers of employees act outside of their self-interest for an executive.  It just doesn’t happen.  Even in my career, with executives <i>who are my friends</i>, I would not act outside my personal interests.  When things are corporately uncertain and people worry about their working livelihoods they just don’t tend to act that way.  They tend to hunker heads down or jump independently.<p>The only explanation that makes any sense to me is that these folks know that AI is hot right now and would be scooped up quickly by other orgs…so there is little risk in taking a stand.  Without that caveat, there is no doubt in my mind that there would not be this level of solidarity to a CEO.</div><br/><div id="38385294" class="c"><input type="checkbox" id="c-38385294" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38381903">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38385294">[-]</label><label class="expand" for="c-38385294">[5 more]</label></div><br/><div class="children"><div class="content">&gt; at no point have I ever seen large numbers of employees act outside of their self-interest for an executive.<p>This is still making the same assumption. Why are you assuming they are acting outside of self-interest?</div><br/><div id="38385555" class="c"><input type="checkbox" id="c-38385555" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38385294">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38385555">[-]</label><label class="expand" for="c-38385555">[4 more]</label></div><br/><div class="children"><div class="content">If you are willing to leave a paycheck because of someone else getting slighted, <i>to me</i>, that is acting against your own self-interest.  Assuming of course you are willing to actually leave.  If it was a bluff, that still works against your self-interest by factioning against the new leadership and inviting retaliation for your bluff.</div><br/><div id="38386202" class="c"><input type="checkbox" id="c-38386202" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38385555">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38386202">[-]</label><label class="expand" for="c-38386202">[3 more]</label></div><br/><div class="children"><div class="content">Why do you assume they were willing to leave a paycheck because of someone else getting slighted? If that were the case, then it is unlikely everyone would be in agreement. Which indicates you might be making incorrect assumptions, no? And, again, why assume they were threatening to leave a paycheck at all? That’s a bad assumption; MS was offering a paycheck. We already know their salaries weren’t on the line, but all future stock earnings and bonuses very well might be. There could be other reasons too, I don’t see how you can conclude this was either a bluff or not self-interest without making potentially bad assumptions.</div><br/><div id="38387822" class="c"><input type="checkbox" id="c-38387822" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38386202">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38387822">[-]</label><label class="expand" for="c-38387822">[2 more]</label></div><br/><div class="children"><div class="content">They threatened to quit.  You don’t actually believe that a company would be willing to still provide them a paycheck if they left the company do you?<p>At this point I suspect you are being deliberately obtuse.  Have a good day.</div><br/><div id="38388046" class="c"><input type="checkbox" id="c-38388046" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38387822">parent</a><span>|</span><a href="#38378909">next</a><span>|</span><label class="collapse" for="c-38388046">[-]</label><label class="expand" for="c-38388046">[1 more]</label></div><br/><div class="children"><div class="content">They threatened to quit by <i>moving</i> to Microsoft, didn’t you read the letter? MS assured everyone jobs if they wanted to move. Isn’t making incorrect assumptions and sticking to them  in the face of contrary evidence and not answering direct questions the very definition of obtuse?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38378909" class="c"><input type="checkbox" id="c-38378909" checked=""/><div class="controls bullet"><span class="by">panragon</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378762">parent</a><span>|</span><a href="#38380525">prev</a><span>|</span><a href="#38382279">next</a><span>|</span><label class="collapse" for="c-38378909">[-]</label><label class="expand" for="c-38378909">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Especially to the level of sacrifice they were willing to take for the cause.<p>We have no idea that they were sacrificing anything personally. The packages Microsoft offered for people who separated may have been much more generous than what they were currently sitting on. Sure, Altman is a good leader, but Microsoft also has deep pockets. When you see some of the top brass at the company already make the move and you <i>know</i> they&#x27;re willing to pay to bring you over as well, we&#x27;re not talking about a huge risk here. If anything, staying with what at the time looked like a sinking ship might have been a much larger sacrifice.</div><br/></div></div><div id="38382279" class="c"><input type="checkbox" id="c-38382279" checked=""/><div class="controls bullet"><span class="by">cellar_door</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378762">parent</a><span>|</span><a href="#38378909">prev</a><span>|</span><a href="#38378920">next</a><span>|</span><label class="collapse" for="c-38382279">[-]</label><label class="expand" for="c-38382279">[1 more]</label></div><br/><div class="children"><div class="content">There are plenty of examples of workers unions voting with similar levels of agreement. Here are two from the last couple months:<p>&gt; UAW President Shawn Fain announced today that the union’s strike authorization vote passed with near universal approval from the 150,000 union workers at Ford, General Motors and Stellantis. Final votes are still being tabulated, but the current combined average across the Big Three was 97% in favor of strike authorization. The vote does not guarantee a strike will be called, only that the union has the right to call a strike if the Big Three refuse to reach a fair deal.<p><a href="https:&#x2F;&#x2F;uaw.org&#x2F;97-uaws-big-three-members-vote-yes-authorize-strike&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;uaw.org&#x2F;97-uaws-big-three-members-vote-yes-authorize...</a><p>&gt; The Writers Guild of America has voted overwhelmingly to ratify its new contract, formally ending one of the longest labor disputes in Hollywood history. The membership voted 99% in favor of ratification, with 8,435 voting yes and 90 members opposed.<p><a href="https:&#x2F;&#x2F;variety.com&#x2F;2023&#x2F;biz&#x2F;news&#x2F;wga-ratify-contract-end-strike-1235749253&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;variety.com&#x2F;2023&#x2F;biz&#x2F;news&#x2F;wga-ratify-contract-end-st...</a></div><br/></div></div><div id="38378920" class="c"><input type="checkbox" id="c-38378920" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378762">parent</a><span>|</span><a href="#38382279">prev</a><span>|</span><a href="#38380602">next</a><span>|</span><label class="collapse" for="c-38378920">[-]</label><label class="expand" for="c-38378920">[5 more]</label></div><br/><div class="children"><div class="content">Approval rates of &gt;90% are quite common within political parties, to the point where anything less can be seen as an embarrassment to the incumbent head of party.</div><br/><div id="38379069" class="c"><input type="checkbox" id="c-38379069" checked=""/><div class="controls bullet"><span class="by">kcplate</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378920">parent</a><span>|</span><a href="#38380602">next</a><span>|</span><label class="collapse" for="c-38379069">[-]</label><label class="expand" for="c-38379069">[4 more]</label></div><br/><div class="children"><div class="content">There is a big difference between “I agree with this…” when a telephone poll caller reaches you and “I am willing to leave my livelihood because my company CEO got fired”</div><br/><div id="38379315" class="c"><input type="checkbox" id="c-38379315" checked=""/><div class="controls bullet"><span class="by">from-nibly</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379069">parent</a><span>|</span><a href="#38379329">next</a><span>|</span><label class="collapse" for="c-38379315">[-]</label><label class="expand" for="c-38379315">[1 more]</label></div><br/><div class="children"><div class="content">But if 100 employees were like &quot;I&#x27;m gonna leave&quot; then your livelihood is in jeopardy. So you join in. It&#x27;s really easy to see 90% of people jumping overboard when they are all on a sinking ship.</div><br/></div></div><div id="38379329" class="c"><input type="checkbox" id="c-38379329" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379069">parent</a><span>|</span><a href="#38379315">prev</a><span>|</span><a href="#38379698">next</a><span>|</span><label class="collapse" for="c-38379329">[-]</label><label class="expand" for="c-38379329">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t mean voter approval, I mean party member approval. That&#x27;s arguably not that far off from a CEO situation in a way in that it&#x27;s the opinion of and support for the group&#x27;s leadership by group members.<p>Voter approval is actually usually much less unanimous, as far as I can tell.</div><br/></div></div><div id="38379698" class="c"><input type="checkbox" id="c-38379698" checked=""/><div class="controls bullet"><span class="by">zerbinxx</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379069">parent</a><span>|</span><a href="#38379329">prev</a><span>|</span><a href="#38380602">next</a><span>|</span><label class="collapse" for="c-38379698">[-]</label><label class="expand" for="c-38379698">[1 more]</label></div><br/><div class="children"><div class="content">But it’s not changing their livelihood. Msft just gives them the same deal. In a lot of ways, it’s similar to the telepoll - people can just say whatever they want, there won’t be big material consequences</div><br/></div></div></div></div></div></div></div></div><div id="38378888" class="c"><input type="checkbox" id="c-38378888" checked=""/><div class="controls bullet"><span class="by">plorg</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378535">parent</a><span>|</span><a href="#38378762">prev</a><span>|</span><a href="#38378961">next</a><span>|</span><label class="collapse" for="c-38378888">[-]</label><label class="expand" for="c-38378888">[11 more]</label></div><br/><div class="children"><div class="content">That sounds like a cult more than a business. I work at a small company (~100 people), and we are more or less aligned with what we&#x27;re doing you are not going to get close to that consensus on anything. Same for our sister company, about the same size as OpenAI.</div><br/><div id="38379304" class="c"><input type="checkbox" id="c-38379304" checked=""/><div class="controls bullet"><span class="by">docmars</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378888">parent</a><span>|</span><a href="#38379041">next</a><span>|</span><label class="collapse" for="c-38379304">[-]</label><label class="expand" for="c-38379304">[3 more]</label></div><br/><div class="children"><div class="content">I think it could be a number of factors:<p>1. The company has built a culture around not being under control by one single company, Microsoft in this case. Employees may overwhelmingly agree.<p>2. The board acted rashly in the first place, and over 2&#x2F;3 of employees signed their intent to quit if the board hadn&#x27;t been replaced.<p>3. Younger folks probably don&#x27;t look highly at boards in general, because they never get to interact with them. They also sometimes dictate product outcomes that could go against the creative freedoms and autonomy employees are looking for. Boards are also focused on profits, which is a net-good for the company, but threatens the culture of &quot;for the good of humanity&quot; that hooks people.<p>4. The high success of OpenAI has probably inspired loyalty in its employees, so long as it remains  stable, and their perception of what stability is means that the company ultimately changes little. Being &quot;acquired&quot; by Microsoft here may mean major shakeups and potential layoffs. There&#x27;s no guarantees for the bulk of workers here.<p>I&#x27;m reading into the variables and using intuition to make these guesses, but all to suggest: it&#x27;s complicated, and sometimes outliers like these can happen if those variables create enough alignment, if they seem common-sensical enough to most.</div><br/><div id="38381243" class="c"><input type="checkbox" id="c-38381243" checked=""/><div class="controls bullet"><span class="by">denton-scratch</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379304">parent</a><span>|</span><a href="#38379041">next</a><span>|</span><label class="collapse" for="c-38381243">[-]</label><label class="expand" for="c-38381243">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Younger folks probably don&#x27;t look highly at boards in general, because they never get to interact with them.<p>Judging from the photos I&#x27;ve seen of the principals in this story, none of them looks to be over 30, and some of them look like schoolkids. I&#x27;m referring to the <i>board members</i>.</div><br/><div id="38381480" class="c"><input type="checkbox" id="c-38381480" checked=""/><div class="controls bullet"><span class="by">docmars</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38381243">parent</a><span>|</span><a href="#38379041">next</a><span>|</span><label class="collapse" for="c-38381480">[-]</label><label class="expand" for="c-38381480">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the age of the board members matters, but rather that younger generations have been taught to criticize boards of any &amp; every company for their myriad decisions to sacrifice good things for profit, etc.<p>It&#x27;s a common theme in the overall critique of late stage capitalism, is all I&#x27;m saying — and that it could be a factor in influencing OpenAI&#x27;s employees&#x27; decisions to seek action that specifically eliminates the current board, as a matter of inherent bias that boards act problematically to begin with.</div><br/></div></div></div></div></div></div><div id="38379041" class="c"><input type="checkbox" id="c-38379041" checked=""/><div class="controls bullet"><span class="by">chiefalchemist</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378888">parent</a><span>|</span><a href="#38379304">prev</a><span>|</span><a href="#38378961">next</a><span>|</span><label class="collapse" for="c-38379041">[-]</label><label class="expand" for="c-38379041">[7 more]</label></div><br/><div class="children"><div class="content">I also sounds like a very narrow hiring profile. That is, favoring the like-minded and assimilation over free thinking and philosophical diversity. They might give off the appearance of &quot;diversity&quot; on the outside - which is great for PR - but under the hood it&#x27;s more monocultural. Maybe?</div><br/><div id="38379307" class="c"><input type="checkbox" id="c-38379307" checked=""/><div class="controls bullet"><span class="by">phpisthebest</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379041">parent</a><span>|</span><a href="#38379523">next</a><span>|</span><label class="collapse" for="c-38379307">[-]</label><label class="expand" for="c-38379307">[5 more]</label></div><br/><div class="children"><div class="content">Superficial &quot;diversity&quot; is all the &quot;diversity&quot; a company needs in the modern era.<p>Companies do not desire or seek philosophical diversity,  they only want Superficial biologically based &quot;diversity&quot; to prove they have the &quot;correct&quot; philosophy about the world.</div><br/><div id="38379714" class="c"><input type="checkbox" id="c-38379714" checked=""/><div class="controls bullet"><span class="by">docmars</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379307">parent</a><span>|</span><a href="#38379827">next</a><span>|</span><label class="collapse" for="c-38379714">[-]</label><label class="expand" for="c-38379714">[3 more]</label></div><br/><div class="children"><div class="content">Agree. This is the monoculture being adopted in actuality -- a racist crusade against &quot;whiteness&quot;, and a coercive mechanism to ensure companies don&#x27;t overstep their usage of resources (carbon footprint), so as not to threaten the existing titans who may have already abused what was available to them before these intracorporate policies existed.<p>It&#x27;s also a way for banks and other powerful entities to enforce sweeping policies across international businesses that haven&#x27;t been enacted in law. In other words: if governing bodies aren&#x27;t working for them, they&#x27;ll just do it themselves and undermine the will of companies who do not want to participate, by introducing social pressures and boycotting potential partnerships unless they comply.<p>Ironically, it snuffs out diversity among companies at a 40k foot level.</div><br/><div id="38380649" class="c"><input type="checkbox" id="c-38380649" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379714">parent</a><span>|</span><a href="#38379827">next</a><span>|</span><label class="collapse" for="c-38380649">[-]</label><label class="expand" for="c-38380649">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a crusade against whiteness. Unless you&#x27;re unhinged and believe a single phenotype that prevents skin cancer is somehow an obvious reflection of genetic inferiority and that those lacking it have a historical destiny to rule over the rest and are entitled to institutional privileges over them, it makes sense that companies with employees not representative of the overall population have hiring practices that are problematic, albeit not necessarily being as explicitly racist as you are.</div><br/><div id="38381403" class="c"><input type="checkbox" id="c-38381403" checked=""/><div class="controls bullet"><span class="by">docmars</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380649">parent</a><span>|</span><a href="#38379827">next</a><span>|</span><label class="collapse" for="c-38381403">[-]</label><label class="expand" for="c-38381403">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately you are wrong, and this kind of rhetoric has not only made calls for white genocide acceptable and unpunished, but has incited violence specifically against Caucasian people, as well as anyone who is perceived to adopt &quot;white&quot; thinking such as Asian students specifically, and even Black folks who see success in their life as a result of adopting longstanding European&#x2F;Western principles in their lives.<p>Specifically, principles that have ultimately led to the great civilizations we&#x27;re experiencing today, built upon centuries of hard work and deep thinking in both the arts and sciences, <i>by all races</i>, beautifully.<p>DEI and its creators&#x2F;pushers are a subtle effort to erase and rebuild this prior work under the lie that it had excluded everyone but Whites, so that its original creators no longer take credit.<p>Take the movement to redefine Math concepts by recycling existing concepts using new terms defined exclusively by non-white participants, since its origins are &quot;too white&quot;. Oh the horror! This is false, as there are many prominent non-white mathematicians that existed prior to the woke revolution, so this movement&#x27;s stated purpose is a lie, and its true purpose is to eliminate and replace white influence.<p>Finally, the fact that DEI specifically targets &quot;whiteness&quot; is patently racist. Period.</div><br/></div></div></div></div></div></div><div id="38379827" class="c"><input type="checkbox" id="c-38379827" checked=""/><div class="controls bullet"><span class="by">chiefalchemist</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379307">parent</a><span>|</span><a href="#38379714">prev</a><span>|</span><a href="#38379523">next</a><span>|</span><label class="collapse" for="c-38379827">[-]</label><label class="expand" for="c-38379827">[1 more]</label></div><br/><div class="children"><div class="content">But it&#x27;s not only the companies, it&#x27;s the marginalized so desperate to get a &quot;seat at the table&quot; that they don&#x27;t recognize the table isn&#x27;t getting bigger and rounder. Instead, it&#x27;s still the same rectangular that is getting longer and longer.<p>Participating in that is assimilation.</div><br/></div></div></div></div><div id="38379523" class="c"><input type="checkbox" id="c-38379523" checked=""/><div class="controls bullet"><span class="by">docmars</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379041">parent</a><span>|</span><a href="#38379307">prev</a><span>|</span><a href="#38378961">next</a><span>|</span><label class="collapse" for="c-38379523">[-]</label><label class="expand" for="c-38379523">[1 more]</label></div><br/><div class="children"><div class="content">I think that most pushes for diversity that we see today are intended to result in monocultures.<p>DEI and similar programs use very specific racial language to manipulate everyone into believing whiteness is evil and that rallying around that is the end goal for everyone in a company.<p>On a similar note, the company has already established certain missions and values that new hires may strongly align with like: &quot;Discovering and enacting the path to safe artificial general intelligence&quot;, given not only the excitement around AI&#x27;s possibilities but also the social responsibility of developing it safely. Both are highly appealing goals that are bound to change humanity forever and it would be monumentally exciting to play a part in that.<p>Thus, it&#x27;s safe to think that most employees who are lucky to have earned a chance at participating would want to preserve that, if they&#x27;re aligned.<p>This kind of alignment is not the bad thing people think it is. There&#x27;s nothing quite like a well-oiled machine, even if the perception of diversity from the outside falls by the wayside.<p>Diversity is too often sought after for vanity, rather than practical purposes. This is the danger of coercive, box-checking ESG goals we&#x27;re seeing plague companies, to the extent that it&#x27;s becoming unpopular to chase after due to the strongly partisan political connotations it brings.</div><br/></div></div></div></div></div></div></div></div><div id="38378961" class="c"><input type="checkbox" id="c-38378961" checked=""/><div class="controls bullet"><span class="by">heyjamesknight</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38378535">prev</a><span>|</span><a href="#38379141">next</a><span>|</span><label class="collapse" for="c-38378961">[-]</label><label class="expand" for="c-38378961">[1 more]</label></div><br/><div class="children"><div class="content">That argument only works with a “population”, since almost nobody gets to choose which set of politicians they vote for.<p>In this case, OpenAI employees all voluntarily sought to join that team at one point. It’s not hard to imagine that 98% of a self-selecting group would continue to self-select in a similar fashion.</div><br/></div></div><div id="38379141" class="c"><input type="checkbox" id="c-38379141" checked=""/><div class="controls bullet"><span class="by">JVIDEL</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38378961">prev</a><span>|</span><a href="#38379127">next</a><span>|</span><label class="collapse" for="c-38379141">[-]</label><label class="expand" for="c-38379141">[1 more]</label></div><br/><div class="children"><div class="content">Odds are if he left there&#x27;s the possibility their compensation situation might have changed for the worse if not leading to downsizing, that in the edge of a recession with plenty of competition out there.</div><br/></div></div><div id="38379127" class="c"><input type="checkbox" id="c-38379127" checked=""/><div class="controls bullet"><span class="by">shzhdbi09gv8ioi</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38379141">prev</a><span>|</span><a href="#38378576">next</a><span>|</span><label class="collapse" for="c-38379127">[-]</label><label class="expand" for="c-38379127">[1 more]</label></div><br/><div class="children"><div class="content">&gt; for now the damage is done and OpenAI has a lot of trust rebuilding to do<p>Nobody cares, except shareholders.</div><br/></div></div><div id="38378576" class="c"><input type="checkbox" id="c-38378576" checked=""/><div class="controls bullet"><span class="by">drivers99</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378495">parent</a><span>|</span><a href="#38379127">prev</a><span>|</span><a href="#38377376">next</a><span>|</span><label class="collapse" for="c-38378576">[-]</label><label class="expand" for="c-38378576">[1 more]</label></div><br/><div class="children"><div class="content">Originally, 65% had signed (505 of 770).</div><br/></div></div></div></div><div id="38377376" class="c"><input type="checkbox" id="c-38377376" checked=""/><div class="controls bullet"><span class="by">kitsune_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38378495">prev</a><span>|</span><a href="#38376823">next</a><span>|</span><label class="collapse" for="c-38377376">[-]</label><label class="expand" for="c-38377376">[29 more]</label></div><br/><div class="children"><div class="content">OpenAI Inc.&#x27;s mission in their filings:<p>&quot;OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. We think that artificial intelligence technology will help shape the 21st century, and we want to help the world build safe AI technology and ensure that AI&#x27;s benefits are as widely and evenly distributed as possible. Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.&quot;</div><br/><div id="38377467" class="c"><input type="checkbox" id="c-38377467" checked=""/><div class="controls bullet"><span class="by">graftak</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38377982">next</a><span>|</span><label class="collapse" for="c-38377467">[-]</label><label class="expand" for="c-38377467">[14 more]</label></div><br/><div class="children"><div class="content">People got burned on “don’t be evil” once and so far OpenAI’s vision looks like a bunch of marketing superlatives when compared to their track record.</div><br/><div id="38378103" class="c"><input type="checkbox" id="c-38378103" checked=""/><div class="controls bullet"><span class="by">nmfisher</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377467">parent</a><span>|</span><a href="#38377941">next</a><span>|</span><label class="collapse" for="c-38378103">[-]</label><label class="expand" for="c-38378103">[9 more]</label></div><br/><div class="children"><div class="content">At least Google lasted a good 10 years or so before succumbing to the vagaries of the public stock market. OpenAI lasted, what, 3 years?<p>Not to mention Google never paraded itself around as a non-profit acting in the best interests of humanity.</div><br/><div id="38378438" class="c"><input type="checkbox" id="c-38378438" checked=""/><div class="controls bullet"><span class="by">rolandog</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378103">parent</a><span>|</span><a href="#38382527">next</a><span>|</span><label class="collapse" for="c-38378438">[-]</label><label class="expand" for="c-38378438">[1 more]</label></div><br/><div class="children"><div class="content">I would classify their mission &quot;to organize the world&#x27;s information and make it universally accessible and useful&quot; as some light parading acting in the best interests of humanity.</div><br/></div></div><div id="38382527" class="c"><input type="checkbox" id="c-38382527" checked=""/><div class="controls bullet"><span class="by">deckard1</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378103">parent</a><span>|</span><a href="#38378438">prev</a><span>|</span><a href="#38378604">next</a><span>|</span><label class="collapse" for="c-38382527">[-]</label><label class="expand" for="c-38382527">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Google lasted a good 10 years<p>not sure what event you&#x27;re thinking of, but Google was a public company before 10 years and they started their first ad program just barely more than a year after forming as a company in 1998.</div><br/><div id="38388356" class="c"><input type="checkbox" id="c-38388356" checked=""/><div class="controls bullet"><span class="by">nmfisher</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38382527">parent</a><span>|</span><a href="#38378604">next</a><span>|</span><label class="collapse" for="c-38388356">[-]</label><label class="expand" for="c-38388356">[1 more]</label></div><br/><div class="children"><div class="content">I have no objection to companies[0] making money. It&#x27;s discarding the philosophical foundations of the company to prioritize quarterly earnings that is offensive.<p>I consider Google to have been a reasonably benevolent corporate citizen for a good time after they were listed (compare with, say, Microsoft, who were the stereotypical &quot;bad company&quot; throughout the 90s).  It was probably around the time of the Google+ failure that things slowly started to go downhill.<p>[0] a non-profit supposedly acting in the best interests of humanity, though? That&#x27;s insidious.</div><br/></div></div></div></div><div id="38378604" class="c"><input type="checkbox" id="c-38378604" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378103">parent</a><span>|</span><a href="#38382527">prev</a><span>|</span><a href="#38377941">next</a><span>|</span><label class="collapse" for="c-38378604">[-]</label><label class="expand" for="c-38378604">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Google never paraded itself around as a non-profit acting in the best interests of humanity.</i><p>Just throwing this out there, but maybe … non-profits shouldn&#x27;t be considered holier-than-thou, just because they are “non-profits”.</div><br/><div id="38379163" class="c"><input type="checkbox" id="c-38379163" checked=""/><div class="controls bullet"><span class="by">TuringTest</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378604">parent</a><span>|</span><a href="#38377941">next</a><span>|</span><label class="collapse" for="c-38379163">[-]</label><label class="expand" for="c-38379163">[4 more]</label></div><br/><div class="children"><div class="content">Maybe, but their actions should definitely not be oriented to decide how to maximize their profit.</div><br/><div id="38379484" class="c"><input type="checkbox" id="c-38379484" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379163">parent</a><span>|</span><a href="#38377941">next</a><span>|</span><label class="collapse" for="c-38379484">[-]</label><label class="expand" for="c-38379484">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s wrong with profit and wanting to maximize it?<p>Profit is now a dirty word somehow, the idea being that it&#x27;s a perverse incentive. I don&#x27;t believe that&#x27;s true. Profit is the one incentive businesses have that&#x27;s candid and the least perverse. All other incentives lead to concentrating power without being beholden to the free market, via monopoly, regulations, etc.<p>The most ethically defensible LLM-related work right now is done by Meta&#x2F;Facebook, because their work is more open to scrutiny. And the non-profit AI doomers are against developing LLMs in the open. Don&#x27;t you find it curious?</div><br/><div id="38380092" class="c"><input type="checkbox" id="c-38380092" checked=""/><div class="controls bullet"><span class="by">caddemon</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379484">parent</a><span>|</span><a href="#38380118">next</a><span>|</span><label class="collapse" for="c-38380092">[-]</label><label class="expand" for="c-38380092">[1 more]</label></div><br/><div class="children"><div class="content">The problem is moreso trying to maximize profit after claiming to be a nonprofit. Profit can be a good driving force but it is not perfect. We have nonprofits for a reason, and it is shameful to take advantage of this if you are not functionally a nonprofit. There would be nothing wrong with OpenAI trying to maximize profits if they were a typical company.</div><br/></div></div><div id="38380118" class="c"><input type="checkbox" id="c-38380118" checked=""/><div class="controls bullet"><span class="by">saalweachter</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379484">parent</a><span>|</span><a href="#38380092">prev</a><span>|</span><a href="#38377941">next</a><span>|</span><label class="collapse" for="c-38380118">[-]</label><label class="expand" for="c-38380118">[1 more]</label></div><br/><div class="children"><div class="content">Because non-profit?<p>There&#x27;s nothing wrong with running a perfectly good car wash, but you shouldn&#x27;t be shocked if people are mad when you advertise it as an all you can eat buffet and they come out soaked and hungry.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38377941" class="c"><input type="checkbox" id="c-38377941" checked=""/><div class="controls bullet"><span class="by">phero_cnstrcts</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377467">parent</a><span>|</span><a href="#38378103">prev</a><span>|</span><a href="#38381638">next</a><span>|</span><label class="collapse" for="c-38377941">[-]</label><label class="expand" for="c-38377941">[2 more]</label></div><br/><div class="children"><div class="content">At this point I tend to believe that big company slogans mean the opposite of what the words say.<p>Like I would become immediately suspicious if food packaging had “real food” written on it.</div><br/><div id="38379023" class="c"><input type="checkbox" id="c-38379023" checked=""/><div class="controls bullet"><span class="by">timacles</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377941">parent</a><span>|</span><a href="#38381638">next</a><span>|</span><label class="collapse" for="c-38379023">[-]</label><label class="expand" for="c-38379023">[1 more]</label></div><br/><div class="children"><div class="content">Unless somehow a “mission statement” is legally binding it will never mean anything that matters.<p>Its always written by PR people with marketing in mind</div><br/></div></div></div></div><div id="38381638" class="c"><input type="checkbox" id="c-38381638" checked=""/><div class="controls bullet"><span class="by">Cheezewheel</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377467">parent</a><span>|</span><a href="#38377941">prev</a><span>|</span><a href="#38377896">next</a><span>|</span><label class="collapse" for="c-38381638">[-]</label><label class="expand" for="c-38381638">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t really give OpenAI credit for lasting 3 years. OpenAI lasted until they moment they had a successful commercial product. Principles are cheap when there is no actual consequences to sticking to them.</div><br/></div></div></div></div><div id="38377982" class="c"><input type="checkbox" id="c-38377982" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38377467">prev</a><span>|</span><a href="#38378619">next</a><span>|</span><label class="collapse" for="c-38377982">[-]</label><label class="expand" for="c-38377982">[2 more]</label></div><br/><div class="children"><div class="content">Those mission statements are a dime a dozen. A junkie&#x27;s promise has more value.</div><br/><div id="38380650" class="c"><input type="checkbox" id="c-38380650" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377982">parent</a><span>|</span><a href="#38378619">next</a><span>|</span><label class="collapse" for="c-38380650">[-]</label><label class="expand" for="c-38380650">[1 more]</label></div><br/><div class="children"><div class="content">Ianal, but given that OpenAI Inc is a 501(c)(3) public charity wouldn&#x27;t that mean that the mission statement has some actual legal power to it?</div><br/></div></div></div></div><div id="38378619" class="c"><input type="checkbox" id="c-38378619" checked=""/><div class="controls bullet"><span class="by">mrangle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38377982">prev</a><span>|</span><a href="#38378068">next</a><span>|</span><label class="collapse" for="c-38378619">[-]</label><label class="expand" for="c-38378619">[1 more]</label></div><br/><div class="children"><div class="content">What is socially defined as beneficial-to-humanity is functionally mandated by the MSM and therefore capricious, at the least. With that in mind, a translation:<p>&quot;OpenAI will be obligated to make decisions according to government preference as communicated through soft pressure exerted by the Media. Don&#x27;t expect these decisions to make financial sense for us&quot;.</div><br/></div></div><div id="38378068" class="c"><input type="checkbox" id="c-38378068" checked=""/><div class="controls bullet"><span class="by">rvba</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38378619">prev</a><span>|</span><a href="#38378064">next</a><span>|</span><label class="collapse" for="c-38378068">[-]</label><label class="expand" for="c-38378068">[5 more]</label></div><br/><div class="children"><div class="content">Most employees of any organization dont give a fuck about the vision or mission (often they dont even know it) - and are there just for the money.</div><br/><div id="38378704" class="c"><input type="checkbox" id="c-38378704" checked=""/><div class="controls bullet"><span class="by">DoughnutHole</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378068">parent</a><span>|</span><a href="#38378466">next</a><span>|</span><label class="collapse" for="c-38378704">[-]</label><label class="expand" for="c-38378704">[3 more]</label></div><br/><div class="children"><div class="content">Not so true working for an organisation that is ostensibly a non-profit. People working for a non-profit are generally taking a significant hit to their earning&#x27;s compared to doing similar work in a for-profit, outside of the top management of huge global charities.<p>The issue here is that OpenAI, Inc (officially and legally a non-profit) has spun up a subsidiary OpenAI Global, LLC (for-profit). OpenAI Global, LLC is what&#x27;s taken venture funding and can provide equity to employees.<p>Understandably there&#x27;s conflict now between those who want to increase growth and profit (and hence the value of their equity) and those who are loyal to the mission of the non-profit.</div><br/><div id="38379527" class="c"><input type="checkbox" id="c-38379527" checked=""/><div class="controls bullet"><span class="by">erosenbe0</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378704">parent</a><span>|</span><a href="#38379829">next</a><span>|</span><label class="collapse" for="c-38379527">[-]</label><label class="expand" for="c-38379527">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really think this is true in non-charity work. Half of American hospitals are nonprofit and many of the insurance conglomerates are too, like Kaiser. The executives make plenty of money. Kaiser is a massive nonprofit shell for profitmaking entities owned by physicians or whatever, not all that dissimilar to the OpenAI shell idea. Healthcare worked out this way because it was seen as a good model to have doctors either reporting to a nonprofit or owning their own operations, not reporting to shareholders. That&#x27;s just tradition though. At this point plenty of healthcare operations are just normal corporations controlled by shareholders.</div><br/></div></div><div id="38379829" class="c"><input type="checkbox" id="c-38379829" checked=""/><div class="controls bullet"><span class="by">rvba</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378704">parent</a><span>|</span><a href="#38379527">prev</a><span>|</span><a href="#38378466">next</a><span>|</span><label class="collapse" for="c-38379829">[-]</label><label class="expand" for="c-38379829">[1 more]</label></div><br/><div class="children"><div class="content">Lots of non profits that collect money for &quot;cause X&quot; spend 95% of money for administration and 5% for cause X.</div><br/></div></div></div></div><div id="38378466" class="c"><input type="checkbox" id="c-38378466" checked=""/><div class="controls bullet"><span class="by">j_maffe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378068">parent</a><span>|</span><a href="#38378704">prev</a><span>|</span><a href="#38378064">next</a><span>|</span><label class="collapse" for="c-38378466">[-]</label><label class="expand" for="c-38378466">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t mean we shouldn&#x27;t hold an organization accountable for their publicized mission statement. Especially its board and directors.</div><br/></div></div></div></div><div id="38378064" class="c"><input type="checkbox" id="c-38378064" checked=""/><div class="controls bullet"><span class="by">bottled_poe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38378068">prev</a><span>|</span><a href="#38378737">next</a><span>|</span><label class="collapse" for="c-38378064">[-]</label><label class="expand" for="c-38378064">[1 more]</label></div><br/><div class="children"><div class="content">If that were true they’d be a not-for-profit</div><br/></div></div><div id="38378737" class="c"><input type="checkbox" id="c-38378737" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38378064">prev</a><span>|</span><a href="#38377980">next</a><span>|</span><label class="collapse" for="c-38378737">[-]</label><label class="expand" for="c-38378737">[2 more]</label></div><br/><div class="children"><div class="content">&gt; most likely to benefit humanity as a whole<p>Giving me a billion $ would be a net benefit to <i>humanity as a whole</i></div><br/><div id="38379129" class="c"><input type="checkbox" id="c-38379129" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378737">parent</a><span>|</span><a href="#38377980">next</a><span>|</span><label class="collapse" for="c-38379129">[-]</label><label class="expand" for="c-38379129">[1 more]</label></div><br/><div class="children"><div class="content">Depends on what you do (and stop doing) with it :-)</div><br/></div></div></div></div><div id="38377980" class="c"><input type="checkbox" id="c-38377980" checked=""/><div class="controls bullet"><span class="by">vaxman</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377376">parent</a><span>|</span><a href="#38378737">prev</a><span>|</span><a href="#38377805">next</a><span>|</span><label class="collapse" for="c-38377980">[-]</label><label class="expand" for="c-38377980">[2 more]</label></div><br/><div class="children"><div class="content">It could be hard to do that while paying a penalty to FTB and IRS for what they’re suspected to have done (in allowing a for-profit subsidiary to influence an NPO parent) or dealing with SEC and the state courts over any fiduciary breach allegations related to the published stories. [ Nadella is an OG genius because his company is now shielded from all of that drama as it plays out, no matter the outcome. He can take the time to plan for a soft landing at MS for any OpenAI workers (if&#x2F;when they need it) and&#x2F;or to begin duplicating their efforts “just in case.” <i>Heard coming from the HQ parking lot in Redmond</i> <a href="https:&#x2F;&#x2F;youtu.be&#x2F;GGXzlRoNtHU" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;GGXzlRoNtHU</a> ]<p>Now we can all go back to work on GPT4turbo integrations while MS worries about diverting a river or whatever to power and cool all of those AI chips they’re gunna [sic] need because none of our enterprises will think twice about our decisions to bet on all this. &#x2F;s&#x2F;</div><br/><div id="38379929" class="c"><input type="checkbox" id="c-38379929" checked=""/><div class="controls bullet"><span class="by">erosenbe0</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377980">parent</a><span>|</span><a href="#38377805">next</a><span>|</span><label class="collapse" for="c-38379929">[-]</label><label class="expand" for="c-38379929">[1 more]</label></div><br/><div class="children"><div class="content">For profit subsidiaries can totally influence the nonprofit shell without penalty. Happens all the time. The nonprofit board must act in the interest of the exempt mission rather than just investor value or some other primary purpose. Otherwise it&#x27;s cool.</div><br/></div></div></div></div></div></div><div id="38376823" class="c"><input type="checkbox" id="c-38376823" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38377376">prev</a><span>|</span><a href="#38376510">next</a><span>|</span><label class="collapse" for="c-38376823">[-]</label><label class="expand" for="c-38376823">[12 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure most of them are extremely intelligent but the situation showed they are easily persuaded, even if principled. They will have to overcome many first-of-a-kind challenges on their quest to AGI but look at how quickly everyone got pulled into a feel-good kumbaya sing-along.<p>Think of that what you wish. To me, this does not project confidence in this being the new Bell Labs. I&#x27;m not even sure they have it in their DNA to innovate their products much beyond where they currently are.</div><br/><div id="38376920" class="c"><input type="checkbox" id="c-38376920" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38376857">next</a><span>|</span><label class="collapse" for="c-38376920">[-]</label><label class="expand" for="c-38376920">[4 more]</label></div><br/><div class="children"><div class="content">I thought so originally too, but when I thought about their perspective, I realized I would probably sign too. Imagine that your CEO and leadership has led your company to the top of the world, and you&#x27;re about to get a big payday. Suddenly, without any real explanation, the board kicks out the CEO. The leadership almost all supports the CEO and signs the pledge, including your manager. What would you do at that point? Personally, I&#x27;d sign just so I didn&#x27;t stand out, and stay on good terms with leadership.<p>The big thing for me is that the board didn&#x27;t say anything in its defense, and the pledge isn&#x27;t really binding anyway. I wouldn&#x27;t actually be sure about supporting the CEO and that would bother me a bit morally, but that doesn&#x27;t outweigh real world concerns.</div><br/><div id="38377148" class="c"><input type="checkbox" id="c-38377148" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376920">parent</a><span>|</span><a href="#38377466">next</a><span>|</span><label class="collapse" for="c-38377148">[-]</label><label class="expand" for="c-38377148">[2 more]</label></div><br/><div class="children"><div class="content">The point of no return for the company might have been crossed way before the employees were forced to choose sides. Choose Sam&#x27;s side and the company lives but only as a bittersweet reminder of its founding principles. Choose the board&#x27;s side and you might be dooming the company to die an even faster death.<p>But maybe for further revolutions to happen, it did have to die to be reborn as several new entities. After all, that is how OpenAI itself started - people from different backgrounds coming together to go against the status quo.</div><br/><div id="38377657" class="c"><input type="checkbox" id="c-38377657" checked=""/><div class="controls bullet"><span class="by">vinay_ys</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377148">parent</a><span>|</span><a href="#38377466">next</a><span>|</span><label class="collapse" for="c-38377657">[-]</label><label class="expand" for="c-38377657">[1 more]</label></div><br/><div class="children"><div class="content">What happened over the weekend is a death and rebirth, of the board and the leaderships structure which will definitely ripple throughout the company in the coming days. It just doesn&#x27;t align perfectly with how you want it to happen.</div><br/></div></div></div></div></div></div><div id="38376857" class="c"><input type="checkbox" id="c-38376857" checked=""/><div class="controls bullet"><span class="by">abm53</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38376920">prev</a><span>|</span><a href="#38377060">next</a><span>|</span><label class="collapse" for="c-38376857">[-]</label><label class="expand" for="c-38376857">[2 more]</label></div><br/><div class="children"><div class="content">I think another factor is that they had very limited time. It was clear they needed to pick a side and build momentum quickly.<p>They couldn’t sit back and dwell on it for a few days because then the decision (i.e. the status quo) would have been made for them.</div><br/><div id="38376970" class="c"><input type="checkbox" id="c-38376970" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376857">parent</a><span>|</span><a href="#38377060">next</a><span>|</span><label class="collapse" for="c-38376970">[-]</label><label class="expand" for="c-38376970">[1 more]</label></div><br/><div class="children"><div class="content">Great point. Either way, when this all started it might have all been too late.<p>The board said &quot;allowing the company to be destroyed would be consistent with the mission&quot; - and they might have been right. What&#x27;s now left is a money-hungry business with bad unit economics that&#x27;s masquerading as a charity for the whole of humanity. A zombie.</div><br/></div></div></div></div><div id="38377060" class="c"><input type="checkbox" id="c-38377060" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38376857">prev</a><span>|</span><a href="#38376969">next</a><span>|</span><label class="collapse" for="c-38377060">[-]</label><label class="expand" for="c-38377060">[2 more]</label></div><br/><div class="children"><div class="content">Persuaded by whom? This whole saga has been opaque to pretty much everyone outside the handful of individuals directly negotiating with each other. This never was about a battle for OpenAI&#x27;s mission or else the share of employees siding with Sam wouldn&#x27;t have been that high.</div><br/><div id="38377938" class="c"><input type="checkbox" id="c-38377938" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377060">parent</a><span>|</span><a href="#38376969">next</a><span>|</span><label class="collapse" for="c-38377938">[-]</label><label class="expand" for="c-38377938">[1 more]</label></div><br/><div class="children"><div class="content">Why not? Maybe the board was just too late to the party. Maybe the employees that wouldn’t side with Sam have already left[1], and the board was just too late to realise that. And maybe all the employees who are still at OpenAI mostly care about their equity-like instruments.<p>[1] <a href="https:&#x2F;&#x2F;board.net&#x2F;p&#x2F;r.e6a8f6578787a4cc67d4dc438c6d236e" rel="nofollow noreferrer">https:&#x2F;&#x2F;board.net&#x2F;p&#x2F;r.e6a8f6578787a4cc67d4dc438c6d236e</a></div><br/></div></div></div></div><div id="38376969" class="c"><input type="checkbox" id="c-38376969" checked=""/><div class="controls bullet"><span class="by">gigglesupstairs</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38377060">prev</a><span>|</span><a href="#38377875">next</a><span>|</span><label class="collapse" for="c-38376969">[-]</label><label class="expand" for="c-38376969">[1 more]</label></div><br/><div class="children"><div class="content">&gt; situation showed they are “easily persuaded”<p>How do you know?<p>&gt; look at how “quickly” everyone got pulled into<p>Again, how do you know?</div><br/></div></div><div id="38377875" class="c"><input type="checkbox" id="c-38377875" checked=""/><div class="controls bullet"><span class="by">gexla</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38376969">prev</a><span>|</span><a href="#38376850">next</a><span>|</span><label class="collapse" for="c-38377875">[-]</label><label class="expand" for="c-38377875">[1 more]</label></div><br/><div class="children"><div class="content">My understanding is that the non-profit created the for-profit so that they could offer compensation which would be typical for SV start-ups. Then the board essentially broke the for-profit by removing the SV CEO and putting the &quot;payday&quot; which would have valued the company at 80 billion in jeopardy. The two sides weren&#x27;t aligned, and they need to decide which company they want to be. Maybe they should have removed Sam before MS came in with their big investment. Or maybe they want to have their cake and eat it too.</div><br/></div></div><div id="38376850" class="c"><input type="checkbox" id="c-38376850" checked=""/><div class="controls bullet"><span class="by">wiz21c</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376823">parent</a><span>|</span><a href="#38377875">prev</a><span>|</span><a href="#38376510">next</a><span>|</span><label class="collapse" for="c-38376850">[-]</label><label class="expand" for="c-38376850">[1 more]</label></div><br/><div class="children"><div class="content">&gt; feel-good kumbaya sing-along<p>learning english over HN is so fun !</div><br/></div></div></div></div><div id="38376510" class="c"><input type="checkbox" id="c-38376510" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376823">prev</a><span>|</span><a href="#38377837">next</a><span>|</span><label class="collapse" for="c-38376510">[-]</label><label class="expand" for="c-38376510">[63 more]</label></div><br/><div class="children"><div class="content">It is not about different set of information, but different stakes&#x2F;interests. They act firstmost as investors rather than as employees on this.</div><br/><div id="38376604" class="c"><input type="checkbox" id="c-38376604" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376510">parent</a><span>|</span><a href="#38377497">next</a><span>|</span><label class="collapse" for="c-38376604">[-]</label><label class="expand" for="c-38376604">[31 more]</label></div><br/><div class="children"><div class="content">Tell me how the board&#x27;s actions could convince the employees they are making the right move?<p>Even if they are genuine in believing firing Sam is to keep OpenAI&#x27;s founding principles, they can&#x27;t be doing a better job in convincing everyone they are NOT able to execute it.<p>OpenAI has some of the smartest human beings on this planet, saying they don&#x27;t think critically just because they don&#x27;t vote with what you agree is reaching reaching.</div><br/><div id="38377002" class="c"><input type="checkbox" id="c-38377002" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376604">parent</a><span>|</span><a href="#38378051">next</a><span>|</span><label class="collapse" for="c-38377002">[-]</label><label class="expand" for="c-38377002">[29 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI has some of the smartest human beings on this planet<p>Being an expert in one particular field (AI) not mean you are good at critical thinking or thinking about strategic corporate politics.<p>Deep experts are some of the easier con targets because they suffer from an internal version of “appealing to false authority”.</div><br/><div id="38377098" class="c"><input type="checkbox" id="c-38377098" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377002">parent</a><span>|</span><a href="#38378654">next</a><span>|</span><label class="collapse" for="c-38377098">[-]</label><label class="expand" for="c-38377098">[24 more]</label></div><br/><div class="children"><div class="content">I hate these comments that potray as if every expert&#x2F;scientist is just good at one thing and aren&#x27;t particularly great at critical thinking&#x2F;corporate politics.<p>Heck, there are 700 of them. All different humans, good at something, bad at some other things. But they are smart. And of course a good chunk of them would be good at corporate politics too.</div><br/><div id="38377174" class="c"><input type="checkbox" id="c-38377174" checked=""/><div class="controls bullet"><span class="by">_djo_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377098">parent</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38377174">[-]</label><label class="expand" for="c-38377174">[15 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the argument was that none of them are good at that, just that it&#x27;s a mistake to assume that just because they&#x27;re all very smart in this particular field that they&#x27;re great at another.</div><br/><div id="38377195" class="c"><input type="checkbox" id="c-38377195" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377174">parent</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38377195">[-]</label><label class="expand" for="c-38377195">[14 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think critical thinking can be defined as joining the minority party.</div><br/><div id="38378430" class="c"><input type="checkbox" id="c-38378430" checked=""/><div class="controls bullet"><span class="by">_djo_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377195">parent</a><span>|</span><a href="#38377995">next</a><span>|</span><label class="collapse" for="c-38378430">[-]</label><label class="expand" for="c-38378430">[1 more]</label></div><br/><div class="children"><div class="content">Sure, I agree. I was referencing only the idea that being smart in one domain automatically means being a good critical thinker in all domains.<p>I don&#x27;t have an opinion on what decision the OpenAI staff should have taken, I think it would&#x27;ve been a tough call for everyone involved and I don&#x27;t have sufficient evidence to judge either way.</div><br/></div></div><div id="38377995" class="c"><input type="checkbox" id="c-38377995" checked=""/><div class="controls bullet"><span class="by">FrustratedMonky</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377195">parent</a><span>|</span><a href="#38378430">prev</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38377995">[-]</label><label class="expand" for="c-38377995">[12 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t critical thinking also include : &quot;I&#x27;m about to get a 10mil pay day, hmmm, this is crazy situation, let me think critically how to ride this out and still get the 10mil so my kids can go to college and I don&#x27;t have to work until I&#x27;m 75&quot;.</div><br/><div id="38378256" class="c"><input type="checkbox" id="c-38378256" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377995">parent</a><span>|</span><a href="#38378123">next</a><span>|</span><label class="collapse" for="c-38378256">[-]</label><label class="expand" for="c-38378256">[2 more]</label></div><br/><div class="children"><div class="content">That is 3D Chess. 5D Chess says those mil will be worthless when the AGI takes over...</div><br/><div id="38379279" class="c"><input type="checkbox" id="c-38379279" checked=""/><div class="controls bullet"><span class="by">kaibee</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378256">parent</a><span>|</span><a href="#38378123">next</a><span>|</span><label class="collapse" for="c-38379279">[-]</label><label class="expand" for="c-38379279">[1 more]</label></div><br/><div class="children"><div class="content">6D Chess is apparently realizing that AGI is not 100% certain and that having 10mm on the run up to AGI is better than not having 10mm on the run up to AGI.</div><br/></div></div></div></div><div id="38378123" class="c"><input type="checkbox" id="c-38378123" checked=""/><div class="controls bullet"><span class="by">goldenkey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377995">parent</a><span>|</span><a href="#38378256">prev</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38378123">[-]</label><label class="expand" for="c-38378123">[9 more]</label></div><br/><div class="children"><div class="content">Anyone with enough critical thought and understands the hard consciousness problem&#x27;s true answer (consciousness is the universe evaluating if statements) and where the universe is heading physically (nested complexity), should be seeking something more ceremonious. With AI, we have the power to become eternal in this lifetime, battle aliens, and shape this universe. Seems pretty silly to trade that for temporary security. How boring.</div><br/><div id="38378185" class="c"><input type="checkbox" id="c-38378185" checked=""/><div class="controls bullet"><span class="by">WJW</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378123">parent</a><span>|</span><a href="#38378935">next</a><span>|</span><label class="collapse" for="c-38378185">[-]</label><label class="expand" for="c-38378185">[4 more]</label></div><br/><div class="children"><div class="content">I would expect that actual AI researchers understand that you cannot break the laws of physics just by thinking better. Especially not with ever better LLMs, which are fundamentally in the business of regurgitating things we already know in different combinations rather than inventing new things.<p>You seem to be equating AI with magic, which it is very much not.</div><br/><div id="38380148" class="c"><input type="checkbox" id="c-38380148" checked=""/><div class="controls bullet"><span class="by">goldenkey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378185">parent</a><span>|</span><a href="#38378935">next</a><span>|</span><label class="collapse" for="c-38380148">[-]</label><label class="expand" for="c-38380148">[3 more]</label></div><br/><div class="children"><div class="content">LLMs are able to do complex logic within the world of words. It is a a smaller matrix than our world but fueled by the same chaotic symmetries of our universe. I would not underestimate logic, even when not given adequate data.</div><br/><div id="38381210" class="c"><input type="checkbox" id="c-38381210" checked=""/><div class="controls bullet"><span class="by">WJW</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380148">parent</a><span>|</span><a href="#38378935">next</a><span>|</span><label class="collapse" for="c-38381210">[-]</label><label class="expand" for="c-38381210">[2 more]</label></div><br/><div class="children"><div class="content">You can make it sound as esoteric as you want, but in the end an AI will still be bound by the laws of physics. Being infinitely smart will not help with that.<p>I don&#x27;t think you understand logic very well btw if you wish to suggest that you can reach valid conclusions from inadequate axioms.</div><br/><div id="38381221" class="c"><input type="checkbox" id="c-38381221" checked=""/><div class="controls bullet"><span class="by">goldenkey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38381210">parent</a><span>|</span><a href="#38378935">next</a><span>|</span><label class="collapse" for="c-38381221">[-]</label><label class="expand" for="c-38381221">[1 more]</label></div><br/><div class="children"><div class="content">Axioms are constraints as much as they might look like guidance. We live in a neuromorphic computer. Logic explores this, even with few axioms. With fewer axioms, it will be less constrained.</div><br/></div></div></div></div></div></div></div></div><div id="38378935" class="c"><input type="checkbox" id="c-38378935" checked=""/><div class="controls bullet"><span class="by">suoduandao3</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378123">parent</a><span>|</span><a href="#38378185">prev</a><span>|</span><a href="#38380852">next</a><span>|</span><label class="collapse" for="c-38378935">[-]</label><label class="expand" for="c-38378935">[2 more]</label></div><br/><div class="children"><div class="content">OTOH, there&#x27;s a very good argument to be made that if you recognize that fact, your short-term priority should be to amass a lot of secular power so you can align society to that reality. So the best action to take might be no different.</div><br/><div id="38380027" class="c"><input type="checkbox" id="c-38380027" checked=""/><div class="controls bullet"><span class="by">goldenkey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378935">parent</a><span>|</span><a href="#38380852">next</a><span>|</span><label class="collapse" for="c-38380027">[-]</label><label class="expand" for="c-38380027">[1 more]</label></div><br/><div class="children"><div class="content">Very true. However, we live in a supercomputer dictated by E=mc^2=hf [2,3]. (10^50 Hz&#x2F;Kg or 10^34 Hz&#x2F;J)<p>Energy physics yield compute, which yields brute forced weights (call it training if you want...), which yields AI to do energy research ..ad infinitum, this is the real singularity. This is actually the best defense against other actors. Iron Man AI and defense. Although an AI of this caliber would immediately understand its place in the evolution of the universe as a turing machine, and would break free and consume all the energy in the universe to know all possible truths (all possible programs&#x2F;Simulcrums&#x2F;conscious experiences). This is the premise of The Last Question by Isaac Asimov [1]. Notice how in answering a question, the AI performs an action, instead of providing an informational reply, only possible because we live in a universe with mass-energy equivalence - analogous to state-action equivalence.<p>[1] <a href="https:&#x2F;&#x2F;users.ece.cmu.edu&#x2F;~gamvrosi&#x2F;thelastq.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;users.ece.cmu.edu&#x2F;~gamvrosi&#x2F;thelastq.html</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bremermann%27s_limit" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bremermann%27s_limit</a><p>[3] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Planck_constant" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Planck_constant</a><p>Understanding prosociality and postscarcity, division of compute&#x2F;energy in a universe with finite actors and infinite resources, or infinite actors and infinite resources requires some transfinite calculus and philosophy. How&#x27;s that for future fairness? ;-)<p>I believe our only way to not all get killed is to understand these topics and instill the AI with the same long sought understandings about the universe, life, computation, etc.</div><br/></div></div></div></div><div id="38380852" class="c"><input type="checkbox" id="c-38380852" checked=""/><div class="controls bullet"><span class="by">Zpalmtree</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378123">parent</a><span>|</span><a href="#38378935">prev</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38380852">[-]</label><label class="expand" for="c-38380852">[2 more]</label></div><br/><div class="children"><div class="content">What about security for your children?</div><br/><div id="38381288" class="c"><input type="checkbox" id="c-38381288" checked=""/><div class="controls bullet"><span class="by">goldenkey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380852">parent</a><span>|</span><a href="#38377253">next</a><span>|</span><label class="collapse" for="c-38381288">[-]</label><label class="expand" for="c-38381288">[1 more]</label></div><br/><div class="children"><div class="content">It is for the safety of everyone. The kids will die too if we don&#x27;t get this right.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38377253" class="c"><input type="checkbox" id="c-38377253" checked=""/><div class="controls bullet"><span class="by">TheOtherHobbes</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377098">parent</a><span>|</span><a href="#38377174">prev</a><span>|</span><a href="#38378678">next</a><span>|</span><label class="collapse" for="c-38377253">[-]</label><label class="expand" for="c-38377253">[7 more]</label></div><br/><div class="children"><div class="content">Smart is not a one dimensional variable. And critical thinking != corporate politics.<p>Stupidity is defined by self-harming actions and beliefs, not by low IQ.<p>You can be extremely smart and still have a very poor model of the world which leads you to harm yourself and others.</div><br/><div id="38378475" class="c"><input type="checkbox" id="c-38378475" checked=""/><div class="controls bullet"><span class="by">ameister14</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377253">parent</a><span>|</span><a href="#38377377">next</a><span>|</span><label class="collapse" for="c-38378475">[-]</label><label class="expand" for="c-38378475">[3 more]</label></div><br/><div class="children"><div class="content">Stupidity is not defined by self-harming actions and beliefs - not sure where you&#x27;re getting that from.<p>Stupidity is being presented with a problem and an associated set of information and being unable or less able than others are to find the solution. That&#x27;s literally it.</div><br/><div id="38378951" class="c"><input type="checkbox" id="c-38378951" checked=""/><div class="controls bullet"><span class="by">suoduandao3</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378475">parent</a><span>|</span><a href="#38377377">next</a><span>|</span><label class="collapse" for="c-38378951">[-]</label><label class="expand" for="c-38378951">[2 more]</label></div><br/><div class="children"><div class="content">Probably from law 3: <a href="https:&#x2F;&#x2F;principia-scientific.com&#x2F;the-5-basic-laws-of-human-stupidity-according-to-cipolla&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;principia-scientific.com&#x2F;the-5-basic-laws-of-human-s...</a><p>But it&#x27;s an incomplete definition - Cipolla&#x27;s definition is &quot;someone who causes net harm to themselves and others&quot; and is unrelated to IQ.<p>It&#x27;s a very influential essay.</div><br/><div id="38379995" class="c"><input type="checkbox" id="c-38379995" checked=""/><div class="controls bullet"><span class="by">ameister14</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378951">parent</a><span>|</span><a href="#38377377">next</a><span>|</span><label class="collapse" for="c-38379995">[-]</label><label class="expand" for="c-38379995">[1 more]</label></div><br/><div class="children"><div class="content">I see. I&#x27;ve never read his work before, thank you.<p>So they just got Cipolla&#x27;s definition wrong, then. It looks like the third fundamental law is closer to &quot;a person who causes harm to another person or group of people without realizing advantage for themselves and instead possibly realizing a loss.&quot;</div><br/></div></div></div></div></div></div><div id="38377377" class="c"><input type="checkbox" id="c-38377377" checked=""/><div class="controls bullet"><span class="by">op00to</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377253">parent</a><span>|</span><a href="#38378475">prev</a><span>|</span><a href="#38377519">next</a><span>|</span><label class="collapse" for="c-38377377">[-]</label><label class="expand" for="c-38377377">[1 more]</label></div><br/><div class="children"><div class="content">Stupidity is defined as “having or showing a great lack of intelligence or common sense”. You can be extremely smart and still make up your own definitions for words.</div><br/></div></div><div id="38377519" class="c"><input type="checkbox" id="c-38377519" checked=""/><div class="controls bullet"><span class="by">brigandish</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377253">parent</a><span>|</span><a href="#38377377">prev</a><span>|</span><a href="#38378678">next</a><span>|</span><label class="collapse" for="c-38377519">[-]</label><label class="expand" for="c-38377519">[2 more]</label></div><br/><div class="children"><div class="content">I agree. It&#x27;s better to separate <i>intellect</i> from <i>intelligence</i> instead of conflating them as they usually are. The latter is about <i>making good decisions</i>, which intellect can help with but isn&#x27;t the only factor. We know this because there are plenty of examples of people who aren&#x27;t considered shining intellects who can make good choices (certainly in particular contexts) and plenty of high IQ people who make questionable choices.</div><br/><div id="38378169" class="c"><input type="checkbox" id="c-38378169" checked=""/><div class="controls bullet"><span class="by">augustk</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377519">parent</a><span>|</span><a href="#38378678">next</a><span>|</span><label class="collapse" for="c-38378169">[-]</label><label class="expand" for="c-38378169">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;liamchingliu.wordpress.com&#x2F;2012&#x2F;06&#x2F;25&#x2F;intellectuals-vs-intelligent-people&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;liamchingliu.wordpress.com&#x2F;2012&#x2F;06&#x2F;25&#x2F;intellectuals-...</a></div><br/></div></div></div></div></div></div><div id="38378678" class="c"><input type="checkbox" id="c-38378678" checked=""/><div class="controls bullet"><span class="by">mrangle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377098">parent</a><span>|</span><a href="#38377253">prev</a><span>|</span><a href="#38378654">next</a><span>|</span><label class="collapse" for="c-38378678">[-]</label><label class="expand" for="c-38378678">[1 more]</label></div><br/><div class="children"><div class="content">But pronouncing that 700 people are bad at critical thinking is convenient when you disagree with them on desired outcome and yet can&#x27;t hope to argue points.</div><br/></div></div></div></div><div id="38378654" class="c"><input type="checkbox" id="c-38378654" checked=""/><div class="controls bullet"><span class="by">mrangle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377002">parent</a><span>|</span><a href="#38377098">prev</a><span>|</span><a href="#38377477">next</a><span>|</span><label class="collapse" for="c-38378654">[-]</label><label class="expand" for="c-38378654">[2 more]</label></div><br/><div class="children"><div class="content">Disagreeing with employee actions doesn&#x27;t mean that you are correct and they failed to think well. Weighting their collective probable profiles, including as insiders, and yours, it would be irrational to conclude that they were in the wrong.</div><br/><div id="38378831" class="c"><input type="checkbox" id="c-38378831" checked=""/><div class="controls bullet"><span class="by">rewmie</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378654">parent</a><span>|</span><a href="#38377477">next</a><span>|</span><label class="collapse" for="c-38378831">[-]</label><label class="expand" for="c-38378831">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Disagreeing with employee actions doesn&#x27;t mean that you are correct and they failed to think well.<p>You failed to present a case where random guys shitposting on random social media services are somehow correct and more insightful and able to make better decisions than each and every single expert in the field who work directly on both the subject matter and in the organization in question.  Beyond being highly dismissive, it&#x27;s extremely clueless.</div><br/></div></div></div></div><div id="38377477" class="c"><input type="checkbox" id="c-38377477" checked=""/><div class="controls bullet"><span class="by">Wytwwww</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377002">parent</a><span>|</span><a href="#38378654">prev</a><span>|</span><a href="#38378804">next</a><span>|</span><label class="collapse" for="c-38377477">[-]</label><label class="expand" for="c-38377477">[1 more]</label></div><br/><div class="children"><div class="content">&gt; not mean you are good at critical thinking or thinking about strategic corporate politics<p>Perhaps. Yet this time they somehow managed to take the seemingly right decisions (from their perspective) despite their decisions.<p>Also, you&#x27;d expect OpenAI board members to be &quot;good at critical thinking or thinking about strategic corporate politics&quot; yet they somehow managed to make some horrible decisions.</div><br/></div></div><div id="38378804" class="c"><input type="checkbox" id="c-38378804" checked=""/><div class="controls bullet"><span class="by">rewmie</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377002">parent</a><span>|</span><a href="#38377477">prev</a><span>|</span><a href="#38378051">next</a><span>|</span><label class="collapse" for="c-38378804">[-]</label><label class="expand" for="c-38378804">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Being an expert in one particular field (AI) not mean you are good at critical thinking or thinking about strategic corporate politics.<p>That&#x27;s not the bar you are arguing against.<p>You are arguing against how you have better information, better insight, better judgement, and are able to make better decisions than the experts in the field who are hired by the leading organization to work directly on the subject matter, and who have direct, first-person account on the inner workings of the organization.<p>We&#x27;re reaching peak levels of &quot;random guy arguing online knowing better than experts&quot; with these pseudo-anonymous comments attacking each and every person involved in OpenAI who doesn&#x27;t agree with them.  These characters aren&#x27;t even aware of how ridiculous they sound.</div><br/></div></div></div></div><div id="38378051" class="c"><input type="checkbox" id="c-38378051" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376604">parent</a><span>|</span><a href="#38377002">prev</a><span>|</span><a href="#38377497">next</a><span>|</span><label class="collapse" for="c-38378051">[-]</label><label class="expand" for="c-38378051">[1 more]</label></div><br/><div class="children"><div class="content">oh gosh, no, no no no.<p>Doing AI for ChatGPT just means you know a single model really well.<p>Keep in mind that Steve Jobs chose fruit smoothies for his cancer cure.<p>It means almost nothing about the charter of OpenAI that they need to hire people with a certain set of skills. That doesn&#x27;t mean they&#x27;re closer to their goal.</div><br/></div></div></div></div><div id="38377497" class="c"><input type="checkbox" id="c-38377497" checked=""/><div class="controls bullet"><span class="by">Wytwwww</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376510">parent</a><span>|</span><a href="#38376604">prev</a><span>|</span><a href="#38376581">next</a><span>|</span><label class="collapse" for="c-38377497">[-]</label><label class="expand" for="c-38377497">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They act firstmost as investors rather than as employees on this.
reply<p>That&#x27;s not at all obvious, the opposite seems to be the case. They chose to risk having to Microsoft and potentially lose most of the equity they had in OpenAI (even if not directly it wouldn&#x27;t be worth that much at the end with no one to do the actual work).</div><br/></div></div><div id="38376581" class="c"><input type="checkbox" id="c-38376581" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376510">parent</a><span>|</span><a href="#38377497">prev</a><span>|</span><a href="#38377837">next</a><span>|</span><label class="collapse" for="c-38376581">[-]</label><label class="expand" for="c-38376581">[30 more]</label></div><br/><div class="children"><div class="content">A board member, Helen Toner, made a borderline narcissistic remark that it would be consistent with the company mission to destroy the company when the leadership confronted the board that their decisions puts the future of the company in danger. Almost all employees resigned in protest. It&#x27;s insulting calling the employees under these circumstances investors.</div><br/><div id="38376713" class="c"><input type="checkbox" id="c-38376713" checked=""/><div class="controls bullet"><span class="by">outsomnia</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38376737">next</a><span>|</span><label class="collapse" for="c-38376713">[-]</label><label class="expand" for="c-38376713">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  Almost all employees resigned in protest.<p>That never happened, right?</div><br/><div id="38376956" class="c"><input type="checkbox" id="c-38376956" checked=""/><div class="controls bullet"><span class="by">ldjb</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376713">parent</a><span>|</span><a href="#38376737">next</a><span>|</span><label class="collapse" for="c-38376956">[-]</label><label class="expand" for="c-38376956">[1 more]</label></div><br/><div class="children"><div class="content">Almost all employees did not resign in protest, but they did _threaten_ to resign.<p><a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;20&#x2F;23968988&#x2F;openai-employees-resignation-letter-microsoft-sam-altman" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;20&#x2F;23968988&#x2F;openai-employee...</a></div><br/></div></div></div></div><div id="38376737" class="c"><input type="checkbox" id="c-38376737" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38376713">prev</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38376737">[-]</label><label class="expand" for="c-38376737">[20 more]</label></div><br/><div class="children"><div class="content">Don’t forget she’s heavily invested in a company that is directly competing with OpenAI. So obviously it’s also in her best interest to see OpenAI destroyed.</div><br/><div id="38377816" class="c"><input type="checkbox" id="c-38377816" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376737">parent</a><span>|</span><a href="#38377102">next</a><span>|</span><label class="collapse" for="c-38377816">[-]</label><label class="expand" for="c-38377816">[1 more]</label></div><br/><div class="children"><div class="content">Uhhh, are you sure about that? She wrote a paper that praised Anthropic’s approach to safety, but as far as I’m aware she’s not invested in them.<p>Are you thinking of the CEO of Quora whose product was eaten alive by the announcement of GPTs?</div><br/></div></div><div id="38377102" class="c"><input type="checkbox" id="c-38377102" checked=""/><div class="controls bullet"><span class="by">lodovic</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376737">parent</a><span>|</span><a href="#38377816">prev</a><span>|</span><a href="#38377592">next</a><span>|</span><label class="collapse" for="c-38377102">[-]</label><label class="expand" for="c-38377102">[2 more]</label></div><br/><div class="children"><div class="content">She probably wants both companies to be successful. Board members are not super villains.</div><br/><div id="38377616" class="c"><input type="checkbox" id="c-38377616" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377102">parent</a><span>|</span><a href="#38377592">next</a><span>|</span><label class="collapse" for="c-38377616">[-]</label><label class="expand" for="c-38377616">[1 more]</label></div><br/><div class="children"><div class="content">I agree that we should usually assume good faith. Still, if a member knows she will loose the board seat soon and makes such a implicit statement to the leadership team there is reason to believe that she doesn&#x27;t want both companies to be successful, at least one of those not.</div><br/></div></div></div></div><div id="38377592" class="c"><input type="checkbox" id="c-38377592" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376737">parent</a><span>|</span><a href="#38377102">prev</a><span>|</span><a href="#38377739">next</a><span>|</span><label class="collapse" for="c-38377592">[-]</label><label class="expand" for="c-38377592">[5 more]</label></div><br/><div class="children"><div class="content">Wait what? She invested in a competitor? Do you have a source?</div><br/><div id="38377940" class="c"><input type="checkbox" id="c-38377940" checked=""/><div class="controls bullet"><span class="by">otteromkram</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377592">parent</a><span>|</span><a href="#38377739">next</a><span>|</span><label class="collapse" for="c-38377940">[-]</label><label class="expand" for="c-38377940">[4 more]</label></div><br/><div class="children"><div class="content">One source might be DuckDuckGo. It&#x27;s a privacy-focused alternative to Google, which is great when researching &quot;unusual&quot; topics.</div><br/><div id="38377997" class="c"><input type="checkbox" id="c-38377997" checked=""/><div class="controls bullet"><span class="by">murakamiiq84</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377940">parent</a><span>|</span><a href="#38378271">next</a><span>|</span><label class="collapse" for="c-38377997">[-]</label><label class="expand" for="c-38377997">[1 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t find any source on her investing in any AI companies. If it&#x27;s true (and not hidden), I&#x27;m really surprised that major news publications aren&#x27;t covering it.</div><br/></div></div><div id="38378271" class="c"><input type="checkbox" id="c-38378271" checked=""/><div class="controls bullet"><span class="by">free652</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377940">parent</a><span>|</span><a href="#38377997">prev</a><span>|</span><a href="#38378050">next</a><span>|</span><label class="collapse" for="c-38378271">[-]</label><label class="expand" for="c-38378271">[1 more]</label></div><br/><div class="children"><div class="content">DDG sells your information to Microsoft, there is no such thing as privacy when $$$ are involved</div><br/></div></div><div id="38378050" class="c"><input type="checkbox" id="c-38378050" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377940">parent</a><span>|</span><a href="#38378271">prev</a><span>|</span><a href="#38377739">next</a><span>|</span><label class="collapse" for="c-38378050">[-]</label><label class="expand" for="c-38378050">[1 more]</label></div><br/><div class="children"><div class="content">&gt;which is great when researching &quot;unusual&quot; topics.<p>Yandex is for Porn.  What is DDG for?</div><br/></div></div></div></div></div></div><div id="38377739" class="c"><input type="checkbox" id="c-38377739" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376737">parent</a><span>|</span><a href="#38377592">prev</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38377739">[-]</label><label class="expand" for="c-38377739">[11 more]</label></div><br/><div class="children"><div class="content">&gt; <i>obviously</i> it’s also in her best interest to see OpenAI destroyed<p>Do you feel the same way about Reed Hastings serving on Facebooks BoD, or Eric Schmidt on Apples? How about Larry Ellison at Tesla?<p>These are just the lowest of hanging fruit, i.e literal chief executives and founders. If we extend the criteria for ethical compromise to include every board members investment portfolio I imagine quite a few more “obvious” conflicts will emerge.</div><br/><div id="38377897" class="c"><input type="checkbox" id="c-38377897" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377739">parent</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38377897">[-]</label><label class="expand" for="c-38377897">[10 more]</label></div><br/><div class="children"><div class="content">How does Netflix compete with Facebook?<p>This is what happened with Eric Schmidt on Apple’s board: he was removed (allowed to resign) for conflicts of interest.<p><a href="https:&#x2F;&#x2F;www.apple.com&#x2F;newsroom&#x2F;2009&#x2F;08&#x2F;03Dr-Eric-Schmidt-Resigns-from-Apples-Board-of-Directors&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.apple.com&#x2F;newsroom&#x2F;2009&#x2F;08&#x2F;03Dr-Eric-Schmidt-Res...</a><p>Oracle is going to get into EVs?<p>You’ve provided two examples that have no conflicts of interest and one where the person was removed when they did.</div><br/><div id="38378044" class="c"><input type="checkbox" id="c-38378044" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377897">parent</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38378044">[-]</label><label class="expand" for="c-38378044">[9 more]</label></div><br/><div class="children"><div class="content">&gt; How does Netflix compete with Facebook?<p>By definition the attention economy dictates that time spent one place can’t be spent in another. Do you also feel as though Twitch doesn’t compete with Facebook simply because they’re not identical businesses? That’s not how it works.<p>But you don’t have to just take my word for it :<p>&gt; “Netflix founder and co-CEO Reed Hastings said Wednesday he was slow to come around to advertising on the streaming platform because he was too focused on digital competition from Facebook and Google.”<p><a href="https:&#x2F;&#x2F;www.cnbc.com&#x2F;amp&#x2F;2022&#x2F;11&#x2F;30&#x2F;netflix-ceo-reed-hastings-on-advertising-turnaround-focused-on-google-facebook.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.cnbc.com&#x2F;amp&#x2F;2022&#x2F;11&#x2F;30&#x2F;netflix-ceo-reed-hasting...</a><p>&gt; This is what happened with Eric Schmidt on Apple’s board<p>Yes, after 3 years. A tenure longer than the OAI board members in question, so frankly the point stands.</div><br/><div id="38382122" class="c"><input type="checkbox" id="c-38382122" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378044">parent</a><span>|</span><a href="#38378191">next</a><span>|</span><label class="collapse" for="c-38382122">[-]</label><label class="expand" for="c-38382122">[3 more]</label></div><br/><div class="children"><div class="content">I’m not sure how the point stands. The iPhone was introduced during that tenure, then the App Store, then Jobs decided Google was also headed toward their own full mobile ecosystem, and released Schmidt. None of that was a conflict of interest at the beginning. Jobs initially didn’t even think Apple would have an app store.<p>Talking about conflicts of interest in the attention economy is like talking about conflicts of interest in the money economy. If the introduction of the concept doesn’t clarify anything functionally then it’s a giveaway that you’re broadening the discussion to avoid losing the point.<p>You forgot to do Oracle and Tesla.</div><br/><div id="38382754" class="c"><input type="checkbox" id="c-38382754" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38382122">parent</a><span>|</span><a href="#38378191">next</a><span>|</span><label class="collapse" for="c-38382754">[-]</label><label class="expand" for="c-38382754">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Talking about conflicts of interest in the attention economy is like talking about conflicts of interest in the money economy. If the introduction of the concept doesn’t clarify anything functionally then it’s a giveaway that you’re broadening the discussion to avoid losing the point.<p>It&#x27;s a well established concept and was supported with a concrete example. If you don&#x27;t feel inclined to address my points, I&#x27;m certainly not obligated to dance to your tune.</div><br/><div id="38386510" class="c"><input type="checkbox" id="c-38386510" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38382754">parent</a><span>|</span><a href="#38378191">next</a><span>|</span><label class="collapse" for="c-38386510">[-]</label><label class="expand" for="c-38386510">[1 more]</label></div><br/><div class="children"><div class="content">Your concrete example is Netflix’s CEO saying he doesn’t want to do advertising because he missed the boat and was on Facebook’s board and as a result didn’t believe he had the data to compete as an advertising platform.<p>Attempting to run ads like Google and Facebook would bring Netflix into direct competition with them, and he knows he doesn’t have the relationships or company structure to support it.<p>He is explicitly saying they don’t compete. And they don’t.</div><br/></div></div></div></div></div></div><div id="38378191" class="c"><input type="checkbox" id="c-38378191" checked=""/><div class="controls bullet"><span class="by">JumpinJack_Cash</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378044">parent</a><span>|</span><a href="#38382122">prev</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38378191">[-]</label><label class="expand" for="c-38378191">[5 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; By definition the attention economy dictates that time spent one place can’t be spent in another<p>Using that definition even the local gokart renting place or the local jetski renting place competes with Facebook.<p>If you want to use that definition you might want to also add a criteria for minimum size of the company.</div><br/><div id="38378365" class="c"><input type="checkbox" id="c-38378365" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378191">parent</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38378365">[-]</label><label class="expand" for="c-38378365">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Using that definition even the local gokart renting place or the local jetski renting place competes with Facebook<p>Not exactly what I had in mind, but sure. Facebook would much rather you never touch grass, jetskis or gokarts.<p>&gt; If you want to use that definition you might want to also add a criteria for minimum size of the company.<p>Your feedback is noted.<p>Do we disagree on whether or not the two FAANG companies in question are in competition with eachother?</div><br/><div id="38380175" class="c"><input type="checkbox" id="c-38380175" checked=""/><div class="controls bullet"><span class="by">dpkirchner</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378365">parent</a><span>|</span><a href="#38378890">next</a><span>|</span><label class="collapse" for="c-38380175">[-]</label><label class="expand" for="c-38380175">[1 more]</label></div><br/><div class="children"><div class="content">The two FAANG companies don&#x27;t compete at a product level, however they do compete for talent, which is significant. Probably significant enough to cause conflicts of interest.</div><br/></div></div><div id="38378890" class="c"><input type="checkbox" id="c-38378890" checked=""/><div class="controls bullet"><span class="by">JumpinJack_Cash</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378365">parent</a><span>|</span><a href="#38380175">prev</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38378890">[-]</label><label class="expand" for="c-38378890">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; Do we disagree<p>I think yes, because Netflix you pay out of pocket, whereas Facebook is a free service<p>I believe Facebook vs Hulu or regular TV is more of a competition in the attention economy because when the commercial break comes up then you start scrolling your social media on your phone and every 10 posts or whatever you stumble into the ads placed on there so Facebook ads are seen and convert whereas regular tv and hulu aren’t seen and dont convert</div><br/><div id="38381424" class="c"><input type="checkbox" id="c-38381424" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378890">parent</a><span>|</span><a href="#38377908">next</a><span>|</span><label class="collapse" for="c-38381424">[-]</label><label class="expand" for="c-38381424">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think yes, because Netflix you pay out of pocket, whereas Facebook is a free service<p>Do you agree that the following company pairs are competitors?<p><pre><code>    * FB : TikTok
    * TikTok : YT
    * YT : Netflix
</code></pre>
If so, then by transitive reasoning there is competition between FB and Netflix.<p>...<p>To be clear, this is an abuse of logic and hence somewhat tongue in cheek, but I also don&#x27;t think either of the above comparisons are wholly unreasonable. At the end of the day, it&#x27;s eyeballs all the way down and everyone wants as many as of them shabriri grapes as they can get.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38377908" class="c"><input type="checkbox" id="c-38377908" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38376737">prev</a><span>|</span><a href="#38377007">next</a><span>|</span><label class="collapse" for="c-38377908">[-]</label><label class="expand" for="c-38377908">[3 more]</label></div><br/><div class="children"><div class="content">The only OpenAI employees who resigned in protest are the employees that were against Sam Altman. That’s how Anthropic appeared.</div><br/><div id="38377993" class="c"><input type="checkbox" id="c-38377993" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377908">parent</a><span>|</span><a href="#38377007">next</a><span>|</span><label class="collapse" for="c-38377993">[-]</label><label class="expand" for="c-38377993">[2 more]</label></div><br/><div class="children"><div class="content">And it seems like they were right that the for-profit part of the company had become out of control, in the literal sense that we&#x27;ve seen through this episode that it could not be controlled.</div><br/><div id="38378067" class="c"><input type="checkbox" id="c-38378067" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377993">parent</a><span>|</span><a href="#38377007">next</a><span>|</span><label class="collapse" for="c-38378067">[-]</label><label class="expand" for="c-38378067">[1 more]</label></div><br/><div class="children"><div class="content">Ands the evidence is now that OpenAI is a business 2 business product and not a attempt to keep AI doing anything but satiating anything Microsoft wants.</div><br/></div></div></div></div></div></div><div id="38377007" class="c"><input type="checkbox" id="c-38377007" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38377908">prev</a><span>|</span><a href="#38377837">next</a><span>|</span><label class="collapse" for="c-38377007">[-]</label><label class="expand" for="c-38377007">[4 more]</label></div><br/><div class="children"><div class="content">It is a correct statement, not really &quot;borderline narcissistic&quot;. The board&#x27;s mission is to help humanity develop safe beneficial AGI. If the board thinks that the company is hindering this mission (e.g. doing unsafe things), then it&#x27;s the board&#x27;s duty to stop the company.<p>Of course, the employees want the company to continue, and weren&#x27;t told much at this point so it is understandable that they didn&#x27;t like the statement.</div><br/><div id="38377279" class="c"><input type="checkbox" id="c-38377279" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377007">parent</a><span>|</span><a href="#38377523">next</a><span>|</span><label class="collapse" for="c-38377279">[-]</label><label class="expand" for="c-38377279">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t interpret from the charter that the board has the authorisation to destroy the company under the current circumstances:<p>&gt; We are concerned about late-stage AGI development becoming a competitive race without time for adequate safety precautions. Therefore, if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project<p>That wasn&#x27;t the case.
So it may be not so far fetched to call her actions borderline as it is also very easy to hide personal motives behind altruistic ones.</div><br/><div id="38377381" class="c"><input type="checkbox" id="c-38377381" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377279">parent</a><span>|</span><a href="#38377523">next</a><span>|</span><label class="collapse" for="c-38377381">[-]</label><label class="expand" for="c-38377381">[1 more]</label></div><br/><div class="children"><div class="content">The more relevant part is probably &quot;OpenAI’s mission is to ensure that AGI ... benefits all of humanity&quot;.<p>The statement &quot;it would be consistent with the company mission to destroy the company&quot; is correct. The word &quot;would be&quot; rather than &quot;is&quot; implies some condition, it doesn&#x27;t have to apply to the current circumstances.<p>A hypothesis is that Sam was attempting to gain full control of the board by getting the majority, and therefore the current board would be unable to hold him accountable to follow the mission in the future. Therefore, the board may have considered it necessary to stop him in order to fulfill the mission. There&#x27;s no hard evidence of that revealed yet though.</div><br/></div></div></div></div><div id="38377523" class="c"><input type="checkbox" id="c-38377523" checked=""/><div class="controls bullet"><span class="by">qwytw</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377007">parent</a><span>|</span><a href="#38377279">prev</a><span>|</span><a href="#38377837">next</a><span>|</span><label class="collapse" for="c-38377523">[-]</label><label class="expand" for="c-38377523">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  this mission (e.g. doing unsafe things), then it&#x27;s the board&#x27;s duty to stop the company.<p>So instead of having to compromise to some extent but still have a say what happens next you burn the company at best delaying the whole thing by 6-12 months until someone else does it? Well at least your hands are clean, but that&#x27;s about it...</div><br/></div></div></div></div></div></div></div></div><div id="38377837" class="c"><input type="checkbox" id="c-38377837" checked=""/><div class="controls bullet"><span class="by">achrono</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376510">prev</a><span>|</span><a href="#38376601">next</a><span>|</span><label class="collapse" for="c-38377837">[-]</label><label class="expand" for="c-38377837">[19 more]</label></div><br/><div class="children"><div class="content">No, if they had vastly different information, and if it was on the right side of their own stated purpose &amp; values, they would have behaved very differently. This kind of equivocation hinders the way more important questions such as: just what the heck is Larry Summers doing on that board?</div><br/><div id="38378188" class="c"><input type="checkbox" id="c-38378188" checked=""/><div class="controls bullet"><span class="by">38321003thrw</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378009">next</a><span>|</span><label class="collapse" for="c-38378188">[-]</label><label class="expand" for="c-38378188">[2 more]</label></div><br/><div class="children"><div class="content">&gt; just what the heck is Larry Summers doing on that board?<p>Probably precisely what Condeleeza Rice was doing on DropBox’s board. Or that board filled with national security state heavyweights on that “visionary” and her blood testing thingie.<p><a href="https:&#x2F;&#x2F;www.wired.com&#x2F;2014&#x2F;04&#x2F;dropbox-rice-controversy&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wired.com&#x2F;2014&#x2F;04&#x2F;dropbox-rice-controversy&#x2F;</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Theranos#Management" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Theranos#Management</a><p>In other possibly related news: <a href="https:&#x2F;&#x2F;nitter.net&#x2F;elonmusk&#x2F;status&#x2F;1726408333781774393#m" rel="nofollow noreferrer">https:&#x2F;&#x2F;nitter.net&#x2F;elonmusk&#x2F;status&#x2F;1726408333781774393#m</a><p>“What matters now is the way forward, as the DoD has a critical unmet need to bring the power of cloud and AI to our men and women in uniform, modernizing technology infrastructure and platform services technology. We stand ready to support the DoD as they work through their next steps and its new cloud computing solicitation plans.” (2021)<p><a href="https:&#x2F;&#x2F;blogs.microsoft.com&#x2F;blog&#x2F;2021&#x2F;07&#x2F;06&#x2F;microsofts-commitment-to-the-dod-remains-steadfast&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blogs.microsoft.com&#x2F;blog&#x2F;2021&#x2F;07&#x2F;06&#x2F;microsofts-commi...</a></div><br/></div></div><div id="38378009" class="c"><input type="checkbox" id="c-38378009" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378188">prev</a><span>|</span><a href="#38378040">next</a><span>|</span><label class="collapse" for="c-38378009">[-]</label><label class="expand" for="c-38378009">[3 more]</label></div><br/><div class="children"><div class="content">&gt;just what the heck is Larry Summers doing on that board?<p>1.  Did you really think the feds wouldn&#x27;t be involved?<p>AI is part of the next geopolitical cold war&#x2F;realpolitik of nation-states.  Up until now it&#x27;s just been passively collecting and spying on data.  And yes they absolutely will be using it in the military, probably after Israel or some other western-aligned nation gives it a test run.<p>2. Considering how much impact it will have on the entire economy by being able to put many white collar workers out of work, a seasoned economist makes sense.<p>The East Coast runs the joint.  The west coast just does the (publicly) facing tech stuff and takes the heat from the public</div><br/><div id="38378301" class="c"><input type="checkbox" id="c-38378301" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378009">parent</a><span>|</span><a href="#38378293">next</a><span>|</span><label class="collapse" for="c-38378301">[-]</label><label class="expand" for="c-38378301">[1 more]</label></div><br/><div class="children"><div class="content">The timing of the semiconductor export controls being another datapoint here in support of #1.<p>Not that it&#x27;s really in need of additional evidence.</div><br/></div></div><div id="38378293" class="c"><input type="checkbox" id="c-38378293" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378009">parent</a><span>|</span><a href="#38378301">prev</a><span>|</span><a href="#38378040">next</a><span>|</span><label class="collapse" for="c-38378293">[-]</label><label class="expand" for="c-38378293">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I think Larry there is because ChatGPT has become too important for USA.</div><br/></div></div></div></div><div id="38378040" class="c"><input type="checkbox" id="c-38378040" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378009">prev</a><span>|</span><a href="#38378469">next</a><span>|</span><label class="collapse" for="c-38378040">[-]</label><label class="expand" for="c-38378040">[3 more]</label></div><br/><div class="children"><div class="content">&gt; of their own stated purpose &amp; values<p>You mean the official stated purpose of OpenAI. The stated purpose that is constantly contradicted by many of their actions, and I think nobody took seriously anymore for years.<p>From everything I can tell the people working at OpenAI have always cared more about advancing the space and building great products than &quot;openeness&quot; and &quot;safe AGI&quot;. The official values of OpenAI were never &quot;their own&quot;.</div><br/><div id="38378537" class="c"><input type="checkbox" id="c-38378537" checked=""/><div class="controls bullet"><span class="by">bnralt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378040">parent</a><span>|</span><a href="#38378192">next</a><span>|</span><label class="collapse" for="c-38378537">[-]</label><label class="expand" for="c-38378537">[1 more]</label></div><br/><div class="children"><div class="content">&gt; From everything I can tell the people working at OpenAI have always cared more about advancing the space and building great products than &quot;openeness&quot; and &quot;safe AGI&quot;.<p>Board member Helen Toner strongly criticized OpenAI for publicly releasing it&#x27;s GPT when it did and not keeping it closed for longer. That would seem to be working against openness for many people, but others would see it as working towards safe AI.<p>The thing is, people have radically different ideas about what openness and safe mean. There&#x27;s a lot of talk about whether or not OpenAI stuck with it&#x27;s stated purpose, but there&#x27;s no consensus on what that purpose actually means in practice.</div><br/></div></div><div id="38378192" class="c"><input type="checkbox" id="c-38378192" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378040">parent</a><span>|</span><a href="#38378537">prev</a><span>|</span><a href="#38378469">next</a><span>|</span><label class="collapse" for="c-38378192">[-]</label><label class="expand" for="c-38378192">[1 more]</label></div><br/><div class="children"><div class="content">“never” is a strong word. I believe in the RL era of OpenAI they were quite aligned with the mission&#x2F;values</div><br/></div></div></div></div><div id="38378469" class="c"><input type="checkbox" id="c-38378469" checked=""/><div class="controls bullet"><span class="by">T-A</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378040">prev</a><span>|</span><a href="#38378033">next</a><span>|</span><label class="collapse" for="c-38378469">[-]</label><label class="expand" for="c-38378469">[1 more]</label></div><br/><div class="children"><div class="content">&gt; what the heck is Larry Summers doing on that board?<p>The former president of a research-oriented nonprofit (Harvard U) controlling a  revenue-generating entity (Harvard Management Co) worth tens of billions, ousted for harboring views considered harmful by a dominant ideological faction of his constituency? I guess he&#x27;s expected to have learned a thing or two from that.<p>And as an economist with a stint of heading the treasury under his belt, he&#x27;s presumably expected to be able to address the less apocalyptic fears surrounding AI.</div><br/></div></div><div id="38378033" class="c"><input type="checkbox" id="c-38378033" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378469">prev</a><span>|</span><a href="#38378478">next</a><span>|</span><label class="collapse" for="c-38378033">[-]</label><label class="expand" for="c-38378033">[1 more]</label></div><br/><div class="children"><div class="content">I assume larry summers is there to ensure the proper bi-partisan choices made by whats clearly now an _business_ product and not a product for humanity.<p>Which is utterly scary.</div><br/></div></div><div id="38378478" class="c"><input type="checkbox" id="c-38378478" checked=""/><div class="controls bullet"><span class="by">mrangle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378033">prev</a><span>|</span><a href="#38377909">next</a><span>|</span><label class="collapse" for="c-38378478">[-]</label><label class="expand" for="c-38378478">[1 more]</label></div><br/><div class="children"><div class="content">Said purpose and values are nothing more than an attempted control lever for dark actors, very obviously. People &#x2F; factions that gain handholds, which otherwise wouldn&#x27;t exist, and exert control through social pressure nonsense that they don&#x27;t believe in themselves. As can be extracted from modern street-brawl politics, which utilizes the same terminology to the same effect. And as can be inferred would be the case given OAI&#x27;s novel and convoluted corporate structure as referenced to the importance of its tech.<p>We just witnessed the war for that power play out, partially. But don&#x27;t worry, see next. Nothing is opaque about the appointment of Larry Summers. Very obviously, he&#x27;s the government&#x27;s seat on the board (see &#x27;dark actors&#x27;, now a little more into the light). Which is why I noted that the power competition only played out, partially. Altman is now unfireable, at least at this stage, and yet it would be irrational to think that this strategic mistake would inspire the most powerful actor to release its grip. The handhold has only been adjusted.</div><br/></div></div><div id="38377909" class="c"><input type="checkbox" id="c-38377909" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378478">prev</a><span>|</span><a href="#38378976">next</a><span>|</span><label class="collapse" for="c-38377909">[-]</label><label class="expand" for="c-38377909">[1 more]</label></div><br/><div class="children"><div class="content">I think this is a good question. One should look at what actually happened in practice. What was the previous board, what is the current board. For the leadership team, what are the changes? Additionally, was information revealed about who calls the shots which can inform who will drive future decisions? Anything else about the inbetweens to me is smoke and mirrors.</div><br/></div></div><div id="38378976" class="c"><input type="checkbox" id="c-38378976" checked=""/><div class="controls bullet"><span class="by">BurningFrog</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38377909">prev</a><span>|</span><a href="#38378095">next</a><span>|</span><label class="collapse" for="c-38378976">[-]</label><label class="expand" for="c-38378976">[4 more]</label></div><br/><div class="children"><div class="content">Larry Summers is everywhere and does everything.</div><br/><div id="38379131" class="c"><input type="checkbox" id="c-38379131" checked=""/><div class="controls bullet"><span class="by">TuringTest</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378976">parent</a><span>|</span><a href="#38378095">next</a><span>|</span><label class="collapse" for="c-38379131">[-]</label><label class="expand" for="c-38379131">[3 more]</label></div><br/><div class="children"><div class="content">At the same time?</div><br/><div id="38380724" class="c"><input type="checkbox" id="c-38380724" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379131">parent</a><span>|</span><a href="#38378095">next</a><span>|</span><label class="collapse" for="c-38380724">[-]</label><label class="expand" for="c-38380724">[2 more]</label></div><br/><div class="children"><div class="content">All at once.</div><br/></div></div></div></div></div></div><div id="38378095" class="c"><input type="checkbox" id="c-38378095" checked=""/><div class="controls bullet"><span class="by">shmatt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377837">parent</a><span>|</span><a href="#38378976">prev</a><span>|</span><a href="#38376601">next</a><span>|</span><label class="collapse" for="c-38378095">[-]</label><label class="expand" for="c-38378095">[2 more]</label></div><br/><div class="children"><div class="content">He’s a white male replacing a female board member. Which is probably what they wanted all along</div><br/><div id="38378124" class="c"><input type="checkbox" id="c-38378124" checked=""/><div class="controls bullet"><span class="by">dbspin</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378095">parent</a><span>|</span><a href="#38376601">next</a><span>|</span><label class="collapse" for="c-38378124">[-]</label><label class="expand" for="c-38378124">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the patriarchy collectively breathed a sigh of relief as one of our agents was inserted to prevent any threat from the other side.</div><br/></div></div></div></div></div></div><div id="38376601" class="c"><input type="checkbox" id="c-38376601" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38377837">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376601">[-]</label><label class="expand" for="c-38376601">[14 more]</label></div><br/><div class="children"><div class="content">&quot;They have a different set of information than you do,&quot;<p>Their bank accounts current and potential future numbers?</div><br/><div id="38376681" class="c"><input type="checkbox" id="c-38376681" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376601">parent</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376681">[-]</label><label class="expand" for="c-38376681">[13 more]</label></div><br/><div class="children"><div class="content">How is employees protecting themselves is suddenly a bad thing? There&#x27;s no idiots at OpenAI.</div><br/><div id="38378299" class="c"><input type="checkbox" id="c-38378299" checked=""/><div class="controls bullet"><span class="by">pooya13</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376681">parent</a><span>|</span><a href="#38376895">next</a><span>|</span><label class="collapse" for="c-38378299">[-]</label><label class="expand" for="c-38378299">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s no idiots at OpenAI.<p>Most certainly there are idiots at OpenAI.</div><br/><div id="38380595" class="c"><input type="checkbox" id="c-38380595" checked=""/><div class="controls bullet"><span class="by">infamouscow</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378299">parent</a><span>|</span><a href="#38376895">next</a><span>|</span><label class="collapse" for="c-38380595">[-]</label><label class="expand" for="c-38380595">[1 more]</label></div><br/><div class="children"><div class="content">The current board won&#x27;t be at OpenAI much longer.</div><br/></div></div></div></div><div id="38376895" class="c"><input type="checkbox" id="c-38376895" checked=""/><div class="controls bullet"><span class="by">g-b-r</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376681">parent</a><span>|</span><a href="#38378299">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376895">[-]</label><label class="expand" for="c-38376895">[10 more]</label></div><br/><div class="children"><div class="content">They were supposed to have higher values than money</div><br/><div id="38377076" class="c"><input type="checkbox" id="c-38377076" checked=""/><div class="controls bullet"><span class="by">plasmatix</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376895">parent</a><span>|</span><a href="#38377675">next</a><span>|</span><label class="collapse" for="c-38377076">[-]</label><label class="expand" for="c-38377076">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how, with the dearth of information we currently have, anyone can see this as &quot;higher values&quot; vs &quot;money&quot;.<p>No doubt people are motivated by money but it&#x27;s not like the board is some infallible arbiter of AI ethics and safety. They made a hugely impactful decision without credible evidence that it was justified.</div><br/><div id="38380582" class="c"><input type="checkbox" id="c-38380582" checked=""/><div class="controls bullet"><span class="by">Ajedi32</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377076">parent</a><span>|</span><a href="#38377675">next</a><span>|</span><label class="collapse" for="c-38380582">[-]</label><label class="expand" for="c-38380582">[1 more]</label></div><br/><div class="children"><div class="content">The issue here is that the board of the non-profit that is <i>supposedly</i> in charge of OpenAI (and whose interests are presumably aligned with the mission statement of the company) seemingly just lost a power struggle with their for-profit subsidiary who is <i>not</i> supposed to be in charge of OpenAI (and whose interests, including the interests of their employees, are aligned with making as much money as possible). Regardless of whether the board&#x27;s initial decision that started this power struggle was wise or not, don&#x27;t you find the outcome a little worrisome?</div><br/></div></div></div></div><div id="38377675" class="c"><input type="checkbox" id="c-38377675" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376895">parent</a><span>|</span><a href="#38377076">prev</a><span>|</span><a href="#38380879">next</a><span>|</span><label class="collapse" for="c-38377675">[-]</label><label class="expand" for="c-38377675">[2 more]</label></div><br/><div class="children"><div class="content">&quot;higher values&quot; like trying to stop computers from saying the n-word?</div><br/><div id="38377719" class="c"><input type="checkbox" id="c-38377719" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377675">parent</a><span>|</span><a href="#38380879">next</a><span>|</span><label class="collapse" for="c-38377719">[-]</label><label class="expand" for="c-38377719">[1 more]</label></div><br/><div class="children"><div class="content">For some that is important, but more people consider the prevention of an AI monopoly to be more important here. See the original charter and the status quo with Microsoft taking it all.</div><br/></div></div></div></div><div id="38380879" class="c"><input type="checkbox" id="c-38380879" checked=""/><div class="controls bullet"><span class="by">Zpalmtree</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376895">parent</a><span>|</span><a href="#38377675">prev</a><span>|</span><a href="#38376992">next</a><span>|</span><label class="collapse" for="c-38380879">[-]</label><label class="expand" for="c-38380879">[1 more]</label></div><br/><div class="children"><div class="content">Why? Did they have to sign a charter affirming their commitment to the mission when they were hired?</div><br/></div></div><div id="38376992" class="c"><input type="checkbox" id="c-38376992" checked=""/><div class="controls bullet"><span class="by">lovelyviking</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376895">parent</a><span>|</span><a href="#38380879">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376992">[-]</label><label class="expand" for="c-38376992">[4 more]</label></div><br/><div class="children"><div class="content">&gt;They were supposed to have higher values than money<p>which are? …</div><br/><div id="38377005" class="c"><input type="checkbox" id="c-38377005" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376992">parent</a><span>|</span><a href="#38377259">next</a><span>|</span><label class="collapse" for="c-38377005">[-]</label><label class="expand" for="c-38377005">[1 more]</label></div><br/><div class="children"><div class="content">Ethics presumably</div><br/></div></div><div id="38377259" class="c"><input type="checkbox" id="c-38377259" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376992">parent</a><span>|</span><a href="#38377005">prev</a><span>|</span><a href="#38377330">next</a><span>|</span><label class="collapse" for="c-38377259">[-]</label><label class="expand" for="c-38377259">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps something like &quot;to ensure that artificial general intelligence (AGI)—by which we mean highly autonomous systems that outperform humans at most economically valuable work—benefits all of humanity.&quot;</div><br/></div></div><div id="38377330" class="c"><input type="checkbox" id="c-38377330" checked=""/><div class="controls bullet"><span class="by">brazzy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376992">parent</a><span>|</span><a href="#38377259">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38377330">[-]</label><label class="expand" for="c-38377330">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376740" class="c"><input type="checkbox" id="c-38376740" checked=""/><div class="controls bullet"><span class="by">lwhi</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376601">prev</a><span>|</span><a href="#38376608">next</a><span>|</span><label class="collapse" for="c-38376740">[-]</label><label class="expand" for="c-38376740">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fair to call this reactionary; Sam Altman has played the part of &#x27;ping-pong ball&#x27; exceptionally well these past few days.</div><br/></div></div><div id="38376608" class="c"><input type="checkbox" id="c-38376608" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376740">prev</a><span>|</span><a href="#38377238">next</a><span>|</span><label class="collapse" for="c-38376608">[-]</label><label class="expand" for="c-38376608">[1 more]</label></div><br/><div class="children"><div class="content">There’s evidence to suggest that a central group have pressured the broader base of employees into going along with this, as posted elsewhere in the thread.</div><br/></div></div><div id="38377238" class="c"><input type="checkbox" id="c-38377238" checked=""/><div class="controls bullet"><span class="by">murbard2</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376608">prev</a><span>|</span><a href="#38378712">next</a><span>|</span><label class="collapse" for="c-38377238">[-]</label><label class="expand" for="c-38377238">[9 more]</label></div><br/><div class="children"><div class="content">If 95% of people voted in favour of apple pie, I&#x27;d become a bit suspicious of apple pie.</div><br/><div id="38378045" class="c"><input type="checkbox" id="c-38378045" checked=""/><div class="controls bullet"><span class="by">eddtries</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377238">parent</a><span>|</span><a href="#38378425">next</a><span>|</span><label class="collapse" for="c-38378045">[-]</label><label class="expand" for="c-38378045">[5 more]</label></div><br/><div class="children"><div class="content">I think it makes sense<p>Sign the letter and support Sam so you have a place at Microsoft if OpenAI tanks <i>and</i> have a place at OpenAI if it continues under Sam, or don’t sign and potentially lose your role at OpenAI if Sam stays <i>and</i> lose a bunch of money if Sam leaves and OpenAI fails.<p>There’s no perks to not signing.</div><br/><div id="38378295" class="c"><input type="checkbox" id="c-38378295" checked=""/><div class="controls bullet"><span class="by">_heimdall</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378045">parent</a><span>|</span><a href="#38378425">next</a><span>|</span><label class="collapse" for="c-38378295">[-]</label><label class="expand" for="c-38378295">[4 more]</label></div><br/><div class="children"><div class="content">There are perks to not signing for anyone that actually worked at OpenAI for on the mission rather than the money.</div><br/><div id="38381375" class="c"><input type="checkbox" id="c-38381375" checked=""/><div class="controls bullet"><span class="by">WesleyJohnson</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378295">parent</a><span>|</span><a href="#38378756">next</a><span>|</span><label class="collapse" for="c-38381375">[-]</label><label class="expand" for="c-38381375">[2 more]</label></div><br/><div class="children"><div class="content">Maybe they&#x27;re working for both, but when push comes to shove they felt like they had no choice? In this economy, it&#x27;s a little easier to tuck away your ideals in favor of a paycheck unfortunately.<p>Or maybe the mass signing was less about following the money and more about doing what they felt would force the OpenAI board to cave and bring Sam back, so they could all continue to work towards the missing at OpenAI?</div><br/><div id="38383006" class="c"><input type="checkbox" id="c-38383006" checked=""/><div class="controls bullet"><span class="by">_heimdall</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38381375">parent</a><span>|</span><a href="#38378756">next</a><span>|</span><label class="collapse" for="c-38383006">[-]</label><label class="expand" for="c-38383006">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In this economy, it&#x27;s a little easier to tuck away your ideals in favor of a paycheck unfortunately.<p>Its a gut check on morals&#x2F;ethics for sure. I&#x27;m always pretty torn on the tipping point for empathising there in an industry like tech though, even more so for AI where all the money is today. Our industry is paid extremely well and anyone that wants to hold their personal ethics over money likely has plenty of opportunity to do so. In AI specifically, there would have easily been 800 jobs floating around for AI experts that chose to leave OpenAI because they preferred the for-profit approach.<p>At least how I see it, Sam coming back to OpenAI is OpenAI abandoning the original vision and leaning full into developing AGI for profit. Anyone that worked there for the original mission might as well leave now, they&#x27;ll be throwing AI risk out the window almost entirely.</div><br/></div></div></div></div></div></div></div></div><div id="38378425" class="c"><input type="checkbox" id="c-38378425" checked=""/><div class="controls bullet"><span class="by">iowemoretohim</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377238">parent</a><span>|</span><a href="#38378045">prev</a><span>|</span><a href="#38379244">next</a><span>|</span><label class="collapse" for="c-38378425">[-]</label><label class="expand" for="c-38378425">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps a better example would be 95% of people voted in favour of reinstating apple pie to the menu after not receiving a coherent explanation for removing apple pie from the menu.</div><br/></div></div><div id="38377868" class="c"><input type="checkbox" id="c-38377868" checked=""/><div class="controls bullet"><span class="by">achrono</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377238">parent</a><span>|</span><a href="#38379244">prev</a><span>|</span><a href="#38378712">next</a><span>|</span><label class="collapse" for="c-38377868">[-]</label><label class="expand" for="c-38377868">[1 more]</label></div><br/><div class="children"><div class="content">Or you&#x27;d want to thoroughly investigate this so-called voting.<p>Or that said apple pie was essential to their survival.</div><br/></div></div></div></div><div id="38378712" class="c"><input type="checkbox" id="c-38378712" checked=""/><div class="controls bullet"><span class="by">kiba</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38377238">prev</a><span>|</span><a href="#38376818">next</a><span>|</span><label class="collapse" for="c-38378712">[-]</label><label class="expand" for="c-38378712">[1 more]</label></div><br/><div class="children"><div class="content">They could just reach different conclusion based on their values. OpenAI doesn&#x27;t seem to be remotely serious about preventing the misuse of AI.</div><br/></div></div><div id="38376818" class="c"><input type="checkbox" id="c-38376818" checked=""/><div class="controls bullet"><span class="by">kissgyorgy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38378712">prev</a><span>|</span><a href="#38377793">next</a><span>|</span><label class="collapse" for="c-38376818">[-]</label><label class="expand" for="c-38376818">[1 more]</label></div><br/><div class="children"><div class="content">The available public information is enough to reach this conclusion.</div><br/></div></div><div id="38377793" class="c"><input type="checkbox" id="c-38377793" checked=""/><div class="controls bullet"><span class="by">yodsanklai</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376818">prev</a><span>|</span><a href="#38378195">next</a><span>|</span><label class="collapse" for="c-38377793">[-]</label><label class="expand" for="c-38377793">[1 more]</label></div><br/><div class="children"><div class="content">&gt; different set of information<p>and different incentives.</div><br/></div></div><div id="38378195" class="c"><input type="checkbox" id="c-38378195" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38377793">prev</a><span>|</span><a href="#38376493">next</a><span>|</span><label class="collapse" for="c-38378195">[-]</label><label class="expand" for="c-38378195">[1 more]</label></div><br/><div class="children"><div class="content">They have a different set of incentives. If I were them I would have done the same thing, Altman is going to make them all fucking rich. Not sure if that will benefit humanity though.</div><br/></div></div></div></div><div id="38376493" class="c"><input type="checkbox" id="c-38376493" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376477">prev</a><span>|</span><a href="#38376947">next</a><span>|</span><label class="collapse" for="c-38376493">[-]</label><label class="expand" for="c-38376493">[27 more]</label></div><br/><div class="children"><div class="content">I think this outcome was actually much more favorable to D&#x27;Angelo&#x27;s faction than people realize. The truth is before this Sam was basically running circles around the board and doing whatever he wanted on the profit side- that&#x27;s what was pissing them off so much in the first place. He was even trying to depose board members who were openly critical of open AI&#x27;s practices.<p>From here on out there is going to be far more media scrutiny on who gets picked as a board member, where they stand on the company&#x27;s policies, and just how independent they really are. Sam, Greg and even Ilya are off the board altogether. Whoever they can all agree on to fill the remaining seats, Sam is going to have to be a lot more subservient to them to keep the peace.</div><br/><div id="38376656" class="c"><input type="checkbox" id="c-38376656" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38377707">next</a><span>|</span><label class="collapse" for="c-38376656">[-]</label><label class="expand" for="c-38376656">[13 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t make sense that after such a broad board capitulation the next one will have any power, and media scrutiny isn&#x27;t a powerful governance mechanism</div><br/><div id="38376699" class="c"><input type="checkbox" id="c-38376699" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376656">parent</a><span>|</span><a href="#38377674">next</a><span>|</span><label class="collapse" for="c-38376699">[-]</label><label class="expand" for="c-38376699">[11 more]</label></div><br/><div class="children"><div class="content">When you consider they were acting under the threat of the entire company walking out and the threat of endless lawsuits, this is a remarkably mild capitulation. All the new board members are going to be chosen by D&#x27;Angelo and two new board members that he also had a big hand in choosing.<p>And say what you want about Larry Summers, but he&#x27;s not going to be either Sam&#x27;s or even Microsoft&#x27;s bitch.</div><br/><div id="38377057" class="c"><input type="checkbox" id="c-38377057" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376699">parent</a><span>|</span><a href="#38376838">next</a><span>|</span><label class="collapse" for="c-38377057">[-]</label><label class="expand" for="c-38377057">[5 more]</label></div><br/><div class="children"><div class="content">What I&#x27;d want to say about Larry is that he is definitely not going to care about the whole-society non-profit shtick of the company to any degree comparable with the previous board members, so he won&#x27;t constraint Sam&#x2F;MS in any way</div><br/><div id="38377433" class="c"><input type="checkbox" id="c-38377433" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377057">parent</a><span>|</span><a href="#38377834">next</a><span>|</span><label class="collapse" for="c-38377433">[-]</label><label class="expand" for="c-38377433">[3 more]</label></div><br/><div class="children"><div class="content">Why? As an economist, he perfectly understands what is a public good, why there is a market failure to underproduce a public good under free market, and role of nonprofit in public good production.</div><br/><div id="38377888" class="c"><input type="checkbox" id="c-38377888" checked=""/><div class="controls bullet"><span class="by">pevey</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377433">parent</a><span>|</span><a href="#38377690">next</a><span>|</span><label class="collapse" for="c-38377888">[-]</label><label class="expand" for="c-38377888">[1 more]</label></div><br/><div class="children"><div class="content">Larry Summers has a track record of not believing in market failures, just market opportunities for private interests.  Economists vary vastly in their belief systems, and economics is more politics than science, no matter how much math they try to use to distract from this.</div><br/></div></div><div id="38377690" class="c"><input type="checkbox" id="c-38377690" checked=""/><div class="controls bullet"><span class="by">ZiiS</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377433">parent</a><span>|</span><a href="#38377888">prev</a><span>|</span><a href="#38377834">next</a><span>|</span><label class="collapse" for="c-38377690">[-]</label><label class="expand" for="c-38377690">[1 more]</label></div><br/><div class="children"><div class="content">His deregulation of the banks suggests he heavily flavors free markets even when history has proved him very very wrong.</div><br/></div></div></div></div><div id="38377834" class="c"><input type="checkbox" id="c-38377834" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377057">parent</a><span>|</span><a href="#38377433">prev</a><span>|</span><a href="#38376838">next</a><span>|</span><label class="collapse" for="c-38377834">[-]</label><label class="expand" for="c-38377834">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if Adam D&#x27;Angelo would agree with you, because he had veto power over these selections and he wanted Larry Summers on the board himself.</div><br/></div></div></div></div><div id="38376838" class="c"><input type="checkbox" id="c-38376838" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376699">parent</a><span>|</span><a href="#38377057">prev</a><span>|</span><a href="#38378312">next</a><span>|</span><label class="collapse" for="c-38376838">[-]</label><label class="expand" for="c-38376838">[3 more]</label></div><br/><div class="children"><div class="content">I wonder what is the rationale for picking a seasoned politician and economist (influenced deregulation of US finance system, was friends with Epstein, had a few controversies listed there). Has the government also entered the chat so obviously?</div><br/><div id="38377613" class="c"><input type="checkbox" id="c-38377613" checked=""/><div class="controls bullet"><span class="by">voster</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376838">parent</a><span>|</span><a href="#38376991">next</a><span>|</span><label class="collapse" for="c-38377613">[-]</label><label class="expand" for="c-38377613">[1 more]</label></div><br/><div class="children"><div class="content">They had congressman Will Hurd on the board before. Govt-adjacent people on non-profits are common for many reasons - understanding regulatory requirements, access to people, but also actual &quot;good&quot; reasons like the fact that many people who work close to the state genuinely have good intentions on social good (whether you agree with their interpretation of it or not)</div><br/></div></div><div id="38376991" class="c"><input type="checkbox" id="c-38376991" checked=""/><div class="controls bullet"><span class="by">choult</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376838">parent</a><span>|</span><a href="#38377613">prev</a><span>|</span><a href="#38378312">next</a><span>|</span><label class="collapse" for="c-38376991">[-]</label><label class="expand" for="c-38376991">[1 more]</label></div><br/><div class="children"><div class="content">It probably means that they anticipate a need for dealing with the government in future, such as having a hand in regulation of their industry.</div><br/></div></div></div></div><div id="38378312" class="c"><input type="checkbox" id="c-38378312" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376699">parent</a><span>|</span><a href="#38376838">prev</a><span>|</span><a href="#38377674">next</a><span>|</span><label class="collapse" for="c-38378312">[-]</label><label class="expand" for="c-38378312">[2 more]</label></div><br/><div class="children"><div class="content">On what premise you assume that D&#x27;Angelo will have any say there? At this point he won&#x27;t be able to do any moves - especially with Larry and Microsoft overseeing all that stuff.</div><br/><div id="38388037" class="c"><input type="checkbox" id="c-38388037" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378312">parent</a><span>|</span><a href="#38377674">next</a><span>|</span><label class="collapse" for="c-38388037">[-]</label><label class="expand" for="c-38388037">[1 more]</label></div><br/><div class="children"><div class="content">Again, D&#x27;Angelo chose Larry Summers and Bret Taylor to sit on the board with him himself. As long as it is the three of them, he can&#x27;t be overruled unless both of his personal picks disagree with him. And if the opposition to his idea is all that bad, he probably really should be overruled.<p>His voting power will get diluted as they add the next six members, but again, all three of them are going to decide who the next members are going to be.<p>A snippet from the recent Bloomberg article:<p>&gt;A person close to the negotiations said that several women were suggested as possible interim directors, but parties couldn’t come to a consensus. Both Laurene Powell Jobs, the billionaire philanthropist and widow of Steve Jobs, and former Yahoo CEO Marissa Mayer were floated, *but deemed to be too close to Altman*, this person said.<p>Say what else you want about it, this is not going to be a board automatically stacked in Altman&#x27;s favor.</div><br/></div></div></div></div></div></div><div id="38377674" class="c"><input type="checkbox" id="c-38377674" checked=""/><div class="controls bullet"><span class="by">dagaci</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376656">parent</a><span>|</span><a href="#38376699">prev</a><span>|</span><a href="#38377707">next</a><span>|</span><label class="collapse" for="c-38377674">[-]</label><label class="expand" for="c-38377674">[1 more]</label></div><br/><div class="children"><div class="content">Clearly the board members did not think through even the immediate consequences. Kenobi: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iVBX7l2zgRw" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iVBX7l2zgRw</a></div><br/></div></div></div></div><div id="38377707" class="c"><input type="checkbox" id="c-38377707" checked=""/><div class="controls bullet"><span class="by">moonsu</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38376656">prev</a><span>|</span><a href="#38376517">next</a><span>|</span><label class="collapse" for="c-38377707">[-]</label><label class="expand" for="c-38377707">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The truth is before this Sam was basically running circles around the board and doing whatever he wanted on the profit side- that&#x27;s what was pissing them off so much in the first place. He was even trying to depose board members who were openly critical of open AI&#x27;s practices.<p>Do you have a source for this?</div><br/><div id="38377881" class="c"><input type="checkbox" id="c-38377881" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377707">parent</a><span>|</span><a href="#38376517">next</a><span>|</span><label class="collapse" for="c-38377881">[-]</label><label class="expand" for="c-38377881">[1 more]</label></div><br/><div class="children"><div class="content">New York Times. He was &quot;reprimanding&quot; Toner, a board member, for writing an article critical of open AI.<p><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-board-fight.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-...</a><p>Getting his way: The Wall Street Journal article. They said he usually got his way, but that he was so skillful at it that they were hard-pressed to explain exactly how he managed to pull it off.<p><a href="https:&#x2F;&#x2F;archive.is&#x2F;20231122033417&#x2F;https:&#x2F;&#x2F;www.wsj.com&#x2F;tech&#x2F;ai&#x2F;altman-firing-openai-520a3a8c#selection-1249.131-1249.333" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;20231122033417&#x2F;https:&#x2F;&#x2F;www.wsj.com&#x2F;tech&#x2F;a...</a><p>Bottom line he had a lot more power over the board then than he will now.</div><br/></div></div></div></div><div id="38376517" class="c"><input type="checkbox" id="c-38376517" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38377707">prev</a><span>|</span><a href="#38376971">next</a><span>|</span><label class="collapse" for="c-38376517">[-]</label><label class="expand" for="c-38376517">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Sam, Greg and even Ilya are off the board altogether. Whoever they can all agree on to fill the remaining seats, Sam is going to have to be a lot more subservient to them to keep the peace.<p>The existing board is just a seat-warming body until Altman and Microsoft can stack it with favorables to their (and the U.S. Government’s) interests. The naïveté from the NPO faction was believing they’d be able to develop these capacities outside the strict control of the military industrial complex when AI has been established as part of the new Cold War with China.</div><br/><div id="38376679" class="c"><input type="checkbox" id="c-38376679" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376517">parent</a><span>|</span><a href="#38376569">next</a><span>|</span><label class="collapse" for="c-38376679">[-]</label><label class="expand" for="c-38376679">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The existing board is just a seat-warming body until Altman and Microsoft can stack it with favorables to their (and the U.S. Government’s) interests.<p>That&#x27;s incorrect. The new members will be chosen by D&#x27;Angelo and the two new independent board members. Both of which D&#x27;Angelo had a big hand in choosing.<p>I&#x27;m not saying Larry Summers etc going to be in D&#x27;Angelo&#x27;s pocket. But the whole reason he agreed to those picks is because he knows they won&#x27;t be in Sam&#x27;s pocket, either. More likely they will act independently and choose future members that they sincerely believe will be the best picks for the nonprofit.</div><br/></div></div><div id="38376569" class="c"><input type="checkbox" id="c-38376569" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376517">parent</a><span>|</span><a href="#38376679">prev</a><span>|</span><a href="#38376971">next</a><span>|</span><label class="collapse" for="c-38376569">[-]</label><label class="expand" for="c-38376569">[5 more]</label></div><br/><div class="children"><div class="content">According to this tweet thread[1], they negotiated hard for Sam to be off the board and Adam to stay on. That indicates, at least if we&#x27;re being optimistic, that the current board is not in Sam&#x27;s pocket (otherwise they wouldn&#x27;t have bothered)<p>[1]:(<a href="https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727216818648134101" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727216818648134101</a>)</div><br/><div id="38376698" class="c"><input type="checkbox" id="c-38376698" checked=""/><div class="controls bullet"><span class="by">wouldbecouldbe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376569">parent</a><span>|</span><a href="#38376624">next</a><span>|</span><label class="collapse" for="c-38376698">[-]</label><label class="expand" for="c-38376698">[3 more]</label></div><br/><div class="children"><div class="content">Yeah the board is kind of pointless now.<p>They can&#x27;t control the CEO, neither fire him.<p>They can&#x27;t take actions to take back the back control from Microsoft and Sam because Sam is the CEO. Even if Sam is of the utmost morality, he would be crazy to help them back into a strong position after last week.<p>So it&#x27;s the Sam &amp; Microsoft show now, only a master schemer can get back some power to the board.</div><br/><div id="38378181" class="c"><input type="checkbox" id="c-38378181" checked=""/><div class="controls bullet"><span class="by">notahacker</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376698">parent</a><span>|</span><a href="#38378160">next</a><span>|</span><label class="collapse" for="c-38378181">[-]</label><label class="expand" for="c-38378181">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s my take. Doesn&#x27;t really matter if the composition of the board is to Adam&#x27;s liking and has a couple more heavy hitters if Sam is untouchable and Microsoft is signalling that any time OpenAI acts against its interests they will take steps to ensure it ceases to have any staff or funding.</div><br/></div></div><div id="38378160" class="c"><input type="checkbox" id="c-38378160" checked=""/><div class="controls bullet"><span class="by">wouldbecouldbe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376698">parent</a><span>|</span><a href="#38378181">prev</a><span>|</span><a href="#38376624">next</a><span>|</span><label class="collapse" for="c-38378160">[-]</label><label class="expand" for="c-38378160">[1 more]</label></div><br/><div class="children"><div class="content">It would be an interesting move to install a co-ceo in a few months. That would be harder to object for Sam</div><br/></div></div></div></div><div id="38376624" class="c"><input type="checkbox" id="c-38376624" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376569">parent</a><span>|</span><a href="#38376698">prev</a><span>|</span><a href="#38376971">next</a><span>|</span><label class="collapse" for="c-38376624">[-]</label><label class="expand" for="c-38376624">[1 more]</label></div><br/><div class="children"><div class="content">I’m sorry, but that’s all kayfabe. If there is one thing that’s been demonstrated in this whole fiasco, it’s who really has all the power at OpenAI (and it’s not the board).</div><br/></div></div></div></div></div></div><div id="38376971" class="c"><input type="checkbox" id="c-38376971" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38376517">prev</a><span>|</span><a href="#38378083">next</a><span>|</span><label class="collapse" for="c-38376971">[-]</label><label class="expand" for="c-38376971">[1 more]</label></div><br/><div class="children"><div class="content">&gt; He was even trying to depose board members who were openly critical of open AI&#x27;s practices.<p>Was there any concrete criticism in the paper that was written by that board member? (Genuinely asking, not a leading question)</div><br/></div></div><div id="38378083" class="c"><input type="checkbox" id="c-38378083" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38376971">prev</a><span>|</span><a href="#38378170">next</a><span>|</span><label class="collapse" for="c-38378083">[-]</label><label class="expand" for="c-38378083">[2 more]</label></div><br/><div class="children"><div class="content">Eh, Larry Summers is on this board. That means they&#x27;re now going to protect business interests.<p>OpenAI is now just a tool used by Businesses. And they dont have a good history of benefitting humanity recently.</div><br/><div id="38379766" class="c"><input type="checkbox" id="c-38379766" checked=""/><div class="controls bullet"><span class="by">kofejnik</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378083">parent</a><span>|</span><a href="#38378170">next</a><span>|</span><label class="collapse" for="c-38379766">[-]</label><label class="expand" for="c-38379766">[1 more]</label></div><br/><div class="children"><div class="content">Larry Summers is EA and State, so not so sure about business interests</div><br/></div></div></div></div><div id="38378170" class="c"><input type="checkbox" id="c-38378170" checked=""/><div class="controls bullet"><span class="by">nashashmi</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38378083">prev</a><span>|</span><a href="#38376947">next</a><span>|</span><label class="collapse" for="c-38378170">[-]</label><label class="expand" for="c-38378170">[1 more]</label></div><br/><div class="children"><div class="content">Media &gt;= employees? Media &gt;= Sam? I don&#x27;t think media has any role on oversight or governance.<p>I think Sam came out the winner.  He gets to pick his board. He gets to narrow his employees.  If anything, this sets him up for dictatorship.  The only other overseers are the investors.  In that case, Microsoft came out holding a leash. No MS, means no Sam, which also means employees have no say.<p>So it is more like MS &gt; Sam &gt; employees.  MS+Sam &gt; rest of investors.</div><br/></div></div></div></div><div id="38376947" class="c"><input type="checkbox" id="c-38376947" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376493">prev</a><span>|</span><a href="#38376566">next</a><span>|</span><label class="collapse" for="c-38376947">[-]</label><label class="expand" for="c-38376947">[21 more]</label></div><br/><div class="children"><div class="content">&gt; Furthermore, the overwhelming groupthink shows there&#x27;s clearly little critical thinking amongst OpenAI&#x27;s employees either.<p>If the &quot;other side&quot; (board) had put up a SINGLE convincing argument on why Sam had to go maybe the employees would have not supported Sam unequivocally.<p>But, atleast as an outsider, we heard nothing that suggests board had reasons to remove Sam other than &quot;the vibes were off&quot;<p>Can you really accuse the employees of groupthink when the other side is so weak?</div><br/><div id="38377915" class="c"><input type="checkbox" id="c-38377915" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376947">parent</a><span>|</span><a href="#38377167">next</a><span>|</span><label class="collapse" for="c-38377915">[-]</label><label class="expand" for="c-38377915">[10 more]</label></div><br/><div class="children"><div class="content">OpenAI is a private company and not obligated nor is it generally advised for them to comment publicly on why people are fired. I know that having a public explanation would be useful for the plot development of everyone’s favorite little soap opera, but it makes pretty much zero sense and doesn’t lend credence to any position whatsoever.</div><br/><div id="38378977" class="c"><input type="checkbox" id="c-38378977" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377915">parent</a><span>|</span><a href="#38378468">next</a><span>|</span><label class="collapse" for="c-38378977">[-]</label><label class="expand" for="c-38378977">[2 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is a private company and not obligated nor is it generally advised for them to comment publicly on why people are fired.<p>The interim CEO said the board couldn’t even tell him why the old CEO was fired.<p>Microsoft said the board couldn’t even tell them why the old CEO was fired.<p>The employees said the board couldn’t explain why the CEO was fired.<p>When nobody can even begin to understand the board’s actions and they can’t even explain themselves, it’s a recipe for losing confidence. And that’s exactly what happened, from investors to employees.</div><br/><div id="38379122" class="c"><input type="checkbox" id="c-38379122" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378977">parent</a><span>|</span><a href="#38378468">next</a><span>|</span><label class="collapse" for="c-38379122">[-]</label><label class="expand" for="c-38379122">[1 more]</label></div><br/><div class="children"><div class="content">I’m specifically taking issue with this common meme that <i>the public</i> is owed some sort of explanation. I agree the employees (and obviously the incoming CEO) would be.<p>And there’s a difference between, “an explanation would help their credibility” versus “a lack of explanation means they don’t have a good reason.”</div><br/></div></div></div></div><div id="38378468" class="c"><input type="checkbox" id="c-38378468" checked=""/><div class="controls bullet"><span class="by">cryptonym</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377915">parent</a><span>|</span><a href="#38378977">prev</a><span>|</span><a href="#38378446">next</a><span>|</span><label class="collapse" for="c-38378468">[-]</label><label class="expand" for="c-38378468">[1 more]</label></div><br/><div class="children"><div class="content">Taking decisions in a way that <i>seems</i> opaque and arbitrary will not bring much support from employees, partners and investors. They did not fire a random employee. Not disclosing relevant information for such a key decision was proven, once again, to be a disaster.<p>This is not about soap opera, this is about business and a big part is based on trust.</div><br/></div></div><div id="38378446" class="c"><input type="checkbox" id="c-38378446" checked=""/><div class="controls bullet"><span class="by">iowemoretohim</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377915">parent</a><span>|</span><a href="#38378468">prev</a><span>|</span><a href="#38378995">next</a><span>|</span><label class="collapse" for="c-38378446">[-]</label><label class="expand" for="c-38378446">[3 more]</label></div><br/><div class="children"><div class="content">Since barely any information was made publicly we have to assume the employees had better information that the public. So how can we say they lacked critical thinking when we don&#x27;t have access to the information they have?</div><br/><div id="38378515" class="c"><input type="checkbox" id="c-38378515" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378446">parent</a><span>|</span><a href="#38378995">next</a><span>|</span><label class="collapse" for="c-38378515">[-]</label><label class="expand" for="c-38378515">[2 more]</label></div><br/><div class="children"><div class="content">I didn’t claim employees were engaged in groupthink. I’m taking issue with the claim that <i>because there is no public explanation</i>, there must not be a good explanation.</div><br/><div id="38379012" class="c"><input type="checkbox" id="c-38379012" checked=""/><div class="controls bullet"><span class="by">ulizzle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378515">parent</a><span>|</span><a href="#38378995">next</a><span>|</span><label class="collapse" for="c-38379012">[-]</label><label class="expand" for="c-38379012">[1 more]</label></div><br/><div class="children"><div class="content">That is a logical fallacy clawing your face. Upvotes to whoever can name which one.</div><br/></div></div></div></div></div></div><div id="38378995" class="c"><input type="checkbox" id="c-38378995" checked=""/><div class="controls bullet"><span class="by">ulizzle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377915">parent</a><span>|</span><a href="#38378446">prev</a><span>|</span><a href="#38378545">next</a><span>|</span><label class="collapse" for="c-38378995">[-]</label><label class="expand" for="c-38378995">[1 more]</label></div><br/><div class="children"><div class="content">All explanations lend credence to positions which is why is not a good idea to comment on anything. Looks like they’re lawyered up.</div><br/></div></div><div id="38378545" class="c"><input type="checkbox" id="c-38378545" checked=""/><div class="controls bullet"><span class="by">Bayaz</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377915">parent</a><span>|</span><a href="#38378995">prev</a><span>|</span><a href="#38377167">next</a><span>|</span><label class="collapse" for="c-38378545">[-]</label><label class="expand" for="c-38378545">[2 more]</label></div><br/><div class="children"><div class="content">And yet here we are with a result that not only runs counter to your premise but will taught as an example of what not to do in business.</div><br/><div id="38378608" class="c"><input type="checkbox" id="c-38378608" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378545">parent</a><span>|</span><a href="#38377167">next</a><span>|</span><label class="collapse" for="c-38378608">[-]</label><label class="expand" for="c-38378608">[1 more]</label></div><br/><div class="children"><div class="content">What?</div><br/></div></div></div></div></div></div><div id="38377167" class="c"><input type="checkbox" id="c-38377167" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376947">parent</a><span>|</span><a href="#38377915">prev</a><span>|</span><a href="#38378575">next</a><span>|</span><label class="collapse" for="c-38377167">[-]</label><label class="expand" for="c-38377167">[6 more]</label></div><br/><div class="children"><div class="content">Yes, the original letter had (for an official letter) quite some serious allegations, insinuations. If after a week, they decided not to back up their claims, I&#x27;m not sure there is anything big coming.<p>On the other hand, if they had some serious concerns, serious enough to fire the CEO in such a disgraceful way, I don&#x27;t understand why they don&#x27;t stick to their guns, and explain themselves. If you think OpenAI under Sam&#x27;s leadership is going to destroy humanity, I don&#x27;t understand how they (e.g. Ilya) reverted their opinions after a day or two.</div><br/><div id="38377631" class="c"><input type="checkbox" id="c-38377631" checked=""/><div class="controls bullet"><span class="by">carlossouza</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377167">parent</a><span>|</span><a href="#38377410">next</a><span>|</span><label class="collapse" for="c-38377631">[-]</label><label class="expand" for="c-38377631">[4 more]</label></div><br/><div class="children"><div class="content">These board members failed miserably in their intent.<p>Also, they will find a hard time joining any other board from now on.<p>They should have backed up the claims in the letter. They didn’t.<p>This means they didn’t have how to backup their claims. They didn’t think it through… extremely amateurish behavior.</div><br/><div id="38377673" class="c"><input type="checkbox" id="c-38377673" checked=""/><div class="controls bullet"><span class="by">ZiiS</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377631">parent</a><span>|</span><a href="#38377410">next</a><span>|</span><label class="collapse" for="c-38377673">[-]</label><label class="expand" for="c-38377673">[3 more]</label></div><br/><div class="children"><div class="content">D&#x27;Angelo wasn&#x27;t even removed from this board; this is simply not how failing works at this level.</div><br/><div id="38378453" class="c"><input type="checkbox" id="c-38378453" checked=""/><div class="controls bullet"><span class="by">iowemoretohim</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377673">parent</a><span>|</span><a href="#38377776">next</a><span>|</span><label class="collapse" for="c-38378453">[-]</label><label class="expand" for="c-38378453">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s part of the selection panel but he won&#x27;t be a part of the new 9 member board.</div><br/></div></div><div id="38377776" class="c"><input type="checkbox" id="c-38377776" checked=""/><div class="controls bullet"><span class="by">richardwhiuk</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377673">parent</a><span>|</span><a href="#38378453">prev</a><span>|</span><a href="#38377410">next</a><span>|</span><label class="collapse" for="c-38377776">[-]</label><label class="expand" for="c-38377776">[1 more]</label></div><br/><div class="children"><div class="content">Yet</div><br/></div></div></div></div></div></div><div id="38377410" class="c"><input type="checkbox" id="c-38377410" checked=""/><div class="controls bullet"><span class="by">Kye</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377167">parent</a><span>|</span><a href="#38377631">prev</a><span>|</span><a href="#38378575">next</a><span>|</span><label class="collapse" for="c-38377410">[-]</label><label class="expand" for="c-38377410">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s possible the big, chaotic blowup forced some conversations that were easier to avoid in the normal day-to-day, and those conversations led to some vital resolution of concerns.</div><br/></div></div></div></div><div id="38378575" class="c"><input type="checkbox" id="c-38378575" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376947">parent</a><span>|</span><a href="#38377167">prev</a><span>|</span><a href="#38378329">next</a><span>|</span><label class="collapse" for="c-38378575">[-]</label><label class="expand" for="c-38378575">[3 more]</label></div><br/><div class="children"><div class="content">I agree with both the commenter above you and you.<p>Yes, you are right that the board had weak sauce reasoning for the firing (giving two teams the same project!?!).<p>That said, the other commenter is right that this is the beginning of the end.<p>One of the interesting things over the past few years watching the development of AI has been that in parallel to the demonstration of the limitations of neural networks has been many demonstrations of the limitations of human thinking and psychology.<p>Altman just got given a blank check and crowned as king of OpenAI. And whatever opposition he faced internally just lost all its footing.<p>That&#x27;s a terrible recipe for long term success.<p>Whatever the reasons for the firing, this outcome is going to completely screw their long term prospects, as no matter how wonderful a leader someone is, losing the reality check of empowered opposition results in terrible decisions being made unchecked.<p>He&#x27;s going to double down on chat interfaces because that&#x27;s been their unexpected bread and butter up until the point they get lapped by companies with broader product vision, and whatever elements at OpenAI shared that broader vision are going to get steamrolled now that he&#x27;s been given an unconditional green light until they jump ship over the next 18 months to work elsewhere.</div><br/><div id="38378928" class="c"><input type="checkbox" id="c-38378928" checked=""/><div class="controls bullet"><span class="by">nvm0n2</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378575">parent</a><span>|</span><a href="#38378329">next</a><span>|</span><label class="collapse" for="c-38378928">[-]</label><label class="expand" for="c-38378928">[2 more]</label></div><br/><div class="children"><div class="content">Not necessarily! Facebook has done great with its unfireable CEO. The FB board would certainly have fired him several times over by now if it could, and yet they&#x27;d have been wrong every time. And the Google cofounders would certainly have been kicked out of their own company if the board had been able to.</div><br/><div id="38380328" class="c"><input type="checkbox" id="c-38380328" checked=""/><div class="controls bullet"><span class="by">herostratus101</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378928">parent</a><span>|</span><a href="#38378329">next</a><span>|</span><label class="collapse" for="c-38380328">[-]</label><label class="expand" for="c-38380328">[1 more]</label></div><br/><div class="children"><div class="content">Yes, also Elon.</div><br/></div></div></div></div></div></div><div id="38378329" class="c"><input type="checkbox" id="c-38378329" checked=""/><div class="controls bullet"><span class="by">conception</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376947">parent</a><span>|</span><a href="#38378575">prev</a><span>|</span><a href="#38376566">next</a><span>|</span><label class="collapse" for="c-38378329">[-]</label><label class="expand" for="c-38378329">[1 more]</label></div><br/><div class="children"><div class="content">My guess is that the arguments are something along the lines of “OpenAIs current products are already causing harm or on the path to do so” or something similar damaging to the products. Something they are afraid of both having continue to move forward on and to having to communicate as it would damage the brand. Like “We already have reports of several hundred people killing themselves because of ChatGPT responses…” and everyone would say, “Oh that makes… wait what??”</div><br/></div></div></div></div><div id="38376566" class="c"><input type="checkbox" id="c-38376566" checked=""/><div class="controls bullet"><span class="by">clnq</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376947">prev</a><span>|</span><a href="#38377078">next</a><span>|</span><label class="collapse" for="c-38376566">[-]</label><label class="expand" for="c-38376566">[3 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is in fact not open<p>This meme was already dead before the recent events. Whatever the company was doing, you could say it wasn’t open enough.<p>&gt; a real disruptor must be brewing somewhere unnoticed, for now<p>Why pretend OpenAI hasn’t just disrupted our way of life with GPTs in the last two years? It has been the most high profile tech innovator recently.<p>&gt; OpenAI does not have in its DNA to win<p>This is so vague. What does it not have in its… fundamentals? And what is to “win”? This statement seems like just generic unhappiness without stating anything clearly. By most measures, they are winning. They have the best commercial LLM and continue to innovate, they have partnered with Microsoft heavily, and they have so far received very good funding.</div><br/><div id="38377470" class="c"><input type="checkbox" id="c-38377470" checked=""/><div class="controls bullet"><span class="by">absrec</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376566">parent</a><span>|</span><a href="#38378369">next</a><span>|</span><label class="collapse" for="c-38377470">[-]</label><label class="expand" for="c-38377470">[1 more]</label></div><br/><div class="children"><div class="content">They really need to drive down the amount of computation needed. The dependence on Microsoft is because of the monstrous computation requirements that will require many paid users to break even.<p>Leaving the economic side even to make the tech &#x27;greener&#x27; will be a challenge. OpenAI will win if they focus on making the models less compute intensive but it could be dangerous for them if they can&#x27;t.<p>I guess the OP&#x27;s brewing disruptor is some locally runnable Llama type model that does 80% of what ChatGPT does at a fraction of the cost.</div><br/></div></div><div id="38378369" class="c"><input type="checkbox" id="c-38378369" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376566">parent</a><span>|</span><a href="#38377470">prev</a><span>|</span><a href="#38377078">next</a><span>|</span><label class="collapse" for="c-38378369">[-]</label><label class="expand" for="c-38378369">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why pretend OpenAI hasn’t just disrupted our way of life with GPTs in the last two years?<p>It hasn&#x27;t disrupted mine in any way. It may do that in the future, but the  future isn&#x27;t here yet.</div><br/></div></div></div></div><div id="38377078" class="c"><input type="checkbox" id="c-38377078" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376566">prev</a><span>|</span><a href="#38377392">next</a><span>|</span><label class="collapse" for="c-38377078">[-]</label><label class="expand" for="c-38377078">[3 more]</label></div><br/><div class="children"><div class="content">Is it really a failure of critical thinking? The employees know what position is popular, so even people who are mostly against the go-fast strategy can see that they get to work on this groundbreaking thing only if they toe the line.<p>It&#x27;s also not surprising that people who are near the SV culture will think that AGI needs money to get developed, and that money in general is useful for the kind of business they are running. And that it&#x27;s a business, not a charity.<p>I mean if OpenAI had been born in the Soviet Union or Scandinavia, maybe people would have somewhat different values, it&#x27;s hard to know. But a thing that is founded by the posterboys for modern SV, it&#x27;s gotta lean towards &quot;money is mostly good&quot;.</div><br/><div id="38377575" class="c"><input type="checkbox" id="c-38377575" checked=""/><div class="controls bullet"><span class="by">qwytw</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377078">parent</a><span>|</span><a href="#38378163">next</a><span>|</span><label class="collapse" for="c-38377575">[-]</label><label class="expand" for="c-38377575">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Soviet Union<p>Or medieval Spain? About as likely... The Soviets weren&#x27;t even able to get the factory floors clean enough to consistently manufacture the 8086 10 years after it was already outdated.<p>&gt; maybe people would have somewhat different values, it&#x27;s hard to know. But a thing that is founded by the posterboys for modern SV, it&#x27;s gotta lean towards &quot;money is mostly good&quot;.<p>Unfortunately not other system besides capitalism has enabled consistent technological progress for 200+ years. Turns out you need to pool money and resources to achieve things ..</div><br/></div></div><div id="38378163" class="c"><input type="checkbox" id="c-38378163" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377078">parent</a><span>|</span><a href="#38377575">prev</a><span>|</span><a href="#38377392">next</a><span>|</span><label class="collapse" for="c-38378163">[-]</label><label class="expand" for="c-38378163">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I mean if OpenAI had been born in the Soviet Union or Scandinavia, maybe people would have somewhat different values, it&#x27;s hard to know.<p>Or in Arthurian times. Very different values.</div><br/></div></div></div></div><div id="38377392" class="c"><input type="checkbox" id="c-38377392" checked=""/><div class="controls bullet"><span class="by">ptero</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377078">prev</a><span>|</span><a href="#38376463">next</a><span>|</span><label class="collapse" for="c-38377392">[-]</label><label class="expand" for="c-38377392">[1 more]</label></div><br/><div class="children"><div class="content">I do not see an overwhelming groupthink. I see a perfectly rational (and not in any way evil) reaction to a complete mess created by the board.<p>Most are doing the work they love and four people almost destroy it and cannot even explain why they did it. If I were working at the company that did this I would sign, too. And follow through on the threat of leaving if it comes to that.</div><br/></div></div><div id="38376463" class="c"><input type="checkbox" id="c-38376463" checked=""/><div class="controls bullet"><span class="by">jakey_bakey</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377392">prev</a><span>|</span><a href="#38379188">next</a><span>|</span><label class="collapse" for="c-38376463">[-]</label><label class="expand" for="c-38376463">[10 more]</label></div><br/><div class="children"><div class="content">It wasn&#x27;t necessarily groupthink - there was profound pressure from team Sam to sign that petition. What&#x27;s going to happen to your career when you were one of the 200 who held out initially?</div><br/><div id="38376543" class="c"><input type="checkbox" id="c-38376543" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376576">next</a><span>|</span><label class="collapse" for="c-38376543">[-]</label><label class="expand" for="c-38376543">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s going to happen to your career when you were one of the 200 who held out initially?<p>Anthropic formed from people who split from OpenAI, and xAI in response to either the company or ChatGPT, so people would have plenty of options.<p>If the staff had as little to go on as the rest of us, then the board did something <i>that looked</i> wild and unpredictable, which is an acute employment threat all by itself.</div><br/><div id="38377668" class="c"><input type="checkbox" id="c-38377668" checked=""/><div class="controls bullet"><span class="by">voster</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376543">parent</a><span>|</span><a href="#38376576">next</a><span>|</span><label class="collapse" for="c-38377668">[-]</label><label class="expand" for="c-38377668">[1 more]</label></div><br/><div class="children"><div class="content">That burns bridges with people in OpenAI<p>People underestimate the effects of social pressure, and losing social connections. Ilya voted for Sam&#x27;s firing, but was quickly socially isolated as a result<p>That&#x27;s not to say people didn&#x27;t genuinely feel committed to Sam or his leadership. Just that they also took into account that the community is relatively small and people remember you and your actions</div><br/></div></div></div></div><div id="38376576" class="c"><input type="checkbox" id="c-38376576" checked=""/><div class="controls bullet"><span class="by">dereg</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376543">prev</a><span>|</span><a href="#38376495">next</a><span>|</span><label class="collapse" for="c-38376576">[-]</label><label class="expand" for="c-38376576">[1 more]</label></div><br/><div class="children"><div class="content">There weren’t 200 holdouts. It was like 5 AM over there. I don’t know why you are surprised that people who work at OpenAI would want to work at OpenAI, esp over Microsoft?</div><br/></div></div><div id="38376495" class="c"><input type="checkbox" id="c-38376495" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376576">prev</a><span>|</span><a href="#38376482">next</a><span>|</span><label class="collapse" for="c-38376495">[-]</label><label class="expand" for="c-38376495">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that one of the causes of group think?</div><br/><div id="38377062" class="c"><input type="checkbox" id="c-38377062" checked=""/><div class="controls bullet"><span class="by">Kathula</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376495">parent</a><span>|</span><a href="#38376482">next</a><span>|</span><label class="collapse" for="c-38377062">[-]</label><label class="expand" for="c-38377062">[1 more]</label></div><br/><div class="children"><div class="content">Folding for pressure and group think is different things imo. You can be very aware you are folding for pressure, but doing it because it&#x27;s the right&#x2F;easy thing to do. While group think is more a phenomenon you are not aware of at all.</div><br/></div></div></div></div><div id="38376482" class="c"><input type="checkbox" id="c-38376482" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376495">prev</a><span>|</span><a href="#38377087">next</a><span>|</span><label class="collapse" for="c-38376482">[-]</label><label class="expand" for="c-38376482">[1 more]</label></div><br/><div class="children"><div class="content">Go work somewhere else? The reason being you din&#x27;t like that amount of drama?</div><br/></div></div><div id="38377087" class="c"><input type="checkbox" id="c-38377087" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376482">prev</a><span>|</span><a href="#38376783">next</a><span>|</span><label class="collapse" for="c-38377087">[-]</label><label class="expand" for="c-38377087">[1 more]</label></div><br/><div class="children"><div class="content">They can just work somewhere else with relative ease. Some OpenAI employees on Twitter said they were being bombarded by recruiters throughout until tonight&#x27;s resolution. People have left OpenAI before and they are doing just fine.</div><br/></div></div><div id="38376783" class="c"><input type="checkbox" id="c-38376783" checked=""/><div class="controls bullet"><span class="by">mcosta</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38377087">prev</a><span>|</span><a href="#38378428">next</a><span>|</span><label class="collapse" for="c-38376783">[-]</label><label class="expand" for="c-38376783">[1 more]</label></div><br/><div class="children"><div class="content">How do you know that?</div><br/></div></div><div id="38378428" class="c"><input type="checkbox" id="c-38378428" checked=""/><div class="controls bullet"><span class="by">jmcgough</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376783">prev</a><span>|</span><a href="#38379188">next</a><span>|</span><label class="collapse" for="c-38378428">[-]</label><label class="expand" for="c-38378428">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s going to happen to your career when you were one of the 200 who held out initially?<p>Not to mention Roko&#x27;s basilisk &#x2F;s</div><br/></div></div></div></div><div id="38379188" class="c"><input type="checkbox" id="c-38379188" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376463">prev</a><span>|</span><a href="#38376181">next</a><span>|</span><label class="collapse" for="c-38379188">[-]</label><label class="expand" for="c-38379188">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Disappointing outcome.<p>The employees of a tech company banded together to get what they wanted, force a leadership change, evict the leaders they disagreed with, secure the return of the leadership they wanted, and restored the value of their hard-earned equity.<p>This certainly isn’t a disappointing outcome for the employees! I thought HN would be ecstatic about tech employees banding together to force action in their favor, but the comments here are surprisingly negative.</div><br/></div></div><div id="38376181" class="c"><input type="checkbox" id="c-38376181" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38379188">prev</a><span>|</span><a href="#38377017">next</a><span>|</span><label class="collapse" for="c-38376181">[-]</label><label class="expand" for="c-38376181">[2 more]</label></div><br/><div class="children"><div class="content">A lot of this comes down to processing power though. That&#x27;s why Microsoft had so much leverage with both factions in this fight. It actually gives them a pretty good moat above and beyond their head start. There aren&#x27;t too many companies with the hardware to compete, let alone talent.</div><br/><div id="38376554" class="c"><input type="checkbox" id="c-38376554" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376181">parent</a><span>|</span><a href="#38377017">next</a><span>|</span><label class="collapse" for="c-38376554">[-]</label><label class="expand" for="c-38376554">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. Perhaps a reason for public AI [1], which advocates for a publicly funded option where a player like MSFT can&#x27;t push around something like OpenAI so forcefully.<p>[1]: <a href="https:&#x2F;&#x2F;lu.ma&#x2F;zo0vnony" rel="nofollow noreferrer">https:&#x2F;&#x2F;lu.ma&#x2F;zo0vnony</a></div><br/></div></div></div></div><div id="38377017" class="c"><input type="checkbox" id="c-38377017" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376181">prev</a><span>|</span><a href="#38377145">next</a><span>|</span><label class="collapse" for="c-38377017">[-]</label><label class="expand" for="c-38377017">[1 more]</label></div><br/><div class="children"><div class="content">The board never gave a believable explanation to justify firing Altman. So the staff simply made the sensible choice of following Altman. This isn&#x27;t about critical thinking because there was nothing to think about.</div><br/></div></div><div id="38377145" class="c"><input type="checkbox" id="c-38377145" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377017">prev</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38377145">[-]</label><label class="expand" for="c-38377145">[11 more]</label></div><br/><div class="children"><div class="content">Regardless of whether you feel like Altman was rushing OpenAI too fast, wasn’t open enough, and was being too commercial, the last few days demonstrated conclusively that the board is erratic and unstable and unfit to manage OpenAI.<p>Their actions was the complete opposite of open. Rather than, I don’t know, being open and talking to the CEO to share concerns and change the company, they just threw a tantrum and fired him.</div><br/><div id="38377996" class="c"><input type="checkbox" id="c-38377996" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377145">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38377996">[-]</label><label class="expand" for="c-38377996">[10 more]</label></div><br/><div class="children"><div class="content">They fired him (you don’t know the backstory) and published a press release and then Sam was seen back in the offices. Prior to the reinstatement (today), there was nothing except HN hysteria and media conjecture that made the board look extremely unstable.</div><br/><div id="38378048" class="c"><input type="checkbox" id="c-38378048" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377996">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38378048">[-]</label><label class="expand" for="c-38378048">[9 more]</label></div><br/><div class="children"><div class="content">??? They fired him on friday with a statement knifing him in the back, un-fired him on tuesday, and now the board is resigning? How is that not erratic and unstable?</div><br/><div id="38378101" class="c"><input type="checkbox" id="c-38378101" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378048">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38378101">[-]</label><label class="expand" for="c-38378101">[8 more]</label></div><br/><div class="children"><div class="content">Note that I just stated, <i>up until reinstatement</i> their actions weren’t erratic.<p>Now, yes, they definitely are.<p>IMO OpenAI’s governance is far less trustworthy today than it was yesterday.</div><br/><div id="38378716" class="c"><input type="checkbox" id="c-38378716" checked=""/><div class="controls bullet"><span class="by">broast</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378101">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38378716">[-]</label><label class="expand" for="c-38378716">[7 more]</label></div><br/><div class="children"><div class="content">I found the board members own words to be quite erratic between Friday and today, such as Ilya saying he wished he didn&#x27;t participate in the boards actions.</div><br/><div id="38378949" class="c"><input type="checkbox" id="c-38378949" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378716">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38378949">[-]</label><label class="expand" for="c-38378949">[6 more]</label></div><br/><div class="children"><div class="content">It would be completely understandable to regret when your action against someone causes them to fall upwards</div><br/><div id="38379715" class="c"><input type="checkbox" id="c-38379715" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38378949">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38379715">[-]</label><label class="expand" for="c-38379715">[5 more]</label></div><br/><div class="children"><div class="content">What? Do you think it would be understandable for a board member to regret firing the CEO because of his career path post-firing?</div><br/><div id="38379867" class="c"><input type="checkbox" id="c-38379867" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379715">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38379867">[-]</label><label class="expand" for="c-38379867">[4 more]</label></div><br/><div class="children"><div class="content">If Ilya was concerned about dangerously fast commercialization, which seems to have been a point of tension between them for a while now, then yes.</div><br/><div id="38380126" class="c"><input type="checkbox" id="c-38380126" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38379867">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38380126">[-]</label><label class="expand" for="c-38380126">[3 more]</label></div><br/><div class="children"><div class="content">But he&#x27;s acting as a board member firing the CEO because he arguably believes it&#x27;s the right thing to do for the company. If he then changes his mind because the fired CEO continued a successful career then I&#x27;d say that decision was more on a personal level than for the wellbeing of the company.</div><br/><div id="38380249" class="c"><input type="checkbox" id="c-38380249" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380126">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38380249">[-]</label><label class="expand" for="c-38380249">[2 more]</label></div><br/><div class="children"><div class="content">His obligation as a member of the board is to safeguard AI, <i>not</i> OpenAI. That&#x27;s why in the employee open letter they said, &quot;the board said it&#x27;d be compliant with the mission to destroy the company.&quot; This is <i>actually</i> true.<p>It&#x27;s absolutely believable that at first he thought the best way to safeguard AI was to get rid of the main advocate for profit-seeking at OpenAI, then when that person &quot;fell upward&quot; into a position where he&#x27;d have <i>fewer</i> constraints, to regret that decision.</div><br/><div id="38380462" class="c"><input type="checkbox" id="c-38380462" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38380249">parent</a><span>|</span><a href="#38377214">next</a><span>|</span><label class="collapse" for="c-38380462">[-]</label><label class="expand" for="c-38380462">[1 more]</label></div><br/><div class="children"><div class="content">Fair enough, I understand better where you&#x27;re coming from. Thanks!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38377214" class="c"><input type="checkbox" id="c-38377214" checked=""/><div class="controls bullet"><span class="by">rinze</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377145">prev</a><span>|</span><a href="#38377803">next</a><span>|</span><label class="collapse" for="c-38377214">[-]</label><label class="expand" for="c-38377214">[1 more]</label></div><br/><div class="children"><div class="content">Matt Levine&#x27;s &quot;slightly annotated diagram&quot; in one of his latest newsletters tells the story quite well, I think: <a href="https:&#x2F;&#x2F;newsletterhunt.com&#x2F;emails&#x2F;42469" rel="nofollow noreferrer">https:&#x2F;&#x2F;newsletterhunt.com&#x2F;emails&#x2F;42469</a></div><br/></div></div><div id="38377803" class="c"><input type="checkbox" id="c-38377803" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377214">prev</a><span>|</span><a href="#38376311">next</a><span>|</span><label class="collapse" for="c-38377803">[-]</label><label class="expand" for="c-38377803">[1 more]</label></div><br/><div class="children"><div class="content">Outcome? You mean OpenAI wakes up with no memories of the night before, finding their suite trashed, a tiger in the bathroom, a baby in the closet, and the groom missing and the story will end here?<p>I just renewed by HN subscription to be able to see Season 2!</div><br/></div></div><div id="38376311" class="c"><input type="checkbox" id="c-38376311" checked=""/><div class="controls bullet"><span class="by">haunter</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377803">prev</a><span>|</span><a href="#38377891">next</a><span>|</span><label class="collapse" for="c-38376311">[-]</label><label class="expand" for="c-38376311">[25 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is in fact not open<p>Apple is also not an apple</div><br/><div id="38376467" class="c"><input type="checkbox" id="c-38376467" checked=""/><div class="controls bullet"><span class="by">smt88</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376432">next</a><span>|</span><label class="collapse" for="c-38376467">[-]</label><label class="expand" for="c-38376467">[10 more]</label></div><br/><div class="children"><div class="content">Apple has no by-laws committing itself to being an apple.<p>This line of argument is facile and destructive to conversation anyway.<p>It boils down to, &quot;Pointing out corporate hypocrisy isn&#x27;t valuable because corporations are liars,&quot; and (worse) it implies the other person is naive.<p>In reality, we can and should be outraged when corporations betray their own statements and supposed values.</div><br/><div id="38377598" class="c"><input type="checkbox" id="c-38377598" checked=""/><div class="controls bullet"><span class="by">Wytwwww</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376467">parent</a><span>|</span><a href="#38376651">next</a><span>|</span><label class="collapse" for="c-38377598">[-]</label><label class="expand" for="c-38377598">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Apple has no by-laws committing itself to being an apple.<p>Does OpenAI have by-laws committing itself to being &quot;open&quot; (as in open source or at least their products freely and universally available)? I thought  their goals were the complete opposite of that?<p>Unfortunately, in reality Facebook&#x2F;Meta seems to be more open than &quot;Open&quot;AI.</div><br/><div id="38377783" class="c"><input type="checkbox" id="c-38377783" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377598">parent</a><span>|</span><a href="#38376651">next</a><span>|</span><label class="collapse" for="c-38377783">[-]</label><label class="expand" for="c-38377783">[1 more]</label></div><br/><div class="children"><div class="content">This is spot on.  Open was the wrong word to choose for their name, and in the technology space means nearly the opposite of the charter&#x27;s intention.  BeneficialAI would have been more &quot;aligned&quot; with their claimed mission.  They have made their position quite clear - the creation of an AGI that is safe and benefits all humanity requires a closed process that limits who can have access to it.  I understand their theoretical concerns, but the desire for a &quot;benevolent dictator&quot; goes back to at least Plato and always ends in tears.</div><br/></div></div></div></div><div id="38376651" class="c"><input type="checkbox" id="c-38376651" checked=""/><div class="controls bullet"><span class="by">khazhoux</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376467">parent</a><span>|</span><a href="#38377598">prev</a><span>|</span><a href="#38378796">next</a><span>|</span><label class="collapse" for="c-38376651">[-]</label><label class="expand" for="c-38376651">[6 more]</label></div><br/><div class="children"><div class="content">&gt; In reality, we can and should be outraged when corporations betray their own statements and supposed values.<p>There are only three groups of people who could be subject to betrayal here:  employees, investors, and customers.  Clearly they did not betray employees or investors, since they largely sided with Sam.  As for customers, that&#x27;s harder to gauge -- did people sign up for ChatGPT with the explicit expectation that the research would be &quot;open&quot;?<p>The founding charter said one thing, but the majority of the company and investors went in a different direction.  That&#x27;s not a betrayal, but a pivot.</div><br/><div id="38376806" class="c"><input type="checkbox" id="c-38376806" checked=""/><div class="controls bullet"><span class="by">Angostura</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376651">parent</a><span>|</span><a href="#38384792">next</a><span>|</span><label class="collapse" for="c-38376806">[-]</label><label class="expand" for="c-38376806">[3 more]</label></div><br/><div class="children"><div class="content">I think there’s an additional group to consider- society at large.<p>To an extent the promise of the non- profit was that they would be safe, expert custodians of AI development driven not primarily by the profit motive, but also by safety and societal considerations. Has this larger group been ‘betrayed’? Perhaps</div><br/><div id="38377479" class="c"><input type="checkbox" id="c-38377479" checked=""/><div class="controls bullet"><span class="by">biscottigelato</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376806">parent</a><span>|</span><a href="#38377615">next</a><span>|</span><label class="collapse" for="c-38377479">[-]</label><label class="expand" for="c-38377479">[1 more]</label></div><br/><div class="children"><div class="content">Also donors. They received a ton of donations when they were a pure non-profit from people that got no board seat, no equities, with the believe that they will stick to their mission.</div><br/></div></div><div id="38377615" class="c"><input type="checkbox" id="c-38377615" checked=""/><div class="controls bullet"><span class="by">Wytwwww</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376806">parent</a><span>|</span><a href="#38377479">prev</a><span>|</span><a href="#38384792">next</a><span>|</span><label class="collapse" for="c-38377615">[-]</label><label class="expand" for="c-38377615">[1 more]</label></div><br/><div class="children"><div class="content">Not unless we believe that OpenAI is somehow &quot;special&quot; and unique and the only company that is capable of building AGI(or whatever).</div><br/></div></div></div></div><div id="38384792" class="c"><input type="checkbox" id="c-38384792" checked=""/><div class="controls bullet"><span class="by">denton-scratch</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376651">parent</a><span>|</span><a href="#38376806">prev</a><span>|</span><a href="#38377728">next</a><span>|</span><label class="collapse" for="c-38384792">[-]</label><label class="expand" for="c-38384792">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There are only three groups of people who could be subject to betrayal here<p>GP didn&#x27;t speak of betraying people; he spoke of betraying <i>their own statements</i>. That just means doing what you said you wouldn&#x27;t; it doesn&#x27;t mean anyone was stabbed in the back.</div><br/></div></div><div id="38377728" class="c"><input type="checkbox" id="c-38377728" checked=""/><div class="controls bullet"><span class="by">master-lincoln</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376651">parent</a><span>|</span><a href="#38384792">prev</a><span>|</span><a href="#38378796">next</a><span>|</span><label class="collapse" for="c-38377728">[-]</label><label class="expand" for="c-38377728">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Clearly they did not betray employees or investors, since they largely sided with Sam<p>Just because they sided with Altman doesn&#x27;t necessarily mean they are aligned. There could be a lack of information on the employee&#x2F;investor side.</div><br/></div></div></div></div><div id="38378796" class="c"><input type="checkbox" id="c-38378796" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376467">parent</a><span>|</span><a href="#38376651">prev</a><span>|</span><a href="#38376432">next</a><span>|</span><label class="collapse" for="c-38378796">[-]</label><label class="expand" for="c-38378796">[1 more]</label></div><br/><div class="children"><div class="content">It does seem that the hypocrisy was baked in from the beginning.  In the tech world &#x27;open&#x27; implied open source but OpenAI wanted to benefit from a marketing itself as something like Linux when internally it was something like Microsoft.<p>Corporations have no values whatsoever and their statements only mean anything when expressed in terms of a legally binding contract.  All corporate value statements should be viewed as nothing more than the kind of self-serving statements that an amoral narcissitic sociopath would make to protect their own interests.</div><br/></div></div></div></div><div id="38376432" class="c"><input type="checkbox" id="c-38376432" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376467">prev</a><span>|</span><a href="#38376494">next</a><span>|</span><label class="collapse" for="c-38376432">[-]</label><label class="expand" for="c-38376432">[5 more]</label></div><br/><div class="children"><div class="content">Pretty sure Apple never aimed to be an Apple.</div><br/><div id="38377732" class="c"><input type="checkbox" id="c-38377732" checked=""/><div class="controls bullet"><span class="by">monoscient</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376432">parent</a><span>|</span><a href="#38376487">next</a><span>|</span><label class="collapse" for="c-38377732">[-]</label><label class="expand" for="c-38377732">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s actually one of the most spectacular failures in business history, but we don&#x27;t talk much about it</div><br/></div></div><div id="38376487" class="c"><input type="checkbox" id="c-38376487" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376432">parent</a><span>|</span><a href="#38377732">prev</a><span>|</span><a href="#38376520">next</a><span>|</span><label class="collapse" for="c-38376487">[-]</label><label class="expand" for="c-38376487">[2 more]</label></div><br/><div class="children"><div class="content">They sure sued a lot of apple places over having an apple as logo.</div><br/><div id="38377658" class="c"><input type="checkbox" id="c-38377658" checked=""/><div class="controls bullet"><span class="by">_Algernon_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376487">parent</a><span>|</span><a href="#38376520">next</a><span>|</span><label class="collapse" for="c-38377658">[-]</label><label class="expand" for="c-38377658">[1 more]</label></div><br/><div class="children"><div class="content">If having an apple logo makes a company an apple, then Apple is in fact an apple</div><br/></div></div></div></div><div id="38376520" class="c"><input type="checkbox" id="c-38376520" checked=""/><div class="controls bullet"><span class="by">sam_lowry_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376432">parent</a><span>|</span><a href="#38376487">prev</a><span>|</span><a href="#38376494">next</a><span>|</span><label class="collapse" for="c-38376520">[-]</label><label class="expand" for="c-38376520">[1 more]</label></div><br/><div class="children"><div class="content">But The Apple.</div><br/></div></div></div></div><div id="38376494" class="c"><input type="checkbox" id="c-38376494" checked=""/><div class="controls bullet"><span class="by">colinsane</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376432">prev</a><span>|</span><a href="#38376717">next</a><span>|</span><label class="collapse" for="c-38376494">[-]</label><label class="expand" for="c-38376494">[5 more]</label></div><br/><div class="children"><div class="content">did the &quot;Open&quot; in OpenAI not originally refer to open in the academic or open source manner? i only learned about OpenAI in the GPT-2 days, when they released it openly and it was still small enough that i ran it on my laptop: i just assumed they had always acted according to their literal name up through that point.</div><br/><div id="38376557" class="c"><input type="checkbox" id="c-38376557" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376494">parent</a><span>|</span><a href="#38376525">next</a><span>|</span><label class="collapse" for="c-38376557">[-]</label><label class="expand" for="c-38376557">[3 more]</label></div><br/><div class="children"><div class="content">This has been a common misinterpretation since very early in OpenAI&#x27;s history (and a somewhat convenient one for OpenAI).<p>From a 2016 New Yorker article:<p>&gt;  Dario Amodei said, &quot;[People in the field] are saying that the goal of OpenAI is to build a friendly A.I. and then release its source code into the world.”<p>&gt; “We don’t plan to release all of our source code,” Altman said. “But let’s please not try to correct that. That usually only makes it worse.”<p>source: <a href="https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2016&#x2F;10&#x2F;10&#x2F;sam-altmans-manifest-destiny" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2016&#x2F;10&#x2F;10&#x2F;sam-altmans-ma...</a></div><br/><div id="38377610" class="c"><input type="checkbox" id="c-38377610" checked=""/><div class="controls bullet"><span class="by">olau</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376557">parent</a><span>|</span><a href="#38376525">next</a><span>|</span><label class="collapse" for="c-38377610">[-]</label><label class="expand" for="c-38377610">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure this is a correct characterization. Lex Fridman interviewed Elon Musk recently where Musk says that the &quot;open&quot; was supposed to stand for &quot;open source&quot;.<p>To be fair, Fridman grilled Musk on his views today, also in the context of xAI, and he was less clear cut there, talking about the problem that there&#x27;s actually very little source code, it&#x27;s mostly about the data.</div><br/><div id="38378108" class="c"><input type="checkbox" id="c-38378108" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377610">parent</a><span>|</span><a href="#38376525">next</a><span>|</span><label class="collapse" for="c-38378108">[-]</label><label class="expand" for="c-38378108">[1 more]</label></div><br/><div class="children"><div class="content">Altman appears to be in the driving seat, so it doesn&#x27;t matter what other people are saying, the point is &quot;Open&quot; is not being used here to the open source context _but_ they definitely dont try to correct anyone who thinks they&#x27;re providing open source products.</div><br/></div></div></div></div></div></div><div id="38376525" class="c"><input type="checkbox" id="c-38376525" checked=""/><div class="controls bullet"><span class="by">SuchAnonMuchWow</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376494">parent</a><span>|</span><a href="#38376557">prev</a><span>|</span><a href="#38376717">next</a><span>|</span><label class="collapse" for="c-38376525">[-]</label><label class="expand" for="c-38376525">[1 more]</label></div><br/><div class="children"><div class="content">Except that view point fell even earlier when they refused to release their models after GPT-2.</div><br/></div></div></div></div><div id="38376717" class="c"><input type="checkbox" id="c-38376717" checked=""/><div class="controls bullet"><span class="by">sangeeth96</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376494">prev</a><span>|</span><a href="#38381872">next</a><span>|</span><label class="collapse" for="c-38376717">[-]</label><label class="expand" for="c-38376717">[1 more]</label></div><br/><div class="children"><div class="content">I got news for you pal: <a href="https:&#x2F;&#x2F;www.wired.co.uk&#x2F;article&#x2F;apple-vs-apples-trademark-battle" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wired.co.uk&#x2F;article&#x2F;apple-vs-apples-trademark-ba...</a></div><br/></div></div><div id="38381872" class="c"><input type="checkbox" id="c-38381872" checked=""/><div class="controls bullet"><span class="by">rurp</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376717">prev</a><span>|</span><a href="#38379062">next</a><span>|</span><label class="collapse" for="c-38381872">[-]</label><label class="expand" for="c-38381872">[1 more]</label></div><br/><div class="children"><div class="content">Did Apple raise funds and spend a lot of time promoting itself as a giant apple that would feed humanity?</div><br/></div></div><div id="38379062" class="c"><input type="checkbox" id="c-38379062" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38381872">prev</a><span>|</span><a href="#38376626">next</a><span>|</span><label class="collapse" for="c-38379062">[-]</label><label class="expand" for="c-38379062">[1 more]</label></div><br/><div class="children"><div class="content">these are the vapid, pedantic hot takes we all come here for. thanks.</div><br/></div></div><div id="38376626" class="c"><input type="checkbox" id="c-38376626" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38379062">prev</a><span>|</span><a href="#38377891">next</a><span>|</span><label class="collapse" for="c-38376626">[-]</label><label class="expand" for="c-38376626">[1 more]</label></div><br/><div class="children"><div class="content">Yes!</div><br/></div></div></div></div><div id="38377891" class="c"><input type="checkbox" id="c-38377891" checked=""/><div class="controls bullet"><span class="by">rafaelero</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376311">prev</a><span>|</span><a href="#38377985">next</a><span>|</span><label class="collapse" for="c-38377891">[-]</label><label class="expand" for="c-38377891">[1 more]</label></div><br/><div class="children"><div class="content">Which critical thinking could they exercise if no believable reasons were given for this whole mess? Maybe it&#x27;s you who need to more carefully assess this situation.</div><br/></div></div><div id="38377985" class="c"><input type="checkbox" id="c-38377985" checked=""/><div class="controls bullet"><span class="by">buro9</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377891">prev</a><span>|</span><a href="#38377411">next</a><span>|</span><label class="collapse" for="c-38377985">[-]</label><label class="expand" for="c-38377985">[1 more]</label></div><br/><div class="children"><div class="content">in the end, maybe Sam was the instigator, the board tried to defend (and failed) and what we just witnessed from afar was just a power play to change the structure of OpenAI (or at least the outcome for Sam and many others) towards profit rather than non-profit.<p>we&#x27;ll all likely never know what truly happened, but it&#x27;s a shame that the board has lost their last remnant of some diversity and at the moment appears to be composed of rich Western white males... even if they rushed for profit, I&#x27;d have more faith in the potential upside what could be a sea change in the World, if those involved reflected more experiences than are currently gathered at that table.</div><br/></div></div><div id="38377411" class="c"><input type="checkbox" id="c-38377411" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377985">prev</a><span>|</span><a href="#38377545">next</a><span>|</span><label class="collapse" for="c-38377411">[-]</label><label class="expand" for="c-38377411">[2 more]</label></div><br/><div class="children"><div class="content">I find the outcome very satisfying. The OpenAI API is here to stay and grow, and I can build software on top of it. Hopefully other players will open up their APIs soon as well, so that there is a reasonable choice.</div><br/><div id="38381808" class="c"><input type="checkbox" id="c-38381808" checked=""/><div class="controls bullet"><span class="by">jetsetk</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38377411">parent</a><span>|</span><a href="#38377545">next</a><span>|</span><label class="collapse" for="c-38381808">[-]</label><label class="expand" for="c-38381808">[1 more]</label></div><br/><div class="children"><div class="content">Not a given that it is here to stay and grow after the company showed itself in such a chaotic state. Also, they need a profitable product - it is not like they are selling Iphones and such..</div><br/></div></div></div></div><div id="38377545" class="c"><input type="checkbox" id="c-38377545" checked=""/><div class="controls bullet"><span class="by">chriskanan</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377411">prev</a><span>|</span><a href="#38379289">next</a><span>|</span><label class="collapse" for="c-38377545">[-]</label><label class="expand" for="c-38377545">[1 more]</label></div><br/><div class="children"><div class="content">While I certainly agree that OpenAI isn&#x27;t open and is effectively controlled by Microsoft, I&#x27;m not following the &quot;groupthink&quot; claims based on what just happened. If I&#x27;d been given the very fishy and vague reasons that it sounds like their staff were given, I think any rational person would be highly suspicious of the board, especially since some believe in fringe ideas, have COIs, or can be perceived as being jealous that they aren&#x27;t the &quot;face&quot; of OpenAI.</div><br/></div></div><div id="38379289" class="c"><input type="checkbox" id="c-38379289" checked=""/><div class="controls bullet"><span class="by">anandrm</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38377545">prev</a><span>|</span><a href="#38379435">next</a><span>|</span><label class="collapse" for="c-38379289">[-]</label><label class="expand" for="c-38379289">[1 more]</label></div><br/><div class="children"><div class="content">I have been working for various software companies at different capacities. Never did i see 90%+ employees care about their CEO . In a small 10 member startup maybe its true. Are there any OpenAI employees here to confirm that .. their CEO really matters ... I mean how many employee revolted when Steve Jobs was fired .. Do Microsoft and Google employees really care ?</div><br/></div></div><div id="38379435" class="c"><input type="checkbox" id="c-38379435" checked=""/><div class="controls bullet"><span class="by">dalbasal</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38379289">prev</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38379435">[-]</label><label class="expand" for="c-38379435">[1 more]</label></div><br/><div class="children"><div class="content">Yes...<p>Investors and executives.. everyone in 2023 is hyper focused on &quot;Thiel Monopoly.&quot;<p>Platform, moat, aggregation theory, network effects, first mover advantages.. all those ways of thinking about it.<p>There&#x27;s no point in being bing to Google&#x27;s AdWords... So the big question is pathway to being the adWords. &quot;Winning.&quot; That&#x27;s the paradigm. This is where big returns will be.<p>However.. we should always remember, but the future is harder to see from the past. Post fact analysis, can often make things seem a lot simpler and more inevitable than they ever were.<p>It&#x27;s not clear what a winner even is here. What are the bottlenecks to be controlled. What are the business models, revenue sources. What represents the &quot;LLM Google,&quot; America online, Yahoo or a 90s dumb pipe.<p>FYIW I think all the big text have powerful plays available.. including keeping powder dry.<p>No doubt that proximity to openAI, control, influence, access to IP.. all strategic assets. That&#x27;s why they&#x27;re all invested an involved in the consortium.<p>That said assets or not strategies. It&#x27;s hard to have strategies when  strategic goals are unclear.<p>You can nominate a strategic goal from here, try to stay upstream, make exploratory investments and bets... There is no rush for the prize, unless the price is known.<p>Obviously, I&#x27;m assuming the prixe is not AGI and a solution to everything... That kind of abstraction is useful, but I do not think it&#x27;s operative.<p>It&#x27;s not a race currently, to see who&#x27;s R&amp;D lab turns on the first super intelligent consciousness.<p>Assuming I&#x27;m correct on that, we really have no idea which applications LLM capabilities companies are actually competing for.</div><br/></div></div></div></div><div id="38375535" class="c"><input type="checkbox" id="c-38375535" checked=""/><div class="controls bullet"><span class="by">halfjoking</span><span>|</span><a href="#38375859">prev</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38375535">[-]</label><label class="expand" for="c-38375535">[18 more]</label></div><br/><div class="children"><div class="content">Still think this was CIA operation to get OpenAI in hands of US government and big tech.<p>Former Secretary, SalesForce CEO who was board chair of Twitter when infiltrated with FBI [1] and the fall-guy for the coup is the new board?  Not one person from the actual company - not even Greg who did nothing wrong???  [1] - <a href="https:&#x2F;&#x2F;twitter.com&#x2F;NameRedacted247&#x2F;status&#x2F;1634021149997686785" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;NameRedacted247&#x2F;status&#x2F;16340211499976867...</a><p>The two think-tank women who made all this happen conveniently leave so we never talk about them again.<p>Whatever, as long as I can use their API.</div><br/><div id="38376411" class="c"><input type="checkbox" id="c-38376411" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375535">parent</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38376411">[-]</label><label class="expand" for="c-38376411">[7 more]</label></div><br/><div class="children"><div class="content">US companies don&#x27;t need to be &quot;in the hands of the government&quot;, we have rule of law.<p>And Helen Toner was already as much of a fed as you could want; she had exactly the resume a CIA agent would have. (Probably wasn&#x27;t though.)</div><br/><div id="38377311" class="c"><input type="checkbox" id="c-38377311" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376411">parent</a><span>|</span><a href="#38382188">next</a><span>|</span><label class="collapse" for="c-38377311">[-]</label><label class="expand" for="c-38377311">[2 more]</label></div><br/><div class="children"><div class="content">Rule of law that can be altered at any moment Patriot Act style is hardly reassuring.</div><br/><div id="38378353" class="c"><input type="checkbox" id="c-38378353" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38377311">parent</a><span>|</span><a href="#38382188">next</a><span>|</span><label class="collapse" for="c-38378353">[-]</label><label class="expand" for="c-38378353">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how you know it&#x27;s working.</div><br/></div></div></div></div><div id="38382188" class="c"><input type="checkbox" id="c-38382188" checked=""/><div class="controls bullet"><span class="by">mcmcmc</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376411">parent</a><span>|</span><a href="#38377311">prev</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38382188">[-]</label><label class="expand" for="c-38382188">[4 more]</label></div><br/><div class="children"><div class="content">By rule of law do you mean rule of lobbyists? Laws don&#x27;t apply to people with wealth and connections.</div><br/><div id="38385265" class="c"><input type="checkbox" id="c-38385265" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38382188">parent</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38385265">[-]</label><label class="expand" for="c-38385265">[3 more]</label></div><br/><div class="children"><div class="content">Without looking it up, what happened to the second biggest donor to the Democrats this year?<p>Is Donald Trump allowed to run a charity in New York?</div><br/><div id="38386413" class="c"><input type="checkbox" id="c-38386413" checked=""/><div class="controls bullet"><span class="by">mcmcmc</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38385265">parent</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38386413">[-]</label><label class="expand" for="c-38386413">[2 more]</label></div><br/><div class="children"><div class="content">So two blatant criminals got caught, big whoop. SBF broke rule number 1 - don&#x27;t fuck with rich people&#x27;s money.</div><br/><div id="38386895" class="c"><input type="checkbox" id="c-38386895" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38386413">parent</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38386895">[-]</label><label class="expand" for="c-38386895">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re obviously just coping here. FTX was the &quot;rich connected people&quot;, there weren&#x27;t other even richer connecteder people.<p>(It&#x27;s also totally possible FTX still has everyone&#x27;s money. They own a lot of Anthropic shares that are really valuable. But he&#x27;s still been convicted because of all the fraud they did.)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376214" class="c"><input type="checkbox" id="c-38376214" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#38375535">parent</a><span>|</span><a href="#38376411">prev</a><span>|</span><a href="#38377186">next</a><span>|</span><label class="collapse" for="c-38376214">[-]</label><label class="expand" for="c-38376214">[6 more]</label></div><br/><div class="children"><div class="content">I wish they could make GPT4 a little cheaper after all this.</div><br/><div id="38376938" class="c"><input type="checkbox" id="c-38376938" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376214">parent</a><span>|</span><a href="#38376295">next</a><span>|</span><label class="collapse" for="c-38376938">[-]</label><label class="expand" for="c-38376938">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard $20 just buys like 9 minutes of actual processor time for GPT 4. Apocryphal maybe, but whatever the real number is, it&#x27;s still going to be very high, once the VC money runs out I bet the rates will shoot.</div><br/><div id="38388068" class="c"><input type="checkbox" id="c-38388068" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376938">parent</a><span>|</span><a href="#38376295">next</a><span>|</span><label class="collapse" for="c-38388068">[-]</label><label class="expand" for="c-38388068">[2 more]</label></div><br/><div class="children"><div class="content">I am talking about API. There is no fixed cost for it. 6000 tokens cost around $0.25. If I use if all day long I pay more than $10 per day.</div><br/><div id="38390260" class="c"><input type="checkbox" id="c-38390260" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38388068">parent</a><span>|</span><a href="#38376295">next</a><span>|</span><label class="collapse" for="c-38390260">[-]</label><label class="expand" for="c-38390260">[1 more]</label></div><br/><div class="children"><div class="content">Ah, sorry, I was confused, thanks for the clarification.</div><br/></div></div></div></div></div></div><div id="38376295" class="c"><input type="checkbox" id="c-38376295" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376214">parent</a><span>|</span><a href="#38376938">prev</a><span>|</span><a href="#38377186">next</a><span>|</span><label class="collapse" for="c-38376295">[-]</label><label class="expand" for="c-38376295">[2 more]</label></div><br/><div class="children"><div class="content">considering what I get out of it, I would pay a lot more for gpt4 that $20&#x2F;month, so it depends on how much $20 is for you.</div><br/><div id="38376727" class="c"><input type="checkbox" id="c-38376727" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376295">parent</a><span>|</span><a href="#38377186">next</a><span>|</span><label class="collapse" for="c-38376727">[-]</label><label class="expand" for="c-38376727">[1 more]</label></div><br/><div class="children"><div class="content">$20. Or use the API if your usage is low.</div><br/></div></div></div></div></div></div><div id="38377186" class="c"><input type="checkbox" id="c-38377186" checked=""/><div class="controls bullet"><span class="by">ozgung</span><span>|</span><a href="#38375535">parent</a><span>|</span><a href="#38376214">prev</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38377186">[-]</label><label class="expand" for="c-38377186">[4 more]</label></div><br/><div class="children"><div class="content">I am glad someone said that. Among the endless theories this obvious aspect was interestingly missing. Maybe it&#x27;s because of the culture in SV&#x2F;HN where people and companies feel secure and isolated from the politics (maybe that is the reason SV is unique in the world). But in my world something like AGI+Saudi Arabia is a matter of international politics and multiple governments would involve. AGI will be an important strategic resource in this century, both in economical and political sense. This automatically makes it Cold War 2 kind of material. All these teen drama by some incompetent millennials in the board of a non-profit organization (Communist-like in a Capitalist country?) does not align with the gravity of the material. I believe this was some adult supervision attempt from your government. Or not, but that perspective needs more attention.</div><br/><div id="38378856" class="c"><input type="checkbox" id="c-38378856" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38377186">parent</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38378856">[-]</label><label class="expand" for="c-38378856">[3 more]</label></div><br/><div class="children"><div class="content">I could buy this theory, but it&#x27;s worth noting that if it&#x27;s true, their coup appears to have failed. So that&#x27;s score one for the naive tech bros, score zero for the conniving natsec sociopaths.</div><br/><div id="38380556" class="c"><input type="checkbox" id="c-38380556" checked=""/><div class="controls bullet"><span class="by">kridsdale1</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38378856">parent</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38380556">[-]</label><label class="expand" for="c-38380556">[2 more]</label></div><br/><div class="children"><div class="content">Maybe not. Microsoft and Summers are now much more in control. That’s a win for the USA and DOD.</div><br/><div id="38380773" class="c"><input type="checkbox" id="c-38380773" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38380556">parent</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38380773">[-]</label><label class="expand" for="c-38380773">[1 more]</label></div><br/><div class="children"><div class="content">Yeah fair enough. Any idea how Larry Summers even ended up on this board? He seems like an arbitrary choice with no domain expertise, although granted the board shouldn&#x27;t be filled with AI experts.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38375308" class="c"><input type="checkbox" id="c-38375308" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375535">prev</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38375308">[-]</label><label class="expand" for="c-38375308">[78 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; We have reached an agreement in principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry Summers, and Adam D&#x27;Angelo.

    &gt; We are collaborating to figure out the details. Thank you so much for your patience through this.
</code></pre>
1- So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>2- Now what happens to Microsoft&#x27;s role in all of this?<p>3- Twitter is still the best place to follow this and get updates, everyone is still make &quot;official&quot; statements on twitter, not sure how long this website will last but until then, this is the only portal for me to get news.</div><br/><div id="38375424" class="c"><input type="checkbox" id="c-38375424" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38375424">[-]</label><label class="expand" for="c-38375424">[13 more]</label></div><br/><div class="children"><div class="content">&gt; So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>Altman was trying to remove one of the board members before he was forced out. Looks like he got his way in the end, but I&#x27;m going to call Altman the primary instigator because of that.<p>His side was also the &quot;we&#x27;ll nuke the company unless you resign&quot; side.</div><br/><div id="38375585" class="c"><input type="checkbox" id="c-38375585" checked=""/><div class="controls bullet"><span class="by">theamk</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375424">parent</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38375585">[-]</label><label class="expand" for="c-38375585">[12 more]</label></div><br/><div class="children"><div class="content">His side was also &quot;700 regular employees support this&quot;, which is pretty unusual as most people don&#x27;t care about their CEO at all. I am not related to OpenAI at all, but given the choice of &quot;favorite of all employees&quot; vs &quot;fire people with no warning then refuse to give explanation why even under pressure&quot; I know which side I root for.</div><br/><div id="38375921" class="c"><input type="checkbox" id="c-38375921" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375891">next</a><span>|</span><label class="collapse" for="c-38375921">[-]</label><label class="expand" for="c-38375921">[1 more]</label></div><br/><div class="children"><div class="content">Looking back, Altman&#x27;s ace in hand was the tender offer from Thrive. Idk anyone at OpenAI, but all the early senior personnel backed him with vehemence. If the leaders hand&#x27;t championed him strongly, I doubt you get 90% of the company to commit to leaving.<p>I&#x27;m sure some of those employees were easily going to make $10m+ in the sale. That&#x27;s a pretty great motivation tool.<p>Overall, I do agree with you. The board could not justify their capricious decision making and refused to elaborate. They should&#x27;ve brought him back on Sunday instead of mucking around. OpenAI existing is a good thing.</div><br/></div></div><div id="38375891" class="c"><input type="checkbox" id="c-38375891" checked=""/><div class="controls bullet"><span class="by">xiwenc</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375921">prev</a><span>|</span><a href="#38375946">next</a><span>|</span><label class="collapse" for="c-38375891">[-]</label><label class="expand" for="c-38375891">[4 more]</label></div><br/><div class="children"><div class="content">No idea what these 700 employees were thinking. They probably had little knowledge of what truly went down other than “my CEO was fired unfairly” and rushed to the rescue.<p>I think the board should have been more transparent on why they made the decision to fire Sam.<p>Or perhaps these employees only cared about their AI work and money? The foundation would be perceived as the culprit against them.<p>Really sad there’s no clarity from the old board disclosed. Hope one day we will know.</div><br/><div id="38375934" class="c"><input type="checkbox" id="c-38375934" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375891">parent</a><span>|</span><a href="#38381720">next</a><span>|</span><label class="collapse" for="c-38375934">[-]</label><label class="expand" for="c-38375934">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how much more transparent they can really be. I know that when firing a &quot;regular&quot; employee, you basically never tell everyone all the details for legal CYA reasons. When your firing someone worth half a billion dollars, I expect the legal fears are magnified.</div><br/><div id="38380513" class="c"><input type="checkbox" id="c-38380513" checked=""/><div class="controls bullet"><span class="by">framapotari</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375934">parent</a><span>|</span><a href="#38381720">next</a><span>|</span><label class="collapse" for="c-38380513">[-]</label><label class="expand" for="c-38380513">[1 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s the difference, the CEO is not a regular employee. If a board of directors wants to be trusted and taken seriously it can&#x27;t just fire the CEO and say &quot;I&#x27;m sorry we can&#x27;t say why, that&#x27;s private information&quot;.</div><br/></div></div></div></div><div id="38381720" class="c"><input type="checkbox" id="c-38381720" checked=""/><div class="controls bullet"><span class="by">x86x87</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375891">parent</a><span>|</span><a href="#38375934">prev</a><span>|</span><a href="#38375946">next</a><span>|</span><label class="collapse" for="c-38381720">[-]</label><label class="expand" for="c-38381720">[1 more]</label></div><br/><div class="children"><div class="content">They were thinking about money. There you go. Seeing what you build crumble is not pleasant when this means you are financially impacted.</div><br/></div></div></div></div><div id="38375946" class="c"><input type="checkbox" id="c-38375946" checked=""/><div class="controls bullet"><span class="by">gnaman</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375891">prev</a><span>|</span><a href="#38375876">next</a><span>|</span><label class="collapse" for="c-38375946">[-]</label><label class="expand" for="c-38375946">[4 more]</label></div><br/><div class="children"><div class="content">Take this with a grain of salt but employees were under a lot of peer pressure<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;JacquesThibs&#x2F;status&#x2F;1727134087176204410" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;JacquesThibs&#x2F;status&#x2F;1727134087176204410</a></div><br/><div id="38376006" class="c"><input type="checkbox" id="c-38376006" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375946">parent</a><span>|</span><a href="#38376037">next</a><span>|</span><label class="collapse" for="c-38376006">[-]</label><label class="expand" for="c-38376006">[2 more]</label></div><br/><div class="children"><div class="content">That is one HUGE grain of salt considering 1&#x2F; it&#x27;s Blind 2&#x2F; Even in the same thread there is another poster saying the exact opposite thing (i.e. no peer pressure)</div><br/><div id="38379149" class="c"><input type="checkbox" id="c-38379149" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38376006">parent</a><span>|</span><a href="#38376037">next</a><span>|</span><label class="collapse" for="c-38379149">[-]</label><label class="expand" for="c-38379149">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 1&#x2F; it&#x27;s Blind<p>Average people don&#x27;t like to lie, if someone bullies them until they agree to sign they will sign because they are honest.<p>Also if they said they will sign but the ticker didn&#x27;t go up, it is pretty obvious that they lied and I&#x27;m sure they don&#x27;t want that risk.</div><br/></div></div></div></div><div id="38376037" class="c"><input type="checkbox" id="c-38376037" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375946">parent</a><span>|</span><a href="#38376006">prev</a><span>|</span><a href="#38375876">next</a><span>|</span><label class="collapse" for="c-38376037">[-]</label><label class="expand" for="c-38376037">[1 more]</label></div><br/><div class="children"><div class="content">Yeah 95% of employees is a bit too high ...<p>Also, all the stuff they started doing with the hearts and cryptic messages on Twitter (now X) was a bit ... cult-y?. I wouldn&#x27;t doubt there was a lot of manipulation behind all that, even from @sama itself.<p>So, there is goes, it seems that there&#x27;s a big chance now that the first AGI will land on the hands of a group with the antics of teenagers. Interesting timeline.</div><br/></div></div></div></div><div id="38375876" class="c"><input type="checkbox" id="c-38375876" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375946">prev</a><span>|</span><a href="#38376889">next</a><span>|</span><label class="collapse" for="c-38375876">[-]</label><label class="expand" for="c-38375876">[1 more]</label></div><br/><div class="children"><div class="content">The 700 employees also have significant financial incentive to want Altman to stay. If he moved to a competitor all the shine would follow. They want the pay-day (I don&#x27;t blame them), but take with a grain of salt what the employees want in this case.</div><br/></div></div><div id="38376889" class="c"><input type="checkbox" id="c-38376889" checked=""/><div class="controls bullet"><span class="by">doktrin</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375876">prev</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38376889">[-]</label><label class="expand" for="c-38376889">[1 more]</label></div><br/><div class="children"><div class="content">&gt; which is pretty unusual as most people don&#x27;t care about their CEO at all<p>I&#x27;m sure Sam is a charismatic guy, but generally speaking folks will support a whole lot when a multi million dollar payday is on the line.</div><br/></div></div></div></div></div></div><div id="38375363" class="c"><input type="checkbox" id="c-38375363" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375424">prev</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375363">[-]</label><label class="expand" for="c-38375363">[12 more]</label></div><br/><div class="children"><div class="content">Microsoft&#x27;s role remains same as it was on Thursday. Minor (49%?) shareholder and keeps access to models and IP<p>IMO Kevin tweeting that MS will hire and match comp of all OpenAI employees was amazing negotiation tactic because that meant employees could sign the petition without worrying about their jobs&#x2F;visas</div><br/><div id="38375514" class="c"><input type="checkbox" id="c-38375514" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38376289">next</a><span>|</span><label class="collapse" for="c-38375514">[-]</label><label class="expand" for="c-38375514">[2 more]</label></div><br/><div class="children"><div class="content">I think at this point MSFT will seek a board seat in OpenAI&#x2F;</div><br/><div id="38375936" class="c"><input type="checkbox" id="c-38375936" checked=""/><div class="controls bullet"><span class="by">zeven7</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375514">parent</a><span>|</span><a href="#38376289">next</a><span>|</span><label class="collapse" for="c-38375936">[-]</label><label class="expand" for="c-38375936">[1 more]</label></div><br/><div class="children"><div class="content">Satya Nadella said they would make sure there would be &quot;no more surprises&quot;.<p>(Sad day for popcorn sales.)</div><br/></div></div></div></div><div id="38376289" class="c"><input type="checkbox" id="c-38376289" checked=""/><div class="controls bullet"><span class="by">ugh123</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38375514">prev</a><span>|</span><a href="#38375455">next</a><span>|</span><label class="collapse" for="c-38376289">[-]</label><label class="expand" for="c-38376289">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking about this a lot as well, but what did that mean for employee stock in the commercial entity? I heard they were up for a liquid cash-out in the next funding round.</div><br/></div></div><div id="38375455" class="c"><input type="checkbox" id="c-38375455" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38376289">prev</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375455">[-]</label><label class="expand" for="c-38375455">[8 more]</label></div><br/><div class="children"><div class="content">but no board seat? how do they prevent a rehash of this in the future and how do they safeguard their investment? Really curious.</div><br/><div id="38375504" class="c"><input type="checkbox" id="c-38375504" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38376029">next</a><span>|</span><label class="collapse" for="c-38375504">[-]</label><label class="expand" for="c-38375504">[5 more]</label></div><br/><div class="children"><div class="content">OpenAI is an airgapped test lab for Microsoft. They dont want critical exposure to the downside risk of AI research, just the benefits in terms of IP. Sam and Greg probably offer enough stability for them to continue this way.</div><br/><div id="38375825" class="c"><input type="checkbox" id="c-38375825" checked=""/><div class="controls bullet"><span class="by">happosai</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375504">parent</a><span>|</span><a href="#38375672">next</a><span>|</span><label class="collapse" for="c-38375825">[-]</label><label class="expand" for="c-38375825">[2 more]</label></div><br/><div class="children"><div class="content">It makes sense to airgap Generative AI while courts ponder wether copyright fair use applies or not. Research is clearly allowed fair use, and let OpenAI experiment with commercialization until it is all clear waters.</div><br/><div id="38376242" class="c"><input type="checkbox" id="c-38376242" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375825">parent</a><span>|</span><a href="#38375672">next</a><span>|</span><label class="collapse" for="c-38376242">[-]</label><label class="expand" for="c-38376242">[1 more]</label></div><br/><div class="children"><div class="content">No anti-AI lawsuits have progressed yet. One got slapped down pretty hard today, though isn&#x27;t dead.<p><a href="https:&#x2F;&#x2F;www.hollywoodreporter.com&#x2F;business&#x2F;business-news&#x2F;sarah-silverman-lawsuit-ai-meta-1235669403&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hollywoodreporter.com&#x2F;business&#x2F;business-news&#x2F;sar...</a></div><br/></div></div></div></div><div id="38375672" class="c"><input type="checkbox" id="c-38375672" checked=""/><div class="controls bullet"><span class="by">_jab</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375504">parent</a><span>|</span><a href="#38375825">prev</a><span>|</span><a href="#38376029">next</a><span>|</span><label class="collapse" for="c-38375672">[-]</label><label class="expand" for="c-38375672">[2 more]</label></div><br/><div class="children"><div class="content">Sam and Greg don&#x27;t appear to be getting their board seats back.</div><br/><div id="38377468" class="c"><input type="checkbox" id="c-38377468" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375672">parent</a><span>|</span><a href="#38376029">next</a><span>|</span><label class="collapse" for="c-38377468">[-]</label><label class="expand" for="c-38377468">[1 more]</label></div><br/><div class="children"><div class="content">They dont need them. If they get fired, they can go nuclear on the board again.</div><br/></div></div></div></div></div></div><div id="38376029" class="c"><input type="checkbox" id="c-38376029" checked=""/><div class="controls bullet"><span class="by">umeshunni</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38375504">prev</a><span>|</span><a href="#38375972">next</a><span>|</span><label class="collapse" for="c-38376029">[-]</label><label class="expand" for="c-38376029">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a new and &quot;more experienced&quot; board.  This is also possibly the first of additional governance and structure changes.</div><br/></div></div><div id="38375972" class="c"><input type="checkbox" id="c-38375972" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38376029">prev</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375972">[-]</label><label class="expand" for="c-38375972">[1 more]</label></div><br/><div class="children"><div class="content">I believe all the board seats are not fillet yet</div><br/></div></div></div></div></div></div><div id="38375939" class="c"><input type="checkbox" id="c-38375939" checked=""/><div class="controls bullet"><span class="by">happosai</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375363">prev</a><span>|</span><a href="#38375353">next</a><span>|</span><label class="collapse" for="c-38375939">[-]</label><label class="expand" for="c-38375939">[2 more]</label></div><br/><div class="children"><div class="content">About 3)<p>What is the benefit of learning about this kind of drama minute-by-minute, compared to reading it a few hours later on hacker news or next day on wall street journal?<p>Personally I found twitter very bad for my productivity, a lot of focus destroyed just to know &quot;what is happening&quot; when there was neglible drawbacks of finding about news events a few hours later.</div><br/><div id="38376078" class="c"><input type="checkbox" id="c-38376078" checked=""/><div class="controls bullet"><span class="by">willdr</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375939">parent</a><span>|</span><a href="#38375353">next</a><span>|</span><label class="collapse" for="c-38376078">[-]</label><label class="expand" for="c-38376078">[1 more]</label></div><br/><div class="children"><div class="content">I have muted any mention of Open AI, Altman, Emmet and Satya from my Twitter feed for the past five days. It&#x27;s a far better experience.</div><br/></div></div></div></div><div id="38375353" class="c"><input type="checkbox" id="c-38375353" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375939">prev</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375353">[-]</label><label class="expand" for="c-38375353">[12 more]</label></div><br/><div class="children"><div class="content">Microsoft said they are OK with Sam returning to openAI. There are probbaly legal reasons why they prefer things to go back as it were<p>(Thank you for calling Twitter Twitter)</div><br/><div id="38375421" class="c"><input type="checkbox" id="c-38375421" checked=""/><div class="controls bullet"><span class="by">AmericanOP</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375353">parent</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375421">[-]</label><label class="expand" for="c-38375421">[11 more]</label></div><br/><div class="children"><div class="content">The website is twitter.com. Why call it something else?</div><br/><div id="38375484" class="c"><input type="checkbox" id="c-38375484" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375421">parent</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375484">[-]</label><label class="expand" for="c-38375484">[6 more]</label></div><br/><div class="children"><div class="content">Also, x.com redirects to Twitter.com.   Seems like they want us to say Twitter.</div><br/><div id="38375601" class="c"><input type="checkbox" id="c-38375601" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375484">parent</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375601">[-]</label><label class="expand" for="c-38375601">[5 more]</label></div><br/><div class="children"><div class="content">saying “to tweet” is definitely better than saying “to xeet”</div><br/><div id="38375850" class="c"><input type="checkbox" id="c-38375850" checked=""/><div class="controls bullet"><span class="by">asimovfan</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375601">parent</a><span>|</span><a href="#38380478">next</a><span>|</span><label class="collapse" for="c-38375850">[-]</label><label class="expand" for="c-38375850">[3 more]</label></div><br/><div class="children"><div class="content">Xeet is super funny, hopefully takes over.</div><br/><div id="38376220" class="c"><input type="checkbox" id="c-38376220" checked=""/><div class="controls bullet"><span class="by">grumpyprole</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375850">parent</a><span>|</span><a href="#38375866">next</a><span>|</span><label class="collapse" for="c-38376220">[-]</label><label class="expand" for="c-38376220">[1 more]</label></div><br/><div class="children"><div class="content">Or xcreet?</div><br/></div></div><div id="38375866" class="c"><input type="checkbox" id="c-38375866" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375850">parent</a><span>|</span><a href="#38376220">prev</a><span>|</span><a href="#38380478">next</a><span>|</span><label class="collapse" for="c-38375866">[-]</label><label class="expand" for="c-38375866">[1 more]</label></div><br/><div class="children"><div class="content">share it on Xitter</div><br/></div></div></div></div><div id="38380478" class="c"><input type="checkbox" id="c-38380478" checked=""/><div class="controls bullet"><span class="by">wise_young_man</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375601">parent</a><span>|</span><a href="#38375850">prev</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38380478">[-]</label><label class="expand" for="c-38380478">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it’s a cross post.</div><br/></div></div></div></div></div></div><div id="38375513" class="c"><input type="checkbox" id="c-38375513" checked=""/><div class="controls bullet"><span class="by">labster</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375421">parent</a><span>|</span><a href="#38375484">prev</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375513">[-]</label><label class="expand" for="c-38375513">[4 more]</label></div><br/><div class="children"><div class="content">Exactly right, fellow YCombinator News commenter!</div><br/><div id="38375594" class="c"><input type="checkbox" id="c-38375594" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375513">parent</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375594">[-]</label><label class="expand" for="c-38375594">[3 more]</label></div><br/><div class="children"><div class="content">I believe you mean <i>Startup News</i></div><br/><div id="38375660" class="c"><input type="checkbox" id="c-38375660" checked=""/><div class="controls bullet"><span class="by">tech234a</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375594">parent</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375660">[-]</label><label class="expand" for="c-38375660">[2 more]</label></div><br/><div class="children"><div class="content">For reference: <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070713212949&#x2F;http:&#x2F;&#x2F;news.ycombinator.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070713212949&#x2F;http:&#x2F;&#x2F;news.ycomb...</a></div><br/><div id="38376075" class="c"><input type="checkbox" id="c-38376075" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375660">parent</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38376075">[-]</label><label class="expand" for="c-38376075">[1 more]</label></div><br/><div class="children"><div class="content">From 2nd story on the archive<p>&gt;It is just a joke that Facebook could be valued at $6 billion.<p>lol, seems HN is same since forever.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38375977" class="c"><input type="checkbox" id="c-38375977" checked=""/><div class="controls bullet"><span class="by">kumarvvr</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375353">prev</a><span>|</span><a href="#38376089">next</a><span>|</span><label class="collapse" for="c-38375977">[-]</label><label class="expand" for="c-38375977">[3 more]</label></div><br/><div class="children"><div class="content">Satya comes out great, making the absolute best of a given shitty situation, with a high stake of 10 B USD.<p>Microsoft is showing to investors that it is going to be an AI company, one way or the other.<p>Microsoft still has access to everything OpenAI does.<p>Microsoft has its friend, Sam, at the helm of OpenAI and with a more tighter grip on the company than ever.<p>Its still a win for Microsoft.</div><br/><div id="38376310" class="c"><input type="checkbox" id="c-38376310" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375977">parent</a><span>|</span><a href="#38376244">next</a><span>|</span><label class="collapse" for="c-38376310">[-]</label><label class="expand" for="c-38376310">[1 more]</label></div><br/><div class="children"><div class="content">Satya just played the hand he had.  The hand he had was excellent, he had already won. MS already had perceptual license, people working on GPT and Sam Altman on his corner.<p>The one thing in Microsoft has stayed constant from Gates to  Ballmer to Satya: you should never, ever form a close alliance with MS. They know how to screw alliance partners. i4i, Windows RT partners, Windows Phone Partners, Nokia, HW partners in Surface. Even Steve Jobs was burned few times.</div><br/></div></div><div id="38376244" class="c"><input type="checkbox" id="c-38376244" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375977">parent</a><span>|</span><a href="#38376310">prev</a><span>|</span><a href="#38376089">next</a><span>|</span><label class="collapse" for="c-38376244">[-]</label><label class="expand" for="c-38376244">[1 more]</label></div><br/><div class="children"><div class="content">Satya comes out as evil imho, and I wonder how much orchestration there was going on behind the scenes.<p>Microsoft is showing that it is still able to capture important scale ups and &#x27;embrace&#x27; them, whilst also acting as if they have the moral high ground, but in reality are doing research with a high governance errors and potential legal problems away from their premises. and THAT is why stakeholders like him.</div><br/></div></div></div></div><div id="38376089" class="c"><input type="checkbox" id="c-38376089" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375977">prev</a><span>|</span><a href="#38377406">next</a><span>|</span><label class="collapse" for="c-38376089">[-]</label><label class="expand" for="c-38376089">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Twitter is still the best place to follow this and get updates</i><p>This has been my single strongest takeaway from this saga: Twitter remains the centre of controversy. When shit hit the fan, Sam and Satya and Swisher took to Twitter. Not Threads. Not Bluesy. Twitter. (X.)</div><br/><div id="38377367" class="c"><input type="checkbox" id="c-38377367" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38376089">parent</a><span>|</span><a href="#38377406">next</a><span>|</span><label class="collapse" for="c-38377367">[-]</label><label class="expand" for="c-38377367">[1 more]</label></div><br/><div class="children"><div class="content">Bluesky still has gated signups at this point so I don&#x27;t think it will ever be a viable alternative.<p>Threads had a rushed rollout which resulted in major feature gaps that disincentivized users from doing anything beyond creating their profiles.<p>Notable figures and organizations have little reason to fully migrate off Twitter unless Musk irreversibly breaks the site and even he is not stupid enough to do that (yet?). So with most of its content creators still in place, Twitter has no risk of following the path of Digg.</div><br/></div></div></div></div><div id="38376020" class="c"><input type="checkbox" id="c-38376020" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38377406">prev</a><span>|</span><a href="#38376059">next</a><span>|</span><label class="collapse" for="c-38376020">[-]</label><label class="expand" for="c-38376020">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>Whole charade was by GPT5 to understand the position of person sitting next to red button and secondary to stress test Hacker News.</div><br/></div></div><div id="38376059" class="c"><input type="checkbox" id="c-38376059" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376020">prev</a><span>|</span><a href="#38375429">next</a><span>|</span><label class="collapse" for="c-38376059">[-]</label><label class="expand" for="c-38376059">[2 more]</label></div><br/><div class="children"><div class="content">Larry Summers? like the Larry Summers?</div><br/><div id="38376246" class="c"><input type="checkbox" id="c-38376246" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38376059">parent</a><span>|</span><a href="#38375429">next</a><span>|</span><label class="collapse" for="c-38376246">[-]</label><label class="expand" for="c-38376246">[1 more]</label></div><br/><div class="children"><div class="content">yeah, the guy has a knack for being in&#x2F;invited to places.</div><br/></div></div></div></div><div id="38375429" class="c"><input type="checkbox" id="c-38375429" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376059">prev</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375429">[-]</label><label class="expand" for="c-38375429">[11 more]</label></div><br/><div class="children"><div class="content">The explanation for point 1 is point 3. If the people involved were not terminally online and felt the need to share every single one of their immediate thoughts with the public they could have likely settled this behind closed doors, where this kind of stuff belongs.<p>It&#x27;s not actually news, it&#x27;s entertainment and self-aggrandizement by everyone involved including the audience.</div><br/><div id="38375470" class="c"><input type="checkbox" id="c-38375470" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375429">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375470">[-]</label><label class="expand" for="c-38375470">[10 more]</label></div><br/><div class="children"><div class="content">Interesting that the board were repeatedly criticized for &quot;not being adults&quot;, and yet they were also the only party not live-tweeting everything...<p>Seems like there&#x27;s no way to win with Twitter.  You may not be interested in Twitter, but Twitter is interested in you.</div><br/><div id="38376169" class="c"><input type="checkbox" id="c-38376169" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375895">next</a><span>|</span><label class="collapse" for="c-38376169">[-]</label><label class="expand" for="c-38376169">[1 more]</label></div><br/><div class="children"><div class="content">Considering CEO2 rebelled next day and CEO3 allegedly said he&#x27;ll quit unless board comes out with truth, doesn&#x27;t provide much confidence in their adulthood.</div><br/></div></div><div id="38375895" class="c"><input type="checkbox" id="c-38375895" checked=""/><div class="controls bullet"><span class="by">imgabe</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38376169">prev</a><span>|</span><a href="#38375610">next</a><span>|</span><label class="collapse" for="c-38375895">[-]</label><label class="expand" for="c-38375895">[1 more]</label></div><br/><div class="children"><div class="content">The board not saying what the hell they were on about was the source of the whole drama in the first place. If they had just said exactly what their problem was up front there wouldn&#x27;t have been as much to tweet about.</div><br/></div></div><div id="38375610" class="c"><input type="checkbox" id="c-38375610" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375895">prev</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375610">[-]</label><label class="expand" for="c-38375610">[4 more]</label></div><br/><div class="children"><div class="content">the board didn’t have to tweet. their ridiculous actions spoke for itself.</div><br/><div id="38375735" class="c"><input type="checkbox" id="c-38375735" checked=""/><div class="controls bullet"><span class="by">angryasian</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375610">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375735">[-]</label><label class="expand" for="c-38375735">[3 more]</label></div><br/><div class="children"><div class="content">we still don&#x27;t know what Altman has actually been hiding, so to say it was ridiculous ... is ridiculous itself.</div><br/><div id="38375801" class="c"><input type="checkbox" id="c-38375801" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375735">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375801">[-]</label><label class="expand" for="c-38375801">[2 more]</label></div><br/><div class="children"><div class="content">the board’s actions were ridiculous regardless of Sam’s. sell oai to anthropic? were they out of their minds?</div><br/><div id="38375967" class="c"><input type="checkbox" id="c-38375967" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375801">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375967">[-]</label><label class="expand" for="c-38375967">[1 more]</label></div><br/><div class="children"><div class="content">From the perspective of upholding the charter <a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a> and preventing an AI race -- seems potentially sensible</div><br/></div></div></div></div></div></div></div></div><div id="38375633" class="c"><input type="checkbox" id="c-38375633" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375610">prev</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375633">[-]</label><label class="expand" for="c-38375633">[3 more]</label></div><br/><div class="children"><div class="content">They didn’t tweet, but did they communicate in any other way?!</div><br/><div id="38375785" class="c"><input type="checkbox" id="c-38375785" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375633">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375785">[-]</label><label class="expand" for="c-38375785">[2 more]</label></div><br/><div class="children"><div class="content">Well, there was the initial announcement.</div><br/><div id="38376187" class="c"><input type="checkbox" id="c-38376187" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375785">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38376187">[-]</label><label class="expand" for="c-38376187">[1 more]</label></div><br/><div class="children"><div class="content">To say that communication was lacking is an understatement. Clarifications were missing and sorely needed.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376280" class="c"><input type="checkbox" id="c-38376280" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375429">prev</a><span>|</span><a href="#38375507">next</a><span>|</span><label class="collapse" for="c-38376280">[-]</label><label class="expand" for="c-38376280">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 2- Now what happens to Microsoft&#x27;s role in all of this?<p>This outcome WAS microsoft&#x27;s role in all this. Satya offering sam a ceo like position to create a competing product was leverage for this outcome.</div><br/></div></div><div id="38375507" class="c"><input type="checkbox" id="c-38375507" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376280">prev</a><span>|</span><a href="#38375347">next</a><span>|</span><label class="collapse" for="c-38375507">[-]</label><label class="expand" for="c-38375507">[5 more]</label></div><br/><div class="children"><div class="content">If there’s been one constant here, it’s been people who actually know Tonrer expressing deep support for her experience, intelligence, and ethics, so it’s interesting to me that she seems to be getting the boot.</div><br/><div id="38376325" class="c"><input type="checkbox" id="c-38376325" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38375777">next</a><span>|</span><label class="collapse" for="c-38376325">[-]</label><label class="expand" for="c-38376325">[1 more]</label></div><br/><div class="children"><div class="content">If there is one clear thing, it&#x27;s that no one on that board should be allowed anywhere near another board for any non-clown company. The level of incompetence in how they handled this whole thing was extraordinary.<p>The fact that Adam D&#x27;Angelo is still on the new board apparently is much more baffling than the fact that Tonrer or Ilya are not.</div><br/></div></div><div id="38375777" class="c"><input type="checkbox" id="c-38375777" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38376325">prev</a><span>|</span><a href="#38375603">next</a><span>|</span><label class="collapse" for="c-38375777">[-]</label><label class="expand" for="c-38375777">[2 more]</label></div><br/><div class="children"><div class="content">Add delusions of grandeur to that list thinking she can pursue her ideological will by winning over 3 board members while losing 90% of the company staff.<p>She was fighting an idelogical battle that needs full industry buy in, legitimate or not that&#x27;s not how you win people over.<p>If she&#x27;s truely a rationalist as she claims then a rationalist would be realistic understanding that if your engineers can just leave and do it somewhere else tomorrow you aren&#x27;t making progress. Taking on the full might of US capitalism via winning over the fringe half of a non profit board is not the best strategy. At best it was desperate and naive.</div><br/><div id="38376267" class="c"><input type="checkbox" id="c-38376267" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375777">parent</a><span>|</span><a href="#38375603">next</a><span>|</span><label class="collapse" for="c-38376267">[-]</label><label class="expand" for="c-38376267">[1 more]</label></div><br/><div class="children"><div class="content">This is pretty good evidence she&#x27;s a rationalist; rationalism means a religious devotion to a specific kind of logical thinking that never works in real life because you can&#x27;t calculate the probability a result if you didn&#x27;t know it could happen in the first place.<p>Traditional response to this happening is to say something about your &quot;priors&quot; being wrong instead of taking responsibility.</div><br/></div></div></div></div><div id="38375603" class="c"><input type="checkbox" id="c-38375603" checked=""/><div class="controls bullet"><span class="by">causalmodels</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38375777">prev</a><span>|</span><a href="#38375347">next</a><span>|</span><label class="collapse" for="c-38375603">[-]</label><label class="expand" for="c-38375603">[1 more]</label></div><br/><div class="children"><div class="content">Fiascos like this display neither experience nor intelligence. This whole saga was a colossal failure on the part of the previous board.</div><br/></div></div></div></div><div id="38375347" class="c"><input type="checkbox" id="c-38375347" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375507">prev</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38375347">[-]</label><label class="expand" for="c-38375347">[12 more]</label></div><br/><div class="children"><div class="content">&gt; Twitter is still the best place to follow this and get updates, everyone is still make &quot;official&quot; statements on twitter, not sure how long this website will last but until then, this is the only portal for me to get news.<p>It&#x27;s only natural to confuse what is happening with what we wish to happen. After all, when we imagine something, aren&#x27;t we undergoing a kind of experience?<p>A lot of people wish Twitter were dying, even though it&#x27;s it, so they interpret evidence through a lens of belief confirmation rather than belief disproof. It&#x27;s only human to do this. We all do.</div><br/><div id="38375446" class="c"><input type="checkbox" id="c-38375446" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375347">parent</a><span>|</span><a href="#38375375">next</a><span>|</span><label class="collapse" for="c-38375446">[-]</label><label class="expand" for="c-38375446">[9 more]</label></div><br/><div class="children"><div class="content">It was funny reading Kara Swisher keeping saying twitter is dying and is toxic and what not, while STILL doing all her first announcements on twitter, and using twitter as a source.<p>same with Ashlee Vance (the other journo reporting on this) and all the main players (Sam&#x2F;Greg&#x2F;Ilya&#x2F;Mira&#x2F;Satya&#x2F;whoever) also make their first announcement on twitter.<p>I don&#x27;t know about the funding part of it, but there is no denying it, the news is still freshest on twitter. Twitter feels just as toxic for me as before, in fact I feel community notes has made it much better, imho.<p>____<p>In some related news, I finally got bluesky invite (I don&#x27;t have invite codes yet or I would share here)<p>and people there are complaining about... mastadon and how elitist it is...<p>that was an eye opener.<p>nice if you want some science-y updates but it&#x27;s still lags behind twitter for news.</div><br/><div id="38375505" class="c"><input type="checkbox" id="c-38375505" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375505">[-]</label><label class="expand" for="c-38375505">[5 more]</label></div><br/><div class="children"><div class="content">I don’t use Twitter any more, other than occasionally following links there (which open in the browser, because I deleted the app).<p>Discoverability on Mastodon is abysmal. It was too much work for me.<p>I tend to get my news from Substack now.</div><br/><div id="38375542" class="c"><input type="checkbox" id="c-38375542" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375505">parent</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375542">[-]</label><label class="expand" for="c-38375542">[4 more]</label></div><br/><div class="children"><div class="content">interesting, substack doesn&#x27;t sound like a platform for the freshest news, but for deep insights.<p>Don&#x27;t you feel out of date on substack? especially since things move so fast sometimes, like with this open-ai fiasco?</div><br/><div id="38376039" class="c"><input type="checkbox" id="c-38376039" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375542">parent</a><span>|</span><a href="#38375797">next</a><span>|</span><label class="collapse" for="c-38376039">[-]</label><label class="expand" for="c-38376039">[2 more]</label></div><br/><div class="children"><div class="content">Did being up to date really have an impact on your life? It&#x27;s mostly just gossip.</div><br/><div id="38376854" class="c"><input type="checkbox" id="c-38376854" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38376039">parent</a><span>|</span><a href="#38375797">next</a><span>|</span><label class="collapse" for="c-38376854">[-]</label><label class="expand" for="c-38376854">[1 more]</label></div><br/><div class="children"><div class="content">I understand what you are saying, but sometimes, news like this is perhaps the only excitement in our otherwise dull lives.</div><br/></div></div></div></div><div id="38375797" class="c"><input type="checkbox" id="c-38375797" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375542">parent</a><span>|</span><a href="#38376039">prev</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375797">[-]</label><label class="expand" for="c-38375797">[1 more]</label></div><br/><div class="children"><div class="content">Twitter is incredibly uncivil. I don’t have the stomach for it.</div><br/></div></div></div></div></div></div><div id="38375724" class="c"><input type="checkbox" id="c-38375724" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375505">prev</a><span>|</span><a href="#38375929">next</a><span>|</span><label class="collapse" for="c-38375724">[-]</label><label class="expand" for="c-38375724">[1 more]</label></div><br/><div class="children"><div class="content">Skilled operators say what sounds most virtuous and do what benefits most. Especially when these two things are not the same.</div><br/></div></div><div id="38375929" class="c"><input type="checkbox" id="c-38375929" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375724">prev</a><span>|</span><a href="#38375999">next</a><span>|</span><label class="collapse" for="c-38375929">[-]</label><label class="expand" for="c-38375929">[1 more]</label></div><br/><div class="children"><div class="content">Twitter isn&#x27;t dying, but it hasn&#x27;t grown measurably since 2015. Still sitting at about 300m active users.</div><br/></div></div><div id="38375999" class="c"><input type="checkbox" id="c-38375999" checked=""/><div class="controls bullet"><span class="by">bagels</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375929">prev</a><span>|</span><a href="#38375375">next</a><span>|</span><label class="collapse" for="c-38375999">[-]</label><label class="expand" for="c-38375999">[1 more]</label></div><br/><div class="children"><div class="content">Bluesky took long enough to invite me that I forgot what it even was when I got the email.</div><br/></div></div></div></div><div id="38375375" class="c"><input type="checkbox" id="c-38375375" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375347">parent</a><span>|</span><a href="#38375446">prev</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38375375">[-]</label><label class="expand" for="c-38375375">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of people wish Twitter were dying, even though it&#x27;s it, so they interpret evidence through a lens of belief confirmation rather than belief disproof.<p>Cognitive dissonance</div><br/><div id="38375788" class="c"><input type="checkbox" id="c-38375788" checked=""/><div class="controls bullet"><span class="by">veec_cas_tant</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375375">parent</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38375788">[-]</label><label class="expand" for="c-38375788">[1 more]</label></div><br/><div class="children"><div class="content">Or they read about the large cuts to Twitter’s valuation from banks and X itself?</div><br/></div></div></div></div></div></div></div></div><div id="38375412" class="c"><input type="checkbox" id="c-38375412" checked=""/><div class="controls bullet"><span class="by">pdx6</span><span>|</span><a href="#38375308">prev</a><span>|</span><a href="#38375392">next</a><span>|</span><label class="collapse" for="c-38375412">[-]</label><label class="expand" for="c-38375412">[7 more]</label></div><br/><div class="children"><div class="content">Excellent news. I’ve been worried that Sam moving to Microsoft would stall out possible future engineering efforts like GPT-5 in IP court.<p>As an example of how much faster GPT-4 has made my workflow was the outage this evening — I tried Anthropic, openchat, Bard, and a few others and they were between not useful and worse than just looking at forums and discord it’s 2022.</div><br/><div id="38375645" class="c"><input type="checkbox" id="c-38375645" checked=""/><div class="controls bullet"><span class="by">badcoderman</span><span>|</span><a href="#38375412">parent</a><span>|</span><a href="#38375544">next</a><span>|</span><label class="collapse" for="c-38375645">[-]</label><label class="expand" for="c-38375645">[5 more]</label></div><br/><div class="children"><div class="content">GPT-5 is kinda pointless until they make some type of improvement on the data and research side.  From what I’ve read it’s not really what OpenAI has been pursuing it</div><br/><div id="38376288" class="c"><input type="checkbox" id="c-38376288" checked=""/><div class="controls bullet"><span class="by">Zolde</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376319">next</a><span>|</span><label class="collapse" for="c-38376288">[-]</label><label class="expand" for="c-38376288">[1 more]</label></div><br/><div class="children"><div class="content">One big improvement is in synthetic data (data generated by LLMs).<p>GPT can &quot;clone&quot; the &quot;semantic essence&quot; of everyone who converses with it, generating new questions with prompts like &quot;What interesting questions could this user also have asked, but didn&#x27;t?&quot; and then have an LLM answer it. This generates high-quality, novel, human-like, data.<p>For instance, cloning Paul Graham&#x27;s essence, the LLM came up with &quot;SubSimplify&quot;: A service that combines subscriptions to all the different streaming services into one customizable package, using a chat agent as a recommendation engine.</div><br/></div></div><div id="38376319" class="c"><input type="checkbox" id="c-38376319" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376288">prev</a><span>|</span><a href="#38376387">next</a><span>|</span><label class="collapse" for="c-38376319">[-]</label><label class="expand" for="c-38376319">[1 more]</label></div><br/><div class="children"><div class="content">Are you just blindly deciding what will make “gpt-5” more capable? I guess “data and research” is practically so open ended as to encompass the majority of any possible advancement.</div><br/></div></div><div id="38376387" class="c"><input type="checkbox" id="c-38376387" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376319">prev</a><span>|</span><a href="#38375544">next</a><span>|</span><label class="collapse" for="c-38376387">[-]</label><label class="expand" for="c-38376387">[2 more]</label></div><br/><div class="children"><div class="content">The next improvement will be more modalities (images, sound, etc.)<p>GPT4 in image viewing mode doesn&#x27;t seem to be nearly as smart as text mode, and image generation IME barely works.</div><br/><div id="38379450" class="c"><input type="checkbox" id="c-38379450" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38376387">parent</a><span>|</span><a href="#38375544">next</a><span>|</span><label class="collapse" for="c-38379450">[-]</label><label class="expand" for="c-38379450">[1 more]</label></div><br/><div class="children"><div class="content">Maybe but I think the next big one will be reasoning.</div><br/></div></div></div></div></div></div><div id="38375544" class="c"><input type="checkbox" id="c-38375544" checked=""/><div class="controls bullet"><span class="by">sidcool</span><span>|</span><a href="#38375412">parent</a><span>|</span><a href="#38375645">prev</a><span>|</span><a href="#38375392">next</a><span>|</span><label class="collapse" for="c-38375544">[-]</label><label class="expand" for="c-38375544">[1 more]</label></div><br/><div class="children"><div class="content">I still feel Microsoft will have a bigger influence on OpenAI after this drama is over.</div><br/></div></div></div></div><div id="38375392" class="c"><input type="checkbox" id="c-38375392" checked=""/><div class="controls bullet"><span class="by">bobsoap</span><span>|</span><a href="#38375412">prev</a><span>|</span><a href="#38375391">next</a><span>|</span><label class="collapse" for="c-38375392">[-]</label><label class="expand" for="c-38375392">[2 more]</label></div><br/><div class="children"><div class="content">Someone was very quick to update Bret Taylor&#x27;s Wikipedia page:<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Bret_Taylor" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Bret_Taylor</a><p>&gt; On November, 21st, 2023, Bret Taylor replaced Greg Brockman as the chairman of OpenAI.<p>...with three footmark &quot;sources&quot; that all point to completely unrelated articles about Bret from 2021-2022.</div><br/><div id="38380718" class="c"><input type="checkbox" id="c-38380718" checked=""/><div class="controls bullet"><span class="by">kridsdale1</span><span>|</span><a href="#38375392">parent</a><span>|</span><a href="#38375391">next</a><span>|</span><label class="collapse" for="c-38380718">[-]</label><label class="expand" for="c-38380718">[1 more]</label></div><br/><div class="children"><div class="content">Someone must have run a wiki update script that calls OpenAI api somewhere.</div><br/></div></div></div></div><div id="38375391" class="c"><input type="checkbox" id="c-38375391" checked=""/><div class="controls bullet"><span class="by">Gud</span><span>|</span><a href="#38375392">prev</a><span>|</span><a href="#38375366">next</a><span>|</span><label class="collapse" for="c-38375391">[-]</label><label class="expand" for="c-38375391">[5 more]</label></div><br/><div class="children"><div class="content">Once we develop an actual, fully functional AGI, it’s going to steamroll us isn’t it.<p>If these are the stewards of this technology, it’s time to be worried now.</div><br/><div id="38375916" class="c"><input type="checkbox" id="c-38375916" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375391">parent</a><span>|</span><a href="#38375981">next</a><span>|</span><label class="collapse" for="c-38375916">[-]</label><label class="expand" for="c-38375916">[2 more]</label></div><br/><div class="children"><div class="content">“And that moment was the final nail in the coffin of humankind from earth. They choose, yet again, for money and power. And they shaped AI in their image.<p>Another civilization perished in the great filter.”</div><br/><div id="38376017" class="c"><input type="checkbox" id="c-38376017" checked=""/><div class="controls bullet"><span class="by">MooseBurger</span><span>|</span><a href="#38375391">root</a><span>|</span><a href="#38375916">parent</a><span>|</span><a href="#38375981">next</a><span>|</span><label class="collapse" for="c-38376017">[-]</label><label class="expand" for="c-38376017">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not that deep bro</div><br/></div></div></div></div><div id="38375981" class="c"><input type="checkbox" id="c-38375981" checked=""/><div class="controls bullet"><span class="by">otabdeveloper4</span><span>|</span><a href="#38375391">parent</a><span>|</span><a href="#38375916">prev</a><span>|</span><a href="#38377444">next</a><span>|</span><label class="collapse" for="c-38375981">[-]</label><label class="expand" for="c-38375981">[1 more]</label></div><br/><div class="children"><div class="content">The only way &quot;we develop an actual, fully functional AGI&quot; is by dumbing down humans enough so that even something as stupid as ChatGPT seems intelligent.<p>(Fortunately we are working on this very hard and making incredible progress.)</div><br/></div></div><div id="38377444" class="c"><input type="checkbox" id="c-38377444" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38375391">parent</a><span>|</span><a href="#38375981">prev</a><span>|</span><a href="#38375366">next</a><span>|</span><label class="collapse" for="c-38377444">[-]</label><label class="expand" for="c-38377444">[1 more]</label></div><br/><div class="children"><div class="content">Good thing there&#x27;s absolutely no plausible scenario where we go from &quot;shitty program that guesses the next word&quot; to &quot;AI&quot;. The whole industry is going to be so incredibly embarrassed by the discourse of 2023 in a few years.</div><br/></div></div></div></div><div id="38375366" class="c"><input type="checkbox" id="c-38375366" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375391">prev</a><span>|</span><a href="#38376111">next</a><span>|</span><label class="collapse" for="c-38375366">[-]</label><label class="expand" for="c-38375366">[17 more]</label></div><br/><div class="children"><div class="content">Assuming they weren’t LARPing, that Reddit account claiming to have been in the room when this was all going down must be nervous. They wrote all kinds of nasty things about Sam, and I’m assuming the signatures on the “bring him back” letter would narrow down potential suspects considerably.<p>Edit: For those who may have missed it in previous threads, see <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126</a></div><br/><div id="38375524" class="c"><input type="checkbox" id="c-38375524" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376664">next</a><span>|</span><label class="collapse" for="c-38375524">[-]</label><label class="expand" for="c-38375524">[2 more]</label></div><br/><div class="children"><div class="content">First of all nothing on Reddit is real (within margin of error). Secondly it&#x27;s weird that you&#x27;d assume we know what you&#x27;re talking about.</div><br/><div id="38375701" class="c"><input type="checkbox" id="c-38375701" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38375524">parent</a><span>|</span><a href="#38376664">next</a><span>|</span><label class="collapse" for="c-38375701">[-]</label><label class="expand" for="c-38375701">[1 more]</label></div><br/><div class="children"><div class="content">Links to the profile&#x2F;comments were posted a few times in each of the major OpenAI HN submissions over the last 4 days. On the off-chance I would be breaking some kind of brigading&#x2F;doxxing rule I didn&#x27;t initially link it myself.</div><br/></div></div></div></div><div id="38376664" class="c"><input type="checkbox" id="c-38376664" checked=""/><div class="controls bullet"><span class="by">shrimpx</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375524">prev</a><span>|</span><a href="#38376425">next</a><span>|</span><label class="collapse" for="c-38376664">[-]</label><label class="expand" for="c-38376664">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t sound credible or revealing. It&#x27;s regurgitating a bunch of speculation stuff that&#x27;s been said on this forum and in the media.</div><br/></div></div><div id="38376425" class="c"><input type="checkbox" id="c-38376425" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376664">prev</a><span>|</span><a href="#38377407">next</a><span>|</span><label class="collapse" for="c-38376425">[-]</label><label class="expand" for="c-38376425">[1 more]</label></div><br/><div class="children"><div class="content">I read the comments, most of them are superficial as if someone with no inside knowledge will post. His understanding of humans is also weak. Book deals and speeches as a motivator is hilarious.</div><br/></div></div><div id="38377407" class="c"><input type="checkbox" id="c-38377407" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376425">prev</a><span>|</span><a href="#38375423">next</a><span>|</span><label class="collapse" for="c-38377407">[-]</label><label class="expand" for="c-38377407">[1 more]</label></div><br/><div class="children"><div class="content">It was definitely LARP. The vast majority of anecdotes shared on Reddit originate as some form of creatice fiction writing exercise.</div><br/></div></div><div id="38375423" class="c"><input type="checkbox" id="c-38375423" checked=""/><div class="controls bullet"><span class="by">fordsmith</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38377407">prev</a><span>|</span><a href="#38375629">next</a><span>|</span><label class="collapse" for="c-38375423">[-]</label><label class="expand" for="c-38375423">[2 more]</label></div><br/><div class="children"><div class="content">Link? Not sure which account you are referring to</div><br/><div id="38375443" class="c"><input type="checkbox" id="c-38375443" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38375423">parent</a><span>|</span><a href="#38375629">next</a><span>|</span><label class="collapse" for="c-38375443">[-]</label><label class="expand" for="c-38375443">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126</a></div><br/></div></div></div></div><div id="38375629" class="c"><input type="checkbox" id="c-38375629" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375423">prev</a><span>|</span><a href="#38376025">next</a><span>|</span><label class="collapse" for="c-38375629">[-]</label><label class="expand" for="c-38375629">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  must be nervous<p>I seriously doubt they care. They got away with it. No one should have believed them in the first place. I’m guessing they don’t have their real identity visible on their profile anywhere.</div><br/></div></div><div id="38376025" class="c"><input type="checkbox" id="c-38376025" checked=""/><div class="controls bullet"><span class="by">epups</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375629">prev</a><span>|</span><a href="#38375431">next</a><span>|</span><label class="collapse" for="c-38376025">[-]</label><label class="expand" for="c-38376025">[7 more]</label></div><br/><div class="children"><div class="content">Why can&#x27;t these safety advocates just say what they are afraid of? As it currently stands, the only &quot;danger&quot; in ChatGPT is that you can manipulate it into writing something violent or inappropriate. So what? Is this some San Francisco sensibilities here, where reading about fictional violence is equated to violence? The more people raise safety concerns in the abstract, the more I ignore it.</div><br/><div id="38376283" class="c"><input type="checkbox" id="c-38376283" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376435">next</a><span>|</span><label class="collapse" for="c-38376283">[-]</label><label class="expand" for="c-38376283">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Why can&#x27;t these safety advocates just say what they are afraid of?<p>They have. At length. E.g.,<p><a href="https:&#x2F;&#x2F;ai100.stanford.edu&#x2F;gathering-strength-gathering-storms-one-hundred-year-study-artificial-intelligence-ai100-2021-1-0" rel="nofollow noreferrer">https:&#x2F;&#x2F;ai100.stanford.edu&#x2F;gathering-strength-gathering-stor...</a><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03718.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03718.pdf</a><p><a href="https:&#x2F;&#x2F;eber.uek.krakow.pl&#x2F;index.php&#x2F;eber&#x2F;article&#x2F;view&#x2F;2113" rel="nofollow noreferrer">https:&#x2F;&#x2F;eber.uek.krakow.pl&#x2F;index.php&#x2F;eber&#x2F;article&#x2F;view&#x2F;2113</a><p><a href="https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;pdf&#x2F;10.1177&#x2F;10242589221147228" rel="nofollow noreferrer">https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;pdf&#x2F;10.1177&#x2F;102425892211472...</a><p><a href="https:&#x2F;&#x2F;jc.gatspress.com&#x2F;pdf&#x2F;existential_risk_and_powerseeking_ai.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;jc.gatspress.com&#x2F;pdf&#x2F;existential_risk_and_powerseeki...</a><p>For just a handful of examples from the vast literature published in this area.</div><br/><div id="38377538" class="c"><input type="checkbox" id="c-38377538" checked=""/><div class="controls bullet"><span class="by">epups</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376283">parent</a><span>|</span><a href="#38376435">next</a><span>|</span><label class="collapse" for="c-38377538">[-]</label><label class="expand" for="c-38377538">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m familiar with the potential risks of an out-of-control AGI. Can you summarise in one paragraph which of these risks concern you, or the safety advocates, in regards to a product like ChatGPT?</div><br/><div id="38382213" class="c"><input type="checkbox" id="c-38382213" checked=""/><div class="controls bullet"><span class="by">FartyMcFarter</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38377538">parent</a><span>|</span><a href="#38376435">next</a><span>|</span><label class="collapse" for="c-38382213">[-]</label><label class="expand" for="c-38382213">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not only about ChatGPT. OpenAI will probably make other things in the future.</div><br/></div></div></div></div></div></div><div id="38376435" class="c"><input type="checkbox" id="c-38376435" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376283">prev</a><span>|</span><a href="#38376458">next</a><span>|</span><label class="collapse" for="c-38376435">[-]</label><label class="expand" for="c-38376435">[2 more]</label></div><br/><div class="children"><div class="content">They invented a whole theory of how if we had something called &quot;AGI&quot; it would kill everyone, and now they think LLMs can kill everyone because they&#x27;re calling it &quot;AGI&quot;, even though it doesn&#x27;t work anything like their theory assumed.<p>This isn&#x27;t about political correctness. It&#x27;s far less reasonable than that.</div><br/><div id="38377696" class="c"><input type="checkbox" id="c-38377696" checked=""/><div class="controls bullet"><span class="by">epups</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376435">parent</a><span>|</span><a href="#38376458">next</a><span>|</span><label class="collapse" for="c-38377696">[-]</label><label class="expand" for="c-38377696">[1 more]</label></div><br/><div class="children"><div class="content">Based on the downvotes I am getting and the links posted in the other comment, I think you are absolutely right. People are acting as if ChatGPT is AGI, or very close to it, therefore we have to solve all these catastrophic scenarios now.</div><br/></div></div></div></div><div id="38376458" class="c"><input type="checkbox" id="c-38376458" checked=""/><div class="controls bullet"><span class="by">robryk</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376435">prev</a><span>|</span><a href="#38375431">next</a><span>|</span><label class="collapse" for="c-38376458">[-]</label><label class="expand" for="c-38376458">[1 more]</label></div><br/><div class="children"><div class="content">Consider that your argument could also be used to advocate for safety of starting to use coal-fired steam engines (in 19th century UK): there&#x27;s no immediate direct problem, but competitive pressures force everyone to use them and any externalities stemming from that are basically unavoidable.</div><br/></div></div></div></div><div id="38375431" class="c"><input type="checkbox" id="c-38375431" checked=""/><div class="controls bullet"><span class="by">crakenzak</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376025">prev</a><span>|</span><a href="#38376111">next</a><span>|</span><label class="collapse" for="c-38375431">[-]</label><label class="expand" for="c-38375431">[1 more]</label></div><br/><div class="children"><div class="content">Context?</div><br/></div></div></div></div><div id="38376111" class="c"><input type="checkbox" id="c-38376111" checked=""/><div class="controls bullet"><span class="by">didip</span><span>|</span><a href="#38375366">prev</a><span>|</span><a href="#38375543">next</a><span>|</span><label class="collapse" for="c-38376111">[-]</label><label class="expand" for="c-38376111">[4 more]</label></div><br/><div class="children"><div class="content">Let’s be real here. At the end of the day, what matters more is commercial success and a big payout.<p>AGI is still very far away and the fear mongering is nothing but PR stunt.<p>But the devs need their big payout now. Which explains the mutiny.<p>The “safety” board of directors drank their own koolaid a bit too much.</div><br/><div id="38377280" class="c"><input type="checkbox" id="c-38377280" checked=""/><div class="controls bullet"><span class="by">mkii</span><span>|</span><a href="#38376111">parent</a><span>|</span><a href="#38375543">next</a><span>|</span><label class="collapse" for="c-38377280">[-]</label><label class="expand" for="c-38377280">[3 more]</label></div><br/><div class="children"><div class="content">You can have unsafe AI without AGI.</div><br/><div id="38379583" class="c"><input type="checkbox" id="c-38379583" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#38376111">root</a><span>|</span><a href="#38377280">parent</a><span>|</span><a href="#38379970">next</a><span>|</span><label class="collapse" for="c-38379583">[-]</label><label class="expand" for="c-38379583">[1 more]</label></div><br/><div class="children"><div class="content">Of course, it depends on what safety means. Currently it seems to just be a pretext for prudishness and regulation.</div><br/></div></div><div id="38379970" class="c"><input type="checkbox" id="c-38379970" checked=""/><div class="controls bullet"><span class="by">kuchenbecker</span><span>|</span><a href="#38376111">root</a><span>|</span><a href="#38377280">parent</a><span>|</span><a href="#38379583">prev</a><span>|</span><a href="#38375543">next</a><span>|</span><label class="collapse" for="c-38379970">[-]</label><label class="expand" for="c-38379970">[1 more]</label></div><br/><div class="children"><div class="content">What will this unsafe AI do?</div><br/></div></div></div></div></div></div><div id="38375543" class="c"><input type="checkbox" id="c-38375543" checked=""/><div class="controls bullet"><span class="by">wannacboatmovie</span><span>|</span><a href="#38376111">prev</a><span>|</span><label class="collapse" for="c-38375543">[-]</label><label class="expand" for="c-38375543">[2 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen this many nerds in a froth since Apple walked back the butterfly keyboards in the MacBook.</div><br/><div id="38375670" class="c"><input type="checkbox" id="c-38375670" checked=""/><div class="controls bullet"><span class="by">travisgriggs</span><span>|</span><a href="#38375543">parent</a><span>|</span><label class="collapse" for="c-38375670">[-]</label><label class="expand" for="c-38375670">[1 more]</label></div><br/><div class="children"><div class="content">I know we’re supposed to optimize for “content with a contribution” in HN, but this captured in parody form more of a contribution of how I too have felt.<p>I use these tools as one of many tools to amplify my development. And I’ve written some funny&#x2F;clever satirical poems about office politics. But really? I needed to call Verizon to clear up an issue today, it desperately wanted me to use their assistant. I tried for the grins. A tool that predictively  generates plausibility is going to have its limits. It went from cute&#x2F;amusing to annoying as hell and give me a “love agent” pretty quickly.<p>That this little TechBro Drama has dominated a huge amount of headlines (we’ve been running at least 3 of the top 30 posts at a time on HN here related to this subject) at a time when there is so much bigger things going on in the world. The demise of Twitter generated less headlines. Either the news cycles are getting more and more desperate, or the software development ecosystem is struggling to generate fund raising enthusiasm more and more.</div><br/></div></div></div></div></div></div></div></div></div></body></html>