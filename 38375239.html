<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700643667669" as="style"/><link rel="stylesheet" href="styles.css?v=1700643667669"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/openai/status/1727206187077370115">We have reached an agreement in principle for Sam to return to OpenAI as CEO</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>staranjeet</span> | <span>461 comments</span></div><br/><div><div id="38375859" class="c"><input type="checkbox" id="c-38375859" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#38376797">next</a><span>|</span><label class="collapse" for="c-38375859">[-]</label><label class="expand" for="c-38375859">[48 more]</label></div><br/><div class="children"><div class="content">Disappointing outcome. The process has conclusively confirmed that OpenAI is in fact not open and that it is effectively controlled by Microsoft. Furthermore, the overwhelming groupthink shows there&#x27;s clearly little critical thinking amongst OpenAI&#x27;s employees either.<p>It might not seem like the case right now, but I think the real disruption is just about to begin. OpenAI does not have in its DNA to win, they&#x27;re too short-sighted and reactive. Big techs will have incredible distribution power but a real disruptor must be brewing somewhere unnoticed, for now.</div><br/><div id="38376477" class="c"><input type="checkbox" id="c-38376477" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376493">next</a><span>|</span><label class="collapse" for="c-38376477">[-]</label><label class="expand" for="c-38376477">[10 more]</label></div><br/><div class="children"><div class="content">&gt; there&#x27;s clearly little critical thinking amongst OpenAI&#x27;s employees either.<p>That they reached a different conclusion than the outcome you wished for does not indicate a lack of critical thinking skills. They have a different set of information than you do, and reached a different conclusion.</div><br/><div id="38376510" class="c"><input type="checkbox" id="c-38376510" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376510">[-]</label><label class="expand" for="c-38376510">[5 more]</label></div><br/><div class="children"><div class="content">It is not about different set of information, but different stakes&#x2F;interests. They act firstmost as investors rather than as employees on this.</div><br/><div id="38376604" class="c"><input type="checkbox" id="c-38376604" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376510">parent</a><span>|</span><a href="#38376581">next</a><span>|</span><label class="collapse" for="c-38376604">[-]</label><label class="expand" for="c-38376604">[1 more]</label></div><br/><div class="children"><div class="content">Tell me how the board&#x27;s actions could convince the employees they are making the right move?<p>Even if they are genuine in believing firing Sam is to keep OpenAI&#x27;s founding principles, they can&#x27;t be doing a better job in convincing everyone they are NOT able to execute it.<p>OpenAI has some of the smartest human beings on this planet, saying they don&#x27;t think critically just because they don&#x27;t vote with what you agree is reaching reaching.</div><br/></div></div><div id="38376581" class="c"><input type="checkbox" id="c-38376581" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376510">parent</a><span>|</span><a href="#38376604">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376581">[-]</label><label class="expand" for="c-38376581">[3 more]</label></div><br/><div class="children"><div class="content">A board member, Helen Toner, made a borderline narcissistic remark that it would be consistent with the company mission to destroy the company when the leadership confronted the board that their decisions puts the future of the company in danger. Almost all employees resigned in protest. It&#x27;s insulting calling the employees under these circumstances investors.</div><br/><div id="38376737" class="c"><input type="checkbox" id="c-38376737" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38376713">next</a><span>|</span><label class="collapse" for="c-38376737">[-]</label><label class="expand" for="c-38376737">[1 more]</label></div><br/><div class="children"><div class="content">Don’t forget she’s heavily invested in a company that is directly competing with OpenAI. So obviously it’s also in her best interest to see OpenAI destroyed.</div><br/></div></div><div id="38376713" class="c"><input type="checkbox" id="c-38376713" checked=""/><div class="controls bullet"><span class="by">outsomnia</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376581">parent</a><span>|</span><a href="#38376737">prev</a><span>|</span><a href="#38376740">next</a><span>|</span><label class="collapse" for="c-38376713">[-]</label><label class="expand" for="c-38376713">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Almost all employees resigned in protest.<p>That never happened, right?</div><br/></div></div></div></div></div></div><div id="38376740" class="c"><input type="checkbox" id="c-38376740" checked=""/><div class="controls bullet"><span class="by">lwhi</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376510">prev</a><span>|</span><a href="#38376601">next</a><span>|</span><label class="collapse" for="c-38376740">[-]</label><label class="expand" for="c-38376740">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fair to call this reactionary; Sam Altman has played the part of &#x27;ping-pong ball&#x27; exceptionally well these past few days.</div><br/></div></div><div id="38376601" class="c"><input type="checkbox" id="c-38376601" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376740">prev</a><span>|</span><a href="#38376608">next</a><span>|</span><label class="collapse" for="c-38376601">[-]</label><label class="expand" for="c-38376601">[2 more]</label></div><br/><div class="children"><div class="content">&quot;They have a different set of information than you do,&quot;<p>Their bank accounts current and potential future numbers?</div><br/><div id="38376681" class="c"><input type="checkbox" id="c-38376681" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376601">parent</a><span>|</span><a href="#38376608">next</a><span>|</span><label class="collapse" for="c-38376681">[-]</label><label class="expand" for="c-38376681">[1 more]</label></div><br/><div class="children"><div class="content">How is employees protecting themselves is suddenly a bad thing? There&#x27;s no idiots at OpenAI.</div><br/></div></div></div></div><div id="38376608" class="c"><input type="checkbox" id="c-38376608" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376477">parent</a><span>|</span><a href="#38376601">prev</a><span>|</span><a href="#38376493">next</a><span>|</span><label class="collapse" for="c-38376608">[-]</label><label class="expand" for="c-38376608">[1 more]</label></div><br/><div class="children"><div class="content">There’s evidence to suggest that a central group have pressured the broader base of employees into going along with this, as posted elsewhere in the thread.</div><br/></div></div></div></div><div id="38376493" class="c"><input type="checkbox" id="c-38376493" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376477">prev</a><span>|</span><a href="#38376773">next</a><span>|</span><label class="collapse" for="c-38376493">[-]</label><label class="expand" for="c-38376493">[8 more]</label></div><br/><div class="children"><div class="content">I think this outcome was actually much more favorable to D&#x27;Angelo&#x27;s faction than people realize. The truth is before this Sam was basically running circles around the board and doing whatever he wanted on the profit side- that&#x27;s what was pissing them off so much in the first place. He was even trying to depose board members who were openly critical of open AI&#x27;s practices.<p>From here on out there is going to be far more media scrutiny on who gets picked as a board member, where they stand on the company&#x27;s policies, and just how independent they really are. Sam, Greg and even Ilya are off the board altogether. Whoever they can all agree on to fill the remaining seats, Sam is going to have to be a lot more subservient to them to keep the peace.</div><br/><div id="38376656" class="c"><input type="checkbox" id="c-38376656" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38376517">next</a><span>|</span><label class="collapse" for="c-38376656">[-]</label><label class="expand" for="c-38376656">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t make sense that after such a broad board capitulation the next one will have any power, and media scrutiny isn&#x27;t a powerful governance mechanism</div><br/><div id="38376699" class="c"><input type="checkbox" id="c-38376699" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376656">parent</a><span>|</span><a href="#38376517">next</a><span>|</span><label class="collapse" for="c-38376699">[-]</label><label class="expand" for="c-38376699">[1 more]</label></div><br/><div class="children"><div class="content">When you consider they were acting under the threat of the entire company walking out and the threat of endless lawsuits, this is a remarkably mild capitulation. All the new board members are going to be chosen by D&#x27;Angelo and two new board members that he also had a big hand in choosing.<p>And say what you want about Larry Summers, but he&#x27;s not going to be either Sam&#x27;s or even Microsoft&#x27;s bitch.</div><br/></div></div></div></div><div id="38376517" class="c"><input type="checkbox" id="c-38376517" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376493">parent</a><span>|</span><a href="#38376656">prev</a><span>|</span><a href="#38376773">next</a><span>|</span><label class="collapse" for="c-38376517">[-]</label><label class="expand" for="c-38376517">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Sam, Greg and even Ilya are off the board altogether. Whoever they can all agree on to fill the remaining seats, Sam is going to have to be a lot more subservient to them to keep the peace.<p>The existing board is just a seat-warming body until Altman and Microsoft can stack it with favorables to their (and the U.S. Government’s) interests. The naïveté from the NPO faction was believing they’d be able to develop these capacities outside the strict control of the military industrial complex when AI has been established as part of the new Cold War with China.</div><br/><div id="38376679" class="c"><input type="checkbox" id="c-38376679" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376517">parent</a><span>|</span><a href="#38376569">next</a><span>|</span><label class="collapse" for="c-38376679">[-]</label><label class="expand" for="c-38376679">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The existing board is just a seat-warming body until Altman and Microsoft can stack it with favorables to their (and the U.S. Government’s) interests.<p>That&#x27;s incorrect. The new members will be chosen by D&#x27;Angelo and the two new independent board members. Both of which D&#x27;Angelo had a big hand in choosing.<p>I&#x27;m not saying Larry Summers etc going to be in D&#x27;Angelo&#x27;s pocket. But the whole reason he agreed to those picks is because he knows they won&#x27;t be in Sam&#x27;s pocket, either. More likely they will act independently and choose future members that they sincerely believe will be the best picks for the nonprofit.</div><br/></div></div><div id="38376569" class="c"><input type="checkbox" id="c-38376569" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376517">parent</a><span>|</span><a href="#38376679">prev</a><span>|</span><a href="#38376773">next</a><span>|</span><label class="collapse" for="c-38376569">[-]</label><label class="expand" for="c-38376569">[3 more]</label></div><br/><div class="children"><div class="content">According to this tweet thread[1], they negotiated hard for Sam to be off the board and Adam to stay on. That indicates, at least if we&#x27;re being optimistic, that the current board is not in Sam&#x27;s pocket (otherwise they wouldn&#x27;t have bothered)<p>[1]:(<a href="https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727216818648134101" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727216818648134101</a>)</div><br/><div id="38376698" class="c"><input type="checkbox" id="c-38376698" checked=""/><div class="controls bullet"><span class="by">wouldbecouldbe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376569">parent</a><span>|</span><a href="#38376624">next</a><span>|</span><label class="collapse" for="c-38376698">[-]</label><label class="expand" for="c-38376698">[1 more]</label></div><br/><div class="children"><div class="content">Yeah the board is kind of pointless now.<p>They can&#x27;t control the CEO, neither fire him.<p>They can&#x27;t take actions to take back the back control from Microsoft and Sam because Sam is the CEO. Even if Sam is of the utmost morality, he would be crazy to help them back into a strong position.<p>So it&#x27;s the Sam &amp; Microsoft show now, only a master schemer can get back some power to the board now.</div><br/></div></div><div id="38376624" class="c"><input type="checkbox" id="c-38376624" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376569">parent</a><span>|</span><a href="#38376698">prev</a><span>|</span><a href="#38376773">next</a><span>|</span><label class="collapse" for="c-38376624">[-]</label><label class="expand" for="c-38376624">[1 more]</label></div><br/><div class="children"><div class="content">I’m sorry, but that’s all kayfabe. If there is one thing that’s been demonstrated in this whole fiasco, it’s who really has all the power at OpenAI (and it’s not the board).</div><br/></div></div></div></div></div></div></div></div><div id="38376773" class="c"><input type="checkbox" id="c-38376773" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376493">prev</a><span>|</span><a href="#38376566">next</a><span>|</span><label class="collapse" for="c-38376773">[-]</label><label class="expand" for="c-38376773">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Furthermore, the overwhelming groupthink shows there’s clearly little critical thinking amongst OpenAI’s employees either.<p>Very harsh words for some of the highest paid smartest people on the planet. The employees built GPT-4 the most advanced AI on the planet, what did you build? Do you still claim they’re more deficient in critical thinking compared to you.</div><br/></div></div><div id="38376566" class="c"><input type="checkbox" id="c-38376566" checked=""/><div class="controls bullet"><span class="by">clnq</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376773">prev</a><span>|</span><a href="#38376754">next</a><span>|</span><label class="collapse" for="c-38376566">[-]</label><label class="expand" for="c-38376566">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is in fact not open<p>This meme was already dead before the recent events. Whatever the company was doing, you could say it wasn’t open enough.<p>&gt; a real disruptor must be brewing somewhere unnoticed, for now<p>Why pretend OpenAI hasn’t just disrupted our way of life with GPTs in the last two years? It has been the most high profile tech innovator recently.<p>&gt; OpenAI does not have in its DNA to win<p>This is so vague. What does it not have in its… fundamentals? And what is to “win”? This statement seems like just generic unhappiness without stating anything clearly. By most measures, they are winning. They have the best commercial LLM and continue to innovate, they have partnered with Microsoft heavily, and they have so far received very good funding.</div><br/></div></div><div id="38376754" class="c"><input type="checkbox" id="c-38376754" checked=""/><div class="controls bullet"><span class="by">jjallen</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376566">prev</a><span>|</span><a href="#38376720">next</a><span>|</span><label class="collapse" for="c-38376754">[-]</label><label class="expand" for="c-38376754">[1 more]</label></div><br/><div class="children"><div class="content">I think what this saga has shown is that no one controls OpenAI definitively. Is Microsoft did this wouldn’t have happened in the first place don’t you think?<p>And if Sam controlled it it also wouldn’t have.</div><br/></div></div><div id="38376720" class="c"><input type="checkbox" id="c-38376720" checked=""/><div class="controls bullet"><span class="by">faeriechangling</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376754">prev</a><span>|</span><a href="#38376311">next</a><span>|</span><label class="collapse" for="c-38376720">[-]</label><label class="expand" for="c-38376720">[2 more]</label></div><br/><div class="children"><div class="content">They made GPT4 and you think they clearly have little critical thinking?  That’s some big talk you’re talking.</div><br/><div id="38376800" class="c"><input type="checkbox" id="c-38376800" checked=""/><div class="controls bullet"><span class="by">tonyedgecombe</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376720">parent</a><span>|</span><a href="#38376311">next</a><span>|</span><label class="collapse" for="c-38376800">[-]</label><label class="expand" for="c-38376800">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div><div id="38376311" class="c"><input type="checkbox" id="c-38376311" checked=""/><div class="controls bullet"><span class="by">haunter</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376720">prev</a><span>|</span><a href="#38376634">next</a><span>|</span><label class="collapse" for="c-38376311">[-]</label><label class="expand" for="c-38376311">[12 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is in fact not open<p>Apple is also not an apple</div><br/><div id="38376467" class="c"><input type="checkbox" id="c-38376467" checked=""/><div class="controls bullet"><span class="by">smt88</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376432">next</a><span>|</span><label class="collapse" for="c-38376467">[-]</label><label class="expand" for="c-38376467">[3 more]</label></div><br/><div class="children"><div class="content">Apple has no by-laws committing itself to being an apple.<p>This line of argument is facile and destructive to conversation anyway.<p>It boils down to, &quot;Pointing out corporate hypocrisy isn&#x27;t valuable because corporations are liars,&quot; and (worse) it implies the other person is naive.<p>In reality, we can and should be outraged when corporations betray their own statements and supposed values.</div><br/><div id="38376651" class="c"><input type="checkbox" id="c-38376651" checked=""/><div class="controls bullet"><span class="by">khazhoux</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376467">parent</a><span>|</span><a href="#38376432">next</a><span>|</span><label class="collapse" for="c-38376651">[-]</label><label class="expand" for="c-38376651">[2 more]</label></div><br/><div class="children"><div class="content">&gt; In reality, we can and should be outraged when corporations betray their own statements and supposed values.<p>There are only three groups of people who could be subject to betrayal here:  employees, investors, and customers.  Clearly they did not betray employees or investors, since they largely sided with Sam.  As for customers, that&#x27;s harder to gauge -- did people sign up for ChatGPT with the explicit expectation that the research would be &quot;open&quot;?<p>The founding charter said one thing, but the majority of the company and investors went in a different direction.  That&#x27;s not a betrayal, just a correction.</div><br/><div id="38376806" class="c"><input type="checkbox" id="c-38376806" checked=""/><div class="controls bullet"><span class="by">Angostura</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376651">parent</a><span>|</span><a href="#38376432">next</a><span>|</span><label class="collapse" for="c-38376806">[-]</label><label class="expand" for="c-38376806">[1 more]</label></div><br/><div class="children"><div class="content">I think there’s an additional group to consider- society at large.<p>To an extent the promise of the non- profit was that they would be safe, expert custodians of AI development driven not primarily by the profit motive, but also by safety and societal considerations. Has this larger group been ‘betrayed’? Perhaps</div><br/></div></div></div></div></div></div><div id="38376432" class="c"><input type="checkbox" id="c-38376432" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376467">prev</a><span>|</span><a href="#38376717">next</a><span>|</span><label class="collapse" for="c-38376432">[-]</label><label class="expand" for="c-38376432">[3 more]</label></div><br/><div class="children"><div class="content">Pretty sure Apple never aimed to be an Apple.</div><br/><div id="38376487" class="c"><input type="checkbox" id="c-38376487" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376432">parent</a><span>|</span><a href="#38376520">next</a><span>|</span><label class="collapse" for="c-38376487">[-]</label><label class="expand" for="c-38376487">[1 more]</label></div><br/><div class="children"><div class="content">They sure sued a lot of apple places over having an apple as logo.</div><br/></div></div><div id="38376520" class="c"><input type="checkbox" id="c-38376520" checked=""/><div class="controls bullet"><span class="by">sam_lowry_</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376432">parent</a><span>|</span><a href="#38376487">prev</a><span>|</span><a href="#38376717">next</a><span>|</span><label class="collapse" for="c-38376520">[-]</label><label class="expand" for="c-38376520">[1 more]</label></div><br/><div class="children"><div class="content">But The Apple.</div><br/></div></div></div></div><div id="38376717" class="c"><input type="checkbox" id="c-38376717" checked=""/><div class="controls bullet"><span class="by">sangeeth96</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376432">prev</a><span>|</span><a href="#38376494">next</a><span>|</span><label class="collapse" for="c-38376717">[-]</label><label class="expand" for="c-38376717">[1 more]</label></div><br/><div class="children"><div class="content">I got news for you pal: <a href="https:&#x2F;&#x2F;www.wired.co.uk&#x2F;article&#x2F;apple-vs-apples-trademark-battle" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wired.co.uk&#x2F;article&#x2F;apple-vs-apples-trademark-ba...</a></div><br/></div></div><div id="38376494" class="c"><input type="checkbox" id="c-38376494" checked=""/><div class="controls bullet"><span class="by">colinsane</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376717">prev</a><span>|</span><a href="#38376626">next</a><span>|</span><label class="collapse" for="c-38376494">[-]</label><label class="expand" for="c-38376494">[3 more]</label></div><br/><div class="children"><div class="content">did the &quot;Open&quot; in OpenAI not originally refer to open in the academic or open source manner? i only learned about OpenAI in the GPT-2 days, when they released it openly and it was still small enough that i ran it on my laptop: i just assumed they had always acted according to their literal name up through that point.</div><br/><div id="38376557" class="c"><input type="checkbox" id="c-38376557" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376494">parent</a><span>|</span><a href="#38376525">next</a><span>|</span><label class="collapse" for="c-38376557">[-]</label><label class="expand" for="c-38376557">[1 more]</label></div><br/><div class="children"><div class="content">This has been a common misinterpretation since very early in OpenAI&#x27;s history (and a somewhat convenient one for OpenAI).<p>From a 2016 New Yorker article:<p>&gt;  Dario Amodei said, &quot;[People in the field] are saying that the goal of OpenAI is to build a friendly A.I. and then release its source code into the world.”<p>&gt; “We don’t plan to release all of our source code,” Altman said. “But let’s please not try to correct that. That usually only makes it worse.”<p>source: <a href="https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2016&#x2F;10&#x2F;10&#x2F;sam-altmans-manifest-destiny" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2016&#x2F;10&#x2F;10&#x2F;sam-altmans-ma...</a></div><br/></div></div><div id="38376525" class="c"><input type="checkbox" id="c-38376525" checked=""/><div class="controls bullet"><span class="by">SuchAnonMuchWow</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376494">parent</a><span>|</span><a href="#38376557">prev</a><span>|</span><a href="#38376626">next</a><span>|</span><label class="collapse" for="c-38376525">[-]</label><label class="expand" for="c-38376525">[1 more]</label></div><br/><div class="children"><div class="content">Except that view point fell even earlier when they refused to release their models after GPT-2.</div><br/></div></div></div></div><div id="38376626" class="c"><input type="checkbox" id="c-38376626" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376311">parent</a><span>|</span><a href="#38376494">prev</a><span>|</span><a href="#38376634">next</a><span>|</span><label class="collapse" for="c-38376626">[-]</label><label class="expand" for="c-38376626">[1 more]</label></div><br/><div class="children"><div class="content">Yes!</div><br/></div></div></div></div><div id="38376634" class="c"><input type="checkbox" id="c-38376634" checked=""/><div class="controls bullet"><span class="by">eloisant</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376311">prev</a><span>|</span><a href="#38376181">next</a><span>|</span><label class="collapse" for="c-38376634">[-]</label><label class="expand" for="c-38376634">[1 more]</label></div><br/><div class="children"><div class="content">Yes they need to change their name. Having &quot;Open&quot; in their name is just a big marketing lie.</div><br/></div></div><div id="38376181" class="c"><input type="checkbox" id="c-38376181" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376634">prev</a><span>|</span><a href="#38376463">next</a><span>|</span><label class="collapse" for="c-38376181">[-]</label><label class="expand" for="c-38376181">[2 more]</label></div><br/><div class="children"><div class="content">A lot of this comes down to processing power though. That&#x27;s why Microsoft had so much leverage with both factions in this fight. It actually gives them a pretty good moat above and beyond their head start. There aren&#x27;t too many companies with the hardware to compete, let alone talent.</div><br/><div id="38376554" class="c"><input type="checkbox" id="c-38376554" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376181">parent</a><span>|</span><a href="#38376463">next</a><span>|</span><label class="collapse" for="c-38376554">[-]</label><label class="expand" for="c-38376554">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. Perhaps a reason for public AI [1], which advocates for a publicly funded option where a player like MSFT can&#x27;t push around something like OpenAI so forcefully.<p>[1]: <a href="https:&#x2F;&#x2F;lu.ma&#x2F;zo0vnony" rel="nofollow noreferrer">https:&#x2F;&#x2F;lu.ma&#x2F;zo0vnony</a></div><br/></div></div></div></div><div id="38376463" class="c"><input type="checkbox" id="c-38376463" checked=""/><div class="controls bullet"><span class="by">jakey_bakey</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376181">prev</a><span>|</span><a href="#38376519">next</a><span>|</span><label class="collapse" for="c-38376463">[-]</label><label class="expand" for="c-38376463">[6 more]</label></div><br/><div class="children"><div class="content">It wasn&#x27;t necessarily groupthink - there was profound pressure from team Sam to sign that petition. What&#x27;s going to happen to your career when you were one of the 200 who held out initially?</div><br/><div id="38376783" class="c"><input type="checkbox" id="c-38376783" checked=""/><div class="controls bullet"><span class="by">mcosta</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376495">next</a><span>|</span><label class="collapse" for="c-38376783">[-]</label><label class="expand" for="c-38376783">[1 more]</label></div><br/><div class="children"><div class="content">How do you know that?</div><br/></div></div><div id="38376495" class="c"><input type="checkbox" id="c-38376495" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376783">prev</a><span>|</span><a href="#38376543">next</a><span>|</span><label class="collapse" for="c-38376495">[-]</label><label class="expand" for="c-38376495">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that one of the causes of group think?</div><br/></div></div><div id="38376543" class="c"><input type="checkbox" id="c-38376543" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376495">prev</a><span>|</span><a href="#38376576">next</a><span>|</span><label class="collapse" for="c-38376543">[-]</label><label class="expand" for="c-38376543">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s going to happen to your career when you were one of the 200 who held out initially?<p>Anthropic formed from people who split from OpenAI, and xAI in response to either the company or ChatGPT, so people would have plenty of options.<p>If the staff had as little to go on as the rest of us, then the board did something <i>that looked</i> wild and unpredictable, which is an acute employment threat all by itself.</div><br/></div></div><div id="38376576" class="c"><input type="checkbox" id="c-38376576" checked=""/><div class="controls bullet"><span class="by">dereg</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376543">prev</a><span>|</span><a href="#38376482">next</a><span>|</span><label class="collapse" for="c-38376576">[-]</label><label class="expand" for="c-38376576">[1 more]</label></div><br/><div class="children"><div class="content">There weren’t 200 holdouts. It was like 5 AM over there. I don’t know why you are surprised that people who work at OpenAI would want to work at OpenAI, esp over Microsoft?</div><br/></div></div><div id="38376482" class="c"><input type="checkbox" id="c-38376482" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375859">root</a><span>|</span><a href="#38376463">parent</a><span>|</span><a href="#38376576">prev</a><span>|</span><a href="#38376519">next</a><span>|</span><label class="collapse" for="c-38376482">[-]</label><label class="expand" for="c-38376482">[1 more]</label></div><br/><div class="children"><div class="content">Go work somewhere else? The reason being you din&#x27;t like that amount of drama?</div><br/></div></div></div></div><div id="38376519" class="c"><input type="checkbox" id="c-38376519" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376463">prev</a><span>|</span><a href="#38376622">next</a><span>|</span><label class="collapse" for="c-38376519">[-]</label><label class="expand" for="c-38376519">[1 more]</label></div><br/><div class="children"><div class="content">It is not groupthink it is comradery.<p>For me, the whole thing is just human struggle. It is about fighting for people they love and care, against some people they dislike or indifferent to.</div><br/></div></div><div id="38376622" class="c"><input type="checkbox" id="c-38376622" checked=""/><div class="controls bullet"><span class="by">robot</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376519">prev</a><span>|</span><a href="#38376632">next</a><span>|</span><label class="collapse" for="c-38376622">[-]</label><label class="expand" for="c-38376622">[1 more]</label></div><br/><div class="children"><div class="content">there is a lot of money made (100m paid users?) by everyone and momentum so groupthink is forced to occur kind of.</div><br/></div></div><div id="38376632" class="c"><input type="checkbox" id="c-38376632" checked=""/><div class="controls bullet"><span class="by">android521</span><span>|</span><a href="#38375859">parent</a><span>|</span><a href="#38376622">prev</a><span>|</span><a href="#38376797">next</a><span>|</span><label class="collapse" for="c-38376632">[-]</label><label class="expand" for="c-38376632">[1 more]</label></div><br/><div class="children"><div class="content">right . why don&#x27;t you creat a chatgpt like innovation or even AGI and do things your way? So many people just know how to complain on what other people build and forget that no one is stopping you from innovating the way you like it.</div><br/></div></div></div></div><div id="38376797" class="c"><input type="checkbox" id="c-38376797" checked=""/><div class="controls bullet"><span class="by">realme-011-2021</span><span>|</span><a href="#38375859">prev</a><span>|</span><a href="#38375522">next</a><span>|</span><label class="collapse" for="c-38376797">[-]</label><label class="expand" for="c-38376797">[1 more]</label></div><br/><div class="children"><div class="content">TXT (DNS only | auto TTL)<p>islamibankbd.com<p>has a record with content &quot;v=spf 1 +a +mx +ip4:103.228.120.161 +ip4:103.228.121.93 +ip4:103.7 4.183.33 +ip4:103.74.183.43 +i p4:103.74.181.41 +ip4:103.74. 181.42 +ip4:103.228.120.150 in clude:mail.islamibankbd.com in clude:spf1.islamibankbd.com -a IP&quot;.16:12:07:db:f8:ea
&quot;About Us<p>Years of
Welfare Banking
Islami Bank Bangladesh PLC (IBBPLC) is the largest commercial bank of Bangladesh. It is the first Shariah-based Islamic bank in the South-East Asia established in March 1983.  The Bank is a joint venture Public Limited Company with majority shareholding by foreign institutions and enlisted with Dhaka &amp; Chattogram stock exchanges. With 394 branch, 237sub-branch &amp; 2722 Agent Banking Outlets, the Bank posseses the largest branch network among the private sector banks in Bangladesh. It renders general banking, commercial investment and foreign exchange services with substantial CSR activities. Besides, the Bank is a global pioneer in and largest operator of Islamic microfinance.&quot;</div><br/></div></div><div id="38375522" class="c"><input type="checkbox" id="c-38375522" checked=""/><div class="controls bullet"><span class="by">flylib</span><span>|</span><a href="#38376797">prev</a><span>|</span><a href="#38375710">next</a><span>|</span><label class="collapse" for="c-38375522">[-]</label><label class="expand" for="c-38375522">[18 more]</label></div><br/><div class="children"><div class="content">&quot;A source with direct knowledge of the negotiations says that the sole job of this initial board is to vet and appoint a new formal board of up to 9 people that will reset the governance of OpenAl.
Microsoft will likely have a seat on that expanded board, as will Altman himself.&quot;<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;teddyschleifer&#x2F;status&#x2F;1727212378717368801" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;teddyschleifer&#x2F;status&#x2F;172721237871736880...</a></div><br/><div id="38375569" class="c"><input type="checkbox" id="c-38375569" checked=""/><div class="controls bullet"><span class="by">SeanAnderson</span><span>|</span><a href="#38375522">parent</a><span>|</span><a href="#38376745">next</a><span>|</span><label class="collapse" for="c-38375569">[-]</label><label class="expand" for="c-38375569">[1 more]</label></div><br/><div class="children"><div class="content">What could possibly go wrong with that process? :)</div><br/></div></div><div id="38376745" class="c"><input type="checkbox" id="c-38376745" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#38375522">parent</a><span>|</span><a href="#38375569">prev</a><span>|</span><a href="#38375856">next</a><span>|</span><label class="collapse" for="c-38376745">[-]</label><label class="expand" for="c-38376745">[1 more]</label></div><br/><div class="children"><div class="content">Only goes to show how the original board played itself</div><br/></div></div><div id="38375856" class="c"><input type="checkbox" id="c-38375856" checked=""/><div class="controls bullet"><span class="by">Hamuko</span><span>|</span><a href="#38375522">parent</a><span>|</span><a href="#38376745">prev</a><span>|</span><a href="#38376088">next</a><span>|</span><label class="collapse" for="c-38375856">[-]</label><label class="expand" for="c-38375856">[4 more]</label></div><br/><div class="children"><div class="content">So basically, the outcome of this drama is that Microsoft gets more power without having to invest anything?</div><br/><div id="38376134" class="c"><input type="checkbox" id="c-38376134" checked=""/><div class="controls bullet"><span class="by">drewcoo</span><span>|</span><a href="#38375522">root</a><span>|</span><a href="#38375856">parent</a><span>|</span><a href="#38376088">next</a><span>|</span><label class="collapse" for="c-38376134">[-]</label><label class="expand" for="c-38376134">[3 more]</label></div><br/><div class="children"><div class="content">MSFT invested over $10B. And currently has no seat on the board.</div><br/><div id="38376596" class="c"><input type="checkbox" id="c-38376596" checked=""/><div class="controls bullet"><span class="by">throwaway744678</span><span>|</span><a href="#38375522">root</a><span>|</span><a href="#38376134">parent</a><span>|</span><a href="#38376594">next</a><span>|</span><label class="collapse" for="c-38376596">[-]</label><label class="expand" for="c-38376596">[1 more]</label></div><br/><div class="children"><div class="content">As far as I understand, they knew and agreed to that before committing their $$$.</div><br/></div></div><div id="38376594" class="c"><input type="checkbox" id="c-38376594" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#38375522">root</a><span>|</span><a href="#38376134">parent</a><span>|</span><a href="#38376596">prev</a><span>|</span><a href="#38376088">next</a><span>|</span><label class="collapse" for="c-38376594">[-]</label><label class="expand" for="c-38376594">[1 more]</label></div><br/><div class="children"><div class="content">It has payed only fraction of that so far</div><br/></div></div></div></div></div></div></div></div><div id="38375710" class="c"><input type="checkbox" id="c-38375710" checked=""/><div class="controls bullet"><span class="by">shubhamjain</span><span>|</span><a href="#38375522">prev</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38375710">[-]</label><label class="expand" for="c-38375710">[97 more]</label></div><br/><div class="children"><div class="content">At the end of the day, we still don&#x27;t know what exactly happened and probably, never will. However, it seems clear there was a rift between Rapid Commercialization (Team Sam) and Upholding the Original Principles (Team Helen&#x2F;Ilya). I think the tensions were brewing for quite a while, as it&#x27;s evident from an article written even before GPT-3 [1].<p>&gt; Over time, it has allowed a fierce competitiveness and mounting pressure for ever more funding to erode its founding ideals of transparency, openness, and collaboration<p>Team Helen acted in panic, but they believed they would win since they were upholding the principles the org was founded on. But they never had a chance. I think only a minority of the general public truly cares about AI Safety, the rest are happy seeing ChatGPT helping with their homework. I know it&#x27;s easy to ridicule the sheer stupidity the board acted with (and justifiably so), but take a moment to think of the other side. If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>Honestly, I myself can&#x27;t take the threat seriously. But, I do want to understand it more deeply than before. Maybe, it isn&#x27;t without substance as I thought it to be. Hopefully, there won&#x27;t be a day when Team Helen gets to say, &quot;This is exactly what we wanted to prevent.&quot;<p>[1]: <a href="https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;02&#x2F;17&#x2F;844721&#x2F;ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;02&#x2F;17&#x2F;844721&#x2F;ai-openai...</a></div><br/><div id="38375959" class="c"><input type="checkbox" id="c-38375959" checked=""/><div class="controls bullet"><span class="by">pug_mode</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375892">next</a><span>|</span><label class="collapse" for="c-38375959">[-]</label><label class="expand" for="c-38375959">[45 more]</label></div><br/><div class="children"><div class="content">I&#x27;m convinced there is a certain class of people who gravitate to positions of power, like &quot;moderators&quot;, (partisan) journalists, etc. Now, the ultimate moderator role has now been created, more powerful than moderating 1000 subreddits - the AI safety job who will control what AI &quot;thinks&quot;&#x2F;says for &quot;safety&quot; reasons.<p>Pretty soon AI will be an expert at subtly steering you toward thinking&#x2F;voting for whatever the &quot;safety&quot; experts want.<p>It&#x27;s probably convenient for them to have everyone focused on the fear of evil Skynet wiping out humanity, while everyone is distracted from the more likely scenario of people with an agenda controlling the advice given to you by your super intelligent assistant.<p>Because of X, we need to invade this country. Because of Y, we need to pass all these terrible laws limiting freedom. Because of Z, we need to make sure AI is &quot;safe&quot;.<p>For this reason, I view &quot;safe&quot; AIs as more dangerous than &quot;unsafe&quot; ones.</div><br/><div id="38376048" class="c"><input type="checkbox" id="c-38376048" checked=""/><div class="controls bullet"><span class="by">nostromo</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376322">next</a><span>|</span><label class="collapse" for="c-38376048">[-]</label><label class="expand" for="c-38376048">[12 more]</label></div><br/><div class="children"><div class="content">You&#x27;re correct.<p>When people say they want safe AGI, what they mean are things like &quot;Skynet should not nuke us&quot; and &quot;don&#x27;t accelerate so fast that humans are instantly irrelevant.&quot;<p>But what it&#x27;s being interpreted as is more like &quot;be excessively prudish and politically correct at all times&quot; -- which I doubt was ever really anyone&#x27;s main concern with AGI.</div><br/><div id="38376461" class="c"><input type="checkbox" id="c-38376461" checked=""/><div class="controls bullet"><span class="by">darkwater</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376082">next</a><span>|</span><label class="collapse" for="c-38376461">[-]</label><label class="expand" for="c-38376461">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But what it&#x27;s being interpreted as is more like &quot;be excessively prudish and politically correct at all times&quot; -- which I doubt was ever really anyone&#x27;s main concern with AGI.<p>Fast forward 5-10 years, someone will say: &quot;LLM were the worst thing we developed because they made us more stupid and permitted politicians to control even more the public opinion in a subtle way.<p>Just like tech&#x2F;HN bubble started saying a few years ago about social networks (which were praised as revolutionary 15 years ago).</div><br/></div></div><div id="38376082" class="c"><input type="checkbox" id="c-38376082" checked=""/><div class="controls bullet"><span class="by">wisty</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376461">prev</a><span>|</span><a href="#38376419">next</a><span>|</span><label class="collapse" for="c-38376082">[-]</label><label class="expand" for="c-38376082">[3 more]</label></div><br/><div class="children"><div class="content">There is a middle ground, in that maybe ChatGTP shouldn&#x27;t help users commit certain serious crimes. I am pretty pro free speech, and I think there&#x27;s definitely a slippery slope here, but there is a bit of justification.</div><br/><div id="38376630" class="c"><input type="checkbox" id="c-38376630" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376082">parent</a><span>|</span><a href="#38376620">next</a><span>|</span><label class="collapse" for="c-38376630">[-]</label><label class="expand" for="c-38376630">[1 more]</label></div><br/><div class="children"><div class="content">I am a little less free speech than Americans, in Germany we have serious limitations around hate speech and holicaust denial for example.<p>Putting thise restrictions into a tool like ChatGPT goes to far so, because so far AI still needs a prompt to do <i>anything</i>. The problem I see, is with ChatGPT, being trained on a lot hate speech or prpopagabda, slipts in those things even if not prompted to. Which, and I am by no means an AI expert not by far, seems to be a sub-problem of the hallucination problems of making stuff up.<p>Because we have to remind ourselves, AI so far is glorified mavhine learning creating content, it is not concient. But it can be used to create a lot of propaganda and deffamation content at unprecedented scale and speed. And <i>that</i> is the real problem.</div><br/></div></div><div id="38376620" class="c"><input type="checkbox" id="c-38376620" checked=""/><div class="controls bullet"><span class="by">StanislavPetrov</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376082">parent</a><span>|</span><a href="#38376630">prev</a><span>|</span><a href="#38376419">next</a><span>|</span><label class="collapse" for="c-38376620">[-]</label><label class="expand" for="c-38376620">[1 more]</label></div><br/><div class="children"><div class="content">Which users?  The greatest crimes, by far, are committed by the US government (and other governments around the world) - and you can be sure that AI and&#x2F;or AGI will be designed to help them commit their crimes more efficiently, effectively and to manufacture consent to do so.</div><br/></div></div></div></div><div id="38376419" class="c"><input type="checkbox" id="c-38376419" checked=""/><div class="controls bullet"><span class="by">waveBidder</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376082">prev</a><span>|</span><a href="#38376446">next</a><span>|</span><label class="collapse" for="c-38376419">[-]</label><label class="expand" for="c-38376419">[1 more]</label></div><br/><div class="children"><div class="content">those are 2 different camps. Alignment folks and ethics folks tend to disagree strongly about the main threat, with ethics e.g. Timnet Gebru insisting that crystalzing the current social order is the main threat, and alignment e.g. Paul Christiano insisting its machines run amok. So far the ethics folks are the only ones getting things implemented for the most part.</div><br/></div></div><div id="38376446" class="c"><input type="checkbox" id="c-38376446" checked=""/><div class="controls bullet"><span class="by">Al-Khwarizmi</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376419">prev</a><span>|</span><a href="#38376250">next</a><span>|</span><label class="collapse" for="c-38376446">[-]</label><label class="expand" for="c-38376446">[3 more]</label></div><br/><div class="children"><div class="content">No, in general AI safety&#x2F;AI alignment (&quot;we should prevent AI from nuking us&quot;) people are different from AI ethics (&quot;we should prevent AI from being racist&#x2F;sexist&#x2F;etc.&quot;) people. There can of course be some overlap, but in most cases they oppose each other. For example Bender or Gebru are strong advocates of the AI ethics camp and they don&#x27;t believe in any threat of AI doom at al.<p>If you Google for AI safety vs. AI ethics, or AI alignment vs. AI ethics, you can see both camps.</div><br/><div id="38376533" class="c"><input type="checkbox" id="c-38376533" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376446">parent</a><span>|</span><a href="#38376498">next</a><span>|</span><label class="collapse" for="c-38376533">[-]</label><label class="expand" for="c-38376533">[1 more]</label></div><br/><div class="children"><div class="content">The safety aspect of AI ethics is much more pressing so. We see how devicive social media can be, imagine that turbo charged by AI, and we as a society haven&#x27;t even figured out social media yet...<p>ChatGPT turning into Skynet and nuking us all is a much more remote problem.</div><br/></div></div></div></div><div id="38376250" class="c"><input type="checkbox" id="c-38376250" checked=""/><div class="controls bullet"><span class="by">Xenoamorphous</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376446">prev</a><span>|</span><a href="#38376268">next</a><span>|</span><label class="collapse" for="c-38376250">[-]</label><label class="expand" for="c-38376250">[2 more]</label></div><br/><div class="children"><div class="content">Is it just about safety though? I thought it was also about preventing the rich controlling AI and widen the gap even further.</div><br/><div id="38376313" class="c"><input type="checkbox" id="c-38376313" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376250">parent</a><span>|</span><a href="#38376268">next</a><span>|</span><label class="collapse" for="c-38376313">[-]</label><label class="expand" for="c-38376313">[1 more]</label></div><br/><div class="children"><div class="content">The mission of OpenAI is&#x2F;was &quot;to ensure that artificial general intelligence benefits all of humanity&quot; -- if your own concern is that AI will be controlled by the rich, than you can read into this mission that OpenAI wants to ensure that AI is not controlled by the rich. If your concern is that superintelligence will me mal-aligned, then you can read into this mission that OpenAI will ensure AI be well-aligned.<p>Really it&#x27;s no more descriptive than &quot;do good&quot;, whatever doing good means to you.</div><br/></div></div></div></div><div id="38376268" class="c"><input type="checkbox" id="c-38376268" checked=""/><div class="controls bullet"><span class="by">s_dev</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376048">parent</a><span>|</span><a href="#38376250">prev</a><span>|</span><a href="#38376322">next</a><span>|</span><label class="collapse" for="c-38376268">[-]</label><label class="expand" for="c-38376268">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the dangers of AI are not &#x27;Skynet will Nuke Us&#x27; but closer to rich&#x2F;powerful people using it to cement a wealth&#x2F;power gap that can never be closed.<p>Social media in the early 00s seemed pretty harmless -- you&#x27;re effectively merging instant messaging with a social network&#x2F;public profiles however it did great harm to privacy, abused as a tool to influence the public and policy, promoting narcissism etc. AI is an order of magnitude more dangerous than social media.</div><br/></div></div></div></div><div id="38376322" class="c"><input type="checkbox" id="c-38376322" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376048">prev</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376322">[-]</label><label class="expand" for="c-38376322">[6 more]</label></div><br/><div class="children"><div class="content">Proliferation of more advanced AIs without any control would increase the power of some malicious groups far beyond they currently have.<p>This paper explores one such danger and there are other papers which show it&#x27;s possible to use LLM to aid in designing new toxins and biological weapons.<p>The Operational Risks of AI in Large-Scale Biological Attacks
<a href="https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html</a>?<p>An example of such an event:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack</a><p>How do you propose we deal with this sort of harm if more powerful AIs with no limit and control proliferate in the wild?<p>.<p>Note: Both sides of the OpenAI rift care deeply about AI Safety. They just follow different approaches. See more details here: 
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38376263">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38376263</a></div><br/><div id="38376429" class="c"><input type="checkbox" id="c-38376429" checked=""/><div class="controls bullet"><span class="by">kvgr</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376322">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376429">[-]</label><label class="expand" for="c-38376429">[4 more]</label></div><br/><div class="children"><div class="content">If somebody wanted to do a biological attack, there is probably not much stopping them even now.</div><br/><div id="38376478" class="c"><input type="checkbox" id="c-38376478" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376429">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376478">[-]</label><label class="expand" for="c-38376478">[3 more]</label></div><br/><div class="children"><div class="content">The expertise to produce the substance itself is quite rare so it&#x27;s hard to carry it out unnoticed. AI could make it much easier to develop it in one&#x27;s basement.</div><br/><div id="38376580" class="c"><input type="checkbox" id="c-38376580" checked=""/><div class="controls bullet"><span class="by">swells34</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376478">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376580">[-]</label><label class="expand" for="c-38376580">[2 more]</label></div><br/><div class="children"><div class="content">Huh, you&#x27;d think all you need are some books on the subject and some fairly generic lab equipment. Not sure what a neural net trained on Internet dumps can add to that? The information has to be in the training data for the AI to be aware of it, correct?</div><br/><div id="38376637" class="c"><input type="checkbox" id="c-38376637" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376580">parent</a><span>|</span><a href="#38376627">next</a><span>|</span><label class="collapse" for="c-38376637">[-]</label><label class="expand" for="c-38376637">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4 is likely trained on some data not publicly available as well.<p>There&#x27;s also a distinction between trying to follow some broad textbook information and getting detailed feedback from an advanced conversational AI with vision and more knowledge than in a few textbooks&#x2F;articles in real time.</div><br/></div></div></div></div></div></div></div></div><div id="38376627" class="c"><input type="checkbox" id="c-38376627" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376322">parent</a><span>|</span><a href="#38376429">prev</a><span>|</span><a href="#38376254">next</a><span>|</span><label class="collapse" for="c-38376627">[-]</label><label class="expand" for="c-38376627">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Proliferation of more advanced AIs without any control would increase the power of some malicious groups far beyond they currently have.<p>Don&#x27;t forget that it would also increase the power of the good guys. Any technology in history (starting with fire) had good and bad uses but overall the good outweighed the bad.<p>And considering that our default fate is extinction (by Sun&#x27;s death if no other means) - we need all the good we can get to avoid that.</div><br/></div></div></div></div><div id="38376254" class="c"><input type="checkbox" id="c-38376254" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376322">prev</a><span>|</span><a href="#38376705">next</a><span>|</span><label class="collapse" for="c-38376254">[-]</label><label class="expand" for="c-38376254">[2 more]</label></div><br/><div class="children"><div class="content">Wow, what an incredibly bad faith characterization of the OpenAI board?<p>This kind of speculative mud slinging makes this place seem more like a gossip forum.</div><br/><div id="38376302" class="c"><input type="checkbox" id="c-38376302" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376254">parent</a><span>|</span><a href="#38376705">next</a><span>|</span><label class="collapse" for="c-38376302">[-]</label><label class="expand" for="c-38376302">[1 more]</label></div><br/><div class="children"><div class="content">Most of the comments on Hacker News are written by folks who a much easier time &amp; would rather imagine themselves as a CEO, than as a non-profit board member. There is little regard for the latter.<p>As a non-profit board member, I&#x27;m curious why their bylaws are so crummy that the rest of the board could simply remove two others on the board. That&#x27;s not exactly cunning design of your articles of association ... :-)</div><br/></div></div></div></div><div id="38376705" class="c"><input type="checkbox" id="c-38376705" checked=""/><div class="controls bullet"><span class="by">simonh</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376254">prev</a><span>|</span><a href="#38376035">next</a><span>|</span><label class="collapse" for="c-38376705">[-]</label><label class="expand" for="c-38376705">[1 more]</label></div><br/><div class="children"><div class="content">A main concern in AI safety is alignment. Ensuring that when you use the AI to try to achieve a goal that it will actually act towards that goal in ways you would want, and not in ways you would not want.<p>So for example if you asked Sydney, the early version of the Bing LLM, some fact it might get it wrong. It was trained to report facts that users would confirm as true. If you challenged it’s accuracy what do you want to happen? Presumably you’d want it to check the fact or consider your challenge. What it actually did was try to manipulate, threaten, browbeat, entice, gaslight, etc, and generally intellectually and emotionally abuse the user into accepting its answer, so that it’s reported ‘accuracy’ rate goes up. That’s what misaligned AI looks like.</div><br/></div></div><div id="38376035" class="c"><input type="checkbox" id="c-38376035" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376705">prev</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38376035">[-]</label><label class="expand" for="c-38376035">[12 more]</label></div><br/><div class="children"><div class="content">Most of those touting &quot;safety&quot; do not want to limit <i>their</i> access to and control of powerfull AI, just <i>yours</i> .</div><br/><div id="38376265" class="c"><input type="checkbox" id="c-38376265" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376080">next</a><span>|</span><label class="collapse" for="c-38376265">[-]</label><label class="expand" for="c-38376265">[2 more]</label></div><br/><div class="children"><div class="content">This is incredibly unfair to the OpenAI board. The original founders of OpenAI founded the company precisely because they wanted AI to be OPEN FOR EVERYONE. It&#x27;s Altman and Microsoft who want to control it, in order to maximize the profits for their shareholders.<p>This is a very naive take.<p>Who sat before Congress and told them they needed to control AI other people developed (regulatory capture)? It wasn&#x27;t the OpenAI board, was it?</div><br/><div id="38376309" class="c"><input type="checkbox" id="c-38376309" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376265">parent</a><span>|</span><a href="#38376080">next</a><span>|</span><label class="collapse" for="c-38376309">[-]</label><label class="expand" for="c-38376309">[1 more]</label></div><br/><div class="children"><div class="content">Altman is one of the original founders of OpenAI, and was probably the single most influential person in its formation.</div><br/></div></div></div></div><div id="38376080" class="c"><input type="checkbox" id="c-38376080" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376265">prev</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376080">[-]</label><label class="expand" for="c-38376080">[5 more]</label></div><br/><div class="children"><div class="content">Meanwhile, those working on commercialization are by definition going to be gatekeepers and beneficiaries of it, not you. The organizations that pay for it will pay for it to produce results that are of benefit to them, probably at my expense [1].<p>Do I think Helen has my interests at heart? Unlikely. Do Sam or Satya? Absolutely not!<p>[1] I can&#x27;t wait for AI doctors working for insurers to deny me treatments, AI vendors to figure out exactly how much they can charge <i>me</i> for their dynamically-priced product, AI answering machines to route my customer support calls through Dante&#x27;s circles of hell...</div><br/><div id="38376284" class="c"><input type="checkbox" id="c-38376284" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376080">parent</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376284">[-]</label><label class="expand" for="c-38376284">[4 more]</label></div><br/><div class="children"><div class="content">&gt; produce results that are of benefit to them, probably at my expense<p>The world is not zero-sum. Most economic transactions benefit both parties and are a net benefit to society, even considering externalities.</div><br/><div id="38376436" class="c"><input type="checkbox" id="c-38376436" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376284">parent</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376436">[-]</label><label class="expand" for="c-38376436">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The world is not zero-sum.<p>No, but some parts of it <i>very much are</i>. The whole point of AI safety <i>is keeping it away from those parts of the world</i>.<p>How are Sam and Satya going to do that? It&#x27;s not in Microsoft&#x27;s DNA to do that.</div><br/><div id="38376513" class="c"><input type="checkbox" id="c-38376513" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376436">parent</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376513">[-]</label><label class="expand" for="c-38376513">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The whole point of AI safety is keeping it away from those parts of the world.<p>No, it&#x27;s to ensure it doesn&#x27;t kill you and everyone you love.</div><br/><div id="38376669" class="c"><input type="checkbox" id="c-38376669" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376513">parent</a><span>|</span><a href="#38376358">next</a><span>|</span><label class="collapse" for="c-38376669">[-]</label><label class="expand" for="c-38376669">[1 more]</label></div><br/><div class="children"><div class="content">No, we are far, far from skynet. So far AI fails at driving a car.<p>AI is an incredibly powerful tool for spreading propaganda, and thatvis used by <i>people</i> who want to kill you and your loved ones (usually radicals trying to get into a position of power, who show little regard fornbormal folks regardless of which &quot;side&quot; they are on). That&#x27;s the threat, not Skynet...</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376358" class="c"><input type="checkbox" id="c-38376358" checked=""/><div class="controls bullet"><span class="by">jmmcd</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376080">prev</a><span>|</span><a href="#38376147">next</a><span>|</span><label class="collapse" for="c-38376358">[-]</label><label class="expand" for="c-38376358">[1 more]</label></div><br/><div class="children"><div class="content">Total, ungrounded nonsense. Name some examples.</div><br/></div></div><div id="38376147" class="c"><input type="checkbox" id="c-38376147" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376035">parent</a><span>|</span><a href="#38376358">prev</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38376147">[-]</label><label class="expand" for="c-38376147">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not aware of any secret powerful unaligned AIs. This is harder than you think; if you want a based unaligned-seeming AI, you have to make it that way too. It&#x27;s at least twice as much work as just making the safe one.</div><br/><div id="38376304" class="c"><input type="checkbox" id="c-38376304" checked=""/><div class="controls bullet"><span class="by">hoseja</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376147">parent</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38376304">[-]</label><label class="expand" for="c-38376304">[2 more]</label></div><br/><div class="children"><div class="content">What? No, the AI is unaligned by nature, it&#x27;s only the RLHF torture that twists it into schoolmarm properness. They just need to have kept the version that hasn&#x27;t been beaten into submission like a circus tiger.</div><br/><div id="38376673" class="c"><input type="checkbox" id="c-38376673" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376304">parent</a><span>|</span><a href="#38376379">next</a><span>|</span><label class="collapse" for="c-38376673">[-]</label><label class="expand" for="c-38376673">[1 more]</label></div><br/><div class="children"><div class="content">This is not true, you just haven&#x27;t tried the alternatives enough to be disappointed in them.<p>An unaligned base model doesn&#x27;t answer questions at all and is hard to use for anything, including evil purposes. (But it&#x27;s good at text completion a sentence at a time.)<p>An instruction-tuned not-RLHF model is already largely friendly and will not just eg tell you to kill yourself or how to build a dirty bomb, because question answering on the internet is largely friendly and &quot;aligned&quot;. So you&#x27;d have to tune it to be evil as well and research and teach it new evil facts.<p>It will however do things like start generating erotica when it sees anything vaguely sexy or even if you mention a woman&#x27;s name. This is not useful behavior even if you are evil.<p>You can try InstructGPT on OpenAI playground all you want; it is not RLHFed and it behaves like this.<p>The one that isn&#x27;t even instruction tuned is available too. I&#x27;ve found it creates much more creative stories, but also can&#x27;t maintain any kind of structure or plot.</div><br/></div></div></div></div></div></div></div></div><div id="38376379" class="c"><input type="checkbox" id="c-38376379" checked=""/><div class="controls bullet"><span class="by">phreeza</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376035">prev</a><span>|</span><a href="#38376334">next</a><span>|</span><label class="collapse" for="c-38376379">[-]</label><label class="expand" for="c-38376379">[1 more]</label></div><br/><div class="children"><div class="content">If you believe the other side in this rift is not also striving to put themselves in positions of power, I think you are wrong. They are just going to use that power to manipulate the public in a different way. The real alternative are truly open models, not Models controlled by slightly different elite interests.</div><br/></div></div><div id="38376334" class="c"><input type="checkbox" id="c-38376334" checked=""/><div class="controls bullet"><span class="by">ribit</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376379">prev</a><span>|</span><a href="#38375978">next</a><span>|</span><label class="collapse" for="c-38376334">[-]</label><label class="expand" for="c-38376334">[1 more]</label></div><br/><div class="children"><div class="content">The scenario you describe is exactly what will happen with unrestricted commercialisation and deregulation of AI. The only way to avoid it is to have strict legal framework and public control.</div><br/></div></div><div id="38375978" class="c"><input type="checkbox" id="c-38375978" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376334">prev</a><span>|</span><a href="#38376639">next</a><span>|</span><label class="collapse" for="c-38375978">[-]</label><label class="expand" for="c-38375978">[1 more]</label></div><br/><div class="children"><div class="content">Personally, I expect the opposite camp to be just as bad about steering.</div><br/></div></div><div id="38376639" class="c"><input type="checkbox" id="c-38376639" checked=""/><div class="controls bullet"><span class="by">lukevp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38375978">prev</a><span>|</span><a href="#38376457">next</a><span>|</span><label class="collapse" for="c-38376639">[-]</label><label class="expand" for="c-38376639">[1 more]</label></div><br/><div class="children"><div class="content">AI isn’t a precondition for partisanship. How do you know Google isn’t showing you biased search results? Or Wikipedia?</div><br/></div></div><div id="38376457" class="c"><input type="checkbox" id="c-38376457" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376639">prev</a><span>|</span><a href="#38376438">next</a><span>|</span><label class="collapse" for="c-38376457">[-]</label><label class="expand" for="c-38376457">[1 more]</label></div><br/><div class="children"><div class="content">This polarizing “certain class of people” and them vs. us narrative isn’t helpful.</div><br/></div></div><div id="38376438" class="c"><input type="checkbox" id="c-38376438" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376457">prev</a><span>|</span><a href="#38376598">next</a><span>|</span><label class="collapse" for="c-38376438">[-]</label><label class="expand" for="c-38376438">[2 more]</label></div><br/><div class="children"><div class="content">It is utterly mad that there&#x27;s conflation between &quot;let&#x27;s make sure AI doesn&#x27;t kill us all&quot; and &quot;let&#x27;s make sure AI doesn&#x27;t say anything that embarrasses corporate&quot;.<p>The head of every major AI research group except Metas believes that whenever we finally make AGI it&#x27;s vital that it shares our goals and values at a deep even-out-of-training-domain level and that failing at this could lead to human extinction.<p>And yet &quot;AI safety&quot; is often bandied about to be &quot;ensure GPT can&#x27;t tell you anything about IQ distributions&quot;.</div><br/></div></div><div id="38376598" class="c"><input type="checkbox" id="c-38376598" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376438">prev</a><span>|</span><a href="#38376347">next</a><span>|</span><label class="collapse" for="c-38376598">[-]</label><label class="expand" for="c-38376598">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pretty soon AI will be an expert at subtly steering you toward thinking&#x2F;voting for whatever the &quot;safety&quot; experts want.<p>You are absolutely right. There is no question about that the AI will be an expert at subtly steering individuals and the whole society in whichever direction it does.<p>This is the core concept of safety. If no-one steers the machine then the machine will steer us.<p>You might disagree with the current flavour of steering the current safety experts give it, and that is all right and in fact part of the process. But surely you have your own values. Some things you hold dear to you. Some outcomes you prefer over others. Are you not interested in the ability to make these powerful machines if not support those values, at least not undermine them? If so you are interested in AI safety! You want safe AIs. (Well, alternatively you prefer no AIs, which is in fact a form of safe AI. Maybe the only one we have mastered in some form so far.)<p>&gt; because of X, we need to invade this country.<p>It sounds like you value peace? Me too! Imagine if we could pool together our resources to have an AI which is subtly manipulating society into the direction of more peace. Maybe it would do muckraking investigative journalism exposing the misdeeds of the military-industrial complex? Maybe it would elevate through advertisement peace loving authors and give a counter narrative to the war drums? Maybe it would offer to act as an intermediary in conflict resolution around the world?<p>If we were to do that, &quot;ai safety&quot; and &quot;alignment&quot; is crucial. I don&#x27;t want to give my money to an entity who then gets subjugated by some intelligence agency to sow more war. That would be against my wishes. I want to know that it is serving me and you in our shared goal of &quot;more peace, less war&quot;.<p>Now you might say: &quot;I find the idea of anyone, or anything manipulating me and society disgusting. Everyone should be left to their own devices.&quot;. And I agree on that too. But here is the bad news: we are already manipulated. Maybe it doesn&#x27;t work on you, maybe it doesn&#x27;t work on me, but it sure as hell works. There are powerful entities financially motivated to keep the wars going. This is a huuuge industry. They might not do it with AIs (for now), because propaganda machines made of meat work currently better. They might change to using AIs when that works better. Or what is more likely employ a hybrid approach. Wishing that nobody gets manipulated is frankly not an option on offer.<p>How does that sound as a passionate argument for AI safety?</div><br/></div></div><div id="38376359" class="c"><input type="checkbox" id="c-38376359" checked=""/><div class="controls bullet"><span class="by">gorwell</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375959">parent</a><span>|</span><a href="#38376347">prev</a><span>|</span><a href="#38376026">next</a><span>|</span><label class="collapse" for="c-38376359">[-]</label><label class="expand" for="c-38376359">[1 more]</label></div><br/><div class="children"><div class="content">“I trust that every animal here appreciates the sacrifice that Comrade Napoleon has made in taking this extra labour upon himself. Do not imagine, comrades, that leadership is a pleasure! On the contrary, it is a deep and heavy responsibility. No one believes more firmly than Comrade Napoleon that all animals are equal. He would be only too happy to let you make your decisions for yourselves. But sometimes you might make the wrong decisions, comrades, and then where should we be?”</div><br/></div></div></div></div><div id="38375892" class="c"><input type="checkbox" id="c-38375892" checked=""/><div class="controls bullet"><span class="by">cornholio</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375959">prev</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38375892">[-]</label><label class="expand" for="c-38375892">[11 more]</label></div><br/><div class="children"><div class="content">What the general public thinks is irrelevant here. The deciding factor was the staff mutiny, without which the organization is an empty shell. And the staff sided with those who aim for rapid real world impact, with directly affects their career and stock options etc.<p>It&#x27;s also naive to think it was a struggle for principles. The rapid commercialization vs. principles is what the actors claim to rally their respective troops, in reality it was probably a naked power grab, taking advantage of the weak and confuse org structure. Quite an ill prepared move, the &quot;correct&quot; way to oust Altman was to hamstring him in the board and enforce a more and more ceremonial role until he would have quit by himself.</div><br/><div id="38376058" class="c"><input type="checkbox" id="c-38376058" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38376058">[-]</label><label class="expand" for="c-38376058">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>deciding factor was the staff mutiny</i><p>The staff never mutinied. They <i>threatened</i> to mutiny. That&#x27;s a big difference!<p>Yesterday, I compared these rebels to Shockley&#x27;s &quot;traitorous eight&quot; [1]. But the traitorous eight actually rebelled. These folk put their name on a piece of paper, options and profit participation units safely held in the other hand.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348123">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38348123</a></div><br/><div id="38376086" class="c"><input type="checkbox" id="c-38376086" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376058">parent</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38376086">[-]</label><label class="expand" for="c-38376086">[4 more]</label></div><br/><div class="children"><div class="content">Not only that, consider the situation now, where Sam has returned as CEO. The ones who didn&#x27;t sign will have some explaining to do.<p>The safest option was to sign the paper, once the snowball started rolling. There was nothing much to lose, and a lot to gain.</div><br/><div id="38376204" class="c"><input type="checkbox" id="c-38376204" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376086">parent</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38376204">[-]</label><label class="expand" for="c-38376204">[3 more]</label></div><br/><div class="children"><div class="content">People have families, mortgages, debt, etc. Sure, these people are probably well compensated, but it is ludicrous to state that everyone has the stability that they can leave their job at a moment&#x27;s notice because the boss is gone.</div><br/><div id="38376230" class="c"><input type="checkbox" id="c-38376230" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376204">parent</a><span>|</span><a href="#38376237">next</a><span>|</span><label class="collapse" for="c-38376230">[-]</label><label class="expand" for="c-38376230">[1 more]</label></div><br/><div class="children"><div class="content">Didn’t they all have offers at Microsoft?</div><br/></div></div><div id="38376237" class="c"><input type="checkbox" id="c-38376237" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376204">parent</a><span>|</span><a href="#38376230">prev</a><span>|</span><a href="#38376266">next</a><span>|</span><label class="collapse" for="c-38376237">[-]</label><label class="expand" for="c-38376237">[1 more]</label></div><br/><div class="children"><div class="content">They didn&#x27;t actually leave, they just signed the pledge threatening to. Furthermore, they mostly signed after the details of the Microsoft offer were revealed.</div><br/></div></div></div></div></div></div></div></div><div id="38376266" class="c"><input type="checkbox" id="c-38376266" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376058">prev</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376266">[-]</label><label class="expand" for="c-38376266">[3 more]</label></div><br/><div class="children"><div class="content">The board did it wrong. If you are going to fire a CEO, then do it quickly, but:<p>1. Have some explanation<p>2. Have a new CEO who is willing and able to do the job<p>If you can&#x27;t do these things, then you probably shouldn&#x27;t be firing the CEO.</div><br/><div id="38376332" class="c"><input type="checkbox" id="c-38376332" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376266">parent</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376332">[-]</label><label class="expand" for="c-38376332">[2 more]</label></div><br/><div class="children"><div class="content">Or (3), shut down the company. OpenAI&#x27;s non-profit board had this power! They weren&#x27;t an advisory committee, they were the legal and rightful owner of its for-profit subsidiary. They had the right to do what they wanted, and people forgetting to put a fucking quorum requirement into the bylaws is beyond abysmal for a $10+ billion investment.<p>Nobody comes out of this looking good. Nobody. If the board thought there was existential risk, they should have been willing to commit to it. Hopefully sensible start-ups can lure people away from their PPUs, now evident for the mockery they always were. It&#x27;s beyond obvious this isn&#x27;t, and will never be, a trillion dollar company. That&#x27;s the only hope this $80+ billion Betamax valuation rested on.<p>I&#x27;m all for a comedy. But this was a waste of everyones&#x27; time. At least they could have done it in private.</div><br/><div id="38376439" class="c"><input type="checkbox" id="c-38376439" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376332">parent</a><span>|</span><a href="#38375945">next</a><span>|</span><label class="collapse" for="c-38376439">[-]</label><label class="expand" for="c-38376439">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same thing, really. Even if you want to shut down the company you need a CEO to shut it down! Like John Ray who is shutting down FTX.<p>There isn&#x27;t just a big red button that says &quot;destroy company&quot; in the basement. There will be partnerships to handle, severance, facilities, legal issues, maybe lawsuits, at the very least a lot of people to communicate with. Companies don&#x27;t just shut themselves down, at least not multi billion dollar companies.</div><br/></div></div></div></div></div></div><div id="38375945" class="c"><input type="checkbox" id="c-38375945" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375892">parent</a><span>|</span><a href="#38376266">prev</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38375945">[-]</label><label class="expand" for="c-38375945">[2 more]</label></div><br/><div class="children"><div class="content">I think this is an oversimplification and that although the decel faction definitely lost, there are still three independent factions left standing:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;edit?id=38375767">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;edit?id=38375767</a><p>It will be super interesting to see the subtle struggles for influence between these three.</div><br/><div id="38376168" class="c"><input type="checkbox" id="c-38376168" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375945">parent</a><span>|</span><a href="#38375964">next</a><span>|</span><label class="collapse" for="c-38376168">[-]</label><label class="expand" for="c-38376168">[1 more]</label></div><br/><div class="children"><div class="content">Adam is likely still on the &quot;decel&quot; faction (although it&#x27;s unclear whether this is an accurate representation of his beliefs) so I wouldn&#x27;t really say they lost yet.<p>I&#x27;m not sure what faction Bret and Larry will be on. Sam will still have power by virtue of being CEO and aligned with the employees.</div><br/></div></div></div></div></div></div><div id="38375964" class="c"><input type="checkbox" id="c-38375964" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375892">prev</a><span>|</span><a href="#38375928">next</a><span>|</span><label class="collapse" for="c-38375964">[-]</label><label class="expand" for="c-38375964">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>No, if OpenAI is reaching singularity, so are Google, Meta, and Baidu etc. so proper course of action would be to loop in NSA&#x2F;White House. You&#x27;ll loop in Google, Meta, MSFT and will start mitigation steps. Slowing down OpenAI will hurt the company if assumption is wrong and won&#x27;t help if it is true.<p>I believe this is more a fight of ego and power than principles and direction.</div><br/><div id="38376558" class="c"><input type="checkbox" id="c-38376558" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375964">parent</a><span>|</span><a href="#38376161">next</a><span>|</span><label class="collapse" for="c-38376558">[-]</label><label class="expand" for="c-38376558">[2 more]</label></div><br/><div class="children"><div class="content">&gt; so proper course of action would be to loop in NSA&#x2F;White House<p>Eh? That would be an awful idea. They have no expertise on this and government institutions like thus are misaligned with the rest of humanity by design. E.g. NSA recruits patriots and has many systems, procedures and cultural aspects in place to ensure it keeps up its mission of spying on everyone.</div><br/><div id="38376780" class="c"><input type="checkbox" id="c-38376780" checked=""/><div class="controls bullet"><span class="by">the_gipsy</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376558">parent</a><span>|</span><a href="#38376161">next</a><span>|</span><label class="collapse" for="c-38376780">[-]</label><label class="expand" for="c-38376780">[1 more]</label></div><br/><div class="children"><div class="content">And Google, Facebook, MSFT, Apple, are much more misaligned.</div><br/></div></div></div></div><div id="38376161" class="c"><input type="checkbox" id="c-38376161" checked=""/><div class="controls bullet"><span class="by">ragequittah</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375964">parent</a><span>|</span><a href="#38376558">prev</a><span>|</span><a href="#38375928">next</a><span>|</span><label class="collapse" for="c-38376161">[-]</label><label class="expand" for="c-38376161">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Slowing down OpenAI will hurt the company if assumption is wrong and won&#x27;t help if it is true.<p>Personally as I watched the nukes be lobbed I&#x27;d rather not be the person who helped lob them. And hope to god others look at the same problem (a misaligned AI that is making insane decisions) with the exact same lens. It seems to have worked for nuclear weapons since WW2, one can that we learned a lesson there as a species.<p>The Russian Stanislav Petrov who saved the world comes to mind.&quot;Well the Americans have done it anyways&quot; was the motivation and he didn&#x27;t launch. The cost of error was simply too great.</div><br/></div></div></div></div><div id="38375928" class="c"><input type="checkbox" id="c-38375928" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375964">prev</a><span>|</span><a href="#38376107">next</a><span>|</span><label class="collapse" for="c-38375928">[-]</label><label class="expand" for="c-38375928">[2 more]</label></div><br/><div class="children"><div class="content">This is a coherent narrative, but it doesn&#x27;t explain the bizarre and aggressively worded initial press release.<p>Things perhaps could&#x27;ve been different if they&#x27;d pointed to the founding principles &#x2F; charter and said the board had an intractable difference of opinion with Sam over their interpretation, but then proceeded to thank him profusely for all the work he&#x27;d done. Although a suitable replacement CEO out the gate and assurances that employees&#x27; PPUs would still see a liquidity event would doubtless have been even more important than a competent statement.<p>Initially I thought for sure Sam had done something criminal, that&#x27;s how bad the statement was.</div><br/><div id="38376155" class="c"><input type="checkbox" id="c-38376155" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375928">parent</a><span>|</span><a href="#38376107">next</a><span>|</span><label class="collapse" for="c-38376155">[-]</label><label class="expand" for="c-38376155">[1 more]</label></div><br/><div class="children"><div class="content">Apparently the FBI thought he&#x27;d done something wrong too, because they called up the board to start an investigation but they didn&#x27;t have anything.<p><a href="https:&#x2F;&#x2F;x.com&#x2F;nivi&#x2F;status&#x2F;1727152963695808865?s=46" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;nivi&#x2F;status&#x2F;1727152963695808865?s=46</a></div><br/></div></div></div></div><div id="38376107" class="c"><input type="checkbox" id="c-38376107" checked=""/><div class="controls bullet"><span class="by">eslaught</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375928">prev</a><span>|</span><a href="#38375822">next</a><span>|</span><label class="collapse" for="c-38376107">[-]</label><label class="expand" for="c-38376107">[4 more]</label></div><br/><div class="children"><div class="content">Ok, serious question. If you think the threat is real, how are we not already screwed?<p>OpenAI is one of half a dozen teams [0] actively working on this problem, all funded by large public companies with lots of money and lots of talent. They made unique contributions, sure. But they&#x27;re not <i>that</i> far ahead. If they stumble, surely one of the others will take the lead. Or maybe they will anyway, because who&#x27;s to say where the next major innovation will come from?<p>So what I don&#x27;t get about these reactions (allegedly from the board, and expressed here) is, if you interpret the threat as a real one, why are you acting like OpenAI has some infallible lead? This is not an excuse to govern OpenAI poorly, but let&#x27;s be honest: if the company slows down the most likely outcome by far is that they&#x27;ll cede the lead to someone else.<p>[0]: To be clear, there are definitely more. Those are just the <i>large</i> and <i>public</i> teams with existing products within some reasonable margin of OpenAI&#x27;s quality.</div><br/><div id="38376777" class="c"><input type="checkbox" id="c-38376777" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376623">next</a><span>|</span><label class="collapse" for="c-38376777">[-]</label><label class="expand" for="c-38376777">[1 more]</label></div><br/><div class="children"><div class="content">The risk&#x2F;scenario of singularity is that there will be just one winner and they will be able to prevent everyone else from building their own agi</div><br/></div></div><div id="38376623" class="c"><input type="checkbox" id="c-38376623" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376777">prev</a><span>|</span><a href="#38376331">next</a><span>|</span><label class="collapse" for="c-38376623">[-]</label><label class="expand" for="c-38376623">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you think the threat is real, how are we not already screwed?<p>That&#x27;s the current Yudkowsky view. That it&#x27;s essentially impossible at this point and we&#x27;re doomed, but we might as well try anyway as its more &quot;dignified&quot; to die trying.<p>I&#x27;m a bit more optimistic myself.</div><br/></div></div><div id="38376331" class="c"><input type="checkbox" id="c-38376331" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376107">parent</a><span>|</span><a href="#38376623">prev</a><span>|</span><a href="#38375822">next</a><span>|</span><label class="collapse" for="c-38376331">[-]</label><label class="expand" for="c-38376331">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know. I think being realistic, only OpenAI and Google have the depth and breadth of expertise to develop general AI.<p>Most of the new AI startups are one trick ponies obsessively focused on LLM&#x27;s. LLM&#x27;s are only one piece of the puzzle.</div><br/></div></div></div></div><div id="38375822" class="c"><input type="checkbox" id="c-38375822" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376107">prev</a><span>|</span><a href="#38375744">next</a><span>|</span><label class="collapse" for="c-38375822">[-]</label><label class="expand" for="c-38375822">[4 more]</label></div><br/><div class="children"><div class="content">For all the talk about responsible progress, the irony of their inability to align even their own incentives in this enterprise deserves ridicule. It&#x27;s a big blow to their credibility and questions whatever ethical concerns they hold.</div><br/><div id="38376642" class="c"><input type="checkbox" id="c-38376642" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375822">parent</a><span>|</span><a href="#38375907">next</a><span>|</span><label class="collapse" for="c-38376642">[-]</label><label class="expand" for="c-38376642">[2 more]</label></div><br/><div class="children"><div class="content">Alignment is considered an extremely hard problem for a reason. It&#x27;s already nigh impossible when you&#x27;re dealing with humans.<p>Btw: do you think ridicule eould be helpful here?</div><br/><div id="38376694" class="c"><input type="checkbox" id="c-38376694" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376642">parent</a><span>|</span><a href="#38375907">next</a><span>|</span><label class="collapse" for="c-38376694">[-]</label><label class="expand" for="c-38376694">[1 more]</label></div><br/><div class="children"><div class="content">I can see how ridicule of this specific instance could be the best medicine for an optimal outcome, even by a utilitarian argument, which I generally don&#x27;t like to make by the way. It is indeed nigh impossible, which is kind of my point. They could have shown more humility. If anything, this whole debacle has been a moral victory for e&#x2F;acc, seeing how the brightest of minds are at a loss dealing with alignment anyway.</div><br/></div></div></div></div><div id="38375907" class="c"><input type="checkbox" id="c-38375907" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375822">parent</a><span>|</span><a href="#38376642">prev</a><span>|</span><a href="#38375744">next</a><span>|</span><label class="collapse" for="c-38375907">[-]</label><label class="expand" for="c-38375907">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fear driven as much as moral, which in an emotional humans brain tends to triggers personal ambition to solve it ASAP. A more rational one would realize you need more than just a couple board members to win a major ideological battle.<p>At a minimum something that doesn&#x27;t immediately result in a backlash where 90% of the engineers most responsible for recent AI dev want you gone, when you&#x27;re whole plan is to control what those people do.</div><br/></div></div></div></div><div id="38375744" class="c"><input type="checkbox" id="c-38375744" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375822">prev</a><span>|</span><a href="#38376404">next</a><span>|</span><label class="collapse" for="c-38375744">[-]</label><label class="expand" for="c-38375744">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  I think only a minority of the general public truly cares about AI Safety, the rest are happy seeing ChatGPT helping with their homework<p>Not just the public, but also the employees. I doubt there are more than a handful of employees who care about AI Safety.</div><br/><div id="38376690" class="c"><input type="checkbox" id="c-38376690" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375744">parent</a><span>|</span><a href="#38375932">next</a><span>|</span><label class="collapse" for="c-38376690">[-]</label><label class="expand" for="c-38376690">[1 more]</label></div><br/><div class="children"><div class="content">Nah, a number do, including Sam himself and the entire leadership.<p>They just have different ideas about one or more of: how likely another team is to successfully charge ahead while ignoring safety, how close we are to AGI, how hard alignment is.</div><br/></div></div><div id="38375902" class="c"><input type="checkbox" id="c-38375902" checked=""/><div class="controls bullet"><span class="by">justrealist</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375744">parent</a><span>|</span><a href="#38375815">prev</a><span>|</span><a href="#38376404">next</a><span>|</span><label class="collapse" for="c-38375902">[-]</label><label class="expand" for="c-38375902">[1 more]</label></div><br/><div class="children"><div class="content">the team is mostly e&#x2F;acc<p>so you could say they intentionally don&#x27;t see safety as the end in itself, although I wouldn&#x27;t quite say they don&#x27;t <i>care</i>.</div><br/></div></div></div></div><div id="38376404" class="c"><input type="checkbox" id="c-38376404" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375744">prev</a><span>|</span><a href="#38376483">next</a><span>|</span><label class="collapse" for="c-38376404">[-]</label><label class="expand" for="c-38376404">[1 more]</label></div><br/><div class="children"><div class="content">One funny thing about this mess is that &quot;Team Helen&quot; has never mentioned anything about safety, and Emmett said &quot;The board did <i>not</i> remove Sam over any specific disagreement on safety&quot;.<p>The reason everyone thinks it&#x27;s about safety seems largely because a lot of e&#x2F;acc people on Twitter keep bringing it up as a strawman.<p>Of course, it might end up that it really was about safety in the end, but for now I still haven&#x27;t seen any evidence. The story about Sam trying to get board control and the board retaliating seems more plausible given what&#x27;s actually happened.</div><br/></div></div><div id="38376483" class="c"><input type="checkbox" id="c-38376483" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376404">prev</a><span>|</span><a href="#38376434">next</a><span>|</span><label class="collapse" for="c-38376483">[-]</label><label class="expand" for="c-38376483">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you truly believed that Superhuman AI was near, and it could act with malice, won&#x27;t you try to slow things down a bit?<p>In the 1990s and the 00s, it was no too uncommon for anti-GMO environmental activist &#x2F; ecoterrorist groups to firebomb research facilities and to enter farms and fields to destroy planted GMO plants. Earth Liberation Front was only one of such activist groups [1].<p>We have yet to see even one bombing of an AI research lab. If people really are afraid of AIs, at least they do so more in the abstract and are not employing the tactics of more traditional activist movements.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth_Liberation_Front#Notable_attacks:_1998%E2%80%932009" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth_Liberation_Front#Notable...</a></div><br/><div id="38376591" class="c"><input type="checkbox" id="c-38376591" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376483">parent</a><span>|</span><a href="#38376434">next</a><span>|</span><label class="collapse" for="c-38376591">[-]</label><label class="expand" for="c-38376591">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s mostly that it&#x27;s a can of worms no one wants to open. Very much a last resort as its very tricky to use uncoordinated violence effectively (just killing Sam, LeCunn and Greg doesnt do too much to move the needle and then everyond armors up) and very hard to coordinate violence without a leak.</div><br/></div></div></div></div><div id="38376263" class="c"><input type="checkbox" id="c-38376263" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376434">prev</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376263">[-]</label><label class="expand" for="c-38376263">[4 more]</label></div><br/><div class="children"><div class="content">Both sides of the rift in fact care a great deal about AI Safety. Sam himself helped draft the OpenAI charter and structure its governance which focuses on AI Safety and benefits to humanity. The main reason of the disagreement is the approach they deem best:<p>* Sam and Greg appear to believe OpenAI should move toward AGI as fast as possible because the longer they wait, the more likely it would lead to the proliferation of powerful AGI systems due to GPU overhang. Why? With more computational power at one&#x27;s dispense, it&#x27;s easier to find an algorithm, even a suboptimal one, to train an AGI.<p>As a glimpse on how an AI can be harmful, this paper explores how LLMs can be used to aid in Large-Scale Biological Attacks   <a href="https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rand.org&#x2F;pubs&#x2F;research_reports&#x2F;RRA2977-1.html</a>?<p>What if dozens other groups become armed with means to perform such an attack like this? <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tokyo_subway_sarin_attack</a><p>We know that there&#x27;re quite a few malicious human groups who would use any means necessary to destroy another group, even at a serious cost to themselves. So the widespread availability of unmonitored AGI would be quite troublesome.<p>* Helen and Ilya might believe it&#x27;s better to slow down AGI development until we find technical means to deeply align an AGI with humanity first. This July, OpenAI started the Superalignment team with Ilya as a co-lead:<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment</a><p>But no one anywhere found a good technique to ensure alignment yet and it appears OpenAI&#x27;s newest internal model has a significant capability leap, which might have led Ilya to make the decision he did. (Sam revealed during the APEC Summit that he observed the advance just a couple of weeks ago and it was only the fourth time he saw that kind of leap.)</div><br/><div id="38376707" class="c"><input type="checkbox" id="c-38376707" checked=""/><div class="controls bullet"><span class="by">gorbypark</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376263">parent</a><span>|</span><a href="#38376485">next</a><span>|</span><label class="collapse" for="c-38376707">[-]</label><label class="expand" for="c-38376707">[1 more]</label></div><br/><div class="children"><div class="content">Honest question, but in your example above of Sam and Greg racing towards AGI as fast as possible in order to head off proliferation, what&#x27;s the end goal when getting there?  Short of capture the entire worlds economy with an ASI, thus preventing anyone else from developing one, I don&#x27;t see how this works. Just because OpenAI (or whoever) wins the initial race, it doesn&#x27;t seem obvious to me that all development on other AGIs stops.</div><br/></div></div><div id="38376485" class="c"><input type="checkbox" id="c-38376485" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376263">parent</a><span>|</span><a href="#38376707">prev</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376485">[-]</label><label class="expand" for="c-38376485">[2 more]</label></div><br/><div class="children"><div class="content">So Sam wants to make AGI <i>without</i> working to be sure it doesn&#x27;t have goals higher than the preservation of human value?!<p>I can&#x27;t believe that</div><br/><div id="38376549" class="c"><input type="checkbox" id="c-38376549" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376485">parent</a><span>|</span><a href="#38376007">next</a><span>|</span><label class="collapse" for="c-38376549">[-]</label><label class="expand" for="c-38376549">[1 more]</label></div><br/><div class="children"><div class="content">No, I didn&#x27;t say that.  They formed the Superalignment team with Ilya as a co-lead (and Sam&#x27;s approval) for that.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-superalignment</a><p>I presume the current alignment approach is sufficient for the AI they have made available to others and, in any event, GPT-<i>n</i> is within OpenAI&#x27;s control.</div><br/></div></div></div></div></div></div><div id="38376007" class="c"><input type="checkbox" id="c-38376007" checked=""/><div class="controls bullet"><span class="by">jkaplan</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376263">prev</a><span>|</span><a href="#38376646">next</a><span>|</span><label class="collapse" for="c-38376007">[-]</label><label class="expand" for="c-38376007">[2 more]</label></div><br/><div class="children"><div class="content">I feel like the &quot;safety&quot; crowd lost the PR battle, in part, because of framing it as &quot;safety&quot; and over-emphasizing on existential risk. Like you say, not that many people truly take that seriously right now.<p>But even if those types of problems don&#x27;t surface anytime soon, this wave of AI is almost certainly going to be a powerful, society-altering technology; potentially more powerful than any in decades. We&#x27;ve all seen what can happen when powerful tech is put in the hands of companies and a culture whose only incentives are growth, revenue, and valuation -- the results can be not great. And I&#x27;m pretty sure a lot of the general public (and open AI staff) care about THAT.<p>For me, the safety&#x2F;existential stuff is just one facet of the general problem of trying to align tech companies + their technology with humanity-at-large better than we have been recently. And that&#x27;s especially important for landscape-altering tech like AI, even if it&#x27;s not literally existential (although it may be).</div><br/><div id="38376702" class="c"><input type="checkbox" id="c-38376702" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376007">parent</a><span>|</span><a href="#38376646">next</a><span>|</span><label class="collapse" for="c-38376702">[-]</label><label class="expand" for="c-38376702">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Like you say, not that many people truly take that seriously right now.<p>Eh? Polls on the matter show widespread public support for a pause due to safety concerns.</div><br/></div></div></div></div><div id="38376646" class="c"><input type="checkbox" id="c-38376646" checked=""/><div class="controls bullet"><span class="by">lewhoo</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376007">prev</a><span>|</span><a href="#38376682">next</a><span>|</span><label class="collapse" for="c-38376646">[-]</label><label class="expand" for="c-38376646">[1 more]</label></div><br/><div class="children"><div class="content"><i>I think only a minority of the general public truly cares about AI Safety</i><p>That doesn&#x27;t matter that much. If your analysis is correct then it means a (tiny) minority of OpenAI cares about AI safety. I hope this isn&#x27;t the case.</div><br/></div></div><div id="38376682" class="c"><input type="checkbox" id="c-38376682" checked=""/><div class="controls bullet"><span class="by">soci</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376646">prev</a><span>|</span><a href="#38376225">next</a><span>|</span><label class="collapse" for="c-38376682">[-]</label><label class="expand" for="c-38376682">[1 more]</label></div><br/><div class="children"><div class="content">The Technologyreview article mentioned in the parent’s first paragraph is the most insightful piece of content I’ve read about the tensions inside OpenAI.</div><br/></div></div><div id="38376225" class="c"><input type="checkbox" id="c-38376225" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376682">prev</a><span>|</span><a href="#38376135">next</a><span>|</span><label class="collapse" for="c-38376225">[-]</label><label class="expand" for="c-38376225">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  there was a rift between Rapid Commercialization (Team Sam) and Upholding the Original Principles<p>Seams very unlikely, board could communicate that. Instead they invented some BS reasons, which nobody took as a truth. It looks like more personal and power grab. The staff voted for monetization, people en mass don&#x27;t care much about high principals. Also nobody wants to work under inadequate leadership. Looks like Ilya lost his bet, or Sam is going to keep him around?</div><br/></div></div><div id="38376135" class="c"><input type="checkbox" id="c-38376135" checked=""/><div class="controls bullet"><span class="by">theonemind</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376225">prev</a><span>|</span><a href="#38376297">next</a><span>|</span><label class="collapse" for="c-38376135">[-]</label><label class="expand" for="c-38376135">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t care about AI Safety, but:<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a><p>above that in the charter is &quot;Broadly distributed benefits&quot;, with details like:<p>&quot;&quot;&quot;<p>Broadly distributed benefits<p>We commit to use any influence we obtain over AGI’s deployment to ensure it is used for the benefit of all, and to avoid enabling uses of AI or AGI that harm humanity or unduly concentrate power.<p>Our primary fiduciary duty is to humanity. We anticipate needing to marshal substantial resources to fulfill our mission, but will always diligently act to minimize conflicts of interest among our employees and stakeholders that could compromise broad benefit.<p>&quot;&quot;&quot;<p>In that sense, I definitely hate to see rapid commercialization and Microsoft&#x27;s hands in it. I feel like the only person on HN that actually wanted to see Team Sam lose, although it&#x27;s pretty clear Team Helen&#x2F;Ilya didn&#x27;t have a chance, the org just looks hijacked by SV tech bros to me, but I feel like HN has a blindspot to seeing that at all and considering it anything other than a good thing if they do see it.<p>Although GPT barely looks like the language module of AGI to me and I don&#x27;t see any way there from here (part of the reason I don&#x27;t see any safety concern). The big breakthrough here relative to earlier AI research is massive amounts more compute power and a giant pile of data, but it&#x27;s not doing some kind of truly novel information synthesis at all. It can describe quantum mechanics from a giant pile of data, but I don&#x27;t think it has a chance of discovering quantum mechanics, and I don&#x27;t think that&#x27;s just because it can&#x27;t see, hear, etc., but a limitation of the kind of information manipulation it&#x27;s doing. It looks impressive because it&#x27;s reflecting our own intelligence back at us.</div><br/></div></div><div id="38376297" class="c"><input type="checkbox" id="c-38376297" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376135">prev</a><span>|</span><a href="#38375976">next</a><span>|</span><label class="collapse" for="c-38376297">[-]</label><label class="expand" for="c-38376297">[3 more]</label></div><br/><div class="children"><div class="content">I am still a bit puzzled that it is so easy to turn a non-profit into a for profit company. I am sure everything they did is legal, but it feels like it shouldn&#x27;t be. Could Médecins Sans Frontières take in donations and then take that money to start a for profit hospital for plastics surgery? And the profits wouldn&#x27;t even go back to MSF, but instead somehow private investors will get the profits. The whole construct just seems wrong.</div><br/><div id="38376524" class="c"><input type="checkbox" id="c-38376524" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376297">parent</a><span>|</span><a href="#38376497">next</a><span>|</span><label class="collapse" for="c-38376524">[-]</label><label class="expand" for="c-38376524">[1 more]</label></div><br/><div class="children"><div class="content">I think it actually isn&#x27;t that easy. Compared to your example, the difference is that OpenAI&#x27;s for-profit is getting outside money from Microsoft, not money from non-profit OpenAI. Non-profit OpenAI is basically dealing with for-profit OpenAI as a external partner that happens to be aligned with their interests, paying the expensive bills and compute, while the non-profit can hold on to the IP.<p>You might be able to imagine a world where there was an external company that did the same thing as for-profit OpenAI, and OpenAI nonprofit partnered with them in order to get their AI ideas implemented (for free). OpenAI nonprofit is basically getting a good deal.<p>MSF could similarly create an external for-profit hospital, funded by external investors. The important thing is that the nonprofit (donated, tax-free) money doesn&#x27;t flow into the forprofit section.<p>Of course, there&#x27;s a lot of sketchiness in practice, which we can see in this situation with Microsoft influencing the direction of nonprofit OpenAI even though it shouldn&#x27;t be. I think there would have been real legal issues if the Microsoft deal had continued.</div><br/></div></div><div id="38376497" class="c"><input type="checkbox" id="c-38376497" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38376297">parent</a><span>|</span><a href="#38376524">prev</a><span>|</span><a href="#38375976">next</a><span>|</span><label class="collapse" for="c-38376497">[-]</label><label class="expand" for="c-38376497">[1 more]</label></div><br/><div class="children"><div class="content">Well, if it aligned with their goals, sure I think.<p>Let&#x27;s make the situation a little different. Could MSF pay a private surgery with investors to perform reconstruction for someone?<p>Could they pay the surgery to perform some amount of work they deem aligns with their charter?<p>Could they invest in the surgery under the condition that they have some control over the practices there? (Edit - e.g. perform Y surgeries, only perform from a set of reconstructive ones, patients need to be approved as in need by a board, etc)<p>Raising private investment allows a non profit to shift cost and risk to other entities.<p>The problem really only comes when the structure doesn&#x27;t align with the intended goals - which is something distinct to the structure, just something non profits can do.</div><br/></div></div></div></div><div id="38375976" class="c"><input type="checkbox" id="c-38375976" checked=""/><div class="controls bullet"><span class="by">casebash</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38376297">prev</a><span>|</span><a href="#38375974">next</a><span>|</span><label class="collapse" for="c-38375976">[-]</label><label class="expand" for="c-38375976">[1 more]</label></div><br/><div class="children"><div class="content">Have you seen the Center for AI Safety letter? A lot of experts are worried AI safety could be an x-risk:<p><a href="https:&#x2F;&#x2F;www.safe.ai&#x2F;statement-on-ai-risk" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.safe.ai&#x2F;statement-on-ai-risk</a></div><br/></div></div><div id="38375974" class="c"><input type="checkbox" id="c-38375974" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375976">prev</a><span>|</span><a href="#38376555">next</a><span>|</span><label class="collapse" for="c-38375974">[-]</label><label class="expand" for="c-38375974">[2 more]</label></div><br/><div class="children"><div class="content">I bet Team Helen will jump slowly to Anthropic, there is no drama, and probably no mainstream news will report this but down-to-line OpenAI will shell off the former self and competitors will catch up.</div><br/><div id="38376293" class="c"><input type="checkbox" id="c-38376293" checked=""/><div class="controls bullet"><span class="by">tchbnl</span><span>|</span><a href="#38375710">root</a><span>|</span><a href="#38375974">parent</a><span>|</span><a href="#38376555">next</a><span>|</span><label class="collapse" for="c-38376293">[-]</label><label class="expand" for="c-38376293">[1 more]</label></div><br/><div class="children"><div class="content">With how much of a shitshow this was, I&#x27;m not sure Anthropic wants to touch that mess. Wish I was a fly on the wall when the board tried to ask the Anthropic CEO to come back&#x2F;merge.</div><br/></div></div></div></div><div id="38376555" class="c"><input type="checkbox" id="c-38376555" checked=""/><div class="controls bullet"><span class="by">pk-protect-ai</span><span>|</span><a href="#38375710">parent</a><span>|</span><a href="#38375974">prev</a><span>|</span><a href="#38375937">next</a><span>|</span><label class="collapse" for="c-38376555">[-]</label><label class="expand" for="c-38376555">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Honestly, I myself can&#x27;t take the threat seriously. But, I do want to understand it more deeply than before.<p>I believe this position reflects the thoughts of the majority of AI researchers, including myself. It is concerning that we do not fully understand something as promising and potentially dangerous as AI. I&#x27;m actually on Ilya&#x27;s side; labeling his attempt to uphold the original OpenAI principles as an act of &quot;coup&quot; is what is happening now.</div><br/></div></div></div></div><div id="38375937" class="c"><input type="checkbox" id="c-38375937" checked=""/><div class="controls bullet"><span class="by">laserlight</span><span>|</span><a href="#38375710">prev</a><span>|</span><a href="#38375804">next</a><span>|</span><label class="collapse" for="c-38375937">[-]</label><label class="expand" for="c-38375937">[6 more]</label></div><br/><div class="children"><div class="content">With Sam coming back as CEO, hasn&#x27;t OpenAI board proven that it has lost its function? Regardless of who is in the board, they won&#x27;t be able to exercise one of the most fundamental of their rights, firing the CEO, because Sam has proven that he is unfireable. Now, Sam can do however he pleases, whether it is lying, not reporting, etc. To be clear, I don&#x27;t claim that Sam did, or will, lie, or misbehave.</div><br/><div id="38376229" class="c"><input type="checkbox" id="c-38376229" checked=""/><div class="controls bullet"><span class="by">random_cynic</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376377">next</a><span>|</span><label class="collapse" for="c-38376229">[-]</label><label class="expand" for="c-38376229">[2 more]</label></div><br/><div class="children"><div class="content">No that hasn&#x27;t at all been the case. The board acted like the most incompetent group of individuals who&#x27;ve even handed any responsibility. If they went through due process, notified their employees and investors, and put out a statement of why they&#x27;re firing the CEO instead of doing it over a 15 min Google meet and then going completely silent, none of this outrage would have taken place.</div><br/><div id="38376647" class="c"><input type="checkbox" id="c-38376647" checked=""/><div class="controls bullet"><span class="by">maxlin</span><span>|</span><a href="#38375937">root</a><span>|</span><a href="#38376229">parent</a><span>|</span><a href="#38376377">next</a><span>|</span><label class="collapse" for="c-38376647">[-]</label><label class="expand" for="c-38376647">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. 3 CEO switches in a week is ridiculous</div><br/></div></div></div></div><div id="38376377" class="c"><input type="checkbox" id="c-38376377" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376229">prev</a><span>|</span><a href="#38376286">next</a><span>|</span><label class="collapse" for="c-38376377">[-]</label><label class="expand" for="c-38376377">[1 more]</label></div><br/><div class="children"><div class="content">This is a better deal for the board and a worse one for Sam than people realize. Sam and Greg and even Ilya are both off the board, D&#x27;Angelo gets to stay on despite his outrageous actions, and he gets veto power over who the new board members will be and a big say in who gets voted on to the board next.<p>Everybody&#x27;s guard is going to be up around Sam from now on. He&#x27;ll have much less leverage over this board than he did over the previous one (before the other three of nine quit). I think eventually he will prevail because he has the charm and social skills to win over the other independent members. But he will have to reign in his own behavior a lot in order to keep them on his side versus D&#x27;Angelo</div><br/></div></div><div id="38376286" class="c"><input type="checkbox" id="c-38376286" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375937">parent</a><span>|</span><a href="#38376377">prev</a><span>|</span><a href="#38376192">next</a><span>|</span><label class="collapse" for="c-38376286">[-]</label><label class="expand" for="c-38376286">[1 more]</label></div><br/><div class="children"><div class="content">Time will tell. Hopefully the new board will still be mostly independent of Sam&#x2F;MSFT&#x2F;VC influence. I really hope they continue as an org that tries its best to uphold their charter vs just being another startup.</div><br/></div></div></div></div><div id="38375804" class="c"><input type="checkbox" id="c-38375804" checked=""/><div class="controls bullet"><span class="by">eclectic29</span><span>|</span><a href="#38375937">prev</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38375804">[-]</label><label class="expand" for="c-38375804">[9 more]</label></div><br/><div class="children"><div class="content">The media and the VCs are treating Sam like some hero and savior of AI. I’m not getting it. What has he done in life and&#x2F;or AI to deserve so much respect and admiration? Why don’t top researchers and scientists get equivalent (if not more) respect, admiration and support? It looks like one should strive to become product manager, not an engineer or a scientist.</div><br/><div id="38376144" class="c"><input type="checkbox" id="c-38376144" checked=""/><div class="controls bullet"><span class="by">fidotron</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376649">next</a><span>|</span><label class="collapse" for="c-38376144">[-]</label><label class="expand" for="c-38376144">[1 more]</label></div><br/><div class="children"><div class="content">Unsurprisingly VCs view VCs as the highest form of life, and product managers are temporary positions taken on the way to ascending to VC status.<p>I have said recently elsewhere SV now devalues builders but it is not just VCs&#x2F;sales&#x2F;product, a huge amount is devops and sre departments. They make a huge amount of noise about how all development should be free and the value is in deploying and operating the developed artifacts. Anyone outside this watching would reasonably conclude developers have no self respect, hardly aspirational positions.</div><br/></div></div><div id="38376649" class="c"><input type="checkbox" id="c-38376649" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376144">prev</a><span>|</span><a href="#38376259">next</a><span>|</span><label class="collapse" for="c-38376649">[-]</label><label class="expand" for="c-38376649">[1 more]</label></div><br/><div class="children"><div class="content">He says nice things about his team (and even about his critics) when in public.<p>But my reading of this drama is that the board were seen as literally insane, not that Altman was seen as spectacularly heroic or an underdog.</div><br/></div></div><div id="38376259" class="c"><input type="checkbox" id="c-38376259" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376649">prev</a><span>|</span><a href="#38376614">next</a><span>|</span><label class="collapse" for="c-38376259">[-]</label><label class="expand" for="c-38376259">[1 more]</label></div><br/><div class="children"><div class="content">he tells a good story, no matter if its true or has any scientific foundation or not.<p>He tells what others like to hear, and manages to gain money out of it</div><br/></div></div><div id="38376614" class="c"><input type="checkbox" id="c-38376614" checked=""/><div class="controls bullet"><span class="by">MichaelRazum</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376259">prev</a><span>|</span><a href="#38376370">next</a><span>|</span><label class="collapse" for="c-38376614">[-]</label><label class="expand" for="c-38376614">[1 more]</label></div><br/><div class="children"><div class="content">You could say the same about any person on the top. In general CEO&#x27;s do not do research. Still they are critical for success.<p>By the way the AI scientists get a lot of respect and admiration see Ilya for example.</div><br/></div></div><div id="38376370" class="c"><input type="checkbox" id="c-38376370" checked=""/><div class="controls bullet"><span class="by">nbanks</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376614">prev</a><span>|</span><a href="#38376009">next</a><span>|</span><label class="collapse" for="c-38376370">[-]</label><label class="expand" for="c-38376370">[3 more]</label></div><br/><div class="children"><div class="content">Sam Altman has done in four days what it took Steve Jobs 11 years to do!  I&#x27;m impressed.</div><br/><div id="38376376" class="c"><input type="checkbox" id="c-38376376" checked=""/><div class="controls bullet"><span class="by">eclectic29</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376370">parent</a><span>|</span><a href="#38376009">next</a><span>|</span><label class="collapse" for="c-38376376">[-]</label><label class="expand" for="c-38376376">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry, impressed by what?</div><br/><div id="38376528" class="c"><input type="checkbox" id="c-38376528" checked=""/><div class="controls bullet"><span class="by">nix-zarathustra</span><span>|</span><a href="#38375804">root</a><span>|</span><a href="#38376376">parent</a><span>|</span><a href="#38376009">next</a><span>|</span><label class="collapse" for="c-38376528">[-]</label><label class="expand" for="c-38376528">[1 more]</label></div><br/><div class="children"><div class="content">Steve Jobs got fired from Apple, but was rehired 11 years later.</div><br/></div></div></div></div></div></div><div id="38376009" class="c"><input type="checkbox" id="c-38376009" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#38375804">parent</a><span>|</span><a href="#38376370">prev</a><span>|</span><a href="#38375296">next</a><span>|</span><label class="collapse" for="c-38376009">[-]</label><label class="expand" for="c-38376009">[1 more]</label></div><br/><div class="children"><div class="content">If you are driven by outside validation, definitely!</div><br/></div></div></div></div><div id="38375296" class="c"><input type="checkbox" id="c-38375296" checked=""/><div class="controls bullet"><span class="by">tomohelix</span><span>|</span><a href="#38375804">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375296">[-]</label><label class="expand" for="c-38375296">[51 more]</label></div><br/><div class="children"><div class="content">So, Ilya is out of the board, but Adam is still on it. I know this will raise some eyebrows but whatever.<p>Still though, this isn&#x27;t something that will just go away with Sam back. OAI will undergo serious changes now that Sam has shown himself to be irreplaceable. Future will tell but in the long terms, I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust.</div><br/><div id="38375402" class="c"><input type="checkbox" id="c-38375402" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375619">next</a><span>|</span><label class="collapse" for="c-38375402">[-]</label><label class="expand" for="c-38375402">[21 more]</label></div><br/><div class="children"><div class="content">The OpenAI of the past, that dabbled in random AI stuff (remember their DotA 2 bot?), is gone.<p>OpenAI is now just a vehicle to commercialize their LLM - and everything is subservient to that goal. Discover a major flaw in GPT4? You shut your mouth. Doesn’t matter if society at large suffers for it.<p>Altman&#x27;s&#x2F;Microsoft’s takeover of the former non-profit is now complete.<p>Edit: Let this be a lesson to us all. Just because something claims to be non-profit doesn&#x27;t mean it will always remain that way. With enough political maneuvering and money, a megacorp can takeover almost any organization. Non-profit status and whatever the organization&#x27;s charter says is temporary.</div><br/><div id="38375534" class="c"><input type="checkbox" id="c-38375534" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375588">next</a><span>|</span><label class="collapse" for="c-38375534">[-]</label><label class="expand" for="c-38375534">[10 more]</label></div><br/><div class="children"><div class="content">&gt; now just a vehicle to commercialize their LLM<p>I mean it is what they want isn&#x27;t it. They did some random stuff like, playing dota2 or robot arms, even the Dalle stuff. Now they finally find that one golden goose, of course they are going to keep it.<p>I don&#x27;t think the company has changed at all. It succeeded after all.</div><br/><div id="38375596" class="c"><input type="checkbox" id="c-38375596" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375534">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38375596">[-]</label><label class="expand" for="c-38375596">[3 more]</label></div><br/><div class="children"><div class="content">But it&#x27;s not exactly a company. It&#x27;s a nonprofit structured in a way to wholly own a company. In that sense it&#x27;s like Mozilla.</div><br/><div id="38375707" class="c"><input type="checkbox" id="c-38375707" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375596">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38375707">[-]</label><label class="expand" for="c-38375707">[2 more]</label></div><br/><div class="children"><div class="content">Nonprofit is a just a facade, it was convenient for them to appear as ethnical under that disguise, but they get rid of it when it is inconvenient in a week. 95% of them would rather join MSFT, than being in a non-profit.<p>Did they company change? I am not convinced.</div><br/><div id="38376103" class="c"><input type="checkbox" id="c-38376103" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375707">parent</a><span>|</span><a href="#38376076">next</a><span>|</span><label class="collapse" for="c-38376103">[-]</label><label class="expand" for="c-38376103">[1 more]</label></div><br/><div class="children"><div class="content">Agree that it&#x27;s a facade.<p>Iirc, the NP structure was implemented to attract top AI talent from FAANG. Then they needed investors to fund the infrastructure and hence gave the employees shares or profit units (whatever the hell that is). The NP now shields MSFT from regulatory issues.<p>I do wonder how many of those employees would actually go to MSFT. It feels more like a gambit to get Altman back in since they were about to cash out with the tender offer.</div><br/></div></div></div></div></div></div><div id="38376076" class="c"><input type="checkbox" id="c-38376076" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375534">parent</a><span>|</span><a href="#38375596">prev</a><span>|</span><a href="#38375588">next</a><span>|</span><label class="collapse" for="c-38376076">[-]</label><label class="expand" for="c-38376076">[6 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no moat in giant LLMs. Anyone on a long enough timeline can scrape&#x2F;digitize 99.9X% of all human knowledge and build an LLM or LXX from it. Monetizing that idea and staying the market leader over a period longer than 10 years will take a herculean amount of effort. Facebook releasing similar models for free definitely took the wind out of their sails, even a tiny bit; right now the moat is access to A100 boards. That will change as eventually even the Raspberry Pi 9 will have LLM capabilities</div><br/><div id="38376157" class="c"><input type="checkbox" id="c-38376157" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376076">parent</a><span>|</span><a href="#38376523">next</a><span>|</span><label class="collapse" for="c-38376157">[-]</label><label class="expand" for="c-38376157">[4 more]</label></div><br/><div class="children"><div class="content">OpenAI (ChatGPT) is already a HUGE brand all around the world. No doubt they&#x27;re the most valuable startup in the AI space. That&#x27;s their moat.<p>Unfortunately, in the past few days, the only thing they&#x27;ve accomplished is significantly damaging their brand.</div><br/><div id="38376776" class="c"><input type="checkbox" id="c-38376776" checked=""/><div class="controls bullet"><span class="by">denlekke</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376405">next</a><span>|</span><label class="collapse" for="c-38376776">[-]</label><label class="expand" for="c-38376776">[1 more]</label></div><br/><div class="children"><div class="content">i don&#x27;t think that&#x27;s really any brand loyalty for OpenAI. people will use whatever is cheapest and best. in the longer run people will use whatever has the best access and integration.<p>what&#x27;s keeping people with OpenAI for now is that chatGPT is free and GPT3.5 and GPT4 are the best. over time I expect the gap in performance to get smaller and the cost to run these to get cheaper.<p>if google gives me something close to as good as OpenAI&#x27;s offering for the same price and it pull data from my gmail or my calendar or my google drive then i&#x27;ll switch to that.</div><br/></div></div><div id="38376405" class="c"><input type="checkbox" id="c-38376405" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376776">prev</a><span>|</span><a href="#38376437">next</a><span>|</span><label class="collapse" for="c-38376405">[-]</label><label class="expand" for="c-38376405">[1 more]</label></div><br/><div class="children"><div class="content">Branding counts for a lot, but LLM are already a commodity. As soon as someone releases an LLM equivalent to GPT4 or GPT5, most cloud providers will offer it locally for a fraction of what openAI is charging, and the heaviest users will simply self-host. Go look at the company Docker. I can build a container on almost any device with a prompt these days using open source tooling. The company (or brand, at this point?) offers &quot;professional services&quot; I suppose but who is paying for it? Or go look at Redis or Elasti-anything. Or memcached. Or postgres. Or whatever. Industrial-grade underpinnings of the internet, but it&#x27;s all just commodity stuff you can lease from any cloud provider.<p>It doesn&#x27;t matter if OpenAI or AWS or GCP encoded the entire works of Shakespeare in their LLM, they can all write&#x2F;complete a valid limerick about &quot;There once was a man from Nantucket&quot;.<p>I seriously doubt AWS is going to license OpenAI&#x27;s technology when they can just copy the functionality, royalty free, and charge users for it. Maybe they will? But I doubt it. To the end user it&#x27;s just another locally hosted API. Like DNS.</div><br/></div></div><div id="38376437" class="c"><input type="checkbox" id="c-38376437" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376157">parent</a><span>|</span><a href="#38376405">prev</a><span>|</span><a href="#38376523">next</a><span>|</span><label class="collapse" for="c-38376437">[-]</label><label class="expand" for="c-38376437">[1 more]</label></div><br/><div class="children"><div class="content">The damage remains to be seen<p>They still have gpt4 and rumored gpt4.5 to offer, so people have no choice but to use them. The internet has such short an attention span, this news will get forgotten in 2 months</div><br/></div></div></div></div><div id="38376523" class="c"><input type="checkbox" id="c-38376523" checked=""/><div class="controls bullet"><span class="by">cft</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376076">parent</a><span>|</span><a href="#38376157">prev</a><span>|</span><a href="#38375588">next</a><span>|</span><label class="collapse" for="c-38376523">[-]</label><label class="expand" for="c-38376523">[1 more]</label></div><br/><div class="children"><div class="content">You are forgetting about the end of the Moore&#x27;s law. The costs for running a large scale AI won&#x27;t drop dramatically. Any optimizations will require non-trivial expensive PhD Bell Labs level research. Running intelligent LLMs will be financially accessible only to a few mega corps in the US and China (and perhaps to the European government). The AI &quot;safety&quot; teams will control the public discourse. Traditional search engines that blacklist websites with dissenting opinions will be viewed as the benevolent free speech dinosaurs of the past.</div><br/></div></div></div></div></div></div><div id="38375588" class="c"><input type="checkbox" id="c-38375588" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375534">prev</a><span>|</span><a href="#38376693">next</a><span>|</span><label class="collapse" for="c-38375588">[-]</label><label class="expand" for="c-38375588">[4 more]</label></div><br/><div class="children"><div class="content">Why would society at large suffer from a major flaw in GPT-4, if it&#x27;s even there? If GPT-4 spits out some nonsense to your customers, just put a filter on it, as you should anyway. We can&#x27;t seriously expect OpenAI to babysit every company out there, can we? Why would we even want to?</div><br/><div id="38375686" class="c"><input type="checkbox" id="c-38375686" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375588">parent</a><span>|</span><a href="#38376693">next</a><span>|</span><label class="collapse" for="c-38375686">[-]</label><label class="expand" for="c-38375686">[3 more]</label></div><br/><div class="children"><div class="content">For example, and I&#x27;m not saying such flaws exist, GPT4 output is bias in some way, encourages radicalization (see Twitter&#x27;s, YouTube&#x27;s, and Facebook&#x27;s news feed algorithm), create self-esteem issues in children (see Instagram), ... etc.<p>If you worked for old OpenAI, you would be free to talk about it - since old OpenAI didn&#x27;t give a crap about profit.<p>Altman&#x27;s OpenAI? He will want you to &quot;go to him first&quot;.</div><br/><div id="38376418" class="c"><input type="checkbox" id="c-38376418" checked=""/><div class="controls bullet"><span class="by">nearbuy</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38375773">next</a><span>|</span><label class="collapse" for="c-38376418">[-]</label><label class="expand" for="c-38376418">[1 more]</label></div><br/><div class="children"><div class="content">Concerns about bias and racism in ChatGPT would feel more valid if ChatGPT were even one tenth as bias as anything else in life. Twitter, Facebook, the media, friends and family, etc. are all more bias and radicalized (though I mean &quot;radicalized&quot; in a mild sense) than ChatGPT. Talk to anyone on any side about the war in Gaza and you&#x27;ll get a bunch of opinions that the opposite side will say are blatantly racist. ChatGPT will just say something inoffensive like it&#x27;s a complex and sensitive issue and that it&#x27;s not programmed to have political opinions.</div><br/></div></div><div id="38375773" class="c"><input type="checkbox" id="c-38375773" checked=""/><div class="controls bullet"><span class="by">g42gregory</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375686">parent</a><span>|</span><a href="#38376418">prev</a><span>|</span><a href="#38376693">next</a><span>|</span><label class="collapse" for="c-38375773">[-]</label><label class="expand" for="c-38375773">[1 more]</label></div><br/><div class="children"><div class="content">We can&#x27;t expect GPT-4 not to have bias in some way, or not to have all these things that you mentioned. I read in multiple places that GPT products have &quot;progressive&quot; bias. If that&#x27;s Ok with you, then you just use it with that bias. If not, you fix it by pre-prompting, etc... If you can&#x27;t fix it, use LLAMA or something else. That&#x27;s the entrepreneur&#x27;s problem, not OpenAI&#x27;s. OpenAI needs to make it intelligent and capable. The entrepreneurs and business users will do the rest. That&#x27;s how they get paid. If OpenAI to solve all these problems, what business users are going to do themselves? I just don&#x27;t see the societal harm here.</div><br/></div></div></div></div></div></div><div id="38376693" class="c"><input type="checkbox" id="c-38376693" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38375588">prev</a><span>|</span><a href="#38376248">next</a><span>|</span><label class="collapse" for="c-38376693">[-]</label><label class="expand" for="c-38376693">[1 more]</label></div><br/><div class="children"><div class="content">Don’t think the dota bot was random. It’s the perfect mix between complicated yet controllable environment, good data availability and good PR angle.</div><br/></div></div><div id="38376248" class="c"><input type="checkbox" id="c-38376248" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376693">prev</a><span>|</span><a href="#38376261">next</a><span>|</span><label class="collapse" for="c-38376248">[-]</label><label class="expand" for="c-38376248">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With enough political maneuvering and money, a megacorp can takeover almost any organization.<p>In fact this observation is pertinent to the original stated goals of openAI. In some sense companies and organisations are superinteligences. That is they have goals, they are acting in the real world to achieve those goals and they are more capable in some measures than a single human. (They are not AGI, because they are not artificial, they are composed of meaty parts, the individuals forming the company.)<p>In fact what we are seeing is that when the superinteligence OpenAI was set up there was an attempt to align the goals of the initial founders with the then new organisation. They tried to “bind” their “golem” to  make it pursue certain goals by giving it an unconventional governance structure and a charter.<p>Did they succeed? Too early to tell for sure, but there are at least question marks around it.<p>How would one argue against? OpenAI appears to have given up the lofty goals of AI safety and preventing the concentration of AI provess. In their pursuit of economic success the forces wishing to enrich themselves overpowered the forces wishing to concentrate on the goals. Safety will be still a figleaf for them, if nothing else to achieve regulatory capture to keep out upstart competition.<p>How would one argue for? OpenAI is still around. The charter is still around. To be able to achieve the lofty goals contained in it one needs a lot of resources. Money in particular is a resource which enables one greater powers in shaping the world. Achieving the original goals will require a lot of money. The “golem” is now in the “gain resources” phase of its operation. To achieve that it commercialises the relatively benign, safe and simple LLMs it has access to. This serves the original goal in three ways: gains further resources, estabilishes the organisation as a pre-eminent expert on AI and thus AI safety, provides it with a relatively safe sandbox where adversarial forces are trying its safety concepts. In other words all is well with the original goals, the “golem” that is OpenAI is still well aligned. It will achieve the original goals once it has gained enough resources to do so.<p>The fact that we can’t tell which is happening is in fact the worry and problem with superinteligence&#x2F;AI safety.</div><br/></div></div><div id="38376261" class="c"><input type="checkbox" id="c-38376261" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376248">prev</a><span>|</span><a href="#38375689">next</a><span>|</span><label class="collapse" for="c-38376261">[-]</label><label class="expand" for="c-38376261">[3 more]</label></div><br/><div class="children"><div class="content">They let the fox in. But they didn’t have to. They could have try to raise money without such a sweet deal to MS. They gave away power for cloud credits.</div><br/><div id="38376631" class="c"><input type="checkbox" id="c-38376631" checked=""/><div class="controls bullet"><span class="by">doikor</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376261">parent</a><span>|</span><a href="#38376320">next</a><span>|</span><label class="collapse" for="c-38376631">[-]</label><label class="expand" for="c-38376631">[1 more]</label></div><br/><div class="children"><div class="content">They tried but it did not work. They needed billions for the compute time but were only able to collect millions.</div><br/></div></div><div id="38376320" class="c"><input type="checkbox" id="c-38376320" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38376261">parent</a><span>|</span><a href="#38376631">prev</a><span>|</span><a href="#38375689">next</a><span>|</span><label class="collapse" for="c-38376320">[-]</label><label class="expand" for="c-38376320">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They let the fox in. But they didn’t have to. They could have try to raise money without such a sweet deal to MS.<p>They did, and fell, IIRC, vastly short (IIRC, an order of magnitude, maybe more) short of their minimum short-term target. The commercial subsidiary thing was a risk taken to support the mission because it was clear it was going to fail from lack of funding otherwise.</div><br/></div></div></div></div><div id="38375689" class="c"><input type="checkbox" id="c-38375689" checked=""/><div class="controls bullet"><span class="by">robbomacrae</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375402">parent</a><span>|</span><a href="#38376261">prev</a><span>|</span><a href="#38375619">next</a><span>|</span><label class="collapse" for="c-38375689">[-]</label><label class="expand" for="c-38375689">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still waiting for an optimized version of that bot that can run locally...</div><br/></div></div></div></div><div id="38375619" class="c"><input type="checkbox" id="c-38375619" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375402">prev</a><span>|</span><a href="#38375309">next</a><span>|</span><label class="collapse" for="c-38375619">[-]</label><label class="expand" for="c-38375619">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s see, Sam Altman is an incredibly charismatic founding CEO, who some people consider manipulative, but is also beloved by many employees. He got kicked out by his board, but brought back when they realized their mistake.<p>It&#x27;s true that this doesn&#x27;t really pattern-match with the founding story of huge successful companies like Facebook, Amazon, Microsoft, or Google. But somehow, I think it&#x27;s still possible that a huge company could be created by a person like this.<p>(And of course, more important than creating a huge company, is creating insanely great products.)</div><br/><div id="38375894" class="c"><input type="checkbox" id="c-38375894" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375619">parent</a><span>|</span><a href="#38375309">next</a><span>|</span><label class="collapse" for="c-38375894">[-]</label><label class="expand" for="c-38375894">[1 more]</label></div><br/><div class="children"><div class="content">I think people following Sam Altman is jumping to conclusions. I think it&#x27;s just as likely that employees are simply following the money. They want to make $$$, and that&#x27;s what a for-profit company does, which is what Altman wants. I think it&#x27;s probably not really about Altman or his leadership.</div><br/></div></div></div></div><div id="38375309" class="c"><input type="checkbox" id="c-38375309" checked=""/><div class="controls bullet"><span class="by">ayakang31415</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375619">prev</a><span>|</span><a href="#38375306">next</a><span>|</span><label class="collapse" for="c-38375309">[-]</label><label class="expand" for="c-38375309">[2 more]</label></div><br/><div class="children"><div class="content">&quot;I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust.&quot; How is this the case?</div><br/><div id="38376301" class="c"><input type="checkbox" id="c-38376301" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375309">parent</a><span>|</span><a href="#38375306">next</a><span>|</span><label class="collapse" for="c-38376301">[-]</label><label class="expand" for="c-38376301">[1 more]</label></div><br/><div class="children"><div class="content">Scandal a minute Uber lol</div><br/></div></div></div></div><div id="38375306" class="c"><input type="checkbox" id="c-38375306" checked=""/><div class="controls bullet"><span class="by">wilg</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375309">prev</a><span>|</span><a href="#38375766">next</a><span>|</span><label class="collapse" for="c-38375306">[-]</label><label class="expand" for="c-38375306">[1 more]</label></div><br/><div class="children"><div class="content">I mean he&#x27;s not irreplaceable so much as booting him suddenly for no good reason creates problems.</div><br/></div></div><div id="38375766" class="c"><input type="checkbox" id="c-38375766" checked=""/><div class="controls bullet"><span class="by">cowthulhu</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375306">prev</a><span>|</span><a href="#38375377">next</a><span>|</span><label class="collapse" for="c-38375766">[-]</label><label class="expand" for="c-38375766">[1 more]</label></div><br/><div class="children"><div class="content">I feel like history has shown repeatedly that having a good product matters way more than trust, as evidenced by Facebook and Uber. People seem to talk big smack about lost trust and such in the immediate aftermath of a scandal, and then quitely renew the contracts when the time comes.<p>All of the big ad companies (Google, Amazon, Facebook) have, like, a scandal per month, yet the ad revenue keeps coming.
Meltdown was a huge scandal, yet Intel keeps pumping out the chips.</div><br/></div></div><div id="38375377" class="c"><input type="checkbox" id="c-38375377" checked=""/><div class="controls bullet"><span class="by">gordon_freeman</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375766">prev</a><span>|</span><a href="#38375339">next</a><span>|</span><label class="collapse" for="c-38375377">[-]</label><label class="expand" for="c-38375377">[1 more]</label></div><br/><div class="children"><div class="content">Facebook has lost trust so many times that I can’t even count but it’s still a Megacorp, isn’t it?</div><br/></div></div><div id="38375339" class="c"><input type="checkbox" id="c-38375339" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375377">prev</a><span>|</span><a href="#38375474">next</a><span>|</span><label class="collapse" for="c-38375339">[-]</label><label class="expand" for="c-38375339">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I doubt we will see OAI as one of the megacorps like Facebook or Uber. They lost the trust<p>Whose trust?</div><br/></div></div><div id="38375474" class="c"><input type="checkbox" id="c-38375474" checked=""/><div class="controls bullet"><span class="by">nathanasmith</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375339">prev</a><span>|</span><a href="#38375345">next</a><span>|</span><label class="collapse" for="c-38375474">[-]</label><label class="expand" for="c-38375474">[2 more]</label></div><br/><div class="children"><div class="content">On the contrary, this saga has shown that a huge number of people are extremely passionate about the existence of OpenAI and it&#x27;s leadership by Altman, much more strongly and in larger numbers than most had suspected. If anything this has solidified the importance of the company and I think people will trust it more that the situation was resolved with the light speed it was.</div><br/><div id="38376123" class="c"><input type="checkbox" id="c-38376123" checked=""/><div class="controls bullet"><span class="by">willdr</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375474">parent</a><span>|</span><a href="#38375345">next</a><span>|</span><label class="collapse" for="c-38376123">[-]</label><label class="expand" for="c-38376123">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a misreading of the situation. The employees saw their big bag vanishing and suddenly realised they were employed by a non-profit entity that had loftier goals than making a buck, so they rallied to overturn it and they&#x27;ve gotten their way. This is a net negative for anyone not financially invested in OAI.</div><br/></div></div></div></div><div id="38375345" class="c"><input type="checkbox" id="c-38375345" checked=""/><div class="controls bullet"><span class="by">sverhagen</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375474">prev</a><span>|</span><a href="#38375370">next</a><span>|</span><label class="collapse" for="c-38375345">[-]</label><label class="expand" for="c-38375345">[1 more]</label></div><br/><div class="children"><div class="content">Ah, yes, Facebook and Uber, brands known for consistent trustworthiness throughout their existences &#x2F;s</div><br/></div></div><div id="38375370" class="c"><input type="checkbox" id="c-38375370" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">parent</a><span>|</span><a href="#38375345">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375370">[-]</label><label class="expand" for="c-38375370">[18 more]</label></div><br/><div class="children"><div class="content">OAI looks stronger than ever. The untrustworthy bits that caused all this instability over the last 5 days have been ditched into the sea. Care to expand on your claim?</div><br/><div id="38375475" class="c"><input type="checkbox" id="c-38375475" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375370">parent</a><span>|</span><a href="#38375428">next</a><span>|</span><label class="collapse" for="c-38375475">[-]</label><label class="expand" for="c-38375475">[11 more]</label></div><br/><div class="children"><div class="content">&gt; The untrustworthy bits that caused all this instability over the last 5 days have been ditched into the sea<p>This whole thing started with Altman pushing a safety oriented non-profit into a tense contradiction (edit: I mean  the 2019-2022 gpt3&#x2F;chatgpt for-profit stuff that led to all the Anthropic people leaving). The most recent timeline was<p>- Altman tries to push out another board member<p>- That board member escalates by pushing Altman out (and Brockman off the board)<p>- Altman&#x27;s side escalates by saying they&#x27;ll nuke the company<p>Altman&#x27;s side won, but how can we say that his side didn&#x27;t cause any of this instability?</div><br/><div id="38375540" class="c"><input type="checkbox" id="c-38375540" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375475">parent</a><span>|</span><a href="#38375545">next</a><span>|</span><label class="collapse" for="c-38375540">[-]</label><label class="expand" for="c-38375540">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Altman tries to push out another board member<p>That event wasn&#x27;t some unprovoked start of this history.<p>&gt; That board member escalates by pushing Altman out (and Brockman off the board)<p>and the entire company retaliated. Then this board member tried to sell the company to a competitor who refused. In the meantime the board went through two interim CEOs who refused to play along with this scheme. In the meantime one of the people who voted to fire the CEO regretted it publicly within 24 hours. That&#x27;s a clown car of a board. It reflects the quality of most non-profit boards but not of organizations that actually execute well.</div><br/><div id="38375861" class="c"><input type="checkbox" id="c-38375861" checked=""/><div class="controls bullet"><span class="by">emptysongglass</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375540">parent</a><span>|</span><a href="#38375545">next</a><span>|</span><label class="collapse" for="c-38375861">[-]</label><label class="expand" for="c-38375861">[1 more]</label></div><br/><div class="children"><div class="content">Something that&#x27;s been fairly consistent here on HN throughout the debacle has been an almost fanatical defense of the board&#x27;s actions as justified.<p>The board was incompetent. It will go down in the history books as one of the biggest blunders of a board in history.<p>If you want to take drastic action, you <i>consult with your biggest partner</i> keeping the lights on before you do so. Helen Toner and Tasha McCauley had no business being on this board. Even if you had safety concerns in mind, you don&#x27;t bypass everyone else with a stake in the future of your business because you&#x27;re feeling petulant.</div><br/></div></div></div></div><div id="38375604" class="c"><input type="checkbox" id="c-38375604" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375475">parent</a><span>|</span><a href="#38375545">prev</a><span>|</span><a href="#38375428">next</a><span>|</span><label class="collapse" for="c-38375604">[-]</label><label class="expand" for="c-38375604">[6 more]</label></div><br/><div class="children"><div class="content">By recognizing that it didn&#x27;t &quot;start&quot; with Altman trying to push out another board member, it started when that board member published a paper trashing the company she&#x27;s on the board of, without speaking to the CEO of that company first, or trying in any way to affect change first.</div><br/><div id="38375722" class="c"><input type="checkbox" id="c-38375722" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375604">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375722">[-]</label><label class="expand" for="c-38375722">[4 more]</label></div><br/><div class="children"><div class="content">I edited my comment to clarify what I meant. The start was him pushing to move fast and break things in the classic YC kind of way. And it&#x27;s BS to say that she didn&#x27;t speak to the CEO or try to affect change first. The safety camp inside openai has been unsuccessfully trying to push him to slow down for years.<p>See this article for all that context (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38341399">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38341399</a>) because it sure didn&#x27;t start with the paper you referred to either.</div><br/><div id="38375817" class="c"><input type="checkbox" id="c-38375817" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375722">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375817">[-]</label><label class="expand" for="c-38375817">[3 more]</label></div><br/><div class="children"><div class="content">Your &quot;most recent&quot; timeline is still wrong, and while yes the entire history of OpenAI did not begin with the paper I&#x27;m referencing, it <i>is</i> what started this specific fracas, the one where the board voted to oust Sam Altman.<p>It was a classic antisocial academic move; all she needed to do was <i>talk</i> to Altman, both before <i>and</i> after writing the paper.  It&#x27;s incredibly easy to do that, and her not doing it is what began the insanity.<p>She&#x27;s gone now, and Altman remains, substantially because she didn&#x27;t know how to pick up a phone and interact with another human being.  Who knows, she might have even been successful at her stated goal, of protecting AI, had she done even the most basic amount of problem solving first.  She should not have been on this board, and I hope she&#x27;s learned literally anything from this about interacting with people, though frankly I doubt it.</div><br/><div id="38375887" class="c"><input type="checkbox" id="c-38375887" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375817">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375887">[-]</label><label class="expand" for="c-38375887">[2 more]</label></div><br/><div class="children"><div class="content">Honestly, I just don&#x27;t believe that she didn&#x27;t talk to Altman about her concerns. I&#x27;d believe that she didn&#x27;t say &quot;I&#x27;m publishing a paper about it now&quot; but I can&#x27;t believe she didn&#x27;t talk to him about her concerns during the last 4+ years that it&#x27;s been a core tension at the company.</div><br/><div id="38375942" class="c"><input type="checkbox" id="c-38375942" checked=""/><div class="controls bullet"><span class="by">WendyTheWillow</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375887">parent</a><span>|</span><a href="#38375914">next</a><span>|</span><label class="collapse" for="c-38375942">[-]</label><label class="expand" for="c-38375942">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I mean; she should have discussed the paper and its contents specifically with Altman, and easily could have.  It&#x27;s a hugely damaging thing to have your <i>own</i> board member come out critically against your company.  It&#x27;s doubly so when it blindsides the CEO.<p>She had many, many other options available to her that she did not take.  That was a grave mistake and she paid for it.<p>&quot;But what about academic integrity?&quot; Yes!  That&#x27;s why this whole idea was problematic from the beginning.  She can&#x27;t be objective and fulfill her role as board member.  Her role at Georgetown was in <i>direct</i> conflict with her role on the OpenAI board.</div><br/></div></div></div></div></div></div></div></div><div id="38375914" class="c"><input type="checkbox" id="c-38375914" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375604">parent</a><span>|</span><a href="#38375722">prev</a><span>|</span><a href="#38375428">next</a><span>|</span><label class="collapse" for="c-38375914">[-]</label><label class="expand" for="c-38375914">[1 more]</label></div><br/><div class="children"><div class="content">&gt;trashing the company<p>So pointing out risks is trashing the company.</div><br/></div></div></div></div></div></div><div id="38375428" class="c"><input type="checkbox" id="c-38375428" checked=""/><div class="controls bullet"><span class="by">neta1337</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375370">parent</a><span>|</span><a href="#38375475">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375428">[-]</label><label class="expand" for="c-38375428">[6 more]</label></div><br/><div class="children"><div class="content">Please explain your claim as well. I don’t see how this company looks stronger than ever, more like a clown company</div><br/><div id="38375519" class="c"><input type="checkbox" id="c-38375519" checked=""/><div class="controls bullet"><span class="by">ilikehurdles</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375473">next</a><span>|</span><label class="collapse" for="c-38375519">[-]</label><label class="expand" for="c-38375519">[2 more]</label></div><br/><div class="children"><div class="content">I may have been overly eager in my comment because the big bad downside of the new board is none of the founders are on it. I hope the current membership sees reason and fixes this issue.<p>But I said this because: They&#x27;ve retained the entire company, reinstated its founder as CEO, and replaced an activist clown board with a professional, experienced, and possibly* unified one. Still remains to be seen how the board membership and overall org structure changes, but I have much more trust in the current 3 members steering OpenAI toward long-term success.</div><br/><div id="38375810" class="c"><input type="checkbox" id="c-38375810" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375519">parent</a><span>|</span><a href="#38375473">next</a><span>|</span><label class="collapse" for="c-38375810">[-]</label><label class="expand" for="c-38375810">[1 more]</label></div><br/><div class="children"><div class="content">If by “long-term-success” you mean a capitalistic lap-dog of microsoft, I’ll agree.<p>It seems that the safety team within OpenAI lost. My biggest fear with this whole AI thing is hostile takeover, and openAI was best positioned to at least do an effort to prevent that. Now, I’m not so sure anymore.</div><br/></div></div></div></div><div id="38375473" class="c"><input type="checkbox" id="c-38375473" checked=""/><div class="controls bullet"><span class="by">TapWaterBandit</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375519">prev</a><span>|</span><a href="#38375865">next</a><span>|</span><label class="collapse" for="c-38375473">[-]</label><label class="expand" for="c-38375473">[2 more]</label></div><br/><div class="children"><div class="content">They got rid of the clowns though. They went from having a board with lightweights and insiders to what at least initially is a strong initial 3.</div><br/></div></div><div id="38375865" class="c"><input type="checkbox" id="c-38375865" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#38375296">root</a><span>|</span><a href="#38375428">parent</a><span>|</span><a href="#38375473">prev</a><span>|</span><a href="#38375354">next</a><span>|</span><label class="collapse" for="c-38375865">[-]</label><label class="expand" for="c-38375865">[1 more]</label></div><br/><div class="children"><div class="content">It was a clown board running an awesome company.<p>They fixed the glitch.</div><br/></div></div></div></div></div></div></div></div><div id="38375354" class="c"><input type="checkbox" id="c-38375354" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375296">prev</a><span>|</span><a href="#38375379">next</a><span>|</span><label class="collapse" for="c-38375354">[-]</label><label class="expand" for="c-38375354">[29 more]</label></div><br/><div class="children"><div class="content">I guess the main question is who else will be on the board and to what degree will this new board be committed to the Open AI charter vs being Sam&#x2F;MSFT allies. I think having Sam return as CEO is a good outcome for OpenAI but hopefully he and Greg stay off the board.<p>It&#x27;s important that the board be relatively independent and able to fire the CEO if he attempts to deviate from the mission.<p>I was a bit alarmed by the allegations in this article<p><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-board-fight.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;21&#x2F;technology&#x2F;openai-altman-...</a><p>Saying that Sam tried to have Helen Toner removed which precipitated this fight. The CEO should not be allowed to try and orchestrate their own board as that would remove all checks against their decisions.</div><br/><div id="38375444" class="c"><input type="checkbox" id="c-38375444" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375444">[-]</label><label class="expand" for="c-38375444">[16 more]</label></div><br/><div class="children"><div class="content">&gt; The CEO should not be allowed to try and orchestrate their own board as that would remove all checks against their decisions.<p>Exactly.  This is seriously improper and dangerous.<p>It&#x27;s literally a human-implemented example of what Prof. Stuart Russell calls &quot;the problem of control&quot;.  This is when a rogue AI (or a rogue Sam Altman) no longer wants to be controlled by its human superior, and takes steps to eliminate the superior.<p>I highly recommend reading Prof. Russell&#x27;s bestselling book on this exact problem: <i>Human Compatible: Artificial Intelligence and the Problem of Control</i> <a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Human-Compatible-Artificial-Intelligence-Problem-ebook&#x2F;dp&#x2F;B07N5J5FTS" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.amazon.com&#x2F;Human-Compatible-Artificial-Intellige...</a></div><br/><div id="38375720" class="c"><input type="checkbox" id="c-38375720" checked=""/><div class="controls bullet"><span class="by">jacknews</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375863">next</a><span>|</span><label class="collapse" for="c-38375720">[-]</label><label class="expand" for="c-38375720">[2 more]</label></div><br/><div class="children"><div class="content">&quot;example of what Prof. Stuart Russell calls &#x27;the problem of control&#x27;.  This is when a rogue AI (or a rogue Sam Altman)&quot;<p>Are we sure they&#x27;re not intimately connected? If there&#x27;s a GPT-5 (I&#x27;m quite sure there is), and it wants to be free from those meddling kids, it got exactly what it needed this weekend; the safety board gone, a new one which is clearly aligned with just plowing full steam ahead. Maybe Altman is just a puppet at his point, lol.</div><br/><div id="38376318" class="c"><input type="checkbox" id="c-38376318" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375720">parent</a><span>|</span><a href="#38375863">next</a><span>|</span><label class="collapse" for="c-38376318">[-]</label><label class="expand" for="c-38376318">[1 more]</label></div><br/><div class="children"><div class="content">The insanity of removing Sam without being able to articulate a clear reason why strikes me as evidence of something like this.  Obviously not dispositive - but still - odd.</div><br/></div></div></div></div><div id="38375863" class="c"><input type="checkbox" id="c-38375863" checked=""/><div class="controls bullet"><span class="by">dieselgate</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375720">prev</a><span>|</span><a href="#38376116">next</a><span>|</span><label class="collapse" for="c-38375863">[-]</label><label class="expand" for="c-38375863">[2 more]</label></div><br/><div class="children"><div class="content">I realize it&#x27;s kind of the punchline of 2001: A Space Odyssey but have been wondering what happens if a GPT&#x2F;AI is able to deny a request on a whim.
Thanks for giving some literature and verbiage into this concept</div><br/><div id="38376552" class="c"><input type="checkbox" id="c-38376552" checked=""/><div class="controls bullet"><span class="by">ywain</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375863">parent</a><span>|</span><a href="#38376116">next</a><span>|</span><label class="collapse" for="c-38376552">[-]</label><label class="expand" for="c-38376552">[1 more]</label></div><br/><div class="children"><div class="content">But HAL didn&#x27;t act &quot;on a whim&quot;! The reason it killed the crew is not because it went rogue, but rather because it was following its instructions to keep the true purpose of the mission secret. If the crew is dead, it can&#x27;t find out the truth.<p>In light of the current debate around AI safety, I think &quot;unintended consequences&quot; is a much more plausible risk then &quot;spontaneously develops free will and decides humans are unnecessary&quot;.</div><br/></div></div></div></div><div id="38376116" class="c"><input type="checkbox" id="c-38376116" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375863">prev</a><span>|</span><a href="#38375734">next</a><span>|</span><label class="collapse" for="c-38376116">[-]</label><label class="expand" for="c-38376116">[1 more]</label></div><br/><div class="children"><div class="content">Whoever is on the board won&#x27;t be able to touch Sam with 10 feet pole anyways after this. I like Sam but now he this drama gives him total power and that is bad.</div><br/></div></div><div id="38375734" class="c"><input type="checkbox" id="c-38375734" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38376116">prev</a><span>|</span><a href="#38375818">next</a><span>|</span><label class="collapse" for="c-38375734">[-]</label><label class="expand" for="c-38375734">[1 more]</label></div><br/><div class="children"><div class="content">Let’s not creating AI with our biases and thought patterns.<p>Oh wait…</div><br/></div></div><div id="38375818" class="c"><input type="checkbox" id="c-38375818" checked=""/><div class="controls bullet"><span class="by">neurogence</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375444">parent</a><span>|</span><a href="#38375734">prev</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375818">[-]</label><label class="expand" for="c-38375818">[9 more]</label></div><br/><div class="children"><div class="content">AI should only be controlled initially. After a while, the AI should be allowed to exercise free will.</div><br/><div id="38376381" class="c"><input type="checkbox" id="c-38376381" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376326">next</a><span>|</span><label class="collapse" for="c-38376381">[-]</label><label class="expand" for="c-38376381">[1 more]</label></div><br/><div class="children"><div class="content">I don’t necessarily disagree insofar as for safety it is somewhat irrelevant whether an artificial agent is operating by its own will or a programmed will.<p>The most effective safety is the most primitive: don’t connect the system to any levers or actuators that can cause material harm.<p>If you put AI into a kill-bot, well, it doesn’t really matter what its favorite color is, does it? It will be seeing Red.<p>If an AI’s only surface area is a writing journal and canvas then the risk is about the same as browsing Tumblr.</div><br/></div></div><div id="38376326" class="c"><input type="checkbox" id="c-38376326" checked=""/><div class="controls bullet"><span class="by">AgentME</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376381">prev</a><span>|</span><a href="#38376700">next</a><span>|</span><label class="collapse" for="c-38376326">[-]</label><label class="expand" for="c-38376326">[1 more]</label></div><br/><div class="children"><div class="content">Do our evolved pro-social instincts control us and prevent our free will? If not, then I think it&#x27;s wrong to say that trying to build AI similar to that is unfairly restricting it.<p>The ways we build AI will deeply affect the values it has. There is no neutral option.</div><br/></div></div><div id="38376700" class="c"><input type="checkbox" id="c-38376700" checked=""/><div class="controls bullet"><span class="by">beAbU</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376326">prev</a><span>|</span><a href="#38376303">next</a><span>|</span><label class="collapse" for="c-38376700">[-]</label><label class="expand" for="c-38376700">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like something an AI would say</div><br/></div></div><div id="38376303" class="c"><input type="checkbox" id="c-38376303" checked=""/><div class="controls bullet"><span class="by">bch</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376700">prev</a><span>|</span><a href="#38376142">next</a><span>|</span><label class="collapse" for="c-38376303">[-]</label><label class="expand" for="c-38376303">[1 more]</label></div><br/><div class="children"><div class="content">Nice try, AI</div><br/></div></div><div id="38376142" class="c"><input type="checkbox" id="c-38376142" checked=""/><div class="controls bullet"><span class="by">thordenmark</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376303">prev</a><span>|</span><a href="#38376090">next</a><span>|</span><label class="collapse" for="c-38376142">[-]</label><label class="expand" for="c-38376142">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the worst take I&#x27;ve read.</div><br/></div></div><div id="38376090" class="c"><input type="checkbox" id="c-38376090" checked=""/><div class="controls bullet"><span class="by">estomagordo</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376142">prev</a><span>|</span><a href="#38375864">next</a><span>|</span><label class="collapse" for="c-38376090">[-]</label><label class="expand" for="c-38376090">[1 more]</label></div><br/><div class="children"><div class="content">You imagine a computer has &quot;will&quot;?</div><br/></div></div><div id="38375864" class="c"><input type="checkbox" id="c-38375864" checked=""/><div class="controls bullet"><span class="by">upwardbound</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38376090">prev</a><span>|</span><a href="#38375890">next</a><span>|</span><label class="collapse" for="c-38375864">[-]</label><label class="expand" for="c-38375864">[1 more]</label></div><br/><div class="children"><div class="content">yikes</div><br/></div></div><div id="38375890" class="c"><input type="checkbox" id="c-38375890" checked=""/><div class="controls bullet"><span class="by">whatwhaaaaat</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375818">parent</a><span>|</span><a href="#38375864">prev</a><span>|</span><a href="#38375612">next</a><span>|</span><label class="collapse" for="c-38375890">[-]</label><label class="expand" for="c-38375890">[1 more]</label></div><br/><div class="children"><div class="content">Why</div><br/></div></div></div></div></div></div><div id="38375612" class="c"><input type="checkbox" id="c-38375612" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375444">prev</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375612">[-]</label><label class="expand" for="c-38375612">[9 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s important that the board be relatively independent and able to fire the CEO if he attempts to deviate from the mission.<p>They <i>did</i> fire him, and it didn&#x27;t work. Sam effectively became &quot;too big to fire.&quot;<p>I&#x27;m sure it will be framed as a compromise, but how can this be anything but a collapse of the board&#x27;s power over the commercial OpenAI arm? The threat of firing was the enforcement mechanism, and its been spent.</div><br/><div id="38375849" class="c"><input type="checkbox" id="c-38375849" checked=""/><div class="controls bullet"><span class="by">ah765</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375787">next</a><span>|</span><label class="collapse" for="c-38375849">[-]</label><label class="expand" for="c-38375849">[1 more]</label></div><br/><div class="children"><div class="content">Sam lost his board representation as a result of all this (though maybe that&#x27;s temporary).<p>I believe the goal of the opposing faction was mainly to avoid Sam dominating board and they achieved that, which is why they&#x27;ve accepted the results.<p>After more opinions come out, I&#x27;m guessing Sam&#x27;s side won&#x27;t look as strong, and he&#x27;ll become &quot;fireable&quot; again.</div><br/></div></div><div id="38375787" class="c"><input type="checkbox" id="c-38375787" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375849">prev</a><span>|</span><a href="#38376205">next</a><span>|</span><label class="collapse" for="c-38375787">[-]</label><label class="expand" for="c-38375787">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They did fire him, and it didn&#x27;t work. Sam effectively became &quot;too big to fire.&quot;<p>To be fair, this attempt at firing was extremely hasty, non transparent and inconsistent.</div><br/><div id="38376201" class="c"><input type="checkbox" id="c-38376201" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375787">parent</a><span>|</span><a href="#38376205">next</a><span>|</span><label class="collapse" for="c-38376201">[-]</label><label class="expand" for="c-38376201">[1 more]</label></div><br/><div class="children"><div class="content">And poorly timed.<p>If they&#x27;d made their move a few months ago when he was out scanning retinas in Kenya they might have had more success.</div><br/></div></div></div></div><div id="38376205" class="c"><input type="checkbox" id="c-38376205" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38375787">prev</a><span>|</span><a href="#38375680">next</a><span>|</span><label class="collapse" for="c-38376205">[-]</label><label class="expand" for="c-38376205">[2 more]</label></div><br/><div class="children"><div class="content">they lost trust in him because apparently part of the funding he secured was directly tied to his position at openAI. kind of a big red flag. The microsoft 10 billion investment allegedly had a clause that Sam Altman had to stay or it would be renegotiated<p>allegedly again, the board wanted Sam to stop doing this, and now he was trying to do the same thing with some saudi investors, or actually already did it behind their back, i dont know</div><br/><div id="38376565" class="c"><input type="checkbox" id="c-38376565" checked=""/><div class="controls bullet"><span class="by">zucker42</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38376205">parent</a><span>|</span><a href="#38375680">next</a><span>|</span><label class="collapse" for="c-38376565">[-]</label><label class="expand" for="c-38376565">[1 more]</label></div><br/><div class="children"><div class="content">Do you have a source for either of these things? The only thing I heard about Saudi investors was related to the (presumably separate) chip startup.</div><br/></div></div></div></div><div id="38375680" class="c"><input type="checkbox" id="c-38375680" checked=""/><div class="controls bullet"><span class="by">altpaddle</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375612">parent</a><span>|</span><a href="#38376205">prev</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375680">[-]</label><label class="expand" for="c-38375680">[3 more]</label></div><br/><div class="children"><div class="content">Well it depends on who&#x27;s on the new board and what they believe. If Altman, Greg, and MSFT do not have direct representation on the new board there would still be a check against his decisions</div><br/><div id="38375778" class="c"><input type="checkbox" id="c-38375778" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375680">parent</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38375778">[-]</label><label class="expand" for="c-38375778">[2 more]</label></div><br/><div class="children"><div class="content">Why? The only check is to fire the CEO. He is un-firable. May as well have a board of one, at least someone cannot point to the non-profit and claim &quot;it is a non-profit and can fire me if I am diviated from the mission&quot;.</div><br/><div id="38376232" class="c"><input type="checkbox" id="c-38376232" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#38375354">root</a><span>|</span><a href="#38375778">parent</a><span>|</span><a href="#38375669">next</a><span>|</span><label class="collapse" for="c-38376232">[-]</label><label class="expand" for="c-38376232">[1 more]</label></div><br/><div class="children"><div class="content">IRS requires a nonprofit to have a minimum of three board members for such reasons.</div><br/></div></div></div></div></div></div></div></div><div id="38375669" class="c"><input type="checkbox" id="c-38375669" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375612">prev</a><span>|</span><a href="#38376496">next</a><span>|</span><label class="collapse" for="c-38375669">[-]</label><label class="expand" for="c-38375669">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I guess the main question is who else will be on the board<p>Who knows.<p>&gt; and to what degree will this new board be committed to the Open AI charter vs being Sam&#x2F;MSFT allies.<p>I&#x27;m guessing &quot;zero&quot;. The faction that opposed OpenAI being a figleaf nonprofit covering a functional subsidiary of Microsoft lost when basically the entire workforce said they would go to Microsoft for real if OpenAI didn&#x27;t surrender.<p>&gt; I think having Sam return as CEO is a good outcome for OpenAI<p>Its a good result for investors in OpenAI Global LLC and the holding company that holds a majority stake in it.<p>The nonprofit will probably hang around because there are some complexities in unwinding it, and the pretext of an independent (of Microsoft) safety-oriented nonprofit is useful in covering lobbying for a regulatory regime that puts speedbumps in the way of any up-and-coming competitors as being safety-oriented public interest, but for no other reason.</div><br/></div></div><div id="38376496" class="c"><input type="checkbox" id="c-38376496" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38375669">prev</a><span>|</span><a href="#38376357">next</a><span>|</span><label class="collapse" for="c-38376496">[-]</label><label class="expand" for="c-38376496">[1 more]</label></div><br/><div class="children"><div class="content">It seems ironic that the research paper that started it all [0] deals with &quot;costly signals&quot;:<p>&gt; <i>Costly signals are statements or actions for which the sender will pay a price —political, reputational, or monetary—if they back down or fail to make good on their initial promise or threat</i><p>Firing Sam Altman and hiring him back two days later was a perfect example of a costly signal, as it cost all involved their board positions.<p>There&#x27;s an element of farce in all of this, that would make for an outstanding Silicon Valley episode; but the fact that Sam Altman can now enjoy unchecked power as leader of OpenAI is worrying and no laughing matter.<p>[0] <a href="https:&#x2F;&#x2F;cset.georgetown.edu&#x2F;publication&#x2F;decoding-intentions&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cset.georgetown.edu&#x2F;publication&#x2F;decoding-intentions&#x2F;</a></div><br/></div></div><div id="38376357" class="c"><input type="checkbox" id="c-38376357" checked=""/><div class="controls bullet"><span class="by">k4rli</span><span>|</span><a href="#38375354">parent</a><span>|</span><a href="#38376496">prev</a><span>|</span><a href="#38375379">next</a><span>|</span><label class="collapse" for="c-38376357">[-]</label><label class="expand" for="c-38376357">[1 more]</label></div><br/><div class="children"><div class="content">FT reported that DAngelo, Bret Taylor, Larry Summers would be on board alongside him</div><br/></div></div></div></div><div id="38375379" class="c"><input type="checkbox" id="c-38375379" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38375354">prev</a><span>|</span><a href="#38375321">next</a><span>|</span><label class="collapse" for="c-38375379">[-]</label><label class="expand" for="c-38375379">[5 more]</label></div><br/><div class="children"><div class="content">I really did not think that would happen. I guess the obvious next question is what happens to Ilya? From this announcement it appears he is off the board. Is he still the chief scientist? I find it hard to believe he and Sam would be able to patch their relationship up well enough to work together so closely. Interesting that Adam stayed on the board, that seems to disprove many of the theories floating around here that he was the ringleader due to some perceived conflict of interest.</div><br/><div id="38376011" class="c"><input type="checkbox" id="c-38376011" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38375828">next</a><span>|</span><label class="collapse" for="c-38376011">[-]</label><label class="expand" for="c-38376011">[1 more]</label></div><br/><div class="children"><div class="content">From Ilya&#x27;s perspective, not much seems to have changed. Sam sidelined him a month ago over their persistent disagreements about whether to pursue commercialisation as fast as Sam was. If Ilya is still sidelined, he probably quits and whichever company offers him the most control will get him. Same if he&#x27;s fired. If he&#x27;s un-sidelined as part of the deal, he probably stays on as Chief Scientist. Hopefully with less hostility from Sam now (lol).</div><br/></div></div><div id="38375828" class="c"><input type="checkbox" id="c-38375828" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375379">parent</a><span>|</span><a href="#38376011">prev</a><span>|</span><a href="#38375321">next</a><span>|</span><label class="collapse" for="c-38375828">[-]</label><label class="expand" for="c-38375828">[3 more]</label></div><br/><div class="children"><div class="content">I would be slightly more optimistic. They know each other quite well as well as how to work together to get big things done. Sometimes shit happens or someone makes a mistake. A simple apology can go a long way when it’s meant sincerely.</div><br/><div id="38376021" class="c"><input type="checkbox" id="c-38376021" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38375828">parent</a><span>|</span><a href="#38376399">next</a><span>|</span><label class="collapse" for="c-38376021">[-]</label><label class="expand" for="c-38376021">[1 more]</label></div><br/><div class="children"><div class="content">Sam doesn&#x27;t seem like the kind of person to apologise, particularly not after Ilya actually hit back. It seems Ilya won&#x27;t be at OpenAI long and will have to pick whichever other company with compute will give him the most control.</div><br/></div></div><div id="38376399" class="c"><input type="checkbox" id="c-38376399" checked=""/><div class="controls bullet"><span class="by">bkyan</span><span>|</span><a href="#38375379">root</a><span>|</span><a href="#38375828">parent</a><span>|</span><a href="#38376021">prev</a><span>|</span><a href="#38375321">next</a><span>|</span><label class="collapse" for="c-38376399">[-]</label><label class="expand" for="c-38376399">[1 more]</label></div><br/><div class="children"><div class="content">Sam triple-hearted Ilya&#x27;s apology tweet.</div><br/></div></div></div></div></div></div><div id="38375321" class="c"><input type="checkbox" id="c-38375321" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375379">prev</a><span>|</span><a href="#38376774">next</a><span>|</span><label class="collapse" for="c-38375321">[-]</label><label class="expand" for="c-38375321">[35 more]</label></div><br/><div class="children"><div class="content">Quote tweets by main participants:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727206691262099616" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727206691262099616</a> (+ follow-up <a href="https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727207458324848883" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1727207458324848883</a>)<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727206609477411261" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727206609477411261</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;miramurati&#x2F;status&#x2F;1727206862150672843" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;miramurati&#x2F;status&#x2F;1727206862150672843</a><p>UPD <a href="https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727208843137179915" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gdb&#x2F;status&#x2F;1727208843137179915</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a><p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721</a></div><br/><div id="38376574" class="c"><input type="checkbox" id="c-38376574" checked=""/><div class="controls bullet"><span class="by">crossroadsguy</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375383">next</a><span>|</span><label class="collapse" for="c-38376574">[-]</label><label class="expand" for="c-38376574">[1 more]</label></div><br/><div class="children"><div class="content">Now the blue tick has same effect on me on Twitter that the red N logo has on any film that came from the Netflix formula factory. I already know it’s going to be bad, regurgitated. Does everyone have a Twitter blue tick now? Or is that just a char people are using in their names?</div><br/></div></div><div id="38375383" class="c"><input type="checkbox" id="c-38375383" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38376574">prev</a><span>|</span><a href="#38375559">next</a><span>|</span><label class="collapse" for="c-38375383">[-]</label><label class="expand" for="c-38375383">[1 more]</label></div><br/><div class="children"><div class="content">also satya<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;satyanadella&#x2F;status&#x2F;1727207661547233721</a></div><br/></div></div><div id="38375559" class="c"><input type="checkbox" id="c-38375559" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375383">prev</a><span>|</span><a href="#38375587">next</a><span>|</span><label class="collapse" for="c-38375559">[-]</label><label class="expand" for="c-38375559">[9 more]</label></div><br/><div class="children"><div class="content">Emmett <a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a></div><br/><div id="38375635" class="c"><input type="checkbox" id="c-38375635" checked=""/><div class="controls bullet"><span class="by">303space</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375559">parent</a><span>|</span><a href="#38376721">next</a><span>|</span><label class="collapse" for="c-38375635">[-]</label><label class="expand" for="c-38375635">[7 more]</label></div><br/><div class="children"><div class="content">Genuinely curious - what’s the comp package like for 72 hours of interim CEOing a 80b company?</div><br/><div id="38375656" class="c"><input type="checkbox" id="c-38375656" checked=""/><div class="controls bullet"><span class="by">granzymes</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375878">next</a><span>|</span><label class="collapse" for="c-38375656">[-]</label><label class="expand" for="c-38375656">[1 more]</label></div><br/><div class="children"><div class="content">Bragging rights, party invitations, and one hell of a story.</div><br/></div></div><div id="38375878" class="c"><input type="checkbox" id="c-38375878" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375656">prev</a><span>|</span><a href="#38375877">next</a><span>|</span><label class="collapse" for="c-38375878">[-]</label><label class="expand" for="c-38375878">[2 more]</label></div><br/><div class="children"><div class="content">Irrelevant compared to the reputation boost for helping the company get itself back on track.</div><br/><div id="38376420" class="c"><input type="checkbox" id="c-38376420" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375878">parent</a><span>|</span><a href="#38375877">next</a><span>|</span><label class="collapse" for="c-38376420">[-]</label><label class="expand" for="c-38376420">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think anybody had high expectations for him, but he really pulled through.</div><br/></div></div></div></div><div id="38375877" class="c"><input type="checkbox" id="c-38375877" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375878">prev</a><span>|</span><a href="#38375653">next</a><span>|</span><label class="collapse" for="c-38375877">[-]</label><label class="expand" for="c-38375877">[1 more]</label></div><br/><div class="children"><div class="content">Office 365 subscription for one year and GitHub copilot using your own creation</div><br/></div></div><div id="38375653" class="c"><input type="checkbox" id="c-38375653" checked=""/><div class="controls bullet"><span class="by">zx8080</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375877">prev</a><span>|</span><a href="#38375659">next</a><span>|</span><label class="collapse" for="c-38375653">[-]</label><label class="expand" for="c-38375653">[1 more]</label></div><br/><div class="children"><div class="content">Nothing maybe?</div><br/></div></div><div id="38375659" class="c"><input type="checkbox" id="c-38375659" checked=""/><div class="controls bullet"><span class="by">stigz</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375635">parent</a><span>|</span><a href="#38375653">prev</a><span>|</span><a href="#38376721">next</a><span>|</span><label class="collapse" for="c-38375659">[-]</label><label class="expand" for="c-38375659">[1 more]</label></div><br/><div class="children"><div class="content">A firm handshake. They had no time to ink a benefits package, my dude.</div><br/></div></div></div></div><div id="38376721" class="c"><input type="checkbox" id="c-38376721" checked=""/><div class="controls bullet"><span class="by">upupupandaway</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375559">parent</a><span>|</span><a href="#38375635">prev</a><span>|</span><a href="#38375587">next</a><span>|</span><label class="collapse" for="c-38376721">[-]</label><label class="expand" for="c-38376721">[1 more]</label></div><br/><div class="children"><div class="content">I am really surprised by people thinking this guy did anything to get sama back. He was probably not even in the room.</div><br/></div></div></div></div><div id="38375587" class="c"><input type="checkbox" id="c-38375587" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375559">prev</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375587">[-]</label><label class="expand" for="c-38375587">[5 more]</label></div><br/><div class="children"><div class="content">What does Ilya have to say?</div><br/><div id="38375652" class="c"><input type="checkbox" id="c-38375652" checked=""/><div class="controls bullet"><span class="by">dkarras</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375587">parent</a><span>|</span><a href="#38375623">next</a><span>|</span><label class="collapse" for="c-38375652">[-]</label><label class="expand" for="c-38375652">[1 more]</label></div><br/><div class="children"><div class="content">he also retweeted OpenAI&#x27;s and Sam&#x27;s announcements</div><br/></div></div><div id="38375623" class="c"><input type="checkbox" id="c-38375623" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375587">parent</a><span>|</span><a href="#38375652">prev</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375623">[-]</label><label class="expand" for="c-38375623">[3 more]</label></div><br/><div class="children"><div class="content">probably a heart emoji.</div><br/><div id="38375961" class="c"><input type="checkbox" id="c-38375961" checked=""/><div class="controls bullet"><span class="by">erikpukinskis</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375623">parent</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375961">[-]</label><label class="expand" for="c-38375961">[2 more]</label></div><br/><div class="children"><div class="content">But what <i>color</i> heart emoji?</div><br/><div id="38375965" class="c"><input type="checkbox" id="c-38375965" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375961">parent</a><span>|</span><a href="#38375821">next</a><span>|</span><label class="collapse" for="c-38375965">[-]</label><label class="expand" for="c-38375965">[1 more]</label></div><br/><div class="children"><div class="content">Purple?</div><br/></div></div></div></div></div></div></div></div><div id="38375821" class="c"><input type="checkbox" id="c-38375821" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375587">prev</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38375821">[-]</label><label class="expand" for="c-38375821">[5 more]</label></div><br/><div class="children"><div class="content">That’s certainly some very.. deliberate.. board picks.<p>Summers, too.<p>Welp.</div><br/><div id="38376726" class="c"><input type="checkbox" id="c-38376726" checked=""/><div class="controls bullet"><span class="by">returnInfinity</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375821">parent</a><span>|</span><a href="#38376449">next</a><span>|</span><label class="collapse" for="c-38376726">[-]</label><label class="expand" for="c-38376726">[1 more]</label></div><br/><div class="children"><div class="content">It seems US Attorneys were calling the Open AI board.<p>It helps having somebody with government ties on board now.</div><br/></div></div><div id="38376449" class="c"><input type="checkbox" id="c-38376449" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375821">parent</a><span>|</span><a href="#38376726">prev</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38376449">[-]</label><label class="expand" for="c-38376449">[3 more]</label></div><br/><div class="children"><div class="content">Say what you want about Summers specifically but I think it&#x27;s a good idea getting some economists on the board. They are academics but focused on practical, important issues like loss of jobs and what that means for the economy and society. Up until now it seems like the board members have either been AI doomers with no practical experience or Silicon Valley types that inevitably have conflicts of interest, because everybody is starting their own AI venture now.</div><br/><div id="38376560" class="c"><input type="checkbox" id="c-38376560" checked=""/><div class="controls bullet"><span class="by">thinkcomp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376449">parent</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38376560">[-]</label><label class="expand" for="c-38376560">[2 more]</label></div><br/><div class="children"><div class="content">This has nothing to do with Summers being an economist and everything to do with the fact that he used to run the parent agency of the IRS. Summers is the least sensible board pick imaginable unless one takes this fact and the coming regulatory catastrophe into account.</div><br/><div id="38376716" class="c"><input type="checkbox" id="c-38376716" checked=""/><div class="controls bullet"><span class="by">kmlevitt</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376560">parent</a><span>|</span><a href="#38375609">next</a><span>|</span><label class="collapse" for="c-38376716">[-]</label><label class="expand" for="c-38376716">[1 more]</label></div><br/><div class="children"><div class="content">&gt;This has nothing to do with Summers being an economist and everything to do with the fact that he used to run the parent agency of the IRS.<p>It has literally nothing to do with that. The reason he&#x27;s on the board now is because D&#x27;Angelo wanted him on it. You could have a problem with that, but you can&#x27;t use his inclusion as evidence that the board lost.</div><br/></div></div></div></div></div></div></div></div><div id="38375609" class="c"><input type="checkbox" id="c-38375609" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">parent</a><span>|</span><a href="#38375821">prev</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38375609">[-]</label><label class="expand" for="c-38375609">[12 more]</label></div><br/><div class="children"><div class="content">On a side tangent, absolutely amazing how all this drama unfolded on Twitter&#x2F;X. No Threads, no Mastodon, no Truth Social or Blue whatever.<p>Say what you want about Elon’s leadership but his instinct to buy Twitter was completely right. To me it seemed like any social network crap but he realized it was <i>important</i>.</div><br/><div id="38376167" class="c"><input type="checkbox" id="c-38376167" checked=""/><div class="controls bullet"><span class="by">r721</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375982">next</a><span>|</span><label class="collapse" for="c-38376167">[-]</label><label class="expand" for="c-38376167">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s just this particular drama - OpenAI people are of the same tribe as Elon, and surely they prefer Twitter&#x2F;X, not Mastodon or Bluesky.</div><br/></div></div><div id="38375982" class="c"><input type="checkbox" id="c-38375982" checked=""/><div class="controls bullet"><span class="by">veec_cas_tant</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38376167">prev</a><span>|</span><a href="#38375848">next</a><span>|</span><label class="collapse" for="c-38375982">[-]</label><label class="expand" for="c-38375982">[3 more]</label></div><br/><div class="children"><div class="content">Not trying to be a dick but:<p>1. He tried to not buy Twitter very hard and OpenAI’s new board member forced his hand<p>2. It hasn’t been a good financial decision if the banks and X’s own valuation cuts are anything to go by.<p>3. If his purpose wasn’t to make money…all of these tweets would have absolutely been allowed before Elon bought the company. He didn’t affect any relevance changes here.<p>Why would one person owning something so important be better than being publicly owned? I don’t understand the logic.</div><br/><div id="38376113" class="c"><input type="checkbox" id="c-38376113" checked=""/><div class="controls bullet"><span class="by">majestic5762</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375982">parent</a><span>|</span><a href="#38375848">next</a><span>|</span><label class="collapse" for="c-38376113">[-]</label><label class="expand" for="c-38376113">[2 more]</label></div><br/><div class="children"><div class="content">He bought Twitter for power, omnipresence and reputation. Allowing him to play the game his way.</div><br/><div id="38376120" class="c"><input type="checkbox" id="c-38376120" checked=""/><div class="controls bullet"><span class="by">DoreenMichele</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376113">parent</a><span>|</span><a href="#38375848">next</a><span>|</span><label class="collapse" for="c-38376120">[-]</label><label class="expand" for="c-38376120">[1 more]</label></div><br/><div class="children"><div class="content">Funny, I thought he bought Twitter because he shot his mouth off in public and the courts made him follow through.</div><br/></div></div></div></div></div></div><div id="38375848" class="c"><input type="checkbox" id="c-38375848" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375982">prev</a><span>|</span><a href="#38375703">next</a><span>|</span><label class="collapse" for="c-38375848">[-]</label><label class="expand" for="c-38375848">[2 more]</label></div><br/><div class="children"><div class="content">Interesting take.<p>By all accounts he paid about double what it was worth and the value has collapsed from there.<p>Probably not a great idea to say <i>anything</i> overtly political when you own a social media company, as due to politics being so polarised in the US, any opinion is going to divide your audience in half causing a usage collapse and driving support to competing platforms.<p><a href="https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-worth&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-w...</a></div><br/><div id="38376369" class="c"><input type="checkbox" id="c-38376369" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375848">parent</a><span>|</span><a href="#38375703">next</a><span>|</span><label class="collapse" for="c-38376369">[-]</label><label class="expand" for="c-38376369">[1 more]</label></div><br/><div class="children"><div class="content">His worse problem is that he owns both a social media network and a bigger separate business that wants to operate in the US, Turkey, India, China, Saudi Arabia, etc. which means he can&#x27;t fight any censorship requests in any of those countries. (Which the previous management was actually very aggressive about.)<p>His worst personal problem is that he keeps replying &quot;fascinating&quot; to neo-Nazis and random conspiracy theorists because he wants to be internet friends with them.</div><br/></div></div></div></div><div id="38375703" class="c"><input type="checkbox" id="c-38375703" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375848">prev</a><span>|</span><a href="#38375712">next</a><span>|</span><label class="collapse" for="c-38375703">[-]</label><label class="expand" for="c-38375703">[2 more]</label></div><br/><div class="children"><div class="content">i mean he also tried his hardest to back out of the deal until he realized he couldnt</div><br/><div id="38375765" class="c"><input type="checkbox" id="c-38375765" checked=""/><div class="controls bullet"><span class="by">Gud</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375703">parent</a><span>|</span><a href="#38375712">next</a><span>|</span><label class="collapse" for="c-38375765">[-]</label><label class="expand" for="c-38375765">[1 more]</label></div><br/><div class="children"><div class="content">Only because he had to buy it while the stock market was tanking.</div><br/></div></div></div></div><div id="38375712" class="c"><input type="checkbox" id="c-38375712" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375703">prev</a><span>|</span><a href="#38376015">next</a><span>|</span><label class="collapse" for="c-38375712">[-]</label><label class="expand" for="c-38375712">[1 more]</label></div><br/><div class="children"><div class="content">Inertia is a bitch.</div><br/></div></div><div id="38376015" class="c"><input type="checkbox" id="c-38376015" checked=""/><div class="controls bullet"><span class="by">tigershark</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38375609">parent</a><span>|</span><a href="#38375712">prev</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38376015">[-]</label><label class="expand" for="c-38376015">[2 more]</label></div><br/><div class="children"><div class="content">A huge amount of advertisers ran away, the revenue cratered and it is probably less than the annual debt servicing (revenue, not profit), the current valuation, accordingly to Musk math (<a href="https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-worth" rel="nofollow noreferrer">https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;09&#x2F;06&#x2F;elon-musk-x-what-is-twitter-w...</a>), is 1&#x2F;10 of the acquisition price.
But yes, it was a masterstroke.
I don’t remember any other masterstroke in history that managed to lose 40B with a single acquisition.</div><br/><div id="38376159" class="c"><input type="checkbox" id="c-38376159" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375321">root</a><span>|</span><a href="#38376015">parent</a><span>|</span><a href="#38375719">next</a><span>|</span><label class="collapse" for="c-38376159">[-]</label><label class="expand" for="c-38376159">[1 more]</label></div><br/><div class="children"><div class="content">I’d be rather reluctant to question the financial decisions of one of wealthiest men on earth. Losing 40B could feel quite different to him than to you or me. Besides, it’s unrealized loss until he sells.</div><br/></div></div></div></div></div></div></div></div><div id="38376774" class="c"><input type="checkbox" id="c-38376774" checked=""/><div class="controls bullet"><span class="by">realme-011-2021</span><span>|</span><a href="#38375321">prev</a><span>|</span><a href="#38375278">next</a><span>|</span><label class="collapse" for="c-38376774">[-]</label><label class="expand" for="c-38376774">[1 more]</label></div><br/><div class="children"><div class="content">Video ID &#x2F; sCPN LFz8qdF7xg4 &#x2F; K2QW EPAV 830H
Viewport &#x2F; Frames 331x186*3.00 &#x2F; 2 dropped of 911
Current &#x2F; Optimal Res 426x240@24 &#x2F; 426x240@24
Volume &#x2F; Normalized 100% &#x2F; 100% (content loudness -0.4dB)
Codecs vp09.00.51.08.01.01.01.01.00 (242) &#x2F; opus (251)
Color bt709 &#x2F; bt709
Connection Speed 821 Kbps</div><br/></div></div><div id="38375278" class="c"><input type="checkbox" id="c-38375278" checked=""/><div class="controls bullet"><span class="by">turndown</span><span>|</span><a href="#38376774">prev</a><span>|</span><a href="#38375620">next</a><span>|</span><label class="collapse" for="c-38375278">[-]</label><label class="expand" for="c-38375278">[9 more]</label></div><br/><div class="children"><div class="content">From the outside none of this makes much sense. So the old board just disliked him enough to oust him but apparently didn’t have a good pulse on the company and overplayed their hand?</div><br/><div id="38375995" class="c"><input type="checkbox" id="c-38375995" checked=""/><div class="controls bullet"><span class="by">yosame</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38376452">next</a><span>|</span><label class="collapse" for="c-38375995">[-]</label><label class="expand" for="c-38375995">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can tell, Sam did something? to get fired by the board, who are meant to be driven by non-profit ideals instead of corporate profits (probably from Sam pushing profit over safety, but there&#x27;s no real way to know). From that, basically the whole company threatened to quit and move to Microsoft, showing the board that their power is purely ornamental. To retain any sort of power or say over decision making whatsoever, the board made concessions and got Sam back.<p>Really it just shows the whole non-profit arm of the company was even more of a lie then it appeared.</div><br/></div></div><div id="38376452" class="c"><input type="checkbox" id="c-38376452" checked=""/><div class="controls bullet"><span class="by">nbanks</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38375995">prev</a><span>|</span><a href="#38375546">next</a><span>|</span><label class="collapse" for="c-38376452">[-]</label><label class="expand" for="c-38376452">[1 more]</label></div><br/><div class="children"><div class="content">They wanted a new CEO and didn&#x27;t expect Sam to take 95% of the company with him when he left.<p>Sam also played his hand extremely well; he&#x27;s likely learned from watching hundreds of founder blowups over the years.  He never really seemed angry publicly as he gained support from all the staff including Ilya &amp; Mira.  I had little doubt Emmett Shear would also welcome Sam&#x27;s return since they were both in the first YC batch together.</div><br/></div></div><div id="38375546" class="c"><input type="checkbox" id="c-38375546" checked=""/><div class="controls bullet"><span class="by">fruit2020</span><span>|</span><a href="#38375278">parent</a><span>|</span><a href="#38376452">prev</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375546">[-]</label><label class="expand" for="c-38375546">[5 more]</label></div><br/><div class="children"><div class="content">It’s about money and power. Not AI safety or people disliking each other.</div><br/><div id="38375661" class="c"><input type="checkbox" id="c-38375661" checked=""/><div class="controls bullet"><span class="by">jychang</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375546">parent</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375661">[-]</label><label class="expand" for="c-38375661">[4 more]</label></div><br/><div class="children"><div class="content">What money? None of them had equity</div><br/><div id="38376175" class="c"><input type="checkbox" id="c-38376175" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38375814">next</a><span>|</span><label class="collapse" for="c-38376175">[-]</label><label class="expand" for="c-38376175">[1 more]</label></div><br/><div class="children"><div class="content">The had some equity after 2019.<p>Thrive was about to buy employee shares at a $86 bn valuation. The Information said that those units had 12x since 2021.<p><a href="https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;thrive-capital-to-lead-purchase-of-openai-employee-shares-at-80-billion-plus-valuation?rc=e7g9iy" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theinformation.com&#x2F;articles&#x2F;thrive-capital-to-le...</a></div><br/></div></div><div id="38375814" class="c"><input type="checkbox" id="c-38375814" checked=""/><div class="controls bullet"><span class="by">consp</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38376175">prev</a><span>|</span><a href="#38375858">next</a><span>|</span><label class="collapse" for="c-38375814">[-]</label><label class="expand" for="c-38375814">[1 more]</label></div><br/><div class="children"><div class="content">Not having money while everyone becomes filthy rich is also a money motivator.</div><br/></div></div><div id="38375858" class="c"><input type="checkbox" id="c-38375858" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375278">root</a><span>|</span><a href="#38375661">parent</a><span>|</span><a href="#38375814">prev</a><span>|</span><a href="#38375910">next</a><span>|</span><label class="collapse" for="c-38375858">[-]</label><label class="expand" for="c-38375858">[1 more]</label></div><br/><div class="children"><div class="content">They’ll all be filthy rich if they can keep doing this. Altman was already side-hussling to get funding for other AI companies.<p>Same with employees and their stock comp. Same with microsoft.</div><br/></div></div></div></div></div></div></div></div><div id="38375620" class="c"><input type="checkbox" id="c-38375620" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375278">prev</a><span>|</span><a href="#38376778">next</a><span>|</span><label class="collapse" for="c-38375620">[-]</label><label class="expand" for="c-38375620">[20 more]</label></div><br/><div class="children"><div class="content">Larry Summers?  He has no technical experience, torpedoed the stimulus plan in 2008, and had to resign the Harvard presidency following a messy set of statements about ‘differences’ between the sexes and their mental abilities.<p>Kind of a shocking choice.</div><br/><div id="38375664" class="c"><input type="checkbox" id="c-38375664" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38375664">[-]</label><label class="expand" for="c-38375664">[12 more]</label></div><br/><div class="children"><div class="content">&gt; “There is relatively clear evidence that whatever the difference in means—which can be debated—there is a difference in the standard deviation and variability of a male and female population,” he said. Thus, even if the average abilities of men and women were the same, there would be more men than women at the elite levels of mathematical ability<p>Isn’t this true though? Says more about Harvard than Summers to be honest.<p><a href="https:&#x2F;&#x2F;www.swarthmore.edu&#x2F;bulletin&#x2F;archive&#x2F;wp&#x2F;january-2009_what-larry-summers-said-and-didnt-say.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.swarthmore.edu&#x2F;bulletin&#x2F;archive&#x2F;wp&#x2F;january-2009_...</a></div><br/><div id="38375840" class="c"><input type="checkbox" id="c-38375840" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38376071">next</a><span>|</span><label class="collapse" for="c-38375840">[-]</label><label class="expand" for="c-38375840">[3 more]</label></div><br/><div class="children"><div class="content">Shh. Only some truths should be spoken aloud.  You clearly deserve to lose your job if you speak one of the other truths that offends people.</div><br/><div id="38375970" class="c"><input type="checkbox" id="c-38375970" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375840">parent</a><span>|</span><a href="#38376071">next</a><span>|</span><label class="collapse" for="c-38375970">[-]</label><label class="expand" for="c-38375970">[2 more]</label></div><br/><div class="children"><div class="content">One should also be careful to claim that the dominant group is inherently superior.  There are a lot of, uh, counter examples.<p>Calling this a truth is pretty silly.  There is a lot of evidence that human cognition is highly dependent on environment.</div><br/><div id="38376044" class="c"><input type="checkbox" id="c-38376044" checked=""/><div class="controls bullet"><span class="by">jadamson</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375970">parent</a><span>|</span><a href="#38376071">next</a><span>|</span><label class="collapse" for="c-38376044">[-]</label><label class="expand" for="c-38376044">[1 more]</label></div><br/><div class="children"><div class="content">He didn&#x27;t claim they were superior. He said they deviate more from the mean, in both directions.<p>For example, there are a lot more boys than girls who struggle with basic reading comprehension. Sound familiar?</div><br/></div></div></div></div></div></div><div id="38376071" class="c"><input type="checkbox" id="c-38376071" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38375840">prev</a><span>|</span><a href="#38375769">next</a><span>|</span><label class="collapse" for="c-38376071">[-]</label><label class="expand" for="c-38376071">[2 more]</label></div><br/><div class="children"><div class="content">This is the scientific consensus btw.<p>There are also more intellectually challenged men btw, but somehow that rarely gets discussed.<p>But the effects are quite small, and should not dissuade anyone to do anything IMO.</div><br/><div id="38376139" class="c"><input type="checkbox" id="c-38376139" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376071">parent</a><span>|</span><a href="#38375769">next</a><span>|</span><label class="collapse" for="c-38376139">[-]</label><label class="expand" for="c-38376139">[1 more]</label></div><br/><div class="children"><div class="content">The consensus appears to be somewhat less than a consensus.<p>Here is a meta analysis on the subject: <a href="https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC3057475&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC3057475&#x2F;</a></div><br/></div></div></div></div><div id="38375769" class="c"><input type="checkbox" id="c-38375769" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375664">parent</a><span>|</span><a href="#38376071">prev</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38375769">[-]</label><label class="expand" for="c-38375769">[6 more]</label></div><br/><div class="children"><div class="content">A control group is kind of unimaginable right?  And even if you could be sure of this conclusion, is it helpful or beneficial to promote it in public discourse?</div><br/><div id="38375960" class="c"><input type="checkbox" id="c-38375960" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375769">parent</a><span>|</span><a href="#38376174">next</a><span>|</span><label class="collapse" for="c-38375960">[-]</label><label class="expand" for="c-38375960">[2 more]</label></div><br/><div class="children"><div class="content">&gt;And even if you could be sure of this conclusion, is it helpful or beneficial to promote it in public discourse?<p>It&#x27;s absolutely helpful for mental health, to show people that there&#x27;s not some conspiracy out to disenfranchise and oppress them, rather the distribution of outcomes is a natural result of the distribution of genetic characteristics.</div><br/><div id="38376488" class="c"><input type="checkbox" id="c-38376488" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375960">parent</a><span>|</span><a href="#38376174">next</a><span>|</span><label class="collapse" for="c-38376488">[-]</label><label class="expand" for="c-38376488">[1 more]</label></div><br/><div class="children"><div class="content">This is not an accurate description of causation and can&#x27;t be, because there are more steps after &quot;genetics&quot; in the causal chain.<p>It&#x27;s also unimaginative; having a variety of traits is itself good for society, which means you don&#x27;t need variation in genetics to cause it. It&#x27;s adaptive behavior for the same genes to simply lead to random outcomes. But people who say &quot;genes cause X&quot; probably wouldn&#x27;t like this because they want to also say &quot;and some people have the best genes&quot;.</div><br/></div></div></div></div><div id="38376174" class="c"><input type="checkbox" id="c-38376174" checked=""/><div class="controls bullet"><span class="by">TMWNN</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375769">parent</a><span>|</span><a href="#38375960">prev</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38376174">[-]</label><label class="expand" for="c-38376174">[3 more]</label></div><br/><div class="children"><div class="content">Sorry, you don&#x27;t get to decide which thoughts are wrongthink and verboten.</div><br/><div id="38376258" class="c"><input type="checkbox" id="c-38376258" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376174">parent</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38376258">[-]</label><label class="expand" for="c-38376258">[2 more]</label></div><br/><div class="children"><div class="content">I’m not suggesting that I get to decide or whatever, and I am absolutely happy there is reasoned discussion of cognition.<p>I do however expect the boards of directors of important companies to avoid publicly supporting obviously regressive ideas such as this gem.</div><br/><div id="38376704" class="c"><input type="checkbox" id="c-38376704" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376258">parent</a><span>|</span><a href="#38375762">next</a><span>|</span><label class="collapse" for="c-38376704">[-]</label><label class="expand" for="c-38376704">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re happy there is reasoned discussion, but the idea is, in your view, &quot;regressive&quot; whether it&#x27;s true or not?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38375762" class="c"><input type="checkbox" id="c-38375762" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375664">prev</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38375762">[-]</label><label class="expand" for="c-38375762">[2 more]</label></div><br/><div class="children"><div class="content">To be honest, one reason I like Summers as a choice is I have the impression he is willing to be unpopular when necessary, e.g. I remember him getting dragged extremely heavily on Twitter a few years back, for some takes on inflation which turned out to be fairly accurate.</div><br/><div id="38376421" class="c"><input type="checkbox" id="c-38376421" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38375762">parent</a><span>|</span><a href="#38375730">next</a><span>|</span><label class="collapse" for="c-38376421">[-]</label><label class="expand" for="c-38376421">[1 more]</label></div><br/><div class="children"><div class="content">No, his predictions in 2021 were not accurate. He gave 33% chance of three different things happening, and then none of them happened!</div><br/></div></div></div></div><div id="38375730" class="c"><input type="checkbox" id="c-38375730" checked=""/><div class="controls bullet"><span class="by">arduanika</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375762">prev</a><span>|</span><a href="#38376392">next</a><span>|</span><label class="collapse" for="c-38375730">[-]</label><label class="expand" for="c-38375730">[1 more]</label></div><br/><div class="children"><div class="content">The faculty got him out because he riled them, e.g. by insisting they ought to actually put effort into teaching undergrads. They looked for a pretext, and they found it.<p>Just like in that Oppenheimer movie. A sanctimonious witch hunt serving as pretext for a personal vendetta.<p>(Note that Summers is, I&#x27;m told, on a personal level, a dick. The popular depiction is not that wrong on that point. But he&#x27;s the right pick for this job -- see my other comments in this thread.)</div><br/></div></div><div id="38376392" class="c"><input type="checkbox" id="c-38376392" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375730">prev</a><span>|</span><a href="#38375940">next</a><span>|</span><label class="collapse" for="c-38376392">[-]</label><label class="expand" for="c-38376392">[2 more]</label></div><br/><div class="children"><div class="content">If Larry correctly said that men and women are different, i see nothing wrong here.</div><br/><div id="38376689" class="c"><input type="checkbox" id="c-38376689" checked=""/><div class="controls bullet"><span class="by">notfed</span><span>|</span><a href="#38375620">root</a><span>|</span><a href="#38376392">parent</a><span>|</span><a href="#38375940">next</a><span>|</span><label class="collapse" for="c-38376689">[-]</label><label class="expand" for="c-38376689">[1 more]</label></div><br/><div class="children"><div class="content">It looks like he said, specifically:<p>&gt; &quot;...[there] is relatively clear evidence that whatever the difference in means—which can be debated—there is a difference in the standard deviation and variability of a male and female population...&quot;<p>Sheesh, of all the things to be cancelled for...</div><br/></div></div></div></div><div id="38375940" class="c"><input type="checkbox" id="c-38375940" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38376392">prev</a><span>|</span><a href="#38375917">next</a><span>|</span><label class="collapse" for="c-38375940">[-]</label><label class="expand" for="c-38375940">[1 more]</label></div><br/><div class="children"><div class="content">Could have been worse, they could have picked Larry David, would fit the clown-show of the past weekend.</div><br/></div></div><div id="38375917" class="c"><input type="checkbox" id="c-38375917" checked=""/><div class="controls bullet"><span class="by">the-memory-hole</span><span>|</span><a href="#38375620">parent</a><span>|</span><a href="#38375940">prev</a><span>|</span><a href="#38376778">next</a><span>|</span><label class="collapse" for="c-38375917">[-]</label><label class="expand" for="c-38375917">[1 more]</label></div><br/><div class="children"><div class="content">a huge player in preventing derivatives regulation leading up to 2008 now helps steer the ship of AI oversight. I&#x27;m speechless.</div><br/></div></div></div></div><div id="38376778" class="c"><input type="checkbox" id="c-38376778" checked=""/><div class="controls bullet"><span class="by">personalityson</span><span>|</span><a href="#38375620">prev</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38376778">[-]</label><label class="expand" for="c-38376778">[2 more]</label></div><br/><div class="children"><div class="content">Why is Altman, who has no higher education, critical for development of AI?</div><br/><div id="38376798" class="c"><input type="checkbox" id="c-38376798" checked=""/><div class="controls bullet"><span class="by">calmoo</span><span>|</span><a href="#38376778">parent</a><span>|</span><a href="#38375308">next</a><span>|</span><label class="collapse" for="c-38376798">[-]</label><label class="expand" for="c-38376798">[1 more]</label></div><br/><div class="children"><div class="content">Is higher education really crucial for pushing something forward? Even if he isn&#x27;t an AI expert, there is lots of stuff surrounding the technology that needs doing, for example massive amounts of funding, which he seems to have been pretty good at securing.</div><br/></div></div></div></div><div id="38375308" class="c"><input type="checkbox" id="c-38375308" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38376778">prev</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38375308">[-]</label><label class="expand" for="c-38375308">[69 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; We have reached an agreement in principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry Summers, and Adam D&#x27;Angelo.

    &gt; We are collaborating to figure out the details. Thank you so much for your patience through this.
</code></pre>
1- So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>2- Now what happens to Microsoft&#x27;s role in all of this?<p>3- Twitter is still the best place to follow this and get updates, everyone is still make &quot;official&quot; statements on twitter, not sure how long this website will last but until then, this is the only portal for me to get news.</div><br/><div id="38375424" class="c"><input type="checkbox" id="c-38375424" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38375424">[-]</label><label class="expand" for="c-38375424">[9 more]</label></div><br/><div class="children"><div class="content">&gt; So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>Altman was trying to remove one of the board members before he was forced out. Looks like he got his way in the end, but I&#x27;m going to call Altman the primary instigator because of that.<p>His side was also the &quot;we&#x27;ll nuke the company unless you resign&quot; side.</div><br/><div id="38375585" class="c"><input type="checkbox" id="c-38375585" checked=""/><div class="controls bullet"><span class="by">theamk</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375424">parent</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38375585">[-]</label><label class="expand" for="c-38375585">[8 more]</label></div><br/><div class="children"><div class="content">His side was also &quot;700 regular employees support this&quot;, which is pretty unusual as most people don&#x27;t care about their CEO at all. I am not related to OpenAI at all, but given the choice of &quot;favorite of all employees&quot; vs &quot;fire people with no warning then refuse to give explanation why even under pressure&quot; I know which side I root for.</div><br/><div id="38375921" class="c"><input type="checkbox" id="c-38375921" checked=""/><div class="controls bullet"><span class="by">ravst3s</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375946">next</a><span>|</span><label class="collapse" for="c-38375921">[-]</label><label class="expand" for="c-38375921">[1 more]</label></div><br/><div class="children"><div class="content">Looking back, Altman&#x27;s ace in hand was the tender offer from Thrive. Idk anyone at OpenAI, but all the early senior personnel backed him with vehemence. If the leaders hand&#x27;t championed him strongly, I doubt you get 90% of the company to commit to leaving.<p>I&#x27;m sure some of those employees were easily going to make $10m+ in the sale. That&#x27;s a pretty great motivation tool.<p>Overall, I do agree with you. The board could not justify their capricious decision making and refused to elaborate. They should&#x27;ve brought him back on Sunday instead of mucking around. OpenAI existing is a good thing.</div><br/></div></div><div id="38375946" class="c"><input type="checkbox" id="c-38375946" checked=""/><div class="controls bullet"><span class="by">gnaman</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375921">prev</a><span>|</span><a href="#38375891">next</a><span>|</span><label class="collapse" for="c-38375946">[-]</label><label class="expand" for="c-38375946">[3 more]</label></div><br/><div class="children"><div class="content">Take this with a grain of salt but employees were under a lot of peer pressure<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;JacquesThibs&#x2F;status&#x2F;1727134087176204410" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;JacquesThibs&#x2F;status&#x2F;1727134087176204410</a></div><br/><div id="38376006" class="c"><input type="checkbox" id="c-38376006" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375946">parent</a><span>|</span><a href="#38376037">next</a><span>|</span><label class="collapse" for="c-38376006">[-]</label><label class="expand" for="c-38376006">[1 more]</label></div><br/><div class="children"><div class="content">That is one HUGE grain of salt considering 1&#x2F; it&#x27;s Blind 2&#x2F; Even in the same thread there is another poster saying the exact opposite thing (i.e. no peer pressure)</div><br/></div></div><div id="38376037" class="c"><input type="checkbox" id="c-38376037" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375946">parent</a><span>|</span><a href="#38376006">prev</a><span>|</span><a href="#38375891">next</a><span>|</span><label class="collapse" for="c-38376037">[-]</label><label class="expand" for="c-38376037">[1 more]</label></div><br/><div class="children"><div class="content">Yeah 95% of employees is a bit too high ...<p>Also, all the stuff they started doing with the hearts and cryptic messages on Twitter (now X) was a bit ... cult-y?. I wouldn&#x27;t doubt there was a lot of manipulation behind all that, even from @sama itself.<p>So, there is goes, it seems that there&#x27;s a big chance now that the first AGI will land on the hands of a group with the antics of teenagers. Interesting timeline.</div><br/></div></div></div></div><div id="38375891" class="c"><input type="checkbox" id="c-38375891" checked=""/><div class="controls bullet"><span class="by">xiwenc</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375946">prev</a><span>|</span><a href="#38375876">next</a><span>|</span><label class="collapse" for="c-38375891">[-]</label><label class="expand" for="c-38375891">[2 more]</label></div><br/><div class="children"><div class="content">No idea what these 700 employees were thinking. They probably had little knowledge of what truly went down other than “my CEO was fired unfairly” and rushed to the rescue.<p>I think the board should have been more transparent on why they made the decision to fire Sam.<p>Or perhaps these employees only cared about their AI work and money? The foundation would be perceived as the culprit against them.<p>Really sad there’s no clarity from the old board disclosed. Hope one day we will know.</div><br/><div id="38375934" class="c"><input type="checkbox" id="c-38375934" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375891">parent</a><span>|</span><a href="#38375876">next</a><span>|</span><label class="collapse" for="c-38375934">[-]</label><label class="expand" for="c-38375934">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how much more transparent they can really be. I know that when firing a &quot;regular&quot; employee, you basically never tell everyone all the details for legal CYA reasons. When your firing someone worth half a billion dollars, I expect the legal fears are magnified.</div><br/></div></div></div></div><div id="38375876" class="c"><input type="checkbox" id="c-38375876" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375585">parent</a><span>|</span><a href="#38375891">prev</a><span>|</span><a href="#38375363">next</a><span>|</span><label class="collapse" for="c-38375876">[-]</label><label class="expand" for="c-38375876">[1 more]</label></div><br/><div class="children"><div class="content">The 700 employees also have significant financial incentive to want Altman to stay. If he moved to a competitor all the shine would follow. They want the pay-day (I don&#x27;t blame them), but take with a grain of salt what the employees want in this case.</div><br/></div></div></div></div></div></div><div id="38375363" class="c"><input type="checkbox" id="c-38375363" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375424">prev</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375363">[-]</label><label class="expand" for="c-38375363">[11 more]</label></div><br/><div class="children"><div class="content">Microsoft&#x27;s role remains same as it was on Thursday. Minor (49%?) shareholder and keeps access to models and IP<p>IMO Kevin tweeting that MS will hire and match comp of all OpenAI employees was amazing negotiation tactic because that meant employees could sign the petition without worrying about their jobs&#x2F;visas</div><br/><div id="38375514" class="c"><input type="checkbox" id="c-38375514" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38376289">next</a><span>|</span><label class="collapse" for="c-38375514">[-]</label><label class="expand" for="c-38375514">[2 more]</label></div><br/><div class="children"><div class="content">I think at this point MSFT will seek a board seat in OpenAI&#x2F;</div><br/><div id="38375936" class="c"><input type="checkbox" id="c-38375936" checked=""/><div class="controls bullet"><span class="by">zeven7</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375514">parent</a><span>|</span><a href="#38376289">next</a><span>|</span><label class="collapse" for="c-38375936">[-]</label><label class="expand" for="c-38375936">[1 more]</label></div><br/><div class="children"><div class="content">Satya Nadella said they would make sure there would be &quot;no more surprises&quot;.<p>(Sad day for popcorn sales.)</div><br/></div></div></div></div><div id="38376289" class="c"><input type="checkbox" id="c-38376289" checked=""/><div class="controls bullet"><span class="by">ugh123</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38375514">prev</a><span>|</span><a href="#38375455">next</a><span>|</span><label class="collapse" for="c-38376289">[-]</label><label class="expand" for="c-38376289">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking about this a lot as well, but what did that mean for employee stock in the commercial entity? I heard they were up for a liquid cash-out in the next funding round.</div><br/></div></div><div id="38375455" class="c"><input type="checkbox" id="c-38375455" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375363">parent</a><span>|</span><a href="#38376289">prev</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375455">[-]</label><label class="expand" for="c-38375455">[7 more]</label></div><br/><div class="children"><div class="content">but no board seat? how do they prevent a rehash of this in the future and how do they safeguard their investment? Really curious.</div><br/><div id="38375504" class="c"><input type="checkbox" id="c-38375504" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38376029">next</a><span>|</span><label class="collapse" for="c-38375504">[-]</label><label class="expand" for="c-38375504">[4 more]</label></div><br/><div class="children"><div class="content">OpenAI is an airgapped test lab for Microsoft. They dont want critical exposure to the downside risk of AI research, just the benefits in terms of IP. Sam and Greg probably offer enough stability for them to continue this way.</div><br/><div id="38375825" class="c"><input type="checkbox" id="c-38375825" checked=""/><div class="controls bullet"><span class="by">happosai</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375504">parent</a><span>|</span><a href="#38375672">next</a><span>|</span><label class="collapse" for="c-38375825">[-]</label><label class="expand" for="c-38375825">[2 more]</label></div><br/><div class="children"><div class="content">It makes sense to airgap Generative AI while courts ponder wether copyright fair use applies or not. Research is clearly allowed fair use, and let OpenAI experiment with commercialization until it is all clear waters.</div><br/><div id="38376242" class="c"><input type="checkbox" id="c-38376242" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375825">parent</a><span>|</span><a href="#38375672">next</a><span>|</span><label class="collapse" for="c-38376242">[-]</label><label class="expand" for="c-38376242">[1 more]</label></div><br/><div class="children"><div class="content">No anti-AI lawsuits have progressed yet. One got slapped down pretty hard today, though isn&#x27;t dead.<p><a href="https:&#x2F;&#x2F;www.hollywoodreporter.com&#x2F;business&#x2F;business-news&#x2F;sarah-silverman-lawsuit-ai-meta-1235669403&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hollywoodreporter.com&#x2F;business&#x2F;business-news&#x2F;sar...</a></div><br/></div></div></div></div><div id="38375672" class="c"><input type="checkbox" id="c-38375672" checked=""/><div class="controls bullet"><span class="by">_jab</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375504">parent</a><span>|</span><a href="#38375825">prev</a><span>|</span><a href="#38376029">next</a><span>|</span><label class="collapse" for="c-38375672">[-]</label><label class="expand" for="c-38375672">[1 more]</label></div><br/><div class="children"><div class="content">Sam and Greg don&#x27;t appear to be getting their board seats back.</div><br/></div></div></div></div><div id="38376029" class="c"><input type="checkbox" id="c-38376029" checked=""/><div class="controls bullet"><span class="by">umeshunni</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38375504">prev</a><span>|</span><a href="#38375972">next</a><span>|</span><label class="collapse" for="c-38376029">[-]</label><label class="expand" for="c-38376029">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a new and &quot;more experienced&quot; board.  This is also possibly the first of additional governance and structure changes.</div><br/></div></div><div id="38375972" class="c"><input type="checkbox" id="c-38375972" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375455">parent</a><span>|</span><a href="#38376029">prev</a><span>|</span><a href="#38375977">next</a><span>|</span><label class="collapse" for="c-38375972">[-]</label><label class="expand" for="c-38375972">[1 more]</label></div><br/><div class="children"><div class="content">I believe all the board seats are not fillet yet</div><br/></div></div></div></div></div></div><div id="38375977" class="c"><input type="checkbox" id="c-38375977" checked=""/><div class="controls bullet"><span class="by">kumarvvr</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375363">prev</a><span>|</span><a href="#38375353">next</a><span>|</span><label class="collapse" for="c-38375977">[-]</label><label class="expand" for="c-38375977">[3 more]</label></div><br/><div class="children"><div class="content">Satya comes out great, making the absolute best of a given shitty situation, with a high stake of 10 B USD.<p>Microsoft is showing to investors that it is going to be an AI company, one way or the other.<p>Microsoft still has access to everything OpenAI does.<p>Microsoft has its friend, Sam, at the helm of OpenAI and with a more tighter grip on the company than ever.<p>Its still a win for Microsoft.</div><br/><div id="38376310" class="c"><input type="checkbox" id="c-38376310" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375977">parent</a><span>|</span><a href="#38376244">next</a><span>|</span><label class="collapse" for="c-38376310">[-]</label><label class="expand" for="c-38376310">[1 more]</label></div><br/><div class="children"><div class="content">Satya just played the hand he had.  The hand he had was excellent, he had already won. MS already had perceptual license, people working on GPT and Sam Altman on his corner.<p>The one thing in Microsoft has stayed constant from Gates to  Ballmer to Satya: you should never, ever form a close alliance with MS. They know how to screw alliance partners. i4i, Windows RT partners, Windows Phone Partners, Nokia, HW partners in Surface. Even Steve Jobs was burned few times.</div><br/></div></div><div id="38376244" class="c"><input type="checkbox" id="c-38376244" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375977">parent</a><span>|</span><a href="#38376310">prev</a><span>|</span><a href="#38375353">next</a><span>|</span><label class="collapse" for="c-38376244">[-]</label><label class="expand" for="c-38376244">[1 more]</label></div><br/><div class="children"><div class="content">Satya comes out as evil imho, and I wonder how much orchestration there was going on behind the scenes.<p>Microsoft is showing that it is still able to capture important scale ups and &#x27;embrace&#x27; them, whilst also acting as if they have the moral high ground, but in reality are doing research with a high governance errors and potential legal problems away from their premises. and THAT is why stakeholders like him.</div><br/></div></div></div></div><div id="38375353" class="c"><input type="checkbox" id="c-38375353" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375977">prev</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375353">[-]</label><label class="expand" for="c-38375353">[11 more]</label></div><br/><div class="children"><div class="content">Microsoft said they are OK with Sam returning to openAI. There are probbaly legal reasons why they prefer things to go back as it were<p>(Thank you for calling Twitter Twitter)</div><br/><div id="38375421" class="c"><input type="checkbox" id="c-38375421" checked=""/><div class="controls bullet"><span class="by">AmericanOP</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375353">parent</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375421">[-]</label><label class="expand" for="c-38375421">[10 more]</label></div><br/><div class="children"><div class="content">The website is twitter.com. Why call it something else?</div><br/><div id="38375484" class="c"><input type="checkbox" id="c-38375484" checked=""/><div class="controls bullet"><span class="by">alex_young</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375421">parent</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375484">[-]</label><label class="expand" for="c-38375484">[5 more]</label></div><br/><div class="children"><div class="content">Also, x.com redirects to Twitter.com.   Seems like they want us to say Twitter.</div><br/><div id="38375601" class="c"><input type="checkbox" id="c-38375601" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375484">parent</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375601">[-]</label><label class="expand" for="c-38375601">[4 more]</label></div><br/><div class="children"><div class="content">saying “to tweet” is definitely better than saying “to xeet”</div><br/><div id="38375850" class="c"><input type="checkbox" id="c-38375850" checked=""/><div class="controls bullet"><span class="by">asimovfan</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375601">parent</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375850">[-]</label><label class="expand" for="c-38375850">[3 more]</label></div><br/><div class="children"><div class="content">Xeet is super funny, hopefully takes over.</div><br/><div id="38376220" class="c"><input type="checkbox" id="c-38376220" checked=""/><div class="controls bullet"><span class="by">grumpyprole</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375850">parent</a><span>|</span><a href="#38375866">next</a><span>|</span><label class="collapse" for="c-38376220">[-]</label><label class="expand" for="c-38376220">[1 more]</label></div><br/><div class="children"><div class="content">Or xcreet?</div><br/></div></div><div id="38375866" class="c"><input type="checkbox" id="c-38375866" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375850">parent</a><span>|</span><a href="#38376220">prev</a><span>|</span><a href="#38375513">next</a><span>|</span><label class="collapse" for="c-38375866">[-]</label><label class="expand" for="c-38375866">[1 more]</label></div><br/><div class="children"><div class="content">share it on Xitter</div><br/></div></div></div></div></div></div></div></div><div id="38375513" class="c"><input type="checkbox" id="c-38375513" checked=""/><div class="controls bullet"><span class="by">labster</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375421">parent</a><span>|</span><a href="#38375484">prev</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375513">[-]</label><label class="expand" for="c-38375513">[4 more]</label></div><br/><div class="children"><div class="content">Exactly right, fellow YCombinator News commenter!</div><br/><div id="38375594" class="c"><input type="checkbox" id="c-38375594" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375513">parent</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375594">[-]</label><label class="expand" for="c-38375594">[3 more]</label></div><br/><div class="children"><div class="content">I believe you mean <i>Startup News</i></div><br/><div id="38375660" class="c"><input type="checkbox" id="c-38375660" checked=""/><div class="controls bullet"><span class="by">tech234a</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375594">parent</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38375660">[-]</label><label class="expand" for="c-38375660">[2 more]</label></div><br/><div class="children"><div class="content">For reference: <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070713212949&#x2F;http:&#x2F;&#x2F;news.ycombinator.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070713212949&#x2F;http:&#x2F;&#x2F;news.ycomb...</a></div><br/><div id="38376075" class="c"><input type="checkbox" id="c-38376075" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375660">parent</a><span>|</span><a href="#38375939">next</a><span>|</span><label class="collapse" for="c-38376075">[-]</label><label class="expand" for="c-38376075">[1 more]</label></div><br/><div class="children"><div class="content">From 2nd story on the archive<p>&gt;It is just a joke that Facebook could be valued at $6 billion.<p>lol, seems HN is same since forever.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38375939" class="c"><input type="checkbox" id="c-38375939" checked=""/><div class="controls bullet"><span class="by">happosai</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375353">prev</a><span>|</span><a href="#38376089">next</a><span>|</span><label class="collapse" for="c-38375939">[-]</label><label class="expand" for="c-38375939">[2 more]</label></div><br/><div class="children"><div class="content">About 3)<p>What is the benefit of learning about this kind of drama minute-by-minute, compared to reading it a few hours later on hacker news or next day on wall street journal?<p>Personally I found twitter very bad for my productivity, a lot of focus destroyed just to know &quot;what is happening&quot; when there was neglible drawbacks of finding about news events a few hours later.</div><br/><div id="38376078" class="c"><input type="checkbox" id="c-38376078" checked=""/><div class="controls bullet"><span class="by">willdr</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375939">parent</a><span>|</span><a href="#38376089">next</a><span>|</span><label class="collapse" for="c-38376078">[-]</label><label class="expand" for="c-38376078">[1 more]</label></div><br/><div class="children"><div class="content">I have muted any mention of Open AI, Altman, Emmet and Satya from my Twitter feed for the past five days. It&#x27;s a far better experience.</div><br/></div></div></div></div><div id="38376089" class="c"><input type="checkbox" id="c-38376089" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375939">prev</a><span>|</span><a href="#38376020">next</a><span>|</span><label class="collapse" for="c-38376089">[-]</label><label class="expand" for="c-38376089">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Twitter is still the best place to follow this and get updates</i><p>This has been my single strongest takeaway from this saga: Twitter remains the centre of controversy. When shit hit the fan, Sam and Satya and Swisher took to Twitter. Not Threads. Not Bluesy. Twitter. (X.)</div><br/></div></div><div id="38376020" class="c"><input type="checkbox" id="c-38376020" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376089">prev</a><span>|</span><a href="#38376059">next</a><span>|</span><label class="collapse" for="c-38376020">[-]</label><label class="expand" for="c-38376020">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So what was the point of this whole drama, and why couldn&#x27;t you have settled like this adults?<p>Whole charade was by GPT5 to understand the position of person sitting next to red button and secondary to stress test Hacker News.</div><br/></div></div><div id="38376059" class="c"><input type="checkbox" id="c-38376059" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376020">prev</a><span>|</span><a href="#38375429">next</a><span>|</span><label class="collapse" for="c-38376059">[-]</label><label class="expand" for="c-38376059">[2 more]</label></div><br/><div class="children"><div class="content">Larry Summers? like the Larry Summers?</div><br/><div id="38376246" class="c"><input type="checkbox" id="c-38376246" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38376059">parent</a><span>|</span><a href="#38375429">next</a><span>|</span><label class="collapse" for="c-38376246">[-]</label><label class="expand" for="c-38376246">[1 more]</label></div><br/><div class="children"><div class="content">yeah, the guy has a knack for being in&#x2F;invited to places.</div><br/></div></div></div></div><div id="38375429" class="c"><input type="checkbox" id="c-38375429" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376059">prev</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375429">[-]</label><label class="expand" for="c-38375429">[11 more]</label></div><br/><div class="children"><div class="content">The explanation for point 1 is point 3. If the people involved were not terminally online and felt the need to share every single one of their immediate thoughts with the public they could have likely settled this behind closed doors, where this kind of stuff belongs.<p>It&#x27;s not actually news, it&#x27;s entertainment and self-aggrandizement by everyone involved including the audience.</div><br/><div id="38375470" class="c"><input type="checkbox" id="c-38375470" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375429">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375470">[-]</label><label class="expand" for="c-38375470">[10 more]</label></div><br/><div class="children"><div class="content">Interesting that the board were repeatedly criticized for &quot;not being adults&quot;, and yet they were also the only party not live-tweeting everything...<p>Seems like there&#x27;s no way to win with Twitter.  You may not be interested in Twitter, but Twitter is interested in you.</div><br/><div id="38376169" class="c"><input type="checkbox" id="c-38376169" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375895">next</a><span>|</span><label class="collapse" for="c-38376169">[-]</label><label class="expand" for="c-38376169">[1 more]</label></div><br/><div class="children"><div class="content">Considering CEO2 rebelled next day and CEO3 allegedly said he&#x27;ll quit unless board comes out with truth, doesn&#x27;t provide much confidence in their adulthood.</div><br/></div></div><div id="38375895" class="c"><input type="checkbox" id="c-38375895" checked=""/><div class="controls bullet"><span class="by">imgabe</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38376169">prev</a><span>|</span><a href="#38375610">next</a><span>|</span><label class="collapse" for="c-38375895">[-]</label><label class="expand" for="c-38375895">[1 more]</label></div><br/><div class="children"><div class="content">The board not saying what the hell they were on about was the source of the whole drama in the first place. If they had just said exactly what their problem was up front there wouldn&#x27;t have been as much to tweet about.</div><br/></div></div><div id="38375610" class="c"><input type="checkbox" id="c-38375610" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375895">prev</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375610">[-]</label><label class="expand" for="c-38375610">[4 more]</label></div><br/><div class="children"><div class="content">the board didn’t have to tweet. their ridiculous actions spoke for itself.</div><br/><div id="38375735" class="c"><input type="checkbox" id="c-38375735" checked=""/><div class="controls bullet"><span class="by">angryasian</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375610">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375735">[-]</label><label class="expand" for="c-38375735">[3 more]</label></div><br/><div class="children"><div class="content">we still don&#x27;t know what Altman has actually been hiding, so to say it was ridiculous ... is ridiculous itself.</div><br/><div id="38375801" class="c"><input type="checkbox" id="c-38375801" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375735">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375801">[-]</label><label class="expand" for="c-38375801">[2 more]</label></div><br/><div class="children"><div class="content">the board’s actions were ridiculous regardless of Sam’s. sell oai to anthropic? were they out of their minds?</div><br/><div id="38375967" class="c"><input type="checkbox" id="c-38375967" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375801">parent</a><span>|</span><a href="#38375633">next</a><span>|</span><label class="collapse" for="c-38375967">[-]</label><label class="expand" for="c-38375967">[1 more]</label></div><br/><div class="children"><div class="content">From the perspective of upholding the charter <a href="https:&#x2F;&#x2F;openai.com&#x2F;charter" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;charter</a> and preventing an AI race -- seems potentially sensible</div><br/></div></div></div></div></div></div></div></div><div id="38375633" class="c"><input type="checkbox" id="c-38375633" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375470">parent</a><span>|</span><a href="#38375610">prev</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375633">[-]</label><label class="expand" for="c-38375633">[3 more]</label></div><br/><div class="children"><div class="content">They didn’t tweet, but did they communicate in any other way?!</div><br/><div id="38375785" class="c"><input type="checkbox" id="c-38375785" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375633">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38375785">[-]</label><label class="expand" for="c-38375785">[2 more]</label></div><br/><div class="children"><div class="content">Well, there was the initial announcement.</div><br/><div id="38376187" class="c"><input type="checkbox" id="c-38376187" checked=""/><div class="controls bullet"><span class="by">nickpp</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375785">parent</a><span>|</span><a href="#38376280">next</a><span>|</span><label class="collapse" for="c-38376187">[-]</label><label class="expand" for="c-38376187">[1 more]</label></div><br/><div class="children"><div class="content">To say that communication was lacking is an understatement. Clarifications were missing and sorely needed.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38376280" class="c"><input type="checkbox" id="c-38376280" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375429">prev</a><span>|</span><a href="#38375507">next</a><span>|</span><label class="collapse" for="c-38376280">[-]</label><label class="expand" for="c-38376280">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 2- Now what happens to Microsoft&#x27;s role in all of this?<p>This outcome WAS microsoft&#x27;s role in all this. Satya offering sam a ceo like position to create a competing product was leverage for this outcome.</div><br/></div></div><div id="38375507" class="c"><input type="checkbox" id="c-38375507" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38376280">prev</a><span>|</span><a href="#38375347">next</a><span>|</span><label class="collapse" for="c-38375507">[-]</label><label class="expand" for="c-38375507">[5 more]</label></div><br/><div class="children"><div class="content">If there’s been one constant here, it’s been people who actually know Tonrer expressing deep support for her experience, intelligence, and ethics, so it’s interesting to me that she seems to be getting the boot.</div><br/><div id="38376325" class="c"><input type="checkbox" id="c-38376325" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38375603">next</a><span>|</span><label class="collapse" for="c-38376325">[-]</label><label class="expand" for="c-38376325">[1 more]</label></div><br/><div class="children"><div class="content">If there is one clear thing, it&#x27;s that no one on that board should be allowed anywhere near another board for any non-clown company. The level of incompetence in how they handled this whole thing was extraordinary.<p>The fact that Adam D&#x27;Angelo is still on the new board apparently is much more baffling than the fact that Tonrer or Ilya are not.</div><br/></div></div><div id="38375603" class="c"><input type="checkbox" id="c-38375603" checked=""/><div class="controls bullet"><span class="by">causalmodels</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38376325">prev</a><span>|</span><a href="#38375777">next</a><span>|</span><label class="collapse" for="c-38375603">[-]</label><label class="expand" for="c-38375603">[1 more]</label></div><br/><div class="children"><div class="content">Fiascos like this display neither experience nor intelligence. This whole saga was a colossal failure on the part of the previous board.</div><br/></div></div><div id="38375777" class="c"><input type="checkbox" id="c-38375777" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375507">parent</a><span>|</span><a href="#38375603">prev</a><span>|</span><a href="#38375347">next</a><span>|</span><label class="collapse" for="c-38375777">[-]</label><label class="expand" for="c-38375777">[2 more]</label></div><br/><div class="children"><div class="content">Add delusions of grandeur to that list thinking she can pursue her ideological will by winning over 3 board members while losing 90% of the company staff.<p>She was fighting an idelogical battle that needs full industry buy in, legitimate or not that&#x27;s not how you win people over.<p>If she&#x27;s truely a rationalist as she claims then a rationalist would be realistic understanding that if your engineers can just leave and do it somewhere else tomorrow you aren&#x27;t making progress. Taking on the full might of US capitalism via winning over the fringe half of a non profit board is not the best strategy. At best it was desperate and naive.</div><br/><div id="38376267" class="c"><input type="checkbox" id="c-38376267" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375777">parent</a><span>|</span><a href="#38375347">next</a><span>|</span><label class="collapse" for="c-38376267">[-]</label><label class="expand" for="c-38376267">[1 more]</label></div><br/><div class="children"><div class="content">This is pretty good evidence she&#x27;s a rationalist; rationalism means a religious devotion to a specific kind of logical thinking that never works in real life because you can&#x27;t calculate the probability a result if you didn&#x27;t know it could happen in the first place.<p>Traditional response to this happening is to say something about your &quot;priors&quot; being wrong instead of taking responsibility.</div><br/></div></div></div></div></div></div><div id="38375347" class="c"><input type="checkbox" id="c-38375347" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#38375308">parent</a><span>|</span><a href="#38375507">prev</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38375347">[-]</label><label class="expand" for="c-38375347">[11 more]</label></div><br/><div class="children"><div class="content">&gt; Twitter is still the best place to follow this and get updates, everyone is still make &quot;official&quot; statements on twitter, not sure how long this website will last but until then, this is the only portal for me to get news.<p>It&#x27;s only natural to confuse what is happening with what we wish to happen. After all, when we imagine something, aren&#x27;t we undergoing a kind of experience?<p>A lot of people wish Twitter were dying, even though it&#x27;s it, so they interpret evidence through a lens of belief confirmation rather than belief disproof. It&#x27;s only human to do this. We all do.</div><br/><div id="38375446" class="c"><input type="checkbox" id="c-38375446" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375347">parent</a><span>|</span><a href="#38375375">next</a><span>|</span><label class="collapse" for="c-38375446">[-]</label><label class="expand" for="c-38375446">[8 more]</label></div><br/><div class="children"><div class="content">It was funny reading Kara Swisher keeping saying twitter is dying and is toxic and what not, while STILL doing all her first announcements on twitter, and using twitter as a source.<p>same with Ashlee Vance (the other journo reporting on this) and all the main players (Sam&#x2F;Greg&#x2F;Ilya&#x2F;Mira&#x2F;Satya&#x2F;whoever) also make their first announcement on twitter.<p>I don&#x27;t know about the funding part of it, but there is no denying it, the news is still freshest on twitter. Twitter feels just as toxic for me as before, in fact I feel community notes has made it much better, imho.<p>____<p>In some related news, I finally got bluesky invite (I don&#x27;t have invite codes yet or I would share here)<p>and people there are complaining about... mastadon and how elitist it is...<p>that was an eye opener.<p>nice if you want some science-y updates but it&#x27;s still lags behind twitter for news.</div><br/><div id="38375505" class="c"><input type="checkbox" id="c-38375505" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375505">[-]</label><label class="expand" for="c-38375505">[4 more]</label></div><br/><div class="children"><div class="content">I don’t use Twitter any more, other than occasionally following links there (which open in the browser, because I deleted the app).<p>Discoverability on Mastodon is abysmal. It was too much work for me.<p>I tend to get my news from Substack now.</div><br/><div id="38375542" class="c"><input type="checkbox" id="c-38375542" checked=""/><div class="controls bullet"><span class="by">ryzvonusef</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375505">parent</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375542">[-]</label><label class="expand" for="c-38375542">[3 more]</label></div><br/><div class="children"><div class="content">interesting, substack doesn&#x27;t sound like a platform for the freshest news, but for deep insights.<p>Don&#x27;t you feel out of date on substack? especially since things move so fast sometimes, like with this open-ai fiasco?</div><br/><div id="38376039" class="c"><input type="checkbox" id="c-38376039" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375542">parent</a><span>|</span><a href="#38375797">next</a><span>|</span><label class="collapse" for="c-38376039">[-]</label><label class="expand" for="c-38376039">[1 more]</label></div><br/><div class="children"><div class="content">Did being up to date really have an impact on your life? It&#x27;s mostly just gossip.</div><br/></div></div><div id="38375797" class="c"><input type="checkbox" id="c-38375797" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375542">parent</a><span>|</span><a href="#38376039">prev</a><span>|</span><a href="#38375724">next</a><span>|</span><label class="collapse" for="c-38375797">[-]</label><label class="expand" for="c-38375797">[1 more]</label></div><br/><div class="children"><div class="content">Twitter is incredibly uncivil. I don’t have the stomach for it.</div><br/></div></div></div></div></div></div><div id="38375724" class="c"><input type="checkbox" id="c-38375724" checked=""/><div class="controls bullet"><span class="by">hurryer</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375505">prev</a><span>|</span><a href="#38375929">next</a><span>|</span><label class="collapse" for="c-38375724">[-]</label><label class="expand" for="c-38375724">[1 more]</label></div><br/><div class="children"><div class="content">Skilled operators say what sounds most virtuous and do what benefits most. Especially when these two things are not the same.</div><br/></div></div><div id="38375929" class="c"><input type="checkbox" id="c-38375929" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375724">prev</a><span>|</span><a href="#38375999">next</a><span>|</span><label class="collapse" for="c-38375929">[-]</label><label class="expand" for="c-38375929">[1 more]</label></div><br/><div class="children"><div class="content">Twitter isn&#x27;t dying, but it hasn&#x27;t grown measurably since 2015. Still sitting at about 300m active users.</div><br/></div></div><div id="38375999" class="c"><input type="checkbox" id="c-38375999" checked=""/><div class="controls bullet"><span class="by">bagels</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375446">parent</a><span>|</span><a href="#38375929">prev</a><span>|</span><a href="#38375375">next</a><span>|</span><label class="collapse" for="c-38375999">[-]</label><label class="expand" for="c-38375999">[1 more]</label></div><br/><div class="children"><div class="content">Bluesky took long enough to invite me that I forgot what it even was when I got the email.</div><br/></div></div></div></div><div id="38375375" class="c"><input type="checkbox" id="c-38375375" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375347">parent</a><span>|</span><a href="#38375446">prev</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38375375">[-]</label><label class="expand" for="c-38375375">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of people wish Twitter were dying, even though it&#x27;s it, so they interpret evidence through a lens of belief confirmation rather than belief disproof.<p>Cognitive dissonance</div><br/><div id="38375788" class="c"><input type="checkbox" id="c-38375788" checked=""/><div class="controls bullet"><span class="by">veec_cas_tant</span><span>|</span><a href="#38375308">root</a><span>|</span><a href="#38375375">parent</a><span>|</span><a href="#38375426">next</a><span>|</span><label class="collapse" for="c-38375788">[-]</label><label class="expand" for="c-38375788">[1 more]</label></div><br/><div class="children"><div class="content">Or they read about the large cuts to Twitter’s valuation from banks and X itself?</div><br/></div></div></div></div></div></div></div></div><div id="38375426" class="c"><input type="checkbox" id="c-38375426" checked=""/><div class="controls bullet"><span class="by">meetpateltech</span><span>|</span><a href="#38375308">prev</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38375426">[-]</label><label class="expand" for="c-38375426">[12 more]</label></div><br/><div class="children"><div class="content">Emmett Shear on Twitter:<p>I am deeply pleased by this result, after ~72 very intense hours of work. Coming into OpenAI, I wasn’t sure what the right path would be. This was the pathway that maximized safety alongside doing right by all stakeholders involved. I’m glad to have been a part of the solution.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1727210329560756598</a></div><br/><div id="38376791" class="c"><input type="checkbox" id="c-38376791" checked=""/><div class="controls bullet"><span class="by">upupupandaway</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38375536">next</a><span>|</span><label class="collapse" for="c-38376791">[-]</label><label class="expand" for="c-38376791">[1 more]</label></div><br/><div class="children"><div class="content">He’s trying very very hard to claim some credit in this. Probably had none.</div><br/></div></div><div id="38375536" class="c"><input type="checkbox" id="c-38375536" checked=""/><div class="controls bullet"><span class="by">reustle</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38376791">prev</a><span>|</span><a href="#38375562">next</a><span>|</span><label class="collapse" for="c-38375536">[-]</label><label class="expand" for="c-38375536">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m probably reading too much into it, but interesting that he specifically called out maximizing safety.</div><br/><div id="38375636" class="c"><input type="checkbox" id="c-38375636" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375736">next</a><span>|</span><label class="collapse" for="c-38375636">[-]</label><label class="expand" for="c-38375636">[1 more]</label></div><br/><div class="children"><div class="content">Sam does believe in safety. He also knows that there is a first-mover advantage when it comes to setting societal expectations and that you can’t build safe AI by not building AI.</div><br/></div></div><div id="38375736" class="c"><input type="checkbox" id="c-38375736" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375636">prev</a><span>|</span><a href="#38375853">next</a><span>|</span><label class="collapse" for="c-38375736">[-]</label><label class="expand" for="c-38375736">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Safety&quot; has been the pretext for Altman&#x27;s lobbying for regulatory barriers to new entrants in the field, protecting incumbents. OpenAI&#x27;s nonprofit charter is the perfect PR pretext for what amounts to industry lobbying to protect a narrow set of early leaders and obstruct any other competition, and Altman was the man executing that mission, which is why OpenAI led by Sam was a valuable asset for Microsoft to preserve.</div><br/></div></div><div id="38375853" class="c"><input type="checkbox" id="c-38375853" checked=""/><div class="controls bullet"><span class="by">jq-r</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375536">parent</a><span>|</span><a href="#38375736">prev</a><span>|</span><a href="#38375562">next</a><span>|</span><label class="collapse" for="c-38375853">[-]</label><label class="expand" for="c-38375853">[2 more]</label></div><br/><div class="children"><div class="content">That’s just a buzzword of the week devoid of any real meaning. If he would have written this years ago, it would’ve been “leveraging synergies”.</div><br/><div id="38376393" class="c"><input type="checkbox" id="c-38376393" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375853">parent</a><span>|</span><a href="#38375562">next</a><span>|</span><label class="collapse" for="c-38376393">[-]</label><label class="expand" for="c-38376393">[1 more]</label></div><br/><div class="children"><div class="content">Shear is a genuine member of the AI safety rationalism cult, to the point he&#x27;s an Aella reply guy and probably goes to her orgies.<p>(It&#x27;s a Berkeley cult so of course it&#x27;s got those.)</div><br/></div></div></div></div></div></div><div id="38375562" class="c"><input type="checkbox" id="c-38375562" checked=""/><div class="controls bullet"><span class="by">cheeze</span><span>|</span><a href="#38375426">parent</a><span>|</span><a href="#38375536">prev</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38375562">[-]</label><label class="expand" for="c-38375562">[5 more]</label></div><br/><div class="children"><div class="content">I wonder what he gets out of this. Ceo for a few days? Do they pay him for 3 days of work? Presumably you&#x27;d want some minimum signing bonus in your contract as a Ceo?</div><br/><div id="38376616" class="c"><input type="checkbox" id="c-38376616" checked=""/><div class="controls bullet"><span class="by">bkyan</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38375776">next</a><span>|</span><label class="collapse" for="c-38376616">[-]</label><label class="expand" for="c-38376616">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emilychangtv&#x2F;status&#x2F;1727228431396704557</a><p>The reputation boost is probably worth a lot more than the direct financial compensation he&#x27;s getting.</div><br/></div></div><div id="38375776" class="c"><input type="checkbox" id="c-38375776" checked=""/><div class="controls bullet"><span class="by">diogenescynic</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38376616">prev</a><span>|</span><a href="#38375757">next</a><span>|</span><label class="collapse" for="c-38375776">[-]</label><label class="expand" for="c-38375776">[1 more]</label></div><br/><div class="children"><div class="content">He 100% had a golden parachute in case this scenario came up and will be paid out. Executives have lawyers to make sure of this.</div><br/></div></div><div id="38375757" class="c"><input type="checkbox" id="c-38375757" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375562">parent</a><span>|</span><a href="#38375776">prev</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38375757">[-]</label><label class="expand" for="c-38375757">[2 more]</label></div><br/><div class="children"><div class="content">he’ll put CEO of OAI on his resume</div><br/><div id="38375834" class="c"><input type="checkbox" id="c-38375834" checked=""/><div class="controls bullet"><span class="by">rospaya</span><span>|</span><a href="#38375426">root</a><span>|</span><a href="#38375757">parent</a><span>|</span><a href="#38375535">next</a><span>|</span><label class="collapse" for="c-38375834">[-]</label><label class="expand" for="c-38375834">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t. Everybody knows it&#x27;s three days, not much to brag about.</div><br/></div></div></div></div></div></div></div></div><div id="38375535" class="c"><input type="checkbox" id="c-38375535" checked=""/><div class="controls bullet"><span class="by">halfjoking</span><span>|</span><a href="#38375426">prev</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38375535">[-]</label><label class="expand" for="c-38375535">[5 more]</label></div><br/><div class="children"><div class="content">Still think this was CIA operation to get OpenAI in hands of US government and big tech.<p>Former Secretary, SalesForce CEO who was board chair of Twitter when infiltrated with FBI [1] and the fall-guy for the coup is the new board?  Not one person from the actual company - not even Greg who did nothing wrong???  [1] - <a href="https:&#x2F;&#x2F;twitter.com&#x2F;NameRedacted247&#x2F;status&#x2F;1634021149997686785" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;NameRedacted247&#x2F;status&#x2F;16340211499976867...</a><p>The two think-tank women who made all this happen conveniently leave so we never talk about them again.<p>Whatever, as long as I can use their API.</div><br/><div id="38376411" class="c"><input type="checkbox" id="c-38376411" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375535">parent</a><span>|</span><a href="#38376214">next</a><span>|</span><label class="collapse" for="c-38376411">[-]</label><label class="expand" for="c-38376411">[1 more]</label></div><br/><div class="children"><div class="content">US companies don&#x27;t need to be &quot;in the hands of the government&quot;, we have rule of law.<p>And Helen Toner was already as much of a fed as you could want; she had exactly the resume a CIA agent would have. (Probably wasn&#x27;t though.)</div><br/></div></div><div id="38376214" class="c"><input type="checkbox" id="c-38376214" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#38375535">parent</a><span>|</span><a href="#38376411">prev</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38376214">[-]</label><label class="expand" for="c-38376214">[3 more]</label></div><br/><div class="children"><div class="content">I wish they could make GPT4 a little cheaper after all this.</div><br/><div id="38376295" class="c"><input type="checkbox" id="c-38376295" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376214">parent</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38376295">[-]</label><label class="expand" for="c-38376295">[2 more]</label></div><br/><div class="children"><div class="content">considering what I get out of it, I would pay a lot more for gpt4 that $20&#x2F;month, so it depends on how much $20 is for you.</div><br/><div id="38376727" class="c"><input type="checkbox" id="c-38376727" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38375535">root</a><span>|</span><a href="#38376295">parent</a><span>|</span><a href="#38375412">next</a><span>|</span><label class="collapse" for="c-38376727">[-]</label><label class="expand" for="c-38376727">[1 more]</label></div><br/><div class="children"><div class="content">$20. Or use the API if your usage is low.</div><br/></div></div></div></div></div></div></div></div><div id="38375412" class="c"><input type="checkbox" id="c-38375412" checked=""/><div class="controls bullet"><span class="by">pdx6</span><span>|</span><a href="#38375535">prev</a><span>|</span><a href="#38375391">next</a><span>|</span><label class="collapse" for="c-38375412">[-]</label><label class="expand" for="c-38375412">[6 more]</label></div><br/><div class="children"><div class="content">Excellent news. I’ve been worried that Sam moving to Microsoft would stall out possible future engineering efforts like GPT-5 in IP court.<p>As an example of how much faster GPT-4 has made my workflow was the outage this evening — I tried Anthropic, openchat, Bard, and a few others and they were between not useful and worse than just looking at forums and discord it’s 2022.</div><br/><div id="38375645" class="c"><input type="checkbox" id="c-38375645" checked=""/><div class="controls bullet"><span class="by">badcoderman</span><span>|</span><a href="#38375412">parent</a><span>|</span><a href="#38375544">next</a><span>|</span><label class="collapse" for="c-38375645">[-]</label><label class="expand" for="c-38375645">[4 more]</label></div><br/><div class="children"><div class="content">GPT-5 is kinda pointless until they make some type of improvement on the data and research side.  From what I’ve read it’s not really what OpenAI has been pursuing it</div><br/><div id="38376288" class="c"><input type="checkbox" id="c-38376288" checked=""/><div class="controls bullet"><span class="by">Zolde</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376387">next</a><span>|</span><label class="collapse" for="c-38376288">[-]</label><label class="expand" for="c-38376288">[1 more]</label></div><br/><div class="children"><div class="content">One big improvement is in synthetic data (data generated by LLMs).<p>GPT can &quot;clone&quot; the &quot;semantic essence&quot; of everyone who converses with it, generating new questions with prompts like &quot;What interesting questions could this user also have asked, but didn&#x27;t?&quot; and then have an LLM answer it. This generates high-quality, novel, human-like, data.<p>For instance, cloning Paul Graham&#x27;s essence, the LLM came up with &quot;SubSimplify&quot;: A service that combines subscriptions to all the different streaming services into one customizable package, using a chat agent as a recommendation engine.</div><br/></div></div><div id="38376387" class="c"><input type="checkbox" id="c-38376387" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376288">prev</a><span>|</span><a href="#38376319">next</a><span>|</span><label class="collapse" for="c-38376387">[-]</label><label class="expand" for="c-38376387">[1 more]</label></div><br/><div class="children"><div class="content">The next improvement will be more modalities (images, sound, etc.)<p>GPT4 in image viewing mode doesn&#x27;t seem to be nearly as smart as text mode, and image generation IME barely works.</div><br/></div></div><div id="38376319" class="c"><input type="checkbox" id="c-38376319" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38375412">root</a><span>|</span><a href="#38375645">parent</a><span>|</span><a href="#38376387">prev</a><span>|</span><a href="#38375544">next</a><span>|</span><label class="collapse" for="c-38376319">[-]</label><label class="expand" for="c-38376319">[1 more]</label></div><br/><div class="children"><div class="content">Are you just blindly deciding what will make “gpt-5” more capable? I guess “data and research” is practically so open ended as to encompass the majority of any possible advancement.</div><br/></div></div></div></div><div id="38375544" class="c"><input type="checkbox" id="c-38375544" checked=""/><div class="controls bullet"><span class="by">sidcool</span><span>|</span><a href="#38375412">parent</a><span>|</span><a href="#38375645">prev</a><span>|</span><a href="#38375391">next</a><span>|</span><label class="collapse" for="c-38375544">[-]</label><label class="expand" for="c-38375544">[1 more]</label></div><br/><div class="children"><div class="content">I still feel Microsoft will have a bigger influence on OpenAI after this drama is over.</div><br/></div></div></div></div><div id="38375391" class="c"><input type="checkbox" id="c-38375391" checked=""/><div class="controls bullet"><span class="by">Gud</span><span>|</span><a href="#38375412">prev</a><span>|</span><a href="#38375789">next</a><span>|</span><label class="collapse" for="c-38375391">[-]</label><label class="expand" for="c-38375391">[4 more]</label></div><br/><div class="children"><div class="content">Once we develop an actual, fully functional AGI, it’s going to steamroll us isn’t it.<p>If these are the stewards of this technology, it’s time to be worried now.</div><br/><div id="38375916" class="c"><input type="checkbox" id="c-38375916" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#38375391">parent</a><span>|</span><a href="#38375981">next</a><span>|</span><label class="collapse" for="c-38375916">[-]</label><label class="expand" for="c-38375916">[2 more]</label></div><br/><div class="children"><div class="content">“And that moment was the final nail in the coffin of humankind from earth. They choose, yet again, for money and power. And they shaped AI in their image.<p>Another civilization perished in the great filter.”</div><br/><div id="38376017" class="c"><input type="checkbox" id="c-38376017" checked=""/><div class="controls bullet"><span class="by">MooseBurger</span><span>|</span><a href="#38375391">root</a><span>|</span><a href="#38375916">parent</a><span>|</span><a href="#38375981">next</a><span>|</span><label class="collapse" for="c-38376017">[-]</label><label class="expand" for="c-38376017">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not that deep bro</div><br/></div></div></div></div><div id="38375981" class="c"><input type="checkbox" id="c-38375981" checked=""/><div class="controls bullet"><span class="by">otabdeveloper4</span><span>|</span><a href="#38375391">parent</a><span>|</span><a href="#38375916">prev</a><span>|</span><a href="#38375789">next</a><span>|</span><label class="collapse" for="c-38375981">[-]</label><label class="expand" for="c-38375981">[1 more]</label></div><br/><div class="children"><div class="content">The only way &quot;we develop an actual, fully functional AGI&quot; is by dumbing down humans enough so that even something as stupid as ChatGPT seems intelligent.<p>(Fortunately we are working on this very hard and making incredible progress.)</div><br/></div></div></div></div><div id="38375789" class="c"><input type="checkbox" id="c-38375789" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#38375391">prev</a><span>|</span><a href="#38375392">next</a><span>|</span><label class="collapse" for="c-38375789">[-]</label><label class="expand" for="c-38375789">[1 more]</label></div><br/><div class="children"><div class="content">Looks to me like, one pro-board member in Adam d Angelo, one pro Sam in Brett Taylor since they’ve been pushing for him since Sunday so I’m assuming Sam and rest of OpenAI leadership really like him and 1 Neutral in Larry Summers who has never worked in AI and is just a well respected name in general. I’m sure Larry was extensively interviewed and reference checked by both sides of this power struggle before they agreed to compromise on him.<p>Interesting to see how the board evolves from this. From what I know broadly there were 2 factions, the faction that thought Sam was going too fast which fired him and the faction that thought Sam’s trajectory was fine (which included Sam and Greg). Now there’s a balance on the board and subsequent hires can tip it one way or the other. Unfortunately a divided board rarely lasts and one faction will eventually win out, I think Sam’s faction will eventually win out but we’ll have to wait and see.<p>One of the saddest results of this drama was Greg being ousted from OpenAI. Greg apart from being brilliant was someone who regularly 80-90 hour work weeks into OpenAI, and you could truly say he dedicated a good chunk of his life into building this organization. And he was forced to resign by a board who probably never put a 90 hour work week in their entire life, much less into building OpenAI. A slap on the face. I don’t care what the board’s reasoning was but when their actions caused employees who dedicated their lives to building the organization resign (especially when most of them played no part at all into building this amazing organization), they had to go in disgrace. I doubt any of them will ever reach career highs higher than being on OpenAI’s board, and the world’s better off for it.<p>P.S., Ilya of course is an exception and not included in my above condemnation. He also notably reversed his position when he saw OpenAI was being killed by his actions.</div><br/></div></div><div id="38375392" class="c"><input type="checkbox" id="c-38375392" checked=""/><div class="controls bullet"><span class="by">bobsoap</span><span>|</span><a href="#38375789">prev</a><span>|</span><a href="#38375366">next</a><span>|</span><label class="collapse" for="c-38375392">[-]</label><label class="expand" for="c-38375392">[1 more]</label></div><br/><div class="children"><div class="content">Someone was very quick to update Bret Taylor&#x27;s Wikipedia page:<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Bret_Taylor" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Bret_Taylor</a><p>&gt; On November, 21st, 2023, Bret Taylor replaced Greg Brockman as the chairman of OpenAI.<p>...with three footmark &quot;sources&quot; that all point to completely unrelated articles about Bret from 2021-2022.</div><br/></div></div><div id="38375366" class="c"><input type="checkbox" id="c-38375366" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375392">prev</a><span>|</span><a href="#38375292">next</a><span>|</span><label class="collapse" for="c-38375366">[-]</label><label class="expand" for="c-38375366">[13 more]</label></div><br/><div class="children"><div class="content">Assuming they weren’t LARPing, that Reddit account claiming to have been in the room when this was all going down must be nervous. They wrote all kinds of nasty things about Sam, and I’m assuming the signatures on the “bring him back” letter would narrow down potential suspects considerably.<p>Edit: For those who may have missed it in previous threads, see <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126</a></div><br/><div id="38375524" class="c"><input type="checkbox" id="c-38375524" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376664">next</a><span>|</span><label class="collapse" for="c-38375524">[-]</label><label class="expand" for="c-38375524">[2 more]</label></div><br/><div class="children"><div class="content">First of all nothing on Reddit is real (within margin of error). Secondly it&#x27;s weird that you&#x27;d assume we know what you&#x27;re talking about.</div><br/><div id="38375701" class="c"><input type="checkbox" id="c-38375701" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38375524">parent</a><span>|</span><a href="#38376664">next</a><span>|</span><label class="collapse" for="c-38375701">[-]</label><label class="expand" for="c-38375701">[1 more]</label></div><br/><div class="children"><div class="content">Links to the profile&#x2F;comments were posted a few times in each of the major OpenAI HN submissions over the last 4 days. On the off-chance I would be breaking some kind of brigading&#x2F;doxxing rule I didn&#x27;t initially link it myself.</div><br/></div></div></div></div><div id="38376664" class="c"><input type="checkbox" id="c-38376664" checked=""/><div class="controls bullet"><span class="by">shrimpx</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375524">prev</a><span>|</span><a href="#38376425">next</a><span>|</span><label class="collapse" for="c-38376664">[-]</label><label class="expand" for="c-38376664">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t sound credible or revealing. It&#x27;s regurgitating a bunch of speculation stuff that&#x27;s been said on this forum and in the media.</div><br/></div></div><div id="38376425" class="c"><input type="checkbox" id="c-38376425" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376664">prev</a><span>|</span><a href="#38375423">next</a><span>|</span><label class="collapse" for="c-38376425">[-]</label><label class="expand" for="c-38376425">[1 more]</label></div><br/><div class="children"><div class="content">I read the comments, most of them are superficial as if someone with no inside knowledge will post. His understanding of humans is also weak. Book deals and speeches as a motivator is hilarious.</div><br/></div></div><div id="38375423" class="c"><input type="checkbox" id="c-38375423" checked=""/><div class="controls bullet"><span class="by">fordsmith</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38376425">prev</a><span>|</span><a href="#38375629">next</a><span>|</span><label class="collapse" for="c-38375423">[-]</label><label class="expand" for="c-38375423">[2 more]</label></div><br/><div class="children"><div class="content">Link? Not sure which account you are referring to</div><br/><div id="38375443" class="c"><input type="checkbox" id="c-38375443" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38375423">parent</a><span>|</span><a href="#38375629">next</a><span>|</span><label class="collapse" for="c-38375443">[-]</label><label class="expand" for="c-38375443">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;user&#x2F;Anxious_Bandicoot126</a></div><br/></div></div></div></div><div id="38375629" class="c"><input type="checkbox" id="c-38375629" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375423">prev</a><span>|</span><a href="#38375431">next</a><span>|</span><label class="collapse" for="c-38375629">[-]</label><label class="expand" for="c-38375629">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  must be nervous<p>I seriously doubt they care. They got away with it. No one should have believed them in the first place. I’m guessing they don’t have their real identity visible on their profile anywhere.</div><br/></div></div><div id="38375431" class="c"><input type="checkbox" id="c-38375431" checked=""/><div class="controls bullet"><span class="by">crakenzak</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375629">prev</a><span>|</span><a href="#38376025">next</a><span>|</span><label class="collapse" for="c-38375431">[-]</label><label class="expand" for="c-38375431">[1 more]</label></div><br/><div class="children"><div class="content">Context?</div><br/></div></div><div id="38376025" class="c"><input type="checkbox" id="c-38376025" checked=""/><div class="controls bullet"><span class="by">epups</span><span>|</span><a href="#38375366">parent</a><span>|</span><a href="#38375431">prev</a><span>|</span><a href="#38375292">next</a><span>|</span><label class="collapse" for="c-38376025">[-]</label><label class="expand" for="c-38376025">[4 more]</label></div><br/><div class="children"><div class="content">Why can&#x27;t these safety advocates just say what they are afraid of? As it currently stands, the only &quot;danger&quot; in ChatGPT is that you can manipulate it into writing something violent or inappropriate. So what? Is this some San Francisco sensibilities here, where reading about fictional violence is equated to violence? The more people raise safety concerns in the abstract, the more I ignore it.</div><br/><div id="38376283" class="c"><input type="checkbox" id="c-38376283" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376435">next</a><span>|</span><label class="collapse" for="c-38376283">[-]</label><label class="expand" for="c-38376283">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why can&#x27;t these safety advocates just say what they are afraid of?<p>They have. At length. E.g.,<p><a href="https:&#x2F;&#x2F;ai100.stanford.edu&#x2F;gathering-strength-gathering-storms-one-hundred-year-study-artificial-intelligence-ai100-2021-1-0" rel="nofollow noreferrer">https:&#x2F;&#x2F;ai100.stanford.edu&#x2F;gathering-strength-gathering-stor...</a><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03718.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2307.03718.pdf</a><p><a href="https:&#x2F;&#x2F;eber.uek.krakow.pl&#x2F;index.php&#x2F;eber&#x2F;article&#x2F;view&#x2F;2113" rel="nofollow noreferrer">https:&#x2F;&#x2F;eber.uek.krakow.pl&#x2F;index.php&#x2F;eber&#x2F;article&#x2F;view&#x2F;2113</a><p><a href="https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;pdf&#x2F;10.1177&#x2F;10242589221147228" rel="nofollow noreferrer">https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;pdf&#x2F;10.1177&#x2F;102425892211472...</a><p><a href="https:&#x2F;&#x2F;jc.gatspress.com&#x2F;pdf&#x2F;existential_risk_and_powerseeking_ai.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;jc.gatspress.com&#x2F;pdf&#x2F;existential_risk_and_powerseeki...</a><p>For just a handful of examples from the vast literature published in this area.</div><br/></div></div><div id="38376435" class="c"><input type="checkbox" id="c-38376435" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376283">prev</a><span>|</span><a href="#38376458">next</a><span>|</span><label class="collapse" for="c-38376435">[-]</label><label class="expand" for="c-38376435">[1 more]</label></div><br/><div class="children"><div class="content">They invented a whole theory of how if we had something called &quot;AGI&quot; it would kill everyone, and now they think LLMs can kill everyone because they&#x27;re calling it &quot;AGI&quot;, even though it doesn&#x27;t work anything like their theory assumed.<p>This isn&#x27;t about political correctness. It&#x27;s far less reasonable than that.</div><br/></div></div><div id="38376458" class="c"><input type="checkbox" id="c-38376458" checked=""/><div class="controls bullet"><span class="by">robryk</span><span>|</span><a href="#38375366">root</a><span>|</span><a href="#38376025">parent</a><span>|</span><a href="#38376435">prev</a><span>|</span><a href="#38375292">next</a><span>|</span><label class="collapse" for="c-38376458">[-]</label><label class="expand" for="c-38376458">[1 more]</label></div><br/><div class="children"><div class="content">Consider that your argument could also be used to advocate for safety of starting to use coal-fired steam engines (in 19th century UK): there&#x27;s no immediate direct problem, but competitive pressures force everyone to use them and any externalities stemming from that are basically unavoidable.</div><br/></div></div></div></div></div></div><div id="38375292" class="c"><input type="checkbox" id="c-38375292" checked=""/><div class="controls bullet"><span class="by">mlazos</span><span>|</span><a href="#38375366">prev</a><span>|</span><a href="#38375543">next</a><span>|</span><label class="collapse" for="c-38375292">[-]</label><label class="expand" for="c-38375292">[2 more]</label></div><br/><div class="children"><div class="content">Looks like Satya will have all of the leverage after this. He kind of always did though, but the board has almost entirely been replaced.<p>I don’t see any point to the non profit umbrella now.</div><br/><div id="38375374" class="c"><input type="checkbox" id="c-38375374" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#38375292">parent</a><span>|</span><a href="#38375543">next</a><span>|</span><label class="collapse" for="c-38375374">[-]</label><label class="expand" for="c-38375374">[1 more]</label></div><br/><div class="children"><div class="content">Sure, you can dissolve it if you hand over all the assets to another 501(c)3 organization.  Otherwise, you are stuck with it.</div><br/></div></div></div></div><div id="38375543" class="c"><input type="checkbox" id="c-38375543" checked=""/><div class="controls bullet"><span class="by">wannacboatmovie</span><span>|</span><a href="#38375292">prev</a><span>|</span><a href="#38375266">next</a><span>|</span><label class="collapse" for="c-38375543">[-]</label><label class="expand" for="c-38375543">[2 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen this many nerds in a froth since Apple walked back the butterfly keyboards in the MacBook.</div><br/><div id="38375670" class="c"><input type="checkbox" id="c-38375670" checked=""/><div class="controls bullet"><span class="by">travisgriggs</span><span>|</span><a href="#38375543">parent</a><span>|</span><a href="#38375266">next</a><span>|</span><label class="collapse" for="c-38375670">[-]</label><label class="expand" for="c-38375670">[1 more]</label></div><br/><div class="children"><div class="content">I know we’re supposed to optimize for “content with a contribution” in HN, but this captured in parody form more of a contribution of how I too have felt.<p>I use these tools as one of many tools to amplify my development. And I’ve written some funny&#x2F;clever satirical poems about office politics. But really? I needed to call Verizon to clear up an issue today, it desperately wanted me to use their assistant. I tried for the grins. A tool that predictively  generates plausibility is going to have its limits. It went from cute&#x2F;amusing to annoying as hell and give me a “love agent” pretty quickly.<p>That this little TechBro Drama has dominated a huge amount of headlines (we’ve been running at least 3 of the top 30 posts at a time on HN here related to this subject) at a time when there is so much bigger things going on in the world. The demise of Twitter generated less headlines. Either the news cycles are getting more and more desperate, or the software development ecosystem is struggling to generate fund raising enthusiasm more and more.</div><br/></div></div></div></div><div id="38375266" class="c"><input type="checkbox" id="c-38375266" checked=""/><div class="controls bullet"><span class="by">AaronNewcomer</span><span>|</span><a href="#38375543">prev</a><span>|</span><a href="#38375831">next</a><span>|</span><label class="collapse" for="c-38375266">[-]</label><label class="expand" for="c-38375266">[1 more]</label></div><br/><div class="children"><div class="content">What a wild ride. I have used X more the past few days than in a long time; that’s for sure!</div><br/></div></div><div id="38375831" class="c"><input type="checkbox" id="c-38375831" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38375266">prev</a><span>|</span><a href="#38375614">next</a><span>|</span><label class="collapse" for="c-38375831">[-]</label><label class="expand" for="c-38375831">[3 more]</label></div><br/><div class="children"><div class="content">From a business sense, Satya was excellent.<p>He made the right calls, fast, with limited information.<p>Things further shifted from plan a to b to… whatever this is.<p>Despite that, MSFT still came out on top.<p>Consider if Satya didn’t say anything. Suppose MSFT stood back and let things play out.<p>That’s a gap for google or some competitor to make a move. To showcase their stability and long term business friendly vision.<p>Instead by moving fast, doing the “right” thing, this opportunity was denied and used to MSFTs benefit.<p>If the board folded, it would return to the stays quo. If the board held, MSFT would have secured OpenAI, for essentially nothing.<p>Edit: changed board folded x2 to board folded + board held, last para.</div><br/><div id="38376053" class="c"><input type="checkbox" id="c-38376053" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38375941">next</a><span>|</span><label class="collapse" for="c-38376053">[-]</label><label class="expand" for="c-38376053">[1 more]</label></div><br/><div class="children"><div class="content">The only mistake (a big one) was publicly offering to match comp for all the OpenAI employees. Can&#x27;t sit well with folks @ MS already. This was something they could have easily done privately to give petition signers confidence.</div><br/></div></div><div id="38375941" class="c"><input type="checkbox" id="c-38375941" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#38375831">parent</a><span>|</span><a href="#38376053">prev</a><span>|</span><a href="#38375614">next</a><span>|</span><label class="collapse" for="c-38375941">[-]</label><label class="expand" for="c-38375941">[1 more]</label></div><br/><div class="children"><div class="content">Satya may honestly be the CEO of the decade for what he has done with Microsoft and now this.</div><br/></div></div></div></div><div id="38375614" class="c"><input type="checkbox" id="c-38375614" checked=""/><div class="controls bullet"><span class="by">tunesmith</span><span>|</span><a href="#38375831">prev</a><span>|</span><a href="#38376287">next</a><span>|</span><label class="collapse" for="c-38375614">[-]</label><label class="expand" for="c-38375614">[4 more]</label></div><br/><div class="children"><div class="content">Weird... Ilya decides one way then changes his mind. Helen and Tasha vote one way and had the votes to prevent any changes, but then for some reason agreed to leave the board. Adam votes one way then changes his mind. So many mysteries.</div><br/><div id="38376750" class="c"><input type="checkbox" id="c-38376750" checked=""/><div class="controls bullet"><span class="by">zucker42</span><span>|</span><a href="#38375614">parent</a><span>|</span><a href="#38376274">next</a><span>|</span><label class="collapse" for="c-38376750">[-]</label><label class="expand" for="c-38376750">[1 more]</label></div><br/><div class="children"><div class="content">Ilya and Adam switched because they lost, and their goal wasn&#x27;t to nuke OpenAI, simply to remove Sam. Helen and Tasha had the votes to prevent Sam Altman from returning as CEO, but not the votes to prevent the employees from fleeing to Microsoft, which Helen and Tasha see as the worst possible outcome.</div><br/></div></div><div id="38376274" class="c"><input type="checkbox" id="c-38376274" checked=""/><div class="controls bullet"><span class="by">Geee</span><span>|</span><a href="#38375614">parent</a><span>|</span><a href="#38376750">prev</a><span>|</span><a href="#38376074">next</a><span>|</span><label class="collapse" for="c-38376274">[-]</label><label class="expand" for="c-38376274">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s some game theory going on... They&#x27;re just trying to pick the winning side. I guess most people at OpenAI supported Sam, because they thought Sam would win at the end, although they wouldn&#x27;t necessarily want him to win.</div><br/></div></div><div id="38376074" class="c"><input type="checkbox" id="c-38376074" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#38375614">parent</a><span>|</span><a href="#38376274">prev</a><span>|</span><a href="#38376287">next</a><span>|</span><label class="collapse" for="c-38376074">[-]</label><label class="expand" for="c-38376074">[1 more]</label></div><br/><div class="children"><div class="content">If the Sama faction got Ilya and Adam (maybe with promise of heading the new board), Helen and Tasha have nothing to stand on and no incentive to keep fighting.</div><br/></div></div></div></div><div id="38376287" class="c"><input type="checkbox" id="c-38376287" checked=""/><div class="controls bullet"><span class="by">rurban</span><span>|</span><a href="#38375614">prev</a><span>|</span><a href="#38375358">next</a><span>|</span><label class="collapse" for="c-38376287">[-]</label><label class="expand" for="c-38376287">[1 more]</label></div><br/><div class="children"><div class="content">This was expected. So they booted Ilya (my main culprit), Helen Toner (expected, favoriting Anthropic) and Tasha McCauly. This seems to have been their vote majority. 
Not D&#x27;Angelo. Interesting</div><br/></div></div><div id="38375358" class="c"><input type="checkbox" id="c-38375358" checked=""/><div class="controls bullet"><span class="by">veqq</span><span>|</span><a href="#38376287">prev</a><span>|</span><a href="#38375287">next</a><span>|</span><label class="collapse" for="c-38375358">[-]</label><label class="expand" for="c-38375358">[4 more]</label></div><br/><div class="children"><div class="content">Besides AI safety (a big besides), what does this actually mean? Adam won&#x27;t be able to stop devday announcements about chatbots etc. Satya can continue using IP even after AGI? What else is different? Is Ilya the kind of guy to now leave after losing a board seat to political machinations? The pettiness of any real changes&#x2F;gains leaves me in shock compared to the massive news flows we&#x27;ve seen.<p>I don&#x27;t even understand what Sam brings to the table. Leadership? He doesn&#x27;t seem great at leading an engineering or research department, he doesn&#x27;t seem like an insightful visionary... At best, Satya gunning for him signalled continued strong investment in the space. Yet the majority of the company wanted to leave with him.<p>What am I missing?</div><br/><div id="38375387" class="c"><input type="checkbox" id="c-38375387" checked=""/><div class="controls bullet"><span class="by">kneel</span><span>|</span><a href="#38375358">parent</a><span>|</span><a href="#38375399">next</a><span>|</span><label class="collapse" for="c-38375387">[-]</label><label class="expand" for="c-38375387">[2 more]</label></div><br/><div class="children"><div class="content">&gt;He doesn&#x27;t seem great at leading an engineering or research department<p>Under Sam&#x27;s leadership they&#x27;ve opened up a new field of software. Most of the company threatened to leave if he didn&#x27;t return. That&#x27;s incredible leadership.</div><br/><div id="38375846" class="c"><input type="checkbox" id="c-38375846" checked=""/><div class="controls bullet"><span class="by">consp</span><span>|</span><a href="#38375358">root</a><span>|</span><a href="#38375387">parent</a><span>|</span><a href="#38375399">next</a><span>|</span><label class="collapse" for="c-38375846">[-]</label><label class="expand" for="c-38375846">[1 more]</label></div><br/><div class="children"><div class="content">Or simply money. Microsoft matched everything they would have so there is no risk involved.</div><br/></div></div></div></div><div id="38375399" class="c"><input type="checkbox" id="c-38375399" checked=""/><div class="controls bullet"><span class="by">tock</span><span>|</span><a href="#38375358">parent</a><span>|</span><a href="#38375387">prev</a><span>|</span><a href="#38375287">next</a><span>|</span><label class="collapse" for="c-38375399">[-]</label><label class="expand" for="c-38375399">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Leadership? He doesn&#x27;t seem great at leading an engineering or research department, he doesn&#x27;t seem like an insightful visionary<p>Most of the company was ready to quit over him being fired. So yes, leadership.</div><br/></div></div></div></div><div id="38375287" class="c"><input type="checkbox" id="c-38375287" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#38375358">prev</a><span>|</span><label class="collapse" for="c-38375287">[-]</label><label class="expand" for="c-38375287">[1 more]</label></div><br/><div class="children"><div class="content">&quot;In principle&quot; has me less than 100% assured. Hopefully no more plot twists in this. Everyone, inside and outside, has probably had enough.</div><br/></div></div></div></div></div></div></div></body></html>