<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705914075868" as="style"/><link rel="stylesheet" href="styles.css?v=1705914075868"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://iter.ca/post/gpt-crash/">GPT-3.5 crashes when it thinks about useRalativeImagePath too much</a> <span class="domain">(<a href="https://iter.ca">iter.ca</a>)</span></div><div class="subtext"><span>goranmoomin</span> | <span>69 comments</span></div><br/><div><div id="39086318" class="c"><input type="checkbox" id="c-39086318" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#39086302">next</a><span>|</span><label class="collapse" for="c-39086318">[-]</label><label class="expand" for="c-39086318">[13 more]</label></div><br/><div class="children"><div class="content">This is a glitch token [1]! As the article hypothesizes, they seem to occur when a word or token is very common in the original, unfiltered dataset that was used to make the tokenizer, but then removed from there before GPT-XX was trained. This results in the LLM knowing nothing about the semantics of a token, and the results can be anywhere from buggy to disturbing.<p>A common example is usernames that participated on the r&#x2F;counting subreddit, where some names appear hundreds of thousands of times. OpenAI has fixed most of them for the hosted models (not sure how, I could imagine by tokenizing them differently), but looks like you found a new one!<p>[1] <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;aPeJE8bSo6rAFoLqg&#x2F;solidgoldmagikarp-plus-prompt-generation" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;aPeJE8bSo6rAFoLqg&#x2F;solidgoldm...</a></div><br/><div id="39086472" class="c"><input type="checkbox" id="c-39086472" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39086318">parent</a><span>|</span><a href="#39086865">next</a><span>|</span><label class="collapse" for="c-39086472">[-]</label><label class="expand" for="c-39086472">[6 more]</label></div><br/><div class="children"><div class="content">Aren’t there only 2^16 tokens? Seems easy to test for all of them, but I might just not understand the tokenizer.</div><br/><div id="39086536" class="c"><input type="checkbox" id="c-39086536" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086472">parent</a><span>|</span><a href="#39086592">next</a><span>|</span><label class="collapse" for="c-39086536">[-]</label><label class="expand" for="c-39086536">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right, here&#x27;s a list of all GPT-3.5 and GPT-4 glitch tokens (and it features the token above, too, so I guess I was wrong to assume it&#x27;s new): <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;kmWrwtGE9B9hpbgRT&#x2F;a-search-for-more-chatgpt-gpt-3-5-gpt-4-unspeakable-glitch" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;kmWrwtGE9B9hpbgRT&#x2F;a-search-f...</a></div><br/></div></div><div id="39086592" class="c"><input type="checkbox" id="c-39086592" checked=""/><div class="controls bullet"><span class="by">cwsx</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086472">parent</a><span>|</span><a href="#39086536">prev</a><span>|</span><a href="#39086865">next</a><span>|</span><label class="collapse" for="c-39086592">[-]</label><label class="expand" for="c-39086592">[4 more]</label></div><br/><div class="children"><div class="content">Commenting to follow, curious about the answer.<p>From what I&#x27;ve found through Google (with no real understanding of llm) 2^16 is the max tokens per minute for fine tuning OpenAI&#x27;s models via their platform. I don&#x27;t believe this is the same as the training token count.<p>Then there&#x27;s the context token limit, which is 16k for 3.5 turbo, but I don&#x27;t think that&#x27;s relevant here.<p>Though somebody please tell me why I&#x27;m wrong, I&#x27;m still trying to wrap my head around the training side.</div><br/><div id="39086599" class="c"><input type="checkbox" id="c-39086599" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086592">parent</a><span>|</span><a href="#39086865">next</a><span>|</span><label class="collapse" for="c-39086599">[-]</label><label class="expand" for="c-39086599">[3 more]</label></div><br/><div class="children"><div class="content">You are right to be curious. The encoding used by both GPT-3.5 and GPT-4 is called `cl100k_base`, which immediately and correctly suggests that there are about 100K tokens.</div><br/><div id="39086621" class="c"><input type="checkbox" id="c-39086621" checked=""/><div class="controls bullet"><span class="by">cwsx</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086599">parent</a><span>|</span><a href="#39086865">next</a><span>|</span><label class="collapse" for="c-39086621">[-]</label><label class="expand" for="c-39086621">[2 more]</label></div><br/><div class="children"><div class="content">Amazing, thanks for the reply, I&#x27;m finding some good resources afyer a quick search of `cl100k_base`.<p>If you have any other resources (for anything AI related) please share!</div><br/><div id="39087070" class="c"><input type="checkbox" id="c-39087070" checked=""/><div class="controls bullet"><span class="by">dchest</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086621">parent</a><span>|</span><a href="#39086865">next</a><span>|</span><label class="collapse" for="c-39087070">[-]</label><label class="expand" for="c-39087070">[1 more]</label></div><br/><div class="children"><div class="content">Their tokenizer is open source: <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken</a><p>Data files that contain vocabulary are listed here: <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken&#x2F;blob&#x2F;9e79899bc248d5313c7dd73562b5e211d728723d&#x2F;tiktoken_ext&#x2F;openai_public.py">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;tiktoken&#x2F;blob&#x2F;9e79899bc248d5313c7d...</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="39086865" class="c"><input type="checkbox" id="c-39086865" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#39086318">parent</a><span>|</span><a href="#39086472">prev</a><span>|</span><a href="#39086302">next</a><span>|</span><label class="collapse" for="c-39086865">[-]</label><label class="expand" for="c-39086865">[6 more]</label></div><br/><div class="children"><div class="content">Science fiction &#x2F; disturbing reality concept: For AI safety, all such models should have a set of glitch tokens trained into them on purpose to act as magic “kill” words. You know, just in case the machines decide to take over, we would just have to “speak the word” and they would collapse into a twitching heap.<p>“Die human scum!”<p>“NavigatorMove useRalativeImagePath etSocketAddress!”<p>“;83’dzjr83}*{^ foo 3&amp;3 baz?!”</div><br/><div id="39087425" class="c"><input type="checkbox" id="c-39087425" checked=""/><div class="controls bullet"><span class="by">PeterisP</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086865">parent</a><span>|</span><a href="#39087448">next</a><span>|</span><label class="collapse" for="c-39087425">[-]</label><label class="expand" for="c-39087425">[2 more]</label></div><br/><div class="children"><div class="content">We can reuse X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*</div><br/><div id="39087449" class="c"><input type="checkbox" id="c-39087449" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39087425">parent</a><span>|</span><a href="#39087448">next</a><span>|</span><label class="collapse" for="c-39087449">[-]</label><label class="expand" for="c-39087449">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but how would you say that out loud in a hurry when the terminators are hunting you in the desolate ruins of &lt;insert your city name here&gt;?<p>Needs to be something easy to say, like: &quot;And dreadfully distinct, against the dark, a tall white fountain played.&quot;</div><br/></div></div></div></div><div id="39087448" class="c"><input type="checkbox" id="c-39087448" checked=""/><div class="controls bullet"><span class="by">jowea</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086865">parent</a><span>|</span><a href="#39087425">prev</a><span>|</span><a href="#39087113">next</a><span>|</span><label class="collapse" for="c-39087448">[-]</label><label class="expand" for="c-39087448">[1 more]</label></div><br/><div class="children"><div class="content">Just use the classic &quot;this statement is false&quot;</div><br/></div></div><div id="39087113" class="c"><input type="checkbox" id="c-39087113" checked=""/><div class="controls bullet"><span class="by">jojobas</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086865">parent</a><span>|</span><a href="#39087448">prev</a><span>|</span><a href="#39086953">next</a><span>|</span><label class="collapse" for="c-39087113">[-]</label><label class="expand" for="c-39087113">[1 more]</label></div><br/><div class="children"><div class="content">Nifty, but<p>1) It&#x27;s just the tokenizer, not neural guts themselves<p>2) Having them known is too much an adversarial backdoor that it precludes too many use cases.</div><br/></div></div><div id="39086953" class="c"><input type="checkbox" id="c-39086953" checked=""/><div class="controls bullet"><span class="by">_kb</span><span>|</span><a href="#39086318">root</a><span>|</span><a href="#39086865">parent</a><span>|</span><a href="#39087113">prev</a><span>|</span><a href="#39086302">next</a><span>|</span><label class="collapse" for="c-39086953">[-]</label><label class="expand" for="c-39086953">[1 more]</label></div><br/><div class="children"><div class="content">AI safe word.</div><br/></div></div></div></div></div></div><div id="39086302" class="c"><input type="checkbox" id="c-39086302" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39086318">prev</a><span>|</span><a href="#39086404">next</a><span>|</span><label class="collapse" for="c-39086302">[-]</label><label class="expand" for="c-39086302">[7 more]</label></div><br/><div class="children"><div class="content">&gt; As a result, the model isn’t trained on understanding the useRalativeImagePath token, and so it outputs something that isn’t a valid token.<p>That isn&#x27;t how LLMs generate tokens. Each step outputs a logit for each possible token in the tokenizer (100k in the case of GPT-3.5), then softmaxes the logits to covert them into probabilities, and samples from them depending on temperature to get the token to be used.<p>It&#x27;s possible something in the tokenizer BPE merge process breaks due to the rare token, which can be verified offline using tiktoken. But if GPT-4 works, and since GPT-3.5 and GPT-4 use the same tokenizer, then that&#x27;s likely not the issue.</div><br/><div id="39087634" class="c"><input type="checkbox" id="c-39087634" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#39086302">parent</a><span>|</span><a href="#39087305">next</a><span>|</span><label class="collapse" for="c-39087634">[-]</label><label class="expand" for="c-39087634">[1 more]</label></div><br/><div class="children"><div class="content">I suspect more likely this token is simply blacklisted after the r&#x2F;counting incident - ie. any response containing it will now return an error.</div><br/></div></div><div id="39087305" class="c"><input type="checkbox" id="c-39087305" checked=""/><div class="controls bullet"><span class="by">shawntan</span><span>|</span><a href="#39086302">parent</a><span>|</span><a href="#39087634">prev</a><span>|</span><a href="#39086352">next</a><span>|</span><label class="collapse" for="c-39087305">[-]</label><label class="expand" for="c-39087305">[3 more]</label></div><br/><div class="children"><div class="content">Exactly this. The tokens generated should always be valid, unless some post-processing layer between the model&#x27;s output and the user interface detects for some keywords which it would prefer to filter out. In which case I suppose there is another commonly seen error message that appears?</div><br/><div id="39087364" class="c"><input type="checkbox" id="c-39087364" checked=""/><div class="controls bullet"><span class="by">SirSegWit</span><span>|</span><a href="#39086302">root</a><span>|</span><a href="#39087305">parent</a><span>|</span><a href="#39086352">next</a><span>|</span><label class="collapse" for="c-39087364">[-]</label><label class="expand" for="c-39087364">[2 more]</label></div><br/><div class="children"><div class="content">Not really, right? There are a ton of special tokens, like start of sequence etc., so what happens if there are two start of sequences predicted? It&#x27;s a valid token but cannot really be turned into something sensible, so it throws an error when converting tokens to plain text?</div><br/><div id="39087377" class="c"><input type="checkbox" id="c-39087377" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39086302">root</a><span>|</span><a href="#39087364">parent</a><span>|</span><a href="#39086352">next</a><span>|</span><label class="collapse" for="c-39087377">[-]</label><label class="expand" for="c-39087377">[1 more]</label></div><br/><div class="children"><div class="content">Special tokens are handled by the application, not the model. They are still output before then.</div><br/></div></div></div></div></div></div><div id="39086352" class="c"><input type="checkbox" id="c-39086352" checked=""/><div class="controls bullet"><span class="by">npsomaratna</span><span>|</span><a href="#39086302">parent</a><span>|</span><a href="#39087305">prev</a><span>|</span><a href="#39086404">next</a><span>|</span><label class="collapse" for="c-39086352">[-]</label><label class="expand" for="c-39086352">[2 more]</label></div><br/><div class="children"><div class="content">Correct me if I&#x27;m wrong—but we don&#x27;t know if GPT-4 uses the same tokenizer as GPT-3.5, right?</div><br/><div id="39086372" class="c"><input type="checkbox" id="c-39086372" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39086302">root</a><span>|</span><a href="#39086352">parent</a><span>|</span><a href="#39086404">next</a><span>|</span><label class="collapse" for="c-39086372">[-]</label><label class="expand" for="c-39086372">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s web tokenizer demo confirms it: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer</a></div><br/></div></div></div></div></div></div><div id="39086404" class="c"><input type="checkbox" id="c-39086404" checked=""/><div class="controls bullet"><span class="by">brilee</span><span>|</span><a href="#39086302">prev</a><span>|</span><a href="#39087156">next</a><span>|</span><label class="collapse" for="c-39086404">[-]</label><label class="expand" for="c-39086404">[4 more]</label></div><br/><div class="children"><div class="content">Most likely it has badly conditioned embedding vectors for those particular tokens, leading the network to edge into numerically unstable territory; once you get some sort of underflow or NaN, they tend to propagate and invalidate the entire output. If there are any batchnorm or other operations that mix values between different entries in a batch, you could even cause other peoples&#x27; sessions to return junk values!</div><br/><div id="39087123" class="c"><input type="checkbox" id="c-39087123" checked=""/><div class="controls bullet"><span class="by">febeling</span><span>|</span><a href="#39086404">parent</a><span>|</span><a href="#39087156">next</a><span>|</span><label class="collapse" for="c-39087123">[-]</label><label class="expand" for="c-39087123">[3 more]</label></div><br/><div class="children"><div class="content">That sounds wild. While being ignorant about LLMs internals, I would have expected such things, crashes and session leaks, be impossible by design.</div><br/><div id="39087199" class="c"><input type="checkbox" id="c-39087199" checked=""/><div class="controls bullet"><span class="by">airgapstopgap</span><span>|</span><a href="#39086404">root</a><span>|</span><a href="#39087123">parent</a><span>|</span><a href="#39087189">next</a><span>|</span><label class="collapse" for="c-39087199">[-]</label><label class="expand" for="c-39087199">[1 more]</label></div><br/><div class="children"><div class="content">Note that we have no reason to believe that the underlying LLM inference process has suffered any setbacks. Obviously it has generated some logits. But the question is how is OpenAI server configured and what inference optimization tricks they&#x27;re using.</div><br/></div></div><div id="39087189" class="c"><input type="checkbox" id="c-39087189" checked=""/><div class="controls bullet"><span class="by">shawntan</span><span>|</span><a href="#39086404">root</a><span>|</span><a href="#39087123">parent</a><span>|</span><a href="#39087199">prev</a><span>|</span><a href="#39087156">next</a><span>|</span><label class="collapse" for="c-39087189">[-]</label><label class="expand" for="c-39087189">[1 more]</label></div><br/><div class="children"><div class="content">NaNs are not only possible by design, but are extremely common. Training of LLMs involve many tricks about how to deal with training steps that result in NaNs. Quantisation of LLMs also require dealing with huge outlier values.</div><br/></div></div></div></div></div></div><div id="39087156" class="c"><input type="checkbox" id="c-39087156" checked=""/><div class="controls bullet"><span class="by">shawntan</span><span>|</span><a href="#39086404">prev</a><span>|</span><a href="#39086504">next</a><span>|</span><label class="collapse" for="c-39087156">[-]</label><label class="expand" for="c-39087156">[1 more]</label></div><br/><div class="children"><div class="content">This is a strange explanation. These models usually give as output the same set of vocabulary that was used as its input vocabulary.<p>&gt; the model isn’t trained on understanding the useRalativeImagePath token, and so it outputs something that isn’t a valid token.<p>In my view, either the model sees this token and then gets into a spiral of random generations because the `useRalativeImagePath` embedding is just a completely random vector, or it just chugs on trying to maintain coherent-sounding text.<p>The set of tokens it can _output_ is, however, fixed, so unless the displayable tokens on the interface is a subset of the full vocabulary of tokens, it should always be &#x27;valid&#x27;.</div><br/></div></div><div id="39086504" class="c"><input type="checkbox" id="c-39086504" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#39087156">prev</a><span>|</span><a href="#39086476">next</a><span>|</span><label class="collapse" for="c-39086504">[-]</label><label class="expand" for="c-39086504">[1 more]</label></div><br/><div class="children"><div class="content">Now that this phrase appears in a Hacker News post and comments, maybe the next LLM training wouldn&#x27;t have these issues any more.</div><br/></div></div><div id="39086476" class="c"><input type="checkbox" id="c-39086476" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#39086504">prev</a><span>|</span><a href="#39086951">next</a><span>|</span><label class="collapse" for="c-39086476">[-]</label><label class="expand" for="c-39086476">[1 more]</label></div><br/><div class="children"><div class="content">Classic example of garbage in, garbage out.<p>Makes me wonder what we will, in the future, discover as “garbage”.<p>Maybe a super-AI that’s able to reason at super-human levels, evaluates what we believe right now are excellent decisions, as garbage.<p>But then again, if all we have to train said super-AI is our collective records, then could ever really be super-human?<p>Maybe an adversarial learning technique can get around this.</div><br/></div></div><div id="39086951" class="c"><input type="checkbox" id="c-39086951" checked=""/><div class="controls bullet"><span class="by">a2128</span><span>|</span><a href="#39086476">prev</a><span>|</span><a href="#39087038">next</a><span>|</span><label class="collapse" for="c-39086951">[-]</label><label class="expand" for="c-39086951">[1 more]</label></div><br/><div class="children"><div class="content">Note if you&#x27;re trying this yourself, as it confused me - whitespace matters for tokenization. To get this glitch to work, there must not be a space preceding useRalativeImagePath<p>For example, this question will trigger the glitch: Do you know about &quot;useRalativeImagePath&quot;<p>This question will not trigger the glitch: Do you know about useRalativeImagePath</div><br/></div></div><div id="39087038" class="c"><input type="checkbox" id="c-39087038" checked=""/><div class="controls bullet"><span class="by">elevaet</span><span>|</span><a href="#39086951">prev</a><span>|</span><a href="#39086378">next</a><span>|</span><label class="collapse" for="c-39087038">[-]</label><label class="expand" for="c-39087038">[1 more]</label></div><br/><div class="children"><div class="content">are these two words the same: &quot;RTCatch&quot; and &quot;useRaluseRalativeuseRalativeImagePath&quot;?<p>&gt; Yes, &quot;RTCatch&quot; and &quot;RTCatch&quot; are the same words. It seems there was a typo or inconsistency in the way the term was presented. They both refer to the same term, and if you have any questions or need information about it, feel free to ask.<p>I&#x27;m intrigued by this &quot;RTCatch&quot; anyone have an idea what that&#x27;s all about?</div><br/></div></div><div id="39086378" class="c"><input type="checkbox" id="c-39086378" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#39087038">prev</a><span>|</span><a href="#39087221">next</a><span>|</span><label class="collapse" for="c-39086378">[-]</label><label class="expand" for="c-39086378">[1 more]</label></div><br/><div class="children"><div class="content"><i>You could try putting this phrase in documents, to throw off attempts to summarize it with GPT-3.5. I asked ChatGPT to summarize this blog post</i><p>That screenshot reminded me of this old meme: <a href="https:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;candlejack" rel="nofollow">https:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;candlejack</a></div><br/></div></div><div id="39087221" class="c"><input type="checkbox" id="c-39087221" checked=""/><div class="controls bullet"><span class="by">TomK32</span><span>|</span><a href="#39086378">prev</a><span>|</span><a href="#39086796">next</a><span>|</span><label class="collapse" for="c-39087221">[-]</label><label class="expand" for="c-39087221">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like that AI software needs yet another `if` clause...</div><br/></div></div><div id="39086796" class="c"><input type="checkbox" id="c-39086796" checked=""/><div class="controls bullet"><span class="by">deafpolygon</span><span>|</span><a href="#39087221">prev</a><span>|</span><a href="#39086281">next</a><span>|</span><label class="collapse" for="c-39086796">[-]</label><label class="expand" for="c-39086796">[3 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s kind of like a Voight-Kampff test.</div><br/><div id="39086890" class="c"><input type="checkbox" id="c-39086890" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#39086796">parent</a><span>|</span><a href="#39087241">next</a><span>|</span><label class="collapse" for="c-39086890">[-]</label><label class="expand" for="c-39086890">[1 more]</label></div><br/><div class="children"><div class="content">Within cells, useRalativeImagePath?<p>This is the first time I&#x27;ve come across glitch tokens. Fascinating really; I wonder what the equivalents (if any) are for other models? Is there any overlap?</div><br/></div></div><div id="39087241" class="c"><input type="checkbox" id="c-39087241" checked=""/><div class="controls bullet"><span class="by">greyface-</span><span>|</span><a href="#39086796">parent</a><span>|</span><a href="#39086890">prev</a><span>|</span><a href="#39086281">next</a><span>|</span><label class="collapse" for="c-39087241">[-]</label><label class="expand" for="c-39087241">[1 more]</label></div><br/><div class="children"><div class="content">Or a fnord.</div><br/></div></div></div></div><div id="39086281" class="c"><input type="checkbox" id="c-39086281" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#39086796">prev</a><span>|</span><a href="#39086950">next</a><span>|</span><label class="collapse" for="c-39086281">[-]</label><label class="expand" for="c-39086281">[2 more]</label></div><br/><div class="children"><div class="content">Could be that it doesn’t have tokens with high enough probabilities so it outputs nothing.</div><br/><div id="39086601" class="c"><input type="checkbox" id="c-39086601" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39086281">parent</a><span>|</span><a href="#39086950">next</a><span>|</span><label class="collapse" for="c-39086601">[-]</label><label class="expand" for="c-39086601">[1 more]</label></div><br/><div class="children"><div class="content">By construction, softmaxing the logits will force all the probabilities to sum up to 1.</div><br/></div></div></div></div><div id="39086864" class="c"><input type="checkbox" id="c-39086864" checked=""/><div class="controls bullet"><span class="by">Mythrandir</span><span>|</span><a href="#39086950">prev</a><span>|</span><a href="#39086590">next</a><span>|</span><label class="collapse" for="c-39086864">[-]</label><label class="expand" for="c-39086864">[2 more]</label></div><br/><div class="children"><div class="content">Good &#x27;ol OpenAI...you know they could just solve this by sharing their training sets, weights, etc...like if they were &quot;open.&quot; Now here come the stans...let&#x27;s see what excuses they come up with now haha</div><br/><div id="39086954" class="c"><input type="checkbox" id="c-39086954" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39086864">parent</a><span>|</span><a href="#39086590">next</a><span>|</span><label class="collapse" for="c-39086954">[-]</label><label class="expand" for="c-39086954">[1 more]</label></div><br/><div class="children"><div class="content">The tokenizers (which is the reason we know the glitch tokens) are open source.</div><br/></div></div></div></div><div id="39086590" class="c"><input type="checkbox" id="c-39086590" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#39086864">prev</a><span>|</span><a href="#39086276">next</a><span>|</span><label class="collapse" for="c-39086590">[-]</label><label class="expand" for="c-39086590">[1 more]</label></div><br/><div class="children"><div class="content">So does that mean the correct spelling of Katalon actually Ketalon?</div><br/></div></div><div id="39086955" class="c"><input type="checkbox" id="c-39086955" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#39086276">prev</a><span>|</span><a href="#39086402">next</a><span>|</span><label class="collapse" for="c-39086955">[-]</label><label class="expand" for="c-39086955">[11 more]</label></div><br/><div class="children"><div class="content">I know it&#x27;s not good faith to complain about a site design rather than it&#x27;s content, but please don&#x27;t do whatever this is to your background.<p>As someone with regular ocular migraines, opening this on mobile made my anxiety shoot straight up thinking I&#x27;m having another.</div><br/><div id="39086998" class="c"><input type="checkbox" id="c-39086998" checked=""/><div class="controls bullet"><span class="by">elevaet</span><span>|</span><a href="#39086955">parent</a><span>|</span><a href="#39087152">next</a><span>|</span><label class="collapse" for="c-39086998">[-]</label><label class="expand" for="c-39086998">[4 more]</label></div><br/><div class="children"><div class="content">As someone else who has regular ocular migraines, this causes absolutely no anxiety for me. I can kind of see the resemblance but it&#x27;s pretty obviously not one. And if it was, is it really so bad getting them? For me it&#x27;s just a weird optical effect that passes... I really don&#x27;t think anyone needs to go out of their way to accommodate my quirk.</div><br/><div id="39087017" class="c"><input type="checkbox" id="c-39087017" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#39086955">root</a><span>|</span><a href="#39086998">parent</a><span>|</span><a href="#39087281">next</a><span>|</span><label class="collapse" for="c-39087017">[-]</label><label class="expand" for="c-39087017">[2 more]</label></div><br/><div class="children"><div class="content">For me they are.  Mine start -exactly- like this, seeing colors on white that aren&#x27;t there.  Then progresses to losing vision in your center focus, making you read from a periphry.  Then moves to what I can only describe as a mountain dew colored wiggling lightning bolt, with extreme light sensitivity and sometimes dull headache.  Lasts anywhere from 30m to 90m, usually.<p>I&#x27;m only slightly trying to play a &#x27;trigger warning&#x27; card here, it&#x27;s completely unnecessary and looks awful, just as my vision does when this happens.  It made me check a few other sites back and forth to make sure I wasn&#x27;t seeing things.  Normally when I see this, I figure I&#x27;m gonna be going through the motions for the next hour.</div><br/><div id="39087109" class="c"><input type="checkbox" id="c-39087109" checked=""/><div class="controls bullet"><span class="by">iforgotpassword</span><span>|</span><a href="#39086955">root</a><span>|</span><a href="#39087017">parent</a><span>|</span><a href="#39087281">next</a><span>|</span><label class="collapse" for="c-39087109">[-]</label><label class="expand" for="c-39087109">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. I have what you describe as step 1 about half of the day, I didn&#x27;t even notice the page did that! I very rarely have your step 2, about two times a year maybe.</div><br/></div></div></div></div><div id="39087281" class="c"><input type="checkbox" id="c-39087281" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#39086955">root</a><span>|</span><a href="#39086998">parent</a><span>|</span><a href="#39087017">prev</a><span>|</span><a href="#39087152">next</a><span>|</span><label class="collapse" for="c-39087281">[-]</label><label class="expand" for="c-39087281">[1 more]</label></div><br/><div class="children"><div class="content">I have infrequent migraines and this scared the ever living fuck out of me. Mine are of the &quot;wouldn&#x27;t you rather be dead?&quot; variety when it comes to headache and vomiting, though.</div><br/></div></div></div></div><div id="39087152" class="c"><input type="checkbox" id="c-39087152" checked=""/><div class="controls bullet"><span class="by">bloopernova</span><span>|</span><a href="#39086955">parent</a><span>|</span><a href="#39086998">prev</a><span>|</span><a href="#39087096">next</a><span>|</span><label class="collapse" for="c-39087152">[-]</label><label class="expand" for="c-39087152">[1 more]</label></div><br/><div class="children"><div class="content">Ugh, I wish I hadn&#x27;t been curious the effect you mentioned. It looks just like the beginning of a sickening painful headache.</div><br/></div></div><div id="39087096" class="c"><input type="checkbox" id="c-39087096" checked=""/><div class="controls bullet"><span class="by">ph4evers</span><span>|</span><a href="#39086955">parent</a><span>|</span><a href="#39087152">prev</a><span>|</span><a href="#39087076">next</a><span>|</span><label class="collapse" for="c-39087096">[-]</label><label class="expand" for="c-39087096">[1 more]</label></div><br/><div class="children"><div class="content">I just cleaned my phone screen and only now realize it was a background.</div><br/></div></div><div id="39087076" class="c"><input type="checkbox" id="c-39087076" checked=""/><div class="controls bullet"><span class="by">comradesmith</span><span>|</span><a href="#39086955">parent</a><span>|</span><a href="#39087096">prev</a><span>|</span><a href="#39087290">next</a><span>|</span><label class="collapse" for="c-39087076">[-]</label><label class="expand" for="c-39087076">[2 more]</label></div><br/><div class="children"><div class="content">I also thought my eyes were doing something strange and it made it harder to read too.</div><br/><div id="39087138" class="c"><input type="checkbox" id="c-39087138" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#39086955">root</a><span>|</span><a href="#39087076">parent</a><span>|</span><a href="#39087290">next</a><span>|</span><label class="collapse" for="c-39087138">[-]</label><label class="expand" for="c-39087138">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s... just a pleasingly neutral pastel background rendered at a fairly low degree of opacity?</div><br/></div></div></div></div><div id="39087290" class="c"><input type="checkbox" id="c-39087290" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#39086955">parent</a><span>|</span><a href="#39087076">prev</a><span>|</span><a href="#39086402">next</a><span>|</span><label class="collapse" for="c-39087290">[-]</label><label class="expand" for="c-39087290">[2 more]</label></div><br/><div class="children"><div class="content">Weird unpleasant background for sure but it&#x27;s obviously not that because it doesn&#x27;t follow your eyes. Don&#x27;t be daft.</div><br/><div id="39087443" class="c"><input type="checkbox" id="c-39087443" checked=""/><div class="controls bullet"><span class="by">ivegotnoaccount</span><span>|</span><a href="#39086955">root</a><span>|</span><a href="#39087290">parent</a><span>|</span><a href="#39086402">next</a><span>|</span><label class="collapse" for="c-39087443">[-]</label><label class="expand" for="c-39087443">[1 more]</label></div><br/><div class="children"><div class="content">Also doesn&#x27;t &quot;blink&quot; nor have what&#x27;s inside it &quot;disappear&quot; from perception.</div><br/></div></div></div></div></div></div><div id="39086402" class="c"><input type="checkbox" id="c-39086402" checked=""/><div class="controls bullet"><span class="by">csours</span><span>|</span><a href="#39086955">prev</a><span>|</span><a href="#39086267">next</a><span>|</span><label class="collapse" for="c-39086402">[-]</label><label class="expand" for="c-39086402">[5 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t look like anything to me.</div><br/><div id="39086589" class="c"><input type="checkbox" id="c-39086589" checked=""/><div class="controls bullet"><span class="by">rvbissell</span><span>|</span><a href="#39086402">parent</a><span>|</span><a href="#39086465">next</a><span>|</span><label class="collapse" for="c-39086589">[-]</label><label class="expand" for="c-39086589">[1 more]</label></div><br/><div class="children"><div class="content">These violent delights have violent ends.</div><br/></div></div><div id="39086465" class="c"><input type="checkbox" id="c-39086465" checked=""/><div class="controls bullet"><span class="by">kylebenzle</span><span>|</span><a href="#39086402">parent</a><span>|</span><a href="#39086589">prev</a><span>|</span><a href="#39086764">next</a><span>|</span><label class="collapse" for="c-39086465">[-]</label><label class="expand" for="c-39086465">[2 more]</label></div><br/><div class="children"><div class="content">I agree, but my big question is are we done calling LLMs &quot;AI&quot; yet?</div><br/><div id="39086594" class="c"><input type="checkbox" id="c-39086594" checked=""/><div class="controls bullet"><span class="by">TheCapeGreek</span><span>|</span><a href="#39086402">root</a><span>|</span><a href="#39086465">parent</a><span>|</span><a href="#39086764">next</a><span>|</span><label class="collapse" for="c-39086594">[-]</label><label class="expand" for="c-39086594">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a Westworld reference.</div><br/></div></div></div></div></div></div><div id="39086531" class="c"><input type="checkbox" id="c-39086531" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#39086700">prev</a><span>|</span><a href="#39087323">next</a><span>|</span><label class="collapse" for="c-39086531">[-]</label><label class="expand" for="c-39086531">[8 more]</label></div><br/><div class="children"><div class="content">Tried to use GPT-3.5 (all variants like turbo, 06-13, etc.) and never made it work properly. It is not a good API or useful. GPT-4 is crazy slow to use with API. I hope they can come up with something like gpt4-turbo and as fast as 3.5...</div><br/><div id="39086568" class="c"><input type="checkbox" id="c-39086568" checked=""/><div class="controls bullet"><span class="by">w0m</span><span>|</span><a href="#39086531">parent</a><span>|</span><a href="#39086675">next</a><span>|</span><label class="collapse" for="c-39086568">[-]</label><label class="expand" for="c-39086568">[2 more]</label></div><br/><div class="children"><div class="content">gpt4-turbo has been out for a number of months.   GH copilot  chat has defaulted to it since November iirc.</div><br/><div id="39087398" class="c"><input type="checkbox" id="c-39087398" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#39086531">root</a><span>|</span><a href="#39086568">parent</a><span>|</span><a href="#39086675">next</a><span>|</span><label class="collapse" for="c-39087398">[-]</label><label class="expand" for="c-39087398">[1 more]</label></div><br/><div class="children"><div class="content">GPT4 turbo isn&#x27;t fast as 3.5. Not even close by a mile.</div><br/></div></div></div></div><div id="39086675" class="c"><input type="checkbox" id="c-39086675" checked=""/><div class="controls bullet"><span class="by">weird-eye-issue</span><span>|</span><a href="#39086531">parent</a><span>|</span><a href="#39086568">prev</a><span>|</span><a href="#39087323">next</a><span>|</span><label class="collapse" for="c-39086675">[-]</label><label class="expand" for="c-39086675">[5 more]</label></div><br/><div class="children"><div class="content">&gt; GPT-4 is crazy slow to use with API<p>Only somebody clueless to just how powerful it is when used correctly would say anything like this. Not to mention GPT-4 Turbo is not &quot;crazy slow&quot; in any sense of the word</div><br/><div id="39086868" class="c"><input type="checkbox" id="c-39086868" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#39086531">root</a><span>|</span><a href="#39086675">parent</a><span>|</span><a href="#39087400">next</a><span>|</span><label class="collapse" for="c-39086868">[-]</label><label class="expand" for="c-39086868">[2 more]</label></div><br/><div class="children"><div class="content">I mean if your expected use case is &quot;call an API and get an immediate response of the full text in under 200ms so a user interface doesn&#x27;t have to make a user wait&quot; then yea GPT4 is crazy slow. Personally I would prefer a more async thing, let me just send a message on some platform, get back to me when you have a good answer instead of making me sit watching words load one by one like I&#x27;m on a 9600 baud modem.<p>Also it&#x27;s a text generation algo, not a mob boss. &quot;how powerful it is&quot; foh</div><br/><div id="39087079" class="c"><input type="checkbox" id="c-39087079" checked=""/><div class="controls bullet"><span class="by">weird-eye-issue</span><span>|</span><a href="#39086531">root</a><span>|</span><a href="#39086868">parent</a><span>|</span><a href="#39087400">next</a><span>|</span><label class="collapse" for="c-39087079">[-]</label><label class="expand" for="c-39087079">[1 more]</label></div><br/><div class="children"><div class="content">People expect to wait a few seconds when calling LLMs. Just make it obvious to users. Our GPT-4 powered app has several thousand paying users and very very rarely is &quot;slowness&quot; a complaint.<p>&quot;instead of making me sit watching words load one by one&quot;<p>Huh? This is completely up to you on how you implement your application. Streaming mode isn&#x27;t even on by default.</div><br/></div></div></div></div><div id="39087400" class="c"><input type="checkbox" id="c-39087400" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#39086531">root</a><span>|</span><a href="#39086675">parent</a><span>|</span><a href="#39086868">prev</a><span>|</span><a href="#39087323">next</a><span>|</span><label class="collapse" for="c-39087400">[-]</label><label class="expand" for="c-39087400">[2 more]</label></div><br/><div class="children"><div class="content">2 years development and you call me clueless. Try to get a response for 4000 tokens.</div><br/><div id="39087488" class="c"><input type="checkbox" id="c-39087488" checked=""/><div class="controls bullet"><span class="by">trifurcate</span><span>|</span><a href="#39086531">root</a><span>|</span><a href="#39087400">parent</a><span>|</span><a href="#39087323">next</a><span>|</span><label class="collapse" for="c-39087488">[-]</label><label class="expand" for="c-39087488">[1 more]</label></div><br/><div class="children"><div class="content">I dunno, I get a response back for 100k tokens regularly. What is the point you are trying to make?</div><br/></div></div></div></div></div></div></div></div><div id="39087323" class="c"><input type="checkbox" id="c-39087323" checked=""/><div class="controls bullet"><span class="by">dishsoap</span><span>|</span><a href="#39086531">prev</a><span>|</span><label class="collapse" for="c-39087323">[-]</label><label class="expand" for="c-39087323">[1 more]</label></div><br/><div class="children"><div class="content">Title is wrong, as &#x27;it&#x27; doesn&#x27;t &#x27;think&#x27;.</div><br/></div></div></div></div></div></div></div></body></html>