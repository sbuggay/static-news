<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725526862753" as="style"/><link rel="stylesheet" href="styles.css?v=1725526862753"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lantern.dev/blog/pgvector-storage">Understanding Pgvector&#x27;s HNSW Index Storage in Postgres</a> <span class="domain">(<a href="https://lantern.dev">lantern.dev</a>)</span></div><div class="subtext"><span>varik77</span> | <span>10 comments</span></div><br/><div><div id="41452939" class="c"><input type="checkbox" id="c-41452939" checked=""/><div class="controls bullet"><span class="by">jadbox</span><span>|</span><a href="#41454427">next</a><span>|</span><label class="collapse" for="c-41452939">[-]</label><label class="expand" for="c-41452939">[4 more]</label></div><br/><div class="children"><div class="content">Vector searching had strange quirks where searching for &quot;cat&quot; would return mostly a lot of paragraphs unrelated to the word. I was using 3072 length for OAI text-embedding-3-large. Each entry was roughly 1-2 paragraphs. For my recent project, I found that PGroonga was more reliable for full text document lookup (with some fuzzy matching support).</div><br/><div id="41453217" class="c"><input type="checkbox" id="c-41453217" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#41452939">parent</a><span>|</span><a href="#41454616">next</a><span>|</span><label class="collapse" for="c-41453217">[-]</label><label class="expand" for="c-41453217">[2 more]</label></div><br/><div class="children"><div class="content">This could of course be a bug, but it&#x27;s worth noting that vector searching in general is a semantic (&quot;meaning based&quot;) search technique, but it doesn&#x27;t operate on the actual text, it operates on the resulting embedding so it may well make sense to include a (possibly fuzzy) full text search as well to catch literal instances of the text if that&#x27;s what you actually need.<p>That said, the particular example you give may be either a configuration problem or just that &quot;cat&quot; is a particularly bad choice of word to use for a vector search in your corpus.<p>HNSW[1] is an approximate nearest neighbour search technique. So if you visualise the embedding as distilling your documents down to a set of numbers, this vector forms the coordinates of a point in a high-dimensional vector space. HNSW is going to take the word &quot;cat&quot; in your example, embed that, and find what are probably the closest other vectors (representing documents) in that space by your distance metric.[2]<p>Now, it&#x27;s easy to imagine the problem - if your document corpus is about something very unrelated to cats (like say your corpus is a bunch of programming books), the results of this search are going to be basically just random, because you have a big blob of embedded documents in your corpus which are relatively close together and your search term embeds way off in empty space and therefore the distance from the search term to any given document is extremely large.  If you were to search a topic that is reflected in your corpus, your search term could embed right in the middle of that blob and the distances would be much more meaningful meaning the results are likely to be more intuitive and useful.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1603.09320" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1603.09320</a> is I think the original paper that introduced the technique<p>[2] The probably&#x2F;approximately get out is what allows the computational complexity of HNSW to stay reasonable even if the corpus is large</div><br/><div id="41454289" class="c"><input type="checkbox" id="c-41454289" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#41452939">root</a><span>|</span><a href="#41453217">parent</a><span>|</span><a href="#41454616">next</a><span>|</span><label class="collapse" for="c-41454289">[-]</label><label class="expand" for="c-41454289">[1 more]</label></div><br/><div class="children"><div class="content">yeah usually much better results getting a list of ~10 fuzzy keyword search results, 10 semantic&#x2F;embeddings results, and using something like Cohere rerank (or just a cheap GPT model) to choose the best 5-10 results from the pile</div><br/></div></div></div></div><div id="41454616" class="c"><input type="checkbox" id="c-41454616" checked=""/><div class="controls bullet"><span class="by">mhuffman</span><span>|</span><a href="#41452939">parent</a><span>|</span><a href="#41453217">prev</a><span>|</span><a href="#41454427">next</a><span>|</span><label class="collapse" for="c-41454616">[-]</label><label class="expand" for="c-41454616">[1 more]</label></div><br/><div class="children"><div class="content">Augmenting your search with fuzzy matching is a good idea. You might also try embedding with smaller chunk sizes (5-8 sentences) at a time. The paragraph breaks will usually not be a problem. The bigger the chunk text, the more likely that the attention in llm embeddings can downplay the significance of a word. You can also use individual sentences with something like FastText to do very rapid embeddings with a smaller vector length and great quality (imho) with higher precision. Also much easier to run in production without paying for a GPU server or API tokens.</div><br/></div></div></div></div><div id="41454427" class="c"><input type="checkbox" id="c-41454427" checked=""/><div class="controls bullet"><span class="by">simedw</span><span>|</span><a href="#41452939">prev</a><span>|</span><a href="#41454035">next</a><span>|</span><label class="collapse" for="c-41454427">[-]</label><label class="expand" for="c-41454427">[2 more]</label></div><br/><div class="children"><div class="content">Very interesting breakdown, OP have you deep dived in pgvectorscale as well?</div><br/><div id="41454568" class="c"><input type="checkbox" id="c-41454568" checked=""/><div class="controls bullet"><span class="by">varik77</span><span>|</span><a href="#41454427">parent</a><span>|</span><a href="#41454035">next</a><span>|</span><label class="collapse" for="c-41454568">[-]</label><label class="expand" for="c-41454568">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! Haven’t done it yet, but afaik the pgvectorscale uses StreamingDiskANN which should have different layout than HNSW.</div><br/></div></div></div></div><div id="41454035" class="c"><input type="checkbox" id="c-41454035" checked=""/><div class="controls bullet"><span class="by">mkesper</span><span>|</span><a href="#41454427">prev</a><span>|</span><label class="collapse" for="c-41454035">[-]</label><label class="expand" for="c-41454035">[3 more]</label></div><br/><div class="children"><div class="content">I wanted to read this article. Gave up because of absolutely missing contrast. Please, if you publish something, use black (#000) for text and almost white for background and not darker grey on a lighter grey background.</div><br/><div id="41454471" class="c"><input type="checkbox" id="c-41454471" checked=""/><div class="controls bullet"><span class="by">varik77</span><span>|</span><a href="#41454035">parent</a><span>|</span><a href="#41454172">next</a><span>|</span><label class="collapse" for="c-41454471">[-]</label><label class="expand" for="c-41454471">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback, we slightly increased the contrast if it helps.</div><br/></div></div></div></div></div></div></div></div></div></body></html>