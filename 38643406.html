<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702630857248" as="style"/><link rel="stylesheet" href="styles.css?v=1702630857248"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://paulrobichaux.com/2023/12/14/first-look-at-microsoft-365-copilot/">First look at Microsoft 365 Copilot</a> <span class="domain">(<a href="https://paulrobichaux.com">paulrobichaux.com</a>)</span></div><div class="subtext"><span>gbacon</span> | <span>6 comments</span></div><br/><div><div id="38652242" class="c"><input type="checkbox" id="c-38652242" checked=""/><div class="controls bullet"><span class="by">_pdp_</span><span>|</span><a href="#38652028">next</a><span>|</span><label class="collapse" for="c-38652242">[-]</label><label class="expand" for="c-38652242">[3 more]</label></div><br/><div class="children"><div class="content">There is a confusion between hallucination and lack of information. RAGs work by finding the top N answers given some query, and then, based on this information, the underlying model tries to make up some text. This is unreasonable, and it will only work out of the box for the most straightforward use cases - i.e., chatting with a single document, but there are limitations.<p>So, I am not surprised that Copilot cannot answer information that is readily available in the right place. It is also unlikely that one can find that document, among many others, on the first try unless one is quoting a specific phrase.<p>The fundamental architecture needs to change. Copilot needs to act more like an agent - i.e., perform multi-step research to find this information and do it fast.</div><br/><div id="38652315" class="c"><input type="checkbox" id="c-38652315" checked=""/><div class="controls bullet"><span class="by">zacmps</span><span>|</span><a href="#38652242">parent</a><span>|</span><a href="#38652028">next</a><span>|</span><label class="collapse" for="c-38652315">[-]</label><label class="expand" for="c-38652315">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s possible to build RAG pipelines that support answering complex questions over multiple documents, and I don&#x27;t think I would say the whole architecture needs to change.<p>Doing it fast is another story, LLMs are pretty high latency at the moment.</div><br/><div id="38652322" class="c"><input type="checkbox" id="c-38652322" checked=""/><div class="controls bullet"><span class="by">_pdp_</span><span>|</span><a href="#38652242">root</a><span>|</span><a href="#38652315">parent</a><span>|</span><a href="#38652028">next</a><span>|</span><label class="collapse" for="c-38652322">[-]</label><label class="expand" for="c-38652322">[1 more]</label></div><br/><div class="children"><div class="content">If you have any examples I can go through it will be greatly appreciated. My main concern is that all RAGs just look for the top N best matching results. That does not mean that the information is in there.</div><br/></div></div></div></div></div></div><div id="38652028" class="c"><input type="checkbox" id="c-38652028" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#38652242">prev</a><span>|</span><a href="#38652084">next</a><span>|</span><label class="collapse" for="c-38652028">[-]</label><label class="expand" for="c-38652028">[1 more]</label></div><br/><div class="children"><div class="content">RAG does not guarantee elimination of hallucination it seems. If the foundation model&#x27;s training outweighs what it is in the external source, it will still hallucinate.<p>Interestingly ChatGPT-4 gets it right. I tried your first question with ChatGPT-4:<p><i>User: what’s the single-engine service ceiling of a Baron 55<p>ChatGPT: The single-engine service ceiling of a Beechcraft Baron 55 is approximately 7,000 feet. This is the maximum altitude at which the aircraft can maintain a specified rate of climb, usually 100 feet per minute, with one engine inoperative.</i></div><br/></div></div><div id="38652084" class="c"><input type="checkbox" id="c-38652084" checked=""/><div class="controls bullet"><span class="by">Neil44</span><span>|</span><a href="#38652028">prev</a><span>|</span><label class="collapse" for="c-38652084">[-]</label><label class="expand" for="c-38652084">[1 more]</label></div><br/><div class="children"><div class="content">We randomly have it enabled on our 365 tenant (we&#x27;re an ms partner) and I tried it the other day for help with a Power Automate script. It had a good stab at the problem but didn&#x27;t quite get there. Maybe with more experience at both prompting and power automate I would have had better luck with it.</div><br/></div></div></div></div></div></div></div></body></html>