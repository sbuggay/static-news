<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733216467547" as="style"/><link rel="stylesheet" href="styles.css?v=1733216467547"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.worldlabs.ai/blog">World Labs: Generate 3D worlds from a single image</a> <span class="domain">(<a href="https://www.worldlabs.ai">www.worldlabs.ai</a>)</span></div><div class="subtext"><span>dmarcos</span> | <span>103 comments</span></div><br/><div><div id="42298159" class="c"><input type="checkbox" id="c-42298159" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#42298374">next</a><span>|</span><label class="collapse" for="c-42298159">[-]</label><label class="expand" for="c-42298159">[36 more]</label></div><br/><div class="children"><div class="content">Once you try the demos, the animated image at the top feels misleading. Each segment cuts at just the right point to make you think you’d be able continue exploring these vast worlds, but in practice you can only walk a couple os steps before hitting an invisible wall, which becomes more frustrating than not being able to move at all. It feels like being trapped in a box. My reaction went from impressed to disappointed <i>fast</i>.<p>I get these are early steps, but they oversold it.</div><br/><div id="42298370" class="c"><input type="checkbox" id="c-42298370" checked=""/><div class="controls bullet"><span class="by">Hakkin</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42300410">next</a><span>|</span><label class="collapse" for="c-42298370">[-]</label><label class="expand" for="c-42298370">[10 more]</label></div><br/><div class="children"><div class="content">You can bypass the &quot;Out of bound&quot; message by setting a Javascript breakpoint after
`let t = JSON.parse(d[e].config_str)`
and then run 
`Object.values(t.camera.presets).map(o=&gt;o.max_distance=50&amp;&amp;o)`
 in the console.<p>It breaks down pretty quickly once you get outside the default bounds, as expected, though.</div><br/><div id="42299404" class="c"><input type="checkbox" id="c-42299404" checked=""/><div class="controls bullet"><span class="by">jfactorial</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298370">parent</a><span>|</span><a href="#42298425">next</a><span>|</span><label class="collapse" for="c-42299404">[-]</label><label class="expand" for="c-42299404">[8 more]</label></div><br/><div class="children"><div class="content">I wonder how much of the remaining work boils down to generating a new scene based on the camera&#x27;s POV when the player hits one of the bounds, and keeping these generated scenes in a tree structure, joining scenes at boundaries.</div><br/><div id="42300211" class="c"><input type="checkbox" id="c-42300211" checked=""/><div class="controls bullet"><span class="by">lukev</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42299404">parent</a><span>|</span><a href="#42300369">next</a><span>|</span><label class="collapse" for="c-42300211">[-]</label><label class="expand" for="c-42300211">[1 more]</label></div><br/><div class="children"><div class="content">Yes, and you wouldn&#x27;t even need to do it in realtime as a user walks around.<p>Generate incrementally using a pathfinding system for a bot to move around and &quot;create the world&quot; as it goes, as if a Google street view car followed the philosophy of George Berkeley.</div><br/></div></div><div id="42300369" class="c"><input type="checkbox" id="c-42300369" checked=""/><div class="controls bullet"><span class="by">tayistay</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42299404">parent</a><span>|</span><a href="#42300211">prev</a><span>|</span><a href="#42302218">next</a><span>|</span><label class="collapse" for="c-42300369">[-]</label><label class="expand" for="c-42300369">[5 more]</label></div><br/><div class="children"><div class="content">I suspect the problem there is that the multiple paths to a new location will not yield consistent results.</div><br/><div id="42300578" class="c"><input type="checkbox" id="c-42300578" checked=""/><div class="controls bullet"><span class="by">kbutler</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300369">parent</a><span>|</span><a href="#42302218">next</a><span>|</span><label class="collapse" for="c-42300578">[-]</label><label class="expand" for="c-42300578">[4 more]</label></div><br/><div class="children"><div class="content">Yes, infinite exploration, but inconsistent</div><br/><div id="42303255" class="c"><input type="checkbox" id="c-42303255" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300578">parent</a><span>|</span><a href="#42303906">next</a><span>|</span><label class="collapse" for="c-42303255">[-]</label><label class="expand" for="c-42303255">[1 more]</label></div><br/><div class="children"><div class="content">Like a bizarro cousin of loop closure in SLAM— which is recognizing when you&#x27;ve found a different path to a place you&#x27;ve been before.<p>Except this time there is no underlying consistent world, so it would be up to the algorithm to use dead reckoning or some kind of coordinate system to recognize that you&#x27;re approaching a place you&#x27;ve &quot;been&quot; before, and incorporate whatever you found there into the new scenes it produces.</div><br/></div></div><div id="42303906" class="c"><input type="checkbox" id="c-42303906" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300578">parent</a><span>|</span><a href="#42303255">prev</a><span>|</span><a href="#42301116">next</a><span>|</span><label class="collapse" for="c-42303906">[-]</label><label class="expand" for="c-42303906">[1 more]</label></div><br/><div class="children"><div class="content">So… very boring?<p>Consistent inconsistency gets old very very fast.</div><br/></div></div><div id="42301116" class="c"><input type="checkbox" id="c-42301116" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300578">parent</a><span>|</span><a href="#42303906">prev</a><span>|</span><a href="#42302218">next</a><span>|</span><label class="collapse" for="c-42301116">[-]</label><label class="expand" for="c-42301116">[1 more]</label></div><br/><div class="children"><div class="content">The same as a dream</div><br/></div></div></div></div></div></div></div></div><div id="42298425" class="c"><input type="checkbox" id="c-42298425" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298370">parent</a><span>|</span><a href="#42299404">prev</a><span>|</span><a href="#42300410">next</a><span>|</span><label class="collapse" for="c-42298425">[-]</label><label class="expand" for="c-42298425">[1 more]</label></div><br/><div class="children"><div class="content">Good hack!</div><br/></div></div></div></div><div id="42300410" class="c"><input type="checkbox" id="c-42300410" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42298370">prev</a><span>|</span><a href="#42298210">next</a><span>|</span><label class="collapse" for="c-42300410">[-]</label><label class="expand" for="c-42300410">[6 more]</label></div><br/><div class="children"><div class="content">I first got irritated a bit by this as well, but then the game Myst came to mind.<p>So I&#x27;m willing to accept the limitation, and at this point we know that this can only get better. Next I thought about the likelihood of Nvidia releasing an AI game engine, or more of a renderer, fully AI based. It should be happening within the next 10 years.<p>Imagine creating a game by describing scenes, like the ones in the article, with a good morphing technology between scenes, so that the transitions between them are like auto-generated scenes which are just as playable.<p>The effects shown in the article were very interesting, like the ripple, sonar or wave. The wave made me think about how trippy games could get in the future, more extreme versions of the Subnautica video [0] which was released last month.<p>We could generate video games which would periodically slip into hallucinations, a thing that is barely doable today, akin to shader effects in Far Cry or other games when the player gets poisoned.<p>Fiebertraum engine.<p>[0] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AJaV92DXN0s&amp;t=218s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AJaV92DXN0s&amp;t=218s</a></div><br/><div id="42300886" class="c"><input type="checkbox" id="c-42300886" checked=""/><div class="controls bullet"><span class="by">Jach</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300410">parent</a><span>|</span><a href="#42301520">next</a><span>|</span><label class="collapse" for="c-42300886">[-]</label><label class="expand" for="c-42300886">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s &quot;old news&quot; I guess at this point, but the AI Minecraft demo (every frame generated from the previous frame, no traditional &quot;engine&quot;) is still the most impressive thing to me in this space <a href="https:&#x2F;&#x2F;oasis.us.decart.ai&#x2F;welcome" rel="nofollow">https:&#x2F;&#x2F;oasis.us.decart.ai&#x2F;welcome</a> There are some interesting &quot;speed runs&quot; people have been doing like <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3UaVQ5_euw8" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3UaVQ5_euw8</a><p>We might all be dead in 10 years, but with big tech companies making their plays, all the VC money flowing in to new startups, and nuclear plants being brought online to power the next base model training runs, there&#x27;s room for a little mild entertainment like these sorts of gimmicks in the next 3 years or so. I doubt anything that comes of it will top even my top 15 video games list though.</div><br/><div id="42300942" class="c"><input type="checkbox" id="c-42300942" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300886">parent</a><span>|</span><a href="#42301520">next</a><span>|</span><label class="collapse" for="c-42300942">[-]</label><label class="expand" for="c-42300942">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We might all be dead in 10 years, but with big tech companies making their plays, all the VC money flowing in to new startups, and nuclear plants being brought online to power the next base model training runs, there&#x27;s room for a little mild entertainment like these sorts of gimmicks in the next 3 years or so. I doubt anything that comes of it will top even my top 15 video games list though.<p>That’s a contestant for the most depressing tradeoff ever. “Yeah, we’ll all die in agony way before our time, but at least we got to play with a neat but ultimately underwhelming tool for a bit”.</div><br/></div></div></div></div><div id="42301520" class="c"><input type="checkbox" id="c-42301520" checked=""/><div class="controls bullet"><span class="by">lancesells</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300410">parent</a><span>|</span><a href="#42300886">prev</a><span>|</span><a href="#42300722">next</a><span>|</span><label class="collapse" for="c-42301520">[-]</label><label class="expand" for="c-42301520">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Imagine creating a game by describing scenes, like the ones in the article, with a good morphing technology between scenes, so that the transitions between them are like auto-generated scenes which are just as playable.<p>Why do you think this game would be good? I&#x27;m not a game maker but the visual layer is not the reason people like or enjoy a game (ex: nintendo). There are teams of professionals making games today that range from awful to great. I get that there are indie games made by a single person that will benefit from generated graphics, but asset creation seems to be a really small part of it.</div><br/></div></div><div id="42300722" class="c"><input type="checkbox" id="c-42300722" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300410">parent</a><span>|</span><a href="#42301520">prev</a><span>|</span><a href="#42300496">next</a><span>|</span><label class="collapse" for="c-42300722">[-]</label><label class="expand" for="c-42300722">[1 more]</label></div><br/><div class="children"><div class="content">You’re describing a pie in the sky. A vision. Not reality. We have been burned many times already, nothing in this field is a given.<p>&gt; at this point we know that this can only get better.<p>We don’t <i>know</i> that. It will probably get better, but will it be better <i>enough</i>? No one knows.<p>&gt; It should be happening within the next 10 years.<p>Every revolution in tech is always ten years away. By now that’s a meme. Saying something is ten years away is about as valuable as saying one has no idea how doable it is.<p>&gt; Imagine<p>Yes, I understand the goal. Everyone does, it’s not complicated. We can all imagine Star Trek technology, we all know where the compass is pointed, that doesn’t make it a given.<p>In fact, the one thing we can say for sure about imagining how everything will be great in ten years is that we routinely fail to predict the bad parts. We don’t live in fantasy land, advancements in tech are routinely used for detrimental reasons.</div><br/></div></div><div id="42300496" class="c"><input type="checkbox" id="c-42300496" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300410">parent</a><span>|</span><a href="#42300722">prev</a><span>|</span><a href="#42298210">next</a><span>|</span><label class="collapse" for="c-42300496">[-]</label><label class="expand" for="c-42300496">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. That&#x27;s the attitude! It&#x27;s all about playing around the constraints. Tech has limitations? Yes, but also opens tons of new possibilities.</div><br/></div></div></div></div><div id="42298210" class="c"><input type="checkbox" id="c-42298210" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42300410">prev</a><span>|</span><a href="#42299249">next</a><span>|</span><label class="collapse" for="c-42298210">[-]</label><label class="expand" for="c-42298210">[9 more]</label></div><br/><div class="children"><div class="content">In the looking ahead section of the post it says:<p>“We are hard at work improving the size and fidelity of our generated worlds”<p>I imagine the further you move from the input image, the more the model has to make up information and the harder to keep it consistent. Similar problem with video generation.</div><br/><div id="42298270" class="c"><input type="checkbox" id="c-42298270" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298210">parent</a><span>|</span><a href="#42300153">next</a><span>|</span><label class="collapse" for="c-42298270">[-]</label><label class="expand" for="c-42298270">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I imagine the further you move from the input image, the more the model has to make up information and the harder to keep it consistent. Similar problem with video generation.<p>Which is the same thing as saying this may turn out to be a dud, like so many other things in tech and the current crop of what we’re calling AI.<p>Like I said, I get this is an early demo, but don’t oversell it. They could’ve started by being honest and clarifying they’re generating <i>scenes</i> (or whatever you want to call them, but they’re <i>definitely</i> not “worlds”), letting you play a bit, then explain the potential and progress. As it is, it just sounds like they want to immediately wow people with a fantasy and it detracts from what they do have.</div><br/><div id="42298299" class="c"><input type="checkbox" id="c-42298299" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298270">parent</a><span>|</span><a href="#42298363">next</a><span>|</span><label class="collapse" for="c-42298299">[-]</label><label class="expand" for="c-42298299">[1 more]</label></div><br/><div class="children"><div class="content">Fair criticism. I’m also not a fan of hyperbole. Still find World Labs stuff super intriguing and I’m optimist about them to be able to fulfill the vision.</div><br/></div></div><div id="42298363" class="c"><input type="checkbox" id="c-42298363" checked=""/><div class="controls bullet"><span class="by">add-sub-mul-div</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298270">parent</a><span>|</span><a href="#42298299">prev</a><span>|</span><a href="#42300153">next</a><span>|</span><label class="collapse" for="c-42298363">[-]</label><label class="expand" for="c-42298363">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they think it&#x27;s a good deal, producing some oversold tech demos in exchange for a decade&#x27;s worth of funding and not having to produce anything more than an &quot;Our Incredible Journey&quot; letter at the end. The prospect of replacing all human labor has made it easier than ever to run the grift on investors in this time of peak FOMO.</div><br/></div></div></div></div><div id="42300153" class="c"><input type="checkbox" id="c-42300153" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298210">parent</a><span>|</span><a href="#42298270">prev</a><span>|</span><a href="#42299054">next</a><span>|</span><label class="collapse" for="c-42300153">[-]</label><label class="expand" for="c-42300153">[2 more]</label></div><br/><div class="children"><div class="content">In general, it depends on how much the model ends up &quot;understanding&quot; the input. (I use &quot;understand&quot; here in the sense some would claim SOTA LLMs do.)<p>You can imagine this as a spectrum. On the one end you have models that, at each output pixel, try to predict pixels that are locally similar to ones in previous frame; on the other end, you could imagine models that &quot;parse&quot; the initial input image to understand the scene - objects (buildings, doors, people, etc.) and their relationships, and separately, the style with which they&#x27;re painted, and use that to extrapolate further frames[0]. The latter would obviously fare better, remaining stylistically consistent for longer.<p>(This model claims to be of the second kind.)<p>The way I see it: a human could do it[1], so there&#x27;s no reason an ML model wouldn&#x27;t be able to.<p>--<p>[0] - Brute-force approach: 1) &quot;style-untransfer&quot; the input, i.e. style-transfer to some common style, e.g. photorealistic or sketch, 2) extrapolate the style-untransfered image, and 3) style-transfer result back using original input as style reference. Feels like it should work somewhat okay-ish; wonder if anyone tried that.<p>[1] - And the hard part wouldn&#x27;t be extrapolating the scene, but rather keeping the style.</div><br/><div id="42300630" class="c"><input type="checkbox" id="c-42300630" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42300153">parent</a><span>|</span><a href="#42299054">next</a><span>|</span><label class="collapse" for="c-42300630">[-]</label><label class="expand" for="c-42300630">[1 more]</label></div><br/><div class="children"><div class="content">This indeed looks more like photogrammetry than a diffusion model predicting the next frame. There&#x27;s 3D information extracted from the input image and likely additional generated poses that allow reconstructing the scene with gaussian splats. Not sure how much segmentation (understanding of each part of the scene) is going on. Probably not much if I have to guess.</div><br/></div></div></div></div><div id="42299054" class="c"><input type="checkbox" id="c-42299054" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298210">parent</a><span>|</span><a href="#42300153">prev</a><span>|</span><a href="#42298670">next</a><span>|</span><label class="collapse" for="c-42299054">[-]</label><label class="expand" for="c-42299054">[2 more]</label></div><br/><div class="children"><div class="content">Models are really great at making stuff up though. And video models already have very good consistency over thousands of frames. It seems like larger worlds shouldn&#x27;t be a huge hurdle. I wonder why they launched without that, as this doesn&#x27;t seem much better than previous work.</div><br/><div id="42299096" class="c"><input type="checkbox" id="c-42299096" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42299054">parent</a><span>|</span><a href="#42298670">next</a><span>|</span><label class="collapse" for="c-42299096">[-]</label><label class="expand" for="c-42299096">[1 more]</label></div><br/><div class="children"><div class="content">To be fair they haven’t launched they are showing progress and laying out the vision.<p>What previous work are you referring to?</div><br/></div></div></div></div></div></div><div id="42301113" class="c"><input type="checkbox" id="c-42301113" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42299249">prev</a><span>|</span><a href="#42299766">next</a><span>|</span><label class="collapse" for="c-42301113">[-]</label><label class="expand" for="c-42301113">[2 more]</label></div><br/><div class="children"><div class="content">Obviously, the generation has to stop at some point and obviously from any key image you could continue generating if you had unlimited GPU, which I’m sorry they didn’t provide for you.</div><br/><div id="42301407" class="c"><input type="checkbox" id="c-42301407" checked=""/><div class="controls bullet"><span class="by">ajmurmann</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42301113">parent</a><span>|</span><a href="#42299766">next</a><span>|</span><label class="collapse" for="c-42301407">[-]</label><label class="expand" for="c-42301407">[1 more]</label></div><br/><div class="children"><div class="content">I am not sure it&#x27;s obvious that you could continue generating from any key image and it wouldn&#x27;t deteriorate into mush. If you take that museum scene and look at the vase-like display piece while walking around it as much as you can it already becomes fuzzy and has the beginnings of weird artifacts growing out of it.</div><br/></div></div></div></div><div id="42299766" class="c"><input type="checkbox" id="c-42299766" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42301113">prev</a><span>|</span><a href="#42302941">next</a><span>|</span><label class="collapse" for="c-42299766">[-]</label><label class="expand" for="c-42299766">[2 more]</label></div><br/><div class="children"><div class="content">I mean its a marketing hype for their product.  Its a pretty good starting step though - assuming they can build on it and expand that world space as opposed to just converting an image to 3D.<p>Certainly has some value to it.. marketing, hiring, fundraising (Assuming its a private company)<p>My take is that its a good start and 3-4 years from now it will have a lot of potential value in world creation if they can make the next steps.</div><br/><div id="42299947" class="c"><input type="checkbox" id="c-42299947" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42299766">parent</a><span>|</span><a href="#42302941">next</a><span>|</span><label class="collapse" for="c-42299947">[-]</label><label class="expand" for="c-42299947">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s definitely a balancing act. World labs was stealth for a bit. Without a brand, stated mission, examples &#x2F; demos of what you are capable of... is harder to hire, fund raise or get the attention and mind-share you need once you are ready to ship product.<p>The risk is setting expectations that can&#x27;t be fulfilled.<p>I&#x27;m in the 3D space and I&#x27;m optimistic about World Labs.</div><br/></div></div></div></div><div id="42302941" class="c"><input type="checkbox" id="c-42302941" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42299766">prev</a><span>|</span><a href="#42298718">next</a><span>|</span><label class="collapse" for="c-42302941">[-]</label><label class="expand" for="c-42302941">[1 more]</label></div><br/><div class="children"><div class="content">I was also disappointed by a still image showing a vast sky, but in motion you see it&#x27;s just a painting on a short ceiling. The model interpreted the vast sky as a painting on a short ceiling.</div><br/></div></div><div id="42298729" class="c"><input type="checkbox" id="c-42298729" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#42298159">parent</a><span>|</span><a href="#42298718">prev</a><span>|</span><a href="#42298374">next</a><span>|</span><label class="collapse" for="c-42298729">[-]</label><label class="expand" for="c-42298729">[3 more]</label></div><br/><div class="children"><div class="content">It seems that you could take the image of the location near the boundary, then create a new 3d world from that, continually.</div><br/><div id="42298806" class="c"><input type="checkbox" id="c-42298806" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42298159">root</a><span>|</span><a href="#42298729">parent</a><span>|</span><a href="#42298761">next</a><span>|</span><label class="collapse" for="c-42298806">[-]</label><label class="expand" for="c-42298806">[1 more]</label></div><br/><div class="children"><div class="content">You could try, but it would quickly devolve into non-euclidean nonsense without global knowledge of the areas it&#x27;s already generated.</div><br/></div></div></div></div></div></div><div id="42298374" class="c"><input type="checkbox" id="c-42298374" checked=""/><div class="controls bullet"><span class="by">evan_</span><span>|</span><a href="#42298159">prev</a><span>|</span><a href="#42300681">next</a><span>|</span><label class="collapse" for="c-42298374">[-]</label><label class="expand" for="c-42298374">[8 more]</label></div><br/><div class="children"><div class="content">When watching 3D movies with a VR headset you have to keep your head perfectly still or the lack of parallax destroys the 3D illusion. Compare to a 3D game where moving your head actually lets you move through space and actually look around objects.<p>Something like this applied to every frame of the movie would allow you to move around a little and preserve the perspective shifts. The limitation that you can only move about 4 feet in any direction would not matter for this use case.<p>Of course this comes at the expense of the director and cinematographer&#x27;s intention, which is no small thing.</div><br/><div id="42299090" class="c"><input type="checkbox" id="c-42299090" checked=""/><div class="controls bullet"><span class="by">ChicagoBoy11</span><span>|</span><a href="#42298374">parent</a><span>|</span><a href="#42301360">next</a><span>|</span><label class="collapse" for="c-42299090">[-]</label><label class="expand" for="c-42299090">[5 more]</label></div><br/><div class="children"><div class="content">Have you ever seen the Google Lightfields demo? They have a rig they concocted to essentially capture a &quot;volume&quot; of video to allow for the stereoscopic effect in VR AND which then cleverly presents a different combination of the footage it captured based on your precise head position, so it makes up for these distortions. I found it absolutely breathtaking... first time seeing VR for a space that actually made me feel like I was in it. This was A LONG time ago and I suspected I&#x27;d be seeing a lot more of that content, but I was... very wrong, it seems.<p>Your point is completely correct. Even Apple&#x27;s awesome new stereoscopic 3D short film for the AVP immediately loses what it could be its total awesomeness from this basic fact. The perspective being perfectly fixed will never quite be there to fool our brains so used to dealing with these micro-movements.</div><br/><div id="42299596" class="c"><input type="checkbox" id="c-42299596" checked=""/><div class="controls bullet"><span class="by">Stevvo</span><span>|</span><a href="#42298374">root</a><span>|</span><a href="#42299090">parent</a><span>|</span><a href="#42299664">next</a><span>|</span><label class="collapse" for="c-42299596">[-]</label><label class="expand" for="c-42299596">[2 more]</label></div><br/><div class="children"><div class="content">Each frame was between 200 and 300mb, at a much lower resolution than AVP. The storage and bandwidth required is a bit wild.</div><br/><div id="42303806" class="c"><input type="checkbox" id="c-42303806" checked=""/><div class="controls bullet"><span class="by">km3r</span><span>|</span><a href="#42298374">root</a><span>|</span><a href="#42299596">parent</a><span>|</span><a href="#42299664">next</a><span>|</span><label class="collapse" for="c-42303806">[-]</label><label class="expand" for="c-42303806">[1 more]</label></div><br/><div class="children"><div class="content">Hey finally a use case (for the masses) for gigabit at home at least.</div><br/></div></div></div></div><div id="42299664" class="c"><input type="checkbox" id="c-42299664" checked=""/><div class="controls bullet"><span class="by">evan_</span><span>|</span><a href="#42298374">root</a><span>|</span><a href="#42299090">parent</a><span>|</span><a href="#42299596">prev</a><span>|</span><a href="#42299192">next</a><span>|</span><label class="collapse" for="c-42299664">[-]</label><label class="expand" for="c-42299664">[1 more]</label></div><br/><div class="children"><div class="content">I have seen that, and I came close to buying one of those Lytro light field cameras so many times (but thankfully restrained myself). Light field seemed like a huge obvious &quot;way of the future&quot; thing in the 2010s but with the benefit of hindsight it did not exactly seem to have changed the world.</div><br/></div></div><div id="42299192" class="c"><input type="checkbox" id="c-42299192" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298374">root</a><span>|</span><a href="#42299090">parent</a><span>|</span><a href="#42299664">prev</a><span>|</span><a href="#42301360">next</a><span>|</span><label class="collapse" for="c-42299192">[-]</label><label class="expand" for="c-42299192">[1 more]</label></div><br/><div class="children"><div class="content">Yeah parallax, reflexions, shadows are as important as stereo. We’ve been always sold that stereo = 3D but it’s just one among many cues that the brain relies on.</div><br/></div></div></div></div><div id="42301360" class="c"><input type="checkbox" id="c-42301360" checked=""/><div class="controls bullet"><span class="by">Manuel_D</span><span>|</span><a href="#42298374">parent</a><span>|</span><a href="#42299090">prev</a><span>|</span><a href="#42298596">next</a><span>|</span><label class="collapse" for="c-42301360">[-]</label><label class="expand" for="c-42301360">[1 more]</label></div><br/><div class="children"><div class="content">I suspect this would be feasible if filming was accompanied with a depth sensing camera like the Microsoft Kinect. In post production, you could tell roughly how far each pixel is from the camera which could aid in the reconstruction of a 3d scene.<p>Maybe this could be done with just the aperture and focal distance, which most modern cinema cameras record as they film.</div><br/></div></div><div id="42298596" class="c"><input type="checkbox" id="c-42298596" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298374">parent</a><span>|</span><a href="#42301360">prev</a><span>|</span><a href="#42300681">next</a><span>|</span><label class="collapse" for="c-42298596">[-]</label><label class="expand" for="c-42298596">[1 more]</label></div><br/><div class="children"><div class="content">Definitely if there’s a future for 3D and immersive video it depends on adding more cues other than just stereo. Lack of parallax one of main reasons causing discomfort for many.</div><br/></div></div></div></div><div id="42300681" class="c"><input type="checkbox" id="c-42300681" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#42298374">prev</a><span>|</span><a href="#42298030">next</a><span>|</span><label class="collapse" for="c-42300681">[-]</label><label class="expand" for="c-42300681">[1 more]</label></div><br/><div class="children"><div class="content">People complaining that it&#x27;s a small area, lol my man, this is fucking insane, i know AI is starting to get normalized, but they converted an image into a 3d world! even if its 1ft&#x2F;1ft its still amazing.</div><br/></div></div><div id="42298030" class="c"><input type="checkbox" id="c-42298030" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#42300681">prev</a><span>|</span><a href="#42298579">next</a><span>|</span><label class="collapse" for="c-42298030">[-]</label><label class="expand" for="c-42298030">[5 more]</label></div><br/><div class="children"><div class="content">Not my project, but another approach recently published used Depth Anywhere to create a virtual depthmap for a given 360º equirectangular image and then apply to point cloud and render using three.js &#x2F; A-Frame.<p>Appears to be similar capability as OP for creating scene depth from 2D, but using point cloud instead of gaussian splatting for rendering so looks more pixelated:
<a href="https:&#x2F;&#x2F;github.com&#x2F;akbartus&#x2F;360-Depth-in-WebXR">https:&#x2F;&#x2F;github.com&#x2F;akbartus&#x2F;360-Depth-in-WebXR</a><p>Also unlike the World Lab example you have the ability to go further outside the bounds of the point cloud to inspect the deficiencies of the approach. It&#x27;s getting there but still needs work.</div><br/><div id="42298134" class="c"><input type="checkbox" id="c-42298134" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298030">parent</a><span>|</span><a href="#42298579">next</a><span>|</span><label class="collapse" for="c-42298134">[-]</label><label class="expand" for="c-42298134">[4 more]</label></div><br/><div class="children"><div class="content">Yeah A-Frame! It makes me happy to see my many years of maintaining it paying off</div><br/><div id="42298208" class="c"><input type="checkbox" id="c-42298208" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#42298030">root</a><span>|</span><a href="#42298134">parent</a><span>|</span><a href="#42301821">next</a><span>|</span><label class="collapse" for="c-42298208">[-]</label><label class="expand" for="c-42298208">[1 more]</label></div><br/><div class="children"><div class="content">Yes and this is a great example of how open A-Frame is compared to OP example. You can inspect every part of the experience from the code to the actual runtime inspector to see how Akbartus achieved the effect -- and then help to make it even better! :)<p>I do think there is the possibility to use something like this eventually to do all the processing in the browser for Depth Anywhere + Splat reconstruction to fill in the holes of the current point cloud approach: <a href="https:&#x2F;&#x2F;github.com&#x2F;ArthurBrussee&#x2F;brush">https:&#x2F;&#x2F;github.com&#x2F;ArthurBrussee&#x2F;brush</a></div><br/></div></div><div id="42301821" class="c"><input type="checkbox" id="c-42301821" checked=""/><div class="controls bullet"><span class="by">raywu</span><span>|</span><a href="#42298030">root</a><span>|</span><a href="#42298134">parent</a><span>|</span><a href="#42298208">prev</a><span>|</span><a href="#42298579">next</a><span>|</span><label class="collapse" for="c-42301821">[-]</label><label class="expand" for="c-42301821">[2 more]</label></div><br/><div class="children"><div class="content">As a consumer of A-Frame, I thank you!</div><br/><div id="42302260" class="c"><input type="checkbox" id="c-42302260" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298030">root</a><span>|</span><a href="#42301821">parent</a><span>|</span><a href="#42298579">next</a><span>|</span><label class="collapse" for="c-42302260">[-]</label><label class="expand" for="c-42302260">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div></div></div></div></div><div id="42298579" class="c"><input type="checkbox" id="c-42298579" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42298030">prev</a><span>|</span><a href="#42298843">next</a><span>|</span><label class="collapse" for="c-42298579">[-]</label><label class="expand" for="c-42298579">[2 more]</label></div><br/><div class="children"><div class="content">Cool, but not as impressive as <a href="https:&#x2F;&#x2F;cat-4d.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cat-4d.github.io&#x2F;</a> to me.</div><br/><div id="42300219" class="c"><input type="checkbox" id="c-42300219" checked=""/><div class="controls bullet"><span class="by">wordpad25</span><span>|</span><a href="#42298579">parent</a><span>|</span><a href="#42298843">next</a><span>|</span><label class="collapse" for="c-42300219">[-]</label><label class="expand" for="c-42300219">[1 more]</label></div><br/><div class="children"><div class="content">Does this also work for macro shots, like a landscape? all the examples are focused on specific objects</div><br/></div></div></div></div><div id="42298843" class="c"><input type="checkbox" id="c-42298843" checked=""/><div class="controls bullet"><span class="by">vinkelhake</span><span>|</span><a href="#42298579">prev</a><span>|</span><a href="#42298017">next</a><span>|</span><label class="collapse" for="c-42298843">[-]</label><label class="expand" for="c-42298843">[2 more]</label></div><br/><div class="children"><div class="content">This is neat I guess. Maybe I&#x27;m just blase with seeing yet another AI demo where I&#x27;m supposed to fill in the blanks in coming up with ways to make the tech actually <i>useful</i>.<p>The &quot;Step into Paintings&quot; section cracked me up. As soon as you pan away from the source material, the craziness of the model is on full display. So sure, I can experience iconic pieces of art in a new way, it&#x27;s just not a <i>good experience</i>.</div><br/><div id="42298950" class="c"><input type="checkbox" id="c-42298950" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42298843">parent</a><span>|</span><a href="#42298017">next</a><span>|</span><label class="collapse" for="c-42298950">[-]</label><label class="expand" for="c-42298950">[1 more]</label></div><br/><div class="children"><div class="content">Who knew that Hopper&#x27;s <i>Nighthawks</i> had a biblically-accurate table and chairs just out of frame?</div><br/></div></div></div></div><div id="42298017" class="c"><input type="checkbox" id="c-42298017" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#42298843">prev</a><span>|</span><a href="#42298465">next</a><span>|</span><label class="collapse" for="c-42298017">[-]</label><label class="expand" for="c-42298017">[8 more]</label></div><br/><div class="children"><div class="content">I feel like a lot of the good that projects like this do get muddied by the overly ambitious claims.</div><br/><div id="42298066" class="c"><input type="checkbox" id="c-42298066" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42298017">parent</a><span>|</span><a href="#42298465">next</a><span>|</span><label class="collapse" for="c-42298066">[-]</label><label class="expand" for="c-42298066">[7 more]</label></div><br/><div class="children"><div class="content">The overly ambitious claims are what led them to raise $230M+ without a product.<p>Fei-Fei Li is a luminary in the field, and she&#x27;s assembled a stellar team of some of the best researchers in the space.<p>Their gamble is that they&#x27;ll be able to move faster than the open research and other companies looking to productionize that research.<p>Time will tell if this can become an ElevenLabs or if it&#x27;ll fizzle out like Character.ai.<p>My worry is that without a product, they&#x27;ll malinvestment their research into cool problems that don&#x27;t satisfy market demand. There&#x27;s nothing like the north star of customers. They&#x27;ll also have a tough time with hiring going forward with that valuation.<p>The market of open research and models is producing a lot of neat stuff in 3D. But there&#x27;s no open pool of data yet, despite HuggingFace and others trying.<p>We&#x27;ll see what happens.</div><br/><div id="42298172" class="c"><input type="checkbox" id="c-42298172" checked=""/><div class="controls bullet"><span class="by">bko</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298066">parent</a><span>|</span><a href="#42298160">next</a><span>|</span><label class="collapse" for="c-42298172">[-]</label><label class="expand" for="c-42298172">[5 more]</label></div><br/><div class="children"><div class="content">I thought you were kidding but World Labs really did raise $230M after being founded less than 1 year ago. Andreessen Horowitz too.<p>What would have to be true for this to be worth $100 billion after 5-10 years?<p><a href="https:&#x2F;&#x2F;www.crunchbase.com&#x2F;organization&#x2F;world-labs" rel="nofollow">https:&#x2F;&#x2F;www.crunchbase.com&#x2F;organization&#x2F;world-labs</a></div><br/><div id="42298699" class="c"><input type="checkbox" id="c-42298699" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298172">parent</a><span>|</span><a href="#42298566">next</a><span>|</span><label class="collapse" for="c-42298699">[-]</label><label class="expand" for="c-42298699">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t have to be 100 billions.  They probably raised at a few billion valuation -- which I do agree is still a lot</div><br/></div></div><div id="42298566" class="c"><input type="checkbox" id="c-42298566" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298172">parent</a><span>|</span><a href="#42298699">prev</a><span>|</span><a href="#42298160">next</a><span>|</span><label class="collapse" for="c-42298566">[-]</label><label class="expand" for="c-42298566">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know enough about venture funding. Did $230M really get transferred into World Labs bank account, or is this a &quot;commitment&quot; of $230M which is trickled out a few million at a time?</div><br/><div id="42300493" class="c"><input type="checkbox" id="c-42300493" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298566">parent</a><span>|</span><a href="#42298714">next</a><span>|</span><label class="collapse" for="c-42300493">[-]</label><label class="expand" for="c-42300493">[1 more]</label></div><br/><div class="children"><div class="content">The general theme is...<p>Before: You and your cofounders share 100% of the stock in your company that&#x27;s valued at $X.<p>After: Your company now has everything it had before plus $Y worth of &quot;something&quot; from the VCs. Your company is now valued at $X plus $Y. The VCs now hold stock in your company worth $Y. You and your cofounders still hold stock your company worth $X.<p>&quot;Something&quot; might be anything. Cash, stocks, commitments to resources, whatever.</div><br/></div></div><div id="42298714" class="c"><input type="checkbox" id="c-42298714" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298566">parent</a><span>|</span><a href="#42300493">prev</a><span>|</span><a href="#42298160">next</a><span>|</span><label class="collapse" for="c-42298714">[-]</label><label class="expand" for="c-42298714">[1 more]</label></div><br/><div class="children"><div class="content">Part of it is often dedicated to compute through credit commitments at Azure&#x2F;Google&#x2F;AWS.  Probably not all is cash and available at t0.<p>That money will go fast though, given GPU costs and salary ranges in the bay</div><br/></div></div></div></div></div></div><div id="42298160" class="c"><input type="checkbox" id="c-42298160" checked=""/><div class="controls bullet"><span class="by">mclau156</span><span>|</span><a href="#42298017">root</a><span>|</span><a href="#42298066">parent</a><span>|</span><a href="#42298172">prev</a><span>|</span><a href="#42298465">next</a><span>|</span><label class="collapse" for="c-42298160">[-]</label><label class="expand" for="c-42298160">[1 more]</label></div><br/><div class="children"><div class="content">I believe Fei-Fei is focused on physical world interaction, <a href="https:&#x2F;&#x2F;behavior.stanford.edu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;behavior.stanford.edu&#x2F;</a>   is a project she works on for more physical interaction with AI</div><br/></div></div></div></div></div></div><div id="42298465" class="c"><input type="checkbox" id="c-42298465" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#42298017">prev</a><span>|</span><a href="#42298057">next</a><span>|</span><label class="collapse" for="c-42298465">[-]</label><label class="expand" for="c-42298465">[7 more]</label></div><br/><div class="children"><div class="content">Their bet is that XYZ can generalize from Unreal and NVIDIA Isaac recordings.<p>Is XYZ diffusion-transformers? Or is XYZ Chameleon? Or some novel architecture?<p>It takes the absolute fastest teams, it seems, 7 months to develop a first version of a model. And it also seems that models are like babies, 9 moms do not produce a model in 1 month.<p>The tough thing is that it may be possible to develop a great video model with DiTs for $220m; or it may be possible to develop a great video model with Chameleon for $1b; but if it&#x27;s 3D + time, will it be too expensive for them to do?<p>The craziest thing to me is that these guys are super talented, but they might not have <i>enough</i> money!</div><br/><div id="42299893" class="c"><input type="checkbox" id="c-42299893" checked=""/><div class="controls bullet"><span class="by">byearthithatius</span><span>|</span><a href="#42298465">parent</a><span>|</span><a href="#42298057">next</a><span>|</span><label class="collapse" for="c-42299893">[-]</label><label class="expand" for="c-42299893">[6 more]</label></div><br/><div class="children"><div class="content">Then they need to sell _billions_ of dollars worth of these worlds to ... game studios? In order for this valuation to make sense they need to convince the majority of major game studios to spend all their world creation budget solely on this company. Seems unrealistic but I guess only time can tell.</div><br/><div id="42299988" class="c"><input type="checkbox" id="c-42299988" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298465">root</a><span>|</span><a href="#42299893">parent</a><span>|</span><a href="#42298057">next</a><span>|</span><label class="collapse" for="c-42299988">[-]</label><label class="expand" for="c-42299988">[5 more]</label></div><br/><div class="children"><div class="content">if they fulfill the mission it will apply to domains other than games like movies, robotics, architecture...</div><br/><div id="42300008" class="c"><input type="checkbox" id="c-42300008" checked=""/><div class="controls bullet"><span class="by">byearthithatius</span><span>|</span><a href="#42298465">root</a><span>|</span><a href="#42299988">parent</a><span>|</span><a href="#42301925">next</a><span>|</span><label class="collapse" for="c-42300008">[-]</label><label class="expand" for="c-42300008">[1 more]</label></div><br/><div class="children"><div class="content">Good point, that&#x27;s fair there are more use cases. IDK about architecture, typically you want more structure&#x2F;determinism instead of probabilistic generation. Overall this is very cool. I like the consistency it has and it does generally amaze me nonetheless. But you gotta admit selling a billion dollars of anything is really hard. That is three times the budget of the highest budget movie ever created! (avengers endgame at 356 million). It is almost the ENTIRE budget of the biggest game ever, grand theft auto six.</div><br/></div></div><div id="42301925" class="c"><input type="checkbox" id="c-42301925" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42298465">root</a><span>|</span><a href="#42299988">parent</a><span>|</span><a href="#42300008">prev</a><span>|</span><a href="#42301319">next</a><span>|</span><label class="collapse" for="c-42301925">[-]</label><label class="expand" for="c-42301925">[1 more]</label></div><br/><div class="children"><div class="content">And everyone will be building these. China will open source dozens of them.</div><br/></div></div><div id="42301319" class="c"><input type="checkbox" id="c-42301319" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42298465">root</a><span>|</span><a href="#42299988">parent</a><span>|</span><a href="#42301925">prev</a><span>|</span><a href="#42298057">next</a><span>|</span><label class="collapse" for="c-42301319">[-]</label><label class="expand" for="c-42301319">[2 more]</label></div><br/><div class="children"><div class="content">Robotics?</div><br/><div id="42301388" class="c"><input type="checkbox" id="c-42301388" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298465">root</a><span>|</span><a href="#42301319">parent</a><span>|</span><a href="#42298057">next</a><span>|</span><label class="collapse" for="c-42301388">[-]</label><label class="expand" for="c-42301388">[1 more]</label></div><br/><div class="children"><div class="content">Need to generate environments for simulation and training</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42298057" class="c"><input type="checkbox" id="c-42298057" checked=""/><div class="controls bullet"><span class="by">lastdong</span><span>|</span><a href="#42298465">prev</a><span>|</span><a href="#42303256">next</a><span>|</span><label class="collapse" for="c-42298057">[-]</label><label class="expand" for="c-42298057">[1 more]</label></div><br/><div class="children"><div class="content">First reaction after trying it was a bit of a surprise when I got an “Out of bounds” message – not what I expected for 3D worlds.
Scrolling down to the &quot;Looking Ahead&quot; section, they are working on improving both size and fidelity.</div><br/></div></div><div id="42303256" class="c"><input type="checkbox" id="c-42303256" checked=""/><div class="controls bullet"><span class="by">TinkersW</span><span>|</span><a href="#42298057">prev</a><span>|</span><a href="#42301444">next</a><span>|</span><label class="collapse" for="c-42303256">[-]</label><label class="expand" for="c-42303256">[1 more]</label></div><br/><div class="children"><div class="content">I think it does look much nicer than the other examples of this nature that I&#x27;ve seen.<p>I would guess they are pre-generating the world from the image, not generating it on the go as it runs reasonably well, but doesn&#x27;t this really limit world size?<p>I noticed some solid geometry that is accidentally transparent.<p>The stuff behind the camera looks pretty good, which is presumably fully generated, so if they can make it so you can actually move around more, and with similar quality it could be interesting.<p>I do wish the examples had a full screen button, the view is tiny..</div><br/></div></div><div id="42301444" class="c"><input type="checkbox" id="c-42301444" checked=""/><div class="controls bullet"><span class="by">fullstackwife</span><span>|</span><a href="#42303256">prev</a><span>|</span><a href="#42302715">next</a><span>|</span><label class="collapse" for="c-42301444">[-]</label><label class="expand" for="c-42301444">[1 more]</label></div><br/><div class="children"><div class="content">baseline images seem to be rendered, because there is shading, lightining, shadows etc.
when I tried other tool (image -&gt; 3d model) it tended to work only for their example images, and when I used anything else it produced some black and flat shape.<p>so the headline should be: Generate 3D worlds from a single image rendered by us that we used to train our model.</div><br/></div></div><div id="42302715" class="c"><input type="checkbox" id="c-42302715" checked=""/><div class="controls bullet"><span class="by">ellis0n</span><span>|</span><a href="#42301444">prev</a><span>|</span><a href="#42300268">next</a><span>|</span><label class="collapse" for="c-42302715">[-]</label><label class="expand" for="c-42302715">[1 more]</label></div><br/><div class="children"><div class="content">Amazing! It looks like this is one step closer to singularity and this startup showcases what future startups should aspire to be. Although the technology for world generation is just in its infancy, but it’s impressive and atmosphere is great with a stunning impact. Everything you need to wow an investor and secure funding while the technology itself can be hotfixed for years to come. I think at this stage the showcased technology seems more aligned with cinema than the metaverse. Great work! Looking forward to the updates.</div><br/></div></div><div id="42300268" class="c"><input type="checkbox" id="c-42300268" checked=""/><div class="controls bullet"><span class="by">iamleppert</span><span>|</span><a href="#42302715">prev</a><span>|</span><a href="#42298571">next</a><span>|</span><label class="collapse" for="c-42300268">[-]</label><label class="expand" for="c-42300268">[1 more]</label></div><br/><div class="children"><div class="content">Is a 2D image really the best input primitive for 3D world construction? As a user, I&#x27;d prefer to have 3D primitives (plane, sphere, mesh) as tools when building my worlds.</div><br/></div></div><div id="42298571" class="c"><input type="checkbox" id="c-42298571" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#42300268">prev</a><span>|</span><a href="#42298460">next</a><span>|</span><label class="collapse" for="c-42298571">[-]</label><label class="expand" for="c-42298571">[4 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t get the &quot;tap to interact&quot; panels to work.  No mouse events had any effect.  I had to take it very literally, but first, I had to drag my browser to my laptop screen, which did enable me to literally tap the screen.</div><br/><div id="42298766" class="c"><input type="checkbox" id="c-42298766" checked=""/><div class="controls bullet"><span class="by">jcjohns</span><span>|</span><a href="#42298571">parent</a><span>|</span><a href="#42298460">next</a><span>|</span><label class="collapse" for="c-42298766">[-]</label><label class="expand" for="c-42298766">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s weird, what device are you using?<p>(I&#x27;m part of World Labs)</div><br/><div id="42299372" class="c"><input type="checkbox" id="c-42299372" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#42298571">root</a><span>|</span><a href="#42298766">parent</a><span>|</span><a href="#42299965">next</a><span>|</span><label class="collapse" for="c-42299372">[-]</label><label class="expand" for="c-42299372">[1 more]</label></div><br/><div class="children"><div class="content">Firefox on Windows 11 on a Lenovo Thinkpad with a touch screen.</div><br/></div></div><div id="42299965" class="c"><input type="checkbox" id="c-42299965" checked=""/><div class="controls bullet"><span class="by">FergusArgyll</span><span>|</span><a href="#42298571">root</a><span>|</span><a href="#42298766">parent</a><span>|</span><a href="#42299372">prev</a><span>|</span><a href="#42298460">next</a><span>|</span><label class="collapse" for="c-42299965">[-]</label><label class="expand" for="c-42299965">[1 more]</label></div><br/><div class="children"><div class="content">Not working for me either, Chrome win 11</div><br/></div></div></div></div></div></div><div id="42298460" class="c"><input type="checkbox" id="c-42298460" checked=""/><div class="controls bullet"><span class="by">julianeon</span><span>|</span><a href="#42298571">prev</a><span>|</span><a href="#42297981">next</a><span>|</span><label class="collapse" for="c-42298460">[-]</label><label class="expand" for="c-42298460">[1 more]</label></div><br/><div class="children"><div class="content">I was interested to see that a co-founder is Stanford CS prof Fei-Fei Li. I&#x27;m reading her nonfiction book now, &quot;The Worlds I See,&quot; about her experience with AI; she testified before Congress about it.</div><br/></div></div><div id="42297981" class="c"><input type="checkbox" id="c-42297981" checked=""/><div class="controls bullet"><span class="by">marcsj</span><span>|</span><a href="#42298460">prev</a><span>|</span><a href="#42302424">next</a><span>|</span><label class="collapse" for="c-42297981">[-]</label><label class="expand" for="c-42297981">[3 more]</label></div><br/><div class="children"><div class="content">The boundaries make it pretty obvious how flat this world still is and even on blurring the edges it&#x27;s obvious there really isn&#x27;t anything to the models. This is cool for sure, and I can see it being useful for better photogrammetry and assisting in building out worlds, but it isn&#x27;t going to suddenly be used to make entire game worlds on its own.</div><br/><div id="42298048" class="c"><input type="checkbox" id="c-42298048" checked=""/><div class="controls bullet"><span class="by">mattlondon</span><span>|</span><a href="#42297981">parent</a><span>|</span><a href="#42302424">next</a><span>|</span><label class="collapse" for="c-42298048">[-]</label><label class="expand" for="c-42298048">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I thought the same and was immediately disappointed that you could only step a tiny bit forwards.<p>BUT, you can turn around and see something that I presume was entirely generated.  So I don&#x27;t think it is just doing some clever tricks to make the photo look 3D, but also &quot;infilling&quot; what is behind the camera too.  That is kinda cool.<p>I&#x27;d love to see this improved so I can walk around some more though, to see what is down those alleys etc.</div><br/><div id="42298100" class="c"><input type="checkbox" id="c-42298100" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42297981">root</a><span>|</span><a href="#42298048">parent</a><span>|</span><a href="#42302424">next</a><span>|</span><label class="collapse" for="c-42298100">[-]</label><label class="expand" for="c-42298100">[1 more]</label></div><br/><div class="children"><div class="content">I’m sure It’ll improve. I imagine, the further from the input image the more the model has to make up stuff. Gen-AI video models are limited to a few seconds. In 3D you’re constrained to a volume</div><br/></div></div></div></div></div></div><div id="42302424" class="c"><input type="checkbox" id="c-42302424" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#42297981">prev</a><span>|</span><a href="#42299828">next</a><span>|</span><label class="collapse" for="c-42302424">[-]</label><label class="expand" for="c-42302424">[2 more]</label></div><br/><div class="children"><div class="content">This is some cool progress, but from what I gather it&#x27;s not actually generating a &quot;world&quot;. What I&#x27;d be really interested in is the capability of fully generating the geometrical world description in something like USD (Universal Scene Description).</div><br/><div id="42302905" class="c"><input type="checkbox" id="c-42302905" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42302424">parent</a><span>|</span><a href="#42299828">next</a><span>|</span><label class="collapse" for="c-42302905">[-]</label><label class="expand" for="c-42302905">[1 more]</label></div><br/><div class="children"><div class="content">What’s your use case?</div><br/></div></div></div></div><div id="42301970" class="c"><input type="checkbox" id="c-42301970" checked=""/><div class="controls bullet"><span class="by">jcims</span><span>|</span><a href="#42299828">prev</a><span>|</span><a href="#42298676">next</a><span>|</span><label class="collapse" for="c-42301970">[-]</label><label class="expand" for="c-42301970">[1 more]</label></div><br/><div class="children"><div class="content">The width of modern mobile phones isn&#x27;t far off from the average pupillary distance of adults.  It feels like there is an opportunity to create a glut of useful 3D data by simply placing one camera on each side of the phone rather than trying to infer it from a single view of the scene.<p>Maybe when there is better technology for viewing 3D content.</div><br/></div></div><div id="42298676" class="c"><input type="checkbox" id="c-42298676" checked=""/><div class="controls bullet"><span class="by">tnolet</span><span>|</span><a href="#42301970">prev</a><span>|</span><a href="#42300015">next</a><span>|</span><label class="collapse" for="c-42298676">[-]</label><label class="expand" for="c-42298676">[2 more]</label></div><br/><div class="children"><div class="content">This is more like the moving &quot;still&quot; pictures in a Harry Potter movie. Not a 3D world.</div><br/><div id="42298732" class="c"><input type="checkbox" id="c-42298732" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42298676">parent</a><span>|</span><a href="#42300015">next</a><span>|</span><label class="collapse" for="c-42298732">[-]</label><label class="expand" for="c-42298732">[1 more]</label></div><br/><div class="children"><div class="content">In some angles you can see there’s some gaussian splat &#x2F; point cloud representation underneath. There’s definitely a 3D representation. But yeah navigable volume is limited at the moment. It will improve</div><br/></div></div></div></div><div id="42302205" class="c"><input type="checkbox" id="c-42302205" checked=""/><div class="controls bullet"><span class="by">krenzo</span><span>|</span><a href="#42300015">prev</a><span>|</span><a href="#42298293">next</a><span>|</span><label class="collapse" for="c-42302205">[-]</label><label class="expand" for="c-42302205">[2 more]</label></div><br/><div class="children"><div class="content">For me, the camera is just looking up and spinning clockwise.  I tried in both Brave and Chrome.</div><br/><div id="42302662" class="c"><input type="checkbox" id="c-42302662" checked=""/><div class="controls bullet"><span class="by">throwaway314155</span><span>|</span><a href="#42302205">parent</a><span>|</span><a href="#42298293">next</a><span>|</span><label class="collapse" for="c-42302662">[-]</label><label class="expand" for="c-42302662">[1 more]</label></div><br/><div class="children"><div class="content">Brave and Chrome are both Chrome. Have you tried Firefox, Safari?</div><br/></div></div></div></div><div id="42298293" class="c"><input type="checkbox" id="c-42298293" checked=""/><div class="controls bullet"><span class="by">Uehreka</span><span>|</span><a href="#42302205">prev</a><span>|</span><a href="#42299660">next</a><span>|</span><label class="collapse" for="c-42298293">[-]</label><label class="expand" for="c-42298293">[1 more]</label></div><br/><div class="children"><div class="content">I’ve been trying to get into this sort of 3D Gaussian Splatting stuff, particularly with this focus on environments as opposed to just individual objects or characters. Does anyone know of a model that’s good at doing that and is openly distributed&#x2F;locally runnable?</div><br/></div></div><div id="42299660" class="c"><input type="checkbox" id="c-42299660" checked=""/><div class="controls bullet"><span class="by">PeterCorless</span><span>|</span><a href="#42298293">prev</a><span>|</span><a href="#42299896">next</a><span>|</span><label class="collapse" for="c-42299660">[-]</label><label class="expand" for="c-42299660">[1 more]</label></div><br/><div class="children"><div class="content">Ugh. The AI-generated rear views being nowhere near at the level of detail of even the uncanny valley foreground images. Is not really generating a &quot;3D &#x27;world&#x27;&quot; so much as extrapolating a 360º view from a single scene. There&#x27;s no sense to the architecture or flora. Staircases that lead nowhere.<p>It&#x27;s more hypecycle nonsense. But they&#x27;ll poor billions into this rather than pay human artists what they&#x27;re worth.</div><br/></div></div><div id="42299896" class="c"><input type="checkbox" id="c-42299896" checked=""/><div class="controls bullet"><span class="by">wkat4242</span><span>|</span><a href="#42299660">prev</a><span>|</span><a href="#42299044">next</a><span>|</span><label class="collapse" for="c-42299896">[-]</label><label class="expand" for="c-42299896">[1 more]</label></div><br/><div class="children"><div class="content">This is amazing. 3D content generation is so time consuming..</div><br/></div></div><div id="42299044" class="c"><input type="checkbox" id="c-42299044" checked=""/><div class="controls bullet"><span class="by">ValentinA23</span><span>|</span><a href="#42299896">prev</a><span>|</span><a href="#42301486">next</a><span>|</span><label class="collapse" for="c-42299044">[-]</label><label class="expand" for="c-42299044">[3 more]</label></div><br/><div class="children"><div class="content">wasd isn&#x27;t accessible for those of us who have the unfortunate disability of not using a qwerty keyboard. If your project isn&#x27;t a competitve FPS, arrows are fine.</div><br/><div id="42299302" class="c"><input type="checkbox" id="c-42299302" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#42299044">parent</a><span>|</span><a href="#42300358">next</a><span>|</span><label class="collapse" for="c-42299302">[-]</label><label class="expand" for="c-42299302">[1 more]</label></div><br/><div class="children"><div class="content">You can install multiple keyboard layouts in your OS. Many users do this.</div><br/></div></div><div id="42300358" class="c"><input type="checkbox" id="c-42300358" checked=""/><div class="controls bullet"><span class="by">jcjohns</span><span>|</span><a href="#42299044">parent</a><span>|</span><a href="#42299302">prev</a><span>|</span><a href="#42301486">next</a><span>|</span><label class="collapse" for="c-42300358">[-]</label><label class="expand" for="c-42300358">[1 more]</label></div><br/><div class="children"><div class="content">Arrow keys also work now, thanks for the feedback!</div><br/></div></div></div></div><div id="42301486" class="c"><input type="checkbox" id="c-42301486" checked=""/><div class="controls bullet"><span class="by">frisco</span><span>|</span><a href="#42299044">prev</a><span>|</span><a href="#42301335">next</a><span>|</span><label class="collapse" for="c-42301486">[-]</label><label class="expand" for="c-42301486">[2 more]</label></div><br/><div class="children"><div class="content">Someone please make a player for these things for Vision Pro and&#x2F;or Quest!</div><br/><div id="42301575" class="c"><input type="checkbox" id="c-42301575" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#42301486">parent</a><span>|</span><a href="#42301335">next</a><span>|</span><label class="collapse" for="c-42301575">[-]</label><label class="expand" for="c-42301575">[1 more]</label></div><br/><div class="children"><div class="content">We have a gaussian splat component (same format that it looks World lab uses) for A-Frame that should work in VR on Quest and Vision Pro in their respective Web browsers. Quest FPS might not be ideal yet<p><a href="https:&#x2F;&#x2F;x.com&#x2F;dmarcos&#x2F;status&#x2F;1714364349928837147" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;dmarcos&#x2F;status&#x2F;1714364349928837147</a></div><br/></div></div></div></div><div id="42301335" class="c"><input type="checkbox" id="c-42301335" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#42301486">prev</a><span>|</span><a href="#42299927">next</a><span>|</span><label class="collapse" for="c-42301335">[-]</label><label class="expand" for="c-42301335">[1 more]</label></div><br/><div class="children"><div class="content">It looks like the Facebook feature that transforms your image in &quot;3d&quot;.</div><br/></div></div><div id="42299927" class="c"><input type="checkbox" id="c-42299927" checked=""/><div class="controls bullet"><span class="by">Vanit</span><span>|</span><a href="#42301335">prev</a><span>|</span><a href="#42300730">next</a><span>|</span><label class="collapse" for="c-42299927">[-]</label><label class="expand" for="c-42299927">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m keen to drop in a few PSX-era Final Fantasy backgrounds to see what it does!</div><br/></div></div><div id="42300730" class="c"><input type="checkbox" id="c-42300730" checked=""/><div class="controls bullet"><span class="by">albtaiuti</span><span>|</span><a href="#42299927">prev</a><span>|</span><label class="collapse" for="c-42300730">[-]</label><label class="expand" for="c-42300730">[1 more]</label></div><br/><div class="children"><div class="content">it looks like they&#x27;re basing the infilling on 360 photos &#x2F; videos. that&#x27;s why you can&#x27;t walk around freely: the inpainting must be done from the center of the sphere</div><br/></div></div></div></div></div></div></div></body></html>