<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686214885893" as="style"/><link rel="stylesheet" href="styles.css?v=1686214885893"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2306.00029">CodeTF: One-Stop Transformer Library for State-of-the-Art Code LLM</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>pabo</span> | <span>7 comments</span></div><br/><div><div id="36234776" class="c"><input type="checkbox" id="c-36234776" checked=""/><div class="controls bullet"><span class="by">Flux159</span><span>|</span><a href="#36234870">next</a><span>|</span><label class="collapse" for="c-36234776">[-]</label><label class="expand" for="c-36234776">[1 more]</label></div><br/><div class="children"><div class="content">Link to the github repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;salesforce&#x2F;CodeTF">https:&#x2F;&#x2F;github.com&#x2F;salesforce&#x2F;CodeTF</a><p>It would be helpful to see some Colab notebook examples of how I could use this or incorporate my own codebase with these open source coding models.<p>The examples show some smaller interesting prediction task &amp; translation between csharp and java, but probably easier to try it out in Colab than having to install locally.<p>I would also want to be able to compare Github Copilot&#x27;s autocomplete with what CodeT5 would return as a prediction.</div><br/></div></div><div id="36234870" class="c"><input type="checkbox" id="c-36234870" checked=""/><div class="controls bullet"><span class="by">Topfi</span><span>|</span><a href="#36234776">prev</a><span>|</span><a href="#36234724">next</a><span>|</span><label class="collapse" for="c-36234870">[-]</label><label class="expand" for="c-36234870">[1 more]</label></div><br/><div class="children"><div class="content">salesforce really seems to invest a lot of resources into coding focused applications for LLMs, which is of course great, especially as they seem very transparent, sharing both papers and usable implementations[0]. However, I feel that I am really starting to lose track over the differences in their releases (T5 vs T5+ vs Gen vs this), especially as they come so fast.<p>Perhaps this reflects poorly on me, but I find it hard to really stay up to date with the consistent stream of preprints and releases (not just from salesforce) as it tends to take me a while before fully internalizing what makes the newest developments so special, so I was very happy to find that they added an overview that compares different supported models (including their releases) to the newest repo[1].<p>Of course, size does not correlate with performance, but it still helped me to get a better grip on what they mean by &quot;one-stop Python transformer-based library for code large language models (Code LLMs) and code intelligence&quot; and how that relates to existing models.<p>CodeTF very grossly oversimplified, intends to make working with models, in a multitude of ways, easier.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;salesforce&#x2F;repositories?q=llm">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;salesforce&#x2F;repositories?q=llm</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;salesforce&#x2F;CodeTF">https:&#x2F;&#x2F;github.com&#x2F;salesforce&#x2F;CodeTF</a></div><br/></div></div><div id="36234724" class="c"><input type="checkbox" id="c-36234724" checked=""/><div class="controls bullet"><span class="by">rektide</span><span>|</span><a href="#36234870">prev</a><span>|</span><a href="#36238092">next</a><span>|</span><label class="collapse" for="c-36234724">[-]</label><label class="expand" for="c-36234724">[2 more]</label></div><br/><div class="children"><div class="content">Im hacking some really dumb code this week &amp; just tried to get StarCoder.cpp to give me some help, but I don&#x27;t have any idea how to prompt it to work with code I already have.<p>I was really surprised that all the HuggingFace stuff needed an account. I didn&#x27;t have any faith my data would stay local, I didn&#x27;t understand what that was all for. Which sucks a bit because StarCoder seems to have a fairly friendly vscode extension, Im just too scared to use it.<p>I think maybe the trick is to just write code comments &amp; ask for help in them? The vscode extension seems to just upload the file, wrapping everything before your cursor in {start token}&#x2F;* your code here *&#x2F;{end token}.<p>I&#x27;m obviously a total newb here, but new a little tiny bit about LLM, how they are tokenizing systems. It still stuns me a bit seeing that these systems absolutely have the most minimal ability to capture context&#x2F;hints from the rest of the project, from typescript definitions.</div><br/><div id="36235387" class="c"><input type="checkbox" id="c-36235387" checked=""/><div class="controls bullet"><span class="by">bavell</span><span>|</span><a href="#36234724">parent</a><span>|</span><a href="#36238092">next</a><span>|</span><label class="collapse" for="c-36235387">[-]</label><label class="expand" for="c-36235387">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m also struggling a bit to get some decent code output (TS) from local LLMs via oobabooga. I&#x27;ve been getting mixed results and I think it&#x27;s pretty sensitive to the exact combo of model&#x2F;parameters&#x2F;prompt. If any one is off or not tuned to work with the others then results aren&#x27;t great.<p>E.g. some models expect very specific formatting of prompts. Some models give nonsense output at temperature=0.7 while others work great. Some models have been fine-tuned on chatbot-bot like instructions (ala chatgpt, so-called &quot;Instruct&quot; models) while others just autocomplete the given prompt. Very important to use the right combo to get the best results.</div><br/></div></div></div></div><div id="36238092" class="c"><input type="checkbox" id="c-36238092" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36234724">prev</a><span>|</span><a href="#36237582">next</a><span>|</span><label class="collapse" for="c-36238092">[-]</label><label class="expand" for="c-36238092">[1 more]</label></div><br/><div class="children"><div class="content">Is there one complete example of effective code generation comparable to OpenAI?</div><br/></div></div><div id="36237582" class="c"><input type="checkbox" id="c-36237582" checked=""/><div class="controls bullet"><span class="by">xvilka</span><span>|</span><a href="#36238092">prev</a><span>|</span><label class="collapse" for="c-36237582">[-]</label><label class="expand" for="c-36237582">[1 more]</label></div><br/><div class="children"><div class="content">Seems no support for C, C++, Rust out of the box, sadly.</div><br/></div></div></div></div></div></div></div></body></html>