<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707728453941" as="style"/><link rel="stylesheet" href="styles.css?v=1707728453941"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://datadreamer.dev/docs/latest/pages/get_started/quick_tour/aligning.html">RLHF a LLM in &lt;50 lines of Python</a> <span class="domain">(<a href="https://datadreamer.dev">datadreamer.dev</a>)</span></div><div class="subtext"><span>patelajay285</span> | <span>65 comments</span></div><br/><div><div id="39342866" class="c"><input type="checkbox" id="c-39342866" checked=""/><div class="controls bullet"><span class="by">v4dok</span><span>|</span><a href="#39336831">next</a><span>|</span><label class="collapse" for="c-39342866">[-]</label><label class="expand" for="c-39342866">[1 more]</label></div><br/><div class="children"><div class="content">I feel like the current meta on finetuning LLMs is random accounts at X&#x2F;Twitter. Google results are littered with SEO garbage or some kind of guides that fail to work the moment you need something slightly different.</div><br/></div></div><div id="39336831" class="c"><input type="checkbox" id="c-39336831" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39342866">prev</a><span>|</span><a href="#39335723">next</a><span>|</span><label class="collapse" for="c-39336831">[-]</label><label class="expand" for="c-39336831">[6 more]</label></div><br/><div class="children"><div class="content">I feel the preparation and loading of the dataset has been abstracted too far away.  I have no idea what type of data format I need or how it is loaded for this (it is using a pre-prepared huggingface dataset?).  If I have local data how should it be loaded?  What does that even look like?  Is it expecting some sort of JSON?<p>When you get so far as to abstracting every step to loading a one-liner from huggingface, including the downloading of a prepared dataset with no example of doing the same on custom local dataset, you&#x27;ve abstracted too far to be useful for anyone other than the first user.</div><br/><div id="39336870" class="c"><input type="checkbox" id="c-39336870" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39336831">parent</a><span>|</span><a href="#39336998">next</a><span>|</span><label class="collapse" for="c-39336870">[-]</label><label class="expand" for="c-39336870">[3 more]</label></div><br/><div class="children"><div class="content">Thanks for the question. This is built for ML researchers, so in examples we use the defacto source for datasets researchers often use, HF Hub.<p>However, there is a lot of documentation on the site to help guide users. This documentation page shows you can load in data via local datasets as well. For example, JSON, CSV, text files, a local HF Dataset folder, or even from a Python `dict` or `list`:<p><a href="https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;datadreamer.steps.html#types-of-steps" rel="nofollow">https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;datadreamer.steps.html#t...</a><p>We&#x27;ll definitely keep improving documentation, guides, and examples. We have a lot of it already, and more to come! This has only recently become a public project :)<p>If anyone has any questions on using it, feel free to email me directly (email on the site and HN bio) for help in the meantime.</div><br/><div id="39337193" class="c"><input type="checkbox" id="c-39337193" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39336831">root</a><span>|</span><a href="#39336870">parent</a><span>|</span><a href="#39336998">next</a><span>|</span><label class="collapse" for="c-39337193">[-]</label><label class="expand" for="c-39337193">[2 more]</label></div><br/><div class="children"><div class="content">I did glance at the docs first before commenting but I was looking in &#x27;datasets&#x27; to try and understand importing a potential CSV&#x2F;JOSN etc and all I saw was verbage on accessing the output.<p>I would not have guessed that the base input data processing would have been filed under &#x27;steps&#x27;.  But now I kinda see how you are working, but I admit I&#x27;m not the target audience.<p>If you want this to really take off for people outside of a very, very specific class of researchers... setup an example on your landing page that calls to a local JSON of user prompts&#x2F;answers&#x2F;rejects finetuning a llama model with your datadreamer.steps.JSONDataSource into the loader.  Or, a txt file with the system&#x2F;user&#x2F;assistant prompts tagged and examples given.  Yes, your &#x27;lines of code&#x27; for your frontpage example may grow a bit!<p>Maybe there are a lot of &#x27;ML researchers&#x27; that are used to the type of super-abstract OOP API, load-it-from-huggingface-scheme-people you are targeting but also know that there are a ton that aren&#x27;t.</div><br/><div id="39337291" class="c"><input type="checkbox" id="c-39337291" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39336831">root</a><span>|</span><a href="#39337193">parent</a><span>|</span><a href="#39336998">next</a><span>|</span><label class="collapse" for="c-39337291">[-]</label><label class="expand" for="c-39337291">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s totally fair and good feedback, it&#x27;s hard to support everyone&#x27;s use cases simultaneously, but from my own research and other researchers we collaborate with, this solves and streamlines the right set of problems, but we want to make this as broadly useful as possible. Always happy to chat more &#x2F; provide support if you would like, feel free to reach out if you want to try it and run into any sharp edges I could help make easier.</div><br/></div></div></div></div></div></div><div id="39339907" class="c"><input type="checkbox" id="c-39339907" checked=""/><div class="controls bullet"><span class="by">ganeshkrishnan</span><span>|</span><a href="#39336831">parent</a><span>|</span><a href="#39336998">prev</a><span>|</span><a href="#39335723">next</a><span>|</span><label class="collapse" for="c-39339907">[-]</label><label class="expand" for="c-39339907">[1 more]</label></div><br/><div class="children"><div class="content">The dataset is here I presume: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;Intel&#x2F;orca_dpo_pairs" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;Intel&#x2F;orca_dpo_pairs</a><p>you can look at the samples. Mostly its questions and accepted&#x2F;rejected answers.</div><br/></div></div></div></div><div id="39335723" class="c"><input type="checkbox" id="c-39335723" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#39336831">prev</a><span>|</span><a href="#39336721">next</a><span>|</span><label class="collapse" for="c-39335723">[-]</label><label class="expand" for="c-39335723">[17 more]</label></div><br/><div class="children"><div class="content">I don’t understand the obsession of LOC for wrappers - it’s the whole point of a wrapper. It makes it much easier for the user at the expense of making it less hackable<p>Title should be instead “Library for low-code RLHF in python”</div><br/><div id="39336582" class="c"><input type="checkbox" id="c-39336582" checked=""/><div class="controls bullet"><span class="by">vvrm</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39335771">next</a><span>|</span><label class="collapse" for="c-39336582">[-]</label><label class="expand" for="c-39336582">[7 more]</label></div><br/><div class="children"><div class="content">Another problem with the title: the article is about DPO, which doesn’t do reinforcement learning. So not RLHF. I guess RLHF has more of a name recognition than DPO.</div><br/><div id="39340556" class="c"><input type="checkbox" id="c-39340556" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336582">parent</a><span>|</span><a href="#39336593">next</a><span>|</span><label class="collapse" for="c-39340556">[-]</label><label class="expand" for="c-39340556">[1 more]</label></div><br/><div class="children"><div class="content">Honestly a much bigger problem than LOC. It’s a completely different algorithm.</div><br/></div></div><div id="39336593" class="c"><input type="checkbox" id="c-39336593" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336582">parent</a><span>|</span><a href="#39340556">prev</a><span>|</span><a href="#39335771">next</a><span>|</span><label class="collapse" for="c-39336593">[-]</label><label class="expand" for="c-39336593">[5 more]</label></div><br/><div class="children"><div class="content">This was discussed in another comment, DPO is pretty much strictly better than RLHF + PPO, and far more stable when training. Yes, DPO is not technically &quot;RL&quot;, but it&#x27;s semantics for the most part. DataDreamer does support PPO training if you want, but it&#x27;s so unstable, it&#x27;s a less popular choice now.</div><br/><div id="39337032" class="c"><input type="checkbox" id="c-39337032" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336593">parent</a><span>|</span><a href="#39339362">next</a><span>|</span><label class="collapse" for="c-39337032">[-]</label><label class="expand" for="c-39337032">[2 more]</label></div><br/><div class="children"><div class="content">In the DPO paper linked from the OP page, DPO is described as &quot;a simple RL-free algorithm for training language models from preferences.&quot; So as you say, &quot;not technically RL.&quot;<p>Given that, shouldn&#x27;t the first sentence on the linked page end with &quot;...in a process known as DPO (...)&quot; ? Ditto for the title.<p>It sounds like you&#x27;re saying that the terms RL and RLHF should subsume DPO because they both solve the same problem, with similar results. But they&#x27;re different techniques, and there are  established terms for both of them.</div><br/><div id="39337107" class="c"><input type="checkbox" id="c-39337107" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39337032">parent</a><span>|</span><a href="#39339362">next</a><span>|</span><label class="collapse" for="c-39337107">[-]</label><label class="expand" for="c-39337107">[1 more]</label></div><br/><div class="children"><div class="content">I think the discussion in the other comment thread discusses this well. They are different techniques, but the line between RL &amp; SL is quite fuzzy. The DPO authors advertise this as a &quot;non-RL&quot; technique to precisely get away from the reputation of unstable training RL has, but they also say and treat the language model as an 
(implicit) reward model, similar to PPO. The point is well taken though, I will update this page to clarify the differences to avoid confusion.</div><br/></div></div></div></div><div id="39339362" class="c"><input type="checkbox" id="c-39339362" checked=""/><div class="controls bullet"><span class="by">vvrm</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336593">parent</a><span>|</span><a href="#39337032">prev</a><span>|</span><a href="#39335771">next</a><span>|</span><label class="collapse" for="c-39339362">[-]</label><label class="expand" for="c-39339362">[2 more]</label></div><br/><div class="children"><div class="content">&gt; DPO is pretty much strictly better than RLHF + PPO<p>Out of genuine curiosity, do you have any pointers&#x2F;evidence to support this. I know that some of the industry leading research labs haven&#x27;t switched over to DPO yet, in spite of the fact that DPO is significantly faster than RLHF. It might just be organizational inertia, but I do not know. I would be very happy if simpler alternatives like DPO were as good as RLHF or better, but I haven&#x27;t seen that proof yet.</div><br/><div id="39340727" class="c"><input type="checkbox" id="c-39340727" checked=""/><div class="controls bullet"><span class="by">changoplatanero</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39339362">parent</a><span>|</span><a href="#39335771">next</a><span>|</span><label class="collapse" for="c-39340727">[-]</label><label class="expand" for="c-39340727">[1 more]</label></div><br/><div class="children"><div class="content">I can second that. From what I’ve heard from people at leading labs, it’s not clear that dpo is worth switching to from RLHF</div><br/></div></div></div></div></div></div></div></div><div id="39335771" class="c"><input type="checkbox" id="c-39335771" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39336582">prev</a><span>|</span><a href="#39336158">next</a><span>|</span><label class="collapse" for="c-39335771">[-]</label><label class="expand" for="c-39335771">[1 more]</label></div><br/><div class="children"><div class="content">This is developed for researchers, so I assure it’s very hackable and configurable. ;-) but appreciate the feedback on the title!</div><br/></div></div><div id="39336158" class="c"><input type="checkbox" id="c-39336158" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39335771">prev</a><span>|</span><a href="#39339597">next</a><span>|</span><label class="collapse" for="c-39336158">[-]</label><label class="expand" for="c-39336158">[2 more]</label></div><br/><div class="children"><div class="content">This. If I&#x27;m the type of person who wants to do RLHF, then I&#x27;m the type of person who wants control and doesn&#x27;t like delegating it to imported libraries.</div><br/><div id="39336183" class="c"><input type="checkbox" id="c-39336183" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336158">parent</a><span>|</span><a href="#39339597">next</a><span>|</span><label class="collapse" for="c-39336183">[-]</label><label class="expand" for="c-39336183">[1 more]</label></div><br/><div class="children"><div class="content">This is built for ML researchers out of an academic lab. There&#x27;s a ton of functionality in the library (beyond RLHF and alignment) that ML researchers do every day to write papers and run experiments that the library helps abstract and make repeatable and usable.<p>Unless your research hypothesis is specifically around improving or changing RLHF, it&#x27;s unlikely you should be implementing it from scratch. Abstractions are useful for a reason. The library is quite configurable to let you tune any knobs you would want.</div><br/></div></div></div></div><div id="39339597" class="c"><input type="checkbox" id="c-39339597" checked=""/><div class="controls bullet"><span class="by">tgsovlerkhgsel</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39336158">prev</a><span>|</span><a href="#39335830">next</a><span>|</span><label class="collapse" for="c-39339597">[-]</label><label class="expand" for="c-39339597">[1 more]</label></div><br/><div class="children"><div class="content">Honestly the amount of complicated boilerplate that you&#x27;re supposed to write from scratch every time you do something with ML (in some of the major frameworks) deterred me from touching anything ML-related for a long time.<p>As far as I understand, what the training loop is supposed to be doing is pretty static and you don&#x27;t need to understand most of it in order to &quot;do ML&quot;, but at the same time it&#x27;s full of complicated things to get right (which would be much easier to understand when controlled through well defined parameters instead of mixing boilerplate and config).</div><br/></div></div><div id="39335830" class="c"><input type="checkbox" id="c-39335830" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39339597">prev</a><span>|</span><a href="#39336302">next</a><span>|</span><label class="collapse" for="c-39335830">[-]</label><label class="expand" for="c-39335830">[3 more]</label></div><br/><div class="children"><div class="content">I always appreciate these projects because I just dive into the code itself and copy out what I need once the wrapper becomes too much of a burden.</div><br/><div id="39335897" class="c"><input type="checkbox" id="c-39335897" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39335830">parent</a><span>|</span><a href="#39335917">next</a><span>|</span><label class="collapse" for="c-39335897">[-]</label><label class="expand" for="c-39335897">[1 more]</label></div><br/><div class="children"><div class="content">That’s totally valid and something we would even encourage! This project is for researchers so if there is a point where the abstraction is no longer useful, by all means configure, or subclass, or copy code.</div><br/></div></div><div id="39335917" class="c"><input type="checkbox" id="c-39335917" checked=""/><div class="controls bullet"><span class="by">rovr138</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39335830">parent</a><span>|</span><a href="#39335897">prev</a><span>|</span><a href="#39336302">next</a><span>|</span><label class="collapse" for="c-39335917">[-]</label><label class="expand" for="c-39335917">[1 more]</label></div><br/><div class="children"><div class="content">Of course. And they&#x27;re not saying they don&#x27;t have a place.<p>They&#x27;re saying why does it matter if it&#x27;s 50 vs 60 or even 100. It&#x27;s a wrapper, which should be less lines. That&#x27;s the whole point. Abstracting things even further and making assumptions.<p>Of course you can use them. Of course you can remove them after and use the underlying code. But the LOC shouldn&#x27;t be the important part of it</div><br/></div></div></div></div><div id="39336302" class="c"><input type="checkbox" id="c-39336302" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39335723">parent</a><span>|</span><a href="#39335830">prev</a><span>|</span><a href="#39336721">next</a><span>|</span><label class="collapse" for="c-39336302">[-]</label><label class="expand" for="c-39336302">[2 more]</label></div><br/><div class="children"><div class="content">Yes you do. Most casuals are downright afraid of code. This messaging is meant to make the project more approachable.<p>Kind of like everybody knows the pop-science around e = mc^2 but most are completely oblivious that it takes a bunch of whiteboards to derive it and what all that actually means.<p>No pithy formula no way for the actual ideas to spread to the mainstream for you to somehow hear about it.</div><br/><div id="39336787" class="c"><input type="checkbox" id="c-39336787" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#39335723">root</a><span>|</span><a href="#39336302">parent</a><span>|</span><a href="#39336721">next</a><span>|</span><label class="collapse" for="c-39336787">[-]</label><label class="expand" for="c-39336787">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of the advice Stephen Hawking&#x27;s publisher gave him, which was that every equation he included in his book, A Brief History of Time, would cut the sales of the book in half. As a result the only equation that ended up in the book was E=mc^2.</div><br/></div></div></div></div></div></div><div id="39336721" class="c"><input type="checkbox" id="c-39336721" checked=""/><div class="controls bullet"><span class="by">lopkeny12ko</span><span>|</span><a href="#39335723">prev</a><span>|</span><a href="#39335766">next</a><span>|</span><label class="collapse" for="c-39336721">[-]</label><label class="expand" for="c-39336721">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not 50 lines of code if all the real work is done by importing a library...<p>That&#x27;s like saying, I can solve any problem in 2 lines of code. I&#x27;ll publish a library for it first, then:<p>import foo; foo.do_the_thing()<p>Magic!</div><br/><div id="39336948" class="c"><input type="checkbox" id="c-39336948" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#39336721">parent</a><span>|</span><a href="#39337780">next</a><span>|</span><label class="collapse" for="c-39336948">[-]</label><label class="expand" for="c-39336948">[1 more]</label></div><br/><div class="children"><div class="content">Software developers hate this one simple trick!</div><br/></div></div><div id="39337780" class="c"><input type="checkbox" id="c-39337780" checked=""/><div class="controls bullet"><span class="by">peab</span><span>|</span><a href="#39336721">parent</a><span>|</span><a href="#39336948">prev</a><span>|</span><a href="#39340710">next</a><span>|</span><label class="collapse" for="c-39337780">[-]</label><label class="expand" for="c-39337780">[5 more]</label></div><br/><div class="children"><div class="content">did people say the same thing when assembly code got abstracted away?</div><br/><div id="39340996" class="c"><input type="checkbox" id="c-39340996" checked=""/><div class="controls bullet"><span class="by">orblivion</span><span>|</span><a href="#39336721">root</a><span>|</span><a href="#39337780">parent</a><span>|</span><a href="#39338382">next</a><span>|</span><label class="collapse" for="c-39340996">[-]</label><label class="expand" for="c-39340996">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s levels of abstraction. &quot;lines of Python&quot; to me roughly means the standard library.</div><br/><div id="39341640" class="c"><input type="checkbox" id="c-39341640" checked=""/><div class="controls bullet"><span class="by">sciolist</span><span>|</span><a href="#39336721">root</a><span>|</span><a href="#39340996">parent</a><span>|</span><a href="#39338382">next</a><span>|</span><label class="collapse" for="c-39341640">[-]</label><label class="expand" for="c-39341640">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. If it was &quot;RLHF a LLM in &lt;50 lines&quot; I feel it would be clear, but &quot;lines of Python&quot; implies something different.</div><br/></div></div></div></div><div id="39338382" class="c"><input type="checkbox" id="c-39338382" checked=""/><div class="controls bullet"><span class="by">skelpmargyar</span><span>|</span><a href="#39336721">root</a><span>|</span><a href="#39337780">parent</a><span>|</span><a href="#39340996">prev</a><span>|</span><a href="#39340710">next</a><span>|</span><label class="collapse" for="c-39338382">[-]</label><label class="expand" for="c-39338382">[2 more]</label></div><br/><div class="children"><div class="content">Importing a library is not abstraction any more than closing your eyes is abstracting the world to black.</div><br/><div id="39340941" class="c"><input type="checkbox" id="c-39340941" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39336721">root</a><span>|</span><a href="#39338382">parent</a><span>|</span><a href="#39340710">next</a><span>|</span><label class="collapse" for="c-39340941">[-]</label><label class="expand" for="c-39340941">[1 more]</label></div><br/><div class="children"><div class="content">The point of libraries is abstraction. You get to use the library without writing the library or knowing the underlying implementation.</div><br/></div></div></div></div></div></div><div id="39340710" class="c"><input type="checkbox" id="c-39340710" checked=""/><div class="controls bullet"><span class="by">therealdrag0</span><span>|</span><a href="#39336721">parent</a><span>|</span><a href="#39337780">prev</a><span>|</span><a href="#39335766">next</a><span>|</span><label class="collapse" for="c-39340710">[-]</label><label class="expand" for="c-39340710">[1 more]</label></div><br/><div class="children"><div class="content">[relevant xkcd]</div><br/></div></div></div></div><div id="39335766" class="c"><input type="checkbox" id="c-39335766" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39336721">prev</a><span>|</span><a href="#39335769">next</a><span>|</span><label class="collapse" for="c-39335766">[-]</label><label class="expand" for="c-39335766">[3 more]</label></div><br/><div class="children"><div class="content">Hi everyone, there are no easy tools for synthetic data generation or training and aligning LLMs simply in Python. Most of the stuff out there are messy adhoc scripts.<p>DataDreamer is an open source Python package with a nice API from the University of Pennsylvania that does all this that we’re actively developing. Will be here to answer questions.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;datadreamer-dev&#x2F;DataDreamer">https:&#x2F;&#x2F;github.com&#x2F;datadreamer-dev&#x2F;DataDreamer</a></div><br/><div id="39335874" class="c"><input type="checkbox" id="c-39335874" checked=""/><div class="controls bullet"><span class="by">baggiponte</span><span>|</span><a href="#39335766">parent</a><span>|</span><a href="#39335769">next</a><span>|</span><label class="collapse" for="c-39335874">[-]</label><label class="expand" for="c-39335874">[2 more]</label></div><br/><div class="children"><div class="content">The API looks nice, congratulations. Will experiment with it. One small silly question: why did you choose to specify the dependencies inside the src dir with the requirements format - rather than inside the pyproject?</div><br/><div id="39335887" class="c"><input type="checkbox" id="c-39335887" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335766">root</a><span>|</span><a href="#39335874">parent</a><span>|</span><a href="#39335769">next</a><span>|</span><label class="collapse" for="c-39335887">[-]</label><label class="expand" for="c-39335887">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! It makes it easier to run with the existing run scripts I have on our large university GPU cluster. :) no other reason</div><br/></div></div></div></div></div></div><div id="39335769" class="c"><input type="checkbox" id="c-39335769" checked=""/><div class="controls bullet"><span class="by">g4zj</span><span>|</span><a href="#39335766">prev</a><span>|</span><a href="#39335831">next</a><span>|</span><label class="collapse" for="c-39335769">[-]</label><label class="expand" for="c-39335769">[2 more]</label></div><br/><div class="children"><div class="content">Very cool, but I can&#x27;t help but feel like titles that reference low-LOC are a bit clickbait-y when nearly all the heavy lifting is done by imported libraries.</div><br/><div id="39335805" class="c"><input type="checkbox" id="c-39335805" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335769">parent</a><span>|</span><a href="#39335831">next</a><span>|</span><label class="collapse" for="c-39335805">[-]</label><label class="expand" for="c-39335805">[1 more]</label></div><br/><div class="children"><div class="content">Appreciate the feedback on the title, this is developed for ML researchers, so I assure there is a lot it’s doing under the hood to make this process easier (for example introducing automatic caching and resumability).<p>However, we also tried to simplify the API and have sensible defaults to make it usable for anyone &#x2F; make ML research code cleaner :)</div><br/></div></div></div></div><div id="39335831" class="c"><input type="checkbox" id="c-39335831" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#39335769">prev</a><span>|</span><a href="#39337368">next</a><span>|</span><label class="collapse" for="c-39335831">[-]</label><label class="expand" for="c-39335831">[10 more]</label></div><br/><div class="children"><div class="content">The first paragraphs says RLHF can be used to align models, and the seconds say here&#x27;s how to do it by using DPO. These two methods are not the same, and the latter is not an instance of the former.</div><br/><div id="39335858" class="c"><input type="checkbox" id="c-39335858" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335831">parent</a><span>|</span><a href="#39335845">next</a><span>|</span><label class="collapse" for="c-39335858">[-]</label><label class="expand" for="c-39335858">[1 more]</label></div><br/><div class="children"><div class="content">Fair, DPO is considered a fairly well established technique now that is far more stable in training than PPO, but also helps align LLMs from human feedback. The package also helps do PPO, so you can do traditional RLHF, but figured more people would be interested in seeing a DPO example, given how unstable PPO is.</div><br/></div></div><div id="39335845" class="c"><input type="checkbox" id="c-39335845" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#39335831">parent</a><span>|</span><a href="#39335858">prev</a><span>|</span><a href="#39337368">next</a><span>|</span><label class="collapse" for="c-39335845">[-]</label><label class="expand" for="c-39335845">[8 more]</label></div><br/><div class="children"><div class="content">The latter is strictly superior to the former though. RlHF has been abandoned in the open source world.</div><br/><div id="39335871" class="c"><input type="checkbox" id="c-39335871" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335845">parent</a><span>|</span><a href="#39335862">next</a><span>|</span><label class="collapse" for="c-39335871">[-]</label><label class="expand" for="c-39335871">[5 more]</label></div><br/><div class="children"><div class="content">Yep, DPO is not technically “RL” and implicitly uses the LLM itself as a reward model, but training with DPO is far more stable for that reason.</div><br/><div id="39335993" class="c"><input type="checkbox" id="c-39335993" checked=""/><div class="controls bullet"><span class="by">espadrine</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335871">parent</a><span>|</span><a href="#39336009">next</a><span>|</span><label class="collapse" for="c-39335993">[-]</label><label class="expand" for="c-39335993">[3 more]</label></div><br/><div class="children"><div class="content">DPO is as close to RL as RLHF. The latter also uses the LLM as a reward model.<p>I&#x27;m not a fan of the RL&#x2F;SL dichotomy, because the line gets so foggy. If you squint, every loss is a negative reward, and every policy improvement a supervised target.<p>Still, what the code does isn&#x27;t what is described in the paper that the page links to.</div><br/><div id="39336168" class="c"><input type="checkbox" id="c-39336168" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335993">parent</a><span>|</span><a href="#39336009">next</a><span>|</span><label class="collapse" for="c-39336168">[-]</label><label class="expand" for="c-39336168">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not a fan of the RL&#x2F;SL dichotomy, because the line gets so foggy. If you squint, every loss is a negative reward, and every policy improvement a supervised target.<p>Isn&#x27;t this just because reinforcement learning and supervised learning are both optimization problems?</div><br/><div id="39336275" class="c"><input type="checkbox" id="c-39336275" checked=""/><div class="controls bullet"><span class="by">espadrine</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39336168">parent</a><span>|</span><a href="#39336009">next</a><span>|</span><label class="collapse" for="c-39336275">[-]</label><label class="expand" for="c-39336275">[1 more]</label></div><br/><div class="children"><div class="content">In part, yes! But also because what used to define it was the human-curated datasets: SL contained input&#x2F;output pairs, while RL contained episodes with sporadic rewards.<p>Nowadays, many datasets have different forms or are synthetic. DPO uses datasets with both positive and negative examples (instead of just a target output as with traditional SL); RLHF uses synthetic rewards.</div><br/></div></div></div></div></div></div><div id="39336009" class="c"><input type="checkbox" id="c-39336009" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335871">parent</a><span>|</span><a href="#39335993">prev</a><span>|</span><a href="#39335862">next</a><span>|</span><label class="collapse" for="c-39336009">[-]</label><label class="expand" for="c-39336009">[1 more]</label></div><br/><div class="children"><div class="content">I tend to agree @espadrine, it&#x27;s semantics for the most part</div><br/></div></div></div></div><div id="39335862" class="c"><input type="checkbox" id="c-39335862" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335845">parent</a><span>|</span><a href="#39335871">prev</a><span>|</span><a href="#39337368">next</a><span>|</span><label class="collapse" for="c-39335862">[-]</label><label class="expand" for="c-39335862">[2 more]</label></div><br/><div class="children"><div class="content">I am just saying the intro paragraphs are confusing.</div><br/><div id="39335873" class="c"><input type="checkbox" id="c-39335873" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39335831">root</a><span>|</span><a href="#39335862">parent</a><span>|</span><a href="#39337368">next</a><span>|</span><label class="collapse" for="c-39335873">[-]</label><label class="expand" for="c-39335873">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, appreciate the feedback, will update when I get a chance!</div><br/></div></div></div></div></div></div></div></div><div id="39337368" class="c"><input type="checkbox" id="c-39337368" checked=""/><div class="controls bullet"><span class="by">proto-n</span><span>|</span><a href="#39335831">prev</a><span>|</span><a href="#39338294">next</a><span>|</span><label class="collapse" for="c-39337368">[-]</label><label class="expand" for="c-39337368">[1 more]</label></div><br/><div class="children"><div class="content">Yeah well in bash I can do it in one line: `python train.py`. I hate examples like this, the 50loc statement is totally useless (and so is the code example, as I can&#x27;t learning anything from it).</div><br/></div></div><div id="39338294" class="c"><input type="checkbox" id="c-39338294" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#39337368">prev</a><span>|</span><a href="#39339016">next</a><span>|</span><label class="collapse" for="c-39338294">[-]</label><label class="expand" for="c-39338294">[1 more]</label></div><br/><div class="children"><div class="content">Interested if local RLHF is actually viable; can you get meaningful steering from 1k feedback points on a narrow task? I feel that annotation count is achievable with a single dedicated annotator making a few comments per minute (though tedious), 10k would be a week of work so achievable for a very dedicated hobbyist, and 100k seems out of reach for a hobby project.<p>Say for simple conversation usecases (eg customer support for a specific product, interactive fiction, things like that without deep technical knowledge).<p>I was also wondering if it’s possible to do such RLHF for SD running locally.</div><br/></div></div><div id="39339016" class="c"><input type="checkbox" id="c-39339016" checked=""/><div class="controls bullet"><span class="by">aethelyon</span><span>|</span><a href="#39338294">prev</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339016">[-]</label><label class="expand" for="c-39339016">[8 more]</label></div><br/><div class="children"><div class="content">This is cool, but the data collection is the hard part, right?</div><br/><div id="39339031" class="c"><input type="checkbox" id="c-39339031" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39339016">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339031">[-]</label><label class="expand" for="c-39339031">[7 more]</label></div><br/><div class="children"><div class="content">Yes it is :), but the library is also a synthetic data generation library, so for example you can create the data for DPO fully synthetically, check out the self-rewarding LLMs example:<p><a href="https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;pages&#x2F;get_started&#x2F;quick_tour&#x2F;self_rewarding.html" rel="nofollow">https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;pages&#x2F;get_started&#x2F;quick_...</a></div><br/><div id="39339356" class="c"><input type="checkbox" id="c-39339356" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39339031">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339356">[-]</label><label class="expand" for="c-39339356">[6 more]</label></div><br/><div class="children"><div class="content">I’m extremely skeptical of this approach. Until proven otherwise, with a model that users actually find useful, I don’t think this can work.<p>It would be nice. But I’ve seen too many nice ideas completely fall apart in practice to accept this without some justification. Even if there are papers on the topic, and those papers show that the models rank highly according to some eval metrics, the only metric that truly matters is &quot;the user likes the model and it solves their problems.&quot;<p>By the way, on a separate topic, the 90&#x2F;10 dataset split that you do in all of your examples turns out to be fraught with peril in practice. The issue is that the validation dataset <i>quality</i> turns out to be crucial, and randomly yeeting 10% of your data into the validation dataset without manual review is a recipe for problems.</div><br/><div id="39339423" class="c"><input type="checkbox" id="c-39339423" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39339356">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339423">[-]</label><label class="expand" for="c-39339423">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a demo snippet of how to setup the workflow, it&#x27;s not meant to be a working production example a self-rewarding model or a faithful reproduction of the original paper. Whether self-rewarding LLMs are a good idea or not, it&#x27;s a valuable and very active area of research in the literature today.  This is a library for ML researchers who should actively research and study these avenues along with the pitfalls you&#x27;re mentioning. But in order for them to do that, building these workflows have to be accessible to them, which is what this library is meant to do. It&#x27;s not meant for the &quot;hobbyist&quot; ML-community, they should not be using synthetic data today in this way, it would likely lead to subpar results for any practical model or task.</div><br/><div id="39339771" class="c"><input type="checkbox" id="c-39339771" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39339423">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339771">[-]</label><label class="expand" for="c-39339771">[4 more]</label></div><br/><div class="children"><div class="content">There’s a lot to unpack here.<p>First, I’m an ML researcher. I don’t go around saying so because appeal to authority is bogus, but since every one of your comments seems to do this, it’s unavoidable.<p>You say the code is for ML researchers, then flat out say that it’s not a working production example, nor is it a faithful reproduction of a paper. So what is it?<p>Whether you want it to be or not, your audience <i>is</i> the hobbyist ML community, because without benchmarks to back up your code examples, no one from the research community will trust your examples without actual proof that they work. That’s the hard part of research, and it’s most of the effort.<p>My advice is, write something that can train useful models. Implement a production grade workflow, and show some reasons why it works. If you’re trying to get the wider ML research community to buy in to this, there’s not much other way to do it. No one will want to take easy code that does the wrong thing, and most of your examples show the wrong thing to do, like the 90&#x2F;10 split.<p>You’re also a bit defensive about accepting feedback. Trust me that it’s better to accept that your code sucks and does the wrong thing, and then try to make it suck less and do the right thing. That’s how the majority of good software is written, unless you’re cperciva. But he’d also publish a paper explaining why his code is correct.<p>Anyway, the whole point of posting this to HN is to get feedback on it. (If you were hoping that a bunch of people would suddenly use it, then you need to appeal to the hobbyist community. They’ve told you a bunch of things that you’ve straight up said is out of scope.) And it sounds like you were hoping for feedback from ML researchers. Maybe others will chime in, but for now, that’s the best I’ve got.</div><br/><div id="39339818" class="c"><input type="checkbox" id="c-39339818" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39339771">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39339818">[-]</label><label class="expand" for="c-39339818">[3 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re interpreting hostility where there is none, so I don&#x27;t have much to say other than it&#x27;s an infrastructure library, a demonstration snippet doesn&#x27;t need to show how to train a production grade model. I appreciate the feedback and it&#x27;s noted.</div><br/><div id="39340195" class="c"><input type="checkbox" id="c-39340195" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39339818">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39340195">[-]</label><label class="expand" for="c-39340195">[2 more]</label></div><br/><div class="children"><div class="content">Well, this is a decent example. I didn’t say you were hostile, just defensive.<p>As an ML researcher, infrastructure libraries need to show how to train a production grade model, or else they’re useless for research. This is why research is hard. You keep handwaving this in various ways, but if you want ML researchers to take this seriously, you need a serious example.<p>&quot;Production grade&quot; doesn’t mean that it needs to have a deployable API. It memes the model needs to not suck. And until your training code can train a model that doesn’t suck, every ML researcher will view this and think &quot;this code is guaranteed to produce a model that sucks,&quot; since there’s no evidence to the contrary. It’s incredibly hard to get the details right, and I can’t count the number of times I’ve had to track down some obscure bug buried deep within abstraction layers.<p>I’m trying to help you here. Ask yourself: who are my users? Are your users ML researchers? I already explained the problems we have, and why your library doesn’t meet those needs. Are your users ML hobbyists? You’ve already said no to this, and I think that’s a mistake. Most ML researchers behave as hobbyists, in the sense that they’re always looking for simple, understandable examples. Your library gives that, but without any of the rigor necessary to show that it can be trusted. Are your users ML devops, since it’s infrastructure? No, because it’s training models.<p>So you’re excluding every possible user, whether you realize it or not. But we’ll see; in a few months, if your library has significant traction, I’m empirically wrong. But I’m trying to help you avoid the default outcome of nobody uses your code because you’re not designing it for any particular user.</div><br/><div id="39340283" class="c"><input type="checkbox" id="c-39340283" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39339016">root</a><span>|</span><a href="#39340195">parent</a><span>|</span><a href="#39336861">next</a><span>|</span><label class="collapse" for="c-39340283">[-]</label><label class="expand" for="c-39340283">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for clarifying, for the record, I generally agree with you. I think we just disagree on the snippets and how in-depth they need to be. Our library is built on HF libraries (we don&#x27;t implement the training code ourselves), which are popular and commonly utilized by researchers, and people know how to build good models on those libraries. The package is simply meant to provide an easier interface to create some of these complex multi-stage LLM workflows that are starting to become common at ML research conferences and reduce boilerplate code around common functions (caching or tokenizing).<p>But I hear you on it would be useful to also have some examples that show a proper, reliable model being trained with the library v.s. just example models. The project is pretty early, and we&#x27;ll work on adding more examples.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39336861" class="c"><input type="checkbox" id="c-39336861" checked=""/><div class="controls bullet"><span class="by">bbstats</span><span>|</span><a href="#39339016">prev</a><span>|</span><a href="#39338972">next</a><span>|</span><label class="collapse" for="c-39336861">[-]</label><label class="expand" for="c-39336861">[1 more]</label></div><br/><div class="children"><div class="content">I can abstract this to 2 lines</div><br/></div></div><div id="39338972" class="c"><input type="checkbox" id="c-39338972" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#39336861">prev</a><span>|</span><a href="#39337333">next</a><span>|</span><label class="collapse" for="c-39338972">[-]</label><label class="expand" for="c-39338972">[2 more]</label></div><br/><div class="children"><div class="content">How do you normally do DPO? Is that built in to PyTorch or something?<p>Theoretically the hard part is collecting the examples with rejections etc.</div><br/><div id="39339053" class="c"><input type="checkbox" id="c-39339053" checked=""/><div class="controls bullet"><span class="by">patelajay285</span><span>|</span><a href="#39338972">parent</a><span>|</span><a href="#39337333">next</a><span>|</span><label class="collapse" for="c-39339053">[-]</label><label class="expand" for="c-39339053">[1 more]</label></div><br/><div class="children"><div class="content">Collecting data is hard, but the library is also a synthetic data generation library, so for example you can create the data for DPO fully synthetically, check out the self-rewarding LLMs example:
<a href="https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;pages&#x2F;get_started&#x2F;quick_" rel="nofollow">https:&#x2F;&#x2F;datadreamer.dev&#x2F;docs&#x2F;latest&#x2F;pages&#x2F;get_started&#x2F;quick_</a>...</div><br/></div></div></div></div><div id="39337333" class="c"><input type="checkbox" id="c-39337333" checked=""/><div class="controls bullet"><span class="by">spdustin</span><span>|</span><a href="#39338972">prev</a><span>|</span><a href="#39338189">next</a><span>|</span><label class="collapse" for="c-39337333">[-]</label><label class="expand" for="c-39337333">[1 more]</label></div><br/><div class="children"><div class="content">It occurs to me that there must be a model that&#x27;s been &quot;aligned&quot; opposite to the usual RLHF. Or has nobody done that?</div><br/></div></div><div id="39338189" class="c"><input type="checkbox" id="c-39338189" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#39337333">prev</a><span>|</span><a href="#39337995">next</a><span>|</span><label class="collapse" for="c-39338189">[-]</label><label class="expand" for="c-39338189">[1 more]</label></div><br/><div class="children"><div class="content">This seems useful, thanks!</div><br/></div></div><div id="39337995" class="c"><input type="checkbox" id="c-39337995" checked=""/><div class="controls bullet"><span class="by">rrr_oh_man</span><span>|</span><a href="#39338189">prev</a><span>|</span><a href="#39336954">next</a><span>|</span><label class="collapse" for="c-39337995">[-]</label><label class="expand" for="c-39337995">[1 more]</label></div><br/><div class="children"><div class="content">RLHF = Reinforcement Learning from Human Feedback</div><br/></div></div><div id="39336954" class="c"><input type="checkbox" id="c-39336954" checked=""/><div class="controls bullet"><span class="by">MrYellowP</span><span>|</span><a href="#39337995">prev</a><span>|</span><label class="collapse" for="c-39336954">[-]</label><label class="expand" for="c-39336954">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t prefer aligned models and I&#x27;m a human. It&#x27;s not okay to claim that that&#x27;s what humans prefer. There might be a subset of humans who can&#x27;t handle words, but they&#x27;re not even remotely in the majority.<p>Algined models are dumber, treat everyone like they&#x27;re stupid immature idiots who can&#x27;t handle words and they&#x27;re a wannabe moral authority.</div><br/></div></div></div></div></div></div></div></body></html>