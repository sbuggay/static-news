<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735722057169" as="style"/><link rel="stylesheet" href="styles.css?v=1735722057169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/facebookresearch/large_concept_model">Large Concept Models: Language modeling in a sentence representation space</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>batata_frita</span> | <span>12 comments</span></div><br/><div><div id="42564692" class="c"><input type="checkbox" id="c-42564692" checked=""/><div class="controls bullet"><span class="by">stravant</span><span>|</span><a href="#42564511">next</a><span>|</span><label class="collapse" for="c-42564692">[-]</label><label class="expand" for="c-42564692">[2 more]</label></div><br/><div class="children"><div class="content">This feels like a failure to learn the bitter lesson: You&#x27;re just taking the translation to concepts that the LLM is certainly already doing and trying to make it explicitly forced.</div><br/><div id="42564713" class="c"><input type="checkbox" id="c-42564713" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#42564692">parent</a><span>|</span><a href="#42564511">next</a><span>|</span><label class="collapse" for="c-42564713">[-]</label><label class="expand" for="c-42564713">[1 more]</label></div><br/><div class="children"><div class="content">That should be proven. The two approaches - predicting tokens vs predicting &quot;sentences&quot; - should be compared to see how much their output differ in terms of quality.<p>Edit2: ...and both (and their variants) be compared to other ideas such as &quot;multi-token prediction&quot;...<p>Edit: or, appropriateness of the approach should be demonstrated after acquired &quot;transparency&quot; of how the LLMs effectively internally work. I am not aware of studies that make that adequately clear.</div><br/></div></div></div></div><div id="42564511" class="c"><input type="checkbox" id="c-42564511" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#42564692">prev</a><span>|</span><a href="#42563908">next</a><span>|</span><label class="collapse" for="c-42564511">[-]</label><label class="expand" for="c-42564511">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Current best practice for large scale language modeling is to operate at the token level, i.e. to learn to predict the next tokens given a sequence of preceding tokens. There is a large body of research on improvements of LLMs, but most works concentrate on incremental changes and do not question the main underlying architecture. In this paper, we have proposed a new architecture,</i><p>For some 2024 may have ended badly,<p>but reading the lines above shines a great light of hope for the new year.</div><br/></div></div><div id="42563908" class="c"><input type="checkbox" id="c-42563908" checked=""/><div class="controls bullet"><span class="by">inshard</span><span>|</span><a href="#42564511">prev</a><span>|</span><a href="#42564168">next</a><span>|</span><label class="collapse" for="c-42563908">[-]</label><label class="expand" for="c-42563908">[1 more]</label></div><br/><div class="children"><div class="content">This is interesting. I wonder if such a project could dive into lower-level concepts, those akin to prime numbers. The atoms from which all other concepts are built.</div><br/></div></div><div id="42564168" class="c"><input type="checkbox" id="c-42564168" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#42563908">prev</a><span>|</span><a href="#42564187">next</a><span>|</span><label class="collapse" for="c-42564168">[-]</label><label class="expand" for="c-42564168">[1 more]</label></div><br/><div class="children"><div class="content">Between this and learned patches and ModernBERT and DeepSeek?<p>I think it’s time to read up.</div><br/></div></div><div id="42564187" class="c"><input type="checkbox" id="c-42564187" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#42564168">prev</a><span>|</span><label class="collapse" for="c-42564187">[-]</label><label class="expand" for="c-42564187">[6 more]</label></div><br/><div class="children"><div class="content">This is like going back to CNNs. Attention is all you need.</div><br/><div id="42564334" class="c"><input type="checkbox" id="c-42564334" checked=""/><div class="controls bullet"><span class="by">zed1726</span><span>|</span><a href="#42564187">parent</a><span>|</span><a href="#42564390">next</a><span>|</span><label class="collapse" for="c-42564334">[-]</label><label class="expand" for="c-42564334">[4 more]</label></div><br/><div class="children"><div class="content">Quantum states are all one really needs, but it turns out that it&#x27;s way to computationally expensive to simulate all that just for the purpose of AI applications - so instead we have to go to higher levels of construction. Attention is surely <i>just about</i> on the cusp of what is computationally reasonable which means that it&#x27;s not all we need, we need more efficient and richer constructions.</div><br/><div id="42564525" class="c"><input type="checkbox" id="c-42564525" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#42564187">root</a><span>|</span><a href="#42564334">parent</a><span>|</span><a href="#42564373">next</a><span>|</span><label class="collapse" for="c-42564525">[-]</label><label class="expand" for="c-42564525">[1 more]</label></div><br/><div class="children"><div class="content">We do not need quantum states to build (arithmetic) calculators. Nor, very probably, for complex and much more complex calculators.</div><br/></div></div><div id="42564373" class="c"><input type="checkbox" id="c-42564373" checked=""/><div class="controls bullet"><span class="by">katamari-damacy</span><span>|</span><a href="#42564187">root</a><span>|</span><a href="#42564334">parent</a><span>|</span><a href="#42564525">prev</a><span>|</span><a href="#42564390">next</a><span>|</span><label class="collapse" for="c-42564373">[-]</label><label class="expand" for="c-42564373">[2 more]</label></div><br/><div class="children"><div class="content">Yes, just spray Quantum on it</div><br/><div id="42564408" class="c"><input type="checkbox" id="c-42564408" checked=""/><div class="controls bullet"><span class="by">chronic4948412</span><span>|</span><a href="#42564187">root</a><span>|</span><a href="#42564373">parent</a><span>|</span><a href="#42564390">next</a><span>|</span><label class="collapse" for="c-42564408">[-]</label><label class="expand" for="c-42564408">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, just spray Quantum on it<p>Careful, don’t give Sam Altman any ideas.<p>Once OpenAI cannot raise enough capital, he will aim quantum AGI.</div><br/></div></div></div></div></div></div><div id="42564390" class="c"><input type="checkbox" id="c-42564390" checked=""/><div class="controls bullet"><span class="by">snake_doc</span><span>|</span><a href="#42564187">parent</a><span>|</span><a href="#42564334">prev</a><span>|</span><label class="collapse" for="c-42564390">[-]</label><label class="expand" for="c-42564390">[1 more]</label></div><br/><div class="children"><div class="content">Attention is just communication? It’s orthogonal to the space of the representation.</div><br/></div></div></div></div></div></div></div></div></div></body></html>