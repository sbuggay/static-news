<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1689066068329" as="style"/><link rel="stylesheet" href="styles.css?v=1689066068329"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://threadreaderapp.com/thread/1678545170508267522.html">GPT-4 details leaked?</a> <span class="domain">(<a href="https://threadreaderapp.com">threadreaderapp.com</a>)</span></div><div class="subtext"><span>bx376</span> | <span>225 comments</span></div><br/><div><div id="36676294" class="c"><input type="checkbox" id="c-36676294" checked=""/><div class="controls bullet"><span class="by">neonate</span><span>|</span><a href="#36676470">next</a><span>|</span><label class="collapse" for="c-36676294">[-]</label><label class="expand" for="c-36676294">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.ph&#x2F;2RQ8X" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;2RQ8X</a></div><br/></div></div><div id="36676470" class="c"><input type="checkbox" id="c-36676470" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#36676294">prev</a><span>|</span><a href="#36676278">next</a><span>|</span><label class="collapse" for="c-36676470">[-]</label><label class="expand" for="c-36676470">[100 more]</label></div><br/><div class="children"><div class="content">&quot;Open&quot; AI, a charity to benefit us all by pushing and publishing the frontier of scientific knowledge.<p>Nevermind, fuckers, actually it&#x27;s just to take your jobs and make a few VCs richer. We&#x27;ll keep the science a secret and try to pressure the government into making it illegal for you to compete with us.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;openlm-research&#x2F;open_llama">https:&#x2F;&#x2F;github.com&#x2F;openlm-research&#x2F;open_llama</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;open-llama-7b-open-instruct-GGML" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;open-llama-7b-open-instruct-...</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;open-llama-13b-open-instruct-GGML" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;open-llama-13b-open-instruct...</a><p>You can use the above without paying OpenAI. You don&#x27;t even need a GPU. There are no license issues like with the facebook llama.</div><br/><div id="36678015" class="c"><input type="checkbox" id="c-36678015" checked=""/><div class="controls bullet"><span class="by">grondilu</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676751">next</a><span>|</span><label class="collapse" for="c-36678015">[-]</label><label class="expand" for="c-36678015">[1 more]</label></div><br/><div class="children"><div class="content">&gt; try to pressure the government into making it illegal for you to compete with us.<p>I mean the guy who created GPT-4 literally demanded a ban of any system more powerful than GPT-4.</div><br/></div></div><div id="36676751" class="c"><input type="checkbox" id="c-36676751" checked=""/><div class="controls bullet"><span class="by">kyledrake</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36678015">prev</a><span>|</span><a href="#36676851">next</a><span>|</span><label class="collapse" for="c-36676751">[-]</label><label class="expand" for="c-36676751">[22 more]</label></div><br/><div class="children"><div class="content">Unfortunately I&#x27;ve found the current OSS models to be vastly inferior to the OpenAI models. Would love to see someone actually get close to what they can do with GPT-3.5&#x2F;4, except capable of running on commodity GPUs. What&#x27;s the most impressive open model so far?</div><br/><div id="36677039" class="c"><input type="checkbox" id="c-36677039" checked=""/><div class="controls bullet"><span class="by">juliensalinas</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676751">parent</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677039">[-]</label><label class="expand" for="c-36677039">[11 more]</label></div><br/><div class="children"><div class="content">LLaMA 30B or 60B can be very impressive when correctly prompted.
Deploying the 60B version is a challenge though and you might need to apply 4-bit quantization with something like <a href="https:&#x2F;&#x2F;github.com&#x2F;PanQiWei&#x2F;AutoGPTQ">https:&#x2F;&#x2F;github.com&#x2F;PanQiWei&#x2F;AutoGPTQ</a> or <a href="https:&#x2F;&#x2F;github.com&#x2F;qwopqwop200&#x2F;GPTQ-for-LLaMa">https:&#x2F;&#x2F;github.com&#x2F;qwopqwop200&#x2F;GPTQ-for-LLaMa</a> . Then you can improve the inference speed by using <a href="https:&#x2F;&#x2F;github.com&#x2F;turboderp&#x2F;exllama">https:&#x2F;&#x2F;github.com&#x2F;turboderp&#x2F;exllama</a> .<p>If you prefer to use an &quot;instruct&quot; model à la ChatGPT (i.e. that does not need few-shot learning to output good results) you can use something like this: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;Wizard-Vicuna-30B-Uncensored-fp16" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;Wizard-Vicuna-30B-Uncensored...</a>
The interesting thing with these Uncensored models is that they don&#x27;t constantly answer that they cannot help you (which is what ChatGPT and GPT-4 are doing more and more).</div><br/><div id="36677369" class="c"><input type="checkbox" id="c-36677369" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677039">parent</a><span>|</span><a href="#36677062">next</a><span>|</span><label class="collapse" for="c-36677369">[-]</label><label class="expand" for="c-36677369">[5 more]</label></div><br/><div class="children"><div class="content">4-bit quantization removes a lot of the model&#x27;s sophistication, and 60B parameters is still smaller than what GPT4 is using.</div><br/><div id="36677829" class="c"><input type="checkbox" id="c-36677829" checked=""/><div class="controls bullet"><span class="by">johnnyworker</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677369">parent</a><span>|</span><a href="#36678202">next</a><span>|</span><label class="collapse" for="c-36677829">[-]</label><label class="expand" for="c-36677829">[2 more]</label></div><br/><div class="children"><div class="content">The point is that it&#x27;s <i>infinitely</i> better in not being there &quot;just to take your jobs and make a few VCs richer&quot;. Nobody even claimed it&#x27;s more performant. It&#x27;s like the difference getting nothing, but keeping your land, and getting glass pearls, losing your land. You have to completely ignore the meat of the argument to even pretend there is a contest.<p>And this is without considering what happened if we stopped  feeding hostile actors and supported ourselves, instead of keeping to do the reverse. Not just here and there, but consistently for decades.</div><br/><div id="36678183" class="c"><input type="checkbox" id="c-36678183" checked=""/><div class="controls bullet"><span class="by">motoxpro</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677829">parent</a><span>|</span><a href="#36678202">next</a><span>|</span><label class="collapse" for="c-36678183">[-]</label><label class="expand" for="c-36678183">[1 more]</label></div><br/><div class="children"><div class="content">There is no way I am going to spin up my own worse LLM so a few people will make less money. Even if it was 1-5% better. It&#x27;s just not worth the time.</div><br/></div></div></div></div><div id="36678202" class="c"><input type="checkbox" id="c-36678202" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677369">parent</a><span>|</span><a href="#36677829">prev</a><span>|</span><a href="#36678124">next</a><span>|</span><label class="collapse" for="c-36678202">[-]</label><label class="expand" for="c-36678202">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 60B parameters is still smaller than what GPT4 is using<p>I mean if the article is right, then it&#x27;s about 3.3% the size of GPT 4 (although it&#x27;s a sparse model so not all of it is used on every pass).<p>Meta also didn&#x27;t train LLaMAs on nearly as much code it seems, so they&#x27;re much worse for that in general.</div><br/></div></div><div id="36678124" class="c"><input type="checkbox" id="c-36678124" checked=""/><div class="controls bullet"><span class="by">Tepix</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677369">parent</a><span>|</span><a href="#36678202">prev</a><span>|</span><a href="#36677062">next</a><span>|</span><label class="collapse" for="c-36678124">[-]</label><label class="expand" for="c-36678124">[1 more]</label></div><br/><div class="children"><div class="content">Does it?
The GTPQ paper claims that the accuracy loss is small.</div><br/></div></div></div></div><div id="36677062" class="c"><input type="checkbox" id="c-36677062" checked=""/><div class="controls bullet"><span class="by">Llamamoe</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677039">parent</a><span>|</span><a href="#36677369">prev</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677062">[-]</label><label class="expand" for="c-36677062">[5 more]</label></div><br/><div class="children"><div class="content">How low can you get the memory and computational power requirements that way?</div><br/><div id="36677216" class="c"><input type="checkbox" id="c-36677216" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677062">parent</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677216">[-]</label><label class="expand" for="c-36677216">[4 more]</label></div><br/><div class="children"><div class="content">You can run that model (Wizard-30) on a computer with 64 gigabytes of RAM (or smaller, I don&#x27;t know how tight you can cut it). You obviously want fast RAM and a good CPU, but you don&#x27;t need a GPU.</div><br/><div id="36677437" class="c"><input type="checkbox" id="c-36677437" checked=""/><div class="controls bullet"><span class="by">ed_mercer</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677216">parent</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677437">[-]</label><label class="expand" for="c-36677437">[3 more]</label></div><br/><div class="children"><div class="content">AFAIK you can get away with a swapfile, no need for large amounts of RAM.</div><br/><div id="36677855" class="c"><input type="checkbox" id="c-36677855" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677437">parent</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677855">[-]</label><label class="expand" for="c-36677855">[2 more]</label></div><br/><div class="children"><div class="content">wont that nearly kill your ssd if you do it for extended periods of time?</div><br/><div id="36677997" class="c"><input type="checkbox" id="c-36677997" checked=""/><div class="controls bullet"><span class="by">ZiiS</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677855">parent</a><span>|</span><a href="#36676905">next</a><span>|</span><label class="collapse" for="c-36677997">[-]</label><label class="expand" for="c-36677997">[1 more]</label></div><br/><div class="children"><div class="content">Most of the ram is for storing the model once it is loaded it is read only so will not harm an SSD.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36676905" class="c"><input type="checkbox" id="c-36676905" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676751">parent</a><span>|</span><a href="#36677039">prev</a><span>|</span><a href="#36677549">next</a><span>|</span><label class="collapse" for="c-36676905">[-]</label><label class="expand" for="c-36676905">[3 more]</label></div><br/><div class="children"><div class="content">Have you tried falcon 40b instruct? Also take into account that chatgpt likely has some preprompt and by talking to falcon or other OS models it&#x27;s all in your hands.<p>Furthermore, Not many people discuss the significance of proper output sampling. I myself used to just test open source models with the greedy decoding only. Who knows if they wouldn&#x27;t even beat (not at all)OpenAI with some clever output sampling scheme.</div><br/><div id="36678229" class="c"><input type="checkbox" id="c-36678229" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676905">parent</a><span>|</span><a href="#36677016">next</a><span>|</span><label class="collapse" for="c-36678229">[-]</label><label class="expand" for="c-36678229">[1 more]</label></div><br/><div class="children"><div class="content">Idk, has <i>anyone</i> tried falcon yet? The support for running it remains nonexistent except for one fork of llama.cpp that isn&#x27;t integrated into anything.</div><br/></div></div><div id="36677016" class="c"><input type="checkbox" id="c-36677016" checked=""/><div class="controls bullet"><span class="by">schappim</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676905">parent</a><span>|</span><a href="#36678229">prev</a><span>|</span><a href="#36677549">next</a><span>|</span><label class="collapse" for="c-36677016">[-]</label><label class="expand" for="c-36677016">[1 more]</label></div><br/><div class="children"><div class="content">Does anyone have a link &#x2F; instructions on getting Falcon 40b to install on Apple Silicon?<p>Apparently &quot;Hugging Face&quot; have some internal swift code that works (but it has not been released). I&#x27;m keen to see how it performs on a maxed out Mac Studio (with all that unified memory available).</div><br/></div></div></div></div><div id="36677549" class="c"><input type="checkbox" id="c-36677549" checked=""/><div class="controls bullet"><span class="by">wiz21c</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676751">parent</a><span>|</span><a href="#36676905">prev</a><span>|</span><a href="#36676781">next</a><span>|</span><label class="collapse" for="c-36677549">[-]</label><label class="expand" for="c-36677549">[5 more]</label></div><br/><div class="children"><div class="content">What are all the researchers in universities doing ? Couldn&#x27;t they improve these models (they do have big brains after all) with tax payer&#x27;s money and put the results under some cool open source license...</div><br/><div id="36677655" class="c"><input type="checkbox" id="c-36677655" checked=""/><div class="controls bullet"><span class="by">jona-f</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677549">parent</a><span>|</span><a href="#36677609">next</a><span>|</span><label class="collapse" for="c-36677655">[-]</label><label class="expand" for="c-36677655">[1 more]</label></div><br/><div class="children"><div class="content">Yes, they are doing the improving, but then you need loads of money to do the learning no university can afford. So now big tech is hiring promising university researchers for good money to scale up their research.
This could be solved by massive decentralization where millions of users provide compute with their gpus and i think it will be at some point, cause i believe foss is more powerful than this openai bs.
There are people working on this, but afaik the techniques aren&#x27;t quite there. You need a different kind of model with much more parallelization then what is currently used.</div><br/></div></div><div id="36677609" class="c"><input type="checkbox" id="c-36677609" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677549">parent</a><span>|</span><a href="#36677655">prev</a><span>|</span><a href="#36677836">next</a><span>|</span><label class="collapse" for="c-36677609">[-]</label><label class="expand" for="c-36677609">[1 more]</label></div><br/><div class="children"><div class="content">They are busily working on all the other large scale engineering projects that they are so good at producing and maintaining.</div><br/></div></div><div id="36677836" class="c"><input type="checkbox" id="c-36677836" checked=""/><div class="controls bullet"><span class="by">maxwin</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677549">parent</a><span>|</span><a href="#36677609">prev</a><span>|</span><a href="#36677613">next</a><span>|</span><label class="collapse" for="c-36677836">[-]</label><label class="expand" for="c-36677836">[1 more]</label></div><br/><div class="children"><div class="content">they produce papers that contain (sometimes) useful ideas. They don&#x27;t produce code (other than proof of concept) and they certainly can&#x27;t afford to train a large model</div><br/></div></div><div id="36677613" class="c"><input type="checkbox" id="c-36677613" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677549">parent</a><span>|</span><a href="#36677836">prev</a><span>|</span><a href="#36676781">next</a><span>|</span><label class="collapse" for="c-36677613">[-]</label><label class="expand" for="c-36677613">[1 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t have enough money and thus computing resources. It&#x27;s a huge gap.</div><br/></div></div></div></div><div id="36676781" class="c"><input type="checkbox" id="c-36676781" checked=""/><div class="controls bullet"><span class="by">asynchronous</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676751">parent</a><span>|</span><a href="#36677549">prev</a><span>|</span><a href="#36676798">next</a><span>|</span><label class="collapse" for="c-36676781">[-]</label><label class="expand" for="c-36676781">[1 more]</label></div><br/><div class="children"><div class="content">Probably Wizard 30B, they released the training weights at every offset as well.</div><br/></div></div><div id="36676798" class="c"><input type="checkbox" id="c-36676798" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676751">parent</a><span>|</span><a href="#36676781">prev</a><span>|</span><a href="#36676851">next</a><span>|</span><label class="collapse" for="c-36676798">[-]</label><label class="expand" for="c-36676798">[1 more]</label></div><br/><div class="children"><div class="content">In my testing, the chat and instruct-tuned versions of MPT-30B is very close to 3.5 for many tasks, but of course the team who made it got bought up immediately and it’s licensed only for non-commercial use. I’m hoping the open source community runs with the base model in the same way they did with LLaMA.</div><br/></div></div></div></div><div id="36676851" class="c"><input type="checkbox" id="c-36676851" checked=""/><div class="controls bullet"><span class="by">KronisLV</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676751">prev</a><span>|</span><a href="#36677987">next</a><span>|</span><label class="collapse" for="c-36676851">[-]</label><label class="expand" for="c-36676851">[9 more]</label></div><br/><div class="children"><div class="content">&gt; You can use the above without paying OpenAI. You don&#x27;t even need a GPU. There are no license issues like with the facebook llama.<p>I actually wrote about getting an LLM chatbot up and running a while ago: <a href="https:&#x2F;&#x2F;blog.kronis.dev&#x2F;tutorials&#x2F;self-hosting-an-ai-llm-chatbot-without-going-broke" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.kronis.dev&#x2F;tutorials&#x2F;self-hosting-an-ai-llm-cha...</a><p>It&#x27;s good that the technology and models are both available for free, and you don&#x27;t even need a GPU for it. However, there are still large memory requirements (if you want output that makes sense) and using CPU does result in somewhat slower performance.<p>There are async use cases where it can make sense, but for something like autocomplete or other near real time situations we&#x27;re not there yet. Nor is the quality of the models comparable to some of the commercial offerings, at least not yet.<p>So I don&#x27;t have it in me to blame anyone who forks over the money to a SaaS platform instead of getting a good GPU&#x2F;RAM and hosting stuff themselves.<p>Here&#x27;s hoping the more open options keep getting better and more competitive, though!</div><br/><div id="36676958" class="c"><input type="checkbox" id="c-36676958" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676851">parent</a><span>|</span><a href="#36677987">next</a><span>|</span><label class="collapse" for="c-36676958">[-]</label><label class="expand" for="c-36676958">[8 more]</label></div><br/><div class="children"><div class="content">I bet that open models win in the end because porn. There is already very weird and vibrant community creating &quot;waifus&quot; and tinkering with these models.</div><br/><div id="36677130" class="c"><input type="checkbox" id="c-36677130" checked=""/><div class="controls bullet"><span class="by">KronisLV</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676958">parent</a><span>|</span><a href="#36677872">next</a><span>|</span><label class="collapse" for="c-36677130">[-]</label><label class="expand" for="c-36677130">[6 more]</label></div><br/><div class="children"><div class="content">Huh, more power to those folks then, I guess.<p>But I can easily imagine more conventional forms of entertainment, as well. Like a game of D&amp;D that&#x27;s narrated by the AI, or a text based adventure set in the Mass Effect universe, Lord of the Rings, Warhammer or any other fandom, really. Maybe like those old Choose Your Own Adventure games.<p>I think some companies are also experimenting with characters in video games that get their dialogue from these models - where the developers give the character a persona, provide information about events in the world and let players interact with them, like the Detective Origins demo. Of course, due to the slightly unpredictable nature of these models and their hardware requirements, no idea how viable this will be.</div><br/><div id="36677349" class="c"><input type="checkbox" id="c-36677349" checked=""/><div class="controls bullet"><span class="by">mahathu</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677130">parent</a><span>|</span><a href="#36677998">next</a><span>|</span><label class="collapse" for="c-36677349">[-]</label><label class="expand" for="c-36677349">[4 more]</label></div><br/><div class="children"><div class="content">The application in games I&#x27;m most excited about is commenters in FIFA career mode that don&#x27;t have a limited set of prerecorded voice lines, and take your recent games, formation changes etc into account too, like real commentators would. The recent installments already do that to a small degree. Of course this would also easily open the doors to having multiple commentators&#x2F;analysts to choose from, each with their individual &quot;personalities&quot;. The technology for that is pretty much all already there right?<p>A game like Fallout&#x2F;Elder Scrolls with AI generated NPCs and questlines would be so sick too if executed well.</div><br/><div id="36677723" class="c"><input type="checkbox" id="c-36677723" checked=""/><div class="controls bullet"><span class="by">hovering_nox</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677349">parent</a><span>|</span><a href="#36677657">next</a><span>|</span><label class="collapse" for="c-36677723">[-]</label><label class="expand" for="c-36677723">[2 more]</label></div><br/><div class="children"><div class="content">There is a mod for Skyrim where someone piped together multiple AI models. It goes like this: You speak into your microphone and ask a NPC something. This gets transcribed (voice to text) by Whisper AI. This transcript gets send to eg. GPT-4 with a pre-prompt engineered to give background, current information and the &quot;personality&quot; for the NPC you are talking to. The output of this gets piped back to a Text-to-Speech solution like eleven-labs with the original NPC voice.</div><br/><div id="36677878" class="c"><input type="checkbox" id="c-36677878" checked=""/><div class="controls bullet"><span class="by">hoseja</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677723">parent</a><span>|</span><a href="#36677657">next</a><span>|</span><label class="collapse" for="c-36677878">[-]</label><label class="expand" for="c-36677878">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen an example and the weakest link seemed to be the TTS, which sounded several generations behind.</div><br/></div></div></div></div><div id="36677657" class="c"><input type="checkbox" id="c-36677657" checked=""/><div class="controls bullet"><span class="by">Al0neStar</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677349">parent</a><span>|</span><a href="#36677723">prev</a><span>|</span><a href="#36677998">next</a><span>|</span><label class="collapse" for="c-36677657">[-]</label><label class="expand" for="c-36677657">[1 more]</label></div><br/><div class="children"><div class="content">Maybe for side quests but even that would be a debug hell.</div><br/></div></div></div></div><div id="36677998" class="c"><input type="checkbox" id="c-36677998" checked=""/><div class="controls bullet"><span class="by">potatototoo99</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677130">parent</a><span>|</span><a href="#36677349">prev</a><span>|</span><a href="#36677872">next</a><span>|</span><label class="collapse" for="c-36677998">[-]</label><label class="expand" for="c-36677998">[1 more]</label></div><br/><div class="children"><div class="content">Do you seriously think D&amp;D and other choose your adventure games will be more popular than porn? Seriously?</div><br/></div></div></div></div><div id="36677872" class="c"><input type="checkbox" id="c-36677872" checked=""/><div class="controls bullet"><span class="by">hoseja</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676958">parent</a><span>|</span><a href="#36677130">prev</a><span>|</span><a href="#36677987">next</a><span>|</span><label class="collapse" for="c-36677872">[-]</label><label class="expand" for="c-36677872">[1 more]</label></div><br/><div class="children"><div class="content">The (even pre-emptive!) opposition and censorship seems way stronger this time around than with previous technologies. Like instead of ignoring the porn (or even profiting from it), they are trying very hard to make it impossible.</div><br/></div></div></div></div></div></div><div id="36677987" class="c"><input type="checkbox" id="c-36677987" checked=""/><div class="controls bullet"><span class="by">ChildOfChaos</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676851">prev</a><span>|</span><a href="#36676907">next</a><span>|</span><label class="collapse" for="c-36677987">[-]</label><label class="expand" for="c-36677987">[1 more]</label></div><br/><div class="children"><div class="content">You forgot to link where I can buy your tin foil hat at the end.</div><br/></div></div><div id="36676907" class="c"><input type="checkbox" id="c-36676907" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36677987">prev</a><span>|</span><a href="#36677393">next</a><span>|</span><label class="collapse" for="c-36676907">[-]</label><label class="expand" for="c-36676907">[1 more]</label></div><br/><div class="children"><div class="content">See also, Orca and Falcon models which are also open source. I&#x27;m not sure if any frontends support them yet.</div><br/></div></div><div id="36677393" class="c"><input type="checkbox" id="c-36677393" checked=""/><div class="controls bullet"><span class="by">pyeri</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676907">prev</a><span>|</span><a href="#36676716">next</a><span>|</span><label class="collapse" for="c-36677393">[-]</label><label class="expand" for="c-36677393">[1 more]</label></div><br/><div class="children"><div class="content">In today&#x27;s world, &quot;Science equals Capitalism&quot;.<p>Or at least Science is allowed to progress and get funded only as long as it serves the interest of Capitalism.</div><br/></div></div><div id="36676716" class="c"><input type="checkbox" id="c-36676716" checked=""/><div class="controls bullet"><span class="by">carabiner</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36677393">prev</a><span>|</span><a href="#36677177">next</a><span>|</span><label class="collapse" for="c-36676716">[-]</label><label class="expand" for="c-36676716">[27 more]</label></div><br/><div class="children"><div class="content">We must destroy OpenAI!</div><br/><div id="36677144" class="c"><input type="checkbox" id="c-36677144" checked=""/><div class="controls bullet"><span class="by">ly3xqhl8g9</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676716">parent</a><span>|</span><a href="#36676906">next</a><span>|</span><label class="collapse" for="c-36677144">[-]</label><label class="expand" for="c-36677144">[10 more]</label></div><br/><div class="children"><div class="content">From the post:<p><pre><code>    [Rumors that start to become lawsuits]

    Some speculations are:
    - LibGen (4M+ books)
    - Sci-Hub (80M+ papers)
    - All of GitHub 
</code></pre>
This is the most funny, but in the end sad aspect. If ChatGPT was indeed trained on pirated content and is able to be(come) such a powerful tool, then the copyright laws should have been abolished yesterday. If ChatGPT was not trained on all these resources out there, then think how much powerful a tool it would be if it were trained, then copyright laws are actively stifling advancement and should have been abolished yesterday.</div><br/><div id="36677187" class="c"><input type="checkbox" id="c-36677187" checked=""/><div class="controls bullet"><span class="by">BelleOfTheBall</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677144">parent</a><span>|</span><a href="#36676906">next</a><span>|</span><label class="collapse" for="c-36677187">[-]</label><label class="expand" for="c-36677187">[9 more]</label></div><br/><div class="children"><div class="content">That is a very dangerous way to approach copyright laws. They are definitely abused by corporations like Disney, infamously so, but abolishing them is absolutely not the answer. Art makers are already struggling en masse, taking away their ability to earn money off their work isn&#x27;t an answer, especially if it&#x27;s just to train a predictive text generator.</div><br/><div id="36677236" class="c"><input type="checkbox" id="c-36677236" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677187">parent</a><span>|</span><a href="#36678190">next</a><span>|</span><label class="collapse" for="c-36677236">[-]</label><label class="expand" for="c-36677236">[5 more]</label></div><br/><div class="children"><div class="content">Counterpoint: there&#x27;s way too much &quot;art makers&quot;, copyright is keeping the quality ceiling down, good content loses monetization game with spam - all while that &quot;predictive text generator&quot; is, for better or worse, pretty much the most magnificent piece of technology invented this century, and - for better or worse - it&#x27;s likely to become next major shift to economy and life.</div><br/><div id="36677818" class="c"><input type="checkbox" id="c-36677818" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677236">parent</a><span>|</span><a href="#36677560">next</a><span>|</span><label class="collapse" for="c-36677818">[-]</label><label class="expand" for="c-36677818">[2 more]</label></div><br/><div class="children"><div class="content">- HN on social media : The powers are too centralized, future is decentralization, question is how<p>- HN on free software: is good<p>- HN on copyright    : WAY TOO MUCH PEASANTS CLAIMING INDIVIDUAL RIGHTS, RIGHTS THAT ARENT EVEN REAL, ART BE CENTRALIZED FOR MAXIMUM MONOPOLY</div><br/><div id="36678014" class="c"><input type="checkbox" id="c-36678014" checked=""/><div class="controls bullet"><span class="by">dwallin</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677818">parent</a><span>|</span><a href="#36677560">next</a><span>|</span><label class="collapse" for="c-36678014">[-]</label><label class="expand" for="c-36678014">[1 more]</label></div><br/><div class="children"><div class="content">Copyright does very little for individuals. Most benefits from the copyright system are accrued to large corporations.</div><br/></div></div></div></div><div id="36677560" class="c"><input type="checkbox" id="c-36677560" checked=""/><div class="controls bullet"><span class="by">bergen</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677236">parent</a><span>|</span><a href="#36677818">prev</a><span>|</span><a href="#36678190">next</a><span>|</span><label class="collapse" for="c-36677560">[-]</label><label class="expand" for="c-36677560">[2 more]</label></div><br/><div class="children"><div class="content">How do you believe copyright is keeping the quality down in particular? As I see it, the reason is marketability and trying to conform to standards. Making a new Marvel Movie is sure to have a payoff. Making Parasite MIGHT have a higher payoff, but the risk is way higher.<p>Removing copyright might help to get various more spin-offs and reiterations on previous work, which does increase the scope, but taking the ability for makers to profit from their work in a traditional sense, will bring us closer (back) to a time when commissioned artwork was the main art you saw</div><br/><div id="36678093" class="c"><input type="checkbox" id="c-36678093" checked=""/><div class="controls bullet"><span class="by">hoseja</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677560">parent</a><span>|</span><a href="#36678190">next</a><span>|</span><label class="collapse" for="c-36678093">[-]</label><label class="expand" for="c-36678093">[1 more]</label></div><br/><div class="children"><div class="content">Letting &quot;makers&quot; (studios) profit from &quot;their&quot; (stolen by unbalanced contracts) work for unreasonable amounts of time has clearly proven to be a failure while crowd-comissioned spaces (patreon etc) are thriving financially AND artistically.</div><br/></div></div></div></div></div></div><div id="36678190" class="c"><input type="checkbox" id="c-36678190" checked=""/><div class="controls bullet"><span class="by">tap-snap-or-nap</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677187">parent</a><span>|</span><a href="#36677236">prev</a><span>|</span><a href="#36678145">next</a><span>|</span><label class="collapse" for="c-36678190">[-]</label><label class="expand" for="c-36678190">[1 more]</label></div><br/><div class="children"><div class="content">The laws themselves are dangerous and encourages the myth of ideas being akin to somebody&#x27;s personal property.</div><br/></div></div><div id="36678145" class="c"><input type="checkbox" id="c-36678145" checked=""/><div class="controls bullet"><span class="by">RugnirViking</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677187">parent</a><span>|</span><a href="#36678190">prev</a><span>|</span><a href="#36677583">next</a><span>|</span><label class="collapse" for="c-36678145">[-]</label><label class="expand" for="c-36678145">[1 more]</label></div><br/><div class="children"><div class="content">since when is struggling artist making use of the copyright system. They are protected by it entirely in theory alone, they aint taking someone to court.</div><br/></div></div><div id="36677583" class="c"><input type="checkbox" id="c-36677583" checked=""/><div class="controls bullet"><span class="by">ly3xqhl8g9</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677187">parent</a><span>|</span><a href="#36678145">prev</a><span>|</span><a href="#36676906">next</a><span>|</span><label class="collapse" for="c-36677583">[-]</label><label class="expand" for="c-36677583">[1 more]</label></div><br/><div class="children"><div class="content">Already copyright laws do not offer protection for writers (see the current [screen]writers strike [1]), visual artists, musicians (see the recent Taylor Swift re-recording debacle [2]), not to speak of the &quot;lower&quot; arts, crafts &amp; merch, where colossi such as H&amp;M and Zara steal art, designs, concepts regularly [3] (not to even mention the sweatshops).<p>Copyright laws, or in fact generally laws, are for the rich and powerful, perhaps even for the corporations, not the individuals, since they paid for them to be so [4], it&#x27;s just us, individually, the <i>hoi polloi</i>, who are still trapped into believing that there is rhyme or reason to our current system.<p>The joke is that while our system extolls itself as the most efficient system in history, based on competition of equals and free markets (two contradictions in terms contradicting each other), it harbours terrible inefficiencies such as the copyright laws, the patent system, and so on.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2023_Writers_Guild_of_America_strike" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2023_Writers_Guild_of_America_...</a><p>[2] <a href="https:&#x2F;&#x2F;www.vox.com&#x2F;culture&#x2F;22278732&#x2F;taylor-swift-re-recording-speak-now-enchanted-mine-master-rights-scooter-braun" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.vox.com&#x2F;culture&#x2F;22278732&#x2F;taylor-swift-re-recordi...</a><p>[3] <a href="https:&#x2F;&#x2F;www.boredpanda.com&#x2F;zara-stealing-designs-copying-independent-artists-tuesday-bassen" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.boredpanda.com&#x2F;zara-stealing-designs-copying-ind...</a><p>[4] The Power Corporations Have In Changing Laws, <a href="https:&#x2F;&#x2F;www.npr.org&#x2F;2021&#x2F;04&#x2F;02&#x2F;983925056&#x2F;the-power-corporations-have-in-changing-laws" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.npr.org&#x2F;2021&#x2F;04&#x2F;02&#x2F;983925056&#x2F;the-power-corporati...</a></div><br/></div></div></div></div></div></div><div id="36676906" class="c"><input type="checkbox" id="c-36676906" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676716">parent</a><span>|</span><a href="#36677144">prev</a><span>|</span><a href="#36677177">next</a><span>|</span><label class="collapse" for="c-36676906">[-]</label><label class="expand" for="c-36676906">[16 more]</label></div><br/><div class="children"><div class="content">Not sure if you&#x27;re being sarcastic but I agree. Humans should not have AI research or advanced AI at all. It (a) removes purpose from people, (b) presents a situation that is too alien for human minds to handle, (c) increases the addictiveness of technology and thereby pushes us further into growing the technological system, (d) crosses the &quot;adaptability threshhold&quot;, i.e. the point at which the PACE of technological development is so rapid that adaptation of our society to such a pace is NO longer possible.<p>In short, we do not have the maturity to handle AI; we are playing with fire. Every person who contributes anything to AI development is responsible for the disasters that AI will bring, and all AI research should be destroyed.</div><br/><div id="36677054" class="c"><input type="checkbox" id="c-36677054" checked=""/><div class="controls bullet"><span class="by">maximamas</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676906">parent</a><span>|</span><a href="#36676932">next</a><span>|</span><label class="collapse" for="c-36677054">[-]</label><label class="expand" for="c-36677054">[6 more]</label></div><br/><div class="children"><div class="content">It’s ironic you say: “we are playing with fire.” Playing with fire is, in large part, literally how humans have come to dominate this planet. Why stop now?</div><br/><div id="36677115" class="c"><input type="checkbox" id="c-36677115" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677054">parent</a><span>|</span><a href="#36677089">next</a><span>|</span><label class="collapse" for="c-36677115">[-]</label><label class="expand" for="c-36677115">[3 more]</label></div><br/><div class="children"><div class="content">Maybe because we&#x27;re on the verge of being able to create fires which can actually consume the only home we have?<p>Playing with fire is in large part an ego and greed issue. Yes, it allows us to dominate, but at what cost?<p>I&#x27;d rather live a more balanced life than a greedy and ego driven life. I may not own the world, but I can be happy and sleep sound at night, and that matters.</div><br/><div id="36677515" class="c"><input type="checkbox" id="c-36677515" checked=""/><div class="controls bullet"><span class="by">rebolek</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677115">parent</a><span>|</span><a href="#36677089">next</a><span>|</span><label class="collapse" for="c-36677515">[-]</label><label class="expand" for="c-36677515">[2 more]</label></div><br/><div class="children"><div class="content">We had nuclear weapons for almost 80 years and the world still hasn&#x27;t ended. And I think that nuclear weapons are way more dangerous than Markov chains on steroids.</div><br/><div id="36677745" class="c"><input type="checkbox" id="c-36677745" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677515">parent</a><span>|</span><a href="#36677089">next</a><span>|</span><label class="collapse" for="c-36677745">[-]</label><label class="expand" for="c-36677745">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t launch a tactical nuke because somebody wronged me, but can create a disinformation campaign with the tools I have and optionally 2-3 smart, motivated individuals, for free.<p>Both can be equally devastating.<p>Or, if I want to go the extra mile, I can use the latter to create motivation for the utilization of the former. e.g. I may say that a country has WMDs, and maybe try to manufacture consent for destruction of these...<p><i>Oh, wait a minute...</i></div><br/></div></div></div></div></div></div><div id="36677089" class="c"><input type="checkbox" id="c-36677089" checked=""/><div class="controls bullet"><span class="by">dclowd9901</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677054">parent</a><span>|</span><a href="#36677115">prev</a><span>|</span><a href="#36676932">next</a><span>|</span><label class="collapse" for="c-36677089">[-]</label><label class="expand" for="c-36677089">[2 more]</label></div><br/><div class="children"><div class="content">To turn your metaphor on its head, we aren’t playing with fire when we use it constructively; rather we are very carefully and thoughtfully deploying it, no doubt due to our gradual and deadly lessons with it over time. When we “play” with it (a la fireworks or neglected campfires), it wreaks rampant destruction.<p>Being we are basically toddlers with this new technology, I would argue the breathless speed at which it’s finding its way into our lives tells me we are not being careful or thoughtful with it.</div><br/><div id="36677244" class="c"><input type="checkbox" id="c-36677244" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677089">parent</a><span>|</span><a href="#36676932">next</a><span>|</span><label class="collapse" for="c-36677244">[-]</label><label class="expand" for="c-36677244">[1 more]</label></div><br/><div class="children"><div class="content">Counterpoint: &quot;playing with it&quot; is the only way we have to actually master something. &quot;Carefully and thoughtfully deploying it&quot; only comes <i>way</i> after many people first extensively played with it (for any specific &quot;it&quot;), first because of curiosity (i.e. for shits and giggles), then for a quick buck.</div><br/></div></div></div></div></div></div><div id="36676932" class="c"><input type="checkbox" id="c-36676932" checked=""/><div class="controls bullet"><span class="by">M3L0NM4N</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676906">parent</a><span>|</span><a href="#36677054">prev</a><span>|</span><a href="#36677177">next</a><span>|</span><label class="collapse" for="c-36676932">[-]</label><label class="expand" for="c-36676932">[9 more]</label></div><br/><div class="children"><div class="content">This is such a pessimistic view to take that I cannot even begin to describe how you are wrong.</div><br/><div id="36677011" class="c"><input type="checkbox" id="c-36677011" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676932">parent</a><span>|</span><a href="#36677177">next</a><span>|</span><label class="collapse" for="c-36677011">[-]</label><label class="expand" for="c-36677011">[8 more]</label></div><br/><div class="children"><div class="content">I would love to see your rebuttals, especially since I have never seen any strong arguments in favour of AI being a net benefit to society, and I have thought and read about this at lenght.<p>Of course, I always expect downvotes on my posts here since there is a strong tendency towards loving technology here. But what I find most interesting is that there is absolutely no taking of responsibility of any technological creations.<p>Before you downvote, please just ask yourself the following: is it reasonable to say that all these latest AI developments have no serious risks? And in response to your reply, humanity is in quite a precarious state now, so isn&#x27;t it expected that a sober analysis of it is rather pessimistic, especially with regard to hyper-advanced technologies?</div><br/><div id="36677122" class="c"><input type="checkbox" id="c-36677122" checked=""/><div class="controls bullet"><span class="by">jackstraw14</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677011">parent</a><span>|</span><a href="#36677588">next</a><span>|</span><label class="collapse" for="c-36677122">[-]</label><label class="expand" for="c-36677122">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But what I find most interesting is that there is absolutely no taking of responsibility of any technological creations.<p>I appreciate your willingness to talk about it, but to be honest it doesn&#x27;t seem like it matters much what you, or any of us (not singling you out in particular), thinks about it, does it? It probably doesn&#x27;t even matter who these people are who should take responsibility. This is one genie, like the internet, that probably isn&#x27;t going back in the bottle anytime soon. I haven&#x27;t seen any argument against &quot;AI&quot; that&#x27;s much different than those against &quot;the internet&quot; and &quot;computers&quot; that we&#x27;ve at other times in the last 50 years when tech hit new mind-blowing milestones. It just keeps going regardless, right?</div><br/><div id="36677211" class="c"><input type="checkbox" id="c-36677211" checked=""/><div class="controls bullet"><span class="by">lacrimacida</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677122">parent</a><span>|</span><a href="#36677588">next</a><span>|</span><label class="collapse" for="c-36677211">[-]</label><label class="expand" for="c-36677211">[3 more]</label></div><br/><div class="children"><div class="content">It actually does make a difference. The genie is out of the bottle partially but it depends a lot on what we allow it it be used on. If we sit idly and allow for ingesting all what’s written for instance, including whats currently written and let bros make derivative works for a quick buck then we mostly killed the writer’s incentive to write or publish. If we slow down and not allow ripping one another off it could have the opposite effect and trully lift all the boats at once. There’s a concurent thread about Sarah Silverman suing OpenAI, that’s what Im talking about as well here</div><br/><div id="36677882" class="c"><input type="checkbox" id="c-36677882" checked=""/><div class="controls bullet"><span class="by">Joeri</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677211">parent</a><span>|</span><a href="#36677403">next</a><span>|</span><label class="collapse" for="c-36677882">[-]</label><label class="expand" for="c-36677882">[1 more]</label></div><br/><div class="children"><div class="content">You can slow things down, but not by more than a few years, because of the gradual democratization of training foundation models. Right now training a model competitive with chatgpt can be done for $150K (microsoft orca 13b). In a few years the cost will be low enough that individuals can train models. At that point regulating it will require draconian dictatorships.<p>I’m also very wary of the copyright angle on this, because just like we don’t prohibit people from learning copyrighted materials in their brains, it feels very wrong to regulate how we train digital brains. I’m ok with forbidding the output of copies of individual existing copyrighted works, but we already have laws on the books for that. I find it downright immoral to prohibit the generation of works “in the style of”. That again reeks like the kind of draconian society I don’t want to live in.<p>People will always be willing to pay for human-made art, just like we pay more for handmade pots, even though machines can make them better, so I think the doomsayers who predict the end of art are flat out wrong. Easy access to mass-generated AI content could be the best thing that happened to true artists, just like chess AI that can beat every human player was the best thing that happened to the chess world. We need labeling laws that show the origin of works so people can choose whether they want artificial or human-made, but please not another extension of the copyright regime to be even more suffocating and hostile of cultural flourishing.</div><br/></div></div><div id="36677403" class="c"><input type="checkbox" id="c-36677403" checked=""/><div class="controls bullet"><span class="by">jackstraw14</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677211">parent</a><span>|</span><a href="#36677882">prev</a><span>|</span><a href="#36677588">next</a><span>|</span><label class="collapse" for="c-36677403">[-]</label><label class="expand" for="c-36677403">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If we sit idly and allow for ingesting all what’s written for instance<p>It&#x27;s already happened. What do you do now? For decades, it&#x27;s happened regardless of the robots.txt so you have to assume it&#x27;s all been ingested by it all, everywhere. What now?</div><br/></div></div></div></div></div></div><div id="36677588" class="c"><input type="checkbox" id="c-36677588" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677011">parent</a><span>|</span><a href="#36677122">prev</a><span>|</span><a href="#36677464">next</a><span>|</span><label class="collapse" for="c-36677588">[-]</label><label class="expand" for="c-36677588">[2 more]</label></div><br/><div class="children"><div class="content">If we were a rational civilization we&#x27;d stop all scientific research immediately. First there&#x27;s a good chance the great filter is ahead of us and will be triggered by a technology break-trough. Second with nuclear weapons we got lucky in that it&#x27;s extremely hard to separate fission capable isotope of uranium from mineral ores; if in the future we invent a powerful weapon that&#x27;s easy to produce organizations like al-Qaeda will destroy every city on Earth.</div><br/><div id="36677985" class="c"><input type="checkbox" id="c-36677985" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677588">parent</a><span>|</span><a href="#36677464">next</a><span>|</span><label class="collapse" for="c-36677985">[-]</label><label class="expand" for="c-36677985">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t figure out if this is a rebuttal by absurdity or serious?</div><br/></div></div></div></div><div id="36677464" class="c"><input type="checkbox" id="c-36677464" checked=""/><div class="controls bullet"><span class="by">ed_mercer</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677011">parent</a><span>|</span><a href="#36677588">prev</a><span>|</span><a href="#36677177">next</a><span>|</span><label class="collapse" for="c-36677464">[-]</label><label class="expand" for="c-36677464">[1 more]</label></div><br/><div class="children"><div class="content">&gt;is it reasonable to say that all these latest AI developments have no serious risks?<p>There are definitely problems today with people abusing ChatGPT for malicious purposes, but given the retardedness of current LLMs I don&#x27;t think we need to worry about a AI mastermind taking over anytime soon.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36677177" class="c"><input type="checkbox" id="c-36677177" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676716">prev</a><span>|</span><a href="#36676691">next</a><span>|</span><label class="collapse" for="c-36677177">[-]</label><label class="expand" for="c-36677177">[4 more]</label></div><br/><div class="children"><div class="content">&gt;There are no license issues like with the facebook llama.<p>OpenLLaMa uses a dataset which does not seem to have gotten propper commercial licensing for the training data. There is potential licensing issues because the copyright situation is not well defended.</div><br/><div id="36677634" class="c"><input type="checkbox" id="c-36677634" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677177">parent</a><span>|</span><a href="#36676691">next</a><span>|</span><label class="collapse" for="c-36677634">[-]</label><label class="expand" for="c-36677634">[3 more]</label></div><br/><div class="children"><div class="content">So far as anyone knows, this is not a derivative work, its transformative, and therefore not subject to any licensing requirement.<p>You&#x27;re right though, that&#x27;s arguably still up for debate, but I think the precedent of transformative work is pretty well attested.</div><br/><div id="36677902" class="c"><input type="checkbox" id="c-36677902" checked=""/><div class="controls bullet"><span class="by">dacryn</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677634">parent</a><span>|</span><a href="#36678010">next</a><span>|</span><label class="collapse" for="c-36677902">[-]</label><label class="expand" for="c-36677902">[1 more]</label></div><br/><div class="children"><div class="content">is it?<p>Because condensation is literally part of the definition of derivative, and basically the weights are a condensed form of the input data. It&#x27;s some sort of lossy compression, when looking at it from the right point of view.<p>Summarization and translation are also clearly derivative.<p>The definition of transformative I found:<p><pre><code>  - add something new (context of other books I guess, this one might pass)
  - with a further purpose or different character (further purpose clearly yes)
  - do not substitute for the original use of the work (this one I find difficult. In the case of books, probably. In the case of github, it aims to replace quite some aspects of it)</code></pre></div><br/></div></div></div></div></div></div><div id="36676554" class="c"><input type="checkbox" id="c-36676554" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36676470">parent</a><span>|</span><a href="#36676691">prev</a><span>|</span><a href="#36676278">next</a><span>|</span><label class="collapse" for="c-36676554">[-]</label><label class="expand" for="c-36676554">[32 more]</label></div><br/><div class="children"><div class="content">Why the vitriol towards OpenAI?<p>If Elon hadn&#x27;t pulled the rug out from under them after they refused his forceful takeover*, they wouldn&#x27;t have had to go to Microsoft and they&#x27;d still be open.<p>* a takeover which he predicated on the claim that OpenAI was &quot;doomed to fail&quot;</div><br/><div id="36676577" class="c"><input type="checkbox" id="c-36676577" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676554">parent</a><span>|</span><a href="#36676945">next</a><span>|</span><label class="collapse" for="c-36676577">[-]</label><label class="expand" for="c-36676577">[19 more]</label></div><br/><div class="children"><div class="content">It&#x27;s several reasons, first it&#x27;s the lies and the abuse of a charity, that wouldn&#x27;t be an issue if they had began as a private company instead of robbing a charity.<p>But secondly, even if they were a private company, it&#x27;s dishonest and reprehensible to claim to congress that you want to &quot;protect the public&quot; when you really only give a shit about protecting your moat, I&#x27;m not happy about that either.<p>I&#x27;m also tired of tech oligarchs general tomfuckery in all our daily lives, as I suspect many more people here are. OpenAI is just particularly egregious about it.<p>I also think it&#x27;s my civic duty to let other developers know that OpenAI does not have, by any stretch of the imagination, a stranglehold on this technology or any secret sauce. That&#x27;s why they&#x27;re lying and sweating in front of congress.</div><br/><div id="36676619" class="c"><input type="checkbox" id="c-36676619" checked=""/><div class="controls bullet"><span class="by">victor9000</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676577">parent</a><span>|</span><a href="#36676954">next</a><span>|</span><label class="collapse" for="c-36676619">[-]</label><label class="expand" for="c-36676619">[6 more]</label></div><br/><div class="children"><div class="content">Yeah, they went from v1 to regulatory capture in the span of months</div><br/><div id="36676659" class="c"><input type="checkbox" id="c-36676659" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676619">parent</a><span>|</span><a href="#36676954">next</a><span>|</span><label class="collapse" for="c-36676659">[-]</label><label class="expand" for="c-36676659">[5 more]</label></div><br/><div class="children"><div class="content">&gt; regulatory capture<p>If this leak is correct, regulatory capture is likely the only moat OpenAI could have hoped for. It would explain why Sam was so absolutely adamant that this tech needed to receive oversight.<p>If correct, every big tech company now has a recipe to build their own GPT-4. I&#x27;d expect for the open source efforts to try to duplicate the results as well. LLMs will increase in quality across the board and become fairly interchangeable, leading to thin margins and a race to the bottom.<p>We could be watching $13 billion going up in flames, all of it predicated on a secret as flimsy as the Coca-Cola recipe.</div><br/><div id="36678128" class="c"><input type="checkbox" id="c-36678128" checked=""/><div class="controls bullet"><span class="by">mahathu</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676659">parent</a><span>|</span><a href="#36677799">next</a><span>|</span><label class="collapse" for="c-36678128">[-]</label><label class="expand" for="c-36678128">[1 more]</label></div><br/><div class="children"><div class="content">My partner is working at a startup that used to sell clothes and then pivoted twice and is now offering &quot;conversational commerce&quot; and helps companies pester their customers through iMessage and WhatsApp. Now a few months ago they pivoted again and are calling themselves an AI startup. Even if OpenAI and its competitors start this race to the bottom, third parties that use AI (or rather advertise as such) should still be fine though right?</div><br/></div></div><div id="36677799" class="c"><input type="checkbox" id="c-36677799" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676659">parent</a><span>|</span><a href="#36678128">prev</a><span>|</span><a href="#36676806">next</a><span>|</span><label class="collapse" for="c-36677799">[-]</label><label class="expand" for="c-36677799">[1 more]</label></div><br/><div class="children"><div class="content">Tbf the coca-cola recipe is a more sustainable trade secret, since the product is “perfected”.<p>GPT4 is a work in progress so a competitor can be objectively better.<p>I’m hoping for open source models to start incorporating some of these ideas.</div><br/></div></div><div id="36676806" class="c"><input type="checkbox" id="c-36676806" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676659">parent</a><span>|</span><a href="#36677799">prev</a><span>|</span><a href="#36676771">next</a><span>|</span><label class="collapse" for="c-36676806">[-]</label><label class="expand" for="c-36676806">[1 more]</label></div><br/><div class="children"><div class="content">$13 billion isn&#x27;t $13 billion if $N billion of it has to mandatorily be spent on high margin (70%?) Azure services.</div><br/></div></div><div id="36676771" class="c"><input type="checkbox" id="c-36676771" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676659">parent</a><span>|</span><a href="#36676806">prev</a><span>|</span><a href="#36676954">next</a><span>|</span><label class="collapse" for="c-36676771">[-]</label><label class="expand" for="c-36676771">[1 more]</label></div><br/><div class="children"><div class="content">Just wait until the RLHF class action hits them.</div><br/></div></div></div></div></div></div><div id="36676954" class="c"><input type="checkbox" id="c-36676954" checked=""/><div class="controls bullet"><span class="by">EagnaIonat</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676577">parent</a><span>|</span><a href="#36676619">prev</a><span>|</span><a href="#36676662">next</a><span>|</span><label class="collapse" for="c-36676954">[-]</label><label class="expand" for="c-36676954">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  the abuse of a charity,<p>A non-profit and charity are two different things.<p>While a charity is a form of non-profit, it has to follow certain rules to qualify as one. Their profits must go towards the charity.<p>A non-profit is a company that is set up not to make a profit. It is allowed to make a profit if it does. This is what OpenAI was.<p>They switched to a &quot;capped&quot; for-profit model so that they could get more funding. It also allowed their employees to invest in the company, and openAI gave equity to their employees.<p>There was no lies or abuse. Where did you get that information from?</div><br/></div></div><div id="36676662" class="c"><input type="checkbox" id="c-36676662" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676577">parent</a><span>|</span><a href="#36676954">prev</a><span>|</span><a href="#36676919">next</a><span>|</span><label class="collapse" for="c-36676662">[-]</label><label class="expand" for="c-36676662">[4 more]</label></div><br/><div class="children"><div class="content">Did you actually read my comment or did you have a preplanned diatribe?<p>They didn&#x27;t start the private company until the person who promised them $1B reneged. That person reneged because they tried to forcefully takeover and were rebuked.<p>They were running out of money and forced to raise funds in a very for-profit way or fold.<p>-<p>Edit: Rate limited because the hivemind has decided that it&#x27;s unacceptable to insult their leader<p>People keep acting like if it wasn&#x27;t for OpenAI we&#x27;d be in some LLM utopia. The reality is some other big tech giant would reach the current SOTA first and we&#x27;d be in the same predicament except with a company with 1000x more machinery to do the things you&#x27;re complaining about.<p>It&#x27;s ridiculous the sense of entitlement some people must have to keep insisting that OpenAI should have crawled into a cave and died because some megalomaniac threw a tantrum.</div><br/><div id="36676708" class="c"><input type="checkbox" id="c-36676708" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676662">parent</a><span>|</span><a href="#36676919">next</a><span>|</span><label class="collapse" for="c-36676708">[-]</label><label class="expand" for="c-36676708">[3 more]</label></div><br/><div class="children"><div class="content">So fold.<p>Running out of money to run a charity means they now suddenly <i>need</i> to fuck over the people the charity was supposed to help (that is, <i>everyone on earth</i>) ?<p>Imagine if a feed the homeless charity accepted private investment and went around installing anti-homeless spikes everywhere after stopping feeding anyone. It&#x27;s a similar style of behavior.</div><br/><div id="36677182" class="c"><input type="checkbox" id="c-36677182" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676708">parent</a><span>|</span><a href="#36676919">next</a><span>|</span><label class="collapse" for="c-36677182">[-]</label><label class="expand" for="c-36677182">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not even remotely the same as anti-homeless spikes.<p>We&#x27;ve <i>just had</i> the massive fine against 3M for knowing and hiding the risks of PFAS, and the top comments here were  &quot;increase the fines! Lock up the bosses!&quot;<p>Now we have a company going &quot;we had to put a lot of effort into preventing this model from cheerfully outputting Al Quaida propaganda, explicit rape threats, and detailed instructions for an amateur to make deadly chemicals using only home supplies&quot;, and despite that effort they still had legal trouble in Italy because the output was unsuitable for minors (as well as the GDPR issues that were the primary headline at the time).<p>And a lot of researchers with no financial incentives saying &quot;yup, there&#x27;s danger in these AI&quot;.<p>The reaction here?<p>Disbelief OpenAI might be saying what they mean, and meaning what they say.<p>And people parroting &quot;moat!&quot; as if none of the other FAANGs could trivially cross any regulatory barriers that emerge.<p>It&#x27;s like the entire topic of AI has been politicised harder than &quot;is nuclear power green?&quot;</div><br/><div id="36677433" class="c"><input type="checkbox" id="c-36677433" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677182">parent</a><span>|</span><a href="#36676919">next</a><span>|</span><label class="collapse" for="c-36677433">[-]</label><label class="expand" for="c-36677433">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;outputs al qaeda propaganda&quot;<p>So does Microsoft Word. Both require a human to tell the software what to output.<p>&gt; as if none of the other FAANGs could trivially cross any regulatory barriers that emerge.<p>That&#x27;s the point.<p>This miracle technology does not belong to a few rich men, it belongs to us all.<p>Tech oligarchs are provably not more responsible than the rest of us, and do not deserve to lock us out of the garden whose fruit they seek to pick.<p>A rich man can meet the regulations that allow him to build a robot to take your job, but <i>YOU</i> are not allowed to build the same robot to help boost your own income? Because that might be <i>irresponsible</i>?</div><br/></div></div></div></div></div></div></div></div><div id="36676919" class="c"><input type="checkbox" id="c-36676919" checked=""/><div class="controls bullet"><span class="by">downWidOutaFite</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676577">parent</a><span>|</span><a href="#36676662">prev</a><span>|</span><a href="#36676945">next</a><span>|</span><label class="collapse" for="c-36676919">[-]</label><label class="expand" for="c-36676919">[7 more]</label></div><br/><div class="children"><div class="content">The &quot;regulatory capture&quot; conspiracy theory makes no sense to me. It takes 9 figures in cash to create and run one of these super big models. Only big tech was ever going to create them, and big tech is already very experienced at navigating regulation, regulation wasn&#x27;t ever going to stop them from competing. And in general, our democracy works better than the nihilist libertarians give it credit for.</div><br/><div id="36677830" class="c"><input type="checkbox" id="c-36677830" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676919">parent</a><span>|</span><a href="#36677195">next</a><span>|</span><label class="collapse" for="c-36677830">[-]</label><label class="expand" for="c-36677830">[2 more]</label></div><br/><div class="children"><div class="content">I interpreted openAIs  regulatory capture bid as more of an attempt to create competition-hostile regulation than an attempt to reduce regulation to cut costs.</div><br/><div id="36677874" class="c"><input type="checkbox" id="c-36677874" checked=""/><div class="controls bullet"><span class="by">downWidOutaFite</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677830">parent</a><span>|</span><a href="#36677195">next</a><span>|</span><label class="collapse" for="c-36677874">[-]</label><label class="expand" for="c-36677874">[1 more]</label></div><br/><div class="children"><div class="content">My point is that openai&#x27;s competitors have no problem handling regulations.</div><br/></div></div></div></div><div id="36677195" class="c"><input type="checkbox" id="c-36677195" checked=""/><div class="controls bullet"><span class="by">flir</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676919">parent</a><span>|</span><a href="#36677830">prev</a><span>|</span><a href="#36676945">next</a><span>|</span><label class="collapse" for="c-36677195">[-]</label><label class="expand" for="c-36677195">[4 more]</label></div><br/><div class="children"><div class="content">I bet it&#x27;ll be 6 figures within 18 months.</div><br/><div id="36677241" class="c"><input type="checkbox" id="c-36677241" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677195">parent</a><span>|</span><a href="#36677644">next</a><span>|</span><label class="collapse" for="c-36677241">[-]</label><label class="expand" for="c-36677241">[1 more]</label></div><br/><div class="children"><div class="content">Even if it was free to train, FAANGs can beat OpenAI on spending to follow regulations.</div><br/></div></div><div id="36677644" class="c"><input type="checkbox" id="c-36677644" checked=""/><div class="controls bullet"><span class="by">RC_ITR</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677195">parent</a><span>|</span><a href="#36677241">prev</a><span>|</span><a href="#36676945">next</a><span>|</span><label class="collapse" for="c-36677644">[-]</label><label class="expand" for="c-36677644">[2 more]</label></div><br/><div class="children"><div class="content">The thing about these models is compute scales quadratically with model dimensionality and memory scales quadratically with sequence length.<p>We are nowhere near diminishing returns for either variable, so sure <i>current</i> models maybe scale quickly but the cutting edge will want as much compute as possible for a long time.<p>That’s kind of the humor of everyone saying this leak somehow leaves OpenAI vulnerable.<p>The work isn’t deciding if an MoE is the right architecture or not, it’s how to run 25k GPUs concurrently in a fault tolerant way (likely the true reason for the deep Azure links).</div><br/><div id="36677978" class="c"><input type="checkbox" id="c-36677978" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677644">parent</a><span>|</span><a href="#36676945">next</a><span>|</span><label class="collapse" for="c-36677978">[-]</label><label class="expand" for="c-36677978">[1 more]</label></div><br/><div class="children"><div class="content">Memory does not scale quadratically with sequence length.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36676945" class="c"><input type="checkbox" id="c-36676945" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676554">parent</a><span>|</span><a href="#36676577">prev</a><span>|</span><a href="#36676589">next</a><span>|</span><label class="collapse" for="c-36676945">[-]</label><label class="expand" for="c-36676945">[1 more]</label></div><br/><div class="children"><div class="content">It was a massive bait and switch, luckily AI isn&#x27;t powerful enough to take over the world we&#x27;d be done for.</div><br/></div></div><div id="36676589" class="c"><input type="checkbox" id="c-36676589" checked=""/><div class="controls bullet"><span class="by">93po</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676554">parent</a><span>|</span><a href="#36676945">prev</a><span>|</span><a href="#36676886">next</a><span>|</span><label class="collapse" for="c-36676589">[-]</label><label class="expand" for="c-36676589">[8 more]</label></div><br/><div class="children"><div class="content">This a really interesting spin on reality</div><br/><div id="36676676" class="c"><input type="checkbox" id="c-36676676" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676589">parent</a><span>|</span><a href="#36676734">next</a><span>|</span><label class="collapse" for="c-36676676">[-]</label><label class="expand" for="c-36676676">[2 more]</label></div><br/><div class="children"><div class="content">I think this commentary was pithier in your head...<p><a href="https:&#x2F;&#x2F;hackernoon.com&#x2F;how-openai-transitioned-from-a-nonprofit-to-a-$29b-for-profit-company" rel="nofollow noreferrer">https:&#x2F;&#x2F;hackernoon.com&#x2F;how-openai-transitioned-from-a-nonpro...</a></div><br/><div id="36677132" class="c"><input type="checkbox" id="c-36677132" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676676">parent</a><span>|</span><a href="#36676734">next</a><span>|</span><label class="collapse" for="c-36677132">[-]</label><label class="expand" for="c-36677132">[1 more]</label></div><br/><div class="children"><div class="content">A &quot;capped&quot; profit of 100x is absolutely ridiculous.  That is not even the slightest attempt to stay in the same ballpark as nonprofit.<p>Blaming any loss of Elon money for that <i>is</i> spin.<p>And he still gave them a hundred million.</div><br/></div></div></div></div><div id="36676734" class="c"><input type="checkbox" id="c-36676734" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676589">parent</a><span>|</span><a href="#36676676">prev</a><span>|</span><a href="#36676886">next</a><span>|</span><label class="collapse" for="c-36676734">[-]</label><label class="expand" for="c-36676734">[5 more]</label></div><br/><div class="children"><div class="content">If it involves Elon being a bad guy, it is certain to have HNers salivating at the thought.</div><br/><div id="36676777" class="c"><input type="checkbox" id="c-36676777" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676734">parent</a><span>|</span><a href="#36676765">next</a><span>|</span><label class="collapse" for="c-36676777">[-]</label><label class="expand" for="c-36676777">[1 more]</label></div><br/><div class="children"><div class="content">Elon isn’t a good guy. But he’s not a bad guy either. He’s just bipolar with no one to constrain his mania.</div><br/></div></div><div id="36676765" class="c"><input type="checkbox" id="c-36676765" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676734">parent</a><span>|</span><a href="#36676777">prev</a><span>|</span><a href="#36676886">next</a><span>|</span><label class="collapse" for="c-36676765">[-]</label><label class="expand" for="c-36676765">[3 more]</label></div><br/><div class="children"><div class="content">At this point, after attempting to start a literal fight with Zuckerberg, Musk is proposing a penis-measuring contest.<p>He appears to be decompensating in real time.  If that&#x27;s salivation fodder, so be it, but it just makes me sad.  You hate to see it happen... or at least I do.</div><br/><div id="36677884" class="c"><input type="checkbox" id="c-36677884" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676765">parent</a><span>|</span><a href="#36677618">next</a><span>|</span><label class="collapse" for="c-36677884">[-]</label><label class="expand" for="c-36677884">[1 more]</label></div><br/><div class="children"><div class="content">Maybe Russia has been injecting lead into his water supply lol.<p>I’m also saddened.<p>Musk is not really a hero or a villain, but his manic stages have given us our first realistic shot at becoming a spacefaring civilization, and moved the needle big time on the lock that the perro cartels had on the automotive industry vis-a-vis electric cars.<p>I hope elon gets better. Losing a billionaire tech maximalists manic episodes is going to set us back decades as more reasonable people chase profit instead of dreams.</div><br/></div></div><div id="36677618" class="c"><input type="checkbox" id="c-36677618" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676765">parent</a><span>|</span><a href="#36677884">prev</a><span>|</span><a href="#36676886">next</a><span>|</span><label class="collapse" for="c-36677618">[-]</label><label class="expand" for="c-36677618">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s joking but making less than no effort to communicate like someone who owns a large company normally would.</div><br/></div></div></div></div></div></div></div></div><div id="36676886" class="c"><input type="checkbox" id="c-36676886" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676554">parent</a><span>|</span><a href="#36676589">prev</a><span>|</span><a href="#36676278">next</a><span>|</span><label class="collapse" for="c-36676886">[-]</label><label class="expand" for="c-36676886">[3 more]</label></div><br/><div class="children"><div class="content">Every company who promotes and develops AI is morally responsible for the coming disaster that it will bring on us. If I could have one wish it would be that every trace of AI research is destroyed.</div><br/><div id="36677623" class="c"><input type="checkbox" id="c-36677623" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36676886">parent</a><span>|</span><a href="#36676278">next</a><span>|</span><label class="collapse" for="c-36677623">[-]</label><label class="expand" for="c-36677623">[2 more]</label></div><br/><div class="children"><div class="content">I recommend reading comments like this and substituting &quot;a baby&quot; for AI. A baby also can&#x27;t be aligned and is capable of deciding to destroy the world. It&#x27;s not gonna do it though.</div><br/><div id="36677890" class="c"><input type="checkbox" id="c-36677890" checked=""/><div class="controls bullet"><span class="by">Brometheus</span><span>|</span><a href="#36676470">root</a><span>|</span><a href="#36677623">parent</a><span>|</span><a href="#36676278">next</a><span>|</span><label class="collapse" for="c-36677890">[-]</label><label class="expand" for="c-36677890">[1 more]</label></div><br/><div class="children"><div class="content">A baby doesn&#x27;t output propaganda at 6GB&#x2F;s in computer readable text.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36676278" class="c"><input type="checkbox" id="c-36676278" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#36676470">prev</a><span>|</span><a href="#36677351">next</a><span>|</span><label class="collapse" for="c-36676278">[-]</label><label class="expand" for="c-36676278">[21 more]</label></div><br/><div class="children"><div class="content">Previously posted about here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36671588">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36671588</a> and here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36674905">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36674905</a><p>With the original source being: <a href="https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;gpt-4-architecture-infrastructure" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;gpt-4-architecture-infrastruc...</a><p>The twitter guy seems to just be paraphrasing the actual blog post?  That&#x27;s presumably why the tweets are now deleted.<p>---<p>The fact that they&#x27;re using MoE was news to me and very interesting.  I&#x27;d love to know more details about how they got that to work.  Variations in that implementation would explain the fluctuations in the quality of output that people have observed.<p>I&#x27;m still waiting for the release of their vision model which is mentioned here but we still know little about, sans a few demos a few months ago.</div><br/><div id="36676438" class="c"><input type="checkbox" id="c-36676438" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#36676278">parent</a><span>|</span><a href="#36676362">next</a><span>|</span><label class="collapse" for="c-36676438">[-]</label><label class="expand" for="c-36676438">[7 more]</label></div><br/><div class="children"><div class="content">Interesting on a meta point that the more clickbaity title &quot;GPT-4 details leaked&quot; won out over the more dispassionate but drier &quot;GPT-4 Architecture, Infrastructure, Training Dataset, Costs&quot;.</div><br/><div id="36676493" class="c"><input type="checkbox" id="c-36676493" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676438">parent</a><span>|</span><a href="#36677819">next</a><span>|</span><label class="collapse" for="c-36676493">[-]</label><label class="expand" for="c-36676493">[3 more]</label></div><br/><div class="children"><div class="content">Clickbait has its time and place. Despite my hatred towards it, sometimes it&#x27;s really needed.</div><br/><div id="36677080" class="c"><input type="checkbox" id="c-36677080" checked=""/><div class="controls bullet"><span class="by">H8crilA</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676493">parent</a><span>|</span><a href="#36677582">next</a><span>|</span><label class="collapse" for="c-36677080">[-]</label><label class="expand" for="c-36677080">[1 more]</label></div><br/><div class="children"><div class="content">It is needed if you want people to click on your content more.</div><br/></div></div><div id="36677582" class="c"><input type="checkbox" id="c-36677582" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676493">parent</a><span>|</span><a href="#36677080">prev</a><span>|</span><a href="#36677819">next</a><span>|</span><label class="collapse" for="c-36677582">[-]</label><label class="expand" for="c-36677582">[1 more]</label></div><br/><div class="children"><div class="content">is it needed when you pay for the blogpost and then immediately chargeback the card like this dude did? <a href="https:&#x2F;&#x2F;twitter.com&#x2F;untitled01ipynb&#x2F;status&#x2F;1678655012015071232" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;untitled01ipynb&#x2F;status&#x2F;16786550120150712...</a><p>what a colossal asshole</div><br/></div></div></div></div><div id="36677819" class="c"><input type="checkbox" id="c-36677819" checked=""/><div class="controls bullet"><span class="by">Aachen</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676438">parent</a><span>|</span><a href="#36676493">prev</a><span>|</span><a href="#36676642">next</a><span>|</span><label class="collapse" for="c-36677819">[-]</label><label class="expand" for="c-36677819">[2 more]</label></div><br/><div class="children"><div class="content">When choosing titles for my own submissions, yeah, the accurate title that HN says they desire gets no votes whatsoever. Any clickbait on here, people bring upon themselves (and this isn&#x27;t even a clickbait-level title)</div><br/><div id="36678028" class="c"><input type="checkbox" id="c-36678028" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36677819">parent</a><span>|</span><a href="#36676642">next</a><span>|</span><label class="collapse" for="c-36678028">[-]</label><label class="expand" for="c-36678028">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t want accurate titles because they&#x27;ll make me vote for it. I want accurate titles because it helps me determine if I&#x27;ll read it BEFORE clicking it.<p>The whole point of accurate titles is that you&#x27;ll get less votes on uninteresting content.</div><br/></div></div></div></div><div id="36676642" class="c"><input type="checkbox" id="c-36676642" checked=""/><div class="controls bullet"><span class="by">nicpottier</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676438">parent</a><span>|</span><a href="#36677819">prev</a><span>|</span><a href="#36676362">next</a><span>|</span><label class="collapse" for="c-36676642">[-]</label><label class="expand" for="c-36676642">[1 more]</label></div><br/><div class="children"><div class="content">To be fair the latter has the meat of it behind a paywall.</div><br/></div></div></div></div><div id="36676362" class="c"><input type="checkbox" id="c-36676362" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36676278">parent</a><span>|</span><a href="#36676438">prev</a><span>|</span><a href="#36676359">next</a><span>|</span><label class="collapse" for="c-36676362">[-]</label><label class="expand" for="c-36676362">[11 more]</label></div><br/><div class="children"><div class="content">I had to ask GPT what MoE means:<p>&quot;MoE&quot; in the context of artificial intelligence typically stands for &quot;Mixture of Experts&quot;. This is a machine learning technique that is based on the idea of dividing a problem into sub-problems, solving each sub-problem with a specialized &quot;expert&quot; (or model), and then combining their outputs.</div><br/><div id="36676403" class="c"><input type="checkbox" id="c-36676403" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676362">parent</a><span>|</span><a href="#36676530">next</a><span>|</span><label class="collapse" for="c-36676403">[-]</label><label class="expand" for="c-36676403">[6 more]</label></div><br/><div class="children"><div class="content">Yep they (would) basically have 8-16 &quot;experts&quot; that are each about the size of GPT-3. Since they each see different batches of the dataset, they learn to model those distributions independently rather than the distribution of the whole dataset. Some of the attention is shared between them however.<p>Then another &quot;routing model&quot; decides which model is most suitable for the given user prompt.<p>Given they use relatively few experts, each one is likely similarly capable to the others on many tasks. I assume this make deployment easier and is a &quot;more conservative&quot; less risky approach. Even if the wrong model is chosen by the router, answers should still tend to be somewhat acceptable, for instance.</div><br/><div id="36677811" class="c"><input type="checkbox" id="c-36677811" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676403">parent</a><span>|</span><a href="#36676473">next</a><span>|</span><label class="collapse" for="c-36677811">[-]</label><label class="expand" for="c-36677811">[2 more]</label></div><br/><div class="children"><div class="content">This is not how mixture of experts works at all. The experts are chosen on each layer, not for the whole network, and attention is shared between all of them.</div><br/><div id="36678043" class="c"><input type="checkbox" id="c-36678043" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36677811">parent</a><span>|</span><a href="#36676473">next</a><span>|</span><label class="collapse" for="c-36678043">[-]</label><label class="expand" for="c-36678043">[1 more]</label></div><br/><div class="children"><div class="content">Oh I’m happy to admit if I’m wrong in the details. My bad.<p>So you’re saying the experts chosen are a more literal mixture of layers from each model? Rather than a simple “pick which model to run”?</div><br/></div></div></div></div><div id="36676473" class="c"><input type="checkbox" id="c-36676473" checked=""/><div class="controls bullet"><span class="by">ta988</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676403">parent</a><span>|</span><a href="#36677811">prev</a><span>|</span><a href="#36676548">next</a><span>|</span><label class="collapse" for="c-36676473">[-]</label><label class="expand" for="c-36676473">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s interesting because that&#x27;s more or less on more level above the multi-head attention.</div><br/></div></div><div id="36676548" class="c"><input type="checkbox" id="c-36676548" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676403">parent</a><span>|</span><a href="#36676473">prev</a><span>|</span><a href="#36676530">next</a><span>|</span><label class="collapse" for="c-36676548">[-]</label><label class="expand" for="c-36676548">[2 more]</label></div><br/><div class="children"><div class="content">Source?</div><br/><div id="36676669" class="c"><input type="checkbox" id="c-36676669" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676548">parent</a><span>|</span><a href="#36676530">next</a><span>|</span><label class="collapse" for="c-36676669">[-]</label><label class="expand" for="c-36676669">[1 more]</label></div><br/><div class="children"><div class="content">Just theorizing from the top-level post here. No clue if it&#x27;s legitimate.</div><br/></div></div></div></div></div></div><div id="36676530" class="c"><input type="checkbox" id="c-36676530" checked=""/><div class="controls bullet"><span class="by">aaron695</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676362">parent</a><span>|</span><a href="#36676403">prev</a><span>|</span><a href="#36676359">next</a><span>|</span><label class="collapse" for="c-36676530">[-]</label><label class="expand" for="c-36676530">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know why HN isn&#x27;t banning accounts that post GPT rubbish. I guess I do HN is pretty much 95% spam these days like 4Chan.<p>If HN readers are a bunch of losers that GPT was good enough they can GPT for themselves.<p>Wikipedia doesn&#x27;t explain it well either - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mixture_of_experts" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mixture_of_experts</a><p>Their example  computer vision -  one for human detection - one for pose estimation<p>This is easy to understand.<p>Don&#x27;t get how that goes to GPT.<p>Would one be trained on books and another be trained on reddit? Or can it be really abstract and no one knows what a expert does?</div><br/><div id="36677684" class="c"><input type="checkbox" id="c-36677684" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676530">parent</a><span>|</span><a href="#36677951">next</a><span>|</span><label class="collapse" for="c-36677684">[-]</label><label class="expand" for="c-36677684">[1 more]</label></div><br/><div class="children"><div class="content">If the answer is wrong, perhaps you could post a correction so that we are all better off, instead of just insulting me.<p>Honestly, I&#x27;ve had a fairly rough day, and your answer has made me a bit more upset than perhaps I should be. At least GPT doesn&#x27;t act like a jerk when I ask it a stupid question.</div><br/></div></div><div id="36677951" class="c"><input type="checkbox" id="c-36677951" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676530">parent</a><span>|</span><a href="#36677684">prev</a><span>|</span><a href="#36677986">next</a><span>|</span><label class="collapse" for="c-36677951">[-]</label><label class="expand" for="c-36677951">[1 more]</label></div><br/><div class="children"><div class="content">You should consider asking ChatGPT for help in clarifying your point(s).</div><br/></div></div><div id="36677986" class="c"><input type="checkbox" id="c-36677986" checked=""/><div class="controls bullet"><span class="by">ikekkdcjkfke</span><span>|</span><a href="#36676278">root</a><span>|</span><a href="#36676530">parent</a><span>|</span><a href="#36677951">prev</a><span>|</span><a href="#36676359">next</a><span>|</span><label class="collapse" for="c-36677986">[-]</label><label class="expand" for="c-36677986">[1 more]</label></div><br/><div class="children"><div class="content">Are you ok?</div><br/></div></div></div></div></div></div><div id="36676359" class="c"><input type="checkbox" id="c-36676359" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36676278">parent</a><span>|</span><a href="#36676362">prev</a><span>|</span><a href="#36676370">next</a><span>|</span><label class="collapse" for="c-36676359">[-]</label><label class="expand" for="c-36676359">[1 more]</label></div><br/><div class="children"><div class="content">The previous posts are to a twitter thread that&#x27;s been taken down, and the preview of a post that requires a $1000 subscription. This post however is freely available (for now at least).</div><br/></div></div><div id="36676370" class="c"><input type="checkbox" id="c-36676370" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36676278">parent</a><span>|</span><a href="#36676359">prev</a><span>|</span><a href="#36677351">next</a><span>|</span><label class="collapse" for="c-36676370">[-]</label><label class="expand" for="c-36676370">[1 more]</label></div><br/><div class="children"><div class="content">FYI, George Hotz has been claiming to know this aspect for a couple of weeks now.<p>&gt; The fact that they&#x27;re using MoE was news to me and very interesting.<p>Maybe adds some legitimacy to the claim.</div><br/></div></div></div></div><div id="36677351" class="c"><input type="checkbox" id="c-36677351" checked=""/><div class="controls bullet"><span class="by">xeckr</span><span>|</span><a href="#36676278">prev</a><span>|</span><a href="#36677020">next</a><span>|</span><label class="collapse" for="c-36677351">[-]</label><label class="expand" for="c-36677351">[7 more]</label></div><br/><div class="children"><div class="content">If this is true, then:<p>1. Training took 21 yottaflops. When was the last time you saw the yotta- prefix for anything?<p>2. The training cost of GPT-4 is now only 1&#x2F;3 of what it was about a year ago. It is absolutely staggering how quickly the price of training an LLM is dropping, which is great news for open source. The google memo was right about the lack of a moat.</div><br/><div id="36677683" class="c"><input type="checkbox" id="c-36677683" checked=""/><div class="controls bullet"><span class="by">theLiminator</span><span>|</span><a href="#36677351">parent</a><span>|</span><a href="#36677020">next</a><span>|</span><label class="collapse" for="c-36677683">[-]</label><label class="expand" for="c-36677683">[6 more]</label></div><br/><div class="children"><div class="content">The real moat is an abundance of high quality data.</div><br/><div id="36677863" class="c"><input type="checkbox" id="c-36677863" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36677351">root</a><span>|</span><a href="#36677683">parent</a><span>|</span><a href="#36677754">next</a><span>|</span><label class="collapse" for="c-36677863">[-]</label><label class="expand" for="c-36677863">[1 more]</label></div><br/><div class="children"><div class="content">Yeah they have the internet from before LLMs were used for anything, so the data is not poisoned. Not unlike carbon dating becoming useless for estimating age of anything made after nuclear atmospheric tests, or low-background steel.</div><br/></div></div><div id="36677754" class="c"><input type="checkbox" id="c-36677754" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36677351">root</a><span>|</span><a href="#36677683">parent</a><span>|</span><a href="#36677863">prev</a><span>|</span><a href="#36677725">next</a><span>|</span><label class="collapse" for="c-36677754">[-]</label><label class="expand" for="c-36677754">[3 more]</label></div><br/><div class="children"><div class="content">Well open AI raised eye brows by crawling the internet and using everyone&#x27;s data  to make a commercial product<p>One day some new startup will train on all of libgen and torrent networks, but it will be very hard to prove. You&#x27;ll keep getting these gaps up in questionable morality and legality, and even openai will complain about playing fair</div><br/><div id="36677843" class="c"><input type="checkbox" id="c-36677843" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36677351">root</a><span>|</span><a href="#36677754">parent</a><span>|</span><a href="#36677899">next</a><span>|</span><label class="collapse" for="c-36677843">[-]</label><label class="expand" for="c-36677843">[1 more]</label></div><br/><div class="children"><div class="content">Google Classroom, teenager&#x27;s essays, written by humans, for learning what it means to be human, and <i>graded</i> by humans, is a richer dataset than anything else I can think of that anyone could get their hands on.</div><br/></div></div><div id="36677899" class="c"><input type="checkbox" id="c-36677899" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36677351">root</a><span>|</span><a href="#36677754">parent</a><span>|</span><a href="#36677843">prev</a><span>|</span><a href="#36677725">next</a><span>|</span><label class="collapse" for="c-36677899">[-]</label><label class="expand" for="c-36677899">[1 more]</label></div><br/><div class="children"><div class="content">Many people train on libgen&#x2F;torrent in the form of books3 (e.g. LLaMa does this).</div><br/></div></div></div></div><div id="36677725" class="c"><input type="checkbox" id="c-36677725" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36677351">root</a><span>|</span><a href="#36677683">parent</a><span>|</span><a href="#36677754">prev</a><span>|</span><a href="#36677020">next</a><span>|</span><label class="collapse" for="c-36677725">[-]</label><label class="expand" for="c-36677725">[1 more]</label></div><br/><div class="children"><div class="content">IMO the real moat right now is expertise &#x2F; smart teams and cash.</div><br/></div></div></div></div></div></div><div id="36677020" class="c"><input type="checkbox" id="c-36677020" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36677351">prev</a><span>|</span><a href="#36676378">next</a><span>|</span><label class="collapse" for="c-36677020">[-]</label><label class="expand" for="c-36677020">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The conspiracy theory that the new GPT-4 quality had been deteriorated might be simply because they are letting the oracle model accept lower probability sequences from the speculative decoding model.</i><p>In other words: the speculation was likely right, I&#x27;ll propose a specific mechanism explaining it, but then still insult the people bringing it up and keep gaslighting them.</div><br/></div></div><div id="36676378" class="c"><input type="checkbox" id="c-36676378" checked=""/><div class="controls bullet"><span class="by">shahules</span><span>|</span><a href="#36677020">prev</a><span>|</span><a href="#36676364">next</a><span>|</span><label class="collapse" for="c-36676378">[-]</label><label class="expand" for="c-36676378">[2 more]</label></div><br/><div class="children"><div class="content">This guy doesn&#x27;t have any idea what he is talking about. He consistently posts such bullshit on twitter. Mostly copy paste with added spice mix.</div><br/><div id="36676507" class="c"><input type="checkbox" id="c-36676507" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#36676378">parent</a><span>|</span><a href="#36676364">next</a><span>|</span><label class="collapse" for="c-36676507">[-]</label><label class="expand" for="c-36676507">[1 more]</label></div><br/><div class="children"><div class="content">I noted several things that don&#x27;t seem consistent with what people have been assuming from before.<p>For instance - MoE yes, but 16 experts at 111B parameters? Doesn&#x27;t make sense.  GPT 3 had 175B parameters.  I doubt they would go less on base models from now on.  The number that makes more sense is ~220B parameters per model and 8 expert models.  That is the same inference cost in total.<p>The 13T tokens of training data seems pulled from thin air.</div><br/></div></div></div></div><div id="36676364" class="c"><input type="checkbox" id="c-36676364" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#36676378">prev</a><span>|</span><a href="#36676910">next</a><span>|</span><label class="collapse" for="c-36676364">[-]</label><label class="expand" for="c-36676364">[10 more]</label></div><br/><div class="children"><div class="content">Google has been doing research into mixture of experts for scaling LLMs. Their GLaM model published in 2022 has 1.7 trillion parameters and 64 experts.<p><a href="https:&#x2F;&#x2F;icml.cc&#x2F;media&#x2F;icml-2022&#x2F;Slides&#x2F;17378.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;icml.cc&#x2F;media&#x2F;icml-2022&#x2F;Slides&#x2F;17378.pdf</a></div><br/><div id="36676499" class="c"><input type="checkbox" id="c-36676499" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36676364">parent</a><span>|</span><a href="#36676910">next</a><span>|</span><label class="collapse" for="c-36676499">[-]</label><label class="expand" for="c-36676499">[9 more]</label></div><br/><div class="children"><div class="content">Google is jokingly behind in terms of LLMs. They&#x27;ve done a pretty good job at incorporating vision and audio ML models into their ecosystem, but they underestimated language.</div><br/><div id="36676678" class="c"><input type="checkbox" id="c-36676678" checked=""/><div class="controls bullet"><span class="by">chucknthem</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36676499">parent</a><span>|</span><a href="#36677612">next</a><span>|</span><label class="collapse" for="c-36676678">[-]</label><label class="expand" for="c-36676678">[5 more]</label></div><br/><div class="children"><div class="content">How do you know? do you have insider knowledge of this or is it just based on what they share publically?</div><br/><div id="36676864" class="c"><input type="checkbox" id="c-36676864" checked=""/><div class="controls bullet"><span class="by">seanthemon</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36676678">parent</a><span>|</span><a href="#36676953">next</a><span>|</span><label class="collapse" for="c-36676864">[-]</label><label class="expand" for="c-36676864">[1 more]</label></div><br/><div class="children"><div class="content">From what I see in that GPT 3 and 4 was a bit of a rugpull for the industry, now we&#x27;re all laughing at Google because seemingly they had their hands on the rug for nearly a decade and did nothing - but from the other perspective, maybe they saw the future openai has now brought us and decided against being the pioneers</div><br/></div></div><div id="36676953" class="c"><input type="checkbox" id="c-36676953" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36676678">parent</a><span>|</span><a href="#36676864">prev</a><span>|</span><a href="#36677612">next</a><span>|</span><label class="collapse" for="c-36676953">[-]</label><label class="expand" for="c-36676953">[3 more]</label></div><br/><div class="children"><div class="content">as a fun ancedote, the Google Bard&#x27;s implicit code execution update from *last month*, advertised by Sundar... no longer works <a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1678495067663925248" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1678495067663925248</a><p>i&#x27;d love to know whats going on in that team.</div><br/><div id="36677101" class="c"><input type="checkbox" id="c-36677101" checked=""/><div class="controls bullet"><span class="by">H8crilA</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36676953">parent</a><span>|</span><a href="#36677612">next</a><span>|</span><label class="collapse" for="c-36677101">[-]</label><label class="expand" for="c-36677101">[2 more]</label></div><br/><div class="children"><div class="content">Probably safety-driven terror. They really really want to get their bots going, but in every single meeting some PM or other concerned engineer talks about safety and f**s up the entire meeting.<p>They even made the bot not respond to arithmetics questions because the bot is bad at this, lol. Someone who knows how to modify the bot had actually spent their time on something as unimportant as that.</div><br/><div id="36677648" class="c"><input type="checkbox" id="c-36677648" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36677101">parent</a><span>|</span><a href="#36677612">next</a><span>|</span><label class="collapse" for="c-36677648">[-]</label><label class="expand" for="c-36677648">[1 more]</label></div><br/><div class="children"><div class="content">Bard being bad at anything else doesn&#x27;t seem to stop it. It hallucinates at the drop of the hat. Asking it almost any question implying X nonexistent thing exists causes it to make that thing up.</div><br/></div></div></div></div></div></div></div></div><div id="36677612" class="c"><input type="checkbox" id="c-36677612" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36676499">parent</a><span>|</span><a href="#36676678">prev</a><span>|</span><a href="#36676910">next</a><span>|</span><label class="collapse" for="c-36677612">[-]</label><label class="expand" for="c-36677612">[3 more]</label></div><br/><div class="children"><div class="content">Their translation service is based on llms and is commercially a successful product.</div><br/><div id="36677637" class="c"><input type="checkbox" id="c-36677637" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36677612">parent</a><span>|</span><a href="#36676910">next</a><span>|</span><label class="collapse" for="c-36677637">[-]</label><label class="expand" for="c-36677637">[2 more]</label></div><br/><div class="children"><div class="content">Transformer models rather than LLMs surely. ChatGPT behaves nothing like Google Translate.</div><br/><div id="36678001" class="c"><input type="checkbox" id="c-36678001" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#36676364">root</a><span>|</span><a href="#36677637">parent</a><span>|</span><a href="#36676910">next</a><span>|</span><label class="collapse" for="c-36678001">[-]</label><label class="expand" for="c-36678001">[1 more]</label></div><br/><div class="children"><div class="content">The T in ChatGPT stands for Transformers. The similarity between the OG Transformer from 2017 and GPT3 (and other modern LLMs) is pretty big</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36676910" class="c"><input type="checkbox" id="c-36676910" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36676364">prev</a><span>|</span><a href="#36677014">next</a><span>|</span><label class="collapse" for="c-36676910">[-]</label><label class="expand" for="c-36676910">[3 more]</label></div><br/><div class="children"><div class="content">The tweet is gone. What was in it?<p>Also, I&#x27;m dubious about this unsubstantiated claim. The biggest past innovation (training with human feedback) actually shrunk the size of a model. Compare Bloom-366B with falcon-40B (much better). I would be mildly surprised if it turned out Gpt4 has 1.8T parameters. (even if it&#x27;s a composite model as they say)<p>The article says they use 16 experts 111B each. So the best thing to assume is probably that each of these experts is basically a fine tuned version of the same initial model for some problem domain.</div><br/><div id="36677919" class="c"><input type="checkbox" id="c-36677919" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676910">parent</a><span>|</span><a href="#36677267">next</a><span>|</span><label class="collapse" for="c-36677919">[-]</label><label class="expand" for="c-36677919">[1 more]</label></div><br/><div class="children"><div class="content">As a note the 366B in Bloom-366B refers to the number of tokens, not the number of parameters. Bloom had 176B parameters (still many more than Falcon)</div><br/></div></div><div id="36677267" class="c"><input type="checkbox" id="c-36677267" checked=""/><div class="controls bullet"><span class="by">Al0neStar</span><span>|</span><a href="#36676910">parent</a><span>|</span><a href="#36677919">prev</a><span>|</span><a href="#36677014">next</a><span>|</span><label class="collapse" for="c-36677267">[-]</label><label class="expand" for="c-36677267">[1 more]</label></div><br/><div class="children"><div class="content">Maybe 111B is the base GPT-3.5 model.</div><br/></div></div></div></div><div id="36677014" class="c"><input type="checkbox" id="c-36677014" checked=""/><div class="controls bullet"><span class="by">mmahemoff</span><span>|</span><a href="#36676910">prev</a><span>|</span><a href="#36676390">next</a><span>|</span><label class="collapse" for="c-36677014">[-]</label><label class="expand" for="c-36677014">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been wondering how freemium services like Thread Reader still operate now that Twitter is charging prohibitive prices for API access and taking measures to prevent scraping. The cheapest API plan with read access is $100&#x2F;month, which reads 10,000 tweets, so could only produce about 500 pages like this one on demand.</div><br/><div id="36677191" class="c"><input type="checkbox" id="c-36677191" checked=""/><div class="controls bullet"><span class="by">errantmind</span><span>|</span><a href="#36677014">parent</a><span>|</span><a href="#36677275">next</a><span>|</span><label class="collapse" for="c-36677191">[-]</label><label class="expand" for="c-36677191">[2 more]</label></div><br/><div class="children"><div class="content">There was a post on HN recently with a workaround these apps are using. I don&#x27;t have it handy but I&#x27;m sure you can find it if you look.</div><br/><div id="36677325" class="c"><input type="checkbox" id="c-36677325" checked=""/><div class="controls bullet"><span class="by">n1c</span><span>|</span><a href="#36677014">root</a><span>|</span><a href="#36677191">parent</a><span>|</span><a href="#36677275">next</a><span>|</span><label class="collapse" for="c-36677325">[-]</label><label class="expand" for="c-36677325">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s probably some interesting bits of info in yesterday&#x27;s Nitter thread: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36665406">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36665406</a></div><br/></div></div></div></div><div id="36677275" class="c"><input type="checkbox" id="c-36677275" checked=""/><div class="controls bullet"><span class="by">xeckr</span><span>|</span><a href="#36677014">parent</a><span>|</span><a href="#36677191">prev</a><span>|</span><a href="#36676390">next</a><span>|</span><label class="collapse" for="c-36677275">[-]</label><label class="expand" for="c-36677275">[1 more]</label></div><br/><div class="children"><div class="content">const puppeteer = require(&#x27;puppeteer&#x27;); and so on and so forth.</div><br/></div></div></div></div><div id="36676390" class="c"><input type="checkbox" id="c-36676390" checked=""/><div class="controls bullet"><span class="by">npsomaratna</span><span>|</span><a href="#36677014">prev</a><span>|</span><a href="#36676918">next</a><span>|</span><label class="collapse" for="c-36676390">[-]</label><label class="expand" for="c-36676390">[3 more]</label></div><br/><div class="children"><div class="content">This is unsubstantiated. The only folks who know exactly how GPT-4 works are employed at OpenAI. The rest of us can only guess.</div><br/><div id="36676547" class="c"><input type="checkbox" id="c-36676547" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#36676390">parent</a><span>|</span><a href="#36676918">next</a><span>|</span><label class="collapse" for="c-36676547">[-]</label><label class="expand" for="c-36676547">[2 more]</label></div><br/><div class="children"><div class="content">Even if I just go with Sam Altman&#x27;s public comment, I would have came to similar conclusion: GPT-4 is big and it is hard to make it is faster.<p>The secret sauce and moat lies in data though. I have heard rumour that they have paid competitive coders to write and annotate code with information like complexity for them.</div><br/><div id="36677687" class="c"><input type="checkbox" id="c-36677687" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36676390">root</a><span>|</span><a href="#36676547">parent</a><span>|</span><a href="#36676918">next</a><span>|</span><label class="collapse" for="c-36677687">[-]</label><label class="expand" for="c-36677687">[1 more]</label></div><br/><div class="children"><div class="content">GPT4 can diagram sentences using link grammar parsing (<a href="https:&#x2F;&#x2F;www.link.cs.cmu.edu&#x2F;link&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.link.cs.cmu.edu&#x2F;link&#x2F;</a>) which is obscure enough I really don&#x27;t think they&#x27;ve generated data for it. So it can get pretty good without that.</div><br/></div></div></div></div></div></div><div id="36676918" class="c"><input type="checkbox" id="c-36676918" checked=""/><div class="controls bullet"><span class="by">langsoul-com</span><span>|</span><a href="#36676390">prev</a><span>|</span><a href="#36677501">next</a><span>|</span><label class="collapse" for="c-36676918">[-]</label><label class="expand" for="c-36676918">[1 more]</label></div><br/><div class="children"><div class="content">We should default to using the thread aggregators instead of using twitter links. My God Twitter threads are unreadable.</div><br/></div></div><div id="36677501" class="c"><input type="checkbox" id="c-36677501" checked=""/><div class="controls bullet"><span class="by">PUSH_AX</span><span>|</span><a href="#36676918">prev</a><span>|</span><a href="#36677224">next</a><span>|</span><label class="collapse" for="c-36677501">[-]</label><label class="expand" for="c-36677501">[4 more]</label></div><br/><div class="children"><div class="content">What is this hyper dramatic nonsense tweet about, “It’s over“? What’s over?</div><br/><div id="36677660" class="c"><input type="checkbox" id="c-36677660" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36677501">parent</a><span>|</span><a href="#36677568">next</a><span>|</span><label class="collapse" for="c-36677660">[-]</label><label class="expand" for="c-36677660">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a meme based on quoting this tweet.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;jebbush&#x2F;status&#x2F;929541504187686912" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;jebbush&#x2F;status&#x2F;929541504187686912</a></div><br/></div></div><div id="36677568" class="c"><input type="checkbox" id="c-36677568" checked=""/><div class="controls bullet"><span class="by">sweezyjeezy</span><span>|</span><a href="#36677501">parent</a><span>|</span><a href="#36677660">prev</a><span>|</span><a href="#36677593">next</a><span>|</span><label class="collapse" for="c-36677568">[-]</label><label class="expand" for="c-36677568">[1 more]</label></div><br/><div class="children"><div class="content">The wait to find out what the model is I&#x27;m guessing?</div><br/></div></div><div id="36677593" class="c"><input type="checkbox" id="c-36677593" checked=""/><div class="controls bullet"><span class="by">toxicFork</span><span>|</span><a href="#36677501">parent</a><span>|</span><a href="#36677568">prev</a><span>|</span><a href="#36677224">next</a><span>|</span><label class="collapse" for="c-36677593">[-]</label><label class="expand" for="c-36677593">[1 more]</label></div><br/><div class="children"><div class="content">The thing, dude, the thing, is over!</div><br/></div></div></div></div><div id="36677224" class="c"><input type="checkbox" id="c-36677224" checked=""/><div class="controls bullet"><span class="by">aussieguy1234</span><span>|</span><a href="#36677501">prev</a><span>|</span><a href="#36677069">next</a><span>|</span><label class="collapse" for="c-36677224">[-]</label><label class="expand" for="c-36677224">[1 more]</label></div><br/><div class="children"><div class="content">The fact they are using MoE is interesting. There are alot of specialised open source models on HuggingFace. You just need an LLM to act as the core &quot;brain&quot; and a few other components.<p>HuggingGPT works similar to this. It automatically chooses, downloads and runs the right &quot;expert&quot; model from HuggingFace <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2303.17580" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2303.17580</a></div><br/></div></div><div id="36677069" class="c"><input type="checkbox" id="c-36677069" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#36677224">prev</a><span>|</span><a href="#36676491">next</a><span>|</span><label class="collapse" for="c-36677069">[-]</label><label class="expand" for="c-36677069">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This, of course, is “only” a batch size of 7.5 million tokens per expert due to not every expert seeing all tokens.<p>&gt; Mixture of Expert Tradeoffs: There are multiple MoE tradeoffs taken: For example, MoE is incredibly difficult to deal with on inference because not every part of the model is utilized on every token generation.<p>Are these experts able to communicate among them in one query? How do they get selected? How do they know who to pass information to?<p>Would I be able to influence the selection of experts by how I create my questions? For example to ensure that a question about code gets passed directly to an expert in code? I feel silly asking this question, but I honestly have no idea how to interpret this.</div><br/></div></div><div id="36676491" class="c"><input type="checkbox" id="c-36676491" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#36677069">prev</a><span>|</span><a href="#36677877">next</a><span>|</span><label class="collapse" for="c-36676491">[-]</label><label class="expand" for="c-36676491">[6 more]</label></div><br/><div class="children"><div class="content">I wonder what the legal implications of them using SciHub and Libgen would be if that&#x27;s true. I&#x27;d imagine OpenAI is big enough to make deals with publishers.</div><br/><div id="36677111" class="c"><input type="checkbox" id="c-36677111" checked=""/><div class="controls bullet"><span class="by">twayt</span><span>|</span><a href="#36676491">parent</a><span>|</span><a href="#36678146">next</a><span>|</span><label class="collapse" for="c-36677111">[-]</label><label class="expand" for="c-36677111">[3 more]</label></div><br/><div class="children"><div class="content">Libgen &#x2F; Scihub or not, if the model can provide details about the book other than just high level info like the summary and no explicit deal with the publisher has been made, you can make a strong argument that it is plagiarism.<p>Even if bits and pieces of the book text are distributed across the internet and you end up picking up portions of the book, you still read the book.<p>It is extremely sad but ChatGPT will be taken down by the end of this year and replaced by a highly neutered model next year.</div><br/><div id="36677954" class="c"><input type="checkbox" id="c-36677954" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#36676491">root</a><span>|</span><a href="#36677111">parent</a><span>|</span><a href="#36677941">next</a><span>|</span><label class="collapse" for="c-36677954">[-]</label><label class="expand" for="c-36677954">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a lawyer and obviously we won&#x27;t get any definite answer unless it actually goes to court, all of this is just hand waving and guessing.<p>But I think that unless GPT starts reciting large parts outside of the context of learning&#x2F;education&#x2F;research, reciting smaller snippets would fall into &quot;fair use&quot; and not be illegal.</div><br/></div></div><div id="36677941" class="c"><input type="checkbox" id="c-36677941" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676491">root</a><span>|</span><a href="#36677111">parent</a><span>|</span><a href="#36677954">prev</a><span>|</span><a href="#36678146">next</a><span>|</span><label class="collapse" for="c-36677941">[-]</label><label class="expand" for="c-36677941">[1 more]</label></div><br/><div class="children"><div class="content">If I read a book and then write a summary, is that plagiarism? What&#x27;s the difference? I am legitimately not familiar with copyright law, but real lawyers seem to think it is unclear whether training on copyrighted data is illegal (in Japan it&#x27;s definitely not).</div><br/></div></div></div></div><div id="36678146" class="c"><input type="checkbox" id="c-36678146" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#36676491">parent</a><span>|</span><a href="#36677111">prev</a><span>|</span><a href="#36677282">next</a><span>|</span><label class="collapse" for="c-36678146">[-]</label><label class="expand" for="c-36678146">[1 more]</label></div><br/><div class="children"><div class="content">probably just easier to use drm-free copies of books</div><br/></div></div><div id="36677282" class="c"><input type="checkbox" id="c-36677282" checked=""/><div class="controls bullet"><span class="by">Fiahil</span><span>|</span><a href="#36676491">parent</a><span>|</span><a href="#36678146">prev</a><span>|</span><a href="#36677877">next</a><span>|</span><label class="collapse" for="c-36677282">[-]</label><label class="expand" for="c-36677282">[1 more]</label></div><br/><div class="children"><div class="content">If that&#x27;s true, then OpenAI has probably taken extreme protective measure to ensure the secret is well protected.  Even if OpenAI is big enough to make deals, they probably did not spend several years making deals with all of them.<p>It&#x27;s, however, very interesting to see if they fund efforts to massively (re)start books digitalisation.</div><br/></div></div></div></div><div id="36677877" class="c"><input type="checkbox" id="c-36677877" checked=""/><div class="controls bullet"><span class="by">nightsd01</span><span>|</span><a href="#36676491">prev</a><span>|</span><a href="#36677140">next</a><span>|</span><label class="collapse" for="c-36677877">[-]</label><label class="expand" for="c-36677877">[2 more]</label></div><br/><div class="children"><div class="content">“Leaked” seems like a strong clickbait claim from whoever wrote this, along with the “it’s over” part….</div><br/><div id="36677911" class="c"><input type="checkbox" id="c-36677911" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36677877">parent</a><span>|</span><a href="#36677140">next</a><span>|</span><label class="collapse" for="c-36677911">[-]</label><label class="expand" for="c-36677911">[1 more]</label></div><br/><div class="children"><div class="content">Leaked is I think an accurate term -- this (or the original post) is fairly new information leaked from openai.</div><br/></div></div></div></div><div id="36677140" class="c"><input type="checkbox" id="c-36677140" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#36677877">prev</a><span>|</span><a href="#36677119">next</a><span>|</span><label class="collapse" for="c-36677140">[-]</label><label class="expand" for="c-36677140">[1 more]</label></div><br/><div class="children"><div class="content">This a duplicate post of pure speculation.</div><br/></div></div><div id="36677119" class="c"><input type="checkbox" id="c-36677119" checked=""/><div class="controls bullet"><span class="by">rjb7731</span><span>|</span><a href="#36677140">prev</a><span>|</span><a href="#36677003">next</a><span>|</span><label class="collapse" for="c-36677119">[-]</label><label class="expand" for="c-36677119">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve previously noticed when playing with GPT-4 it can sometimes &#x27;autocomplete&#x27; on different sections of the text its feeding back, sometimes what looks like 4 or more different sections. Might be unrelated but is this MoE in action or them streaming the response in some way?</div><br/><div id="36677260" class="c"><input type="checkbox" id="c-36677260" checked=""/><div class="controls bullet"><span class="by">LiamPowell</span><span>|</span><a href="#36677119">parent</a><span>|</span><a href="#36677003">next</a><span>|</span><label class="collapse" for="c-36677260">[-]</label><label class="expand" for="c-36677260">[1 more]</label></div><br/><div class="children"><div class="content">This is just an issue with their frontend that seems to occur when it encounters \n\n. The actual data coming in only changes at the end of the message.</div><br/></div></div></div></div><div id="36677003" class="c"><input type="checkbox" id="c-36677003" checked=""/><div class="controls bullet"><span class="by">Ozzie_osman</span><span>|</span><a href="#36677119">prev</a><span>|</span><a href="#36676640">next</a><span>|</span><label class="collapse" for="c-36677003">[-]</label><label class="expand" for="c-36677003">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a section at the end where there is speculation on what the entire dataset entails. My guess is a chunk of it is probably from ChatGPT data (or GPT3 data from when training on your requests was opt-out rather than opt-in).</div><br/></div></div><div id="36676640" class="c"><input type="checkbox" id="c-36676640" checked=""/><div class="controls bullet"><span class="by">getmeinrn</span><span>|</span><a href="#36677003">prev</a><span>|</span><a href="#36676346">next</a><span>|</span><label class="collapse" for="c-36676640">[-]</label><label class="expand" for="c-36676640">[3 more]</label></div><br/><div class="children"><div class="content">&gt;If their cost in the cloud was about $1 per A100 hour, the training costs for this run alone would be about $63 million.<p>If someone legitimate put together a crowd funding effort, I would donate a non-insignificant amount to train an open model. Has it been tried before?</div><br/><div id="36677643" class="c"><input type="checkbox" id="c-36677643" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#36676640">parent</a><span>|</span><a href="#36676799">next</a><span>|</span><label class="collapse" for="c-36677643">[-]</label><label class="expand" for="c-36677643">[1 more]</label></div><br/><div class="children"><div class="content">Some kind of SETI project,  but for training a high number parameter llm would be awesome.</div><br/></div></div><div id="36676799" class="c"><input type="checkbox" id="c-36676799" checked=""/><div class="controls bullet"><span class="by">asynchronous</span><span>|</span><a href="#36676640">parent</a><span>|</span><a href="#36677643">prev</a><span>|</span><a href="#36676346">next</a><span>|</span><label class="collapse" for="c-36676799">[-]</label><label class="expand" for="c-36676799">[1 more]</label></div><br/><div class="children"><div class="content">Not yet, heard tale of several people having the same idea to train an open model though through either crowdfunding or some wizardry with crowdsourcing GPUs.<p>$65 million sounds pretty high though.</div><br/></div></div></div></div><div id="36676346" class="c"><input type="checkbox" id="c-36676346" checked=""/><div class="controls bullet"><span class="by">eminence32</span><span>|</span><a href="#36676640">prev</a><span>|</span><a href="#36676401">next</a><span>|</span><label class="collapse" for="c-36676346">[-]</label><label class="expand" for="c-36676346">[5 more]</label></div><br/><div class="children"><div class="content">&gt; It is over.<p>What does this mean?</div><br/><div id="36676475" class="c"><input type="checkbox" id="c-36676475" checked=""/><div class="controls bullet"><span class="by">aaronbrethorst</span><span>|</span><a href="#36676346">parent</a><span>|</span><a href="#36676607">next</a><span>|</span><label class="collapse" for="c-36676475">[-]</label><label class="expand" for="c-36676475">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the tweet equivalent of one of those obnoxious YouTube &#x27;reaction&#x27; thumbnails.</div><br/></div></div><div id="36676607" class="c"><input type="checkbox" id="c-36676607" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#36676346">parent</a><span>|</span><a href="#36676475">prev</a><span>|</span><a href="#36676459">next</a><span>|</span><label class="collapse" for="c-36676607">[-]</label><label class="expand" for="c-36676607">[1 more]</label></div><br/><div class="children"><div class="content">“It’s over” is the latest meme phrase to describe some kind of defeat.</div><br/></div></div><div id="36676459" class="c"><input type="checkbox" id="c-36676459" checked=""/><div class="controls bullet"><span class="by">purplecats</span><span>|</span><a href="#36676346">parent</a><span>|</span><a href="#36676607">prev</a><span>|</span><a href="#36676483">next</a><span>|</span><label class="collapse" for="c-36676459">[-]</label><label class="expand" for="c-36676459">[1 more]</label></div><br/><div class="children"><div class="content">presumably the speculation</div><br/></div></div><div id="36676483" class="c"><input type="checkbox" id="c-36676483" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#36676346">parent</a><span>|</span><a href="#36676459">prev</a><span>|</span><a href="#36676401">next</a><span>|</span><label class="collapse" for="c-36676483">[-]</label><label class="expand" for="c-36676483">[1 more]</label></div><br/><div class="children"><div class="content">If this is true, anyone [1] can now build a GPT-4 given training data and budget.<p>There&#x27;s no magic here.<p>[1] That&#x27;s probably twenty or so orgs right now, which will blow away OpenAI&#x27;s moat and margins.</div><br/></div></div></div></div><div id="36676401" class="c"><input type="checkbox" id="c-36676401" checked=""/><div class="controls bullet"><span class="by">DanAtC</span><span>|</span><a href="#36676346">prev</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36676401">[-]</label><label class="expand" for="c-36676401">[8 more]</label></div><br/><div class="children"><div class="content">These words are nonsense to me. Can someone explain?</div><br/><div id="36676477" class="c"><input type="checkbox" id="c-36676477" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#36676401">parent</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36676477">[-]</label><label class="expand" for="c-36676477">[7 more]</label></div><br/><div class="children"><div class="content">GPT-4 is the name of a machine learning (language) model that is the basis of chatGPT. This post speculates about its internals.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GPT-4" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GPT-4</a></div><br/><div id="36676600" class="c"><input type="checkbox" id="c-36676600" checked=""/><div class="controls bullet"><span class="by">DanAtC</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36676477">parent</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36676600">[-]</label><label class="expand" for="c-36676600">[6 more]</label></div><br/><div class="children"><div class="content">I meant things like:<p>- parameters<p>- layers<p>- &quot;Mixture Of Experts&quot;<p>- tokens<p>That&#x27;s about as far as I made it</div><br/><div id="36676624" class="c"><input type="checkbox" id="c-36676624" checked=""/><div class="controls bullet"><span class="by">DANmode</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36676600">parent</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36676624">[-]</label><label class="expand" for="c-36676624">[5 more]</label></div><br/><div class="children"><div class="content">Parameters: In the context of AI and language models, parameters refer to the internal settings or variables that an AI model uses to make predictions or generate responses. Think of them as the knobs and switches that can be adjusted to fine-tune how the AI understands and generates language. These parameters are learned during the training process, where the AI model analyzes vast amounts of data to optimize its performance.<p>Layers: In AI, layers are like stacked building blocks within a neural network, which is the fundamental structure of many AI models. Each layer performs different computations, transforming the input data as it passes through them. Think of a layer as a specific task or filter that the AI model can utilize to understand and process information. The deeper the neural network, the more layers it has, allowing for more complex patterns and representations to be learned.<p>&quot;Mixture Of Experts&quot;: An &quot;MoE&quot; is an approach in AI that combines multiple specialized AI models, known as &quot;experts,&quot; to work together on a task. Each expert focuses on a particular subset or aspect of the problem, leveraging their expertise to contribute to the final result. It&#x27;s like having a team of experts who specialize in different areas collaborating to provide the best solution. By dividing the task and letting each expert handle their niche, the AI model can achieve better overall performance.<p>Tokens: In the context of AI and language models, tokens are chunks of text that are used as input or output. They can be individual words, characters, or even subwords, depending on how the language model is designed. For example, in the sentence &quot;I love cats,&quot; the tokens would be &quot;I,&quot; &quot;love,&quot; and &quot;cats.&quot; Tokens help the AI model understand and process language by breaking it down into manageable units. They allow the model to learn patterns, context, and relationships between words to generate meaningful responses or predictions.<p>See: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer</a></div><br/><div id="36677347" class="c"><input type="checkbox" id="c-36677347" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36676624">parent</a><span>|</span><a href="#36677629">next</a><span>|</span><label class="collapse" for="c-36677347">[-]</label><label class="expand" for="c-36677347">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>&quot;Mixture Of Experts&quot;: An &quot;MoE&quot; is an approach in AI that combines multiple specialized AI models, known as &quot;experts,&quot; (...)</i><p>Wonder when that stopped being called just an &quot;ensemble model&quot;, which is a term I recall from 10 years ago. Terminology churn?</div><br/><div id="36677948" class="c"><input type="checkbox" id="c-36677948" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36677347">parent</a><span>|</span><a href="#36677629">next</a><span>|</span><label class="collapse" for="c-36677948">[-]</label><label class="expand" for="c-36677948">[1 more]</label></div><br/><div class="children"><div class="content">Mixture of experts is different from ensembles because MoE happens at every layer as opposed to joining the models once at the end</div><br/></div></div></div></div><div id="36677629" class="c"><input type="checkbox" id="c-36677629" checked=""/><div class="controls bullet"><span class="by">dr_kiszonka</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36676624">parent</a><span>|</span><a href="#36677347">prev</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36677629">[-]</label><label class="expand" for="c-36677629">[2 more]</label></div><br/><div class="children"><div class="content">Great explanations! How about Multi-Query Attention?</div><br/><div id="36677967" class="c"><input type="checkbox" id="c-36677967" checked=""/><div class="controls bullet"><span class="by">why_only_15</span><span>|</span><a href="#36676401">root</a><span>|</span><a href="#36677629">parent</a><span>|</span><a href="#36677508">next</a><span>|</span><label class="collapse" for="c-36677967">[-]</label><label class="expand" for="c-36677967">[1 more]</label></div><br/><div class="children"><div class="content">This is the original paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.02150" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.02150</a> . The idea is that with a transformer you have many heads, say 64 for LLaMa, and for each head you have 1 &quot;query&quot; vector one &quot;key&quot; vector and one &quot;value&quot; vector per token. Most of the cost of inferencing models is loading the key and value vectors from GPU memory to the GPU itself. the idea behind MQA is that instead of having 64 queries, 64 keys, and 64 values, you have 64 queries, 1 key, and 1 value (&quot;Multi-Query&quot; as opposed to &quot;Multi-Head&quot;, the original name). This means that there is much less data to load from GPU memory to the GPU during inference.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36677508" class="c"><input type="checkbox" id="c-36677508" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#36676401">prev</a><span>|</span><a href="#36676289">next</a><span>|</span><label class="collapse" for="c-36677508">[-]</label><label class="expand" for="c-36677508">[1 more]</label></div><br/><div class="children"><div class="content">Bard taking notes…</div><br/></div></div><div id="36676472" class="c"><input type="checkbox" id="c-36676472" checked=""/><div class="controls bullet"><span class="by">RC_ITR</span><span>|</span><a href="#36676289">prev</a><span>|</span><a href="#36676310">next</a><span>|</span><label class="collapse" for="c-36676472">[-]</label><label class="expand" for="c-36676472">[4 more]</label></div><br/><div class="children"><div class="content">For all the &#x27;I know every number&#x27; certainty of this post, there&#x27;s some weird stuff:<p>&gt;(Today, the pre-training could be done with ~8,192 H100 in ~55 days for $21.5 million at $2 per H100 hour.)<p>Why flex both system size <i>and</i> training time to arbitrary numbers?<p>&gt;For example, MoE is incredibly difficult to deal with on inference because not every part of the model is utilized on every token generation. 
This means parts may sit dormant when other parts are being used. When serving users, this really hurts utilization rates.<p>Utilization of what? Memory?  If you&#x27;re that worried about inference utilization, then why not just fire up a non-MOE model?<p>Here&#x27;s what the post said about MQA:<p>&gt;Because of that only 1 head is needed and memory capacity can be significantly reduced for the KV cache<p>This is close but wrong.  You only need one <i>Key and Value (KV)</i> head, but you still have the same amount of query heads.<p>My guess is that this is all a relatively knowledgeable person, using formulas laid out by the 2020 scaling paper and making a fantasy system (with the correct math), based on that.<p>Put differently, I could probably fake my way through a similar post and be an equal level of close but definitely wrong because I&#x27;m way out of my league. That vibe makes me very suspicious.</div><br/><div id="36677639" class="c"><input type="checkbox" id="c-36677639" checked=""/><div class="controls bullet"><span class="by">moconnor</span><span>|</span><a href="#36676472">parent</a><span>|</span><a href="#36676568">next</a><span>|</span><label class="collapse" for="c-36677639">[-]</label><label class="expand" for="c-36677639">[2 more]</label></div><br/><div class="children"><div class="content">No, the post is correct about MQA. A KV-cache only caches the key and value heads. The point of MQA is that your KV-cache is 1&#x2F;heads smaller than usual because of this sharing.<p>Having multiple query heads does not affect the cache size, which is the limiting factor in MHA decoding for both memory capacity and bandwidth reasons.</div><br/><div id="36677711" class="c"><input type="checkbox" id="c-36677711" checked=""/><div class="controls bullet"><span class="by">RC_ITR</span><span>|</span><a href="#36676472">root</a><span>|</span><a href="#36677639">parent</a><span>|</span><a href="#36676568">next</a><span>|</span><label class="collapse" for="c-36677711">[-]</label><label class="expand" for="c-36677711">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Autoregressive decoder inference is a severe bottleneck for Transformer models due to the memory bandwidth overhead from loading decoder weights and all attention keys and values at every decoding step (Shazeer, 2019; Pope et al., 2022; de Jong et al., 2022). The memory bandwidth from loading keys and values can be sharply reduced through multi-query attention (Shazeer, 2019), <i>which uses
multiple query heads</i> but single key and value heads.<p>Emphasis mine, source here [0]<p>[0] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.13245.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.13245.pdf</a><p>FWIW the original MQA paper is called One <i>Write</i> head is all you need.<p>Here&#x27;s the quote from that referencing multiple heads [1]<p>&gt;We propose a variant called multi-query attention, where
the keys and values are shared across all of the different attention &quot;heads&quot;, greatly reducing the size of
these tensors and hence the memory bandwidth requirements of incremental decoding. We verify experimentally that the resulting models can indeed be much faster to decode, and incur only minor quality degradation from the baseline.<p>[1]<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1911.02150.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1911.02150.pdf</a></div><br/></div></div></div></div></div></div><div id="36676310" class="c"><input type="checkbox" id="c-36676310" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36676472">prev</a><span>|</span><a href="#36676575">next</a><span>|</span><label class="collapse" for="c-36676310">[-]</label><label class="expand" for="c-36676310">[6 more]</label></div><br/><div class="children"><div class="content">No, this is fake, a light dusting of nothing on top of a meme post that was circulating in grifting communities as early as Q4 2022. It gains a little bit in every retelling, sort of impressive to see its almost blog scale.</div><br/><div id="36676347" class="c"><input type="checkbox" id="c-36676347" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36676310">parent</a><span>|</span><a href="#36676327">next</a><span>|</span><label class="collapse" for="c-36676347">[-]</label><label class="expand" for="c-36676347">[4 more]</label></div><br/><div class="children"><div class="content">No, a meme post from 2022 did not in fact reference papers posted in 2023.<p>You must be thinking of some other post, or you&#x27;re just making stuff up.</div><br/><div id="36676544" class="c"><input type="checkbox" id="c-36676544" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36676310">root</a><span>|</span><a href="#36676347">parent</a><span>|</span><a href="#36676327">next</a><span>|</span><label class="collapse" for="c-36676544">[-]</label><label class="expand" for="c-36676544">[3 more]</label></div><br/><div class="children"><div class="content">Like I said, it gains a little bit in every retelling. Why are you aggressively defending unsourced tripe?</div><br/><div id="36676959" class="c"><input type="checkbox" id="c-36676959" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36676310">root</a><span>|</span><a href="#36676544">parent</a><span>|</span><a href="#36676327">next</a><span>|</span><label class="collapse" for="c-36676959">[-]</label><label class="expand" for="c-36676959">[2 more]</label></div><br/><div class="children"><div class="content">well as someone out of the loop - is there a source on the Q4 2022 version then?</div><br/><div id="36677463" class="c"><input type="checkbox" id="c-36677463" checked=""/><div class="controls bullet"><span class="by">ompto</span><span>|</span><a href="#36676310">root</a><span>|</span><a href="#36676959">parent</a><span>|</span><a href="#36676327">next</a><span>|</span><label class="collapse" for="c-36677463">[-]</label><label class="expand" for="c-36677463">[1 more]</label></div><br/><div class="children"><div class="content">Not sure about the Q4 2022 version but there was a post [1] a month ago that also claimed something like 16 MOE that got a lot of attention, and some similar-ish rumors before too with less detail.<p>So could be either more detail leaking over time or just a random made up post that took root a long time ago continually being retold with slightly more guesstimated detail added own each time to make the poster sound like they&#x27;re in the know.<p>Impossible to tell until the actual details are confirmed I guess.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36413296">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36413296</a></div><br/></div></div></div></div></div></div></div></div><div id="36676327" class="c"><input type="checkbox" id="c-36676327" checked=""/><div class="controls bullet"><span class="by">tills13</span><span>|</span><a href="#36676310">parent</a><span>|</span><a href="#36676347">prev</a><span>|</span><a href="#36676575">next</a><span>|</span><label class="collapse" for="c-36676327">[-]</label><label class="expand" for="c-36676327">[1 more]</label></div><br/><div class="children"><div class="content">That explains why an ad when I tried to click through to the tweet.</div><br/></div></div></div></div><div id="36676688" class="c"><input type="checkbox" id="c-36676688" checked=""/><div class="controls bullet"><span class="by">esaym</span><span>|</span><a href="#36676575">prev</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36676688">[-]</label><label class="expand" for="c-36676688">[9 more]</label></div><br/><div class="children"><div class="content">Everyone hates on crypto because of all the electricity use for mining. But how much electricity is the training of all the giant LLMs costing us?</div><br/><div id="36676697" class="c"><input type="checkbox" id="c-36676697" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36676688">parent</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36676697">[-]</label><label class="expand" for="c-36676697">[8 more]</label></div><br/><div class="children"><div class="content">LLMs actually have tangible use (granted far from bespoke yet). Crypto mining has no tangible benefit.</div><br/><div id="36677057" class="c"><input type="checkbox" id="c-36677057" checked=""/><div class="controls bullet"><span class="by">drak0n1c</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676697">parent</a><span>|</span><a href="#36676729">next</a><span>|</span><label class="collapse" for="c-36677057">[-]</label><label class="expand" for="c-36677057">[1 more]</label></div><br/><div class="children"><div class="content">Not tangible, but there will always be a theoretical and idealistic appeal for decentralized app&#x2F;game&#x2F;protocol hosting and governance. Corporate bodies like OpenAI, Twitter, YouTube, Blizzard Entertainment have made unpopular changes to popular services they own in a centralized fashion. What if LLMs, social media, and MMOs were both open source and hosted and controlled by their users, not just the whims of a single IP owner?<p>It seems that much like running a co-op or commune the barrier is whether enough people care to take up the fraction of effort and cost it takes to join such an arrangement.</div><br/></div></div><div id="36676729" class="c"><input type="checkbox" id="c-36676729" checked=""/><div class="controls bullet"><span class="by">dorkwood</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676697">parent</a><span>|</span><a href="#36677057">prev</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36676729">[-]</label><label class="expand" for="c-36676729">[6 more]</label></div><br/><div class="children"><div class="content">To be fair, it’s still early for crypto. The best use cases of the technology are yet to emerge.</div><br/><div id="36676802" class="c"><input type="checkbox" id="c-36676802" checked=""/><div class="controls bullet"><span class="by">keeler</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676729">parent</a><span>|</span><a href="#36676764">next</a><span>|</span><label class="collapse" for="c-36676802">[-]</label><label class="expand" for="c-36676802">[2 more]</label></div><br/><div class="children"><div class="content">Crypto enthusiasts have been saying that for the past 14 years.</div><br/></div></div><div id="36676764" class="c"><input type="checkbox" id="c-36676764" checked=""/><div class="controls bullet"><span class="by">anaganisk</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676729">parent</a><span>|</span><a href="#36676802">prev</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36676764">[-]</label><label class="expand" for="c-36676764">[3 more]</label></div><br/><div class="children"><div class="content">Since 12 years?</div><br/><div id="36676817" class="c"><input type="checkbox" id="c-36676817" checked=""/><div class="controls bullet"><span class="by">yosame</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676764">parent</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36676817">[-]</label><label class="expand" for="c-36676817">[2 more]</label></div><br/><div class="children"><div class="content">Surely they&#x27;ll find a use case before the sun burns out!</div><br/><div id="36677364" class="c"><input type="checkbox" id="c-36677364" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36676688">root</a><span>|</span><a href="#36676817">parent</a><span>|</span><a href="#36676535">next</a><span>|</span><label class="collapse" for="c-36677364">[-]</label><label class="expand" for="c-36677364">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s quite uncertain, given that Bitcoin is couple scaling rounds from literally sucking the sun dry to power the &quot;proof of work&quot; scheme.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36676535" class="c"><input type="checkbox" id="c-36676535" checked=""/><div class="controls bullet"><span class="by">abrax3141</span><span>|</span><a href="#36676688">prev</a><span>|</span><label class="collapse" for="c-36676535">[-]</label><label class="expand" for="c-36676535">[15 more]</label></div><br/><div class="children"><div class="content">If it was trained on CS textbooks, they weren&#x27;t very good ones. I asked it (GPT4) to write a quantum computer algorithm to square a number. It very confidently told me that to simplify the problem it would use two bits. Okay, fine. But then the algorithm it (again confidently) implemented did a left shift (which it reminded me was multiplying by 2, so it definitely intended this!) and then add the number to itself. It then wrote that in terms of QC gates. Tada! It took me a half beat to realize that rather than this being some new version of squaring a number that I somehow wasn&#x27;t aware of, it&#x27;s completely wrong. It only works on 00! Confronted, of course it did the usual &quot;So sorry... I guess I don&#x27;t know how to do this.&quot; dance. I don&#x27;t get why anyone thinks that this thing is worth anything at all, except for cheating on creative writing tests.</div><br/><div id="36676560" class="c"><input type="checkbox" id="c-36676560" checked=""/><div class="controls bullet"><span class="by">wastewastewaste</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36677749">next</a><span>|</span><label class="collapse" for="c-36676560">[-]</label><label class="expand" for="c-36676560">[1 more]</label></div><br/><div class="children"><div class="content">Damn so you tried once to use it for a thing and it failed? That&#x27;s crazy, truly a mystery then why so many devs continue to use it daily.</div><br/></div></div><div id="36677749" class="c"><input type="checkbox" id="c-36677749" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36676560">prev</a><span>|</span><a href="#36676618">next</a><span>|</span><label class="collapse" for="c-36677749">[-]</label><label class="expand" for="c-36677749">[1 more]</label></div><br/><div class="children"><div class="content">1. I asked my child how to write a quantum computer algorithm to square a number and they didn&#x27;t know.  It&#x27;s amazing that anyone thinks children are worth anything at all.  I immediately sold mine to be harvested for organs and I suggest everyone else do the same.<p>2. I looked in The Art of Computer Programming for a quantum computer algorithm to square a number and it didn&#x27;t have one. If it&#x27;s a CS textbook it obviously isn&#x27;t a very good one.  In fact it&#x27;s amazing that anyone thinks Knuth is worth anything at all. I immediately threw my copies in the recycling.<p>In fact you can divide everything into the set of things which know how to square a number on a quantum computer (let&#x27;s call that the set of <i>valuable things</i>) and everything else.  Everything else can be discarded.</div><br/></div></div><div id="36676618" class="c"><input type="checkbox" id="c-36676618" checked=""/><div class="controls bullet"><span class="by">tlb</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36677749">prev</a><span>|</span><a href="#36676580">next</a><span>|</span><label class="collapse" for="c-36676618">[-]</label><label class="expand" for="c-36676618">[4 more]</label></div><br/><div class="children"><div class="content">What percentile rank among college-educated Americans would that correspond to?<p>I&#x27;d guess that takes it out of the top 0.1%, but not the top 1%.</div><br/><div id="36676725" class="c"><input type="checkbox" id="c-36676725" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676618">parent</a><span>|</span><a href="#36676580">next</a><span>|</span><label class="collapse" for="c-36676725">[-]</label><label class="expand" for="c-36676725">[3 more]</label></div><br/><div class="children"><div class="content">Call it 100 million college-educated Americans. I don’t think 100,000 people can formulate working quantum computing algorithms in ten seconds. It is probably closer to 0.001%, but those people probably can’t describe 13th century medical technology very well.</div><br/><div id="36677389" class="c"><input type="checkbox" id="c-36677389" checked=""/><div class="controls bullet"><span class="by">agos</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676725">parent</a><span>|</span><a href="#36676916">next</a><span>|</span><label class="collapse" for="c-36677389">[-]</label><label class="expand" for="c-36677389">[1 more]</label></div><br/><div class="children"><div class="content">the tricky part is that the rest of that million college-educated folks would answer &quot;I don&#x27;t know&quot;, something LLMs really struggle at</div><br/></div></div><div id="36676916" class="c"><input type="checkbox" id="c-36676916" checked=""/><div class="controls bullet"><span class="by">seanthemon</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676725">parent</a><span>|</span><a href="#36677389">prev</a><span>|</span><a href="#36676580">next</a><span>|</span><label class="collapse" for="c-36676916">[-]</label><label class="expand" for="c-36676916">[1 more]</label></div><br/><div class="children"><div class="content">Surprisingly you need to be quite adept at 14th century medicine in order to write quantum algorithms</div><br/></div></div></div></div></div></div><div id="36676580" class="c"><input type="checkbox" id="c-36676580" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36676618">prev</a><span>|</span><a href="#36676591">next</a><span>|</span><label class="collapse" for="c-36676580">[-]</label><label class="expand" for="c-36676580">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you don&#x27;t know how to use it effectively is all I can see from your post.</div><br/></div></div><div id="36676591" class="c"><input type="checkbox" id="c-36676591" checked=""/><div class="controls bullet"><span class="by">mindwok</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36676580">prev</a><span>|</span><a href="#36676735">next</a><span>|</span><label class="collapse" for="c-36676591">[-]</label><label class="expand" for="c-36676591">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s arguably the first useful general purpose AI. Claiming it is not worth anything at all because it can&#x27;t solve a problem that 99.999% of humans would not be able to solve is a pretty ridiculous definition of &#x27;worth&#x27;.</div><br/><div id="36676694" class="c"><input type="checkbox" id="c-36676694" checked=""/><div class="controls bullet"><span class="by">Al0neStar</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676591">parent</a><span>|</span><a href="#36676735">next</a><span>|</span><label class="collapse" for="c-36676694">[-]</label><label class="expand" for="c-36676694">[3 more]</label></div><br/><div class="children"><div class="content">99.999% of humans who haven&#x27;t seen the data.</div><br/><div id="36676748" class="c"><input type="checkbox" id="c-36676748" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676694">parent</a><span>|</span><a href="#36676735">next</a><span>|</span><label class="collapse" for="c-36676748">[-]</label><label class="expand" for="c-36676748">[2 more]</label></div><br/><div class="children"><div class="content">If you had just spent 90 days observing the equivalent of millions of books what are the odds you could recall even one thing from each of them.</div><br/><div id="36677155" class="c"><input type="checkbox" id="c-36677155" checked=""/><div class="controls bullet"><span class="by">Al0neStar</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676748">parent</a><span>|</span><a href="#36676735">next</a><span>|</span><label class="collapse" for="c-36677155">[-]</label><label class="expand" for="c-36677155">[1 more]</label></div><br/><div class="children"><div class="content">Zero.</div><br/></div></div></div></div></div></div></div></div><div id="36676735" class="c"><input type="checkbox" id="c-36676735" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#36676535">parent</a><span>|</span><a href="#36676591">prev</a><span>|</span><label class="collapse" for="c-36676735">[-]</label><label class="expand" for="c-36676735">[3 more]</label></div><br/><div class="children"><div class="content">I must be getting old, because GPT-4 is basically magic compared to what has come before... and just a few months in people are happily dunking on it.</div><br/><div id="36676927" class="c"><input type="checkbox" id="c-36676927" checked=""/><div class="controls bullet"><span class="by">seanthemon</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676735">parent</a><span>|</span><a href="#36676935">next</a><span>|</span><label class="collapse" for="c-36676927">[-]</label><label class="expand" for="c-36676927">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an ego problem imo, some folks have a co-dependency problem with being &quot;smart&quot; and now GenAi took away their trophy</div><br/></div></div><div id="36676935" class="c"><input type="checkbox" id="c-36676935" checked=""/><div class="controls bullet"><span class="by">balls187</span><span>|</span><a href="#36676535">root</a><span>|</span><a href="#36676735">parent</a><span>|</span><a href="#36676927">prev</a><span>|</span><label class="collapse" for="c-36676935">[-]</label><label class="expand" for="c-36676935">[1 more]</label></div><br/><div class="children"><div class="content">jquery is definitely old.<p>The dunking makes sense to me—“AI is taking our Jobs” is a real concern, so pointing out how bad ChatGPT is at coding on an arguably coding social network is one way to control the narrative.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>