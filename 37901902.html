<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697533267604" as="style"/><link rel="stylesheet" href="styles.css?v=1697533267604"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/cpacker/MemGPT">MemGPT – LLMs with self-editing memory for unbounded context</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>shishirpatil</span> | <span>81 comments</span></div><br/><div><div id="37903850" class="c"><input type="checkbox" id="c-37903850" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37899268">next</a><span>|</span><label class="collapse" for="c-37903850">[-]</label><label class="expand" for="c-37903850">[1 more]</label></div><br/><div class="children"><div class="content">Hey all, MemGPT authors here! Happy to answer any questions about the implementation.<p>If you want to try it out yourself, we have a Discord bot up-and-running on the MemGPT Discord server (<a href="https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE" rel="nofollow noreferrer">https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE</a>) where you can see the memory editing in action - as you chat with the bot, you&#x27;ll see MemGPT edit its memory to update its profile about you (and itself).<p>Everything&#x27;s open source, so can also try running MemGPT locally using the code here: <a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT</a>. In the repo we also have a document-focused example where you can chat with MemGPT about the LlamaIndex API docs.</div><br/></div></div><div id="37899268" class="c"><input type="checkbox" id="c-37899268" checked=""/><div class="controls bullet"><span class="by">empath-nirvana</span><span>|</span><a href="#37903850">prev</a><span>|</span><a href="#37899487">next</a><span>|</span><label class="collapse" for="c-37899268">[-]</label><label class="expand" for="c-37899268">[5 more]</label></div><br/><div class="children"><div class="content">Is there any reason you&#x27;re just doing everything within a single context window?  I experimented with similar stuff months ago and basically parallelized everything into multiple requests to different agents in pre and post-processing steps.  The main context window, for example, wasn&#x27;t aware of memories being generated or retrieved.  I had a post-processor just automatically generating memories and saving them, along with all the conversations being saved in a vector database, and a pre-processor that would automatically inject relevant memories and context based on the conversation, even re-writing the history so it would look to the main context window like the memory had always been there.<p>It saved a lot of space in the main context window for unnecessary system prompts and so on.</div><br/><div id="37907307" class="c"><input type="checkbox" id="c-37907307" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37899268">parent</a><span>|</span><a href="#37899915">next</a><span>|</span><label class="collapse" for="c-37907307">[-]</label><label class="expand" for="c-37907307">[1 more]</label></div><br/><div class="children"><div class="content">These are all great points - who or what you ask to manage memory is a design decision and IMO there&#x27;s two main ways to do it (in the context of chatbots):<p>* implicit memory management, where the &quot;main LLM&quot; (or for chat, the &quot;dialogue thread&quot;) is unaware that memory is being managed in the background (by a &quot;memory LLM&quot;, a rule-based script, a small neural network, etc.), and<p>* explicit memory management (MemGPT), where one LLM does everything<p>Prior research in multi-session &#x2F; long-range chat is often implicit, with a designated memory creation process. If I had to guess, I&#x27;d say the vast majority of consumer chatbots that implement some type of memory store are also implicit. This is because getting explicit memory management to work requires a lot of complex instruction following, and in our experience this just isn&#x27;t possible at the moment with most publicly available LLMs (we&#x27;re actively looking into ways to fix this via eg fine-tuning open models).<p>The tradeoffs are as you mentioned: with implicit, you don&#x27;t have to stuff all the memory management instructions into the LLM preprompt (in MemGPT, the total system message is ~1k tokens). But on the upside, explicit memory management (when the LLM works) makes the overall system a lot simpler - there&#x27;s no need to manage multiple LLM models running on parallel threads, which can add a lot of overhead.</div><br/></div></div><div id="37899915" class="c"><input type="checkbox" id="c-37899915" checked=""/><div class="controls bullet"><span class="by">spaintech</span><span>|</span><a href="#37899268">parent</a><span>|</span><a href="#37907307">prev</a><span>|</span><a href="#37907238">next</a><span>|</span><label class="collapse" for="c-37899915">[-]</label><label class="expand" for="c-37899915">[1 more]</label></div><br/><div class="children"><div class="content">This is a fascinating approach. I’m working on something similar but as part of the feedback loop, as you said, rewriting history with transactional data as part of the context window. I feel as though the LLM and the NLP could potentially be a more realizable interface to structured data, well, I should say, this is the idea we are exploring. For us, as data is created (within a certain context of the business) we extract the data, generate the embeddings and build out the vector database as to:<p>Pre and Post-Processing:<p>- Post-Processing: After the main model responds, a post-processor takes over, automatically generating memories from the conversation and saving them. This ensures that important context is stored without burdening the primary model with these tasks. We also execute any relevan business logic as part of the request, then feed that back to the systems…<p>- Pre-Processing: Before a new input is sent to the main model, a pre-processor checks saved memories and injects relevant context. * executes logic *  It’s as if this pre-processor gives the main model a “refresher” on prior conversations, preparing it to provide more informed and consistent responses.</div><br/></div></div><div id="37907238" class="c"><input type="checkbox" id="c-37907238" checked=""/><div class="controls bullet"><span class="by">sabareesh</span><span>|</span><a href="#37899268">parent</a><span>|</span><a href="#37899915">prev</a><span>|</span><a href="#37900810">next</a><span>|</span><label class="collapse" for="c-37907238">[-]</label><label class="expand" for="c-37907238">[1 more]</label></div><br/><div class="children"><div class="content">Multi Agent has several potential, I am having more confidence as there is some level of entropy on agent reply that makes it a worthwhile</div><br/></div></div><div id="37900810" class="c"><input type="checkbox" id="c-37900810" checked=""/><div class="controls bullet"><span class="by">keithnoizu</span><span>|</span><a href="#37899268">parent</a><span>|</span><a href="#37907238">prev</a><span>|</span><a href="#37899487">next</a><span>|</span><label class="collapse" for="c-37900810">[-]</label><label class="expand" for="c-37900810">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I have a similar solution.</div><br/></div></div></div></div><div id="37899487" class="c"><input type="checkbox" id="c-37899487" checked=""/><div class="controls bullet"><span class="by">huevosabio</span><span>|</span><a href="#37899268">prev</a><span>|</span><a href="#37905802">next</a><span>|</span><label class="collapse" for="c-37899487">[-]</label><label class="expand" for="c-37899487">[3 more]</label></div><br/><div class="children"><div class="content">Good job!<p>On the limitations you wrote:
```
 Similarly, we also found that the most popular the Llama 2 70B model variants (even those
fine-tuned for function calling) would consistently generate incorrect function calls or even hallucinate functions outside the providede schema.
```<p>You could use grammar-based sampling [0] to ensure that the function call is at least syntactically correct.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;tree&#x2F;master&#x2F;grammars">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;tree&#x2F;master&#x2F;grammars</a></div><br/><div id="37907054" class="c"><input type="checkbox" id="c-37907054" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37899487">parent</a><span>|</span><a href="#37905802">next</a><span>|</span><label class="collapse" for="c-37907054">[-]</label><label class="expand" for="c-37907054">[2 more]</label></div><br/><div class="children"><div class="content">Grammar-based sampling is a great idea and a perfect fit for something like MemGPT! In our experiments using MemGPT with non-gpt-4 models, the biggest issue impacting performance ended up being incorrect use of function parameters and function hallucination. For example, even large models finetuned on function call data (eg <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;jondurbin&#x2F;airoboros-l2-70b-2.1#agentfunction-calling" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;jondurbin&#x2F;airoboros-l2-70b-2.1#agentf...</a>) would generally output correct parsable JSON, but the arguments or function name would be wrong. For example the LLM might output a call to `personal_diary.add` (never specified in the preprompt) instead of the correct `working_context.append` call (explicitly specified in the preprompt) when trying to write data.</div><br/><div id="37912213" class="c"><input type="checkbox" id="c-37912213" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#37899487">root</a><span>|</span><a href="#37907054">parent</a><span>|</span><a href="#37905802">next</a><span>|</span><label class="collapse" for="c-37912213">[-]</label><label class="expand" for="c-37912213">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see why you&#x27;d need to stop at &quot;grammar&quot;.  If you have something like intellisense that can tell you all legal completions (eg. list of member functions of the class of the last-referenced object) then you could use the same approach to limit sampling to function names that actually exist.</div><br/></div></div></div></div></div></div><div id="37905802" class="c"><input type="checkbox" id="c-37905802" checked=""/><div class="controls bullet"><span class="by">KhoomeiK</span><span>|</span><a href="#37899487">prev</a><span>|</span><a href="#37902923">next</a><span>|</span><label class="collapse" for="c-37905802">[-]</label><label class="expand" for="c-37905802">[2 more]</label></div><br/><div class="children"><div class="content">The title made me think this was an approach that used memory editing techniques (e.g. ROME [1]) to allow an LLM&#x27;s neural memory (not just its context) to change over the course of conversation. Pretty happy to realize that this is just a fancy RAG work—will be building my version of MemEditGPT soon.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.05262" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.05262</a></div><br/><div id="37906294" class="c"><input type="checkbox" id="c-37906294" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37905802">parent</a><span>|</span><a href="#37902923">next</a><span>|</span><label class="collapse" for="c-37906294">[-]</label><label class="expand" for="c-37906294">[1 more]</label></div><br/><div class="children"><div class="content">Awesome, feel free to open issues or PRs to our repo if you want to contribute! It&#x27;s all open source and under Apache 2.0, and we&#x27;re actively looking at integrating common workflows to the CLI.<p>You&#x27;re correct that MemGPT doesn&#x27;t do editing of LLM weights like in ROME - the &quot;memory&quot; we&#x27;re considering in MemGPT is at the text&#x2F;token level, not the weight level. The core concepts behind MemGPT is giving the LLM the ability to edit a working memory scratchpad (held in-context) and reading&#x2F;writing to external context via functions. An important detail is that reads are always paginated (chunked) to deal with finite context limits, and MemGPT can do many iterative read&#x2F;writes from a single user input (by chaining functions together). This allows MemGPT to search over a large database of documents for example, collecting information from various sources to return an answer (as in our LlamaIndex API docs example on the README).</div><br/></div></div></div></div><div id="37902923" class="c"><input type="checkbox" id="c-37902923" checked=""/><div class="controls bullet"><span class="by">Difwif</span><span>|</span><a href="#37905802">prev</a><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37902923">[-]</label><label class="expand" for="c-37902923">[20 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had a suspicion for a while now that this is what ChatGPT does within a conversation (chat.openai.com, not the api). I&#x27;ve had very long chat histories that seem to gracefully degrade instead of just forgetting everything. Maybe there&#x27;s more clues in the context than I realize though.<p>Either way this type of idea will probably be a fundamental feature for all chat bots in the future IMO.</div><br/><div id="37904084" class="c"><input type="checkbox" id="c-37904084" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37903717">next</a><span>|</span><label class="collapse" for="c-37904084">[-]</label><label class="expand" for="c-37904084">[4 more]</label></div><br/><div class="children"><div class="content">Recursive summarization is a simple and popular way to provide the illusion of infinite context (when you need to free up space, just summarize the oldest N messages into 1 summary message). It&#x27;s lossy and you&#x27;ll inevitably lose important information, but it should degrade relatively gracefully. In MemGPT we use (implicit) recursive summarization on top of all the explicit memory management.</div><br/><div id="37904457" class="c"><input type="checkbox" id="c-37904457" checked=""/><div class="controls bullet"><span class="by">ASalazarMX</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37904084">parent</a><span>|</span><a href="#37906366">next</a><span>|</span><label class="collapse" for="c-37904457">[-]</label><label class="expand" for="c-37904457">[2 more]</label></div><br/><div class="children"><div class="content">Would this be the same method used to assign a title to your chat based on the first prompt? It&#x27;s surprisingly effective at getting the core idea most of the time.</div><br/><div id="37904680" class="c"><input type="checkbox" id="c-37904680" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37904457">parent</a><span>|</span><a href="#37906366">next</a><span>|</span><label class="collapse" for="c-37904680">[-]</label><label class="expand" for="c-37904680">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for your interest! Question - does the title of the chat ever change after it&#x27;s first assigned? If so, using a recursive summary to refresh the title sounds like a reasonable idea (especially if you&#x27;re already computing a summary to extend context).<p>From what I remember the title in ChatGPT gets set once after a few messages, in which case I&#x27;d assume it&#x27;s generated with a special &quot;title generation&quot; prompt (that gets the first few messages as input).<p>In either case since I don&#x27;t work at OpenAI I can&#x27;t tell you for sure ;)</div><br/></div></div></div></div><div id="37906366" class="c"><input type="checkbox" id="c-37906366" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37904084">parent</a><span>|</span><a href="#37904457">prev</a><span>|</span><a href="#37903717">next</a><span>|</span><label class="collapse" for="c-37906366">[-]</label><label class="expand" for="c-37906366">[1 more]</label></div><br/><div class="children"><div class="content">This is how we do things at our work with the API and chunking since we don&#x27;t have the 32k API. It works fairly well in limited windows.</div><br/></div></div></div></div><div id="37903717" class="c"><input type="checkbox" id="c-37903717" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37904084">prev</a><span>|</span><a href="#37904081">next</a><span>|</span><label class="collapse" for="c-37903717">[-]</label><label class="expand" for="c-37903717">[1 more]</label></div><br/><div class="children"><div class="content">There are definitely a lot more clues than you realize (plus the context window is something like 12 written pages of standard English text, without much space wasted for the system prompts). If you were doing anything interesting at all, the output is heavily biased by your prompt. You lose some bits of information in that you only have one sample (the previous output&#x2F;history) rather than the soft probabilities, and you lose some bits in that multiple inputs can map to the same output (like the class of prompts &quot;output the 2nd letter of the following phrase: ...&quot;), but real-world prompts tend to be the easiest&#x2F;shortest thing to come to mind that you think will give you the result you&#x27;re looking for, so the LLM&#x27;s best guess for that prompt (there are lots of ways of guessing, so suppose for the sake of argument you did something like textual inversion on the one sample) is likely to not be a half-bad interpretation of the missing context -- i.e., a lot of the seemingly missing information was retained in the LLM&#x27;s output, and you don&#x27;t lose too many bits at a time as the old context trails off.</div><br/></div></div><div id="37904081" class="c"><input type="checkbox" id="c-37904081" checked=""/><div class="controls bullet"><span class="by">shishirpatil</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37903717">prev</a><span>|</span><a href="#37906377">next</a><span>|</span><label class="collapse" for="c-37904081">[-]</label><label class="expand" for="c-37904081">[1 more]</label></div><br/><div class="children"><div class="content">Yeah! While it’s not known what close-sourced models do, what we think is happening based on some prompt attacks, is that  they also use recursive summarization (in addition to what others have mentioned in this thread).</div><br/></div></div><div id="37906377" class="c"><input type="checkbox" id="c-37906377" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37904081">prev</a><span>|</span><a href="#37903283">next</a><span>|</span><label class="collapse" for="c-37906377">[-]</label><label class="expand" for="c-37906377">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still very much learning this stuff, but I wonder if that&#x27;s related to the vanishing gradient problem, which seems to be a fundamental aspect of these types of approaches.  (Please don&#x27;t assume that&#x27;s correct)<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vanishing_gradient_problem" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vanishing_gradient_problem</a></div><br/><div id="37907145" class="c"><input type="checkbox" id="c-37907145" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37906377">parent</a><span>|</span><a href="#37907806">next</a><span>|</span><label class="collapse" for="c-37907145">[-]</label><label class="expand" for="c-37907145">[5 more]</label></div><br/><div class="children"><div class="content">Vanishing gradient was an issue for non-residual deep networks and vanilla RNNs. While the long context memory issues are along sequence dimension, not network depth.<p>The problem could be some kind of instability of attention as it scales above 10k tokens. A recent paper suggests attention mechanism needs a default value (a &quot;sink&quot;), and its absence produces instability.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.17453" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.17453</a><p>Another paper says the middle part is lossy while the beginning and end are better attended.</div><br/><div id="37908727" class="c"><input type="checkbox" id="c-37908727" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37907145">parent</a><span>|</span><a href="#37907477">next</a><span>|</span><label class="collapse" for="c-37908727">[-]</label><label class="expand" for="c-37908727">[1 more]</label></div><br/><div class="children"><div class="content">For anyone who&#x27;s curious, the paper in question, entitled, &quot;Lost in the Middle: How Language Models Use Long Contexts&quot; (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.03172" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.03172</a>)</div><br/></div></div><div id="37907477" class="c"><input type="checkbox" id="c-37907477" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37907145">parent</a><span>|</span><a href="#37908727">prev</a><span>|</span><a href="#37907806">next</a><span>|</span><label class="collapse" for="c-37907477">[-]</label><label class="expand" for="c-37907477">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a really recent paper. Do you actually keep up to date with everything? How do you find the time?</div><br/><div id="37910532" class="c"><input type="checkbox" id="c-37910532" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37907477">parent</a><span>|</span><a href="#37909829">next</a><span>|</span><label class="collapse" for="c-37910532">[-]</label><label class="expand" for="c-37910532">[1 more]</label></div><br/><div class="children"><div class="content">Just reading a couple papers every day, the most interesting ones, and following up on reddit and twitter to get notified what people are talking about. And I am directly interested in long-context LLMs for a work related task.<p>I have also been dabbling with neural nets (pre-transformer), especially LSTM which have a &quot;residual&quot; connection, the one I was mentioning. That makes gradients better behaved. Schmidhuber tech.</div><br/></div></div><div id="37909829" class="c"><input type="checkbox" id="c-37909829" checked=""/><div class="controls bullet"><span class="by">totoglazer</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37907477">parent</a><span>|</span><a href="#37910532">prev</a><span>|</span><a href="#37907806">next</a><span>|</span><label class="collapse" for="c-37909829">[-]</label><label class="expand" for="c-37909829">[1 more]</label></div><br/><div class="children"><div class="content">Not to denigrate the person you’re responding to, but to add some context: That paper got a decent amount of attention already. Probably one of the more notable in the literature over the last month. Plus compared to the past year everything is slow now.</div><br/></div></div></div></div></div></div><div id="37907806" class="c"><input type="checkbox" id="c-37907806" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37906377">parent</a><span>|</span><a href="#37907145">prev</a><span>|</span><a href="#37903283">next</a><span>|</span><label class="collapse" for="c-37907806">[-]</label><label class="expand" for="c-37907806">[2 more]</label></div><br/><div class="children"><div class="content">Regarding the vanishing gradient problem, has anyone tried to train using only a randomly chosen set of independent parameters in each iteration? (Updating only the weights in a small random independent set).</div><br/><div id="37911448" class="c"><input type="checkbox" id="c-37911448" checked=""/><div class="controls bullet"><span class="by">jdthedisciple</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37907806">parent</a><span>|</span><a href="#37903283">next</a><span>|</span><label class="collapse" for="c-37911448">[-]</label><label class="expand" for="c-37911448">[1 more]</label></div><br/><div class="children"><div class="content">Are you referring to Regularization?<p><a href="https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;sid321axn&#x2F;regularization-techniques-in-deep-learning" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;sid321axn&#x2F;regularization-techniq...</a></div><br/></div></div></div></div></div></div><div id="37903283" class="c"><input type="checkbox" id="c-37903283" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37906377">prev</a><span>|</span><a href="#37903074">next</a><span>|</span><label class="collapse" for="c-37903283">[-]</label><label class="expand" for="c-37903283">[1 more]</label></div><br/><div class="children"><div class="content">To me it just feels like they’re trimming the min amount of oldest tokens in the conversation to stay under the token limit. Conversations don’t degrade in a way that feels like it has medium term memory.</div><br/></div></div><div id="37903074" class="c"><input type="checkbox" id="c-37903074" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#37902923">parent</a><span>|</span><a href="#37903283">prev</a><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37903074">[-]</label><label class="expand" for="c-37903074">[4 more]</label></div><br/><div class="children"><div class="content">ChatGPT degrades precisely because they aren&#x27;t doing anything special to extend their memory beyond the context length.<p>There are trivial techniques to implement &quot;lossy&quot; memory, such as just average pooling tokens (the same approach used by sentence transformers). Not sure why it&#x27;s so rare to see this used for condensing a huge amount of context into a prompt. It is effectively &quot;medium&quot; term memory.</div><br/><div id="37906686" class="c"><input type="checkbox" id="c-37906686" checked=""/><div class="controls bullet"><span class="by">lgats</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37903074">parent</a><span>|</span><a href="#37904722">next</a><span>|</span><label class="collapse" for="c-37906686">[-]</label><label class="expand" for="c-37906686">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;e367a1de-c28b-4408-aa3d-2e4b85ea08b4" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;e367a1de-c28b-4408-aa3d-2e4b85...</a><p>Fed chatGPT special numbers, then 3k tokens, then 2k tokens.
after that, it was unable to understand any question about the special numbers provided.</div><br/><div id="37908258" class="c"><input type="checkbox" id="c-37908258" checked=""/><div class="controls bullet"><span class="by">sharkjacobs</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37906686">parent</a><span>|</span><a href="#37904722">next</a><span>|</span><label class="collapse" for="c-37908258">[-]</label><label class="expand" for="c-37908258">[1 more]</label></div><br/><div class="children"><div class="content">On the other hand<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;8a0675b6-2876-4606-ac79-646391dce370" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;8a0675b6-2876-4606-ac79-646391...</a></div><br/></div></div></div></div><div id="37904722" class="c"><input type="checkbox" id="c-37904722" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37902923">root</a><span>|</span><a href="#37903074">parent</a><span>|</span><a href="#37906686">prev</a><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37904722">[-]</label><label class="expand" for="c-37904722">[1 more]</label></div><br/><div class="children"><div class="content">At the very least I would average vectors inside single words or word compounds getting a 2-3x reduction in length without much work.</div><br/></div></div></div></div></div></div><div id="37895685" class="c"><input type="checkbox" id="c-37895685" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#37902923">prev</a><span>|</span><a href="#37897120">next</a><span>|</span><label class="collapse" for="c-37895685">[-]</label><label class="expand" for="c-37895685">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t remember the name, but there&#x27;s already an Esolang that executes its commands unreliably. Through careful program design, you can ensure that a <i>sequence</i> of commands will execute with 99%, 99.9%, etc. reliability.</div><br/><div id="37896892" class="c"><input type="checkbox" id="c-37896892" checked=""/><div class="controls bullet"><span class="by">Aeolos</span><span>|</span><a href="#37895685">parent</a><span>|</span><a href="#37908633">next</a><span>|</span><label class="collapse" for="c-37896892">[-]</label><label class="expand" for="c-37896892">[3 more]</label></div><br/><div class="children"><div class="content">Java2000 iirc.<p>2 decades later, the same approach was unironically popularized for infrastructure as “chaos engineering”.</div><br/><div id="37897052" class="c"><input type="checkbox" id="c-37897052" checked=""/><div class="controls bullet"><span class="by">majewsky</span><span>|</span><a href="#37895685">root</a><span>|</span><a href="#37896892">parent</a><span>|</span><a href="#37908633">next</a><span>|</span><label class="collapse" for="c-37897052">[-]</label><label class="expand" for="c-37897052">[2 more]</label></div><br/><div class="children"><div class="content">Not sure if that was &#x2F;s or not, but it is indeed an important insight to realize that no IT system can have 100% reliability once you factor in hardware failures and power outages. And that&#x27;s before we talk about bugs.</div><br/><div id="37897631" class="c"><input type="checkbox" id="c-37897631" checked=""/><div class="controls bullet"><span class="by">ansc</span><span>|</span><a href="#37895685">root</a><span>|</span><a href="#37897052">parent</a><span>|</span><a href="#37908633">next</a><span>|</span><label class="collapse" for="c-37897631">[-]</label><label class="expand" for="c-37897631">[1 more]</label></div><br/><div class="children"><div class="content">Not to even mention the heat death of the universe!</div><br/></div></div></div></div></div></div><div id="37908633" class="c"><input type="checkbox" id="c-37908633" checked=""/><div class="controls bullet"><span class="by">codezero</span><span>|</span><a href="#37895685">parent</a><span>|</span><a href="#37896892">prev</a><span>|</span><a href="#37897120">next</a><span>|</span><label class="collapse" for="c-37908633">[-]</label><label class="expand" for="c-37908633">[1 more]</label></div><br/><div class="children"><div class="content">Sounds a bit like Malbolge but not quite. <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Malbolge" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Malbolge</a></div><br/></div></div></div></div><div id="37897120" class="c"><input type="checkbox" id="c-37897120" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895685">prev</a><span>|</span><a href="#37902910">next</a><span>|</span><label class="collapse" for="c-37897120">[-]</label><label class="expand" for="c-37897120">[3 more]</label></div><br/><div class="children"><div class="content">Update - we just released a Discord perpetual chatbot implemented on top of MemGPT, you can try it here: <a href="https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE" rel="nofollow noreferrer">https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE</a><p>You can also run the chatbot demo + a doc QA bot demo (where you can ask MemGPT about API docs) locally with the code on GitHub.</div><br/><div id="37897447" class="c"><input type="checkbox" id="c-37897447" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37897120">parent</a><span>|</span><a href="#37902910">next</a><span>|</span><label class="collapse" for="c-37897447">[-]</label><label class="expand" for="c-37897447">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! How do I use the bot?</div><br/><div id="37897630" class="c"><input type="checkbox" id="c-37897630" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37897120">root</a><span>|</span><a href="#37897447">parent</a><span>|</span><a href="#37902910">next</a><span>|</span><label class="collapse" for="c-37897630">[-]</label><label class="expand" for="c-37897630">[1 more]</label></div><br/><div class="children"><div class="content">If you want to try the MemGPT Discord chatbot, join the Discord server (linked above), then check out the #memgpt channel to start messaging the bot.<p>If you want to run the chatbot or API docs examples locally, you can follow the instructions here: <a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT&#x2F;tree&#x2F;main#quick-setup">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT&#x2F;tree&#x2F;main#quick-setup</a>.</div><br/></div></div></div></div></div></div><div id="37902910" class="c"><input type="checkbox" id="c-37902910" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#37897120">prev</a><span>|</span><a href="#37903892">next</a><span>|</span><label class="collapse" for="c-37902910">[-]</label><label class="expand" for="c-37902910">[7 more]</label></div><br/><div class="children"><div class="content">Discussed last night: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37894403">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37894403</a><p>(Mostly arguing about the authors&#x27; choice of title)</div><br/><div id="37906914" class="c"><input type="checkbox" id="c-37906914" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37902910">parent</a><span>|</span><a href="#37902971">next</a><span>|</span><label class="collapse" for="c-37906914">[-]</label><label class="expand" for="c-37906914">[1 more]</label></div><br/><div class="children"><div class="content">OK, I&#x27;ve merged the comments from that thread which were <i>not</i> arguing about the title into this thread.</div><br/></div></div></div></div><div id="37903892" class="c"><input type="checkbox" id="c-37903892" checked=""/><div class="controls bullet"><span class="by">zerop</span><span>|</span><a href="#37902910">prev</a><span>|</span><a href="#37908204">next</a><span>|</span><label class="collapse" for="c-37903892">[-]</label><label class="expand" for="c-37903892">[2 more]</label></div><br/><div class="children"><div class="content">Context window is biggest limitation to LLMs, IMO. The great reasoning capabilities hit the context window limitation in many practical use cases.</div><br/><div id="37904064" class="c"><input type="checkbox" id="c-37904064" checked=""/><div class="controls bullet"><span class="by">shishirpatil</span><span>|</span><a href="#37903892">parent</a><span>|</span><a href="#37908204">next</a><span>|</span><label class="collapse" for="c-37904064">[-]</label><label class="expand" for="c-37904064">[1 more]</label></div><br/><div class="children"><div class="content">Yeah absolutely! And hopefully with some of the techniques we introduce here, we can think of designing perpetual chat bots!</div><br/></div></div></div></div><div id="37908204" class="c"><input type="checkbox" id="c-37908204" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#37903892">prev</a><span>|</span><a href="#37903948">next</a><span>|</span><label class="collapse" for="c-37908204">[-]</label><label class="expand" for="c-37908204">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Resursive summarization (Wu et al., 2021b) is a simple way to address overflowing context windows, however, recursive summarization is inherently lossy and eventually leads to large holes in the memory of the system.<p>Yes, it does.<p>&gt; In our experiments ... conversational context is read-only with a special eviction policy (if the queue reaches a certain size, a portion of the front is truncated or compressed via recursive summarization), and working context is writeable by the LLM processor via function calls.<p>You&#x27;re doing the same thing, and you have the same problems.<p>You&#x27;re just doing it slightly differently; in this case instead of recursively summarizing everything, you&#x27;re selectively searching the history and generating it for each request. Cool idea.<p>...but, I&#x27;m skeptical; this fundamentally relies on the assumption that the existing context consists of low entropy summarizable context, and that any query relies only on a subset of the history.<p>This might be true for, eg. chat, or &#x27;answer question about some document in this massive set of documents&#x27;.<p>...but, both of these assumptions are false in some contexts; for example, generating code, where the context is densely packed with information which is not discardable (eg. specific api definitions), and a wide context is required (ie. many api definitions).<p>It is interesting how this is structured and done, and hey, the demo is cool.<p>I&#x27;m annoyed to see these papers about summary things fail to acknowledge the fundamental limitations of the approach.</div><br/><div id="37908826" class="c"><input type="checkbox" id="c-37908826" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37908204">parent</a><span>|</span><a href="#37909603">next</a><span>|</span><label class="collapse" for="c-37908826">[-]</label><label class="expand" for="c-37908826">[3 more]</label></div><br/><div class="children"><div class="content">Thanks for checking out the paper! Just to clarify in case there was any misunderstanding, recursive summarization is just one part of the memory management in MemGPT: as you mentioned, in MemGPT the conversation queue is managed via recursive summarization, just like in prior work (and many chatbot implementations). However there is also a (read&#x2F;write) &quot;pinned&quot; section of &quot;LLM memory&quot; that&#x27;s unrelated to recursive summarization, we call this &quot;working context&quot; in the paper. So MemGPT has access to both recursive summaries (generated automatically), as well as working context, which MemGPT actively manages to keep up-to-date.<p>These are both separate from MemGPT&#x27;s external context, which is pulled into the conversation queue via function calls. In all our examples, reads from external context are uncompressed (no summarization) and paginated. MemGPT receives a system alert when the queue summarization is triggered, so if MemGPT needs to keep specific details from the conversation queue it can write it to working context before it&#x27;s erased or summarized.<p>In the conversational agent examples, working context (no summarization, and separate from the conversation queue) is used to store key facts about the user and agent to maintain consistent conversation. Because the working context is always seen by the LLM, there&#x27;s no need to retrieve it to see it. In doc QA, working context can be used to keep track of the current task&#x2F;question and progress towards that task (for complex queries, this helps MemGPT keep track of details like the previous search, previous page request, etc.).</div><br/><div id="37909525" class="c"><input type="checkbox" id="c-37909525" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#37908204">root</a><span>|</span><a href="#37908826">parent</a><span>|</span><a href="#37910412">next</a><span>|</span><label class="collapse" for="c-37909525">[-]</label><label class="expand" for="c-37909525">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Just to clarify in case there was any misunderstanding<p>I am not confused.<p>It&#x27;s good; it solves a specific set of problems with querying large datasets, the same as a vector search would.<p>...but the various memory zones you&#x27;ve created make absolutely no difference to the fundamental limitation of the LLM context length.<p>No matter how you swing it, this is just creative prompt engineering. You&#x27;re packing the context with relevant information; but, if you have too much relevant information, it won&#x27;t work.</div><br/></div></div><div id="37910412" class="c"><input type="checkbox" id="c-37910412" checked=""/><div class="controls bullet"><span class="by">majestic5762</span><span>|</span><a href="#37908204">root</a><span>|</span><a href="#37908826">parent</a><span>|</span><a href="#37909525">prev</a><span>|</span><a href="#37909603">next</a><span>|</span><label class="collapse" for="c-37910412">[-]</label><label class="expand" for="c-37910412">[1 more]</label></div><br/><div class="children"><div class="content">We took a similar approach like MemGPT (working memory: summarized conversation with eviction), but our long memory is a graph we can operate on (add&#x2F;remove&#x2F;edit nodes &amp; edges). We bring the top_k nodes and their neighbors in the working memory.</div><br/></div></div></div></div></div></div><div id="37903948" class="c"><input type="checkbox" id="c-37903948" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#37908204">prev</a><span>|</span><a href="#37903217">next</a><span>|</span><label class="collapse" for="c-37903948">[-]</label><label class="expand" for="c-37903948">[3 more]</label></div><br/><div class="children"><div class="content">Heh, I&#x27;ve been working on...a good portion of the basics that this project &#x2F; paper have tested out for the past few months as an idea (as I work more on other more material problems for my side project).<p>I have a whole document of my thoughts on this topic, and as I was reading through the paper just piece after piece of the concepts that I had documented kept coming up.<p>Glad I am not the only one thinking in this direction.</div><br/><div id="37904162" class="c"><input type="checkbox" id="c-37904162" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37903948">parent</a><span>|</span><a href="#37903217">next</a><span>|</span><label class="collapse" for="c-37904162">[-]</label><label class="expand" for="c-37904162">[2 more]</label></div><br/><div class="children"><div class="content">Happy to chat more about other ideas in this direction! There are plenty of things we tried with varying degrees of success (especially when trying to get MemGPT to work on less powerful LLMs), and we&#x27;d be interested in hearing what you observed in your own work.</div><br/><div id="37905913" class="c"><input type="checkbox" id="c-37905913" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#37903948">root</a><span>|</span><a href="#37904162">parent</a><span>|</span><a href="#37903217">next</a><span>|</span><label class="collapse" for="c-37905913">[-]</label><label class="expand" for="c-37905913">[1 more]</label></div><br/><div class="children"><div class="content">I know we&#x27;re chatting on Discord, but figured i&#x27;d leave the link to what I was working on a couple of months ago here if anyone else is interested: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;Tostino&#x2F;3f0b0887591ed06aa9f54ca2ddbd1707" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.github.com&#x2F;Tostino&#x2F;3f0b0887591ed06aa9f54ca2ddbd...</a></div><br/></div></div></div></div></div></div><div id="37903217" class="c"><input type="checkbox" id="c-37903217" checked=""/><div class="controls bullet"><span class="by">wilg</span><span>|</span><a href="#37903948">prev</a><span>|</span><a href="#37904409">next</a><span>|</span><label class="collapse" for="c-37903217">[-]</label><label class="expand" for="c-37903217">[4 more]</label></div><br/><div class="children"><div class="content">I was just suggesting something like this to a friend yesterday! (Neither of us know enough to do it or know if it&#x27;s a good idea.)<p>However, I do think the context length is one of the top improvements that would make LLMs much more useful.</div><br/><div id="37905195" class="c"><input type="checkbox" id="c-37905195" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37903217">parent</a><span>|</span><a href="#37903524">next</a><span>|</span><label class="collapse" for="c-37905195">[-]</label><label class="expand" for="c-37905195">[1 more]</label></div><br/><div class="children"><div class="content">If you have a chance try it out via the Discord bot or with the GitHub repo! Or even just check out the short demo GIFs we released (at <a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;memgpt">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;memgpt</a>) to get an idea of the MemGPT inputs&#x2F;outputs.<p>The high-level memory read&#x2F;writes are quite intuitive and you may be surprised at how closely it matches what you were suggesting to your friend.</div><br/></div></div><div id="37903524" class="c"><input type="checkbox" id="c-37903524" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#37903217">parent</a><span>|</span><a href="#37905195">prev</a><span>|</span><a href="#37904409">next</a><span>|</span><label class="collapse" for="c-37903524">[-]</label><label class="expand" for="c-37903524">[2 more]</label></div><br/><div class="children"><div class="content">Same here, it looks like the idea was pretty obvious. Glad to see it implemented  though.<p>Context length being so limited is the number one thing that rules LLM as possessing something that resemble “intelligence”, so if we this kind of unbounded context length we&#x27;re entering into a completely new universe in terms of LLM abilities.</div><br/><div id="37904129" class="c"><input type="checkbox" id="c-37904129" checked=""/><div class="controls bullet"><span class="by">shishirpatil</span><span>|</span><a href="#37903217">root</a><span>|</span><a href="#37903524">parent</a><span>|</span><a href="#37904409">next</a><span>|</span><label class="collapse" for="c-37904129">[-]</label><label class="expand" for="c-37904129">[1 more]</label></div><br/><div class="children"><div class="content">Thanks @wilg and @littlestymaar ! Yeah totally, with the benefit of hindsight, this makes total sense! Hope you find some of our codebase useful to build on top of. We are an Apache 2.0 licensed open source project and welcome contributions :)</div><br/></div></div></div></div></div></div><div id="37904409" class="c"><input type="checkbox" id="c-37904409" checked=""/><div class="controls bullet"><span class="by">sideshowb</span><span>|</span><a href="#37903217">prev</a><span>|</span><a href="#37898577">next</a><span>|</span><label class="collapse" for="c-37904409">[-]</label><label class="expand" for="c-37904409">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone else find that self editing a linear memory evokes images of the theoretical Turing machine with its infinite tape?</div><br/><div id="37906873" class="c"><input type="checkbox" id="c-37906873" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37904409">parent</a><span>|</span><a href="#37898577">next</a><span>|</span><label class="collapse" for="c-37906873">[-]</label><label class="expand" for="c-37906873">[1 more]</label></div><br/><div class="children"><div class="content">Interesting analogy! There&#x27;s no clear infinite tape equivalent in MemGPT, but you can view the virtual context loosely as a tape. Moving the head could correspond to MemGPT indexing into virtual context - if the data is in-context (inside the LLM window), it&#x27;s a direct read, but if data isn&#x27;t there (it may&#x2F;may not be stored in external context), the read requires a function call to &quot;page in&quot; the data.</div><br/></div></div></div></div><div id="37898577" class="c"><input type="checkbox" id="c-37898577" checked=""/><div class="controls bullet"><span class="by">upghost</span><span>|</span><a href="#37904409">prev</a><span>|</span><a href="#37895861">next</a><span>|</span><label class="collapse" for="c-37898577">[-]</label><label class="expand" for="c-37898577">[2 more]</label></div><br/><div class="children"><div class="content">absolutely stellar work to you and your team. Thank you for giving voice and a framework to this -- many of us having been struggling with how to do this for a long time.  You&#x27;re a total champ!</div><br/><div id="37901205" class="c"><input type="checkbox" id="c-37901205" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37898577">parent</a><span>|</span><a href="#37895861">next</a><span>|</span><label class="collapse" for="c-37901205">[-]</label><label class="expand" for="c-37901205">[1 more]</label></div><br/><div class="children"><div class="content">Thanks @upghost</div><br/></div></div></div></div><div id="37895861" class="c"><input type="checkbox" id="c-37895861" checked=""/><div class="controls bullet"><span class="by">a1j9o94</span><span>|</span><a href="#37898577">prev</a><span>|</span><a href="#37897414">next</a><span>|</span><label class="collapse" for="c-37895861">[-]</label><label class="expand" for="c-37895861">[2 more]</label></div><br/><div class="children"><div class="content">This is super interesting! I was thinking about how to approach a similar problem for a project I&#x27;m working on, and my approach is similar.<p>I am curious about the benefit of having the agent interact with the user (or doing the task) and managing its memory instead of having an observer agent that modifies the memory separately. The thought process is to let the agent use all of its tokens to focus on the task and not memory management.</div><br/><div id="37895910" class="c"><input type="checkbox" id="c-37895910" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895861">parent</a><span>|</span><a href="#37897414">next</a><span>|</span><label class="collapse" for="c-37895910">[-]</label><label class="expand" for="c-37895910">[1 more]</label></div><br/><div class="children"><div class="content">Explicit memory management (MemGPT-style) vs implicit&#x2F;external memory management is an interesting tradeoff. Like you said, adding all the instructions on how to manage memory consumes ~1k tokens (using the default prompts on our MemGPT GitHub release), which is a lot when your context window is 8k. Additionally, it requires the base LLM to be very good at instruction following; gpt-4 can do it well, but it&#x27;s much more difficult to get explicit memory management to work with gpt-3.5-turbo or llama2 70b finetunes (so to build a robust system, you may have to end up having to &quot;split&quot; the thinking out of necessity).<p>One of the main benefits of explicit memory management is simplicity - e.g., you don&#x27;t have to manage logic between a &quot;memory creation&quot; thread and a &quot;dialogue thread&quot;. The explicit approach also integrates well with the iterative paging&#x2F;retrieval for document analysis we demo in the paper&#x2F;on GitHub.</div><br/></div></div></div></div><div id="37897414" class="c"><input type="checkbox" id="c-37897414" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37895861">prev</a><span>|</span><a href="#37903602">next</a><span>|</span><label class="collapse" for="c-37897414">[-]</label><label class="expand" for="c-37897414">[2 more]</label></div><br/><div class="children"><div class="content">Been thinking about this. My naive way to do this using existing LLMs is to have a JSON the LLM can spit out when it wants to store and then then calling code shoves that in a “RAG” DB. It also has the ability to generate queries if it’s knowledge.</div><br/><div id="37897725" class="c"><input type="checkbox" id="c-37897725" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37897414">parent</a><span>|</span><a href="#37903602">next</a><span>|</span><label class="collapse" for="c-37897725">[-]</label><label class="expand" for="c-37897725">[1 more]</label></div><br/><div class="children"><div class="content">This is similar to how our external context is implemented under the hood - you might be interested in our perpetual chat bot example in the GitHub repo (<a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT</a>), the message traces in the demo GIF should give you an idea of how things work at a glance.</div><br/></div></div></div></div><div id="37903602" class="c"><input type="checkbox" id="c-37903602" checked=""/><div class="controls bullet"><span class="by">earth2mars</span><span>|</span><a href="#37897414">prev</a><span>|</span><a href="#37905321">next</a><span>|</span><label class="collapse" for="c-37903602">[-]</label><label class="expand" for="c-37903602">[1 more]</label></div><br/><div class="children"><div class="content">It would be interesting to see how does ring attention technique affect this. This maybe still valid for cost reasons, but unlimited context is like in-memory computing vs. traditional.
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.01889.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.01889.pdf</a></div><br/></div></div><div id="37905321" class="c"><input type="checkbox" id="c-37905321" checked=""/><div class="controls bullet"><span class="by">spatilfan</span><span>|</span><a href="#37903602">prev</a><span>|</span><a href="#37895836">next</a><span>|</span><label class="collapse" for="c-37905321">[-]</label><label class="expand" for="c-37905321">[1 more]</label></div><br/><div class="children"><div class="content">Super excited to see longer-lived context showing up for LLM models. The current chatbots aren&#x27;t really useful to me as long-term AI... &quot;companions&quot; ;) because they forget anything personal every 15 minutes</div><br/></div></div><div id="37895836" class="c"><input type="checkbox" id="c-37895836" checked=""/><div class="controls bullet"><span class="by">hereforcomments</span><span>|</span><a href="#37905321">prev</a><span>|</span><a href="#37904815">next</a><span>|</span><label class="collapse" for="c-37895836">[-]</label><label class="expand" for="c-37895836">[5 more]</label></div><br/><div class="children"><div class="content">There will be a Hackathon at work and with my team mate we are preparing with some kind of hierarchical memory&#x2F;knowledge solution.<p>Briefly: we tell ChatGPT what API based tools we have, explaines them in 1 sentence and where it can reach their documentation. We added documentations as endpoint. example.com&#x2F;docs&#x2F;main is always the starting point that returns high level overview of the app and all available endpoints to call. Every endpoint has its own documentation as well. E.g.: &#x2F;geocoder has &#x2F;docs&#x2F;geocoder documentation endpoint that describes what it does, what input it expects and what it will return.<p>We also provieded ChatGPT with actions like read_docs, call_endpoint and end_conversation. An action is a structured JSON object with a set of parameters. If ChatGPT wants to interact with the mentioned resources, it emits an action, it gets executed and the answer fed back to it.<p>With this I can do a task like: &quot;Get a 30 minutes drivetime polygon around 15 Bond Street, London and send it to Foster.&quot;<p>It plans and executes the following all alone. First it calls the geocoder to get the coordinates for the isochrone endpoint, then gets the isochrone by calling the isochrone 
endpoint and saves it, calls Microsoft Graph API and queries my top 50 connections to find out who Foster is and calls the MS Graph API&#x27;s send mail endpoint to send the email with attachment to Foster.<p>It can hierarchically explore the available resources so we don&#x27;t need a huge context window and we don&#x27;t have to train the model either. Also we could implement multiple agents. 1 would be a manager and there could me multiple agents to perform each task and return the results to the manager. It would furthet reduce reduce the required context window.<p>Very likely some BS app will win the Hackathon like always like a market price predictor using Weka&#x27;s multilayer perceptron with default settings but we believe our solution could be extremely powerful.</div><br/><div id="37895898" class="c"><input type="checkbox" id="c-37895898" checked=""/><div class="controls bullet"><span class="by">a1j9o94</span><span>|</span><a href="#37895836">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37895898">[-]</label><label class="expand" for="c-37895898">[3 more]</label></div><br/><div class="children"><div class="content">This is interesting. Can you expand on how this gets around the context window problem? Are you thinking the agent does a one-off task rather than continuing back and forth with the user?<p>I do think this will be way less than having all of the functions listed to begin with though. I think the discoverability is a novel approach. Honestly, I&#x27;m surprised ChatGPT with plugins doesn&#x27;t do something like this by default rather than making you pick which plugins you want at the beginning of the conversation.</div><br/><div id="37895969" class="c"><input type="checkbox" id="c-37895969" checked=""/><div class="controls bullet"><span class="by">hereforcomments</span><span>|</span><a href="#37895836">root</a><span>|</span><a href="#37895898">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37895969">[-]</label><label class="expand" for="c-37895969">[2 more]</label></div><br/><div class="children"><div class="content">First, the discoverability reduces the required context window. We don&#x27;t have to explain every app we have, it&#x27;s enough to tell ChatGPT one sentence about them and it will go deeper if it thinks that would help it to perform the task.<p>Also, we have not implemented it, we can have one or multiple level of managers just like at a company and each would delegate a task to a worker (who could also be a manager) and they would report back the result. Just like in real life, a manager doesn&#x27;t have to know how something is done, it should only know it&#x27;s done and the get the results.<p>We work for a large company and very likely have 100s of apps. We could build wrappers around them e.g. using selenium and we could interact with even old apps.<p>We could also do the same approach with databases. The db itself would have docs, each table and each field as well. So we could ask ChatGPT to query data from the db and it could fully understand the data before writing the sql query.</div><br/><div id="37896174" class="c"><input type="checkbox" id="c-37896174" checked=""/><div class="controls bullet"><span class="by">novax81</span><span>|</span><a href="#37895836">root</a><span>|</span><a href="#37895969">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37896174">[-]</label><label class="expand" for="c-37896174">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve written about some hierarchical manager system with some friends when exploring how to use AI for larger set tasks.  While the easy answer is simply using something with much larger context - `Claude` is amazing with an API key if you&#x27;re on the waitlist - we definitely followed the same idea of splitting up the context into individual groups.<p>We had some success actually with layering another AI into the mix - having one AI look at a <i>summary</i> version of the context as a whole, and decide which pieces of context to assign to each manager.  This of course requires a sidestep into another database of some kind to store the &quot;master context&quot; (AKA the full conversation, so you likely already have it in some form of storage), and of course a lot more calls to the AI which overall increases latency quite a bit.<p>1. Use an AI to provide a short summary of each piece of logical context and map it by access ID
2. Use another AI to determine which pieces contain the most useful additional context to the piece of the task being evaluated
3. Build the context from the generated ID list and pass to individual task manager AI</div><br/></div></div></div></div></div></div></div></div><div id="37904815" class="c"><input type="checkbox" id="c-37904815" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37895836">prev</a><span>|</span><label class="collapse" for="c-37904815">[-]</label><label class="expand" for="c-37904815">[5 more]</label></div><br/><div class="children"><div class="content">the link and title of this suspiciously changed. @dang</div><br/><div id="37904971" class="c"><input type="checkbox" id="c-37904971" checked=""/><div class="controls bullet"><span class="by">shishirpatil</span><span>|</span><a href="#37904815">parent</a><span>|</span><a href="#37904870">next</a><span>|</span><label class="collapse" for="c-37904971">[-]</label><label class="expand" for="c-37904971">[1 more]</label></div><br/><div class="children"><div class="content">Hey @behnamoh, maybe you are referring to the community post pre-release? It is still very much live here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37894403">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37894403</a>! 
As we released MemGPT this morning (including discord bot, and on Twitter), we took the community feedback to emphasize more on the context length in the title :) Thank you all for the feedback and keep it coming - we are listening!</div><br/></div></div><div id="37904870" class="c"><input type="checkbox" id="c-37904870" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#37904815">parent</a><span>|</span><a href="#37904971">prev</a><span>|</span><label class="collapse" for="c-37904870">[-]</label><label class="expand" for="c-37904870">[3 more]</label></div><br/><div class="children"><div class="content">It’s not suspicious, the previous title calling it an operating system was extremely incorrect and intentionally misleading to generate buzz. Aka clickbait.</div><br/></div></div></div></div></div></div></div></div></div></body></html>