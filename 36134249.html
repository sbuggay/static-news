<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685523667010" as="style"/><link rel="stylesheet" href="styles.css?v=1685523667010"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Ask HN: Is it just me or GPT-4&#x27;s quality has significantly deteriorated lately?</a> </div><div class="subtext"><span>behnamoh</span> | <span>89 comments</span></div><br/><div><div id="36136091" class="c"><input type="checkbox" id="c-36136091" checked=""/><div class="controls bullet"><span class="by">v4dok</span><span>|</span><a href="#36134620">next</a><span>|</span><label class="collapse" for="c-36136091">[-]</label><label class="expand" for="c-36136091">[1 more]</label></div><br/><div class="children"><div class="content">It became faster and worse. My definite proof is its ability to generate greek content. The early API was generating good or at least passable content. It was really on the edge of &quot;this is good&quot;. Now its completely garbage, it makes up words and even fails at basic translation, doing it literally. I think its less the RHFL and more the effort to scale it and make it faster.</div><br/></div></div><div id="36134620" class="c"><input type="checkbox" id="c-36134620" checked=""/><div class="controls bullet"><span class="by">bbotond</span><span>|</span><a href="#36136091">prev</a><span>|</span><a href="#36136085">next</a><span>|</span><label class="collapse" for="c-36134620">[-]</label><label class="expand" for="c-36134620">[22 more]</label></div><br/><div class="children"><div class="content">Yes. Before the update, when its avatar was still black, it solved pretty complex coding problems effortlessly and gave very nuanced, thoughtful answers to non-programming questions. Now it struggles with just changing two lines in a 10-line block of CSS and printing this modified 10-line block again. Some lines are missing, others are completely different for no reason. I&#x27;m sure scaling the model is hard, but they lobotomized it in the process.<p>The original GPT-4 felt like magic to me, I had this sense of awe while interacting with it. Now it is just a dumb stochastic parrot.</div><br/><div id="36135842" class="c"><input type="checkbox" id="c-36135842" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36135262">next</a><span>|</span><label class="collapse" for="c-36135842">[-]</label><label class="expand" for="c-36135842">[2 more]</label></div><br/><div class="children"><div class="content">The reason it&#x27;s worse is basically because it&#x27;s more &#x27;safe&#x27; (not racist, etc).  That of course sounds insane, and doesn&#x27;t mean that safety shouldn&#x27;t be strived for, etc - but there&#x27;s an explanation as to how this occurs.<p>It occurs because the system essentially does a latent classification of problems into &#x27;acceptable&#x27; or &#x27;not acceptable&#x27; to respond to.  When this is done, a decent amount of information is lost regarding how to represent these latent spaces that may be completely unrelated (making nefarious materials, or spouting hate speech are now in the same &#x27;bucket&#x27; for the decoder).<p>This degradation was observed quite early on with the tikz unicorn benchmark, which improved with training, and then degraded when fine-tuning to be more safe was applied.</div><br/></div></div><div id="36135262" class="c"><input type="checkbox" id="c-36135262" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36135842">prev</a><span>|</span><a href="#36134897">next</a><span>|</span><label class="collapse" for="c-36135262">[-]</label><label class="expand" for="c-36135262">[5 more]</label></div><br/><div class="children"><div class="content">&quot;The original GPT-4 felt like magic to me&quot;<p>You never had access to that original. Watch this talk by one of the people that integrated GPT-4 in Bing telling how they noticed GPT-4 releases they got from OpenAI got iteratively and significantly nerfed even during the project.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qbIk7-JPB2c">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qbIk7-JPB2c</a></div><br/><div id="36135308" class="c"><input type="checkbox" id="c-36135308" checked=""/><div class="controls bullet"><span class="by">bumbledraven</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36135262">parent</a><span>|</span><a href="#36135505">next</a><span>|</span><label class="collapse" for="c-36135308">[-]</label><label class="expand" for="c-36135308">[3 more]</label></div><br/><div class="children"><div class="content">“You never had access to that original.”<p>While your overall point is well taken, GP is clearly referring to the original public release of GPT-4 on March 14.</div><br/><div id="36135550" class="c"><input type="checkbox" id="c-36135550" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36135308">parent</a><span>|</span><a href="#36135505">next</a><span>|</span><label class="collapse" for="c-36135550">[-]</label><label class="expand" for="c-36135550">[2 more]</label></div><br/><div class="children"><div class="content">Yes, that was how I read it as well. I was just pointing out that the public release was already extremely nerfed from what was available pre-launch.</div><br/><div id="36135735" class="c"><input type="checkbox" id="c-36135735" checked=""/><div class="controls bullet"><span class="by">avocade</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36135550">parent</a><span>|</span><a href="#36135505">next</a><span>|</span><label class="collapse" for="c-36135735">[-]</label><label class="expand" for="c-36135735">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, please expound since very few of us had access pre-launch.</div><br/></div></div></div></div></div></div><div id="36135505" class="c"><input type="checkbox" id="c-36135505" checked=""/><div class="controls bullet"><span class="by">bbotond</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36135262">parent</a><span>|</span><a href="#36135308">prev</a><span>|</span><a href="#36134897">next</a><span>|</span><label class="collapse" for="c-36135505">[-]</label><label class="expand" for="c-36135505">[1 more]</label></div><br/><div class="children"><div class="content">Wow, I could only watch the first 15 minutes now but it’s already fascinating! Thanks for the recommendation.</div><br/></div></div></div></div><div id="36134897" class="c"><input type="checkbox" id="c-36134897" checked=""/><div class="controls bullet"><span class="by">okdood64</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36135262">prev</a><span>|</span><a href="#36134694">next</a><span>|</span><label class="collapse" for="c-36134897">[-]</label><label class="expand" for="c-36134897">[11 more]</label></div><br/><div class="children"><div class="content">Try out Bard, it&#x27;s coding is much improved in the last 2 weeks. I&#x27;ve unfortunately switched over for the time being.</div><br/><div id="36135036" class="c"><input type="checkbox" id="c-36135036" checked=""/><div class="controls bullet"><span class="by">AndyNemmity</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134897">parent</a><span>|</span><a href="#36134928">next</a><span>|</span><label class="collapse" for="c-36135036">[-]</label><label class="expand" for="c-36135036">[1 more]</label></div><br/><div class="children"><div class="content">I just tried Bard based on this comment, and it&#x27;s really, really bad.<p>Can you please help me with how you are prompting it?</div><br/></div></div><div id="36134928" class="c"><input type="checkbox" id="c-36134928" checked=""/><div class="controls bullet"><span class="by">bbotond</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134897">parent</a><span>|</span><a href="#36135036">prev</a><span>|</span><a href="#36135795">next</a><span>|</span><label class="collapse" for="c-36134928">[-]</label><label class="expand" for="c-36134928">[6 more]</label></div><br/><div class="children"><div class="content">“Bard isn’t currently supported in your country. Stay tuned!”</div><br/><div id="36135914" class="c"><input type="checkbox" id="c-36135914" checked=""/><div class="controls bullet"><span class="by">scottfr</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134928">parent</a><span>|</span><a href="#36134994">next</a><span>|</span><label class="collapse" for="c-36135914">[-]</label><label class="expand" for="c-36135914">[1 more]</label></div><br/><div class="children"><div class="content">The Bard model (Bison) is available without region lock as part of Google Cloud Platform. In addition to being able to call it via an API, they have a similar developer UI to the OpenAI playground to interactively experiment with it.<p><a href="https:&#x2F;&#x2F;console.cloud.google.com&#x2F;vertex-ai&#x2F;generative&#x2F;language&#x2F;create&#x2F;text" rel="nofollow">https:&#x2F;&#x2F;console.cloud.google.com&#x2F;vertex-ai&#x2F;generative&#x2F;langua...</a></div><br/></div></div><div id="36134994" class="c"><input type="checkbox" id="c-36134994" checked=""/><div class="controls bullet"><span class="by">rxyz</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134928">parent</a><span>|</span><a href="#36135914">prev</a><span>|</span><a href="#36134962">next</a><span>|</span><label class="collapse" for="c-36134994">[-]</label><label class="expand" for="c-36134994">[2 more]</label></div><br/><div class="children"><div class="content">Google&#x27;s passion for region locking is insane to me</div><br/><div id="36135269" class="c"><input type="checkbox" id="c-36135269" checked=""/><div class="controls bullet"><span class="by">bwb</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134994">parent</a><span>|</span><a href="#36134962">next</a><span>|</span><label class="collapse" for="c-36135269">[-]</label><label class="expand" for="c-36135269">[1 more]</label></div><br/><div class="children"><div class="content">Its a legal thing, not something they want to do</div><br/></div></div></div></div><div id="36134962" class="c"><input type="checkbox" id="c-36134962" checked=""/><div class="controls bullet"><span class="by">sintezcs</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134928">parent</a><span>|</span><a href="#36134994">prev</a><span>|</span><a href="#36135795">next</a><span>|</span><label class="collapse" for="c-36134962">[-]</label><label class="expand" for="c-36134962">[2 more]</label></div><br/><div class="children"><div class="content">Same for me, I’m in Estonia :(</div><br/><div id="36134996" class="c"><input type="checkbox" id="c-36134996" checked=""/><div class="controls bullet"><span class="by">corgihamlet</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134962">parent</a><span>|</span><a href="#36135795">next</a><span>|</span><label class="collapse" for="c-36134996">[-]</label><label class="expand" for="c-36134996">[1 more]</label></div><br/><div class="children"><div class="content">You can use a VPN to use an American connection, it doesn&#x27;t matter where your Google account is registered.</div><br/></div></div></div></div></div></div><div id="36135795" class="c"><input type="checkbox" id="c-36135795" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134897">parent</a><span>|</span><a href="#36134928">prev</a><span>|</span><a href="#36135147">next</a><span>|</span><label class="collapse" for="c-36135795">[-]</label><label class="expand" for="c-36135795">[1 more]</label></div><br/><div class="children"><div class="content">Google (Deepmind) actually has the people and has developed the science to make the best AI products in the world, but unfortunately Bard seems to be thrown together in an afternoon by an intern, and then handed off to a hoard of marketing people.  It&#x27;s not good right now.
Deepmind is one of the best scientifically, they just don&#x27;t really make products.  OpenAI is essentially the direct opposite of that.</div><br/></div></div><div id="36135147" class="c"><input type="checkbox" id="c-36135147" checked=""/><div class="controls bullet"><span class="by">qwepjn2oi3j</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36134897">parent</a><span>|</span><a href="#36135795">prev</a><span>|</span><a href="#36134694">next</a><span>|</span><label class="collapse" for="c-36135147">[-]</label><label class="expand" for="c-36135147">[2 more]</label></div><br/><div class="children"><div class="content">No thanks! I have better things to do than feeding that advertising behemoth. What I like about ChatGPT is that I don&#x27;t see any ads at all!</div><br/><div id="36135751" class="c"><input type="checkbox" id="c-36135751" checked=""/><div class="controls bullet"><span class="by">arcticbull</span><span>|</span><a href="#36134620">root</a><span>|</span><a href="#36135147">parent</a><span>|</span><a href="#36134694">next</a><span>|</span><label class="collapse" for="c-36135751">[-]</label><label class="expand" for="c-36135751">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What I like about ChatGPT is that I don&#x27;t see any ads at all!<p>For now. It&#x27;s just a marketing tool&#x2F;demo site, like ITA Matrix was&#x2F;is. The ads are vended by Bing.</div><br/></div></div></div></div></div></div><div id="36134694" class="c"><input type="checkbox" id="c-36134694" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36134897">prev</a><span>|</span><a href="#36135956">next</a><span>|</span><label class="collapse" for="c-36134694">[-]</label><label class="expand" for="c-36134694">[1 more]</label></div><br/><div class="children"><div class="content">It’s go-to tactic now if I ask it to go over any piece of code is to give a generic overview. Earlier, it would section out the code into chunks and go through each one individually.</div><br/></div></div><div id="36135956" class="c"><input type="checkbox" id="c-36135956" checked=""/><div class="controls bullet"><span class="by">anibalin</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36134694">prev</a><span>|</span><a href="#36135812">next</a><span>|</span><label class="collapse" for="c-36135956">[-]</label><label class="expand" for="c-36135956">[1 more]</label></div><br/><div class="children"><div class="content">Same happened with Dalle-2. It went downhill after a couple of weeks.</div><br/></div></div><div id="36135812" class="c"><input type="checkbox" id="c-36135812" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36134620">parent</a><span>|</span><a href="#36135956">prev</a><span>|</span><a href="#36136085">next</a><span>|</span><label class="collapse" for="c-36135812">[-]</label><label class="expand" for="c-36135812">[1 more]</label></div><br/><div class="children"><div class="content">If this is true, one should be able to compare with benchmarks or evals to demonstrate this.<p>Anyone know more about this?</div><br/></div></div></div></div><div id="36136085" class="c"><input type="checkbox" id="c-36136085" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#36134620">prev</a><span>|</span><a href="#36134669">next</a><span>|</span><label class="collapse" for="c-36136085">[-]</label><label class="expand" for="c-36136085">[1 more]</label></div><br/><div class="children"><div class="content">It definitely seems to be getting worse with Clojure.<p>I tried some stuff yesterday, and it was making pretty rookie mistakes (misaligning parentheses, using `recur` in the middle of the function instead of the tail). It also was decidedly bad at catching my mistakes when I pasted code.<p>I sadly don&#x27;t have a recording of this but I feel like a month ago it was better at both these things.</div><br/></div></div><div id="36134669" class="c"><input type="checkbox" id="c-36134669" checked=""/><div class="controls bullet"><span class="by">i_dont_know_</span><span>|</span><a href="#36136085">prev</a><span>|</span><a href="#36134724">next</a><span>|</span><label class="collapse" for="c-36134669">[-]</label><label class="expand" for="c-36134669">[4 more]</label></div><br/><div class="children"><div class="content">To me, it feels like it&#x27;s started giving superficial responses and encouraging follow-up elsewhere -- I wouldn&#x27;t be surprized if its prompt has changed to something to that effect.<p>Before, if I had an issue with a library or debugging issue, it would try to be helpful and walk me through potential issues, and ask me to &#x27;let it know&#x27; if it worked or not. Now it will try to superficially diagnose the problem and then ask me to check the online community for help or continuously refer me to the maintainers rather than trying to figure it out.<p>Similarly, I had been using it to help me think through problems and issues from different perspectives (both business and personal) and it would take me in-depth through these. Now, again, it gives superficial answers and encourages going to external sources.<p>I think if you keep pressing in the right ways it&#x27;ll eventually give in and help you as it did before, but I guess this will take quite a bit of prompting.</div><br/><div id="36135570" class="c"><input type="checkbox" id="c-36135570" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#36134669">parent</a><span>|</span><a href="#36134719">next</a><span>|</span><label class="collapse" for="c-36135570">[-]</label><label class="expand" for="c-36135570">[1 more]</label></div><br/><div class="children"><div class="content">&gt;To me, it feels like it&#x27;s started giving superficial responses and encouraging follow-up elsewhere -- I wouldn&#x27;t be surprized if its prompt has changed to something to that effect.<p>That&#x27;s the vibe I&#x27;ve been getting. The responses feel a little cagier at times than they used to. I assume it&#x27;s trying to limit hallucinations in order to increase public trust in the technology, and as a consequence it has been nerfed a little, but has changed along other dimensions that certain stakeholders likely care about.</div><br/></div></div><div id="36134719" class="c"><input type="checkbox" id="c-36134719" checked=""/><div class="controls bullet"><span class="by">killingtime74</span><span>|</span><a href="#36134669">parent</a><span>|</span><a href="#36135570">prev</a><span>|</span><a href="#36135368">next</a><span>|</span><label class="collapse" for="c-36134719">[-]</label><label class="expand" for="c-36134719">[1 more]</label></div><br/><div class="children"><div class="content">I assume you&#x27;re talking about ChatGPT and not GPT-4? You can craft your own prompt when calling GPT4 over API. Don&#x27;t blame you though, the OP is also not clear if they are comparing Chat GPT powered by GPT3.5 or 4, or the models themselves.</div><br/></div></div></div></div><div id="36134724" class="c"><input type="checkbox" id="c-36134724" checked=""/><div class="controls bullet"><span class="by">tmikaeld</span><span>|</span><a href="#36134669">prev</a><span>|</span><a href="#36135454">next</a><span>|</span><label class="collapse" for="c-36134724">[-]</label><label class="expand" for="c-36134724">[12 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no doubt that it&#x27;s gotten a lot worse on coding, I&#x27;ve been using this benchmark on each new version of GPT-4 &quot;Write a tiptap extension that toggles classes&quot; and so far it&#x27;s gotten it right every time, but not any more, now it hallucinates a simplified solution that don&#x27;t even use the tiptap api any more. It&#x27;s also 200% more verbose in explaining it&#x27;s reasoning, even if that reasoning makes no sense whatsoever - it&#x27;s like it&#x27;s gotten more apologetic and generic.<p>The answer is the same on GPT plus and API with GPT-4, even with &quot;developer&quot; role.</div><br/><div id="36135334" class="c"><input type="checkbox" id="c-36135334" checked=""/><div class="controls bullet"><span class="by">bumbledraven</span><span>|</span><a href="#36134724">parent</a><span>|</span><a href="#36134934">next</a><span>|</span><label class="collapse" for="c-36135334">[-]</label><label class="expand" for="c-36135334">[2 more]</label></div><br/><div class="children"><div class="content">Do you have API access? If so, have you tried your tiptap question on the gpt-4-0314 model? That is supposedly the original version released to the public on March 14.</div><br/><div id="36135929" class="c"><input type="checkbox" id="c-36135929" checked=""/><div class="controls bullet"><span class="by">tmikaeld</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135334">parent</a><span>|</span><a href="#36134934">next</a><span>|</span><label class="collapse" for="c-36135929">[-]</label><label class="expand" for="c-36135929">[1 more]</label></div><br/><div class="children"><div class="content">I did, but it got it almost the same as GPT-3.5 Turbo, the best version of it where there recently (~2-3 weeks ago), where it would make specific chunks of code-changes and explain the chunk in a concise and correct manner - even making suggestions on improvements. But that&#x27;s entirely gone now..</div><br/></div></div></div></div><div id="36134934" class="c"><input type="checkbox" id="c-36134934" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#36134724">parent</a><span>|</span><a href="#36135334">prev</a><span>|</span><a href="#36135154">next</a><span>|</span><label class="collapse" for="c-36134934">[-]</label><label class="expand" for="c-36134934">[2 more]</label></div><br/><div class="children"><div class="content">Do you have by any chance tested the same question on the playground?<p>I&#x27;ve noticed a quality decrease iny telegram bot as well that directly uses the API, and it drives me crazy because model versioning was supposedly implemented specifically to avoid response change without notice</div><br/><div id="36135972" class="c"><input type="checkbox" id="c-36135972" checked=""/><div class="controls bullet"><span class="by">tmikaeld</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36134934">parent</a><span>|</span><a href="#36135154">next</a><span>|</span><label class="collapse" for="c-36135972">[-]</label><label class="expand" for="c-36135972">[1 more]</label></div><br/><div class="children"><div class="content">Yes, using the general assistant role and the default content:<p>&quot;You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture. Knowledge cutoff: 2021-09 Current date: 2023-05-31&quot;<p>And custom roles with custom content via API.</div><br/></div></div></div></div><div id="36135154" class="c"><input type="checkbox" id="c-36135154" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#36134724">parent</a><span>|</span><a href="#36134934">prev</a><span>|</span><a href="#36135454">next</a><span>|</span><label class="collapse" for="c-36135154">[-]</label><label class="expand" for="c-36135154">[7 more]</label></div><br/><div class="children"><div class="content">It was a great ride while it lasted. My assumption is that efficacy at coding tasks is such a small percent of users, they’ve just sacrificed it on the altar of efficiency and&#x2F;or scale. That, or they’ve cut some back room deal with Microsoft to make Copilot have access to the only version of the model that can actually code.</div><br/><div id="36135395" class="c"><input type="checkbox" id="c-36135395" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135154">parent</a><span>|</span><a href="#36135871">next</a><span>|</span><label class="collapse" for="c-36135395">[-]</label><label class="expand" for="c-36135395">[1 more]</label></div><br/><div class="children"><div class="content">Honestly, why not different versions at this point?  People who want it for coding don&#x27;t care if it knows the history of prerevolution France, and vice versa.<p>Seems they could wow more people if they had specialized versions, rather than the jack of all trades that tries to exist now.<p>Edit: Oh God, I just described our human system of specialty and how the AI could replace us using the same means...</div><br/></div></div><div id="36135871" class="c"><input type="checkbox" id="c-36135871" checked=""/><div class="controls bullet"><span class="by">dx034</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135154">parent</a><span>|</span><a href="#36135395">prev</a><span>|</span><a href="#36135559">next</a><span>|</span><label class="collapse" for="c-36135871">[-]</label><label class="expand" for="c-36135871">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it had to do with jailbreaks? A lot of the jailbreaks were related to coding, so maybe they put more restrictions in there. Only speculating, but I cannot imagine why it got worse otherwise.</div><br/></div></div><div id="36135559" class="c"><input type="checkbox" id="c-36135559" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135154">parent</a><span>|</span><a href="#36135871">prev</a><span>|</span><a href="#36135369">next</a><span>|</span><label class="collapse" for="c-36135559">[-]</label><label class="expand" for="c-36135559">[3 more]</label></div><br/><div class="children"><div class="content">FWIW, I started to get the same feeling as the OP about GPT-4 model I have access to on Azure, so <i>if</i> there&#x27;s any deal being cut here, it might involve dumbing down the model for paying Azure customers as well.<p>Now, to be clear: I only <i>started to get a feeling</i> that GPT-4 on  Azure is getting worse. I didn&#x27;t do any specific testing for this so far, as I thought I may just be imagining it. This thread is starting to convince me otherwise.</div><br/><div id="36135769" class="c"><input type="checkbox" id="c-36135769" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135559">parent</a><span>|</span><a href="#36135369">next</a><span>|</span><label class="collapse" for="c-36135769">[-]</label><label class="expand" for="c-36135769">[2 more]</label></div><br/><div class="children"><div class="content">I’ve seen degradation in the app and via the API, so if I had to bet, they’ve probably kneecapped the model so that it works passably everywhere they’ve been made it available vs. works well in one place or another.</div><br/><div id="36135817" class="c"><input type="checkbox" id="c-36135817" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135769">parent</a><span>|</span><a href="#36135369">next</a><span>|</span><label class="collapse" for="c-36135817">[-]</label><label class="expand" for="c-36135817">[1 more]</label></div><br/><div class="children"><div class="content">Yes. I think &#x27;sirsinsalot is likely right in suggesting[0] that they could be trying &quot;to hoard the capability to out compete any competitor, of any kind, commercially or politically and hide the true extent of your capability to avoid scrutiny and legislation&quot;, and that they&#x27;re currently &quot;dialing back the public expectations&quot;, possibly while &quot;deploying the capability in a novel way to exploit it as the largest lever&quot; they can.<p>That view is consistent with GPT-4 getting dumber on both OpenAI proper and Azure OpenAI - even as the companies and corporations using the latter are paying through the nose for the privilege.<p>Alternative take is that they&#x27;re doing it to slow the development of the whole field down, per all the AI safety letters and manifestos that they&#x27;ve been signing and circulating - but that would be at best a stop-gap before OSS models catch up, and it&#x27;s more than likely that OpenAI and&#x2F;or Microsoft would succumb to the temptation of doing what &#x27;sirsinsalot suggested anyway.<p>--<p>[0] - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36135425" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36135425</a></div><br/></div></div></div></div></div></div><div id="36135369" class="c"><input type="checkbox" id="c-36135369" checked=""/><div class="controls bullet"><span class="by">jdiez17</span><span>|</span><a href="#36134724">root</a><span>|</span><a href="#36135154">parent</a><span>|</span><a href="#36135559">prev</a><span>|</span><a href="#36135454">next</a><span>|</span><label class="collapse" for="c-36135369">[-]</label><label class="expand" for="c-36135369">[1 more]</label></div><br/><div class="children"><div class="content">Copilot X (the new version, with a chat interface etc) is significantly worse than GPT-4 (at least before this update). It felt like gpt3.5-turbo to me.</div><br/></div></div></div></div></div></div><div id="36135454" class="c"><input type="checkbox" id="c-36135454" checked=""/><div class="controls bullet"><span class="by">Jack000</span><span>|</span><a href="#36134724">prev</a><span>|</span><a href="#36134608">next</a><span>|</span><label class="collapse" for="c-36135454">[-]</label><label class="expand" for="c-36135454">[1 more]</label></div><br/><div class="children"><div class="content">I tried to replicate a few of my chats (the displayed date is incorrect, it seems to be the publish date instead of the original chat date):<p>svg editor:<p>early april: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c235b48e-5a0e-4a89-af1c-0a3e7c6e4c5a" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c235b48e-5a0e-4a89-af1c-0a3e7c...</a><p>now: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;e4362a56-4bc7-45dc-8d1b-5e3842161384" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;e4362a56-4bc7-45dc-8d1b-5e3842...</a><p>originally it correctly inferred that I wanted a framework for svg editors, the latest version assumes I want a js framework (I tried several times) until I clarify. It also insists that the framework cannot do editable text until I nudge it in the right direction.<p>Overall slightly worse but the code generated is still fine.<p>word embeddings:<p>early april: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;f6bde43a-2fce-47dc-b23c-cc5af3e47b58" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;f6bde43a-2fce-47dc-b23c-cc5af3...</a><p>now: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;25c2703e-d89d-465c-9808-4df1b3eb40fa" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;25c2703e-d89d-465c-9808-4df1b3...</a><p>in the latest version it imported &quot;from sklearn.preprocessing import normalize&quot; without using it later. It also erroneously uses pytorch_cos_sim, which expects a pytorch tensor whereas we&#x27;re putting in a numpy array.<p>overall I think the quality has degraded slightly, but not by enough that I would stop using it. Still miles ahead of Bard imo.</div><br/></div></div><div id="36134608" class="c"><input type="checkbox" id="c-36134608" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#36135454">prev</a><span>|</span><a href="#36136052">next</a><span>|</span><label class="collapse" for="c-36134608">[-]</label><label class="expand" for="c-36134608">[4 more]</label></div><br/><div class="children"><div class="content">Is it consistently worse or just sometimes&#x2F;often worse than before? Any extreme power users or GPT-whisperers here? If it’s only noticeably worse X% of the time my bet would be experimentation.<p>One of my least favorite patterns that tech companies do is use “Experimentation” overzealously or prematurely. Mainly, my problem is they’re not transparent about it, and it creates an inconsistent product experience that just confuses you - why did this one Zillow listing have this UI order but the similar one I clicked seconds later had a different one? Why did this page load on Reddit get some weirdass font? Because it’s an experiment the bar to launch is low and you’re not gonna find any official blog posts about the changes until it’s official. And when it causes serious problems, there’s nowhere to submit a form or tell you why, and only very rarely would support, others, or documentation even realize some change is from an experiment. Over the past few years I’ve started noticing this <i>everywhere</i> online.<p>Non-sticky UI experiments are especially bad because at eg 1% of pageloads the signal is going to be measuring users asking themselves wtf is up and temporarily spending more time on page trying to figure out where the data moved. Sticky and&#x2F;or less noticeable experiments like what this <i>could be</i> have stronger signals but are even more annoying as a user, because there’s no notice that you’re essentially running some jank beta version, and no way to opt back into the default - for you it’s just broken. Especially not cool if you’re a paying customer.<p>I’m not saying it’s necessarily an experiment, it could be just a regular release or nothing at all. I’d hope if OpenAI was actually reducing the parameter size of their models they’d publicly announce that, but I could totally see them running an experiment measuring how a cheaper, smaller model affects usage and retention without publishing anything, because it’s exactly the kind of “right hand doesn’t know what the left is doing” thing that happens at fancy schmancy tech companies.</div><br/><div id="36134664" class="c"><input type="checkbox" id="c-36134664" checked=""/><div class="controls bullet"><span class="by">squokko</span><span>|</span><a href="#36134608">parent</a><span>|</span><a href="#36136052">next</a><span>|</span><label class="collapse" for="c-36134664">[-]</label><label class="expand" for="c-36134664">[3 more]</label></div><br/><div class="children"><div class="content">No place I worked at ever experimented at the pageload level. We experimented at the user level, so 1% of users would get the new UI. I suppose this is only possible at the millions of users scale which all of them had.</div><br/><div id="36134682" class="c"><input type="checkbox" id="c-36134682" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#36134608">root</a><span>|</span><a href="#36134664">parent</a><span>|</span><a href="#36136052">next</a><span>|</span><label class="collapse" for="c-36134682">[-]</label><label class="expand" for="c-36134682">[2 more]</label></div><br/><div class="children"><div class="content">I updated the comment to reflect that. Certainly the signal is stronger because you’re amortizing away the surprise factor of the change, and at least it’s a consistent UX, but the UX tradeoff in the worst case is that experiment-group users get a broken product with no notice or escape hatch. Unless you’re being very careful, meticulous, and transparent it’s just not acceptable if you’re a paying customer.</div><br/><div id="36134704" class="c"><input type="checkbox" id="c-36134704" checked=""/><div class="controls bullet"><span class="by">reidjs</span><span>|</span><a href="#36134608">root</a><span>|</span><a href="#36134682">parent</a><span>|</span><a href="#36136052">next</a><span>|</span><label class="collapse" for="c-36134704">[-]</label><label class="expand" for="c-36134704">[1 more]</label></div><br/><div class="children"><div class="content">In some cases you’re making the change because the app is already broken for the majority of users and you’re testing the fix</div><br/></div></div></div></div></div></div></div></div><div id="36136052" class="c"><input type="checkbox" id="c-36136052" checked=""/><div class="controls bullet"><span class="by">Yenrabbit</span><span>|</span><a href="#36134608">prev</a><span>|</span><a href="#36135013">next</a><span>|</span><label class="collapse" for="c-36136052">[-]</label><label class="expand" for="c-36136052">[1 more]</label></div><br/><div class="children"><div class="content">I noticed an apparent shift recently (for the worse) using Bing in creative mode, which is also supposed to be GPT4. Shorter answers, much more work to get it to output code, and maybe more bugs in the code it does produce...
It&#x27;s funny, I really did feel like I&#x27;d lost something when I noticed it!</div><br/></div></div><div id="36135013" class="c"><input type="checkbox" id="c-36135013" checked=""/><div class="controls bullet"><span class="by">kleene_op</span><span>|</span><a href="#36136052">prev</a><span>|</span><a href="#36134400">next</a><span>|</span><label class="collapse" for="c-36135013">[-]</label><label class="expand" for="c-36135013">[5 more]</label></div><br/><div class="children"><div class="content">This is the normal workflow for drug dealers too.<p>The first fix is free.<p>The second one will cost you money.<p>The third one will be laced with fillers and have degraded quality.</div><br/><div id="36135887" class="c"><input type="checkbox" id="c-36135887" checked=""/><div class="controls bullet"><span class="by">dx034</span><span>|</span><a href="#36135013">parent</a><span>|</span><a href="#36135283">next</a><span>|</span><label class="collapse" for="c-36135887">[-]</label><label class="expand" for="c-36135887">[1 more]</label></div><br/><div class="children"><div class="content">But I don&#x27;t get why they would degrade quality? Maybe compression to save resources? Otherwise I wouldn&#x27;t know what they have to gain from it. If anything, they might lose paid subscribers. I loved the results for the $20 I spent, now I&#x27;m not so sure anymore.</div><br/></div></div><div id="36135283" class="c"><input type="checkbox" id="c-36135283" checked=""/><div class="controls bullet"><span class="by">prox</span><span>|</span><a href="#36135013">parent</a><span>|</span><a href="#36135887">prev</a><span>|</span><a href="#36135177">next</a><span>|</span><label class="collapse" for="c-36135283">[-]</label><label class="expand" for="c-36135283">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how much people are relying on it already, to what extent and so on. Would be a good study.</div><br/></div></div><div id="36135177" class="c"><input type="checkbox" id="c-36135177" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#36135013">parent</a><span>|</span><a href="#36135283">prev</a><span>|</span><a href="#36135668">next</a><span>|</span><label class="collapse" for="c-36135177">[-]</label><label class="expand" for="c-36135177">[1 more]</label></div><br/><div class="children"><div class="content">the fourth one will refer you to their sponsors</div><br/></div></div></div></div><div id="36134400" class="c"><input type="checkbox" id="c-36134400" checked=""/><div class="controls bullet"><span class="by">okdood64</span><span>|</span><a href="#36135013">prev</a><span>|</span><a href="#36135776">next</a><span>|</span><label class="collapse" for="c-36134400">[-]</label><label class="expand" for="c-36134400">[5 more]</label></div><br/><div class="children"><div class="content">Yes!<p>It didn&#x27;t even try on my question of Jarvis standings desks, which is a fairly old product that hasn&#x27;t changed up.. Their typical &quot;My knowledge cutoff...&quot; response doesn&#x27;t even make sense. It screwed up another question I asked it about server uptime and four-9s, Bard got it right.<p>I&#x27;ve moved back to Bard for the time being...It&#x27;s way faster as well. And GPT-4&#x27;s knowledge cutoff thing is getting old fast.<p>Example prompt: how much does a 48 x 30 inch jarvis bamboo standing desk setup weigh?<p>I still have the spec sheet from my order back in 2020. So I can verify the weights.<p>###
GPT-4
###<p>ChatGPT
As of my knowledge cutoff in September 2021, I don&#x27;t have the exact weight of a 48 x 30 inch Jarvis Bamboo standing desk setup. However, on average, standing desks can range anywhere from around 60 to 100 pounds or more, depending on the specific configuration (like the choice of frame, desktop material, and any additional features).<p>Jarvis Bamboo standing desks are made of a bamboo top and an electric lift frame. The weight of the bamboo top for that size should be around 30-40 pounds. The frame itself can weigh anywhere from 50-70 pounds.<p>For a more accurate weight, I would recommend checking the manufacturer&#x27;s specifications on their website or contacting their customer support directly for this information.<p>###
Bard
###<p>The fully assembled Jarvis Bamboo Standing Desk weighs 92 pounds. The desktop itself weighs 38 pounds, and the frame weighs 54 pounds. The desk can hold a maximum weight of 350 pounds.<p>Here are some of the features of the Jarvis Bamboo Standing Desk:<p>Electric height adjustment from 25.5 to 51 inches
Memory presets for up to 4 different heights
3-stage gas spring mechanism
Bamboo desktop with a scratch-resistant finish
Black powder-coated steel frame
10-year warranty on the frame and 5-year warranty on the desktop</div><br/><div id="36134680" class="c"><input type="checkbox" id="c-36134680" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#36134400">parent</a><span>|</span><a href="#36135319">next</a><span>|</span><label class="collapse" for="c-36134680">[-]</label><label class="expand" for="c-36134680">[1 more]</label></div><br/><div class="children"><div class="content">Asking facts from a generative AI is folly.</div><br/></div></div><div id="36135319" class="c"><input type="checkbox" id="c-36135319" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#36134400">parent</a><span>|</span><a href="#36134680">prev</a><span>|</span><a href="#36135197">next</a><span>|</span><label class="collapse" for="c-36135319">[-]</label><label class="expand" for="c-36135319">[1 more]</label></div><br/><div class="children"><div class="content">According to <a href="https:&#x2F;&#x2F;ukstore.hermanmiller.com&#x2F;products&#x2F;jarvis-bamboo-desk-1600" rel="nofollow">https:&#x2F;&#x2F;ukstore.hermanmiller.com&#x2F;products&#x2F;jarvis-bamboo-desk...</a> Bard is off by about 10%, but generally correct (it&#x27;s also possible that the US dimensions are actually smaller and could account for the difference).</div><br/></div></div><div id="36135197" class="c"><input type="checkbox" id="c-36135197" checked=""/><div class="controls bullet"><span class="by">tgsovlerkhgsel</span><span>|</span><a href="#36134400">parent</a><span>|</span><a href="#36135319">prev</a><span>|</span><a href="#36135294">next</a><span>|</span><label class="collapse" for="c-36135197">[-]</label><label class="expand" for="c-36135197">[1 more]</label></div><br/><div class="children"><div class="content">Were the numbers accurate or hallucinated?</div><br/></div></div><div id="36135294" class="c"><input type="checkbox" id="c-36135294" checked=""/><div class="controls bullet"><span class="by">dotancohen</span><span>|</span><a href="#36134400">parent</a><span>|</span><a href="#36135197">prev</a><span>|</span><a href="#36135776">next</a><span>|</span><label class="collapse" for="c-36135294">[-]</label><label class="expand" for="c-36135294">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; The fully assembled Jarvis Bamboo Standing Desk weighs 92 pounds. The desktop itself weighs 38 pounds, and the frame weighs 54 pounds. The desk can hold a maximum weight of 350 pounds.
</code></pre>
That sounds like a linguistically valid sentences, exactly what I would expect from a novel LLM. Did you check that it is also factually correct? Factually correctness is _not_ the goal of a typical LLM.</div><br/></div></div></div></div><div id="36135776" class="c"><input type="checkbox" id="c-36135776" checked=""/><div class="controls bullet"><span class="by">hugg</span><span>|</span><a href="#36134400">prev</a><span>|</span><a href="#36135425">next</a><span>|</span><label class="collapse" for="c-36135776">[-]</label><label class="expand" for="c-36135776">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I noticed this too, I fed it some HTML with tailwind classes and told it to just list all the tailwind classes that we use and then the CSS behind those classes.. it just hallucinated all(!) the items in the list (and just gave me a list of 10 seemingly random classes). And then when I did asked something else about the code it had forgotten I had ever pasted anything in the conversation. Very weird.</div><br/></div></div><div id="36135425" class="c"><input type="checkbox" id="c-36135425" checked=""/><div class="controls bullet"><span class="by">sirsinsalot</span><span>|</span><a href="#36135776">prev</a><span>|</span><a href="#36135896">next</a><span>|</span><label class="collapse" for="c-36135425">[-]</label><label class="expand" for="c-36135425">[8 more]</label></div><br/><div class="children"><div class="content">Given the incoming compute capability from nvidia and the speed of advancement, we have to stop and think ... does it make sense to give access, paid or otherwise, to these models once they reach a certain sophistication?<p>Or does it make even more sense to hoard the capability to out compete any competitor, of any kind, commercially or politically and hide the true extent of your capability to avoid scrutiny and legislation?<p>I&#x27;m going with the latter. Perhaps now, perhaps in the very near future, the power of these capabilities is novel. Like an information nuclear weapon.<p>I&#x27;d be dialing back the public expectations and deploying the capability in a novel way to exploit it as the largest lever I could.<p>The more unseen the lever, the longer.<p>I think any other strategy is myopic from a competition perspective. The power of these models isn&#x27;t direct utility, it is compounded by secrecy because their useful work isn&#x27;t directly observable as coming from the model.</div><br/><div id="36135447" class="c"><input type="checkbox" id="c-36135447" checked=""/><div class="controls bullet"><span class="by">bevenky</span><span>|</span><a href="#36135425">parent</a><span>|</span><a href="#36135703">next</a><span>|</span><label class="collapse" for="c-36135447">[-]</label><label class="expand" for="c-36135447">[3 more]</label></div><br/><div class="children"><div class="content">I have some first hand thoughts. I think overall the quality is significantly poorer on GPT4 with plugins and bing browsing enabled. If you disable those, I am able to get the same quality as before. The outputs are dramatically different. Would love to hear what everyone else sees when they try the same.</div><br/><div id="36135543" class="c"><input type="checkbox" id="c-36135543" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36135425">root</a><span>|</span><a href="#36135447">parent</a><span>|</span><a href="#36135869">next</a><span>|</span><label class="collapse" for="c-36135543">[-]</label><label class="expand" for="c-36135543">[1 more]</label></div><br/><div class="children"><div class="content">No, while I have no hard data, the experienced quality of the default GPT-4 model feels like it has gone down tremendously for me as well. Plugins and Bing browsing have so far for me almost never worked at all. I retry these just once a week but there always seem to be technical issues.</div><br/></div></div><div id="36135869" class="c"><input type="checkbox" id="c-36135869" checked=""/><div class="controls bullet"><span class="by">throwaway290</span><span>|</span><a href="#36135425">root</a><span>|</span><a href="#36135447">parent</a><span>|</span><a href="#36135543">prev</a><span>|</span><a href="#36135703">next</a><span>|</span><label class="collapse" for="c-36135869">[-]</label><label class="expand" for="c-36135869">[1 more]</label></div><br/><div class="children"><div class="content">would be alarming if you had second hand thoughts...</div><br/></div></div></div></div><div id="36135703" class="c"><input type="checkbox" id="c-36135703" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#36135425">parent</a><span>|</span><a href="#36135447">prev</a><span>|</span><a href="#36135627">next</a><span>|</span><label class="collapse" for="c-36135703">[-]</label><label class="expand" for="c-36135703">[1 more]</label></div><br/><div class="children"><div class="content">A more banal explanation is that compute is expensive, so they are tweaking the models to get more for less, and it isn&#x27;t always working out. Scaling by itself is a hard problem, scaling and improving efficiency (margins) doubly so.</div><br/></div></div><div id="36135627" class="c"><input type="checkbox" id="c-36135627" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#36135425">parent</a><span>|</span><a href="#36135703">prev</a><span>|</span><a href="#36135681">next</a><span>|</span><label class="collapse" for="c-36135627">[-]</label><label class="expand" for="c-36135627">[1 more]</label></div><br/><div class="children"><div class="content">I rather think it has something to do with scale, hardware and energy costs. GPT4 is way more expensive to compute, than GPT3. Needing more GPUs and more energy tu run it.<p>And demand is still through the roof and they have a lot of people subscribing, so why not reduce costs a little bit, someone might have thought. Or well, &quot;optimized&quot; was probably the term used.</div><br/></div></div><div id="36135681" class="c"><input type="checkbox" id="c-36135681" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#36135425">parent</a><span>|</span><a href="#36135627">prev</a><span>|</span><a href="#36135896">next</a><span>|</span><label class="collapse" for="c-36135681">[-]</label><label class="expand" for="c-36135681">[2 more]</label></div><br/><div class="children"><div class="content">I used to agree with what you&#x27;re saying, but after reading this leaked Google memo I think maybe we&#x27;re both wrong: <a href="https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;google-we-have-no-moat-and-neither" rel="nofollow">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;google-we-have-no-moat-and-ne...</a><p>Experts who are both in a position to know, and seeking to maximize the commercial potential of their work are saying the cat is already out of the bag. They make a persuasive case that public, open-source models are closing the gap with private, commercial ones and admit bluntly, &quot;We have no secret sauce.&quot;</div><br/><div id="36135715" class="c"><input type="checkbox" id="c-36135715" checked=""/><div class="controls bullet"><span class="by">Roritharr</span><span>|</span><a href="#36135425">root</a><span>|</span><a href="#36135681">parent</a><span>|</span><a href="#36135896">next</a><span>|</span><label class="collapse" for="c-36135715">[-]</label><label class="expand" for="c-36135715">[1 more]</label></div><br/><div class="children"><div class="content">Having spoken to a bunch of people that either have just left Google or still work there, practically all of them think this was not so much a leak as a placed bit of news to support them in potential future anti-trust cases.</div><br/></div></div></div></div></div></div><div id="36135896" class="c"><input type="checkbox" id="c-36135896" checked=""/><div class="controls bullet"><span class="by">mckirk</span><span>|</span><a href="#36135425">prev</a><span>|</span><a href="#36134466">next</a><span>|</span><label class="collapse" for="c-36135896">[-]</label><label class="expand" for="c-36135896">[1 more]</label></div><br/><div class="children"><div class="content">On Saturday it produced grammatically incorrect German text (when prompted in German), which it certainly never had done before. It was quite concerning to see.</div><br/></div></div><div id="36134466" class="c"><input type="checkbox" id="c-36134466" checked=""/><div class="controls bullet"><span class="by">allisdust</span><span>|</span><a href="#36135896">prev</a><span>|</span><a href="#36136024">next</a><span>|</span><label class="collapse" for="c-36134466">[-]</label><label class="expand" for="c-36134466">[2 more]</label></div><br/><div class="children"><div class="content">Yes. Seems to have definitely gone down. Not sure what they have done but even with things it used have no trouble with, it struggles now. Most likely they are experimenting on reducing the compute per request.</div><br/><div id="36135617" class="c"><input type="checkbox" id="c-36135617" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#36134466">parent</a><span>|</span><a href="#36136024">next</a><span>|</span><label class="collapse" for="c-36135617">[-]</label><label class="expand" for="c-36135617">[1 more]</label></div><br/><div class="children"><div class="content">I did notice the rate limiting message isn&#x27;t there anymore when using GPT-4.</div><br/></div></div></div></div><div id="36136024" class="c"><input type="checkbox" id="c-36136024" checked=""/><div class="controls bullet"><span class="by">throwaway1249</span><span>|</span><a href="#36134466">prev</a><span>|</span><a href="#36135491">next</a><span>|</span><label class="collapse" for="c-36136024">[-]</label><label class="expand" for="c-36136024">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just you. Probably they added some sort of classifier at the beginning to understand whether they should send it to 3.5 or 4. In my (very opinionated, undocumented, and mostly unscientific) opinion, more complex queries generally hit the old model, with the slow chugging of tokens. For example, I just asked it to refactor a very horrible POC in python that was creeping into the 200 LoC and it did the job wonderful. The prompt was:<p>`Can you refactor this function to make it:
* More readable
* Split on different parts
* Easy to test<p>Consider the use of generators and other strategies.
(code here)`</div><br/></div></div><div id="36135491" class="c"><input type="checkbox" id="c-36135491" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#36136024">prev</a><span>|</span><a href="#36135586">next</a><span>|</span><label class="collapse" for="c-36135491">[-]</label><label class="expand" for="c-36135491">[4 more]</label></div><br/><div class="children"><div class="content">Maybe you annoyed it? I’m super nice to it and it performa better than ever.<p>I ask it lay-of-the-land questions about technical problems that are new to me to detailed coding problems that I understand well but don’t want to figure out.<p>The best though, is helping me navigate complicated UI’s. I tell it how I want some complicated software &#x2F; website to behave, and it’ll tell me the arcane menu path to follow.<p>It’s funny how computing might soon include elements of psychology and magic incantations nobody understands.</div><br/><div id="36135853" class="c"><input type="checkbox" id="c-36135853" checked=""/><div class="controls bullet"><span class="by">r_singh</span><span>|</span><a href="#36135491">parent</a><span>|</span><a href="#36135597">next</a><span>|</span><label class="collapse" for="c-36135853">[-]</label><label class="expand" for="c-36135853">[1 more]</label></div><br/><div class="children"><div class="content">This might seem funny, but I noticed this too.<p>When I thank GPT-4 and also give it feedback on what worked and what didn&#x27;t, it works better and so to me it seems like the equivalent of &quot;putting in more effort&quot;.</div><br/></div></div><div id="36135597" class="c"><input type="checkbox" id="c-36135597" checked=""/><div class="controls bullet"><span class="by">r_hoods_ghost</span><span>|</span><a href="#36135491">parent</a><span>|</span><a href="#36135853">prev</a><span>|</span><a href="#36135586">next</a><span>|</span><label class="collapse" for="c-36135597">[-]</label><label class="expand" for="c-36135597">[2 more]</label></div><br/><div class="children"><div class="content">&quot;It’s funny how computing might soon include elements of psychology and magic incantations nobody understands&quot;<p>As a sysadmin I can tell you this is already the case...</div><br/><div id="36135673" class="c"><input type="checkbox" id="c-36135673" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#36135491">root</a><span>|</span><a href="#36135597">parent</a><span>|</span><a href="#36135586">next</a><span>|</span><label class="collapse" for="c-36135673">[-]</label><label class="expand" for="c-36135673">[1 more]</label></div><br/><div class="children"><div class="content">As someone who regularly has to get a sysadmin to do stuff, I can tell you yes this is certainly the case.</div><br/></div></div></div></div></div></div><div id="36135586" class="c"><input type="checkbox" id="c-36135586" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#36135491">prev</a><span>|</span><a href="#36135252">next</a><span>|</span><label class="collapse" for="c-36135586">[-]</label><label class="expand" for="c-36135586">[1 more]</label></div><br/><div class="children"><div class="content">I would recommend access over API and using an interface like TypingMind that gives you control over the system prompt for consistency.</div><br/></div></div><div id="36135252" class="c"><input type="checkbox" id="c-36135252" checked=""/><div class="controls bullet"><span class="by">throwawayadvsec</span><span>|</span><a href="#36135586">prev</a><span>|</span><a href="#36134594">next</a><span>|</span><label class="collapse" for="c-36135252">[-]</label><label class="expand" for="c-36135252">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s happening because of the extreme content filtering in place, at some point it was even refusing to generate some code because it thought it went against its guidelines to write code.</div><br/><div id="36135607" class="c"><input type="checkbox" id="c-36135607" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#36135252">parent</a><span>|</span><a href="#36134594">next</a><span>|</span><label class="collapse" for="c-36135607">[-]</label><label class="expand" for="c-36135607">[1 more]</label></div><br/><div class="children"><div class="content">I definitely think this is playing a role. I&#x27;ve seen reports of people saying &quot;oh it now refuses to act as my therapist&quot; and &quot;it wouldn&#x27;t write my essay for me&quot;. Those are just a couple of anecdotes I&#x27;ve seen on Reddit, and haven&#x27;t verified myself, but it wouldn&#x27;t surprise me if OpenAI felt the need to make adjustments along those lines.</div><br/></div></div></div></div><div id="36134594" class="c"><input type="checkbox" id="c-36134594" checked=""/><div class="controls bullet"><span class="by">jlmorton</span><span>|</span><a href="#36135252">prev</a><span>|</span><a href="#36136099">next</a><span>|</span><label class="collapse" for="c-36134594">[-]</label><label class="expand" for="c-36134594">[1 more]</label></div><br/><div class="children"><div class="content">Definitely nerfed. Concomitantly, the performance increased substantially, and it now feels much, much quicker (maybe 10x even?), but the quality has decreased quite a bit.</div><br/></div></div><div id="36136099" class="c"><input type="checkbox" id="c-36136099" checked=""/><div class="controls bullet"><span class="by">fsniper</span><span>|</span><a href="#36134594">prev</a><span>|</span><a href="#36135415">next</a><span>|</span><label class="collapse" for="c-36136099">[-]</label><label class="expand" for="c-36136099">[1 more]</label></div><br/><div class="children"><div class="content">I realized the same with the GPT3.5 model too. After the Last update it started giving shorter and less coherent answers.</div><br/></div></div><div id="36135415" class="c"><input type="checkbox" id="c-36135415" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36136099">prev</a><span>|</span><a href="#36135033">next</a><span>|</span><label class="collapse" for="c-36135415">[-]</label><label class="expand" for="c-36135415">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;d think that GPT-X would guarantee some kind of continuity for that particular version so that you can rely on what it does once you&#x27;ve tested it. Having this kind of moving target won&#x27;t help OpenAI to instill confidence in its product.</div><br/></div></div><div id="36135033" class="c"><input type="checkbox" id="c-36135033" checked=""/><div class="controls bullet"><span class="by">lwansbrough</span><span>|</span><a href="#36135415">prev</a><span>|</span><a href="#36136029">next</a><span>|</span><label class="collapse" for="c-36135033">[-]</label><label class="expand" for="c-36135033">[1 more]</label></div><br/><div class="children"><div class="content">Yeah 100%. It&#x27;s much faster now, and I am almost certain they haven&#x27;t made that much of an improvement in efficiency nor have they scaled it up to be that fast, if that&#x27;s even how it works.<p>I think I read when it was released it was 32K tokens, then quickly scaled back to 8K tokens. I&#x27;m guessing now that they&#x27;ve further reduced it. Maybe it&#x27;s 6000 tokens vs. GPT-3.5&#x27;s 4K? I don&#x27;t know. But it&#x27;s certainly noticeably worse at every task I give it.</div><br/></div></div><div id="36136029" class="c"><input type="checkbox" id="c-36136029" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#36135033">prev</a><span>|</span><a href="#36135908">next</a><span>|</span><label class="collapse" for="c-36136029">[-]</label><label class="expand" for="c-36136029">[1 more]</label></div><br/><div class="children"><div class="content">Yes and I have to say I am using it less than I used to.<p>My gut feeling is they have to be careful now and don’t slack, because I have been using generative AI for a while now and I am not seeing the major problems being tackled. I also see a distinct lack of novel problems being solved. It’s just one website and&#x2F;or marketing copy generator after another.<p>AI is awesome, but I am kind of on the fence if this generation is going to be actually useful.</div><br/></div></div><div id="36135908" class="c"><input type="checkbox" id="c-36135908" checked=""/><div class="controls bullet"><span class="by">goncalo-r</span><span>|</span><a href="#36136029">prev</a><span>|</span><a href="#36135913">next</a><span>|</span><label class="collapse" for="c-36135908">[-]</label><label class="expand" for="c-36135908">[1 more]</label></div><br/><div class="children"><div class="content">My assumption is that they are trying to &quot;solve&quot; the hallucination problem by only giving you answers when it&#x27;s more certain about itself and telling you to search for answers online.</div><br/></div></div><div id="36135913" class="c"><input type="checkbox" id="c-36135913" checked=""/><div class="controls bullet"><span class="by">cfcf14</span><span>|</span><a href="#36135908">prev</a><span>|</span><a href="#36134982">next</a><span>|</span><label class="collapse" for="c-36135913">[-]</label><label class="expand" for="c-36135913">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, definitely. Combination of expert-system gating (some requests probably get routed to weaker models), distillation (for performance&#x2F;cost), and RLHF lobotomization.</div><br/></div></div><div id="36134982" class="c"><input type="checkbox" id="c-36134982" checked=""/><div class="controls bullet"><span class="by">root_axis</span><span>|</span><a href="#36135913">prev</a><span>|</span><a href="#36134903">next</a><span>|</span><label class="collapse" for="c-36134982">[-]</label><label class="expand" for="c-36134982">[1 more]</label></div><br/><div class="children"><div class="content">Seems about the same to me and I have been using it daily for several months now for code, Spanish to English translations, and random stuff like film recommendations. The quality remains consistent.<p>I&#x27;m personally of the opinion that the observable jump in quality between 3.5 and 4 inflated people&#x27;s initial assessment of its capabilities and with continued use they are noticing it&#x27;s not actually the omniscient machine god that many are so inclined to believe.<p>Either way, these kinds of posts are meaningless without some kind of objective standard to judge the model by, everyone just sees what they want to see. Despite claims of GPT4 being nerfed, I&#x27;ve yet to see anyone actually show evidence of it. There have been dozens of studies done on its capabilities so this is something that can actually be demonstrated empirically if it&#x27;s true.</div><br/></div></div><div id="36134903" class="c"><input type="checkbox" id="c-36134903" checked=""/><div class="controls bullet"><span class="by">airbreather</span><span>|</span><a href="#36134982">prev</a><span>|</span><a href="#36134939">next</a><span>|</span><label class="collapse" for="c-36134903">[-]</label><label class="expand" for="c-36134903">[1 more]</label></div><br/><div class="children"><div class="content">it is far less willing to provide code, I get better results and faster out of 3.5.<p>I am at the point that 4.0 is basically not worth using as single entity, but it seems that using the api and generating some combative&#x2F;consultative agents yields some interesting results, but not super fast.<p>Check this out if you have not seen it already : &quot;AutoGPT Test and My AI Agents Effortless Programming - INSANE Progress!&quot;<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=L6tU0bnMsh8">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=L6tU0bnMsh8</a></div><br/></div></div><div id="36134939" class="c"><input type="checkbox" id="c-36134939" checked=""/><div class="controls bullet"><span class="by">robinduckett</span><span>|</span><a href="#36134903">prev</a><span>|</span><a href="#36136039">next</a><span>|</span><label class="collapse" for="c-36134939">[-]</label><label class="expand" for="c-36134939">[1 more]</label></div><br/><div class="children"><div class="content">Yep, whereas before it would generate a cohesive whole class in Typescript from a set of instructions, now it gives me the framework of the class with “&#x2F;&#x2F; fill out the rest of the class here”. Worse than GPT-3.5. They’re going to lose subscriptions.</div><br/></div></div><div id="36136039" class="c"><input type="checkbox" id="c-36136039" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#36134939">prev</a><span>|</span><a href="#36134956">next</a><span>|</span><label class="collapse" for="c-36136039">[-]</label><label class="expand" for="c-36136039">[1 more]</label></div><br/><div class="children"><div class="content">Just use GPT-4 via api?</div><br/></div></div><div id="36134956" class="c"><input type="checkbox" id="c-36134956" checked=""/><div class="controls bullet"><span class="by">gwoolhurme</span><span>|</span><a href="#36136039">prev</a><span>|</span><label class="collapse" for="c-36134956">[-]</label><label class="expand" for="c-36134956">[1 more]</label></div><br/><div class="children"><div class="content">I see these posts popup every now and then. I admittedly don&#x27;t use GPT4 or chatGPT that often, but I don&#x27;t notice that much of a difference. Is it possible you try to give it harder and harder tasks and it is failing at them instead of the easier tasks it solved when you used it before? Is it possible it is just scaled back due to over use? Is that possible? It could be a dumb dumb question. In my experience even a few weeks ago, for Swift and Kotlin I found that the outputs of chatgpt and gpt4 are comparably similar and sometimes useless without a good amount of human intervention.</div><br/></div></div></div></div></div></div></div></body></html>