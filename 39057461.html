<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705741252715" as="style"/><link rel="stylesheet" href="styles.css?v=1705741252715"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://colah.github.io/posts/2015-08-Backprop/">Calculus on Computational Graphs: Backpropagation (2015)</a> <span class="domain">(<a href="https://colah.github.io">colah.github.io</a>)</span></div><div class="subtext"><span>throwup238</span> | <span>25 comments</span></div><br/><div><div id="39060615" class="c"><input type="checkbox" id="c-39060615" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#39059775">next</a><span>|</span><label class="collapse" for="c-39060615">[-]</label><label class="expand" for="c-39060615">[1 more]</label></div><br/><div class="children"><div class="content">If you want more on this, check out this paper by Terence Parr and Jeremy Howard: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.01528" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.01528</a><p>It is rather accessible.</div><br/></div></div><div id="39059775" class="c"><input type="checkbox" id="c-39059775" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39060615">prev</a><span>|</span><a href="#39062797">next</a><span>|</span><label class="collapse" for="c-39059775">[-]</label><label class="expand" for="c-39059775">[1 more]</label></div><br/><div class="children"><div class="content">Discussed at the time:<p><i>Calculus on Computational Graphs: Backpropagation</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10148064">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10148064</a> - Aug 2015 (9 comments)</div><br/></div></div><div id="39062797" class="c"><input type="checkbox" id="c-39062797" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#39059775">prev</a><span>|</span><a href="#39058873">next</a><span>|</span><label class="collapse" for="c-39062797">[-]</label><label class="expand" for="c-39062797">[2 more]</label></div><br/><div class="children"><div class="content">Or do Andrej Karpathy&#x27;s youtube backprop ninja exercise on jupyter notebook by hand no?</div><br/><div id="39062879" class="c"><input type="checkbox" id="c-39062879" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#39062797">parent</a><span>|</span><a href="#39058873">next</a><span>|</span><label class="collapse" for="c-39062879">[-]</label><label class="expand" for="c-39062879">[1 more]</label></div><br/><div class="children"><div class="content">Protip here: Do it by hand, though when you start getting tired of typing latex you can switch to IDE and let github copilot complete it(it will mostly be incorrect) and then you can go in and fix its mistakes, it still saves a bunch of time. For example:<p>```
The importtant thing is that the derivative needs to be computed from a number of elements
logits = h@W+b<p>logits = h@W+b<p>h =<p>h11 h12 h13<p>h21 h21 h23<p>W = 
w11 w12<p>w21 w22<p>w31 w32<p>b = b1, b2 and<p>Logit11 = h11<i>w11+ h12</i>w21 + h13<i>w31 + b1  - Eq.1<p>Logit12 = h11</i>w12+ h12<i>w22 + h13</i>w32 + b2  - Eq.2<p>Logit21 = h21<i>w11+ h22</i>w21 + h23<i>w31 + b1  - Eq.3<p>Logit22 = h21</i>w12+ h22<i>w22 + h23</i>w32 + b2  - Eq.4<p>DL&#x2F;Dh11 = DL&#x2F;DLogit11 * DLogit11&#x2F;Dh11 + DL&#x2F;DLogit12 * DLogit12&#x2F;Dh11 = DL&#x2F;Dlogit11 * w11 + DL&#x2F;DLogit12 * w12<p>DL&#x2F;Dh12 = DL&#x2F;DLogit11 * DLogit11&#x2F;Dh12 + DL&#x2F;DLogit12 * DLogit12&#x2F;Dh12 = DL&#x2F;Dlogit11 * w21 + DL&#x2F;DLogit12 * w22<p>DL&#x2F;Dh13 = DL&#x2F;DLogit11 * DLogit11&#x2F;Dh13 + DL&#x2F;DLogit12 * DLogit12&#x2F;Dh13 = DL&#x2F;Dlogit11 * w31 + DL&#x2F;DLogit12 * w32<p>DL&#x2F;Dh21 = DL&#x2F;DLogit21 * DLogit21&#x2F;Dh21 + DL&#x2F;DLogit22 * DLogit22&#x2F;Dh21 = DL&#x2F;Dlogit21 * w11 + DL&#x2F;DLogit22 * w12<p>DL&#x2F;Dh22 = DL&#x2F;DLogit21 * DLogit21&#x2F;Dh22 + DL&#x2F;DLogit22 * DLogit22&#x2F;Dh22 = DL&#x2F;Dlogit21 * w21 + DL&#x2F;DLogit22 * w22<p>DL&#x2F;Dh23 = DL&#x2F;DLogit21 * DLogit21&#x2F;Dh23 + DL&#x2F;DLogit22 * DLogit22&#x2F;Dh23 = DL&#x2F;Dlogit21 * w31 + DL&#x2F;DLogit22 * w32<p>DL&#x2F;Dh = [<p><pre><code>    DL&#x2F;Dh11 DL&#x2F;Dh12 DL&#x2F;Dh13

    DL&#x2F;Dh21 DL&#x2F;Dh22 DL&#x2F;Dh23
</code></pre>
] = [[DL&#x2F;Dlogit11 DL&#x2F;Dlogit12], @ [[w11 w21 w31],<p><pre><code>    [DL&#x2F;Dlogit21 DL&#x2F;Dlogit22]]     [w12 w22 w32]]
</code></pre>
= DL&#x2F;Dlogit * W^T -------------&gt; This is the final gradient and note that it is a matrix multiplication or a projection of the logit gradient on the Weight layer<p>Now lets compute DL&#x2F;dW<p>DL&#x2F;dW = DL&#x2F;DLogit * DLogit&#x2F;DW<p>DL&#x2F;DW11 = DL&#x2F;DLogit11 * DLogit11&#x2F;DW11 + DL&#x2F;Dlogit21 * Dlogit21&#x2F;DW11 = DL&#x2F;DLogit11 * h11 + DL&#x2F;Dlogit21 * h21<p>DL&#x2F;DW12 = DL&#x2F;DLogit12 * DLogit12&#x2F;DW12 + DL&#x2F;Dlogit22 * Dlogit22&#x2F;DW12 = DL&#x2F;DLogit12 * h11 + DL&#x2F;Dlogit22 * h21<p>DL&#x2F;DW21 = DL&#x2F;DLogit11 * DLogit11&#x2F;DW21 + DL&#x2F;Dlogit21 * Dlogit21&#x2F;DW21 = DL&#x2F;DLogit11 * h12 + DL&#x2F;Dlogit21 * h22<p>DL&#x2F;DW22 = DL&#x2F;DLogit12 * DLogit12&#x2F;DW22 + DL&#x2F;Dlogit22 * Dlogit22&#x2F;DW22 = DL&#x2F;DLogit12 * h12 + DL&#x2F;Dlogit22 * h22<p>DL&#x2F;DW31 = DL&#x2F;DLogit11 * DLogit11&#x2F;DW31 + DL&#x2F;Dlogit21 * Dlogit21&#x2F;DW31 = DL&#x2F;DLogit11 * h13 + DL&#x2F;Dlogit21 * h23<p>DL&#x2F;DW32 = DL&#x2F;DLogit12 * DLogit12&#x2F;DW32 + DL&#x2F;Dlogit22 * Dlogit22&#x2F;DW32 = DL&#x2F;DLogit12 * h13 + DL&#x2F;Dlogit22 * h23<p>DL&#x2F;DW = [[h11 h21] @ [[DL&#x2F;DLogit11, DL&#x2F;DLogit12]<p><pre><code>         [h12 h22]     [DL&#x2F;DLogit21, DL&#x2F;DLogit22]]

         [h13 h23]

        ]

        = h^T @ DL&#x2F;DLogit -------------&gt; This is the final gradient and note that it is a matrix multiplication or a projection of the logit gradient on the hidden layer.</code></pre>
```</div><br/></div></div></div></div><div id="39058873" class="c"><input type="checkbox" id="c-39058873" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#39062797">prev</a><span>|</span><a href="#39059755">next</a><span>|</span><label class="collapse" for="c-39058873">[-]</label><label class="expand" for="c-39058873">[10 more]</label></div><br/><div class="children"><div class="content">Nice blog. I&#x27;ll be provocative&#x2F;pedantic for no good reason and say that what&#x27;s described isn&#x27;t &quot;calculus&quot; per se, because you can&#x27;t do calculus on discrete objects like a graph. However, you can define the derivative purely algebraically (as a linear operation which satisfies the Leibniz chain&#x2F;product rule), which is more accurately what is being described.</div><br/><div id="39059443" class="c"><input type="checkbox" id="c-39059443" checked=""/><div class="controls bullet"><span class="by">philipfweiss</span><span>|</span><a href="#39058873">parent</a><span>|</span><a href="#39064491">next</a><span>|</span><label class="collapse" for="c-39059443">[-]</label><label class="expand" for="c-39059443">[2 more]</label></div><br/><div class="children"><div class="content">You’re not doing calculus on a graph- you’re using a graph algorithm to automate the derivative taking process.<p>Essentially, you transform your function into a “circuit” or just a graph with edge labels according to the relationship between parts of the expression. The circuit has the nice property that there is an algorithm you can run on it, with very simple rules, which gets you the derivative of the function used to create that circuit.<p>So taking the derivative becomes:<p>1. Transform function F into circuit C. 
2. Run compute_gradiant(c) to get the gradient of F.<p>Lots of useful examples here: <a href="https:&#x2F;&#x2F;cs231n.github.io&#x2F;optimization-2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cs231n.github.io&#x2F;optimization-2&#x2F;</a></div><br/><div id="39062769" class="c"><input type="checkbox" id="c-39062769" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39058873">root</a><span>|</span><a href="#39059443">parent</a><span>|</span><a href="#39064491">next</a><span>|</span><label class="collapse" for="c-39062769">[-]</label><label class="expand" for="c-39062769">[1 more]</label></div><br/><div class="children"><div class="content">That is a great example. It&#x27;s rarely bad to be pedantic if it leads to better understanding!</div><br/></div></div></div></div><div id="39064491" class="c"><input type="checkbox" id="c-39064491" checked=""/><div class="controls bullet"><span class="by">gatane</span><span>|</span><a href="#39058873">parent</a><span>|</span><a href="#39059443">prev</a><span>|</span><a href="#39059951">next</a><span>|</span><label class="collapse" for="c-39064491">[-]</label><label class="expand" for="c-39064491">[1 more]</label></div><br/><div class="children"><div class="content">Pardon? The more it changes...
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Discrete_calculus#Calculus_of_differences_and_sums" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Discrete_calculus#Calculus_of_...</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Calculus_on_finite_weighted_graphs" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Calculus_on_finite_weighted_gr...</a><p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;D0EUFP7-P1M?si=y1JSriU4mZ9nzntK" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;D0EUFP7-P1M?si=y1JSriU4mZ9nzntK</a></div><br/></div></div><div id="39059951" class="c"><input type="checkbox" id="c-39059951" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#39058873">parent</a><span>|</span><a href="#39064491">prev</a><span>|</span><a href="#39061856">next</a><span>|</span><label class="collapse" for="c-39059951">[-]</label><label class="expand" for="c-39059951">[2 more]</label></div><br/><div class="children"><div class="content">If we&#x27;re being pedantic, then there&#x27;s also a more general definition of calculus, which is the first definition in Merriam-Webster: &quot;a method of computation or calculation in a special notation (as of logic or symbolic logic).&quot; One example of this is the lambda calculus. Differential and integral calculus are just special cases of this general definition.</div><br/><div id="39060536" class="c"><input type="checkbox" id="c-39060536" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#39058873">root</a><span>|</span><a href="#39059951">parent</a><span>|</span><a href="#39061856">next</a><span>|</span><label class="collapse" for="c-39060536">[-]</label><label class="expand" for="c-39060536">[1 more]</label></div><br/><div class="children"><div class="content">Right but this is about differential calculus (the chain rule)</div><br/></div></div></div></div><div id="39061856" class="c"><input type="checkbox" id="c-39061856" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#39058873">parent</a><span>|</span><a href="#39059951">prev</a><span>|</span><a href="#39064499">next</a><span>|</span><label class="collapse" for="c-39061856">[-]</label><label class="expand" for="c-39061856">[2 more]</label></div><br/><div class="children"><div class="content">&gt;because you can&#x27;t do calculus on discrete objects like a graph<p>Of course you can, what do you think shift operators and recurrence relations are?
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Finite_difference?#Calculus_of_finite_differences" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Finite_difference?#Calculus_of...</a></div><br/><div id="39063799" class="c"><input type="checkbox" id="c-39063799" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#39058873">root</a><span>|</span><a href="#39061856">parent</a><span>|</span><a href="#39064499">next</a><span>|</span><label class="collapse" for="c-39063799">[-]</label><label class="expand" for="c-39063799">[1 more]</label></div><br/><div class="children"><div class="content">All fields are graphs.<p>We do calculus to predict behavior in fields.<p>We observe metrics and conservational symmetry 
(or not) over paths in fields.<p>Nonlinearity is approximated with backpropagation.<p>What are field operators (graph operators)?</div><br/></div></div></div></div><div id="39064499" class="c"><input type="checkbox" id="c-39064499" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39058873">parent</a><span>|</span><a href="#39061856">prev</a><span>|</span><a href="#39058922">next</a><span>|</span><label class="collapse" for="c-39064499">[-]</label><label class="expand" for="c-39064499">[1 more]</label></div><br/><div class="children"><div class="content">That’s not what’s being done here.</div><br/></div></div></div></div><div id="39059755" class="c"><input type="checkbox" id="c-39059755" checked=""/><div class="controls bullet"><span class="by">coolThingsFirst</span><span>|</span><a href="#39058873">prev</a><span>|</span><label class="collapse" for="c-39059755">[-]</label><label class="expand" for="c-39059755">[10 more]</label></div><br/><div class="children"><div class="content">I still don’t understand the process of learning ML, like sure we build micrograd but is it only didactic exercise or can we use it to train it to do something serious on our own hardware?</div><br/><div id="39060529" class="c"><input type="checkbox" id="c-39060529" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#39059755">parent</a><span>|</span><a href="#39059815">next</a><span>|</span><label class="collapse" for="c-39060529">[-]</label><label class="expand" for="c-39060529">[3 more]</label></div><br/><div class="children"><div class="content">I don’t understand this comment, for one we’re engineers&#x2F;hackers and should be curious how this stuff works.  It’s exciting.  Practically speaking this is like asking why learn how to write a simple forum or blog when we can’t host Facebook on our on hardware: it’s going to be hard to work on the latest models if you don’t first understand the basics.</div><br/><div id="39061400" class="c"><input type="checkbox" id="c-39061400" checked=""/><div class="controls bullet"><span class="by">coolThingsFirst</span><span>|</span><a href="#39059755">root</a><span>|</span><a href="#39060529">parent</a><span>|</span><a href="#39059815">next</a><span>|</span><label class="collapse" for="c-39061400">[-]</label><label class="expand" for="c-39061400">[2 more]</label></div><br/><div class="children"><div class="content">You learn what Db is you can use a db for your own custom task.<p>What so i do with micrograd? Hang the code on my wall?</div><br/><div id="39062577" class="c"><input type="checkbox" id="c-39062577" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#39059755">root</a><span>|</span><a href="#39061400">parent</a><span>|</span><a href="#39059815">next</a><span>|</span><label class="collapse" for="c-39062577">[-]</label><label class="expand" for="c-39062577">[1 more]</label></div><br/><div class="children"><div class="content">Yes exactly.  Learn this so you can then apply it to your own software</div><br/></div></div></div></div></div></div><div id="39059815" class="c"><input type="checkbox" id="c-39059815" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#39059755">parent</a><span>|</span><a href="#39060529">prev</a><span>|</span><a href="#39060015">next</a><span>|</span><label class="collapse" for="c-39059815">[-]</label><label class="expand" for="c-39059815">[1 more]</label></div><br/><div class="children"><div class="content">This is like building a tiny C compiler. At some program scale, optimizations become important.</div><br/></div></div><div id="39060015" class="c"><input type="checkbox" id="c-39060015" checked=""/><div class="controls bullet"><span class="by">pmelendez</span><span>|</span><a href="#39059755">parent</a><span>|</span><a href="#39059815">prev</a><span>|</span><a href="#39060567">next</a><span>|</span><label class="collapse" for="c-39060015">[-]</label><label class="expand" for="c-39060015">[1 more]</label></div><br/><div class="children"><div class="content">&gt;do something serious<p>I guess it depends on what you mean by serious. Pre-training a competitive LLM with current methods and consumer hardware is prohibitive for sure. Solving a classification problem could be totally doable depending on the domain.</div><br/></div></div><div id="39060567" class="c"><input type="checkbox" id="c-39060567" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#39059755">parent</a><span>|</span><a href="#39060015">prev</a><span>|</span><a href="#39061774">next</a><span>|</span><label class="collapse" for="c-39060567">[-]</label><label class="expand" for="c-39060567">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;ll probably need some hardware acceleration. There&#x27;s a good course that builds something like micrograd in the beginning and extends on it: <a href="https:&#x2F;&#x2F;dlsyscourse.org&#x2F;lectures&#x2F;" rel="nofollow">https:&#x2F;&#x2F;dlsyscourse.org&#x2F;lectures&#x2F;</a></div><br/><div id="39061423" class="c"><input type="checkbox" id="c-39061423" checked=""/><div class="controls bullet"><span class="by">coolThingsFirst</span><span>|</span><a href="#39059755">root</a><span>|</span><a href="#39060567">parent</a><span>|</span><a href="#39061774">next</a><span>|</span><label class="collapse" for="c-39061423">[-]</label><label class="expand" for="c-39061423">[2 more]</label></div><br/><div class="children"><div class="content">I have a 3060 Ti, that enough?</div><br/><div id="39062701" class="c"><input type="checkbox" id="c-39062701" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#39059755">root</a><span>|</span><a href="#39061423">parent</a><span>|</span><a href="#39061774">next</a><span>|</span><label class="collapse" for="c-39062701">[-]</label><label class="expand" for="c-39062701">[1 more]</label></div><br/><div class="children"><div class="content">It should be worth to do these kind of hardware accelerations with any kind of hardware that has more TFlop&#x2F;s (and memory bandwidth) than your CPU basically.<p>I mean, enough for what?</div><br/></div></div></div></div></div></div><div id="39061774" class="c"><input type="checkbox" id="c-39061774" checked=""/><div class="controls bullet"><span class="by">genman</span><span>|</span><a href="#39059755">parent</a><span>|</span><a href="#39060567">prev</a><span>|</span><label class="collapse" for="c-39061774">[-]</label><label class="expand" for="c-39061774">[1 more]</label></div><br/><div class="children"><div class="content">You can totally do some visual classification problems (like object detection) on current consumer hardware. Even more. You can also take some smaller existing language models and fine tune them for some special task - also completely feasible.</div><br/></div></div></div></div></div></div></div></div></div></body></html>