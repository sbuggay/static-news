<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721379649402" as="style"/><link rel="stylesheet" href="styles.css?v=1721379649402"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/mutableai/status/1813815706783490055">Show HN: How we leapfrogged traditional vector based RAG with a &#x27;language map&#x27;</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>oshams</span> | <span>21 comments</span></div><br/><div><div id="41003540" class="c"><input type="checkbox" id="c-41003540" checked=""/><div class="controls bullet"><span class="by">senko</span><span>|</span><a href="#41002519">next</a><span>|</span><label class="collapse" for="c-41003540">[-]</label><label class="expand" for="c-41003540">[1 more]</label></div><br/><div class="children"><div class="content">Looks similar to what we&#x27;re doing in Pythagora with CodeMonkey agent (prompt: <a href="https:&#x2F;&#x2F;github.com&#x2F;Pythagora-io&#x2F;gpt-pilot&#x2F;blob&#x2F;main&#x2F;core&#x2F;prompts&#x2F;code-monkey&#x2F;describe_file.prompt">https:&#x2F;&#x2F;github.com&#x2F;Pythagora-io&#x2F;gpt-pilot&#x2F;blob&#x2F;main&#x2F;core&#x2F;pro...</a>, code: <a href="https:&#x2F;&#x2F;github.com&#x2F;Pythagora-io&#x2F;gpt-pilot&#x2F;blob&#x2F;main&#x2F;core&#x2F;agents&#x2F;code_monkey.py#L91">https:&#x2F;&#x2F;github.com&#x2F;Pythagora-io&#x2F;gpt-pilot&#x2F;blob&#x2F;main&#x2F;core&#x2F;age...</a>)<p>I think everyone who&#x27;s seriously tackled the &quot;code RAG&quot; problem is aware a naive vector approach doesn&#x27;t work, and some hybrid approach is needed (see also Paul&#x27;s comments on Aider).<p>Intuitively, I expect a combo of lsp&#x2F;treesitter directed by LLM + vector-RAG over &quot;wiki&quot; &#x2F; metadata would be a viable approach.<p>Very exciting to see all the research into this!</div><br/></div></div><div id="41002519" class="c"><input type="checkbox" id="c-41002519" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#41003540">prev</a><span>|</span><a href="#41002186">next</a><span>|</span><label class="collapse" for="c-41002519">[-]</label><label class="expand" for="c-41002519">[4 more]</label></div><br/><div class="children"><div class="content">I agree that many AI coding tools have rushed to adopt naive RAG on code.<p>Have you done any quantitative evaluation of your wiki style code summaries? My first impression is that they might be too wordy and not deliver valuable context in a token efficient way.<p>Aider uses a repository map [0] to deliver code context. Relevant code is identified  using a graph optimization on the repository&#x27;s AST &amp; call graph, not vector similarity as is typical with RAG. The repo map shows the selected code within its AST context.<p>Aider currently holds the 2nd highest score on the main SWE Bench [1], without doing any code RAG. So there is some evidence that the repo map is effective at helping the LLM understand large code bases.<p>[0] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;repomap.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;repomap.html</a><p>[1] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;06&#x2F;02&#x2F;main-swe-bench.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;06&#x2F;02&#x2F;main-swe-bench.html</a></div><br/><div id="41002895" class="c"><input type="checkbox" id="c-41002895" checked=""/><div class="controls bullet"><span class="by">lemming</span><span>|</span><a href="#41002519">parent</a><span>|</span><a href="#41002186">next</a><span>|</span><label class="collapse" for="c-41002895">[-]</label><label class="expand" for="c-41002895">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been thinking about this a lot recently. So in Aider, it looks like &quot;importance&quot; is based on just the number of references to a particular file, is that right?<p>It seems like in a large repo, you&#x27;d want to have a summary of, say, each module, and what its main functions are, and allow the LLM to request repo maps of parts of the repo based on those summaries. e.g. in my website project, I have a documentation module, a client side module, a server side module, and a deployment module. It seems like it would be good for the AI to be able to determine that a particular request requires changes to the client and server parts, and just request those.</div><br/><div id="41003014" class="c"><input type="checkbox" id="c-41003014" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#41002519">root</a><span>|</span><a href="#41002895">parent</a><span>|</span><a href="#41002186">next</a><span>|</span><label class="collapse" for="c-41003014">[-]</label><label class="expand" for="c-41003014">[2 more]</label></div><br/><div class="children"><div class="content">The repo map is computed dynamically, based on the current contents of the coding chat. So &quot;importance&quot; is relative to that, and will pull out the parts of each file which are most relevant to the task at hand.</div><br/><div id="41003247" class="c"><input type="checkbox" id="c-41003247" checked=""/><div class="controls bullet"><span class="by">lemming</span><span>|</span><a href="#41002519">root</a><span>|</span><a href="#41003014">parent</a><span>|</span><a href="#41002186">next</a><span>|</span><label class="collapse" for="c-41003247">[-]</label><label class="expand" for="c-41003247">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, how does Aider decide what’s relevant to the chat?</div><br/></div></div></div></div></div></div></div></div><div id="41002186" class="c"><input type="checkbox" id="c-41002186" checked=""/><div class="controls bullet"><span class="by">langcss</span><span>|</span><a href="#41002519">prev</a><span>|</span><a href="#41002509">next</a><span>|</span><label class="collapse" for="c-41002186">[-]</label><label class="expand" for="c-41002186">[4 more]</label></div><br/><div class="children"><div class="content">This sort of approach always made more sense to me than RAG. I am less likely to try RAG than something that feeds the LLM what it actually needs. RAG is risky in providing piecemeal information that confuses the LLM.<p>The way I thought would work and like to try out is ask the LLM what info it wants next from an index of contents. Like a book. That index can be LLM generated or not. Then backtrack as you don&#x27;t need that lookup in your dialogue any more and insert the result.<p>It won&#x27;t work for everything but should work for many &quot;small expert&quot; cases and you then don&#x27;t need a vector DB you just do prompts!<p>Cheap LLMs make this more viable perhaps than it used to be. Use an open source small LLM for the decision making then a quality open source or proprietary LLM for the chat or code gen.</div><br/><div id="41002613" class="c"><input type="checkbox" id="c-41002613" checked=""/><div class="controls bullet"><span class="by">PhilippGille</span><span>|</span><a href="#41002186">parent</a><span>|</span><a href="#41002509">next</a><span>|</span><label class="collapse" for="c-41002613">[-]</label><label class="expand" for="c-41002613">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still RAG, just the R in RAG is not vector-based anymore, no?</div><br/><div id="41003119" class="c"><input type="checkbox" id="c-41003119" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#41002186">root</a><span>|</span><a href="#41002613">parent</a><span>|</span><a href="#41002509">next</a><span>|</span><label class="collapse" for="c-41003119">[-]</label><label class="expand" for="c-41003119">[2 more]</label></div><br/><div class="children"><div class="content">What you describe sounds like Agetic RAG <a href="https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;agentic-rag" rel="nofollow">https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;agentic-rag</a></div><br/><div id="41003434" class="c"><input type="checkbox" id="c-41003434" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41002186">root</a><span>|</span><a href="#41003119">parent</a><span>|</span><a href="#41002509">next</a><span>|</span><label class="collapse" for="c-41003434">[-]</label><label class="expand" for="c-41003434">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The traditional way to do RAG is to find information relevant to a query - and then incorporate it into the LLM prompt together with the question we want it to answer.<p>Technically this is incorrect. The original RAG paper used a seq2seq generator (BART) and involved two methods: RAG sequence and RAG token.<p>RAG sequence used the same fixed documents and appended them to the input query (note, this is different from a decoder-only model). RAG token generates each token based on a different document.<p>I only nitpick this because if someone is going to invent new fancy-sounding variants of RAG they should at least get the basics right.</div><br/></div></div></div></div></div></div></div></div><div id="41002509" class="c"><input type="checkbox" id="c-41002509" checked=""/><div class="controls bullet"><span class="by">tlarkworthy</span><span>|</span><a href="#41002186">prev</a><span>|</span><a href="#41001803">next</a><span>|</span><label class="collapse" for="c-41002509">[-]</label><label class="expand" for="c-41002509">[1 more]</label></div><br/><div class="children"><div class="content">This is literate programming! Why not just put the codebase in the wiki and not have two representations diverging. Why can&#x27;t we have diagrams and links in code??? We can, like <a href="https:&#x2F;&#x2F;observablehq.com" rel="nofollow">https:&#x2F;&#x2F;observablehq.com</a> notebooks, it&#x27;s a better representation for understanding.</div><br/></div></div><div id="41001803" class="c"><input type="checkbox" id="c-41001803" checked=""/><div class="controls bullet"><span class="by">spirobelv2</span><span>|</span><a href="#41002509">prev</a><span>|</span><a href="#41001922">next</a><span>|</span><label class="collapse" for="c-41001803">[-]</label><label class="expand" for="c-41001803">[1 more]</label></div><br/><div class="children"><div class="content">it wants me to login to ask a question<p>I will just keep using phind<p>you have vc dollars - sponsor a public free search over open source repos.<p>Also think about what happens when your question touches multiple repos.<p>I tried a similar &quot;search github repo with ai&quot; product before, but it led me right back to phind, when it couldnt answer a question that required specific information from the repositiory as well as a google search.</div><br/></div></div></div></div></div></div></div></body></html>