<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710493274638" as="style"/><link rel="stylesheet" href="styles.css?v=1710493274638"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/">How Figma&#x27;s databases team lived to tell the scale</a> <span class="domain">(<a href="https://www.figma.com">www.figma.com</a>)</span></div><div class="subtext"><span>pinser98</span> | <span>211 comments</span></div><br/><div><div id="39710018" class="c"><input type="checkbox" id="c-39710018" checked=""/><div class="controls bullet"><span class="by">thekhatribharat</span><span>|</span><a href="#39707437">next</a><span>|</span><label class="collapse" for="c-39710018">[-]</label><label class="expand" for="c-39710018">[18 more]</label></div><br/><div class="children"><div class="content">1. They mention that the largest tables ran into several TBs, and they would have soon topped the max IOPS supported by RDS. RDS for PostgreSQL peaks at 256,000 IOPS for a 64 TB volume. For a multi-AZ setup, this costs ~$70K&#x2F;mo.<p>2. Let&#x27;s assume the final outcome was a 5-way shard with each shard supporting ~50,000 IOPS and ~12 TB data. For a multi-AZ setup, this costs ~$100K&#x2F;mo.<p>3. It took 9 months to shard their first table. Since it required application changes as well, let&#x27;s assume this was 9mo * 20 work days&#x2F;mo * (3 DB engineers + 2 app engineers) = 900 work days. Even at $100K avg. annual pay for an engineer, this is ~$400K.<p>4. A PostgreSQL-compatible NewSQL like YugabyteDB should cost ~$15K&#x2F;mo to match top-of-the-line RDS performance. So Figma spent ~25x ($400K&#x2F;$15K) to implement horizontal sharding in-house, and is still on RDS which costs ~6x ($100K&#x2F;$15K)</div><br/><div id="39710689" class="c"><input type="checkbox" id="c-39710689" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#39710018">parent</a><span>|</span><a href="#39711428">next</a><span>|</span><label class="collapse" for="c-39710689">[-]</label><label class="expand" for="c-39710689">[3 more]</label></div><br/><div class="children"><div class="content">&gt; A PostgreSQL-compatible NewSQL like YugabyteDB should cost ~$15K&#x2F;mo to match top-of-the-line RDS performance.<p>&quot;to match&quot; is doing a lot of work here. It&#x27;s extremely unwise that a &quot;compatible&quot; database will have the same performance characteristics and no performance cliffs.<p>&gt; So Figma spent ~25x ($400K&#x2F;$15K)<p>They nearly got acquired for $20B, I don&#x27;t think they give a hoot about 400K if it means keeping their stack the same and getting to keep all of the existing organizational knowledge about how to keep the thing online.</div><br/><div id="39711071" class="c"><input type="checkbox" id="c-39711071" checked=""/><div class="controls bullet"><span class="by">__float</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710689">parent</a><span>|</span><a href="#39711032">next</a><span>|</span><label class="collapse" for="c-39711071">[-]</label><label class="expand" for="c-39711071">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re also using sticker pricing, which as we know is likely far from what they actually paid.<p>(And the rest of the argument sounds a lot like our former employer with their...choice of document DB :) which I&#x27;ll defend too!)</div><br/></div></div><div id="39711032" class="c"><input type="checkbox" id="c-39711032" checked=""/><div class="controls bullet"><span class="by">thanksgiving</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710689">parent</a><span>|</span><a href="#39711071">prev</a><span>|</span><a href="#39711428">next</a><span>|</span><label class="collapse" for="c-39711032">[-]</label><label class="expand" for="c-39711032">[1 more]</label></div><br/><div class="children"><div class="content">That’s the problem with case studies, isn’t it? 
What works for one company in one industry might be a death sentence for another organization with slimmer margins…</div><br/></div></div></div></div><div id="39711428" class="c"><input type="checkbox" id="c-39711428" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#39710018">parent</a><span>|</span><a href="#39710689">prev</a><span>|</span><a href="#39710565">next</a><span>|</span><label class="collapse" for="c-39711428">[-]</label><label class="expand" for="c-39711428">[1 more]</label></div><br/><div class="children"><div class="content">Figma, worth $10billion, was migrating what seems like their core production data. They probably didn&#x27;t want to bet the company on a comparatively small software vendor like Yugabyte.<p>Most likely the engineering cost was much much higher than your quotes, but still insignificant compared to the potential risks. And migrating from RDS to not-RDS could easily not have been cheap in engineering time either, depending on how much software they&#x27;ve built around it.</div><br/></div></div><div id="39710565" class="c"><input type="checkbox" id="c-39710565" checked=""/><div class="controls bullet"><span class="by">jimbokun</span><span>|</span><a href="#39710018">parent</a><span>|</span><a href="#39711428">prev</a><span>|</span><a href="#39710160">next</a><span>|</span><label class="collapse" for="c-39710565">[-]</label><label class="expand" for="c-39710565">[1 more]</label></div><br/><div class="children"><div class="content">Past a certain data size, migrations are always a nightmare.  For a much longer time than what you initially estimated, you are managing two systems with all the related operational costs and complexity, as well as all of the IOPs and bandwidth migrating the data.<p>I imagine scaling out RDS instead mitigated a lot of those costs.</div><br/></div></div><div id="39710160" class="c"><input type="checkbox" id="c-39710160" checked=""/><div class="controls bullet"><span class="by">avianlyric</span><span>|</span><a href="#39710018">parent</a><span>|</span><a href="#39710565">prev</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39710160">[-]</label><label class="expand" for="c-39710160">[10 more]</label></div><br/><div class="children"><div class="content">Their rationale for this choice is covered in the article somewhat extensively near the top.<p>&gt; Additionally, over the past few years, we’ve developed a lot of expertise on how to reliably and performantly run RDS Postgres in-house. While migrating, we would have had to rebuild our domain expertise from scratch. Given our very aggressive growth rate, we had only months of runway remaining. De-risking an entirely new storage layer and completing an end-to-end-migration of our most business-critical use cases would have been extremely risky on the necessary timeline. We favored known low-risk solutions over potentially easier options with much higher uncertainty, where we had less control over the outcome.<p>TL;DR they were working in a short timeline, with a limited team size, and wanted to minimise any risks to the business.<p>Clearly cost is an issue for Figma, but downtime, or worse data loss, would have a ginormous impact on their business and potential future growth. If your product is already profitable, your user base growing fast, and with your ARR. Why would risk that growth and future ARR just to save a few $10Ks a month? A very low risk DB migration that lets you keep scaling and raking in more money, is way better than a high risk migration that might save some cash in the long term, but also risks killing your primary business if it goes wrong.</div><br/><div id="39710342" class="c"><input type="checkbox" id="c-39710342" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710160">parent</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39710342">[-]</label><label class="expand" for="c-39710342">[9 more]</label></div><br/><div class="children"><div class="content">Ok, what risk? Cockroachdb is already proven technology and costs marginally more (if you use their serverless setup, it&#x27;s free until you hit real scale). At the startups I&#x27;ve been at that hit scale, scaling sql was always a massive undertaking and affected product development on every single time.<p>If you don&#x27;t want downtime, don&#x27;t use databases that require downtime to do a migration?<p>Netflix, roblox, every single online gambling website all use cockroachdb.</div><br/><div id="39710409" class="c"><input type="checkbox" id="c-39710409" checked=""/><div class="controls bullet"><span class="by">martin-adams</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710342">parent</a><span>|</span><a href="#39710445">next</a><span>|</span><label class="collapse" for="c-39710409">[-]</label><label class="expand" for="c-39710409">[2 more]</label></div><br/><div class="children"><div class="content">Sounds like their discomfort was in the migration path to &#x27;any other database&#x27; alongside not having the experience with another database to mitigate any unknown unknowns.<p>&gt; During our evaluation, we explored CockroachDB, TiDB, Spanner, and Vitess. However, switching to any of these alternative databases would have required a complex data migration to ensure consistency and reliability across two different database stores.</div><br/><div id="39713148" class="c"><input type="checkbox" id="c-39713148" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710409">parent</a><span>|</span><a href="#39710445">next</a><span>|</span><label class="collapse" for="c-39713148">[-]</label><label class="expand" for="c-39713148">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ensure consistency and reliability across two different database stores.<p>This is main known known. And this is hard thing to attain.<p>My favorite story on that is testing of tendermint consensus implementation [1]. The testing process found a way to break the consensus and the reason was that protocol implementation and KV store controlled by protocol used different databases.<p>[1] <a href="https:&#x2F;&#x2F;jepsen.io&#x2F;analyses&#x2F;tendermint-0-10-2" rel="nofollow">https:&#x2F;&#x2F;jepsen.io&#x2F;analyses&#x2F;tendermint-0-10-2</a></div><br/></div></div></div></div><div id="39710445" class="c"><input type="checkbox" id="c-39710445" checked=""/><div class="controls bullet"><span class="by">kamikaz1k</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710342">parent</a><span>|</span><a href="#39710409">prev</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39710445">[-]</label><label class="expand" for="c-39710445">[6 more]</label></div><br/><div class="children"><div class="content">Never used cockroach so pardon my ignorance, but are there no operational challenges with running&#x2F;using them? Or are they the same challenges? And how compatible is it from an application developer perspective?</div><br/><div id="39710513" class="c"><input type="checkbox" id="c-39710513" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710445">parent</a><span>|</span><a href="#39711119">next</a><span>|</span><label class="collapse" for="c-39710513">[-]</label><label class="expand" for="c-39710513">[1 more]</label></div><br/><div class="children"><div class="content">The managed service is hassle free and it&#x27;s auto sharded so you don&#x27;t have traditional scaling issues. You do need to think about how your index choices spread writes and reads on the cluster to avoid hotspots. It&#x27;s almost completely compatible with postgres wire protocol but it doesn&#x27;t support things like extensions for the most part.</div><br/></div></div><div id="39711119" class="c"><input type="checkbox" id="c-39711119" checked=""/><div class="controls bullet"><span class="by">MarkMarine</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710445">parent</a><span>|</span><a href="#39710513">prev</a><span>|</span><a href="#39710521">next</a><span>|</span><label class="collapse" for="c-39711119">[-]</label><label class="expand" for="c-39711119">[1 more]</label></div><br/><div class="children"><div class="content">There are TONS of operational issues running cockroach. At the last company I was at cockroach was probably over used as a magical way to run multiple DCs and keep things consistent without high developer overhead, but it was #1 source of large outages. So much so that we’d run a cockroach segmented out for a single microservice to limit the blast radius when it eventually failed.<p>That and its comically more expensive than Postgres, if you think IOPs are expensive wait till you see the service contract.</div><br/></div></div><div id="39710521" class="c"><input type="checkbox" id="c-39710521" checked=""/><div class="controls bullet"><span class="by">jamra</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710445">parent</a><span>|</span><a href="#39711119">prev</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39710521">[-]</label><label class="expand" for="c-39710521">[3 more]</label></div><br/><div class="children"><div class="content">CRDB is Postgres compliant so the wire protocol and SQL syntax is all Postgres. It should be a 1 to 1.</div><br/><div id="39710577" class="c"><input type="checkbox" id="c-39710577" checked=""/><div class="controls bullet"><span class="by">jimbokun</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710521">parent</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39710577">[-]</label><label class="expand" for="c-39710577">[2 more]</label></div><br/><div class="children"><div class="content">Are all the corresponding latencies for every query one to one too?</div><br/><div id="39711244" class="c"><input type="checkbox" id="c-39711244" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#39710018">root</a><span>|</span><a href="#39710577">parent</a><span>|</span><a href="#39711307">next</a><span>|</span><label class="collapse" for="c-39711244">[-]</label><label class="expand" for="c-39711244">[1 more]</label></div><br/><div class="children"><div class="content">In ye olden times I used to stop bosses from throwing away the slowest machine we had, and try to get at least one faster machine.<p>It’s still somewhat the case, but at the time the world was rotten with concurrent code that only worked because an implicit invariant (almost) always held. One that was enforced by the relative time or latency involved with two competing tasks. Get new motherboards or storage or memory and that invariant goes from failing only when the exact right packet loss happens, to failing every day, or hour, or minute.<p>Yes, it’s a bug, but it wasn’t on your radar and the system was trucking along yesterday and now everything is on fire.<p>The people who know this think the parent is a very interesting question. The people who don’t, tend to think it’s a non sequitur.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39710090" class="c"><input type="checkbox" id="c-39710090" checked=""/><div class="controls bullet"><span class="by">chikitabanana</span><span>|</span><a href="#39710018">parent</a><span>|</span><a href="#39711307">prev</a><span>|</span><a href="#39707437">next</a><span>|</span><label class="collapse" for="c-39710090">[-]</label><label class="expand" for="c-39710090">[1 more]</label></div><br/><div class="children"><div class="content">bhai, use the western numbering system, for clarity&#x27;s sake. Thanks for the summary</div><br/></div></div></div></div><div id="39707437" class="c"><input type="checkbox" id="c-39707437" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#39710018">prev</a><span>|</span><a href="#39712205">next</a><span>|</span><label class="collapse" for="c-39707437">[-]</label><label class="expand" for="c-39707437">[60 more]</label></div><br/><div class="children"><div class="content">One thought that comes up: Wouldn’t it be easier to have each customer in their own (logical) database? I mean, you don’t need transactions across different customers, right? So you’re essentially solving a harder problem than the one you’ve got.<p>Not sure postgres (logical) databases would scale that well, but don’t see a principal reason why it couldn’t. Has anyone explored this further?</div><br/><div id="39709671" class="c"><input type="checkbox" id="c-39709671" checked=""/><div class="controls bullet"><span class="by">tharkun__</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39708605">next</a><span>|</span><label class="collapse" for="c-39709671">[-]</label><label class="expand" for="c-39709671">[7 more]</label></div><br/><div class="children"><div class="content">Yes, we&#x27;ve been doing that at my place basically since the start. Each tenant is a schema in postgres. Works perfectly fine on the one hand, i.e. your tables don&#x27;t grow to &#x27;infinity&#x27; just because you&#x27;re adding more and more tenants. If there&#x27;s a particular tenant that has lots of data, only that tenant&#x27;s indexes and tables grow huge and become slower because of that particular reason etc. If a tenant leaves, you keep the schema around for some time, so they can come back and then at some point you just drop the schema!<p>It does mean having to upgrade each schema individually, which also makes it both easier and harder. Easier because the tables are smaller, so any schema changes that require things like say a table lock, are locking for a smaller amount of time and won&#x27;t affect more than the one tenant at a given time. It also means that you can get into an inconsistent state of course, where some of your tenants have all the latest DB upgrades, while it failed on another subset.<p>At some point Postgres&#x27;s internal tables become a bit of a &quot;problem&quot;, as you want to run as many of these updates in parallel as you can for speed, which could lead to contention on Postgres&#x27; administrative side. You&#x27;ll also still need to shard across multiple actual RDS instances, because you still have many tenants running against a single physical piece of hardware that will show its limitations if too many large or active tenants happen to be on the same shard.<p>And then you have the problem of keeping a record of which physical RDS instance (i.e. shard) the tenant is on. Your application code will need to look that up (and cache that info for some time ;)) and you have some choice there as well. I.e. do you shard those as well and juggle load balancing as basically a 1:1 mapping to shards or do you have your application layer connect to <i>all</i> database shards and handle <i>any</i> tenants? One is more complicated I would say while the other could run out of connections depending on how you need to scale the application layer and what kind of RDS instance you have.</div><br/><div id="39710573" class="c"><input type="checkbox" id="c-39710573" checked=""/><div class="controls bullet"><span class="by">neeleshs</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709671">parent</a><span>|</span><a href="#39710157">next</a><span>|</span><label class="collapse" for="c-39710573">[-]</label><label class="expand" for="c-39710573">[1 more]</label></div><br/><div class="children"><div class="content">This is a very common approach and scales quite well. I worked for a company that had thousands of customers and each had their own schema. A single master database that kept track of which customer is on what physical db cluster, and this was globally replicated (EU,ANZ, NA).<p>Certainly needs a bunch of tooling, but worked well. Some apps were stateless and could connect to any physical cluster. Some others were sticky and only connected to a subset.<p>Similar architecture in my current company as well and we serve nearly a thousand customer instances served across 4 physical clusters.<p>We do have some basic tools to provision  new customers on the emptiest cluster, move customers from one cluster to another etc</div><br/></div></div><div id="39710157" class="c"><input type="checkbox" id="c-39710157" checked=""/><div class="controls bullet"><span class="by">Syntaf</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709671">parent</a><span>|</span><a href="#39710573">prev</a><span>|</span><a href="#39711815">next</a><span>|</span><label class="collapse" for="c-39710157">[-]</label><label class="expand" for="c-39710157">[4 more]</label></div><br/><div class="children"><div class="content">I recall a popular rails gem[1] once upon a time that provided multi-tenancy via postgres schemas.<p>As it turns out, even the company the initially developed the gem ended up ditching the approach due to some of the issues you outlined above.<p>Managing separate schemas feels like one of those nefarious decisions that make things simple _initially_ but get you into a world of hurt when you need to scale. The company is since defunct but they have an article where they discuss why they ditched the approach [2], TL;DR it&#x27;s too difficult to maintain and scale<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;influitive&#x2F;apartment#tenants-on-different-servers">https:&#x2F;&#x2F;github.com&#x2F;influitive&#x2F;apartment#tenants-on-different...</a>
[2] <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201108191323&#x2F;https:&#x2F;&#x2F;influitive.io&#x2F;our-multi-tenancy-journey-with-postgres-schemas-and-apartment-6ecda151a21f?gi=21f51677ff2e" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201108191323&#x2F;https:&#x2F;&#x2F;influitiv...</a></div><br/><div id="39710217" class="c"><input type="checkbox" id="c-39710217" checked=""/><div class="controls bullet"><span class="by">cqqxo4zV46cp</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710157">parent</a><span>|</span><a href="#39710622">next</a><span>|</span><label class="collapse" for="c-39710217">[-]</label><label class="expand" for="c-39710217">[1 more]</label></div><br/><div class="children"><div class="content">This is the conclusion I came to when faced with the same quandary.</div><br/></div></div><div id="39710622" class="c"><input type="checkbox" id="c-39710622" checked=""/><div class="controls bullet"><span class="by">tharkun__</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710157">parent</a><span>|</span><a href="#39710217">prev</a><span>|</span><a href="#39711815">next</a><span>|</span><label class="collapse" for="c-39710622">[-]</label><label class="expand" for="c-39710622">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s address these one by one based on our experience (the part of the journey that I&#x27;ve been there at least as the implementation of the solution predates me but I live with it).<p><i>Migrations</i><p><pre><code>    Things slow down past 100 [...] No one wants friction in their deployment process, especially as we’re attempting to deploy daily or more frequently.
</code></pre>
We have more than a thousand schemas per database shard. That is why I said you want things to run in parallel for speed, yes. However, we deploy way more than daily and it&#x27;s not really an issue in that sense. Schema updates are not that frequent but you do of course need to take into account that you will have to make the schema updates as a separate PR, wait and check that it worked and then deploy your actual change making use of the changes in application code. Which honestly isn&#x27;t much different from ensuring that your BE changes and FE changes are compatible or made in the right order so that you don&#x27;t get failed requests because an old FE happens to call a new BE node or vice versa :shrug:<p><i>Database resources</i><p><pre><code>    &quot;Need too large of an instance&quot; r3.4xl
</code></pre>
We seem to have m5.large. That has 2 virtual cores. Some r5.larges etc. Their r3.4xl has 16?! So not sure what kind of load pattern they have :shrug:<p><i>Client Memory Bloat</i><p><pre><code>    Ruby ActiveRecord something
</code></pre>
Yeah well, we don&#x27;t have that, so not sure what to say :shrug: Definitely not a generalized reason to say &quot;can&#x27;t do, is too complicated for scaling&quot;.<p><i>Record Identification</i><p><pre><code>    One major drawback of schemas as tenants is that your sequence generators will reside independently in each tenant. 
</code></pre>
I respectfully disagree. This is a great advantage because it means just because you get more and more tenants (some of which churn and you throw away their data anyway) your identifiers don&#x27;t grow past limits as easily. In fact, in most cases the identifiers never run out of runway at all.<p>They complain about &quot;what if you need to join this data somewhere else, then you need to also add the tenantId&quot;. Yeah, so? We also have a data warehouse we we do just that. Not a problem at all. We also have other services than our main one, which do use different database technologies where we use tenant as part of the key (for loads that actually benefit from being in a NoSQL type DB) and there we do not have sharding other than what the NoSQL database does by itself so to speak by dividing the keyspace.<p>That&#x27;s it. End of article. Basically, we have none of these issues. They don&#x27;t mention their actual scale. The only number they mention is the &quot;hundreds of schemas&quot;. We have more than ten times that number per physical shard and have tens of thousands of tenants total. Again :shrug:</div><br/><div id="39711217" class="c"><input type="checkbox" id="c-39711217" checked=""/><div class="controls bullet"><span class="by">nightpool</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710622">parent</a><span>|</span><a href="#39711815">next</a><span>|</span><label class="collapse" for="c-39711217">[-]</label><label class="expand" for="c-39711217">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s still 2 orders of magnitude smaller than the scale of Figma—they would need to somehow manage <i>millions</i> of Postgres schemas. I don&#x27;t think it&#x27;s a realistic possibility</div><br/></div></div></div></div></div></div><div id="39711815" class="c"><input type="checkbox" id="c-39711815" checked=""/><div class="controls bullet"><span class="by">aledalgrande</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709671">parent</a><span>|</span><a href="#39710157">prev</a><span>|</span><a href="#39708605">next</a><span>|</span><label class="collapse" for="c-39711815">[-]</label><label class="expand" for="c-39711815">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a single physical piece of hardware that will show its limitations if too many large or active tenants happen to be on the same shard<p>Shopify has pretty much mastered this <a href="https:&#x2F;&#x2F;shopify.engineering&#x2F;mysql-database-shard-balancing-terabyte-scale" rel="nofollow">https:&#x2F;&#x2F;shopify.engineering&#x2F;mysql-database-shard-balancing-t...</a></div><br/></div></div></div></div><div id="39708605" class="c"><input type="checkbox" id="c-39708605" checked=""/><div class="controls bullet"><span class="by">jerbear4328</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709671">prev</a><span>|</span><a href="#39707498">next</a><span>|</span><label class="collapse" for="c-39708605">[-]</label><label class="expand" for="c-39708605">[6 more]</label></div><br/><div class="children"><div class="content">Actually, Apple does this for iCloud! They use FoundationDB[1] to store billions of databases, one for each user (plus shared or global databases).<p>See: <a href="https:&#x2F;&#x2F;read.engineerscodex.com&#x2F;p&#x2F;how-apple-built-icloud-to-store-billions" rel="nofollow">https:&#x2F;&#x2F;read.engineerscodex.com&#x2F;p&#x2F;how-apple-built-icloud-to-...</a><p>Discussed on HN at the time: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39028672">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39028672</a><p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb">https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb</a> <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;FoundationDB" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;FoundationDB</a></div><br/><div id="39708936" class="c"><input type="checkbox" id="c-39708936" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39708605">parent</a><span>|</span><a href="#39707498">next</a><span>|</span><label class="collapse" for="c-39708936">[-]</label><label class="expand" for="c-39708936">[5 more]</label></div><br/><div class="children"><div class="content">&gt; store billions of databases<p>This is sort of true and sort of false. When you think of a &quot;database&quot;, if you&#x27;re thinking of a Postgres database, you&#x27;re way off the reality of what &quot;database&quot; means here.<p>FoundationDB has a concept called &quot;layers&quot;, and essentially they have created a layer that looks like a separate database on top of a layer that is separately encrypted groups of keys. They don&#x27;t have billions of FoundationDB clusters or machines, and at the infra level, i.e. the instances of the FoundationDB server software, it&#x27;s unaware of individual &quot;databases&quot;.<p>A closer analogy would be like having billions of tables, but even that isn&#x27;t accurate because in relational databases a table is usually a notably more static concept than data in a table. The closest analogy would be that each of the billions of users has a bunch of rows with a user-id field on them, and there&#x27;s a proxy that filters everything such that you can view the table as if it only had one user&#x27;s data in it.<p>To be clear, FoundationDB is awesome and Apple have done some really cool stuff with it, but it&#x27;s less crazy&#x2F;impressive than it sounds.</div><br/><div id="39709361" class="c"><input type="checkbox" id="c-39709361" checked=""/><div class="controls bullet"><span class="by">dexwiz</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39708936">parent</a><span>|</span><a href="#39707498">next</a><span>|</span><label class="collapse" for="c-39709361">[-]</label><label class="expand" for="c-39709361">[4 more]</label></div><br/><div class="children"><div class="content">This sounds like a pretty standard multitenant datastore. Everything has a user&#x2F;group Id on it, and a logical layer that locks a connection to a specific group.</div><br/><div id="39711314" class="c"><input type="checkbox" id="c-39711314" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709361">parent</a><span>|</span><a href="#39711308">next</a><span>|</span><label class="collapse" for="c-39711314">[-]</label><label class="expand" for="c-39711314">[1 more]</label></div><br/><div class="children"><div class="content">FoundationDB is really just a set of structures and tools to build any type of database you want on top of a solid foundation.<p>&quot;FoundationDB decouples its data storage technology from its data model. FoundationDB’s core ordered key-value storage technology can be efficiently adapted and remapped to a broad array of rich data models. Using indexing as an example, FoundationDB’s core provides no indexing and never will. Instead, a layer provides indexing by storing two kinds of key-values, one for the data and one for the index.&quot;<p><a href="https:&#x2F;&#x2F;apple.github.io&#x2F;foundationdb&#x2F;layer-concept.html" rel="nofollow">https:&#x2F;&#x2F;apple.github.io&#x2F;foundationdb&#x2F;layer-concept.html</a><p>Then existing standard layers like the Record layer, providing &quot;(very) roughly equivalent to a simple relational database&quot; providing structured types, index, complex types, queries, etc.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;FoundationDB&#x2F;fdb-record-layer">https:&#x2F;&#x2F;github.com&#x2F;FoundationDB&#x2F;fdb-record-layer</a><p>Or one for documents, which speaks the MongoDB wire protocol<p><a href="https:&#x2F;&#x2F;github.com&#x2F;FoundationDB&#x2F;fdb-document-layer">https:&#x2F;&#x2F;github.com&#x2F;FoundationDB&#x2F;fdb-document-layer</a></div><br/></div></div><div id="39709754" class="c"><input type="checkbox" id="c-39709754" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709361">parent</a><span>|</span><a href="#39711308">prev</a><span>|</span><a href="#39707498">next</a><span>|</span><label class="collapse" for="c-39709754">[-]</label><label class="expand" for="c-39709754">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the advantage or difference here is that these &quot;layers&quot; are a common design pattern with FoundationDB, several ship in FDB by default, and you&#x27;re encouraged to make more, so the database certainly has better support than just adding a column for TenantID, but still you&#x27;re right that it&#x27;s not too out there.</div><br/></div></div></div></div></div></div></div></div><div id="39707498" class="c"><input type="checkbox" id="c-39707498" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39708605">prev</a><span>|</span><a href="#39709487">next</a><span>|</span><label class="collapse" for="c-39707498">[-]</label><label class="expand" for="c-39707498">[6 more]</label></div><br/><div class="children"><div class="content">The problem - conceptually - is made much simpler this way; we make use of this at work.<p>However you will still have shared resource problems - some rogue query destroys IOPS in one tenant now ends up bringing down all tenants etc. There are in theory databases that solve this as well, but my experience has been that at that point what you buy into is a bad version of resource sharing - ie what an operating  system does - and you’re better off using OS mechanisms<p>In other words: yes, but you still have noisy neighbours, and may be better off running lots of small fully separated DBMSes than a big logically separated one</div><br/><div id="39709302" class="c"><input type="checkbox" id="c-39709302" checked=""/><div class="controls bullet"><span class="by">hacker_newz</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707498">parent</a><span>|</span><a href="#39709487">next</a><span>|</span><label class="collapse" for="c-39709302">[-]</label><label class="expand" for="c-39709302">[5 more]</label></div><br/><div class="children"><div class="content">If tenants are on separate databases how would that be an issue?</div><br/><div id="39709515" class="c"><input type="checkbox" id="c-39709515" checked=""/><div class="controls bullet"><span class="by">sgarland</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709302">parent</a><span>|</span><a href="#39709466">next</a><span>|</span><label class="collapse" for="c-39709515">[-]</label><label class="expand" for="c-39709515">[3 more]</label></div><br/><div class="children"><div class="content">Because database, in Postgres terms, doesn’t mean physical node. It’s more akin to a VM than anything else. The term for an installation of Postgres is database cluster, which can contain N databases, each of which can contain M schemas.</div><br/><div id="39710302" class="c"><input type="checkbox" id="c-39710302" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709515">parent</a><span>|</span><a href="#39709466">next</a><span>|</span><label class="collapse" for="c-39710302">[-]</label><label class="expand" for="c-39710302">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! Is there a good primer to this terminology that clarifies these terms on various popular database and cloud platforms?<p>It seems there is good potential for confusion unless we use the same terms consistently when discussing architecture and design across teams.<p>Even the term RDS (Relational Database Service) is sometimes said to be inaccurate since it is a &quot;Relational Database SERVER as a Service&quot;<p>A few related terms that cause confusion:<p>&quot;Schema&quot; could refer to a Database Schema or in some contexts, a single table&#x27;s logical data structure. (Or a single data set&#x27;s data structure -- or a standard for one, like JSON Schema)<p>Data Catalog products like &quot;AWS Glue Data Catalog&quot; which only store the metadata or schemas of the table they crawl ... refer to the entities they store as &quot;Databases&quot; and &quot;Tables&quot; (but no &quot;Schemas&quot;) and documentation includes guides talk about &quot;creating a database&quot;[1] and &quot;creating a table&quot;[2] in AWS Glue. There has to be a better way to refer to all these entities without using the word schema with so many meanings -- or calling both physical tables and their metadata as &quot;tables&quot;. Otherwise this is needlessly confusing and hard for beginners.<p>---<p>EDIT: even more madness. This StackOverflow discussion [3] has more examples of confusing usage:<p>&gt; On Oracle .... A Schema is effectively a user. More specifically it&#x27;s a set of tables&#x2F;procs&#x2F;indexes etc owned by a user. Another user has a different schema (tables he&#x2F;she owns) however user can also see any schemas they have select priviliedges on.<p>&gt; MySQL: database&#x2F;schema :: table<p>&gt; SQL Server: database :: (schema&#x2F;namespace ::) table<p>&gt; Oracle: database&#x2F;schema&#x2F;user :: (tablespace ::) table<p>[1]: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;define-database.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;define-database.h...</a><p>[2]: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;tables-described.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;tables-described....</a><p>[3]: <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;298739&#x2F;what-is-the-difference-between-a-schema-and-a-table-and-a-database" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;298739&#x2F;what-is-the-diffe...</a></div><br/><div id="39710682" class="c"><input type="checkbox" id="c-39710682" checked=""/><div class="controls bullet"><span class="by">sgarland</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710302">parent</a><span>|</span><a href="#39709466">next</a><span>|</span><label class="collapse" for="c-39710682">[-]</label><label class="expand" for="c-39710682">[1 more]</label></div><br/><div class="children"><div class="content">Not AFAIK. In MySQL, the only time “cluster” is used is to refer to NDB Cluster, which is a distributed DB product. Schema means a logical grouping of tables, the same (more or less) as Postgres.<p>As to schema itself, yes, it’s heavily overloaded, and you just to grok it from context. I can talk about a table’s schema or a DB’s schema, or as you mentioned, JSON schema. Although the latter is helped by simply not using JSON in a relational DB.<p>You must remember that SQL is an ancient language, and the relational model is even older. There are going to be oddities.</div><br/></div></div></div></div></div></div><div id="39709466" class="c"><input type="checkbox" id="c-39709466" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709302">parent</a><span>|</span><a href="#39709515">prev</a><span>|</span><a href="#39709487">next</a><span>|</span><label class="collapse" for="c-39709466">[-]</label><label class="expand" for="c-39709466">[1 more]</label></div><br/><div class="children"><div class="content">Separate <i>logical</i> databases, within the same RDBMs, so sharing CPU, disks, RAM etc</div><br/></div></div></div></div></div></div><div id="39709487" class="c"><input type="checkbox" id="c-39709487" checked=""/><div class="controls bullet"><span class="by">ummonk</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39707498">prev</a><span>|</span><a href="#39709722">next</a><span>|</span><label class="collapse" for="c-39709487">[-]</label><label class="expand" for="c-39709487">[8 more]</label></div><br/><div class="children"><div class="content">This seems to be an architecture Cloudflare is aiming to support with their SQLite service. One database per customer, each database located in the customer’s primary region.</div><br/><div id="39713369" class="c"><input type="checkbox" id="c-39713369" checked=""/><div class="controls bullet"><span class="by">fauigerzigerk</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709487">parent</a><span>|</span><a href="#39709568">next</a><span>|</span><label class="collapse" for="c-39713369">[-]</label><label class="expand" for="c-39713369">[1 more]</label></div><br/><div class="children"><div class="content">That would be fantastic. Unfortunately it&#x27;s not true. D1 doesn&#x27;t support the one database per customer approach unless you have just a handful of customers that you can set up manually.<p>You have to create each database manually using wrangler or the website. Then you have to create a binding for each database in wrangler.toml so that the database becomes accessible as a variable in your Workers code. Then you have to change your Worker source code to do something with that variable. Then you redeploy.<p>The issue is that Workers cannot create or list databases. There&#x27;s no API for it.</div><br/></div></div><div id="39709568" class="c"><input type="checkbox" id="c-39709568" checked=""/><div class="controls bullet"><span class="by">jasonwatkinspdx</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709487">parent</a><span>|</span><a href="#39713369">prev</a><span>|</span><a href="#39709722">next</a><span>|</span><label class="collapse" for="c-39709568">[-]</label><label class="expand" for="c-39709568">[6 more]</label></div><br/><div class="children"><div class="content">I think there&#x27;s quite a few people chasing similar ideas, like Azure&#x27;s Durable Entities.<p>I&#x27;ve been calling it the Lots of Little Databases model vs the Globe Spanning Gorilla.<p>Like the Spanner paper points out, even if your distributed database semantically appears like a single giant instance, in practice performance means developers avoid using distributed joins, etc, because these can lead to shuffling very large amounts of intermediate results across the network. So the illusion of being on a single giant machine ends up leaking through the reality, and people end up writing workarounds for distributed joins like async materialization.<p>If we give up the single machine illusion we get a lot of simplification, at the cost of features devs were unlikely to use anyhow. I see having consistent distributed commit but without cross shard joins as a really interesting alternative.<p>And besides scalability I like the extra security rope of fine grained partitioning from the start.<p>I&#x27;ll write a blog post along these lines if I get anything worthwhile done.</div><br/><div id="39710187" class="c"><input type="checkbox" id="c-39710187" checked=""/><div class="controls bullet"><span class="by">themoonisachees</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709568">parent</a><span>|</span><a href="#39711431">next</a><span>|</span><label class="collapse" for="c-39710187">[-]</label><label class="expand" for="c-39710187">[3 more]</label></div><br/><div class="children"><div class="content">An advantage worth noting is that having actually separated databases means you physically can&#x27;t make these expensive operations, so a junior dev can&#x27;t write incredibly inefficient code that would bring down your entire infra.</div><br/><div id="39711818" class="c"><input type="checkbox" id="c-39711818" checked=""/><div class="controls bullet"><span class="by">ummonk</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710187">parent</a><span>|</span><a href="#39711912">next</a><span>|</span><label class="collapse" for="c-39711818">[-]</label><label class="expand" for="c-39711818">[1 more]</label></div><br/><div class="children"><div class="content">Also makes it a lot harder for devs to do some footgun and leak data across domains.</div><br/></div></div><div id="39711912" class="c"><input type="checkbox" id="c-39711912" checked=""/><div class="controls bullet"><span class="by">aledalgrande</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710187">parent</a><span>|</span><a href="#39711818">prev</a><span>|</span><a href="#39711431">next</a><span>|</span><label class="collapse" for="c-39711912">[-]</label><label class="expand" for="c-39711912">[1 more]</label></div><br/><div class="children"><div class="content">Bring down the infra or foot you a 6 figures bill at the end of the month</div><br/></div></div></div></div><div id="39711431" class="c"><input type="checkbox" id="c-39711431" checked=""/><div class="controls bullet"><span class="by">shalabhc</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709568">parent</a><span>|</span><a href="#39710187">prev</a><span>|</span><a href="#39711848">next</a><span>|</span><label class="collapse" for="c-39711431">[-]</label><label class="expand" for="c-39711431">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Lots of Little Databases&quot; reminded me of <a href="https:&#x2F;&#x2F;www.actordb.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.actordb.com&#x2F;</a> which does lots of server-side sqlite instances, but the project now looks defunct.</div><br/></div></div><div id="39711848" class="c"><input type="checkbox" id="c-39711848" checked=""/><div class="controls bullet"><span class="by">ummonk</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709568">parent</a><span>|</span><a href="#39711431">prev</a><span>|</span><a href="#39709722">next</a><span>|</span><label class="collapse" for="c-39711848">[-]</label><label class="expand" for="c-39711848">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. Durable Entities strikes me as closer to Cloudflare&#x27;s Durable Objects (both in name and in design as actors backed by persistent storage).</div><br/></div></div></div></div></div></div><div id="39709722" class="c"><input type="checkbox" id="c-39709722" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709487">prev</a><span>|</span><a href="#39709405">next</a><span>|</span><label class="collapse" for="c-39709722">[-]</label><label class="expand" for="c-39709722">[3 more]</label></div><br/><div class="children"><div class="content">I worked at a place that did this with MySQL. Every tiny, trial account got their own database. Every huge, actual customer got their own database. Migrations were kinda painful. I would think carefully about doing it this way.</div><br/><div id="39710016" class="c"><input type="checkbox" id="c-39710016" checked=""/><div class="controls bullet"><span class="by">freefaler</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709722">parent</a><span>|</span><a href="#39709405">next</a><span>|</span><label class="collapse" for="c-39710016">[-]</label><label class="expand" for="c-39710016">[2 more]</label></div><br/><div class="children"><div class="content">we&#x27;ve been doing this for 20k databases with mysql for the last 10+ years. It solves more problems than it creates.
Migrations are trickier, but you get sharding, data isolation and easier backups that way.</div><br/><div id="39710098" class="c"><input type="checkbox" id="c-39710098" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710016">parent</a><span>|</span><a href="#39709405">next</a><span>|</span><label class="collapse" for="c-39710098">[-]</label><label class="expand" for="c-39710098">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying it&#x27;s always a bad idea, you just need to think about what you&#x27;re doing. This was closer to 15 years ago now. We had to develop a bunch of our own tooling, and make our own modifications to frameworks that are now ancient history.</div><br/></div></div></div></div></div></div><div id="39709405" class="c"><input type="checkbox" id="c-39709405" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709722">prev</a><span>|</span><a href="#39707482">next</a><span>|</span><label class="collapse" for="c-39709405">[-]</label><label class="expand" for="c-39709405">[7 more]</label></div><br/><div class="children"><div class="content">This works great until (1) your largest customer outgrows the largest available DB (happens sooner than you&#x27;d think for large companies) or (2) you <i>do</i> need transactions across different customers, say to facilitate some kind of sharing. Going all-in on the isolated tenant strategy means when you hit one of these cases it&#x27;s a nightmare to unwind and rearchitect your entire DB layer.</div><br/><div id="39709752" class="c"><input type="checkbox" id="c-39709752" checked=""/><div class="controls bullet"><span class="by">jasonwatkinspdx</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709405">parent</a><span>|</span><a href="#39709879">next</a><span>|</span><label class="collapse" for="c-39709752">[-]</label><label class="expand" for="c-39709752">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d respond by saying (1) is more rare than you&#x27;re asserting.<p>There is a huge long tail of companies with datasets that won&#x27;t fit on a single machine but can be handled by a dozen or so, and where no single customer or service is near the limits of an individual node.<p>These customers are poorly served at the moment. Most of the easy to implement SaaS options for what they need would be hugely costly vs a small fleet of db servers they administer. Meanwhile, most of the open source options are cargo culting Google or Facebook style architecture, which is a huge burden for a small company. I mean do you really want to run K8S when you have 10 servers in total?<p>I think there&#x27;s a lot of interesting stuff happening in this end of the market that&#x27;s not trying to be a mini Google, like Fly.io.<p>As for (2), I think a middle ground is supporting cross shard transactions but not joins. This works well enough for VoltDB et all.</div><br/><div id="39710746" class="c"><input type="checkbox" id="c-39710746" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709752">parent</a><span>|</span><a href="#39709879">next</a><span>|</span><label class="collapse" for="c-39710746">[-]</label><label class="expand" for="c-39710746">[2 more]</label></div><br/><div class="children"><div class="content">&gt; that won&#x27;t fit on a single machine<p>It&#x27;s rarely an issue with the number of bytes and more an issue with hot shards. Whatever shard Google is on (that is, Google the Figma customer) is surely going to be one _hell_ of a hot shard. They have more designers&#x2F;engineers&#x2F;PMs actively using Figma than most startups have _users total_. You don&#x27;t need more than one really really hot customer for this to become more than a hypothetical problem.<p>When you start to think about it that way, suddenly you need to seriously consider your iops (if you&#x27;re on RDS) or how much redundancy that physical machine&#x27;s SSDs have (if you&#x27;re running it on your own boxes).</div><br/><div id="39712151" class="c"><input type="checkbox" id="c-39712151" checked=""/><div class="controls bullet"><span class="by">ndriscoll</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710746">parent</a><span>|</span><a href="#39709879">next</a><span>|</span><label class="collapse" for="c-39712151">[-]</label><label class="expand" for="c-39712151">[1 more]</label></div><br/><div class="children"><div class="content">Google still only has ~180k employees, and obviously not all of them use figma, and obviously not all of their figma users are performing actions simultaneously. I&#x27;d be surprised if it broke 10k QPS (would an org like Google even have 10k peak active user sessions? Seems doubtful). Human generated traffic tends to just not reach that large of scales unless you&#x27;re trying to fit the entire planet on one instance.<p>RDS can be absurdly limited with IOPS, granted, but a modern laptop for example ought to be up to the task. Realistically you could probably be fine even on RDS but you might need to pay through the nose for extra IOPS.</div><br/></div></div></div></div></div></div><div id="39709879" class="c"><input type="checkbox" id="c-39709879" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709405">parent</a><span>|</span><a href="#39709752">prev</a><span>|</span><a href="#39709749">next</a><span>|</span><label class="collapse" for="c-39709879">[-]</label><label class="expand" for="c-39709879">[1 more]</label></div><br/><div class="children"><div class="content">Figma is more or less a desktop application that happens to run in a web browser.<p>If I use Photoshop to edit a .psd file I don’t think “man that psd file should really be stored in a single planet-sized database of all psd files in existence”. It’s just a file on my computer.<p>Figma requires a little bit more intermingling of data than Photoshop, it has multiuser support for one, so a pure local storage based approach wouldn’t work. But, at its heart it’s still based on the document model. When you open a Figma document it’s its own isolated little universe, the connections with resources outside the document are limited, and that matches user expectations.</div><br/></div></div><div id="39709749" class="c"><input type="checkbox" id="c-39709749" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709405">parent</a><span>|</span><a href="#39709879">prev</a><span>|</span><a href="#39709559">next</a><span>|</span><label class="collapse" for="c-39709749">[-]</label><label class="expand" for="c-39709749">[1 more]</label></div><br/><div class="children"><div class="content">Can you give an example of when a single customer has outgrown the largest available DB?</div><br/></div></div><div id="39709559" class="c"><input type="checkbox" id="c-39709559" checked=""/><div class="controls bullet"><span class="by">winrid</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709405">parent</a><span>|</span><a href="#39709749">prev</a><span>|</span><a href="#39707482">next</a><span>|</span><label class="collapse" for="c-39709559">[-]</label><label class="expand" for="c-39709559">[1 more]</label></div><br/><div class="children"><div class="content">A figma customer won&#x27;t exceed the requirements of an i3.metal...</div><br/></div></div></div></div><div id="39707482" class="c"><input type="checkbox" id="c-39707482" checked=""/><div class="controls bullet"><span class="by">eatonphil</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709405">prev</a><span>|</span><a href="#39710346">next</a><span>|</span><label class="collapse" for="c-39707482">[-]</label><label class="expand" for="c-39707482">[6 more]</label></div><br/><div class="children"><div class="content">I imagine it only gets you so far. What do you do about customers like Walmart or Oracle? Hundreds, if not thousands, of users all leaving hundreds of comments on Figma files every day. If you want good latency without giving up strong consistency (which the article says they want) you&#x27;ll need to keep sharding.</div><br/><div id="39709113" class="c"><input type="checkbox" id="c-39709113" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707482">parent</a><span>|</span><a href="#39708541">next</a><span>|</span><label class="collapse" for="c-39709113">[-]</label><label class="expand" for="c-39709113">[1 more]</label></div><br/><div class="children"><div class="content">I bet it gets you further than you imagine. Entirely depends on the backend services and what they touch but in this scenario you would be deploying&#x2F;scaling that service based on the customer seat size. I suspect that even for large enterprise customers, the users actively touching Figma are not reaching he thousands but I am happy to be wrong.<p>After all, Stackoverflow is running off of a handful of machines.</div><br/></div></div><div id="39708541" class="c"><input type="checkbox" id="c-39708541" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707482">parent</a><span>|</span><a href="#39709113">prev</a><span>|</span><a href="#39707726">next</a><span>|</span><label class="collapse" for="c-39708541">[-]</label><label class="expand" for="c-39708541">[2 more]</label></div><br/><div class="children"><div class="content">They were running their whole business on one RDS instance 4 years ago. Do you think they now have one customer larger than all their customers combined 4 years ago?</div><br/><div id="39708565" class="c"><input type="checkbox" id="c-39708565" checked=""/><div class="controls bullet"><span class="by">eatonphil</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39708541">parent</a><span>|</span><a href="#39707726">next</a><span>|</span><label class="collapse" for="c-39708565">[-]</label><label class="expand" for="c-39708565">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Figma’s database stack has grown almost 100x since 2020<p>The first sentence from the article seems to suggest its possible?</div><br/></div></div></div></div><div id="39707726" class="c"><input type="checkbox" id="c-39707726" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707482">parent</a><span>|</span><a href="#39708541">prev</a><span>|</span><a href="#39710346">next</a><span>|</span><label class="collapse" for="c-39707726">[-]</label><label class="expand" for="c-39707726">[2 more]</label></div><br/><div class="children"><div class="content">A single db can handle that load easily</div><br/><div id="39710881" class="c"><input type="checkbox" id="c-39710881" checked=""/><div class="controls bullet"><span class="by">paulryanrogers</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707726">parent</a><span>|</span><a href="#39710346">next</a><span>|</span><label class="collapse" for="c-39710881">[-]</label><label class="expand" for="c-39710881">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean an RDBMS running on a single, big-iron, bare-metal server?</div><br/></div></div></div></div></div></div><div id="39710346" class="c"><input type="checkbox" id="c-39710346" checked=""/><div class="controls bullet"><span class="by">menthe</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39707482">prev</a><span>|</span><a href="#39709371">next</a><span>|</span><label class="collapse" for="c-39710346">[-]</label><label class="expand" for="c-39710346">[4 more]</label></div><br/><div class="children"><div class="content">This, seriously. The long-term maintenance, tribal knowledge &amp; risks associated with this giant hack will be greater than anything they&#x27;d ever have expected. Inb4 global outage post-mortem &amp; key-man dependency salaries.<p>There&#x27;s no virtually no excuse not spinning up a pg pod (or two) for each tenant - heck even a namespace with the whole stack.<p>Embed your 4-phases migrations directly in your releases &#x2F; deployments, slap a py script to manage progressive rollouts, and  you&#x27;re done.<p>Discovery is automated, blast &#x2F; loss radius is reduced to the smallest denominator, you can now monitor &#x2F; pin &#x2F; adjust the stack for each customer individually as necessary, sort the release ordering &#x2F; schedule based on client criticality &#x2F; sensitivity, you can now easily geolocate the deployment to the tenant&#x27;s location, charge by resource usage, and much more.<p>And you can still query &amp; roll-up all of your databases at once for analytics with Trino&#x2F;DBT with nothing more but a yaml inventory.<p>No magic, no proprietary garbage.</div><br/><div id="39711197" class="c"><input type="checkbox" id="c-39711197" checked=""/><div class="controls bullet"><span class="by">nightpool</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39710346">parent</a><span>|</span><a href="#39709371">next</a><span>|</span><label class="collapse" for="c-39711197">[-]</label><label class="expand" for="c-39711197">[3 more]</label></div><br/><div class="children"><div class="content">Figma has <i>millions</i> of customers. The idea of having a Postgres pod for each one would be nearly impossible without completely overhauling their DB choice.</div><br/><div id="39711966" class="c"><input type="checkbox" id="c-39711966" checked=""/><div class="controls bullet"><span class="by">asguy</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39711197">parent</a><span>|</span><a href="#39712017">next</a><span>|</span><label class="collapse" for="c-39711966">[-]</label><label class="expand" for="c-39711966">[1 more]</label></div><br/><div class="children"><div class="content">Thousands of directories over thousands of installations?  It’s not that far fetched.</div><br/></div></div><div id="39712017" class="c"><input type="checkbox" id="c-39712017" checked=""/><div class="controls bullet"><span class="by">menthe</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39711197">parent</a><span>|</span><a href="#39711966">prev</a><span>|</span><a href="#39709371">next</a><span>|</span><label class="collapse" for="c-39712017">[-]</label><label class="expand" for="c-39712017">[1 more]</label></div><br/><div class="children"><div class="content">You are making a major conflation here. While they do millions of users, they were last reported to only have ~60k tenants.<p>Decently sized EKS nodes can easily hold nearly 800 pods each (as documented), that&#x27;d make it 75 nodes. Each EKS cluster supports up to 13,500 nodes. Spread in a couple of regions to improve your customer experience, you&#x27;re looking at 20 EKS nodes per cluster. This is a nothingburger.<p>Besides, it&#x27;s far from being rocket science to co-locate tenant schemas on medium-sized pg instances, monitor tenant growth, and re-balance schemas as necessary. Tenants&#x27; contracts does not evolve overnight, and certainly does not grow orders of magnitude on week over week basis - a company using Figma either has 10 seats, 100 seats, 1000, or 10,000 seats. It&#x27;s easy to plan ahead for. And I would MUCH rather having to think of re-balancing a heavy hitter customer&#x27;s schema to another instance every now and then (can be 100% automated too), compared to facing a business-wide SPOF, and having to hire L07+ DBAs to maintain a proprietary query parser &#x2F; planner &#x2F; router.<p>Hell, OVH does tenant-based deployments of Ceph clusters, with collocated&#x2F;coscheduled SSD&#x2F;HDD hardware and does hot-spot resolution. And running Ceph is significantly more demanding and admin+monitoring heavy.</div><br/></div></div></div></div></div></div><div id="39709371" class="c"><input type="checkbox" id="c-39709371" checked=""/><div class="controls bullet"><span class="by">dhash</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39710346">prev</a><span>|</span><a href="#39707986">next</a><span>|</span><label class="collapse" for="c-39709371">[-]</label><label class="expand" for="c-39709371">[1 more]</label></div><br/><div class="children"><div class="content">I believe physalia [0] explores this concept at production scale quite well.<p>[0] <a href="https:&#x2F;&#x2F;blog.acolyer.org&#x2F;2020&#x2F;03&#x2F;04&#x2F;millions-of-tiny-databases&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.acolyer.org&#x2F;2020&#x2F;03&#x2F;04&#x2F;millions-of-tiny-databas...</a></div><br/></div></div><div id="39707986" class="c"><input type="checkbox" id="c-39707986" checked=""/><div class="controls bullet"><span class="by">N_A_T_E</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709371">prev</a><span>|</span><a href="#39709519">next</a><span>|</span><label class="collapse" for="c-39707986">[-]</label><label class="expand" for="c-39707986">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like they actually did something like this. Their shard key selection could be customer, project, folder or something in their data model at a reasonably high logical level in their hierarchy.</div><br/></div></div><div id="39709519" class="c"><input type="checkbox" id="c-39709519" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39707986">prev</a><span>|</span><a href="#39708145">next</a><span>|</span><label class="collapse" for="c-39709519">[-]</label><label class="expand" for="c-39709519">[1 more]</label></div><br/><div class="children"><div class="content">Spanners interleaved tables seem like a similar solution, ie you interleave customer data so it all ends up on the same set of hosts for performance, while still having the ability to create transactions across customers.</div><br/></div></div><div id="39708145" class="c"><input type="checkbox" id="c-39708145" checked=""/><div class="controls bullet"><span class="by">infra_dev</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39709519">prev</a><span>|</span><a href="#39707754">next</a><span>|</span><label class="collapse" for="c-39708145">[-]</label><label class="expand" for="c-39708145">[1 more]</label></div><br/><div class="children"><div class="content">Nile is a Serverless Postgres that virtualizes tenants&#x2F;customers. It is specifically built for SaaS companies similar to Figma <a href="https:&#x2F;&#x2F;www.thenile.dev&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.thenile.dev&#x2F;</a>. I am the CEO of Nile.</div><br/></div></div><div id="39707754" class="c"><input type="checkbox" id="c-39707754" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39708145">prev</a><span>|</span><a href="#39710915">next</a><span>|</span><label class="collapse" for="c-39707754">[-]</label><label class="expand" for="c-39707754">[4 more]</label></div><br/><div class="children"><div class="content">I have pondered about this for quite some time and came to the conclusion that it would make schema migrations more difficult to handle. I think Shopify is using an approach which is similar to what you are describing. The advantage is that you don&#x27;t end up with hot shards because you can move around large customers independently.<p>In practice there isn&#x27;t a big difference, they just colocate several customers according to their sharding key in the same logical database.</div><br/><div id="39709679" class="c"><input type="checkbox" id="c-39709679" checked=""/><div class="controls bullet"><span class="by">yard2010</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707754">parent</a><span>|</span><a href="#39709583">next</a><span>|</span><label class="collapse" for="c-39709679">[-]</label><label class="expand" for="c-39709679">[1 more]</label></div><br/><div class="children"><div class="content">I worked in a place that had a database for each tenant and the schema migrations were a real pain. Every time everything goes smoothly except these few databases that have an edge case that screws the whole migration.</div><br/></div></div><div id="39709583" class="c"><input type="checkbox" id="c-39709583" checked=""/><div class="controls bullet"><span class="by">jamesfinlayson</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39707754">parent</a><span>|</span><a href="#39709679">prev</a><span>|</span><a href="#39710915">next</a><span>|</span><label class="collapse" for="c-39709583">[-]</label><label class="expand" for="c-39709583">[2 more]</label></div><br/><div class="children"><div class="content">I remember Postgres table spaces being used to separate customers at a previous job - I can&#x27;t remember how migrations were handled (pretty sure they were applied per table space) but I don&#x27;t think it was a problem (at our scale anyway).</div><br/><div id="39710156" class="c"><input type="checkbox" id="c-39710156" checked=""/><div class="controls bullet"><span class="by">vmfunction</span><span>|</span><a href="#39707437">root</a><span>|</span><a href="#39709583">parent</a><span>|</span><a href="#39710915">next</a><span>|</span><label class="collapse" for="c-39710156">[-]</label><label class="expand" for="c-39710156">[1 more]</label></div><br/><div class="children"><div class="content">&gt;There is usually not much point in making more than one tablespace per logical file system, since you cannot control the location of individual files within a logical file system. However, PostgreSQL does not enforce any such limitation, and indeed it is not directly aware of the file system boundaries on your system. It just stores files in the directories you tell it to use.<p>seems like the limitation is the logical file system. Which probably will work for most users.</div><br/></div></div></div></div></div></div><div id="39710915" class="c"><input type="checkbox" id="c-39710915" checked=""/><div class="controls bullet"><span class="by">erikpukinskis</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39707754">prev</a><span>|</span><a href="#39708346">next</a><span>|</span><label class="collapse" for="c-39710915">[-]</label><label class="expand" for="c-39710915">[1 more]</label></div><br/><div class="children"><div class="content">Im curious for anyone who has done this: what’s the point of going all the way from one-db to one-db-per-customer? Why not just split the customers to 2 databases, then to 3, etc? Seems like the same level of system complexity but you avoid the lots-of-databases scaling problem.<p>You probably don’t even need to be able to migrate people between shards… just put everyone on one db until you hit 50% utilization, then spin up a fresh db and put all new customers on that one. Repeat whenever you run out of databases under 50%.</div><br/></div></div><div id="39708346" class="c"><input type="checkbox" id="c-39708346" checked=""/><div class="controls bullet"><span class="by">GordonS</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39710915">prev</a><span>|</span><a href="#39710594">next</a><span>|</span><label class="collapse" for="c-39708346">[-]</label><label class="expand" for="c-39708346">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve done something like this before, with each customer getting their own <i>schema</i> within a single Postgres instance.</div><br/></div></div><div id="39710594" class="c"><input type="checkbox" id="c-39710594" checked=""/><div class="controls bullet"><span class="by">jimbokun</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39708346">prev</a><span>|</span><a href="#39709791">next</a><span>|</span><label class="collapse" for="c-39710594">[-]</label><label class="expand" for="c-39710594">[1 more]</label></div><br/><div class="children"><div class="content">If customers are not of similar size, and you have a lot of customers, managing all the different databases can be a big headache.<p>Having a more granular partition key makes it easier to shard the data more evenly.</div><br/></div></div><div id="39709791" class="c"><input type="checkbox" id="c-39709791" checked=""/><div class="controls bullet"><span class="by">petervandijck</span><span>|</span><a href="#39707437">parent</a><span>|</span><a href="#39710594">prev</a><span>|</span><a href="#39712205">next</a><span>|</span><label class="collapse" for="c-39709791">[-]</label><label class="expand" for="c-39709791">[1 more]</label></div><br/><div class="children"><div class="content">Ongoing product development with migrations, tweaking indexes etc. becomes really hard. Every small database tweak now has to be deployed over 1000s of databases.</div><br/></div></div></div></div><div id="39712205" class="c"><input type="checkbox" id="c-39712205" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#39707437">prev</a><span>|</span><a href="#39707227">next</a><span>|</span><label class="collapse" for="c-39712205">[-]</label><label class="expand" for="c-39712205">[1 more]</label></div><br/><div class="children"><div class="content">It looks like figma mostly just implemented the Instagram sharding paper, and then did the obvious next level of semi-intelligent yet delicate and fragile query routing.<p>Definitely a technically challenging and overall fun &#x2F; satisfying engineering exercise!<p><a href="https:&#x2F;&#x2F;instagram-engineering.com&#x2F;sharding-ids-at-instagram-1cf5a71e5a5c" rel="nofollow">https:&#x2F;&#x2F;instagram-engineering.com&#x2F;sharding-ids-at-instagram-...</a></div><br/></div></div><div id="39707227" class="c"><input type="checkbox" id="c-39707227" checked=""/><div class="controls bullet"><span class="by">emptysea</span><span>|</span><a href="#39712205">prev</a><span>|</span><a href="#39712737">next</a><span>|</span><label class="collapse" for="c-39707227">[-]</label><label class="expand" for="c-39707227">[1 more]</label></div><br/><div class="children"><div class="content">Seems they’ve built out a PG version of MySQL’s Vitess<p>Query rewriting seems interesting, having a layer between your DB and your application would also allow various ACL stuff as well</div><br/></div></div><div id="39712737" class="c"><input type="checkbox" id="c-39712737" checked=""/><div class="controls bullet"><span class="by">ing33k</span><span>|</span><a href="#39707227">prev</a><span>|</span><a href="#39707338">next</a><span>|</span><label class="collapse" for="c-39712737">[-]</label><label class="expand" for="c-39712737">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Additionally, over the past few years, we’ve developed a lot of expertise on how to reliably and performantly run RDS Postgres in-house&quot;. Isn&#x27;t the whole point of paying AWS the premium is that they do it for you ?</div><br/></div></div><div id="39707338" class="c"><input type="checkbox" id="c-39707338" checked=""/><div class="controls bullet"><span class="by">mannyv</span><span>|</span><a href="#39712737">prev</a><span>|</span><a href="#39707430">next</a><span>|</span><label class="collapse" for="c-39707338">[-]</label><label class="expand" for="c-39707338">[4 more]</label></div><br/><div class="children"><div class="content">Hmm, wonder why they didn&#x27;t try FoundationDB.<p>Interesting that they had problems with vacuuming. I always thought that part of Postgres was the worst part. I vaguely remember that you needed twice the space to vacuum successfully, which hopefully has changed in later versions.<p>An article about why vacuum is needed in pg (as compared to mysql&#x2F;innodb).<p><a href="http:&#x2F;&#x2F;rhaas.blogspot.com&#x2F;2011&#x2F;02&#x2F;mysql-vs-postgresql-part-2-vacuum-vs.html" rel="nofollow">http:&#x2F;&#x2F;rhaas.blogspot.com&#x2F;2011&#x2F;02&#x2F;mysql-vs-postgresql-part-2...</a></div><br/><div id="39707405" class="c"><input type="checkbox" id="c-39707405" checked=""/><div class="controls bullet"><span class="by">eatonphil</span><span>|</span><a href="#39707338">parent</a><span>|</span><a href="#39709561">next</a><span>|</span><label class="collapse" for="c-39707405">[-]</label><label class="expand" for="c-39707405">[1 more]</label></div><br/><div class="children"><div class="content">The article mentions they&#x27;re trying very hard to stick with Postgres. FoundationDB is great but doesn&#x27;t even have a SQL access layer, let alone a Postgres SQL access layer. :)</div><br/></div></div><div id="39709561" class="c"><input type="checkbox" id="c-39709561" checked=""/><div class="controls bullet"><span class="by">yashap</span><span>|</span><a href="#39707338">parent</a><span>|</span><a href="#39707405">prev</a><span>|</span><a href="#39707426">next</a><span>|</span><label class="collapse" for="c-39709561">[-]</label><label class="expand" for="c-39709561">[1 more]</label></div><br/><div class="children"><div class="content">They want pretty full SQL support, so FoundationDB would be out. I’d think “buy” options for them would be more like Citus, Yugabyte, Cockroach or Spanner.</div><br/></div></div><div id="39707426" class="c"><input type="checkbox" id="c-39707426" checked=""/><div class="controls bullet"><span class="by">harikb</span><span>|</span><a href="#39707338">parent</a><span>|</span><a href="#39709561">prev</a><span>|</span><a href="#39707430">next</a><span>|</span><label class="collapse" for="c-39707426">[-]</label><label class="expand" for="c-39707426">[1 more]</label></div><br/><div class="children"><div class="content">Do you know of any performant relational-db layer on top of FoundationDB? It seems there usecase would need at least simple join, which raw FoundationDB lacks.</div><br/></div></div></div></div><div id="39707430" class="c"><input type="checkbox" id="c-39707430" checked=""/><div class="controls bullet"><span class="by">dakiol</span><span>|</span><a href="#39707338">prev</a><span>|</span><a href="#39707988">next</a><span>|</span><label class="collapse" for="c-39707430">[-]</label><label class="expand" for="c-39707430">[4 more]</label></div><br/><div class="children"><div class="content">I cannot help but think this all sounds pretty much like a hack (a clever one, though).<p>We do not handle, let&#x27;s say low-level I&#x2F;O buffering&#x2F;caching, by ourselves anymore, right? (at least the folks doing web development&#x2F;saas). We rely instead of the OS APIs, and that&#x27;s good. I think we are missing something similar but for  db sharding. It seems to me that we are still missing some fundamental piece of technology&#x2F;infrastructure to handle horizontal data sharding.</div><br/><div id="39709289" class="c"><input type="checkbox" id="c-39709289" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39707430">parent</a><span>|</span><a href="#39710539">next</a><span>|</span><label class="collapse" for="c-39709289">[-]</label><label class="expand" for="c-39709289">[1 more]</label></div><br/><div class="children"><div class="content">Citus and Vitess are examples of horzontal data sharding technology for PostgreSQL and MySQL respectively.<p>At Figma&#x27;s size there are sometimes reasons to roll your own, which I think they explain pretty clearly in the article. They wanted a solution they could incrementally engineer onto their existing stack without doing a full rewrite or lift-and-shift to something else.</div><br/></div></div><div id="39710539" class="c"><input type="checkbox" id="c-39710539" checked=""/><div class="controls bullet"><span class="by">efxhoy</span><span>|</span><a href="#39707430">parent</a><span>|</span><a href="#39709289">prev</a><span>|</span><a href="#39709745">next</a><span>|</span><label class="collapse" for="c-39710539">[-]</label><label class="expand" for="c-39710539">[1 more]</label></div><br/><div class="children"><div class="content">I’m no computer scientist but I think the fundamental problem is that the CAP theorem makes it really tricky to do in a “cost free” way. You fundamentally need to sacrifice one, at least a tiny bit.</div><br/></div></div><div id="39709745" class="c"><input type="checkbox" id="c-39709745" checked=""/><div class="controls bullet"><span class="by">yard2010</span><span>|</span><a href="#39707430">parent</a><span>|</span><a href="#39710539">prev</a><span>|</span><a href="#39707988">next</a><span>|</span><label class="collapse" for="c-39709745">[-]</label><label class="expand" for="c-39709745">[1 more]</label></div><br/><div class="children"><div class="content">This is Hacker News after all</div><br/></div></div></div></div><div id="39707988" class="c"><input type="checkbox" id="c-39707988" checked=""/><div class="controls bullet"><span class="by">ijustlovemath</span><span>|</span><a href="#39707430">prev</a><span>|</span><a href="#39708695">next</a><span>|</span><label class="collapse" for="c-39707988">[-]</label><label class="expand" for="c-39707988">[6 more]</label></div><br/><div class="children"><div class="content">&gt; NoSQL databases are another common scalable-by-default solution that companies adopt as they grow. However, we have a very complex relational data model built on top of our current Postgres architecture and NoSQL APIs don’t offer this kind of versatility.<p>As I understand it, NoSQL is for people who need a backend that ingests just about any unstructured data, for teams that may not have a complex relational model worked out&#x2F;stabilized. Postgres has this in its native jsonb datatype, but they wouldn&#x27;t need to use that much since it sounds like they already have a good data model. What am I missing here?</div><br/><div id="39708791" class="c"><input type="checkbox" id="c-39708791" checked=""/><div class="controls bullet"><span class="by">suhastech</span><span>|</span><a href="#39707988">parent</a><span>|</span><a href="#39708205">next</a><span>|</span><label class="collapse" for="c-39708791">[-]</label><label class="expand" for="c-39708791">[1 more]</label></div><br/><div class="children"><div class="content">Using NoSQL might not be the best idea in this case. I&#x27;ve seen it backfire for many companies. They start with NoSQL, but then end up needing relational features as their business grows. This leads to performance issues, redundancy, and data sync problems early on, which shouldn&#x27;t be happening.<p>Especially in the early days, NoSQL companies used to market their databases as general-purpose database that scale easily, but that hasn&#x27;t always been the case obviously.<p>I usually recommend starting with a relational database like PostgreSQL. If scaling becomes necessary later on, you can invest in sharding the database. Figma&#x27;s approach seems reasonable given the tools available at the time.<p>I&#x27;ve helped small companies switch from NoSQL to SQL because the benefits of NoSQL weren&#x27;t worth the trade-offs at their stage of growth. In case, anyone is in a similar boat: <a href="https:&#x2F;&#x2F;mongotosqlmigration.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;mongotosqlmigration.com&#x2F;</a></div><br/></div></div><div id="39708205" class="c"><input type="checkbox" id="c-39708205" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#39707988">parent</a><span>|</span><a href="#39708791">prev</a><span>|</span><a href="#39708236">next</a><span>|</span><label class="collapse" for="c-39708205">[-]</label><label class="expand" for="c-39708205">[1 more]</label></div><br/><div class="children"><div class="content">What is your exact question? To me it makes sense that you’d not want to use NoSQL if you’re dealing with data that’s already relational, and heavily leveraging features common in relational DBs that may not come out of the box with NoSQL DBs.<p>They’re saying basically that NoSQL DBs solve a lot of horizontal scaling problems but aren’t a good fit for their highly relational data, is my understanding. Not that they can’t get NoSQL functionality at eg the query level in relational DBs.</div><br/></div></div><div id="39708236" class="c"><input type="checkbox" id="c-39708236" checked=""/><div class="controls bullet"><span class="by">ffsm8</span><span>|</span><a href="#39707988">parent</a><span>|</span><a href="#39708205">prev</a><span>|</span><a href="#39710767">next</a><span>|</span><label class="collapse" for="c-39708236">[-]</label><label class="expand" for="c-39708236">[1 more]</label></div><br/><div class="children"><div class="content">I think they&#x27;re equating relation database with databases with ACID guarantees, as thats basically a full overlap on a venn diagram.<p>And we all know that acid has to go at <i>some</i> scale, even if that scale keeps getting pushed further out as our hardware gets better.<p>(Same with the relational guarantees that eat performance... But only once you&#x27;ve reached a certain amount of throughput and data)</div><br/></div></div><div id="39710767" class="c"><input type="checkbox" id="c-39710767" checked=""/><div class="controls bullet"><span class="by">jimbokun</span><span>|</span><a href="#39707988">parent</a><span>|</span><a href="#39708236">prev</a><span>|</span><a href="#39710316">next</a><span>|</span><label class="collapse" for="c-39710767">[-]</label><label class="expand" for="c-39710767">[1 more]</label></div><br/><div class="children"><div class="content">If scaling isn’t an issue, use a relational database.<p>“NoSQL” only really pays off when you need to scale horizontally.  And even then, one of the horizontally scaling SQL solutions might be a better bet.</div><br/></div></div><div id="39710316" class="c"><input type="checkbox" id="c-39710316" checked=""/><div class="controls bullet"><span class="by">vmfunction</span><span>|</span><a href="#39707988">parent</a><span>|</span><a href="#39710767">prev</a><span>|</span><a href="#39708695">next</a><span>|</span><label class="collapse" for="c-39710316">[-]</label><label class="expand" for="c-39710316">[1 more]</label></div><br/><div class="children"><div class="content">if you have postgres, just use <a href="https:&#x2F;&#x2F;github.com&#x2F;FerretDB&#x2F;FerretDB">https:&#x2F;&#x2F;github.com&#x2F;FerretDB&#x2F;FerretDB</a></div><br/></div></div></div></div><div id="39708695" class="c"><input type="checkbox" id="c-39708695" checked=""/><div class="controls bullet"><span class="by">hintymad</span><span>|</span><a href="#39707988">prev</a><span>|</span><a href="#39707447">next</a><span>|</span><label class="collapse" for="c-39708695">[-]</label><label class="expand" for="c-39708695">[5 more]</label></div><br/><div class="children"><div class="content">Given that sharding has become a pretty mature practice, is it still worth considering the NewSQL solutions like CRDB, Yugabyte, and TiDB for the sake of auto sharding, given that these NewSQL databases usually trade throughput and latency for auto-sharding and multi-region support? Another added cost is learning how to operate NewSQL databases, assuming one is already familiar with either MySQL or Postgres.</div><br/><div id="39709491" class="c"><input type="checkbox" id="c-39709491" checked=""/><div class="controls bullet"><span class="by">emmanueloga_</span><span>|</span><a href="#39708695">parent</a><span>|</span><a href="#39710387">next</a><span>|</span><label class="collapse" for="c-39709491">[-]</label><label class="expand" for="c-39709491">[1 more]</label></div><br/><div class="children"><div class="content">In the OP they said they built their own sharding solution because it was risky to move to a different (newsql) solution and they already had sharding expertise with PG.<p>I think if starting from scratch it makes sense to look at these newsql DBs that are built to horizontally scale from the very beginning.</div><br/></div></div><div id="39710387" class="c"><input type="checkbox" id="c-39710387" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#39708695">parent</a><span>|</span><a href="#39709491">prev</a><span>|</span><a href="#39707447">next</a><span>|</span><label class="collapse" for="c-39710387">[-]</label><label class="expand" for="c-39710387">[3 more]</label></div><br/><div class="children"><div class="content">Sharding mysql and postgres has been a shitshow at every company I&#x27;ve worked at.</div><br/><div id="39711793" class="c"><input type="checkbox" id="c-39711793" checked=""/><div class="controls bullet"><span class="by">hintymad</span><span>|</span><a href="#39708695">root</a><span>|</span><a href="#39710387">parent</a><span>|</span><a href="#39711426">next</a><span>|</span><label class="collapse" for="c-39711793">[-]</label><label class="expand" for="c-39711793">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. This is kinda of information I look for. Could you give more specifics? Why  were they shit shows? If the tables are naturally shardable, say by user ID as described in the Figma&#x27;s case, would the situation be different?</div><br/></div></div><div id="39711426" class="c"><input type="checkbox" id="c-39711426" checked=""/><div class="controls bullet"><span class="by">paulryanrogers</span><span>|</span><a href="#39708695">root</a><span>|</span><a href="#39710387">parent</a><span>|</span><a href="#39711793">prev</a><span>|</span><a href="#39707447">next</a><span>|</span><label class="collapse" for="c-39711426">[-]</label><label class="expand" for="c-39711426">[1 more]</label></div><br/><div class="children"><div class="content">Why? How did they shard?</div><br/></div></div></div></div></div></div><div id="39707447" class="c"><input type="checkbox" id="c-39707447" checked=""/><div class="controls bullet"><span class="by">adastral</span><span>|</span><a href="#39708695">prev</a><span>|</span><a href="#39707709">next</a><span>|</span><label class="collapse" for="c-39707447">[-]</label><label class="expand" for="c-39707447">[23 more]</label></div><br/><div class="children"><div class="content">I see they don&#x27;t mention Citus (<a href="https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;citus">https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;citus</a>), which is already a fairly mature native Postgres extension. From the details given in the article, it sounds like they just reimplemented it.<p>I wonder if they were unaware of it or disregarded it for a reason —I currently am in a similar situation as the one described in the blog, trying to shard a massive Postgres DB.</div><br/><div id="39708203" class="c"><input type="checkbox" id="c-39708203" checked=""/><div class="controls bullet"><span class="by">gshulegaard</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707708">next</a><span>|</span><label class="collapse" for="c-39708203">[-]</label><label class="expand" for="c-39708203">[3 more]</label></div><br/><div class="children"><div class="content">I have worked on teams that have both sharded and partitioned PostgreSQL ourselves (somewhat like Figma) (Postgres 9.4-ish time frame) as well as those that have utilized Citus.  I am a strong proponent of Citus and point colleagues in that direction frequently, but depending on how long ago Figma was considering this path I will say that there were some very interesting limitations to Citus not that long ago.<p>For example, it was only 2 years ago that Citus allowed the joining of data in &quot;local&quot; tables and data retrieved from distributed tables (<a href="https:&#x2F;&#x2F;www.citusdata.com&#x2F;updates&#x2F;v11-0" rel="nofollow">https:&#x2F;&#x2F;www.citusdata.com&#x2F;updates&#x2F;v11-0</a>).  In this major update as well, Citus enabled _any_ node to handle queries, previously all queries (whether or not it was modifying data) had to go through the &quot;coordinator&quot; node in your cluster.  This could turn into a pretty significant bottleneck which had ramifications for your cluster administration and choices made about how to shape your data (what goes into local tables, reference tables, or distributed tables).<p>Again, huge fan of Citus, but it&#x27;s not a magic bullet that makes it so you no longer have to think about scale when using Postgres.  It makes it _much_ easier and adds some killer features that push complexity down the stack such that it is _almost_ completely abstracted from application logic.  But you still have be cognizant of it, sometimes even altering your data model to accommodate.</div><br/><div id="39708651" class="c"><input type="checkbox" id="c-39708651" checked=""/><div class="controls bullet"><span class="by">gen220</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708203">parent</a><span>|</span><a href="#39707708">next</a><span>|</span><label class="collapse" for="c-39708651">[-]</label><label class="expand" for="c-39708651">[2 more]</label></div><br/><div class="children"><div class="content">You also benefit from the tailwind of the CitusData team making continued improvement to the extension, whereas an in-house system depends on your company&#x27;s ability to hire and retain people to maintain + improve the in-house system.<p>It&#x27;s hard to account for the value of benefits that have yet to accrue, but this kind of analysis, even if you pretty heavily-discount that future value, tilts the ROI in favor of solutions like Citus, IMO. Especially if your time horizon is 5+ or 10+ years out.<p>Like you said, if they made this decision 3ish years ago, you would have had to be pretty trusting on that future value. A choice, made today, hinges less on that variable.</div><br/><div id="39709128" class="c"><input type="checkbox" id="c-39709128" checked=""/><div class="controls bullet"><span class="by">wayne-li2</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708651">parent</a><span>|</span><a href="#39707708">next</a><span>|</span><label class="collapse" for="c-39709128">[-]</label><label class="expand" for="c-39709128">[1 more]</label></div><br/><div class="children"><div class="content">Huh, I would have thought the opposite. Companies at Figma size are easily able to hire talent to maintain a core part of their engineering stack. On the other hand, they retain no control of Citus decision making. Those tailwinds could easily have been headwinds if they went in a direction that did not suit Figma.</div><br/></div></div></div></div></div></div><div id="39707708" class="c"><input type="checkbox" id="c-39707708" checked=""/><div class="controls bullet"><span class="by">sgarland</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39708203">prev</a><span>|</span><a href="#39707690">next</a><span>|</span><label class="collapse" for="c-39707708">[-]</label><label class="expand" for="c-39707708">[1 more]</label></div><br/><div class="children"><div class="content">I thought of that as well. The only thing I could think of is that they mentioned that they don&#x27;t want to move off of RDS, and there is 0% chance of Citus coming to AWS since Microsoft bought them.</div><br/></div></div><div id="39707690" class="c"><input type="checkbox" id="c-39707690" checked=""/><div class="controls bullet"><span class="by">junto</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707708">prev</a><span>|</span><a href="#39707917">next</a><span>|</span><label class="collapse" for="c-39707690">[-]</label><label class="expand" for="c-39707690">[6 more]</label></div><br/><div class="children"><div class="content">Before clicking on the article I assumed it was Citus, and was surprised when it wasn’t.<p>Maybe because CitusData was bought by Microsoft around the same time, so Microsoft could create “Azure Cosmos DB for Postgres Cluster”, yet another one of Microsoft’s typical product naming crapshoots.</div><br/><div id="39708349" class="c"><input type="checkbox" id="c-39708349" checked=""/><div class="controls bullet"><span class="by">victor106</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707690">parent</a><span>|</span><a href="#39707917">next</a><span>|</span><label class="collapse" for="c-39708349">[-]</label><label class="expand" for="c-39708349">[5 more]</label></div><br/><div class="children"><div class="content">&gt; yet another one of Microsoft’s typical product naming crapshoots.<p>Well said. I haven&#x27;t seen any company as terrible as Microsoft at naming things. Anyone know why?</div><br/><div id="39709093" class="c"><input type="checkbox" id="c-39709093" checked=""/><div class="controls bullet"><span class="by">salynchnew</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708349">parent</a><span>|</span><a href="#39710060">next</a><span>|</span><label class="collapse" for="c-39709093">[-]</label><label class="expand" for="c-39709093">[2 more]</label></div><br/><div class="children"><div class="content">Naming things is hard.<p>At a previous employer, I saw several cool-ish open source projects instantly doomed to obscurity by picking a name that either completely duplicated the name of an existing OSS project or were guaranteed to have terrible SEO for another reason.<p>However, Microsoft seems to have a unique crossover of fragmented business units and centralized marketing. That&#x27;s why you end up with Azure -&gt; Subproject -&gt; Actual Product&#x2F;Service word soup. Perviously, they did this with the Windows Live brand from 2005-2012, and &quot;Xbox&quot; for a wide range of gaming projects (many of which were on PC).</div><br/><div id="39709947" class="c"><input type="checkbox" id="c-39709947" checked=""/><div class="controls bullet"><span class="by">thomasjudge</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39709093">parent</a><span>|</span><a href="#39710060">next</a><span>|</span><label class="collapse" for="c-39709947">[-]</label><label class="expand" for="c-39709947">[1 more]</label></div><br/><div class="children"><div class="content">related, Microsoft on Microsoft marketing:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EUXnJraKM3k" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EUXnJraKM3k</a></div><br/></div></div></div></div><div id="39710060" class="c"><input type="checkbox" id="c-39710060" checked=""/><div class="controls bullet"><span class="by">r-bar</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708349">parent</a><span>|</span><a href="#39709093">prev</a><span>|</span><a href="#39708956">next</a><span>|</span><label class="collapse" for="c-39710060">[-]</label><label class="expand" for="c-39710060">[1 more]</label></div><br/><div class="children"><div class="content">The committee wanted Cosmos, Azure, and Postgres all in the name and wouldn&#x27;t compromise.</div><br/></div></div><div id="39708956" class="c"><input type="checkbox" id="c-39708956" checked=""/><div class="controls bullet"><span class="by">studmuffin650</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708349">parent</a><span>|</span><a href="#39710060">prev</a><span>|</span><a href="#39707917">next</a><span>|</span><label class="collapse" for="c-39708956">[-]</label><label class="expand" for="c-39708956">[1 more]</label></div><br/><div class="children"><div class="content">AWS is putting up good fight</div><br/></div></div></div></div></div></div><div id="39707917" class="c"><input type="checkbox" id="c-39707917" checked=""/><div class="controls bullet"><span class="by">jabart</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707690">prev</a><span>|</span><a href="#39707543">next</a><span>|</span><label class="collapse" for="c-39707917">[-]</label><label class="expand" for="c-39707917">[3 more]</label></div><br/><div class="children"><div class="content">Figma uses AWS RDS, RDS doesn&#x27;t list citus as a supported extension.</div><br/><div id="39708608" class="c"><input type="checkbox" id="c-39708608" checked=""/><div class="controls bullet"><span class="by">gen220</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707917">parent</a><span>|</span><a href="#39707543">next</a><span>|</span><label class="collapse" for="c-39708608">[-]</label><label class="expand" for="c-39708608">[2 more]</label></div><br/><div class="children"><div class="content">This is my guess of why they didn&#x27;t use Citus. They weren&#x27;t interested in the options of (1) going multi-cloud [DB in Azure Cosmos &#x2F; Backend(s) in AWS] (2) going all-in on Azure [DB in Azure Cosmos &#x2F; Backend(s) in Azure] (3) self-managing Postgres+Citus in EC2.<p>It&#x27;d be interesting to compare the expected capex of developing this in-house solution + the opex of maintaining it vs the same categories of expected costs for option (3) – because I imagine that&#x27;s probably the most palatable option.<p>They also may have pre-paid for dedicated RDS instances for the next X years (<i>before</i> this horizontal scaling initiative began, to boot), as AWS allows companies to do this at a pretty steep discount rate, which would probably tilt them away from (3).</div><br/><div id="39709445" class="c"><input type="checkbox" id="c-39709445" checked=""/><div class="controls bullet"><span class="by">sgarland</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708608">parent</a><span>|</span><a href="#39707543">next</a><span>|</span><label class="collapse" for="c-39709445">[-]</label><label class="expand" for="c-39709445">[1 more]</label></div><br/><div class="children"><div class="content">Especially because Option 3 lets you go waaaay farther on vertical scaling, since you can get native NVMe drives (they mentioned hitting IOPS limits for RDS), more exotic instance classes with far more RAM, and do stuff like ZFS for native compression and snapshots.</div><br/></div></div></div></div></div></div><div id="39707543" class="c"><input type="checkbox" id="c-39707543" checked=""/><div class="controls bullet"><span class="by">iamdanieljohns</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707917">prev</a><span>|</span><a href="#39707488">next</a><span>|</span><label class="collapse" for="c-39707543">[-]</label><label class="expand" for="c-39707543">[1 more]</label></div><br/><div class="children"><div class="content">I would love to see a comparison of the major PostgresQL services such as Citus, EDB, Crunchy, Neon, and some OSS distributions&#x2F;packages</div><br/></div></div><div id="39707488" class="c"><input type="checkbox" id="c-39707488" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707543">prev</a><span>|</span><a href="#39708579">next</a><span>|</span><label class="collapse" for="c-39707488">[-]</label><label class="expand" for="c-39707488">[7 more]</label></div><br/><div class="children"><div class="content">how &quot;massive&quot; is massive in your case?</div><br/><div id="39707557" class="c"><input type="checkbox" id="c-39707557" checked=""/><div class="controls bullet"><span class="by">dijit</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707488">parent</a><span>|</span><a href="#39707551">next</a><span>|</span><label class="collapse" for="c-39707557">[-]</label><label class="expand" for="c-39707557">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had CitusDB running across 68 bare metal machines (40 vCPU, 768GiB ram, 20TiB of storage each + 40GiB network links) and it ran decently well.<p>Not sure what your definition of massive is, I think Spanner would easily beat it.<p>Also, it&#x27;s very use-case dependent, you can&#x27;t &quot;just use&quot; Citus for everything, it&#x27;s not <i>quite</i> as flexible as a bog-standard pgsql install due to the way it&#x27;s sharding, you have to be a tad more careful with your data model.</div><br/><div id="39711320" class="c"><input type="checkbox" id="c-39711320" checked=""/><div class="controls bullet"><span class="by">VHRanger</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707557">parent</a><span>|</span><a href="#39708831">next</a><span>|</span><label class="collapse" for="c-39711320">[-]</label><label class="expand" for="c-39711320">[2 more]</label></div><br/><div class="children"><div class="content">Is there a reason there&#x27;s comparatively little storage in your machines in relation to RAM or even CPUs?<p>Do your machines do compute heavy loads or something?<p>For a DB I&#x27;d expect a lot more storage per node</div><br/><div id="39711992" class="c"><input type="checkbox" id="c-39711992" checked=""/><div class="controls bullet"><span class="by">dijit</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39711320">parent</a><span>|</span><a href="#39708831">next</a><span>|</span><label class="collapse" for="c-39711992">[-]</label><label class="expand" for="c-39711992">[1 more]</label></div><br/><div class="children"><div class="content">NVMe SSDs aren&#x27;t so large unfortunately.<p>a 1U server has capacity for 8 drives, we used 2 slots for the OS (RAID1), 2 slots for the WAL volume (2 slots) leaving only 4 slots in RAID10.<p>So I&#x27;m already cheating a little and claiming WAL storage was part of total storage.</div><br/></div></div></div></div><div id="39708831" class="c"><input type="checkbox" id="c-39708831" checked=""/><div class="controls bullet"><span class="by">skunkworker</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707557">parent</a><span>|</span><a href="#39711320">prev</a><span>|</span><a href="#39707551">next</a><span>|</span><label class="collapse" for="c-39708831">[-]</label><label class="expand" for="c-39708831">[2 more]</label></div><br/><div class="children"><div class="content">What is your definition of &quot;decently well&quot;, and is your primary cluster (without replicas) above 1PB?</div><br/><div id="39709269" class="c"><input type="checkbox" id="c-39709269" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39708831">parent</a><span>|</span><a href="#39707551">next</a><span>|</span><label class="collapse" for="c-39709269">[-]</label><label class="expand" for="c-39709269">[1 more]</label></div><br/><div class="children"><div class="content">They said 20TiB * 68, which I think is 1.5PB.</div><br/></div></div></div></div></div></div><div id="39707551" class="c"><input type="checkbox" id="c-39707551" checked=""/><div class="controls bullet"><span class="by">adastral</span><span>|</span><a href="#39707447">root</a><span>|</span><a href="#39707488">parent</a><span>|</span><a href="#39707557">prev</a><span>|</span><a href="#39708579">next</a><span>|</span><label class="collapse" for="c-39707551">[-]</label><label class="expand" for="c-39707551">[1 more]</label></div><br/><div class="children"><div class="content">Around ten heavily-updated (50-400k updated rows&#x2F;min) tables ranging between 500M and 5B rows, 
with a couple tables over 40B rows each (5TB each IIRC).</div><br/></div></div></div></div><div id="39708579" class="c"><input type="checkbox" id="c-39708579" checked=""/><div class="controls bullet"><span class="by">gregors</span><span>|</span><a href="#39707447">parent</a><span>|</span><a href="#39707488">prev</a><span>|</span><a href="#39707709">next</a><span>|</span><label class="collapse" for="c-39708579">[-]</label><label class="expand" for="c-39708579">[1 more]</label></div><br/><div class="children"><div class="content">Where&#x27;s the fun in that? I&#x27;m not being snarky either. Maybe it&#x27;s not the best decision business-wise, but I guarantee it was more challenging and more fun. There&#x27;s something to be said for that.</div><br/></div></div></div></div><div id="39707709" class="c"><input type="checkbox" id="c-39707709" checked=""/><div class="controls bullet"><span class="by">vinner_roy</span><span>|</span><a href="#39707447">prev</a><span>|</span><a href="#39707181">next</a><span>|</span><label class="collapse" for="c-39707709">[-]</label><label class="expand" for="c-39707709">[12 more]</label></div><br/><div class="children"><div class="content">Could you use Aurora Limitless for this instead? <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;about-aws&#x2F;whats-new&#x2F;2023&#x2F;11&#x2F;amazon-aurora-limitless-database&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;about-aws&#x2F;whats-new&#x2F;2023&#x2F;11&#x2F;amazon-au...</a></div><br/><div id="39707751" class="c"><input type="checkbox" id="c-39707751" checked=""/><div class="controls bullet"><span class="by">bearjaws</span><span>|</span><a href="#39707709">parent</a><span>|</span><a href="#39707820">next</a><span>|</span><label class="collapse" for="c-39707751">[-]</label><label class="expand" for="c-39707751">[6 more]</label></div><br/><div class="children"><div class="content">I doubt even VC money can afford this service.<p>Serverless Aurora is incredibly expensive for most workloads. I have yet to find a use case for any SaaS product that is used &gt;4 hours a day. Since all my products span at least 3 time zones there is at least 12 hours of activity a day.</div><br/><div id="39707978" class="c"><input type="checkbox" id="c-39707978" checked=""/><div class="controls bullet"><span class="by">Scubabear68</span><span>|</span><a href="#39707709">root</a><span>|</span><a href="#39707751">parent</a><span>|</span><a href="#39708488">prev</a><span>|</span><a href="#39707918">next</a><span>|</span><label class="collapse" for="c-39707978">[-]</label><label class="expand" for="c-39707978">[3 more]</label></div><br/><div class="children"><div class="content">We found this out the hard way in a small startup. The per query and I&#x2F;O expense was through the roof.</div><br/><div id="39709841" class="c"><input type="checkbox" id="c-39709841" checked=""/><div class="controls bullet"><span class="by">yard2010</span><span>|</span><a href="#39707709">root</a><span>|</span><a href="#39707978">parent</a><span>|</span><a href="#39707918">next</a><span>|</span><label class="collapse" for="c-39709841">[-]</label><label class="expand" for="c-39709841">[2 more]</label></div><br/><div class="children"><div class="content">Did it work though? Did you achieve unlimited scaling? Because if so you should compare the price to the price of a team of great minds such as in this article, working for 2 years to get a solution.<p>I bet it still would be cheaper to pay people over Amazon, but I&#x27;m curious about the numbers</div><br/><div id="39710150" class="c"><input type="checkbox" id="c-39710150" checked=""/><div class="controls bullet"><span class="by">Scubabear68</span><span>|</span><a href="#39707709">root</a><span>|</span><a href="#39709841">parent</a><span>|</span><a href="#39707918">next</a><span>|</span><label class="collapse" for="c-39710150">[-]</label><label class="expand" for="c-39710150">[1 more]</label></div><br/><div class="children"><div class="content">It worked fine, the problem was our workloads were minuscule and it still cost $3,000 a month to support 50ish users on a lightly used platform.<p>The same load in a non-Serverless instance was around $100&#x2F;month.</div><br/></div></div></div></div></div></div><div id="39707918" class="c"><input type="checkbox" id="c-39707918" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#39707709">root</a><span>|</span><a href="#39707751">parent</a><span>|</span><a href="#39707978">prev</a><span>|</span><a href="#39707820">next</a><span>|</span><label class="collapse" for="c-39707918">[-]</label><label class="expand" for="c-39707918">[1 more]</label></div><br/><div class="children"><div class="content">What products</div><br/></div></div></div></div><div id="39707820" class="c"><input type="checkbox" id="c-39707820" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39707709">parent</a><span>|</span><a href="#39707751">prev</a><span>|</span><a href="#39708049">next</a><span>|</span><label class="collapse" for="c-39707820">[-]</label><label class="expand" for="c-39707820">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Limitless&quot; refers to the bill, not just the scale.</div><br/></div></div><div id="39708049" class="c"><input type="checkbox" id="c-39708049" checked=""/><div class="controls bullet"><span class="by">sgarland</span><span>|</span><a href="#39707709">parent</a><span>|</span><a href="#39707820">prev</a><span>|</span><a href="#39708192">next</a><span>|</span><label class="collapse" for="c-39708049">[-]</label><label class="expand" for="c-39708049">[1 more]</label></div><br/><div class="children"><div class="content">At my company, we were given an early talk on Limitless. Never once did the reps mention that it ran on Serverless. Dear lord, that&#x27;s going to be a hard no from me. Unless they&#x27;ve dramatically changed pricing for Limitless as opposed to normal Serverless, that&#x27;ll be through the roof.</div><br/></div></div><div id="39708192" class="c"><input type="checkbox" id="c-39708192" checked=""/><div class="controls bullet"><span class="by">vinner_roy</span><span>|</span><a href="#39707709">parent</a><span>|</span><a href="#39708049">prev</a><span>|</span><a href="#39708033">next</a><span>|</span><label class="collapse" for="c-39708192">[-]</label><label class="expand" for="c-39708192">[1 more]</label></div><br/><div class="children"><div class="content">Haha alright I get the picture. Too expensive.</div><br/></div></div><div id="39708033" class="c"><input type="checkbox" id="c-39708033" checked=""/><div class="controls bullet"><span class="by">MapleWalnut</span><span>|</span><a href="#39707709">parent</a><span>|</span><a href="#39708192">prev</a><span>|</span><a href="#39707181">next</a><span>|</span><label class="collapse" for="c-39708033">[-]</label><label class="expand" for="c-39708033">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but that wasn&#x27;t available when they did this migration</div><br/><div id="39710556" class="c"><input type="checkbox" id="c-39710556" checked=""/><div class="controls bullet"><span class="by">jamesfinlayson</span><span>|</span><a href="#39707709">root</a><span>|</span><a href="#39708033">parent</a><span>|</span><a href="#39707181">next</a><span>|</span><label class="collapse" for="c-39710556">[-]</label><label class="expand" for="c-39710556">[1 more]</label></div><br/><div class="children"><div class="content">Hm, looks like it&#x27;s only available as a preview too.
I was wondering why I hadn&#x27;t seen in mentioned before.</div><br/></div></div></div></div></div></div><div id="39707181" class="c"><input type="checkbox" id="c-39707181" checked=""/><div class="controls bullet"><span class="by">nosefrog</span><span>|</span><a href="#39707709">prev</a><span>|</span><a href="#39712266">next</a><span>|</span><label class="collapse" for="c-39707181">[-]</label><label class="expand" for="c-39707181">[28 more]</label></div><br/><div class="children"><div class="content">Coming from Google, where Spanner is this magical technology that supports infinite horizontal sharding with transactions and has become the standard storage engine for everything at Google (almost every project not using Spanner was moving to Spanner), I&#x27;m curious how Figma evaluated Cloud Spanner.  Cloud Spanner does have a postgres translation layer, though I don&#x27;t know how well it works.<p>It seems like they&#x27;ve (hopefully only temporarily) given up real transactional support with their horizontal postgres scheme?</div><br/><div id="39707350" class="c"><input type="checkbox" id="c-39707350" checked=""/><div class="controls bullet"><span class="by">umvi</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39708083">next</a><span>|</span><label class="collapse" for="c-39707350">[-]</label><label class="expand" for="c-39707350">[13 more]</label></div><br/><div class="children"><div class="content">Never a good idea to rely on Google proprietary tech (unless you are Google)... it could be sunset at any time without warning. I use GCP but I try my best to stay Google agnostic (avoid GCP-only offerings, etc) so that I can move to AWS if Google pulls the rug out from under me.</div><br/><div id="39708445" class="c"><input type="checkbox" id="c-39708445" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707350">parent</a><span>|</span><a href="#39707960">next</a><span>|</span><label class="collapse" for="c-39708445">[-]</label><label class="expand" for="c-39708445">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m biased having worked on GCP, but I think GCP actually has a very good track record of not sunsetting entire products or removing core functionality. When I worked on AppEngine, I would often see apps written 10+ years ago still chugging along.<p>It is true though that GCP sometimes sunsets specific product functionality, requiring changes on the customers&#x27; part. Some of these are unavoidable (eg committing to apply security patches to Python 2.7 given that the rest of the world is mostly not upstreaming these patches anymore), but not all of them.<p>I would certainly use Cloud Spanner externally now that I&#x27;ve left the company, and IMO spanner has such a compelling featureset that it&#x27;s a strong reason to use GCP for greenfield development. The problem though is that it&#x27;s only available on GCP, and could become expensive at large scale.</div><br/><div id="39710908" class="c"><input type="checkbox" id="c-39710908" checked=""/><div class="controls bullet"><span class="by">nojvek</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708445">parent</a><span>|</span><a href="#39709235">next</a><span>|</span><label class="collapse" for="c-39710908">[-]</label><label class="expand" for="c-39710908">[2 more]</label></div><br/><div class="children"><div class="content">My previous employer was a GCP customer. Google did pull occasional shenanigans totally breaking us with random upgrades without notifying us. Their support wouldn’t acknowledge it was their fault until we were mad at them.<p>My newer employer is AWS. Their offerings are a lot more stable and support is helpful.<p>If you want to build a serious business I would avoid GCP. Google doesn’t really give a shit at winning Cloud. Ads is their core business.</div><br/><div id="39711389" class="c"><input type="checkbox" id="c-39711389" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39710908">parent</a><span>|</span><a href="#39709235">next</a><span>|</span><label class="collapse" for="c-39711389">[-]</label><label class="expand" for="c-39711389">[1 more]</label></div><br/><div class="children"><div class="content">Ugh I&#x27;m so sorry, you should definitely have been notified in advance about breaking changes, unless they were accidental bugs and regressions. That was something we took pretty seriously for the products I worked on.<p>I have definitely enjoyed using AWS support. But I&#x27;ve also encountered some broken&#x2F;janky functionality (eg using custom domain + api gateway + websockets + Lambda for the apparently niche-task of having a real website use the Lambda-websockets integration) on AWS that I don&#x27;t think would have made it to production at Google. I also really dislike how they handle project-level logging compared to how it&#x27;s done on GCP.<p>Ultimately I do think some GCP products like Bigquery, Cloud Run (I&#x27;m biased here), and Spanner as well as general DevEx&#x2F;reliability factors are compelling enough for GCP to be worth serious consideration, even if AWS offers better support.</div><br/></div></div></div></div><div id="39709235" class="c"><input type="checkbox" id="c-39709235" checked=""/><div class="controls bullet"><span class="by">jerrygenser</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708445">parent</a><span>|</span><a href="#39710908">prev</a><span>|</span><a href="#39707960">next</a><span>|</span><label class="collapse" for="c-39709235">[-]</label><label class="expand" for="c-39709235">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It is true though that GCP sometimes sunsets specific product functionality, requiring changes on the customers&#x27; part. Some of these are unavoidable (eg committing to apply security patches to Python 2.7 given that the rest of the world is mostly not upstreaming these patches anymore), but not all of them.<p>A good example is probably IoT. I&#x27;ve heard first hand anecdotes of very difficult migrations off this service.</div><br/></div></div></div></div><div id="39707960" class="c"><input type="checkbox" id="c-39707960" checked=""/><div class="controls bullet"><span class="by">rockostrich</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707350">parent</a><span>|</span><a href="#39708445">prev</a><span>|</span><a href="#39708083">next</a><span>|</span><label class="collapse" for="c-39707960">[-]</label><label class="expand" for="c-39707960">[8 more]</label></div><br/><div class="children"><div class="content">GCP products have a much better track record than Google consumer products when it comes to support since there are usually enterprise customers with multi-year contracts worth tens, if not hundreds, of millions of dollars using them.</div><br/><div id="39708223" class="c"><input type="checkbox" id="c-39708223" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707960">parent</a><span>|</span><a href="#39709226">next</a><span>|</span><label class="collapse" for="c-39708223">[-]</label><label class="expand" for="c-39708223">[4 more]</label></div><br/><div class="children"><div class="content">That’s what AppEngine customers thought.</div><br/><div id="39710094" class="c"><input type="checkbox" id="c-39710094" checked=""/><div class="controls bullet"><span class="by">tempnow987</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708223">parent</a><span>|</span><a href="#39708293">next</a><span>|</span><label class="collapse" for="c-39710094">[-]</label><label class="expand" for="c-39710094">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t they also hammer folks using google maps in a business &#x2F; cloud context?<p>I was also an old app engine user, but bailed ages ago (original app engine).</div><br/></div></div><div id="39708293" class="c"><input type="checkbox" id="c-39708293" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708223">parent</a><span>|</span><a href="#39710094">prev</a><span>|</span><a href="#39709226">next</a><span>|</span><label class="collapse" for="c-39708293">[-]</label><label class="expand" for="c-39708293">[2 more]</label></div><br/><div class="children"><div class="content">I worked on AppEngine (well, Serverless Compute) at Google for over 4 years and left on Friday. Did something happen to AppEngine in the last week?</div><br/><div id="39708416" class="c"><input type="checkbox" id="c-39708416" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708293">parent</a><span>|</span><a href="#39709226">next</a><span>|</span><label class="collapse" for="c-39708416">[-]</label><label class="expand" for="c-39708416">[1 more]</label></div><br/><div class="children"><div class="content">I’m talking about the pricing disaster that happened in 2017&#x2F;2018 where user prices went up from 10x-100x because Google wanted to kill the product without actually killing it.</div><br/></div></div></div></div></div></div><div id="39709226" class="c"><input type="checkbox" id="c-39709226" checked=""/><div class="controls bullet"><span class="by">jerrygenser</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707960">parent</a><span>|</span><a href="#39708223">prev</a><span>|</span><a href="#39709639">next</a><span>|</span><label class="collapse" for="c-39709226">[-]</label><label class="expand" for="c-39709226">[2 more]</label></div><br/><div class="children"><div class="content">IoT is one example of a big backbone service that was sunset.</div><br/><div id="39709348" class="c"><input type="checkbox" id="c-39709348" checked=""/><div class="controls bullet"><span class="by">endisneigh</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39709226">parent</a><span>|</span><a href="#39709639">next</a><span>|</span><label class="collapse" for="c-39709348">[-]</label><label class="expand" for="c-39709348">[1 more]</label></div><br/><div class="children"><div class="content">It had barely any usage though from what I can tell from searching about it.<p>Not that it’s any solace to those affected.</div><br/></div></div></div></div><div id="39709639" class="c"><input type="checkbox" id="c-39709639" checked=""/><div class="controls bullet"><span class="by">marcinzm</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707960">parent</a><span>|</span><a href="#39709226">prev</a><span>|</span><a href="#39708083">next</a><span>|</span><label class="collapse" for="c-39709639">[-]</label><label class="expand" for="c-39709639">[1 more]</label></div><br/><div class="children"><div class="content">AI Platform is a recent example that’s been deprecated.</div><br/></div></div></div></div></div></div><div id="39708083" class="c"><input type="checkbox" id="c-39708083" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39707350">prev</a><span>|</span><a href="#39707441">next</a><span>|</span><label class="collapse" for="c-39708083">[-]</label><label class="expand" for="c-39708083">[3 more]</label></div><br/><div class="children"><div class="content">My perspective from working both inside and outside of Google:<p>The external spanner documentation doesn’t seem as good as the internal documentation, in my opinion. Because it’s not generally well known outside of G, they ought to do a better job explaining it and its benefits. It truly is magical technology but you have to be a database nerd to see why.<p>It’s also pretty expensive and because you generally need to rewrite your applications to work with it, there is a degree of lockin. So taking on Spanner is a risky proposition - if your prices get hiked or it starts costing more than you want, you’ll have to spend even more time and money migrating off it. Spanner’s advantages over other DBs (trying to “solve” the CAP theorem) then become a curse, because it’s hard to find any other DB that gives you horizontal scaling, ACID, and high availability out of the box, and you might have to solve those problems yourself&#x2F;redesign the rest of your system.<p>Personally I would consider using Cloud Spanner, but I wouldn’t bet my business on it.</div><br/><div id="39710939" class="c"><input type="checkbox" id="c-39710939" checked=""/><div class="controls bullet"><span class="by">nojvek</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39708083">parent</a><span>|</span><a href="#39707441">next</a><span>|</span><label class="collapse" for="c-39710939">[-]</label><label class="expand" for="c-39710939">[2 more]</label></div><br/><div class="children"><div class="content">If you really have that much data and traffic, the $ costs start to add up to multiple engineer comp costs. At that point it’s cheaper to move to something you have good control over.<p>I.e sharding at application layer and connecting to the DB instance replica where the customer data is hosted.</div><br/><div id="39711539" class="c"><input type="checkbox" id="c-39711539" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39710939">parent</a><span>|</span><a href="#39707441">next</a><span>|</span><label class="collapse" for="c-39711539">[-]</label><label class="expand" for="c-39711539">[1 more]</label></div><br/><div class="children"><div class="content">Depends. The cost may pay for itself but the engineers you have already may have higher ROI things to do. It&#x27;s also nice to have operational stuff managed for you. Personally I&#x27;d be happy to pay extra for the kinds of problems Spanner solves to free myself up to do other things (to a point, ofc).<p>&gt; sharding at application layer and connecting to the DB instance replica where the customer data is hosted.<p>Spanner does global consistency&#x2F;replication. If having good performance per-tenant globally is a concern, this helps a lot, and is hard to implement on your own. It can also ultimately save you money by limiting cross-region traffic.</div><br/></div></div></div></div></div></div><div id="39707441" class="c"><input type="checkbox" id="c-39707441" checked=""/><div class="controls bullet"><span class="by">shalabhc</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39708083">prev</a><span>|</span><a href="#39709152">next</a><span>|</span><label class="collapse" for="c-39707441">[-]</label><label class="expand" for="c-39707441">[3 more]</label></div><br/><div class="children"><div class="content">Global consistency is expensive, both latency-wise and cost-wise. In reality most apps don&#x27;t need global serializability across all objects. For instance, you probably don&#x27;t need serializability across different tenants, organizations, workspaces, etc. Spanner provides serializability across all objects IIUC - so you pay for it whether you need it or not.<p>The other side of something like Spanner is the quorum-based latency is often optimized by adding another cache on top, which instantly defeats the original consistency guarantees. The consistency of (spanner+my_cache) is not the same as the consistency of spanner. So if we&#x27;re back to app level consistency guarantees anyway, turns out the &quot;managed&quot; solution is only partial.<p>Ideally the managed db systems would have flexible consistency, allowing me to configure not just which object sets need consistency but also letting me configure caches with lag tolerance. This would let me choose trade-offs without having to implement consistent caching and other optimization tricks on top of globally consistent&#x2F;serializable databases.</div><br/><div id="39708566" class="c"><input type="checkbox" id="c-39708566" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707441">parent</a><span>|</span><a href="#39707635">next</a><span>|</span><label class="collapse" for="c-39708566">[-]</label><label class="expand" for="c-39708566">[1 more]</label></div><br/><div class="children"><div class="content">While it doesn&#x27;t help much with the costs of replication, Spanner can be configured with read only replicas that don&#x27;t participate in voting for commits, so they don&#x27;t impact the quorum latency.<p>Reads can then be done with different consistency requirements, e.g., bounded staleness (which guarantees data less stale than the time bound requested).<p>See <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;reference&#x2F;rest&#x2F;v1&#x2F;TransactionOptions" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;reference&#x2F;rest&#x2F;v1&#x2F;Tran...</a> or <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;reads#read_types" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;reads#read_types</a> and <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;create-manage-configurations#create-configuration" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;create-manage-configur...</a></div><br/></div></div><div id="39707635" class="c"><input type="checkbox" id="c-39707635" checked=""/><div class="controls bullet"><span class="by">eatonphil</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707441">parent</a><span>|</span><a href="#39708566">prev</a><span>|</span><a href="#39709152">next</a><span>|</span><label class="collapse" for="c-39707635">[-]</label><label class="expand" for="c-39707635">[1 more]</label></div><br/><div class="children"><div class="content">See also: &quot;Strict-serializability, but at what cost, for what purpose?&quot;<p><a href="https:&#x2F;&#x2F;muratbuffalo.blogspot.com&#x2F;2022&#x2F;08&#x2F;strict-serializability-but-at-what-cost.html" rel="nofollow">https:&#x2F;&#x2F;muratbuffalo.blogspot.com&#x2F;2022&#x2F;08&#x2F;strict-serializabi...</a>.</div><br/></div></div></div></div><div id="39709152" class="c"><input type="checkbox" id="c-39709152" checked=""/><div class="controls bullet"><span class="by">zenbowman</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39707441">prev</a><span>|</span><a href="#39707289">next</a><span>|</span><label class="collapse" for="c-39709152">[-]</label><label class="expand" for="c-39709152">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t say &quot;infinite&quot;, its still susceptible to read hotspotting; and while fine-grained locking enables generally higher write throughputs, you can still get in a situation where interconnected updates end up being pretty slow.<p>That said, its way better than anything else I&#x27;ve used in my career.</div><br/></div></div><div id="39707289" class="c"><input type="checkbox" id="c-39707289" checked=""/><div class="controls bullet"><span class="by">ksb</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39709152">prev</a><span>|</span><a href="#39707235">next</a><span>|</span><label class="collapse" for="c-39707289">[-]</label><label class="expand" for="c-39707289">[1 more]</label></div><br/><div class="children"><div class="content">Ping time from AWS data centers to GCP ones</div><br/></div></div><div id="39707235" class="c"><input type="checkbox" id="c-39707235" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39707289">prev</a><span>|</span><a href="#39707202">next</a><span>|</span><label class="collapse" for="c-39707235">[-]</label><label class="expand" for="c-39707235">[3 more]</label></div><br/><div class="children"><div class="content">The problem is nobody outside Google trusts them to run or operate anything.<p>Edit: To the Googlers downvoting these comments. Your behavior only reinforces our views.</div><br/><div id="39707281" class="c"><input type="checkbox" id="c-39707281" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707235">parent</a><span>|</span><a href="#39707202">next</a><span>|</span><label class="collapse" for="c-39707281">[-]</label><label class="expand" for="c-39707281">[2 more]</label></div><br/><div class="children"><div class="content">Google means: good chance discontinued after you have worked out the bugs and have a stable system at last</div><br/><div id="39707758" class="c"><input type="checkbox" id="c-39707758" checked=""/><div class="controls bullet"><span class="by">groestl</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707281">parent</a><span>|</span><a href="#39707202">next</a><span>|</span><label class="collapse" for="c-39707758">[-]</label><label class="expand" for="c-39707758">[1 more]</label></div><br/><div class="children"><div class="content">This is definitely not the case with their core cloud products.<p>&gt; almost every project not using Spanner was moving to Spanner<p>This even includes Datastore. Even Datastore moved to Spanner.</div><br/></div></div></div></div></div></div><div id="39707202" class="c"><input type="checkbox" id="c-39707202" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39707181">parent</a><span>|</span><a href="#39707235">prev</a><span>|</span><a href="#39712266">next</a><span>|</span><label class="collapse" for="c-39707202">[-]</label><label class="expand" for="c-39707202">[3 more]</label></div><br/><div class="children"><div class="content">Why would <i>anyone</i> marry themselves to Google? That sounds like the most boneheaded move possible.<p>First, you should never be beholden to a single vendor for the most critical technological underpinnings. You&#x27;re backing yourself into a corner.<p>But more importantly, Google can&#x27;t even figure out how to prioritize their cloud efforts. That&#x27;s not a good partnership to be in for anyone except Google.<p>I wouldn&#x27;t care if my solution was 10x worse than Cloud Spanner from a technology perspective. It&#x27;d be 1000x better from a strategy perspective.<p>You can hire engineers to do consistency at scale. It&#x27;s your core competency and you can&#x27;t just handwave and outsource that, lest you wind up stuck in a crevasse. Hire smart engineers and do the work yourself. It&#x27;ll pay off.</div><br/><div id="39709057" class="c"><input type="checkbox" id="c-39709057" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39707202">parent</a><span>|</span><a href="#39712266">next</a><span>|</span><label class="collapse" for="c-39709057">[-]</label><label class="expand" for="c-39709057">[2 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t, that&#x27;s why spanner only exists a Google. That tech is that good, not found anywhere else.</div><br/><div id="39709739" class="c"><input type="checkbox" id="c-39709739" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39707181">root</a><span>|</span><a href="#39709057">parent</a><span>|</span><a href="#39712266">next</a><span>|</span><label class="collapse" for="c-39709739">[-]</label><label class="expand" for="c-39709739">[1 more]</label></div><br/><div class="children"><div class="content">But you don&#x27;t need it. There are a limitless number of ways to deal with the problems spanner solves. And by choosing your own, you can focus on the subset that matter to your case and not be tied down to Google.</div><br/></div></div></div></div></div></div></div></div><div id="39712266" class="c"><input type="checkbox" id="c-39712266" checked=""/><div class="controls bullet"><span class="by">Xenya</span><span>|</span><a href="#39707181">prev</a><span>|</span><a href="#39708510">next</a><span>|</span><label class="collapse" for="c-39712266">[-]</label><label class="expand" for="c-39712266">[1 more]</label></div><br/><div class="children"><div class="content">amazing team, but the author doesn&#x27;t seem to understand the details</div><br/></div></div><div id="39708510" class="c"><input type="checkbox" id="c-39708510" checked=""/><div class="controls bullet"><span class="by">cynicalsecurity</span><span>|</span><a href="#39712266">prev</a><span>|</span><a href="#39708284">next</a><span>|</span><label class="collapse" for="c-39708510">[-]</label><label class="expand" for="c-39708510">[7 more]</label></div><br/><div class="children"><div class="content">They came up with a really over-engineered, over-complicated attempt at splitting data into multiple databases. I&#x27;m not sure this was the best idea or even a good idea, but then I also don&#x27;t understand how it came to the situation when they only had a few months before their current database gets overflown and the whole system collapses.</div><br/><div id="39708638" class="c"><input type="checkbox" id="c-39708638" checked=""/><div class="controls bullet"><span class="by">dwaltrip</span><span>|</span><a href="#39708510">parent</a><span>|</span><a href="#39708284">next</a><span>|</span><label class="collapse" for="c-39708638">[-]</label><label class="expand" for="c-39708638">[6 more]</label></div><br/><div class="children"><div class="content">Can you offer insight into what a better approach might have been?</div><br/><div id="39708760" class="c"><input type="checkbox" id="c-39708760" checked=""/><div class="controls bullet"><span class="by">TheP1000</span><span>|</span><a href="#39708510">root</a><span>|</span><a href="#39708638">parent</a><span>|</span><a href="#39708284">next</a><span>|</span><label class="collapse" for="c-39708760">[-]</label><label class="expand" for="c-39708760">[5 more]</label></div><br/><div class="children"><div class="content">As others have mentioned, moving to per tenant databases can really simplify things at scale and doesn&#x27;t leave a massive amount of engineering complexity and debt in its wake.<p>I feel sorry for the team managing this 5 years from now.</div><br/><div id="39709295" class="c"><input type="checkbox" id="c-39709295" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39708510">root</a><span>|</span><a href="#39708760">parent</a><span>|</span><a href="#39708959">next</a><span>|</span><label class="collapse" for="c-39709295">[-]</label><label class="expand" for="c-39709295">[3 more]</label></div><br/><div class="children"><div class="content">Moving to a per-tenant database sounds like even more work to me than moving to shards. Moving to per-tenant means rewriting _everything_ - moving to shards has you rewriting a lot less.</div><br/><div id="39712452" class="c"><input type="checkbox" id="c-39712452" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#39708510">root</a><span>|</span><a href="#39709295">parent</a><span>|</span><a href="#39709460">next</a><span>|</span><label class="collapse" for="c-39712452">[-]</label><label class="expand" for="c-39712452">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by &quot;rewriting everything&quot;? Or maybe your definition of &quot;per-tenant database&quot; is different from mine. In our product, it&#x27;s just a small layer which routes requests to the target organization&#x27;s DB. When an organization is created, we create a new DB. Most of application code has no idea there are different DBs under the hood.<p>There are logical DBs (folders&#x2F;files on a single physical server), and there&#x27;s a few physical servers. We&#x27;re currently at the stage where the first physical server hosts most of smaller organizations, and all other physical servers are usually dedicated servers for larger clients with high loads.</div><br/></div></div><div id="39709460" class="c"><input type="checkbox" id="c-39709460" checked=""/><div class="controls bullet"><span class="by">infra_dev</span><span>|</span><a href="#39708510">root</a><span>|</span><a href="#39709295">parent</a><span>|</span><a href="#39712452">prev</a><span>|</span><a href="#39708959">next</a><span>|</span><label class="collapse" for="c-39709460">[-]</label><label class="expand" for="c-39709460">[1 more]</label></div><br/><div class="children"><div class="content">This is possible to do, but lots of engineering. You can provide the experience of a single DB while each tenant can be placed in their own dedicated Postgres compute. This would help the application to stay the same while tenants are moved to independent computes (you can even move only a few tenants and leave the rest on a shared Postgres compute).</div><br/></div></div></div></div><div id="39708959" class="c"><input type="checkbox" id="c-39708959" checked=""/><div class="controls bullet"><span class="by">cynicalsecurity</span><span>|</span><a href="#39708510">root</a><span>|</span><a href="#39708760">parent</a><span>|</span><a href="#39709295">prev</a><span>|</span><a href="#39708284">next</a><span>|</span><label class="collapse" for="c-39708959">[-]</label><label class="expand" for="c-39708959">[1 more]</label></div><br/><div class="children"><div class="content">Exactly this. But at this point, I don&#x27;t even want to give them advice, I don&#x27;t really like their service. I like Lunacy more.</div><br/></div></div></div></div></div></div></div></div><div id="39708284" class="c"><input type="checkbox" id="c-39708284" checked=""/><div class="controls bullet"><span class="by">HermitX</span><span>|</span><a href="#39708510">prev</a><span>|</span><a href="#39708742">next</a><span>|</span><label class="collapse" for="c-39708284">[-]</label><label class="expand" for="c-39708284">[2 more]</label></div><br/><div class="children"><div class="content">I This is an intriguing article, clearly showing the team&#x27;s fondness for Postgres. However, Postgres is an OLTP product. I&#x27;m curious about what system Figma&#x27;s data team uses for their data analysis tasks.</div><br/><div id="39709200" class="c"><input type="checkbox" id="c-39709200" checked=""/><div class="controls bullet"><span class="by">jerrygenser</span><span>|</span><a href="#39708284">parent</a><span>|</span><a href="#39708742">next</a><span>|</span><label class="collapse" for="c-39709200">[-]</label><label class="expand" for="c-39709200">[1 more]</label></div><br/><div class="children"><div class="content">They mentioned analyzing query logs in Snowflake in this very article. So... at least they use Snowflake for some things?</div><br/></div></div></div></div><div id="39708742" class="c"><input type="checkbox" id="c-39708742" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#39708284">prev</a><span>|</span><a href="#39709763">next</a><span>|</span><label class="collapse" for="c-39708742">[-]</label><label class="expand" for="c-39708742">[3 more]</label></div><br/><div class="children"><div class="content">How transactions work when you end up querying different shards?</div><br/><div id="39709308" class="c"><input type="checkbox" id="c-39709308" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39708742">parent</a><span>|</span><a href="#39708910">next</a><span>|</span><label class="collapse" for="c-39709308">[-]</label><label class="expand" for="c-39709308">[1 more]</label></div><br/><div class="children"><div class="content">I imagine that&#x27;s one of the reasons they have &quot;colos&quot; - you can aim to collocate tables that are likely to be part of the same transaction in the same shard by putting them in the same colo group.</div><br/></div></div><div id="39708910" class="c"><input type="checkbox" id="c-39708910" checked=""/><div class="controls bullet"><span class="by">blauditore</span><span>|</span><a href="#39708742">parent</a><span>|</span><a href="#39709308">prev</a><span>|</span><a href="#39709763">next</a><span>|</span><label class="collapse" for="c-39708910">[-]</label><label class="expand" for="c-39708910">[1 more]</label></div><br/><div class="children"><div class="content">IIUC they never have db transactions across shards, because customers are basically data silos, which makes sharding quite straightforward.</div><br/></div></div></div></div><div id="39709763" class="c"><input type="checkbox" id="c-39709763" checked=""/><div class="controls bullet"><span class="by">AtlasBarfed</span><span>|</span><a href="#39708742">prev</a><span>|</span><a href="#39709605">next</a><span>|</span><label class="collapse" for="c-39709763">[-]</label><label class="expand" for="c-39709763">[1 more]</label></div><br/><div class="children"><div class="content">1 postgres<p>2 postgres replicas+sharding<p>3 Cassandra &#x2F; dynamo<p>If you are at stage 2, you are using bandaids. You need to start architecting a transition of your most heavily used data views to truly scalable databases like Cassandra &#x2F; dynamo. I have not used foundation, but aphyr liked it.<p>That transition takes time, evaluation, pro typing, and organizational learning both at the application programmer, support engineer, and management.</div><br/></div></div><div id="39709605" class="c"><input type="checkbox" id="c-39709605" checked=""/><div class="controls bullet"><span class="by">tbarbugli</span><span>|</span><a href="#39709763">prev</a><span>|</span><a href="#39711555">next</a><span>|</span><label class="collapse" for="c-39709605">[-]</label><label class="expand" for="c-39709605">[1 more]</label></div><br/><div class="children"><div class="content">Citus seems incredibly close to what they built, I wonder why they did not use it</div><br/></div></div><div id="39711555" class="c"><input type="checkbox" id="c-39711555" checked=""/><div class="controls bullet"><span class="by">DonnyV</span><span>|</span><a href="#39709605">prev</a><span>|</span><a href="#39707278">next</a><span>|</span><label class="collapse" for="c-39711555">[-]</label><label class="expand" for="c-39711555">[1 more]</label></div><br/><div class="children"><div class="content">Is it me or did they just recreate Mongodb Shard feature? But now they have to maintain it. They would of been better off going Mongodb or another document database. Then you wouldn&#x27;t have to worry about scheme changes. Since your scheme lives there n your data model. You could just map changed fields. They should of just used a tenant based design. If a customer was hindering performance on neighboring tenants. They could just migrate them over to their own large server.</div><br/></div></div><div id="39707278" class="c"><input type="checkbox" id="c-39707278" checked=""/><div class="controls bullet"><span class="by">goshx</span><span>|</span><a href="#39711555">prev</a><span>|</span><a href="#39707916">next</a><span>|</span><label class="collapse" for="c-39707278">[-]</label><label class="expand" for="c-39707278">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Sorry, you’ve stumbled upon a temporary technical issue. Please try refreshing this page in a moment.&quot;<p>Have they? :) I am excited to read the article when it loads</div><br/><div id="39707518" class="c"><input type="checkbox" id="c-39707518" checked=""/><div class="controls bullet"><span class="by">nix0n</span><span>|</span><a href="#39707278">parent</a><span>|</span><a href="#39707904">next</a><span>|</span><label class="collapse" for="c-39707518">[-]</label><label class="expand" for="c-39707518">[1 more]</label></div><br/><div class="children"><div class="content">It worked for me on the first try, but here&#x27;s an archive link in case it goes down again: <a href="https:&#x2F;&#x2F;archive.is&#x2F;xusR7" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;xusR7</a></div><br/></div></div><div id="39707904" class="c"><input type="checkbox" id="c-39707904" checked=""/><div class="controls bullet"><span class="by">Lucasoato</span><span>|</span><a href="#39707278">parent</a><span>|</span><a href="#39707518">prev</a><span>|</span><a href="#39707916">next</a><span>|</span><label class="collapse" for="c-39707904">[-]</label><label class="expand" for="c-39707904">[1 more]</label></div><br/><div class="children"><div class="content">This might be another case of “death by HN”</div><br/></div></div></div></div><div id="39707916" class="c"><input type="checkbox" id="c-39707916" checked=""/><div class="controls bullet"><span class="by">cynicalsecurity</span><span>|</span><a href="#39707278">prev</a><span>|</span><a href="#39707553">next</a><span>|</span><label class="collapse" for="c-39707916">[-]</label><label class="expand" for="c-39707916">[1 more]</label></div><br/><div class="children"><div class="content">It would have benefitted the article to use less of annoying corporate talk.</div><br/></div></div><div id="39707553" class="c"><input type="checkbox" id="c-39707553" checked=""/><div class="controls bullet"><span class="by">TkTech</span><span>|</span><a href="#39707916">prev</a><span>|</span><a href="#39708226">next</a><span>|</span><label class="collapse" for="c-39707553">[-]</label><label class="expand" for="c-39707553">[6 more]</label></div><br/><div class="children"><div class="content">Am I the only one finding the layout of this blog distracting? Kind of disappointing from a UX company. The images are also massive, the page was 42.21mb!<p>Good article none the less! Always appreciate when companies like Figma document technical challenges.</div><br/><div id="39709265" class="c"><input type="checkbox" id="c-39709265" checked=""/><div class="controls bullet"><span class="by">ghostly_s</span><span>|</span><a href="#39707553">parent</a><span>|</span><a href="#39708811">next</a><span>|</span><label class="collapse" for="c-39709265">[-]</label><label class="expand" for="c-39709265">[1 more]</label></div><br/><div class="children"><div class="content">Odd, it looks perfectly bog-standard for me on Firefox and iOS, aside from the lavender bg which I quite like. I even disabled my ad-blocker to see if it made a difference, no changing bg colors for me...</div><br/></div></div><div id="39708811" class="c"><input type="checkbox" id="c-39708811" checked=""/><div class="controls bullet"><span class="by">zelphirkalt</span><span>|</span><a href="#39707553">parent</a><span>|</span><a href="#39709265">prev</a><span>|</span><a href="#39707776">next</a><span>|</span><label class="collapse" for="c-39708811">[-]</label><label class="expand" for="c-39708811">[1 more]</label></div><br/><div class="children"><div class="content">Maybe someone designed this castle in Figma.</div><br/></div></div><div id="39707776" class="c"><input type="checkbox" id="c-39707776" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#39707553">parent</a><span>|</span><a href="#39708811">prev</a><span>|</span><a href="#39708226">next</a><span>|</span><label class="collapse" for="c-39707776">[-]</label><label class="expand" for="c-39707776">[3 more]</label></div><br/><div class="children"><div class="content">It seems like someone at Figma decided to use the latest CSS tricks they just had discovered. Changing background color? Come on.</div><br/><div id="39708161" class="c"><input type="checkbox" id="c-39708161" checked=""/><div class="controls bullet"><span class="by">Cwizard</span><span>|</span><a href="#39707553">root</a><span>|</span><a href="#39707776">parent</a><span>|</span><a href="#39709051">next</a><span>|</span><label class="collapse" for="c-39708161">[-]</label><label class="expand" for="c-39708161">[1 more]</label></div><br/><div class="children"><div class="content">I thought this was a bug at first. Does anyone actually want this?</div><br/></div></div></div></div></div></div><div id="39708226" class="c"><input type="checkbox" id="c-39708226" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#39707553">prev</a><span>|</span><a href="#39708844">next</a><span>|</span><label class="collapse" for="c-39708226">[-]</label><label class="expand" for="c-39708226">[2 more]</label></div><br/><div class="children"><div class="content">Given the list of authors and acknowledgees, what I&#x27;d really like to read is the differences between this solution and Dropbox&#x27;s.</div><br/><div id="39709477" class="c"><input type="checkbox" id="c-39709477" checked=""/><div class="controls bullet"><span class="by">sp1nozick</span><span>|</span><a href="#39708226">parent</a><span>|</span><a href="#39708844">next</a><span>|</span><label class="collapse" for="c-39709477">[-]</label><label class="expand" for="c-39709477">[1 more]</label></div><br/><div class="children"><div class="content">horizontal sharding is such a foundational skillset in working with databases - it&#x27;s essential to database architecture</div><br/></div></div></div></div><div id="39708844" class="c"><input type="checkbox" id="c-39708844" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39708226">prev</a><span>|</span><a href="#39708374">next</a><span>|</span><label class="collapse" for="c-39708844">[-]</label><label class="expand" for="c-39708844">[1 more]</label></div><br/><div class="children"><div class="content">Honestly it&#x27;s depressing that I remember doing this same thing more than a decade ago and we still have to spend developer cycles on this nonsense in 2024.</div><br/></div></div><div id="39707066" class="c"><input type="checkbox" id="c-39707066" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39709488">prev</a><span>|</span><label class="collapse" for="c-39707066">[-]</label><label class="expand" for="c-39707066">[16 more]</label></div><br/><div class="children"><div class="content">This is such a familiar story. Company starts with a centralized database, runs into scaling problems, then spends man-years sharding it. Just use a distributed database.</div><br/><div id="39707249" class="c"><input type="checkbox" id="c-39707249" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39707066">parent</a><span>|</span><a href="#39707106">next</a><span>|</span><label class="collapse" for="c-39707249">[-]</label><label class="expand" for="c-39707249">[1 more]</label></div><br/><div class="children"><div class="content">&quot;<i>Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.</i>&quot;<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/></div></div><div id="39707106" class="c"><input type="checkbox" id="c-39707106" checked=""/><div class="controls bullet"><span class="by">jack_riminton</span><span>|</span><a href="#39707066">parent</a><span>|</span><a href="#39707249">prev</a><span>|</span><a href="#39707104">next</a><span>|</span><label class="collapse" for="c-39707106">[-]</label><label class="expand" for="c-39707106">[7 more]</label></div><br/><div class="children"><div class="content">If every startup used every scale-proof method available from the beginning they&#x27;d never have the time or resources to build the products to get the customers that would require them to use the scale-proof methods</div><br/><div id="39707150" class="c"><input type="checkbox" id="c-39707150" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707106">parent</a><span>|</span><a href="#39707104">next</a><span>|</span><label class="collapse" for="c-39707150">[-]</label><label class="expand" for="c-39707150">[6 more]</label></div><br/><div class="children"><div class="content">I agree with your general point but there are relational distributed databases, open source and &quot;serverless&quot;, that are compatible with MySQL (planetscale, tidb, vitess...) and postgres (citus, cockroachdb...)<p>edited for examples.</div><br/><div id="39707196" class="c"><input type="checkbox" id="c-39707196" checked=""/><div class="controls bullet"><span class="by">mplanchard</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707150">parent</a><span>|</span><a href="#39707169">next</a><span>|</span><label class="collapse" for="c-39707196">[-]</label><label class="expand" for="c-39707196">[1 more]</label></div><br/><div class="children"><div class="content">And many of these are substantially more expensive than RDS, or have terrible INSERT performance, or require making the correct decisions really early about what to use as partition keys. There&#x27;s no free lunch, sadly.</div><br/></div></div><div id="39707169" class="c"><input type="checkbox" id="c-39707169" checked=""/><div class="controls bullet"><span class="by">noja</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707150">parent</a><span>|</span><a href="#39707196">prev</a><span>|</span><a href="#39707294">next</a><span>|</span><label class="collapse" for="c-39707169">[-]</label><label class="expand" for="c-39707169">[3 more]</label></div><br/><div class="children"><div class="content">One reason they don&#x27;t is unhelpful comments like these: alluding to products without naming them.</div><br/><div id="39707238" class="c"><input type="checkbox" id="c-39707238" checked=""/><div class="controls bullet"><span class="by">ofrzeta</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707169">parent</a><span>|</span><a href="#39707210">next</a><span>|</span><label class="collapse" for="c-39707238">[-]</label><label class="expand" for="c-39707238">[1 more]</label></div><br/><div class="children"><div class="content">From the article: &quot;During our evaluation, we explored CockroachDB, TiDB, Spanner, and Vitess&quot;. Three of them are open source if I am not mistaken.</div><br/></div></div></div></div><div id="39707294" class="c"><input type="checkbox" id="c-39707294" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707150">parent</a><span>|</span><a href="#39707169">prev</a><span>|</span><a href="#39707104">next</a><span>|</span><label class="collapse" for="c-39707294">[-]</label><label class="expand" for="c-39707294">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think these were mature products when Figma started to be developed in 2012.</div><br/></div></div></div></div></div></div><div id="39707104" class="c"><input type="checkbox" id="c-39707104" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#39707066">parent</a><span>|</span><a href="#39707106">prev</a><span>|</span><a href="#39707218">next</a><span>|</span><label class="collapse" for="c-39707104">[-]</label><label class="expand" for="c-39707104">[4 more]</label></div><br/><div class="children"><div class="content">This assumes that using a distributed database from the start doesn&#x27;t offer it&#x27;s own penalties&#x2F;drawbacks (particularly in 2016).<p>Particularly considering as per the figma note, they consider their data highly relational (i.e. presumably this means lots of joins in queries)<p>What database would you have chosen?</div><br/><div id="39707132" class="c"><input type="checkbox" id="c-39707132" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707104">parent</a><span>|</span><a href="#39707296">prev</a><span>|</span><a href="#39707218">next</a><span>|</span><label class="collapse" for="c-39707132">[-]</label><label class="expand" for="c-39707132">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a fair response for then, but not today where you&#x27;re spoiled for choice. Spanner was released as a service in 2017, which isn&#x27;t far off.</div><br/><div id="39708660" class="c"><input type="checkbox" id="c-39708660" checked=""/><div class="controls bullet"><span class="by">prisenco</span><span>|</span><a href="#39707066">root</a><span>|</span><a href="#39707132">parent</a><span>|</span><a href="#39707218">next</a><span>|</span><label class="collapse" for="c-39708660">[-]</label><label class="expand" for="c-39708660">[1 more]</label></div><br/><div class="children"><div class="content">Spanner is quite expensive though.</div><br/></div></div></div></div></div></div><div id="39707218" class="c"><input type="checkbox" id="c-39707218" checked=""/><div class="controls bullet"><span class="by">mamcx</span><span>|</span><a href="#39707066">parent</a><span>|</span><a href="#39707104">prev</a><span>|</span><a href="#39707264">next</a><span>|</span><label class="collapse" for="c-39707218">[-]</label><label class="expand" for="c-39707218">[1 more]</label></div><br/><div class="children"><div class="content">There are many kinds of apps that use of &quot;distributed&quot; databases is an antipattern...and useless to make them scale.<p>MOST apps did not need more than &quot;tenant-per-company&quot; and then, maybe, distributed among a small set of servers.<p>Is it just that the kind of app that shows here (and has this problems) are just niche apps like social networks and complex chat apps.</div><br/></div></div><div id="39707264" class="c"><input type="checkbox" id="c-39707264" checked=""/><div class="controls bullet"><span class="by">battwell</span><span>|</span><a href="#39707066">parent</a><span>|</span><a href="#39707218">prev</a><span>|</span><a href="#39707101">next</a><span>|</span><label class="collapse" for="c-39707264">[-]</label><label class="expand" for="c-39707264">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t seem a crazy way to start a company. RDS will have scaling problems but is very mature and fairly easy to use early on when you&#x27;re working on your MVP<p>I&#x27;ve used CRDB early on at a startup. There was some overhead. You don&#x27;t get all the nice PSQL features<p>Although it did save us a giant migration later on</div><br/></div></div></div></div></div></div></div></div></div></body></html>