<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1691744463831" as="style"/><link rel="stylesheet" href="styles.css?v=1691744463831"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://simonwillison.net/2020/Oct/9/git-scraping/">Git scraping: track changes over time by scraping to a Git repository</a>Â <span class="domain">(<a href="https://simonwillison.net">simonwillison.net</a>)</span></div><div class="subtext"><span>ekiauhce</span> | <span>51 comments</span></div><br/><div><div id="37083019" class="c"><input type="checkbox" id="c-37083019" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083831">next</a><span>|</span><label class="collapse" for="c-37083019">[-]</label><label class="expand" for="c-37083019">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been promoting this idea for a few years now, and I&#x27;ve seen an increasing number of people put it into action.<p>A fun way to track how people are using this is with the git-scraping topic on GitHub:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;topics&#x2F;git-scraping?o=desc&amp;s=updated">https:&#x2F;&#x2F;github.com&#x2F;topics&#x2F;git-scraping?o=desc&amp;s=updated</a><p>That page orders repos tagged git-scraping by most-recently-updated, which shows which scrapers have run most recently.<p>As I write this, just in the last minute repos that updated include:<p>queensland-traffic-conditions: <a href="https:&#x2F;&#x2F;github.com&#x2F;drzax&#x2F;queensland-traffic-conditions">https:&#x2F;&#x2F;github.com&#x2F;drzax&#x2F;queensland-traffic-conditions</a><p>bbcrss: <a href="https:&#x2F;&#x2F;github.com&#x2F;jasoncartwright&#x2F;bbcrss">https:&#x2F;&#x2F;github.com&#x2F;jasoncartwright&#x2F;bbcrss</a><p>metrobus-timetrack-history: <a href="https:&#x2F;&#x2F;github.com&#x2F;jackharrhy&#x2F;metrobus-timetrack-history">https:&#x2F;&#x2F;github.com&#x2F;jackharrhy&#x2F;metrobus-timetrack-history</a><p>bchydro-outages: <a href="https:&#x2F;&#x2F;github.com&#x2F;outages&#x2F;bchydro-outages">https:&#x2F;&#x2F;github.com&#x2F;outages&#x2F;bchydro-outages</a></div><br/><div id="37086506" class="c"><input type="checkbox" id="c-37086506" checked=""/><div class="controls bullet"><span class="by">tomashubelbauer</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37084411">next</a><span>|</span><label class="collapse" for="c-37086506">[-]</label><label class="expand" for="c-37086506">[1 more]</label></div><br/><div class="children"><div class="content">Hey, I have been doing the same thing as you for some types of online resources I am interested in for a long time, too. Really nice work! One small thing you might find interesting: in the beginning, I would push the automated commits via my GitHub identity so they would all be associated to my account as my activity. This annoyed me but I also couldn&#x27;t accept the idea of the commits coming from a non-GitHub account (so the username wouldn&#x27;t be clickable) nor the idea of creating and maintaining a separate set of credentials to push the change under. I though about what would be a good default identity I could use and after some experimentation I found that if you use these credentials, the commits appear as if they GitHub Actions native GitHub bot pushed them:<p><pre><code>        git config --global user.email &quot;41898282+github-actions[bot]@users.noreply.github.com&quot;
        git config --global user.name &quot;github-actions[bot]&quot;
</code></pre>
They have the right icon, clickable username and it is as simple as just using this email and name. You or someone else might like to do this, too, so here&#x27;s me sharing this neat trick I found.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;TomasHubelbauer&#x2F;github-actions#write-workflow">https:&#x2F;&#x2F;github.com&#x2F;TomasHubelbauer&#x2F;github-actions#write-work...</a></div><br/></div></div><div id="37084411" class="c"><input type="checkbox" id="c-37084411" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37086506">prev</a><span>|</span><a href="#37083531">next</a><span>|</span><label class="collapse" for="c-37084411">[-]</label><label class="expand" for="c-37084411">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for linking to the topic, that was interesting<p>As a heads up to anyone trying this stunt, please be mindful that git-diff is ultimately a <i>line oriented</i> action (yeah, yeah, &quot;git stores snapshots&quot;)<p>For example <a href="https:&#x2F;&#x2F;github.com&#x2F;pmc-ss&#x2F;mastodon-scraping&#x2F;commit&#x2F;2a15ce1b2c79d0837f484e0f33d88d03ab6f442d">https:&#x2F;&#x2F;github.com&#x2F;pmc-ss&#x2F;mastodon-scraping&#x2F;commit&#x2F;2a15ce1b2...</a> is all :fu: because git sees basically the &quot;first line&quot; changed<p>However, had the author normalized the instances.json with something like &quot;jq -S&quot; then one would end up with a more reasonable 1736 textual changes, which github would have almost certainly rendered<p><pre><code>  diff -u \
    &lt;(git ls-tree HEAD^1 -- instances.json | cut -d&#x27; &#x27; -f3 | xargs git show --pretty=raw | jq -S) \
    &lt;(git ls-tree HEAD   -- instances.json | cut -d&#x27; &#x27; -f3 | xargs git show --pretty=raw | jq -S)
  --- &#x2F;dev&#x2F;fd&#x2F;63 2023-08-10 19:31:03.000000000 -0700
  +++ &#x2F;dev&#x2F;fd&#x2F;62 2023-08-10 19:31:03.000000000 -0700
  @@ -1,6 +1,6 @@
   [
     {
  -    &quot;connections&quot;: 5088,
  +    &quot;connections&quot;: 5089,</code></pre></div><br/></div></div><div id="37083531" class="c"><input type="checkbox" id="c-37083531" checked=""/><div class="controls bullet"><span class="by">nickmp</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37084411">prev</a><span>|</span><a href="#37085109">next</a><span>|</span><label class="collapse" for="c-37083531">[-]</label><label class="expand" for="c-37083531">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been doing this to track the UK&#x27;s &quot;carbon intensity&quot; forecast and compare it with what is actually measured. Now have several months&#x27; data about the quality of the model and forecast published here: <a href="https:&#x2F;&#x2F;carbonintensity.org.uk&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;carbonintensity.org.uk&#x2F;</a> . Thanks for the inspiration!<p><a href="https:&#x2F;&#x2F;github.com&#x2F;nmpowell&#x2F;carbon-intensity-forecast-tracking&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;nmpowell&#x2F;carbon-intensity-forecast-tracki...</a></div><br/></div></div><div id="37085109" class="c"><input type="checkbox" id="c-37085109" checked=""/><div class="controls bullet"><span class="by">emmelaich</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37083531">prev</a><span>|</span><a href="#37083371">next</a><span>|</span><label class="collapse" for="c-37085109">[-]</label><label class="expand" for="c-37085109">[1 more]</label></div><br/><div class="children"><div class="content">Yeah this is great, I&#x27;m sure many including me have used a similar tool but half-arsed for internal use.  For me it was tracking changes to a website where all the changes were done through a gui.  I was asked to provide a backup &#x2F; rollback which  I did with git scraping.<p>I also started but never finished a terms-of-service, privacy-statement tracker. I stopped at the boring part where you&#x27;d have find the url for thousands of companies and&#x2F;or engage others to do it.</div><br/></div></div><div id="37083371" class="c"><input type="checkbox" id="c-37083371" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37085109">prev</a><span>|</span><a href="#37083877">next</a><span>|</span><label class="collapse" for="c-37083371">[-]</label><label class="expand" for="c-37083371">[1 more]</label></div><br/><div class="children"><div class="content">i do this as a demo:  <a href="https:&#x2F;&#x2F;github.com&#x2F;swyxio&#x2F;gh-action-data-scraping">https:&#x2F;&#x2F;github.com&#x2F;swyxio&#x2F;gh-action-data-scraping</a><p>but conveniently it also serves as a way to track the downtime of github actions, which used to be bad but seems to be fine the last couple months: <a href="https:&#x2F;&#x2F;github.com&#x2F;swyxio&#x2F;gh-action-data-scraping&#x2F;assets&#x2F;6764957&#x2F;934d5e15-ba33-451b-bef4-5e31b34ed52b">https:&#x2F;&#x2F;github.com&#x2F;swyxio&#x2F;gh-action-data-scraping&#x2F;assets&#x2F;676...</a></div><br/></div></div><div id="37083877" class="c"><input type="checkbox" id="c-37083877" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37083371">prev</a><span>|</span><a href="#37083966">next</a><span>|</span><label class="collapse" for="c-37083877">[-]</label><label class="expand" for="c-37083877">[6 more]</label></div><br/><div class="children"><div class="content">One thing I notice is that the diff still requires pretty deep analysis. You need to be able to compare xml or JSON over time.<p>I keep thinking the real power of git-based data-over-time storage is flatter data structures. Rather than one or a dozen or so files, scaped &amp; stored, we could synthesize some kind of directory structure &amp; simple value files - alike a plan9&#x2F;9p system - that express the data, but where changes are more structurally apparent.<p>Thoughts?</div><br/><div id="37083963" class="c"><input type="checkbox" id="c-37083963" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083019">root</a><span>|</span><a href="#37083877">parent</a><span>|</span><a href="#37083960">next</a><span>|</span><label class="collapse" for="c-37083963">[-]</label><label class="expand" for="c-37083963">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know enough about plan9 to understand what you&#x27;re getting at there.<p>There&#x27;s definitely a LOT of scope for innovation around how the values are compared over time. So far my explorations have been around loading the deltas into SQLite in various ways, see <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2021&#x2F;Dec&#x2F;7&#x2F;git-history&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;simonwillison.net&#x2F;2021&#x2F;Dec&#x2F;7&#x2F;git-history&#x2F;</a></div><br/><div id="37085564" class="c"><input type="checkbox" id="c-37085564" checked=""/><div class="controls bullet"><span class="by">emmelaich</span><span>|</span><a href="#37083019">root</a><span>|</span><a href="#37083963">parent</a><span>|</span><a href="#37085430">next</a><span>|</span><label class="collapse" for="c-37085564">[-]</label><label class="expand" for="c-37085564">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps Jaunty is referring to <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Venti" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Venti</a><p>Which also one of the inspirations for Git.</div><br/></div></div><div id="37085430" class="c"><input type="checkbox" id="c-37085430" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#37083019">root</a><span>|</span><a href="#37083963">parent</a><span>|</span><a href="#37085564">prev</a><span>|</span><a href="#37083960">next</a><span>|</span><label class="collapse" for="c-37085430">[-]</label><label class="expand" for="c-37085430">[2 more]</label></div><br/><div class="children"><div class="content">Sysfs or procfs on Linux are similar. Rather than have deeply structured data files, let the file system be used to make hierarchy.<p>Rather than a JSON with a bunch of weather stations, make a directory with a bunch of stations as subdirectories, each with lat, long, temp, humidity properties. Let the fs express the structure.<p>Then when we watch in git, we can filter by changes to one of these subdirs, for example. Or see every time the humidity changes in one. I don&#x27;t have a good name for the general practice, but trying to use the filesystem to express the structure is the essence.</div><br/><div id="37085478" class="c"><input type="checkbox" id="c-37085478" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083019">root</a><span>|</span><a href="#37085430">parent</a><span>|</span><a href="#37083960">next</a><span>|</span><label class="collapse" for="c-37085478">[-]</label><label class="expand" for="c-37085478">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I see what you mean.<p>Yeah, there&#x27;s definitely a lot to be said for breaking up your scraped data into separate files rather than having it all in a single file.<p>I have a few projects where I do that kind of thing. My best example is probably this one, where I scrape the &quot;--help&quot; output for the AWS CLI commands and write that into a separate file for each command:<p>help-scraper&#x2F;tree&#x2F;main&#x2F;aws: <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;help-scraper&#x2F;tree&#x2F;main&#x2F;aws">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;help-scraper&#x2F;tree&#x2F;main&#x2F;aws</a><p>This is fantastically useful for keeping track of which AWS features were added or changed at what point.</div><br/></div></div></div></div></div></div><div id="37083960" class="c"><input type="checkbox" id="c-37083960" checked=""/><div class="controls bullet"><span class="by">marcolussetti</span><span>|</span><a href="#37083019">root</a><span>|</span><a href="#37083877">parent</a><span>|</span><a href="#37083963">prev</a><span>|</span><a href="#37083966">next</a><span>|</span><label class="collapse" for="c-37083960">[-]</label><label class="expand" for="c-37083960">[1 more]</label></div><br/><div class="children"><div class="content">I have to agree. I&#x27;ve been playing around with this for a while at <a href="https:&#x2F;&#x2F;github.com&#x2F;outages&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;outages&#x2F;</a> (which includes the bchydro-outages mentioned in the original comment).<p>While it&#x27;s easy to gather the data, the friction in analyzing it has always pushed the priority of doing so below other datasets I&#x27;ve gathered.</div><br/></div></div></div></div><div id="37083966" class="c"><input type="checkbox" id="c-37083966" checked=""/><div class="controls bullet"><span class="by">gremlinsinc</span><span>|</span><a href="#37083019">parent</a><span>|</span><a href="#37083877">prev</a><span>|</span><a href="#37083831">next</a><span>|</span><label class="collapse" for="c-37083966">[-]</label><label class="expand" for="c-37083966">[1 more]</label></div><br/><div class="children"><div class="content">wow, this is one of those things where I&#x27;ve thought of the problem many times and the solution makes me go, oh duh.</div><br/></div></div></div></div><div id="37083831" class="c"><input type="checkbox" id="c-37083831" checked=""/><div class="controls bullet"><span class="by">theultdev</span><span>|</span><a href="#37083019">prev</a><span>|</span><a href="#37086104">next</a><span>|</span><label class="collapse" for="c-37083831">[-]</label><label class="expand" for="c-37083831">[2 more]</label></div><br/><div class="children"><div class="content">I did this when I was a kid, decompiling a flash game client for an MMO (Tibia).<p>By itself a single decompile was hard to parse, but if you do it for each release, commit the decompiled sources, and diff them you can easily see code changes.<p>So you just run a script to poll for a new client version to drop and automatically download, decompile, commit, and tag.<p>I&#x27;d have a diff of the client changes immediately, allowing insight into the protocol changes to update the private game server code to support it.</div><br/><div id="37083885" class="c"><input type="checkbox" id="c-37083885" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083831">parent</a><span>|</span><a href="#37086104">next</a><span>|</span><label class="collapse" for="c-37083885">[-]</label><label class="expand" for="c-37083885">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s brilliant!</div><br/></div></div></div></div><div id="37086104" class="c"><input type="checkbox" id="c-37086104" checked=""/><div class="controls bullet"><span class="by">kissgyorgy</span><span>|</span><a href="#37083831">prev</a><span>|</span><a href="#37085372">next</a><span>|</span><label class="collapse" for="c-37086104">[-]</label><label class="expand" for="c-37086104">[1 more]</label></div><br/><div class="children"><div class="content">One of my friends is doing this tracking Hungarian law modifications:
<a href="https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;torvenyek">https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;torvenyek</a><p>He has tools for parsing them written in Rust: <a href="https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;hun_law_rs">https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;hun_law_rs</a><p>and Python: <a href="https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;hun_law_py">https:&#x2F;&#x2F;github.com&#x2F;badicsalex&#x2F;hun_law_py</a><p>I&#x27;m doing it myself tracking my GitHub star changes: <a href="https:&#x2F;&#x2F;github.com&#x2F;kissgyorgy&#x2F;my-stars">https:&#x2F;&#x2F;github.com&#x2F;kissgyorgy&#x2F;my-stars</a></div><br/></div></div><div id="37085372" class="c"><input type="checkbox" id="c-37085372" checked=""/><div class="controls bullet"><span class="by">bobek</span><span>|</span><a href="#37086104">prev</a><span>|</span><a href="#37082878">next</a><span>|</span><label class="collapse" for="c-37085372">[-]</label><label class="expand" for="c-37085372">[1 more]</label></div><br/><div class="children"><div class="content">I use this approach for monitoring open ports in our infrastructure -- running masscan, commiting results to git repo. If there are changes, open the merge request for review. During the review, one would investigate the actual server, why there was change in open ports.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;bobek&#x2F;masscan_as_a_service">https:&#x2F;&#x2F;github.com&#x2F;bobek&#x2F;masscan_as_a_service</a></div><br/></div></div><div id="37082878" class="c"><input type="checkbox" id="c-37082878" checked=""/><div class="controls bullet"><span class="by">mr_ndrsn</span><span>|</span><a href="#37085372">prev</a><span>|</span><a href="#37082970">next</a><span>|</span><label class="collapse" for="c-37082878">[-]</label><label class="expand" for="c-37082878">[3 more]</label></div><br/><div class="children"><div class="content">This looks very cool!<p>Please consider adding a user agent string with a link to the repo or some Google-able name to your curl call, it can help site operators get in touch with you if it starts to misbehave somehow.</div><br/><div id="37083492" class="c"><input type="checkbox" id="c-37083492" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#37082878">parent</a><span>|</span><a href="#37083002">next</a><span>|</span><label class="collapse" for="c-37083492">[-]</label><label class="expand" for="c-37083492">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s tough when there&#x27;s a cat and mouse game to spoof your UA so you don&#x27;t get blocked. I wish webmasters had better relationships with scrapers and could accept the realities that your data will be scraped no matter how much you try and stop it.</div><br/></div></div><div id="37083002" class="c"><input type="checkbox" id="c-37083002" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37082878">parent</a><span>|</span><a href="#37083492">prev</a><span>|</span><a href="#37082970">next</a><span>|</span><label class="collapse" for="c-37083002">[-]</label><label class="expand" for="c-37083002">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s good idea - I need to add that to my suggestions for how to implement this.</div><br/></div></div></div></div><div id="37082970" class="c"><input type="checkbox" id="c-37082970" checked=""/><div class="controls bullet"><span class="by">powersnail</span><span>|</span><a href="#37082878">prev</a><span>|</span><a href="#37083829">next</a><span>|</span><label class="collapse" for="c-37082970">[-]</label><label class="expand" for="c-37082970">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The implementation of the scraper is entirely contained in a single GitHub Actions workflow.<p>It&#x27;s interesting that you can run a scraper at fixed intervals on a free, hosted CI like that. If the scraped content is larger, more than a single JSON file, will GitHub have a problem with it?</div><br/><div id="37082992" class="c"><input type="checkbox" id="c-37082992" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37082970">parent</a><span>|</span><a href="#37082994">next</a><span>|</span><label class="collapse" for="c-37082992">[-]</label><label class="expand" for="c-37082992">[1 more]</label></div><br/><div class="children"><div class="content">GitHub repos appear to have a &quot;soft&quot; size limit of about 1GB - I feel completely comfortable with free repos with up to that size of content.<p>Once you get above 5GB I believe GitHub Support may send you a quiet polite email asking you to reconsider!<p><a href="https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;repositories&#x2F;working-with-files&#x2F;managing-large-files&#x2F;about-large-files-on-github" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;repositories&#x2F;working-with-files&#x2F;m...</a> has some more information on limits - they suggest keeping individual files below 50MB (and definitely below 100MB).</div><br/></div></div></div></div><div id="37083829" class="c"><input type="checkbox" id="c-37083829" checked=""/><div class="controls bullet"><span class="by">pdimitar</span><span>|</span><a href="#37082970">prev</a><span>|</span><a href="#37084003">next</a><span>|</span><label class="collapse" for="c-37083829">[-]</label><label class="expand" for="c-37083829">[2 more]</label></div><br/><div class="children"><div class="content">Funnily enough I do something very close to this with the RFC database at rfc-editor.org, here&#x27;s the script that I have put in my `cron`:<p><pre><code>    pushd ~&#x2F;data&#x2F;rfc # this is a GIT repo
    rsync -avzuh --delete --progress --exclude=.git ftp.rfc-editor.org::rfcs-text-only ~&#x2F;data&#x2F;rfc&#x2F;text-only&#x2F;
    rsync -avzuh --delete --progress --exclude=.git ftp.rfc-editor.org::refs ~&#x2F;data&#x2F;rfc&#x2F;refs
    rsync -avzuh --delete --progress --exclude=.git ftp.rfc-editor.org::rfcs-pdf-only ~&#x2F;data&#x2F;rfc&#x2F;pdf-only&#x2F;
    git add .
    git commit -m &quot;update $(date &#x27;+%Y-%m-%d&#x27;)&quot;
    git reflog expire --expire=now --all
    git gc --prune=now --aggressive
    git push origin master
    popd
</code></pre>
Though I admit using GitHub&#x27;s servers for this is more clever than me using one of my home servers. Still, I lean more to self-hosting.<p>@simonw Will take a look at `git-history`, looks intriguing!</div><br/><div id="37085572" class="c"><input type="checkbox" id="c-37085572" checked=""/><div class="controls bullet"><span class="by">emmelaich</span><span>|</span><a href="#37083829">parent</a><span>|</span><a href="#37084003">next</a><span>|</span><label class="collapse" for="c-37085572">[-]</label><label class="expand" for="c-37085572">[1 more]</label></div><br/><div class="children"><div class="content">I find -i or -ii give a nicer output than -v in rsync</div><br/></div></div></div></div><div id="37084003" class="c"><input type="checkbox" id="c-37084003" checked=""/><div class="controls bullet"><span class="by">great_psy</span><span>|</span><a href="#37083829">prev</a><span>|</span><a href="#37082964">next</a><span>|</span><label class="collapse" for="c-37084003">[-]</label><label class="expand" for="c-37084003">[2 more]</label></div><br/><div class="children"><div class="content">âââ
It runs on a schedule at 6, 26 and 46 minutes past the hourâI like to offset my cron times like this since I assume that the majority of crons run exactly on the hour, so running not-on-the-hour feels polite.
âââ<p>Not sure how much of a difference it makes to the underlying service but I will also do this with my scraping.<p>Thank you for point that out</div><br/><div id="37085381" class="c"><input type="checkbox" id="c-37085381" checked=""/><div class="controls bullet"><span class="by">madphilosopher</span><span>|</span><a href="#37084003">parent</a><span>|</span><a href="#37082964">next</a><span>|</span><label class="collapse" for="c-37085381">[-]</label><label class="expand" for="c-37085381">[1 more]</label></div><br/><div class="children"><div class="content">Further to this, I also put the following snippet in front of my web-scraping cron jobs so they start at a random time between the minute boundaries:<p><pre><code>    perl -le &#x27;sleep rand 60&#x27;;
</code></pre>
It&#x27;s the most compact code I could find to do the job.</div><br/></div></div></div></div><div id="37082964" class="c"><input type="checkbox" id="c-37082964" checked=""/><div class="controls bullet"><span class="by">ojkelly</span><span>|</span><a href="#37084003">prev</a><span>|</span><a href="#37084344">next</a><span>|</span><label class="collapse" for="c-37082964">[-]</label><label class="expand" for="c-37082964">[1 more]</label></div><br/><div class="children"><div class="content">Itâs probably not a coincidence the other place Iâve seen this technique was also for archiving a feed of  fires.<p>It that case the data was about 250gb when fully uncompressed, and IIRC under a gig when stored as a git repo.<p>Itâs a really neat idea, though it can make analysis on the data harder to do, in particular quality control (the aforementioned dataset had a lot of duplicates and inconsistency).<p>Like everything itâs a process of trading off between compute or storage, in this case optimising storage.</div><br/></div></div><div id="37084344" class="c"><input type="checkbox" id="c-37084344" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#37082964">prev</a><span>|</span><a href="#37083245">next</a><span>|</span><label class="collapse" for="c-37084344">[-]</label><label class="expand" for="c-37084344">[1 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s basically using Git as an &quot;append-only&quot; (no update-in-place) database to then do time queries?  It&#x27;s not the first time I see people using Git that way.<p>EDIT: hmmm I realize in addition to that it&#x27;s also a way to not have to do specific queries over time: the diff takes care of finding everything that changed (<i>i.e.</i> you don&#x27;t have to say <i>&quot;I want to see how this and that values changed over time&quot;</i>: the diff does it all).  Nice.</div><br/></div></div><div id="37083245" class="c"><input type="checkbox" id="c-37083245" checked=""/><div class="controls bullet"><span class="by">downWidOutaFite</span><span>|</span><a href="#37084344">prev</a><span>|</span><a href="#37084699">next</a><span>|</span><label class="collapse" for="c-37083245">[-]</label><label class="expand" for="c-37083245">[12 more]</label></div><br/><div class="children"><div class="content">This is cool but the name is confusing. First of all, git is not being scraped nor is git being used to do any scraping, git is only used as the storage format for the snapshots. Second, there is no scraping happening at all. Scraping is when you parse a file intended for human display in order to extract the embedded unstructured data. The examples given are about periodically downloading an already structured json file and uploading it to github. No parsing is happening unless you count when he manually searches for the json file in the browser dev tools.</div><br/><div id="37083378" class="c"><input type="checkbox" id="c-37083378" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083245">parent</a><span>|</span><a href="#37084016">next</a><span>|</span><label class="collapse" for="c-37083378">[-]</label><label class="expand" for="c-37083378">[10 more]</label></div><br/><div class="children"><div class="content">Git is a key technology in this approach, because the value you get out of this form of scraping is the commit history - it&#x27;s a way of turning a static source of information into a record of how that information changed over time.<p>I think it&#x27;s fine to use the term &quot;scraping&quot; to refer to downloading a JSON file.<p>These days an increasing number of websites work by serving up JSON which is then turned into HTML by a client-side JavaScript app. The JSON often isn&#x27;t a formally documented API, but you can grab it directly to avoid the extra step of processing the HTML.<p>I do run Git scrapers that process HTML as well. A couple of examples:<p>scrape-san-mateo-fire-dispatch <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-san-mateo-fire-dispatch">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-san-mateo-fire-dispatch</a> scrapes the HTML from <a href="http:&#x2F;&#x2F;www.firedispatch.com&#x2F;iPhoneActiveIncident.asp?Agency=04100" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.firedispatch.com&#x2F;iPhoneActiveIncident.asp?Agency=...</a> and records both the original HTML and converted JSON in the repository.<p>scrape-hacker-news-by-domain <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-hacker-news-by-domain">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-hacker-news-by-domain</a> uses my <a href="https:&#x2F;&#x2F;shot-scraper.datasette.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;shot-scraper.datasette.io&#x2F;</a> browser automation tool to convert an HTML page on Hacker News into JSON and save that to the repo. I wrote more about how that works here: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2022&#x2F;Dec&#x2F;2&#x2F;datasette-write-api&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;simonwillison.net&#x2F;2022&#x2F;Dec&#x2F;2&#x2F;datasette-write-api&#x2F;</a><p>That one&#x27;s a particularly fun demo because it&#x27;s currently capturing changes to the points and comment count on this thread - a recent example commit: <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-hacker-news-by-domain&#x2F;commit&#x2F;a7e2f3fcc6dfa6a442a2f93608062c83e20512e8">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;scrape-hacker-news-by-domain&#x2F;commi...</a></div><br/><div id="37084335" class="c"><input type="checkbox" id="c-37084335" checked=""/><div class="controls bullet"><span class="by">cachvico</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37083378">parent</a><span>|</span><a href="#37084041">next</a><span>|</span><label class="collapse" for="c-37084335">[-]</label><label class="expand" for="c-37084335">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not scraping, you&#x27;re just consuming an API.<p>Scraping is when you&#x27;re parsing human-readable content (HTML) and extracting data, as the parent comment correctly points out.</div><br/><div id="37084771" class="c"><input type="checkbox" id="c-37084771" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37084335">parent</a><span>|</span><a href="#37084041">next</a><span>|</span><label class="collapse" for="c-37084771">[-]</label><label class="expand" for="c-37084771">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that definition is universally agreed upon. I have had many conversations over the years where the term &quot;scraping&quot; referred to activities that didn&#x27;t involve things like parsing HTML.</div><br/><div id="37085315" class="c"><input type="checkbox" id="c-37085315" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37084771">parent</a><span>|</span><a href="#37085282">next</a><span>|</span><label class="collapse" for="c-37085315">[-]</label><label class="expand" for="c-37085315">[1 more]</label></div><br/><div class="children"><div class="content">Scraping specifically refers to extracting information from source documents&#x2F;data. Merely downloading them is just retrieval or, when following links, crawling.<p>âGit scrapingâ would intuitively refer to extracting specific information from Git repositories. The naming in the article is therefore confusing. âSnapshotting into Gitâ would be more accurate. (Git itself uses the term âsnapshotâ for a reason.)</div><br/></div></div><div id="37085282" class="c"><input type="checkbox" id="c-37085282" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37084771">parent</a><span>|</span><a href="#37085315">prev</a><span>|</span><a href="#37084041">next</a><span>|</span><label class="collapse" for="c-37085282">[-]</label><label class="expand" for="c-37085282">[4 more]</label></div><br/><div class="children"><div class="content">Agree to disagree. To me, scraping implies a level of fragility that hitting an endpoint that returns JSON does not have.</div><br/><div id="37086170" class="c"><input type="checkbox" id="c-37086170" checked=""/><div class="controls bullet"><span class="by">oneeyedpigeon</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37085282">parent</a><span>|</span><a href="#37085459">next</a><span>|</span><label class="collapse" for="c-37086170">[-]</label><label class="expand" for="c-37086170">[1 more]</label></div><br/><div class="children"><div class="content">Exactly - &quot;scraping&quot; is the final resort when sites don&#x27;t make data available via an API. It&#x27;s almost exactly synonymous with &quot;parsing HTML&quot;.</div><br/></div></div><div id="37085459" class="c"><input type="checkbox" id="c-37085459" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37085282">parent</a><span>|</span><a href="#37086170">prev</a><span>|</span><a href="#37084041">next</a><span>|</span><label class="collapse" for="c-37085459">[-]</label><label class="expand" for="c-37085459">[2 more]</label></div><br/><div class="children"><div class="content">Undocumented endpoints that return JSON are pretty fragile!<p>One of the benefits of catching them in a Git repo is that it helps you spot when their structure changes in ways that may break code that you write on top of them.</div><br/><div id="37086219" class="c"><input type="checkbox" id="c-37086219" checked=""/><div class="controls bullet"><span class="by">oneeyedpigeon</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37085459">parent</a><span>|</span><a href="#37084041">next</a><span>|</span><label class="collapse" for="c-37086219">[-]</label><label class="expand" for="c-37086219">[1 more]</label></div><br/><div class="children"><div class="content">From the Wikipedia entry for &quot;data scraping&quot;:<p>&gt; the key element that distinguishes data scraping from regular parsing is that the output being scraped is intended for display to an end-user, rather than as an input to another program<p>Snapshotting JSON files can be incredibly useful, but I don&#x27;t think you should call it &quot;scraping&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37084041" class="c"><input type="checkbox" id="c-37084041" checked=""/><div class="controls bullet"><span class="by">gremlinsinc</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37083378">parent</a><span>|</span><a href="#37084335">prev</a><span>|</span><a href="#37084016">next</a><span>|</span><label class="collapse" for="c-37084041">[-]</label><label class="expand" for="c-37084041">[2 more]</label></div><br/><div class="children"><div class="content">I think the name is also a little ambiguous. I suggest maybe, commited-scraping, or time-scraping, or chronicle-scraping... and chatGPT could probably come up with something even better lol.</div><br/><div id="37085388" class="c"><input type="checkbox" id="c-37085388" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#37083245">root</a><span>|</span><a href="#37084041">parent</a><span>|</span><a href="#37084016">next</a><span>|</span><label class="collapse" for="c-37085388">[-]</label><label class="expand" for="c-37085388">[1 more]</label></div><br/><div class="children"><div class="content">âPeriodic snapshottingâ would be more accurate. Thatâs the usual term of the art.</div><br/></div></div></div></div></div></div><div id="37084016" class="c"><input type="checkbox" id="c-37084016" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#37083245">parent</a><span>|</span><a href="#37083378">prev</a><span>|</span><a href="#37084699">next</a><span>|</span><label class="collapse" for="c-37084016">[-]</label><label class="expand" for="c-37084016">[1 more]</label></div><br/><div class="children"><div class="content">I think &quot;time-lapse&quot; might be the right metaphor. With time-lapse photography, we see snapshots of a continuous process taken at regular intervals.<p>I&#x27;m not sure what it has to do with git. It seems like any version control system would work. Or, really, the main use of git here is that GitHub is effectively being used as a free database. The snapshots and timestamps are enough to see the changes, regardless of storage format.</div><br/></div></div></div></div><div id="37084699" class="c"><input type="checkbox" id="c-37084699" checked=""/><div class="controls bullet"><span class="by">nomilk</span><span>|</span><a href="#37083245">prev</a><span>|</span><a href="#37084286">next</a><span>|</span><label class="collapse" for="c-37084699">[-]</label><label class="expand" for="c-37084699">[1 more]</label></div><br/><div class="children"><div class="content">Love that the author provides a 5 minute video explaining the purpose and how he did it: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2CjA-03yK8I">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2CjA-03yK8I</a></div><br/></div></div><div id="37084286" class="c"><input type="checkbox" id="c-37084286" checked=""/><div class="controls bullet"><span class="by">modestygrime</span><span>|</span><a href="#37084699">prev</a><span>|</span><a href="#37085201">next</a><span>|</span><label class="collapse" for="c-37084286">[-]</label><label class="expand" for="c-37084286">[1 more]</label></div><br/><div class="children"><div class="content">I use the same technique to maintain a json file mapping Slack channel names to channel IDs, as Slack for some reason doesn&#x27;t have an API endpoint for getting a channel ID from its name.</div><br/></div></div><div id="37085201" class="c"><input type="checkbox" id="c-37085201" checked=""/><div class="controls bullet"><span class="by">a-dub</span><span>|</span><a href="#37084286">prev</a><span>|</span><a href="#37084081">next</a><span>|</span><label class="collapse" for="c-37085201">[-]</label><label class="expand" for="c-37085201">[2 more]</label></div><br/><div class="children"><div class="content">some covid datasets were published as git repositories. the cool part was that it added a publish date dimension for historical data so that one could understand how long it took for historical counts to reach a steady state.</div><br/><div id="37085813" class="c"><input type="checkbox" id="c-37085813" checked=""/><div class="controls bullet"><span class="by">tim-fan</span><span>|</span><a href="#37085201">parent</a><span>|</span><a href="#37084081">next</a><span>|</span><label class="collapse" for="c-37085813">[-]</label><label class="expand" for="c-37085813">[1 more]</label></div><br/><div class="children"><div class="content">Yes! New Zealand published current covid locations of interest (where infected people had been) to a github repo - I created an animation of locations over time by crawling the repo history. It gave an idea for how it was spreading through the country, and Auckland in particular.<p>Animation: <a href="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;tim-fan&#x2F;media&#x2F;main&#x2F;20210926_location_of_interest_animation&#x2F;as_at_20210926&#x2F;loi_auckland.gif" rel="nofollow noreferrer">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;tim-fan&#x2F;media&#x2F;main&#x2F;2021092...</a><p>Code: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;tim-fan&#x2F;5f601c274a30505b1ae6b989a0150877" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.github.com&#x2F;tim-fan&#x2F;5f601c274a30505b1ae6b989a015...</a></div><br/></div></div></div></div><div id="37084081" class="c"><input type="checkbox" id="c-37084081" checked=""/><div class="controls bullet"><span class="by">alphanumeric0</span><span>|</span><a href="#37085201">prev</a><span>|</span><a href="#37084966">next</a><span>|</span><label class="collapse" for="c-37084081">[-]</label><label class="expand" for="c-37084081">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the benefit of this versus a time series database?</div><br/><div id="37084144" class="c"><input type="checkbox" id="c-37084144" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37084081">parent</a><span>|</span><a href="#37084966">next</a><span>|</span><label class="collapse" for="c-37084144">[-]</label><label class="expand" for="c-37084144">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how those are comparable.<p>The trick here is to take some source of information online that&#x27;s updated frequently and turn that into a historic record of every change made to that source, by setting up a GitHub repository and dropping a YAML file into it setting up a scheduled action.<p>Achieving the same thing with a time series database would require a whole lot more work I think - you&#x27;d need to run that database somewhere, then run code that scrapes and writes to it on a scheduled basis.<p>If you already have a time series database running and a machine that runs cron I guess it wouldn&#x27;t be too much work to put that in place.<p>Git scraping also lets you easily track changes made to textual content, which I don&#x27;t think would fit neatly in a time series database.</div><br/><div id="37085271" class="c"><input type="checkbox" id="c-37085271" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#37084081">root</a><span>|</span><a href="#37084144">parent</a><span>|</span><a href="#37084722">next</a><span>|</span><label class="collapse" for="c-37085271">[-]</label><label class="expand" for="c-37085271">[1 more]</label></div><br/><div class="children"><div class="content">I mean you could use SQLite the wrong way and use it as a time series database, which would save you from having to have a machine to host it, and I&#x27;m sure you could cobble together some sort of hosting for it and glue it to a web cron system. this github seems quite a bit more straightforwards, but then you&#x27;re on git instead of something else.</div><br/></div></div><div id="37084722" class="c"><input type="checkbox" id="c-37084722" checked=""/><div class="controls bullet"><span class="by">alphanumeric0</span><span>|</span><a href="#37084081">root</a><span>|</span><a href="#37084144">parent</a><span>|</span><a href="#37085271">prev</a><span>|</span><a href="#37084966">next</a><span>|</span><label class="collapse" for="c-37084722">[-]</label><label class="expand" for="c-37084722">[1 more]</label></div><br/><div class="children"><div class="content">Yes, maybe they are a bit &#x27;apples to oranges&#x27;.  You have some good points, especially when it comes to textual data. Thanks!</div><br/></div></div></div></div></div></div><div id="37084966" class="c"><input type="checkbox" id="c-37084966" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#37084081">prev</a><span>|</span><label class="collapse" for="c-37084966">[-]</label><label class="expand" for="c-37084966">[1 more]</label></div><br/><div class="children"><div class="content">(2020)</div><br/></div></div></div></div></div></div></div></body></html>