<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709629269954" as="style"/><link rel="stylesheet" href="styles.css?v=1709629269954"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.together.ai/blog/based">Based: Simple linear attention language models</a> <span class="domain">(<a href="https://www.together.ai">www.together.ai</a>)</span></div><div class="subtext"><span>swyx</span> | <span>14 comments</span></div><br/><div><div id="39598734" class="c"><input type="checkbox" id="c-39598734" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#39600665">next</a><span>|</span><label class="collapse" for="c-39598734">[-]</label><label class="expand" for="c-39598734">[2 more]</label></div><br/><div class="children"><div class="content">The paper &#x27;Hopfield networks are all you need&#x27; talks about why the softmax in the normal attention formulation is important for recall, and I&#x27;m always surprised its ideas haven&#x27;t penetrated further in the community. Basically, viewing attention as a Hopfield network, there&#x27;s a theoretical maximum number of patterns that, for linear functions, is actually very low, but for the exponential functions, you get very high information density and recall.</div><br/><div id="39599030" class="c"><input type="checkbox" id="c-39599030" checked=""/><div class="controls bullet"><span class="by">dilawar</span><span>|</span><a href="#39598734">parent</a><span>|</span><a href="#39600665">next</a><span>|</span><label class="collapse" for="c-39599030">[-]</label><label class="expand" for="c-39599030">[1 more]</label></div><br/><div class="children"><div class="content">True. And it&#x27;s scaling down properties are much better than any other network I&#x27;ve played with (not an expert). I could run MNIST benchmark on a ESP32 board.<p>I also liked the Convex Concave trick in the paper. The guarantee that at every step you are closer to the minima is very nice.</div><br/></div></div></div></div><div id="39600665" class="c"><input type="checkbox" id="c-39600665" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#39598734">prev</a><span>|</span><a href="#39598259">next</a><span>|</span><label class="collapse" for="c-39600665">[-]</label><label class="expand" for="c-39600665">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s striking how this paper appears like experimental science. They have a proposal and run experiments to confirm it rather than proving it mathematically. Also I love that their new DSL is named thunder kittens. I&#x27;m glad they don&#x27;t take themselves too seriously.</div><br/></div></div><div id="39598259" class="c"><input type="checkbox" id="c-39598259" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#39600665">prev</a><span>|</span><a href="#39598439">next</a><span>|</span><label class="collapse" for="c-39598259">[-]</label><label class="expand" for="c-39598259">[3 more]</label></div><br/><div class="children"><div class="content">Together.ai is interesting; I think it might be a relatively new business model in tech -- since they sell inference and training, you might be tempted to think of them as an engineering &#x2F; infrastructure company.<p>But, because inference is largely quality based -- e.g. customers seem to be selecting &quot;cheapest generation at the quality I require&quot;, they have a strong incentive to optimize speed of inference at different quality points, and so this paper is coming at the market from a very different place than &quot;quality first - sell second&quot;, like OpenAI or Anthropic. On those terms, the ideas and concepts in Based are pretty interesting. Faster inference is awesome, faster sequential token generation is awesome, cheaper long range memory is awesome..<p>As revenues at these places grow, they should have access to more compute, which should mean they&#x27;ll be able to start training at a scale that will get to &#x27;minimum acceptable quality&#x27;, and then they&#x27;ll be off to the races.<p>I&#x27;m looking forward to the next year, where companies like together can start putting out models optimized toward specific workflows that compete on quality!</div><br/><div id="39598552" class="c"><input type="checkbox" id="c-39598552" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39598259">parent</a><span>|</span><a href="#39598439">next</a><span>|</span><label class="collapse" for="c-39598552">[-]</label><label class="expand" for="c-39598552">[2 more]</label></div><br/><div class="children"><div class="content">we actually talked to them a few weeks ago - they&#x27;re actually almost 50% a research lab!<p><a href="https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;together" rel="nofollow">https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;together</a><p>i think it makes total sense - infra will commoditize rapidly so you have to make research bets on future differentiators. Together is basically the only GPU infra company with a successful research dept (am I missing someone? i probably am) that is likely to pay off turning it into a frontier model lab at some point in future.</div><br/><div id="39600429" class="c"><input type="checkbox" id="c-39600429" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#39598259">root</a><span>|</span><a href="#39598552">parent</a><span>|</span><a href="#39598439">next</a><span>|</span><label class="collapse" for="c-39600429">[-]</label><label class="expand" for="c-39600429">[1 more]</label></div><br/><div class="children"><div class="content">They also recently were involved in Evo, genome-scale modeling of DNA: <a href="https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2024.02.27.582234v1" rel="nofollow">https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2024.02.27.582234v1</a>
The second author works at together.ai and the huggingfaces space from together.ai hosts the model <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;togethercomputer&#x2F;evo-1-131k-base" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;togethercomputer&#x2F;evo-1-131k-base</a></div><br/></div></div></div></div></div></div><div id="39598064" class="c"><input type="checkbox" id="c-39598064" checked=""/><div class="controls bullet"><span class="by">vicktorium</span><span>|</span><a href="#39598115">prev</a><span>|</span><label class="collapse" for="c-39598064">[-]</label><label class="expand" for="c-39598064">[5 more]</label></div><br/><div class="children"><div class="content">The RWVK modal was mention which is not based on transformers but on NN. [1]<p>The context window is particularly interesting, i have interacted with the people over discord some time ago and the model seems good but not widely used yet.<p>People are noticing the limitations will not shift to pure hardware -&gt; energy now.<p>the transformers allows heavy parallelization but it&#x27;s too computationally-intensive even with quantitization.<p>people are simply trying to run from the transformer is seem.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;RWKV-LM">https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;RWKV-LM</a></div><br/><div id="39598631" class="c"><input type="checkbox" id="c-39598631" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39598064">parent</a><span>|</span><label class="collapse" for="c-39598631">[-]</label><label class="expand" for="c-39598631">[4 more]</label></div><br/><div class="children"><div class="content">(not to toot own horn too much but i believe we were also the first big ai pod to feature rwkv: <a href="https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;rwkv" rel="nofollow">https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;rwkv</a> )<p>Based presents the first real challenge to rwkv&#x2F;mamba i&#x27;ve seen, both of which fall prey to the recall tradeoff referenced in TFA.  i do have real questions on how the recall can grow unbounded with no tradeoff like that but then again i havent seriously studied the math.</div><br/><div id="39598937" class="c"><input type="checkbox" id="c-39598937" checked=""/><div class="controls bullet"><span class="by">kartoolOz</span><span>|</span><a href="#39598064">root</a><span>|</span><a href="#39598631">parent</a><span>|</span><a href="#39600303">prev</a><span>|</span><a href="#39599869">next</a><span>|</span><label class="collapse" for="c-39598937">[-]</label><label class="expand" for="c-39598937">[1 more]</label></div><br/><div class="children"><div class="content">The Info extraction and Question Answering metrics are far worse than transformers though.<p>They also say that in the blog &quot;However, both Based and Mamba still underperform the strongest Transformer baseline, sometimes by large margins. This is consistent with our “no free lunch” observation above&quot;</div><br/></div></div><div id="39599869" class="c"><input type="checkbox" id="c-39599869" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39598064">root</a><span>|</span><a href="#39598631">parent</a><span>|</span><a href="#39598937">prev</a><span>|</span><label class="collapse" for="c-39599869">[-]</label><label class="expand" for="c-39599869">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s fundamentally a trade-off: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2209.04881" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2209.04881</a> . (Unless the Strong Exponential Time Hypothesis is false, but that&#x27;s pretty unlikely, like P being equal to NP).</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>