<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686992467816" as="style"/><link rel="stylesheet" href="styles.css?v=1686992467816"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://spectrum.ieee.org/deep-learning-computational-cost">Deep Learning’s Diminishing Returns (2021)</a> <span class="domain">(<a href="https://spectrum.ieee.org">spectrum.ieee.org</a>)</span></div><div class="subtext"><span>jrepinc</span> | <span>28 comments</span></div><br/><div><div id="36365963" class="c"><input type="checkbox" id="c-36365963" checked=""/><div class="controls bullet"><span class="by">dmayle</span><span>|</span><a href="#36364907">next</a><span>|</span><label class="collapse" for="c-36365963">[-]</label><label class="expand" for="c-36365963">[2 more]</label></div><br/><div class="children"><div class="content">The paper has a fundamental flaw, which can be seen if trying to reverse the reasoning to look at the past, rather than trying to predict the future.<p>If you used today&#x27;s level of computation with 2012 era models, then you wouldn&#x27;t have the error rates of today&#x27;s models, you would have much higher, much worse errors.<p>The single biggest bottleneck in deep learning is not computation, it&#x27;s the ingenuity used to devise new structures and new optimizations that allow for scaling.<p>For a given structure, with given techniques, you can throw more computation at a problem to decrease error rate, but the gains scale poorly with cost.  Cost improvements only come with new techniques and structures.</div><br/><div id="36368495" class="c"><input type="checkbox" id="c-36368495" checked=""/><div class="controls bullet"><span class="by">blackbear_</span><span>|</span><a href="#36365963">parent</a><span>|</span><a href="#36364907">next</a><span>|</span><label class="collapse" for="c-36368495">[-]</label><label class="expand" for="c-36368495">[1 more]</label></div><br/><div class="children"><div class="content">And don&#x27;t forget data!</div><br/></div></div></div></div><div id="36364907" class="c"><input type="checkbox" id="c-36364907" checked=""/><div class="controls bullet"><span class="by">deepsquirrelnet</span><span>|</span><a href="#36365963">prev</a><span>|</span><a href="#36368273">next</a><span>|</span><label class="collapse" for="c-36364907">[-]</label><label class="expand" for="c-36364907">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t find the authors points to be very convincing. There&#x27;s a bit of a self-contradiction in the arguments being made -- namely that if you want better generalization, you need more parameters (which equates to higher energy consumption in training).<p>However, the obvious retort here is that if you train a model that is good at generalizing, then you don&#x27;t need train more models! A show of hands, who has used GPT or an open LLM vs who has <i>trained</i> one would yield a vast disparity. If you don&#x27;t need generalization, you don&#x27;t need huge models. Small models are efficient over narrow domains and don&#x27;t require vast compute&#x2F;energy resources.<p>Secondarily, it&#x27;s a self-solving issue. Energy isn&#x27;t cheap, and GPUs aren&#x27;t cheap. If you&#x27;re going to burn 10&#x27;s of thousands of dollars in energy costs, you should probably have a decent reason to do it. But those reasons are quickly diminishing as things that have already been _done_.<p>Third, overparameterized models are becoming less of an issue during inference with efficient quantization techniques. Distillation, though harder, is another option. Again, you do can these things one time after training.</div><br/><div id="36367159" class="c"><input type="checkbox" id="c-36367159" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36364907">parent</a><span>|</span><a href="#36366832">next</a><span>|</span><label class="collapse" for="c-36367159">[-]</label><label class="expand" for="c-36367159">[2 more]</label></div><br/><div class="children"><div class="content">Once you have an NN model and you know you want to keep the model weight set, moving to an optical neural network can massively drop the energy use.  Its not necessarily easy, and certain architectures may not be as amenable, but it can certainly be a path to reducing energy use.</div><br/><div id="36367239" class="c"><input type="checkbox" id="c-36367239" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36364907">root</a><span>|</span><a href="#36367159">parent</a><span>|</span><a href="#36366832">next</a><span>|</span><label class="collapse" for="c-36367239">[-]</label><label class="expand" for="c-36367239">[1 more]</label></div><br/><div class="children"><div class="content">I’m not aware of anyone having done this for a production ready scenario, I thought it was all still highly experimental and very early days?</div><br/></div></div></div></div><div id="36366832" class="c"><input type="checkbox" id="c-36366832" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36364907">parent</a><span>|</span><a href="#36367159">prev</a><span>|</span><a href="#36368273">next</a><span>|</span><label class="collapse" for="c-36366832">[-]</label><label class="expand" for="c-36366832">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A show of hands, who has used GPT or an open LLM vs who has trained one would yield a vast disparity.<p>Believe me, that has almost nothing to do with &quot;only needing one model&quot; and everything to do with the compute required being absurd.<p>&gt; Small models are efficient over narrow domains and don&#x27;t require vast compute&#x2F;energy resources.<p>The &quot;best&quot; small models are still typically born from the &quot;best&quot; overall models (however large) using a student&#x2F;teacher paradigm. This is active research. As such, it is typically encouraged to go for &quot;the big one&quot;, as you can distill it to far better small models than if you were to train the small models from scratch first.<p>&gt; If you&#x27;re going to burn 10&#x27;s of thousands of dollars in energy costs, you should probably have a decent reason to do it. But those reasons are quickly diminishing as things that have already been _done_.<p>Again, this is _not_ the reason researchers don&#x27;t train their own GPT-4&#x27;s. They _absolutely_ would if they could raise that much money. The notion that researchers have everything they ever could have wanted from OpenAI&#x27;s API-based walled garden approach is patently absurd. If they would release the weights, then finetuning and such could occur and you might have a point.<p>To be clear, I&#x27;m not defending the article&#x27;s main point. You just happened to have used some strange arguments against it (imo).<p>The best argument is a sibling comment which points out that new architectures will be discovered that are more parameter efficient and run better on the hardware available. The burgeoning field of architecture search may mean we even have the ability to get the models themselves to help speed up this process of finding better ML architectures. It&#x27;s always difficult to know when we have hit a wall of sorts however, and it may be that the transformer (and similar approaches) can only be refined so much. Time will tell.</div><br/></div></div></div></div><div id="36362014" class="c"><input type="checkbox" id="c-36362014" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36368273">prev</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36362014">[-]</label><label class="expand" for="c-36362014">[13 more]</label></div><br/><div class="children"><div class="content">None of these articles admit to a basic truth: deep learning is only a small slice of total computation, and even if it grew 2 orders of magnitude, would not be the largest consumer by area.<p>If DL costs are unsustainable, it means those other things (SAP, web hosting, and all the ridiculous stuff people waste cycles on) are even more unsustainable, and should be addressed first.</div><br/><div id="36364455" class="c"><input type="checkbox" id="c-36364455" checked=""/><div class="controls bullet"><span class="by">aeturnum</span><span>|</span><a href="#36362014">parent</a><span>|</span><a href="#36363083">next</a><span>|</span><label class="collapse" for="c-36364455">[-]</label><label class="expand" for="c-36364455">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;re trying to beg the question that &quot;the point&quot; must be: &quot;which thing is wasting the most power right now?&quot; It&#x27;s not. People can talk about at least two things at once. This is critiquing the diminishing returns in terms of cost-per-output. It compares badly, on a unit level, to most other methods. That&#x27;s a fair critique when planning which technique to use in the future.<p>Articles are often talking about something that won&#x27;t end up mattering. But if you can&#x27;t actually address the point the article is making on its own terms, you&#x27;re going to struggle to refute it.</div><br/><div id="36364867" class="c"><input type="checkbox" id="c-36364867" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36364455">parent</a><span>|</span><a href="#36363083">next</a><span>|</span><label class="collapse" for="c-36364867">[-]</label><label class="expand" for="c-36364867">[2 more]</label></div><br/><div class="children"><div class="content">But we aren&#x27;t seeing diminishing returns in terms of cost-per-output.  We&#x27;re seeing enormous advances, both in the quality of networks, and what we understand about how to train them, with a large but not unanticipated growth in compute which is still smaller than the growth of compute in other areas which aren&#x27;t producing scientific advances.<p>When I refute a paper I start with the weakest points; if I convince my audience to ignore the paper on those terms, I don&#x27;t spend time refuting the main point (perhaps this is not a great technique, but it is fairly efficient).  I didn&#x27;t even really address their main arguments because after reading the paper, I was just aghast at some of the things that say.<p>Let&#x27;s give an example like this:
&quot;&quot;&quot;The first part is true of all statistical models: To improve performance by a factor of k, at least k**2 more data points must be used to train the model.&quot;&quot;&quot;<p>I guess that&#x27;s true of nearly all modern statistical models, at least small ones with simple model functions and fairly small number of data points.  But I don&#x27;t think that most advanced deep learning experts think in those terms; modern DLs do not behave anything like classical statistical models.  I think those experts see increasing the data as providing an opportunity for overparameterized systems to generalize in ways we don&#x27;t undertand and don&#x27;t follow normal statistical rules.  Modern DL systems are more like complex systems with emergent properties, than statistical models as understand by modern statisticians.<p>Here&#x27;s another example: they sort of ignore the fact that we only need to train a small number of really big models and then all other models are fine-tuned from that.  To get a world-class tardigrade detector, I took mobilenet, gave it a few hundred extra examples, trained for less than an hour on my home GPU (a 3080Ti), and then re-used that model for millions of predictions on my microscope.  I didn&#x27;t have to retrain any model from or use absurd amounts of extra data.  I took advantage of all the work the original model trainign did to discover basis functions that can compactly encode the difference between tardigrade, algae, and dirt.  I see a direct linear increase in my model&#x27;s performance as I move to linearly larger models, and I need to add linear number of images to train more classes.  We can reasonable expect this to be true of a wide range of models.<p>Similarly, for people doing molecular dynamics- the big CPU waster before DL- many parts of MD can now be approximated with DLs that are cheaper to run than MD, using models that were just trained once.<p>What about AlphaFold?  Even if it cost DeepMind $100M in training time (and probably more in salaries), it has already generated some results that simply couldn&#x27;t be produced without their technology- it didn&#x27;t even exist!  What they demonstrated, quite convincingly, is that algorithmic improvements could extract far more information from fairly cheap and low quality sequence data, compared to expensive structural data.  So instead of extremely expensive MD sims or whatever to predict structure, you just run this model.  My friends in pharma research (I work in pharma) are delighted with the results.<p>In short, I think the author&#x27;s economic model is naive, I think his udnerstanding of improvement in DL is naive, and he undercounts the value of having a small number of huge models which are trained on O(nlogn), not n**2 data sets.<p>And I think that in the next decade it&#x27;s likely either Google, Meta, or Microsoft will be actively training multi-modal models that basically include the sum of all publicly available, unencumbered data to produce networks that can move smoothly between video, audio, text, do logical reasoning, everything required to produce a virtual human being that could fool even experts, and probably even exceed human performance in science and mathematics in an impactful way.  So what if they spend $100B to get there.  That&#x27;s just two years of NIH&#x27;s budget.</div><br/><div id="36366452" class="c"><input type="checkbox" id="c-36366452" checked=""/><div class="controls bullet"><span class="by">aeturnum</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36364867">parent</a><span>|</span><a href="#36363083">next</a><span>|</span><label class="collapse" for="c-36366452">[-]</label><label class="expand" for="c-36366452">[1 more]</label></div><br/><div class="children"><div class="content">So - this feels like a convincing refutation of the article! You should have said this first! I&#x27;m naive in all aspects of the details here but I&#x27;m glad to see that you had something more in your coat than &quot;there are bigger energy eaters than these.&quot; Thanks!</div><br/></div></div></div></div></div></div><div id="36363083" class="c"><input type="checkbox" id="c-36363083" checked=""/><div class="controls bullet"><span class="by">mrtranscendence</span><span>|</span><a href="#36362014">parent</a><span>|</span><a href="#36364455">prev</a><span>|</span><a href="#36365670">next</a><span>|</span><label class="collapse" for="c-36363083">[-]</label><label class="expand" for="c-36363083">[3 more]</label></div><br/><div class="children"><div class="content">The amount of computation in the world devoted to deep learning, in aggregate, might be a small slice of total computation. But in terms of costs borne by individual organizations who train such models, deep learning could be extremely substantial. Particularly if it takes millions in additional investment to achieve only marginal reductions in error.</div><br/><div id="36363466" class="c"><input type="checkbox" id="c-36363466" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36363083">parent</a><span>|</span><a href="#36365670">next</a><span>|</span><label class="collapse" for="c-36363466">[-]</label><label class="expand" for="c-36363466">[2 more]</label></div><br/><div class="children"><div class="content">How is that different from any other capital-intensive industry.
Basically my point is that there is nothing specific to DL in these articles&#x2F;complaints, people are just jumping on the bandwagon.</div><br/><div id="36366519" class="c"><input type="checkbox" id="c-36366519" checked=""/><div class="controls bullet"><span class="by">mrtranscendence</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36363466">parent</a><span>|</span><a href="#36365670">next</a><span>|</span><label class="collapse" for="c-36366519">[-]</label><label class="expand" for="c-36366519">[1 more]</label></div><br/><div class="children"><div class="content">For me, the takeaway is that training state of the art models may become cost prohibitive even for large companies. There may be a practical limit to how complex models can become. This is at least plausibly interesting to know.</div><br/></div></div></div></div></div></div><div id="36365670" class="c"><input type="checkbox" id="c-36365670" checked=""/><div class="controls bullet"><span class="by">hn_thrwn</span><span>|</span><a href="#36362014">parent</a><span>|</span><a href="#36363083">prev</a><span>|</span><a href="#36363487">next</a><span>|</span><label class="collapse" for="c-36365670">[-]</label><label class="expand" for="c-36365670">[1 more]</label></div><br/><div class="children"><div class="content">I remember people saying the same thing about crypto. Then it started consuming more electricity than Ireland: <a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2017&#x2F;nov&#x2F;27&#x2F;bitcoin-mining-consumes-electricity-ireland" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2017&#x2F;nov&#x2F;27&#x2F;bitcoin-m...</a></div><br/></div></div><div id="36363487" class="c"><input type="checkbox" id="c-36363487" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#36362014">parent</a><span>|</span><a href="#36365670">prev</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36363487">[-]</label><label class="expand" for="c-36363487">[5 more]</label></div><br/><div class="children"><div class="content">&gt;If DL costs are unsustainable, it means those other things (SAP, web hosting, and all the ridiculous stuff people waste cycles on) are even more unsustainable, and should be addressed first.<p>That fundamentally misunderstands the point. If it costs me $XXX amounts of dollars to compute the job I&#x27;m trying to replace, which only actually costs $X dollar, then it&#x27;s not financially viable to use the model to replace the job. It makes no difference what the global percentage of computation that makes up.</div><br/><div id="36363715" class="c"><input type="checkbox" id="c-36363715" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36363487">parent</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36363715">[-]</label><label class="expand" for="c-36363715">[4 more]</label></div><br/><div class="children"><div class="content">The reason the global percentage matters is that if you are truly trying to address environmental impacts, you wouldn&#x27;t talk about DL, it&#x27;s currently too small (and will be for some time) to make a difference.<p>Just like not optimizing the 1% bottleneck in your code when there&#x27;s a 50% bottleneck- focus on the big players where the cheap, easy wins are first.</div><br/><div id="36364317" class="c"><input type="checkbox" id="c-36364317" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36363715">parent</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36364317">[-]</label><label class="expand" for="c-36364317">[3 more]</label></div><br/><div class="children"><div class="content">Yes, your point makes sense from the perspective of trying to reduce global carbon usage... but that doesn&#x27;t seem to be the perspective the article is written from, and the title is &quot;Deep Learning&#x27;s Diminishing Returns&quot; not &quot;Deep Learning Is Not Environmentally Friendly&quot; so I think the point that DL has diminishing returns stands.</div><br/><div id="36364733" class="c"><input type="checkbox" id="c-36364733" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36364317">parent</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36364733">[-]</label><label class="expand" for="c-36364733">[2 more]</label></div><br/><div class="children"><div class="content">The paper advances several lines of arguments.  Environmental is one of them, it&#x27;s used as a negative consequence of their purported scaling laws for training.<p>The paper explicitly says: &quot;&quot;&quot;Important work by scholars at the University of Massachusetts Amherst allows us to understand the economic cost and carbon emissions implied by this computational burden. The answers are grim: Training such a model would cost US $100 billion and would produce as much carbon emissions as New York City does in a month. And if we estimate the computational burden of a 1 percent error rate, the results are considerably worse.&quot;&quot;&quot;<p>(that paper was debunked by people who build and operate extremely large scale cloud machine learning systems).<p>Remember, Google already built and runs its TPU fleet continuously and the machines are almost always busy at at least 50% of their capacity, meaning the money is already being spent and the carbon (which is much smaller than their estimates) being spewed.<p>As for the rest of the paper, their arguments about the need to increase parameters to get better results are fairly simplistic, and filled with misleading information&#x2F;untrue statements.<p>Basically, everything they claim in the article has been shown to be empirically not true.  And the community is already grappling with the &quot;too many parameters approach&quot;.  The authors would have served the community far better by writing a less critical paper that focused on the opportunities to identify good approaches to parameter and compute reduction  that don&#x27;t affect performance. In looking at the main author&#x27;s area of research, it looks like he is more of a economist&#x2F;public policy wonk than DL expert, which I think negatively affects the quality of the paper.</div><br/><div id="36366333" class="c"><input type="checkbox" id="c-36366333" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#36362014">root</a><span>|</span><a href="#36364733">parent</a><span>|</span><a href="#36363114">next</a><span>|</span><label class="collapse" for="c-36366333">[-]</label><label class="expand" for="c-36366333">[1 more]</label></div><br/><div class="children"><div class="content">AI people sure don&#x27;t like criticism. I have noted that.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36363114" class="c"><input type="checkbox" id="c-36363114" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36362014">prev</a><span>|</span><a href="#36365474">next</a><span>|</span><label class="collapse" for="c-36363114">[-]</label><label class="expand" for="c-36363114">[1 more]</label></div><br/><div class="children"><div class="content">Discussed at the time:<p><i>Deep Learning&#x27;s Diminishing Returns</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28646256">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28646256</a> - Sept 2021 (84 comments)</div><br/></div></div><div id="36365474" class="c"><input type="checkbox" id="c-36365474" checked=""/><div class="controls bullet"><span class="by">cultofmetatron</span><span>|</span><a href="#36363114">prev</a><span>|</span><a href="#36363638">next</a><span>|</span><label class="collapse" for="c-36365474">[-]</label><label class="expand" for="c-36365474">[1 more]</label></div><br/><div class="children"><div class="content">things like this make me really appreciate the energy efficiency of a human brain. a typical human learns these kinds of tasks with less energy than it takes to boil a tea kettle</div><br/></div></div><div id="36363638" class="c"><input type="checkbox" id="c-36363638" checked=""/><div class="controls bullet"><span class="by">rictic</span><span>|</span><a href="#36365474">prev</a><span>|</span><a href="#36367146">next</a><span>|</span><label class="collapse" for="c-36363638">[-]</label><label class="expand" for="c-36363638">[4 more]</label></div><br/><div class="children"><div class="content">A disappointing analysis. It discusses cost in isolation from revenue, and raises environmental impacts without mentioning that the major cloud computing providers where the largest models are trained and run are carbon neutral.<p>Better results for general purpose tasks are likely to find willing buyers at prices orders of magnitude higher than even the largest language models of today. In most cases, the best alternative is human labor, and for more latency-sensitive cases, there is no alternative to a language model available at any price.</div><br/><div id="36364000" class="c"><input type="checkbox" id="c-36364000" checked=""/><div class="controls bullet"><span class="by">_Algernon_</span><span>|</span><a href="#36363638">parent</a><span>|</span><a href="#36365702">next</a><span>|</span><label class="collapse" for="c-36364000">[-]</label><label class="expand" for="c-36364000">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Carbon neutrality&quot; is shameless greenwashing while carbon credits in large part remain a scam.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Carbon_offsets_and_credits#Concerns_with_forestry_projects" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Carbon_offsets_and_credits#Con...</a></div><br/></div></div><div id="36365702" class="c"><input type="checkbox" id="c-36365702" checked=""/><div class="controls bullet"><span class="by">hn_thrwn</span><span>|</span><a href="#36363638">parent</a><span>|</span><a href="#36364000">prev</a><span>|</span><a href="#36363953">next</a><span>|</span><label class="collapse" for="c-36365702">[-]</label><label class="expand" for="c-36365702">[1 more]</label></div><br/><div class="children"><div class="content">Carbon neutral is the indulgence of our age. And about as effective.</div><br/></div></div><div id="36363953" class="c"><input type="checkbox" id="c-36363953" checked=""/><div class="controls bullet"><span class="by">wokkel</span><span>|</span><a href="#36363638">parent</a><span>|</span><a href="#36365702">prev</a><span>|</span><a href="#36367146">next</a><span>|</span><label class="collapse" for="c-36363953">[-]</label><label class="expand" for="c-36363953">[1 more]</label></div><br/><div class="children"><div class="content">Regarding carbon neutrality: yeah, by using their enourmous capital&#x2F;pricing power to buy all green power relegating the rest of the country to either use greenwashed grey power or outright grey power. So learning is green, it&#x27;s just the rest that is poluting....</div><br/></div></div></div></div><div id="36367146" class="c"><input type="checkbox" id="c-36367146" checked=""/><div class="controls bullet"><span class="by">ryan93</span><span>|</span><a href="#36363638">prev</a><span>|</span><label class="collapse" for="c-36367146">[-]</label><label class="expand" for="c-36367146">[1 more]</label></div><br/><div class="children"><div class="content">One month of nyc carbon is no big deal. Once a model is trained using it is much much cheaper</div><br/></div></div></div></div></div></div></div></body></html>