<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1704358854790" as="style"/><link rel="stylesheet" href="styles.css?v=1704358854790"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/">Understand how transformers work by demystifying the math behind them</a> <span class="domain">(<a href="https://osanseviero.github.io">osanseviero.github.io</a>)</span></div><div class="subtext"><span>LaserPineapple</span> | <span>85 comments</span></div><br/><div><div id="38860426" class="c"><input type="checkbox" id="c-38860426" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#38864561">next</a><span>|</span><label class="collapse" for="c-38860426">[-]</label><label class="expand" for="c-38860426">[25 more]</label></div><br/><div class="children"><div class="content">The whole &quot;mystery&quot; of transformer is that instead of a linear sequence of static weights times values in each layer, you now have 3 different matrices that are obtained from the same input through multiplication of learned weights, and then you just multiply the matrices together. I.e more parallelism which works out nice, but very restrictive since the attention formula is static.<p>We arent going to see more progress until we have a way to generalize the compute graph as a learnable parameter. I dunno if this is even possible in the traditional sense of gradients due to chaotic effects (i.e small changes reflect big shifts in performance),  it may have to be some form of genetic algorithm or pso that happens under the hood.</div><br/><div id="38864320" class="c"><input type="checkbox" id="c-38864320" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38860980">next</a><span>|</span><label class="collapse" for="c-38864320">[-]</label><label class="expand" for="c-38864320">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The whole &quot;mystery&quot; of transformer is that instead of a linear sequence of static weights times values in each layer, you now have 3 different matrices that are obtained from the same input through multiplication of learned weights, and then you just multiply the matrices together. I.e more parallelism which works out nice, but very restrictive since the attention formula is static.<p>That&#x27;s not it at all. What&#x27;s special about transformers is they allow each element in a sequence to decide which parts of data are most important to it from each other element in the sequence, then extract those out and compute on them. The big theoretical advantage over RNNs (which were used for sequences prior to transformers), is that transformers support this in a lossless way, as each element has full access to all the information in every other element in the sequence (or at least all the ones that occurred before it in time sequences). RNNs and &quot;linear transformers&quot; on the other hand compress past values, so generally the last element of a long sequence will not have access to all the information in the first element of the sequence (unless the RNN internal state was really really big so it didn&#x27;t need to discard any information).</div><br/></div></div><div id="38860980" class="c"><input type="checkbox" id="c-38860980" checked=""/><div class="controls bullet"><span class="by">necroforest</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38864320">prev</a><span>|</span><a href="#38860451">next</a><span>|</span><label class="collapse" for="c-38860980">[-]</label><label class="expand" for="c-38860980">[10 more]</label></div><br/><div class="children"><div class="content">&gt; We arent going to see more progress until we have a way to generalize the compute graph as a learnable parameter<p>That&#x27;s a bold statement since a ton of progress has been made without learning the compute graph.</div><br/><div id="38861143" class="c"><input type="checkbox" id="c-38861143" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860980">parent</a><span>|</span><a href="#38861274">next</a><span>|</span><label class="collapse" for="c-38861143">[-]</label><label class="expand" for="c-38861143">[3 more]</label></div><br/><div class="children"><div class="content">From my naive perspective, there seems to be a plateau, that everyone is converging on, somewhere between ChatGPT 3.5 and 4 level of performance, with some suspecting that the implementation of 4 might involve several expert models, which would already be extra sauce, external to the LLM. This, combined with the observation that generative models converge to the same output, given the same training data, regardless of architecture (having trouble finding the link, it was posted here some weeks ago), external secret sauce, outside the model, might be where the near term gains are.<p>I suppose we&#x27;ll see in the next year!</div><br/><div id="38862059" class="c"><input type="checkbox" id="c-38862059" checked=""/><div class="controls bullet"><span class="by">manojlds</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38861143">parent</a><span>|</span><a href="#38861274">next</a><span>|</span><label class="collapse" for="c-38862059">[-]</label><label class="expand" for="c-38862059">[2 more]</label></div><br/><div class="children"><div class="content">We already have competitors to Transformers<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.00752" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.00752</a></div><br/><div id="38862600" class="c"><input type="checkbox" id="c-38862600" checked=""/><div class="controls bullet"><span class="by">heyoni</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38862059">parent</a><span>|</span><a href="#38861274">next</a><span>|</span><label class="collapse" for="c-38862600">[-]</label><label class="expand" for="c-38862600">[1 more]</label></div><br/><div class="children"><div class="content">Where do I enter in my credit card info?</div><br/></div></div></div></div></div></div><div id="38861274" class="c"><input type="checkbox" id="c-38861274" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860980">parent</a><span>|</span><a href="#38861143">prev</a><span>|</span><a href="#38862777">next</a><span>|</span><label class="collapse" for="c-38861274">[-]</label><label class="expand" for="c-38861274">[4 more]</label></div><br/><div class="children"><div class="content">We have made progress in efficiency, not functionality. Instead of searching google or stack overflow or any particular documentation, we just go to Chatgpt.<p>Information compression is cool, but I want actual AI.</div><br/><div id="38861765" class="c"><input type="checkbox" id="c-38861765" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38861274">parent</a><span>|</span><a href="#38862644">next</a><span>|</span><label class="collapse" for="c-38861765">[-]</label><label class="expand" for="c-38861765">[1 more]</label></div><br/><div class="children"><div class="content">The idea that there has been no progress in functionality is silly.<p>Your whole brain might just be doing &quot;information compression&quot; by that analogy. An LLM is sort of learning concepts. Even Word2Vec &quot;learned&quot; than king - male + female = queen and that&#x27;s a small model that&#x27;s really just one part (not exact, but similar) of a transformer.</div><br/></div></div><div id="38862644" class="c"><input type="checkbox" id="c-38862644" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38861274">parent</a><span>|</span><a href="#38861765">prev</a><span>|</span><a href="#38862777">next</a><span>|</span><label class="collapse" for="c-38862644">[-]</label><label class="expand" for="c-38862644">[2 more]</label></div><br/><div class="children"><div class="content">Fascinating. What’s “actual AI”?</div><br/><div id="38864265" class="c"><input type="checkbox" id="c-38864265" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38862644">parent</a><span>|</span><a href="#38862777">next</a><span>|</span><label class="collapse" for="c-38864265">[-]</label><label class="expand" for="c-38864265">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>What’s “actual AI”</i><p>Is Ibn Sina (Avicenna, year ~1000) fine?<p>&gt; <i>[the higher faculty proper of humans is] the primary function of a natural body possessing organs in so far as it commits acts of rational choice and deduction through opinion; and in so far as it perceives universal matters</i><p>Or, &quot;Intelligence is the ability to reason, determining concepts&quot;.<p>(And a proper artificial such thing is something that does it well.)</div><br/></div></div></div></div></div></div><div id="38862777" class="c"><input type="checkbox" id="c-38862777" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860980">parent</a><span>|</span><a href="#38861274">prev</a><span>|</span><a href="#38860451">next</a><span>|</span><label class="collapse" for="c-38862777">[-]</label><label class="expand" for="c-38862777">[2 more]</label></div><br/><div class="children"><div class="content">A ton of progress can be made climbing a tree, but if your goal is reaching the moon it becomes clear pretty quickly that climbing taller trees will never get you there.</div><br/><div id="38863316" class="c"><input type="checkbox" id="c-38863316" checked=""/><div class="controls bullet"><span class="by">nethi</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38862777">parent</a><span>|</span><a href="#38860451">next</a><span>|</span><label class="collapse" for="c-38863316">[-]</label><label class="expand" for="c-38863316">[1 more]</label></div><br/><div class="children"><div class="content">True, but it is the process of climbing trees that gives the insight whether taller trees help or not and if not, what to do next.</div><br/></div></div></div></div></div></div><div id="38860451" class="c"><input type="checkbox" id="c-38860451" checked=""/><div class="controls bullet"><span class="by">ex3ndr</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38860980">prev</a><span>|</span><a href="#38864104">next</a><span>|</span><label class="collapse" for="c-38860451">[-]</label><label class="expand" for="c-38860451">[7 more]</label></div><br/><div class="children"><div class="content">This is basically this - it can learn ignore some paths, and amplify something more important, then you can just cut this paths without sensible loss of quality. The problem is that you are not going to win anything from this - non-matrix multiplication would be slower or the same.</div><br/><div id="38860507" class="c"><input type="checkbox" id="c-38860507" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860451">parent</a><span>|</span><a href="#38864104">next</a><span>|</span><label class="collapse" for="c-38860507">[-]</label><label class="expand" for="c-38860507">[6 more]</label></div><br/><div class="children"><div class="content">The issue is that you are thinking of this in terms of information compression, which is what LLMs are.<p>Im more concerned with an LLM having the ability to be trained to the point where a subset of the graph represents all the nand gates necessary for a cpu and ram, so when you ask it questions it can actually run code to compute them accurately instead of offering a statistical best guess, i.e decompression after lossy compression.</div><br/><div id="38860571" class="c"><input type="checkbox" id="c-38860571" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860507">parent</a><span>|</span><a href="#38861967">next</a><span>|</span><label class="collapse" for="c-38860571">[-]</label><label class="expand" for="c-38860571">[4 more]</label></div><br/><div class="children"><div class="content">Just give it a computer? Even a virtual machine. It can output assembly code or high level code that gets compiled.</div><br/><div id="38860939" class="c"><input type="checkbox" id="c-38860939" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860571">parent</a><span>|</span><a href="#38861967">next</a><span>|</span><label class="collapse" for="c-38860939">[-]</label><label class="expand" for="c-38860939">[3 more]</label></div><br/><div class="children"><div class="content">The issue is not having access to the cpu, the issue is that the model being able to be trained in such a way that it has representative structures for applicable problem solving.  Furthermore, the structures itself should<p>Philosophically, you can start ad hoc-ing functionalities on top of LLMs and expect major progress. Sure, you can make them better, but you will never get to the state where AI is massively useful.<p>For example, lets say you gather a whole bunch of experts in respective fields, and you give them a task to put together a detailed plan on how to build a flying car. You will have people doing design, doing simulations, researching material sourcing, creating CNC programs for manufacturing parts, sourcing tools and equipment, writing software, e.t.c. And when executing this plan, they would be open to feedback for anything missed, and can advise on how to proceed.<p>The AI with above capability should be able to go out on the internet, gather respective data, run any soft of algorithms it needs to run, and perhaps after a month of number crunching on a cloud rented TPU rack produce step by step plan with costs on how to do all of that. And it would be better than those experts because it should be able to create a much higher fidelity simulations to account for things like vibration and predict if some connector if going to wobble loose .</div><br/><div id="38861746" class="c"><input type="checkbox" id="c-38861746" checked=""/><div class="controls bullet"><span class="by">beambot</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860939">parent</a><span>|</span><a href="#38861763">next</a><span>|</span><label class="collapse" for="c-38861746">[-]</label><label class="expand" for="c-38861746">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Philosophically, you can start ad hoc-ing functionalities on top of LLMs and expect major progress. Sure, you can make them better, but you will never get to the state where AI is massively useful.<p>Evolution created various neural structures in biological brains (visual cortex, medulla, thalamus, etc) rather ad-hoc, and those resulted in &quot;massively useful&quot; systems.  Why should AI be different?</div><br/></div></div><div id="38861763" class="c"><input type="checkbox" id="c-38861763" checked=""/><div class="controls bullet"><span class="by">itishappy</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860939">parent</a><span>|</span><a href="#38861746">prev</a><span>|</span><a href="#38861967">next</a><span>|</span><label class="collapse" for="c-38861763">[-]</label><label class="expand" for="c-38861763">[1 more]</label></div><br/><div class="children"><div class="content">LLMs seem like the least efficient way to accomplish this. NAND gates, for example, are inherently 1-bit operators, but LLMs use more. If weights are all binary, than gradients are restricted to -1, 0, and 1, which doesn&#x27;t give you much room to make incremental improvements. You can add extra bits back, but that&#x27;s pure overhead. But all this is besides the real issue, which is that LLMs and NNs in general are inherently fuzzy; they guess. Computers aren&#x27;t, we have perfect simulators.<p>Consider how humans design things. We don&#x27;t talk through every CPU cycle to convince ourself a design works, we use bespoke tooling. Not all problems are language shaped.</div><br/></div></div></div></div></div></div><div id="38861967" class="c"><input type="checkbox" id="c-38861967" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38860507">parent</a><span>|</span><a href="#38860571">prev</a><span>|</span><a href="#38864104">next</a><span>|</span><label class="collapse" for="c-38861967">[-]</label><label class="expand" for="c-38861967">[1 more]</label></div><br/><div class="children"><div class="content">Well, just remember that NAND gates are made of transistors themselves which are a statistical model of a sort… just designed to appear digital when combined to that NAND level.<p>This is why I am very interested in analog again—quantum stuff is statistical already, so why go from statistical (analog) to digital (huge drop off of performance, e.g. just look at basic addition in a ALU) and back to statistical. Very interested. Not sure if it will ever be worth it, but can’t rule it out.</div><br/></div></div></div></div></div></div><div id="38864104" class="c"><input type="checkbox" id="c-38864104" checked=""/><div class="controls bullet"><span class="by">mikeknoop</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38860451">prev</a><span>|</span><a href="#38861885">next</a><span>|</span><label class="collapse" for="c-38864104">[-]</label><label class="expand" for="c-38864104">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t find your contact info. Email me?</div><br/></div></div><div id="38861885" class="c"><input type="checkbox" id="c-38861885" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38864104">prev</a><span>|</span><a href="#38861646">next</a><span>|</span><label class="collapse" for="c-38861885">[-]</label><label class="expand" for="c-38861885">[1 more]</label></div><br/><div class="children"><div class="content">hyperparameter tuning does already go some of the way towards learning the compute graph, though very constrained and with a lot more training required.</div><br/></div></div><div id="38861646" class="c"><input type="checkbox" id="c-38861646" checked=""/><div class="controls bullet"><span class="by">knightoffaith</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38861885">prev</a><span>|</span><a href="#38862250">next</a><span>|</span><label class="collapse" for="c-38861646">[-]</label><label class="expand" for="c-38861646">[2 more]</label></div><br/><div class="children"><div class="content">How can gradient descent work on compute graphs when the space of compute graphs is discrete?</div><br/><div id="38862069" class="c"><input type="checkbox" id="c-38862069" checked=""/><div class="controls bullet"><span class="by">tnecniv</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38861646">parent</a><span>|</span><a href="#38862250">next</a><span>|</span><label class="collapse" for="c-38862069">[-]</label><label class="expand" for="c-38862069">[1 more]</label></div><br/><div class="children"><div class="content">It can’t. There’s no gradient since it’s not a sufficiently nice space for them. You can use gradient free methods but I’d be shocked if there was an efficient enough way to do that</div><br/></div></div></div></div><div id="38862250" class="c"><input type="checkbox" id="c-38862250" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#38860426">parent</a><span>|</span><a href="#38861646">prev</a><span>|</span><a href="#38864561">next</a><span>|</span><label class="collapse" for="c-38862250">[-]</label><label class="expand" for="c-38862250">[2 more]</label></div><br/><div class="children"><div class="content">Genetic algorithms figured out GI the first time, but it took a while.</div><br/><div id="38864339" class="c"><input type="checkbox" id="c-38864339" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#38860426">root</a><span>|</span><a href="#38862250">parent</a><span>|</span><a href="#38864561">next</a><span>|</span><label class="collapse" for="c-38864339">[-]</label><label class="expand" for="c-38864339">[1 more]</label></div><br/><div class="children"><div class="content">Could you please expand?</div><br/></div></div></div></div></div></div><div id="38864561" class="c"><input type="checkbox" id="c-38864561" checked=""/><div class="controls bullet"><span class="by">sam16180</span><span>|</span><a href="#38860426">prev</a><span>|</span><a href="#38860632">next</a><span>|</span><label class="collapse" for="c-38864561">[-]</label><label class="expand" for="c-38864561">[1 more]</label></div><br/><div class="children"><div class="content">Is there an error in the positional encoding example? For example when calculating PE(1, 3), I&#x27;d expect i = 1 as 3 = 2 * 1 + 1<p>So for “World”<p>PE(1, 0) = sin(1 &#x2F; 10000^(2*0 &#x2F; 4)) = sin(1 &#x2F; 10000^0) = sin(1) ≈ 0.84<p>PE(1, 1) = cos(1 &#x2F; 10000^(2*0 &#x2F; 4)) = cos(1 &#x2F; 10000^0) = cos(1) ≈ 0.54<p>PE(1, 2) = sin(1 &#x2F; 10000^(2*1 &#x2F; 4)) = sin(1 &#x2F; 10000^.5) ≈ 0.01<p>PE(1, 3) = cos(1 &#x2F; 10000^(2*1 &#x2F; 4)) = cos(1 &#x2F; 10000^.5) ≈ 1<p>I also wondered if these formulae were devised with 1-based indexing in mind (though I guess for larger dimensions it doesn&#x27;t make much difference), as the paper states<p>&gt; The wavelengths form a geometric progression from 2π to 10000 · 2π<p>That led me to this chain of PRs - <a href="https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensor2tensor&#x2F;pull&#x2F;177">https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensor2tensor&#x2F;pull&#x2F;177</a> - turns out the original code was actually quite different to that stated in the paper. I guess slight variations in how you calculate this encoding doesn&#x27;t affect things too much?</div><br/></div></div><div id="38860632" class="c"><input type="checkbox" id="c-38860632" checked=""/><div class="controls bullet"><span class="by">enriquto</span><span>|</span><a href="#38864561">prev</a><span>|</span><a href="#38860689">next</a><span>|</span><label class="collapse" for="c-38860632">[-]</label><label class="expand" for="c-38860632">[2 more]</label></div><br/><div class="children"><div class="content">For a dryer, more formal and succinct approach, see &quot;The Transformer Model in Equations&quot; [0], by
John Thickstun.  The whole thing fits in a single page, using standard mathematical notation.<p>[0] <a href="https:&#x2F;&#x2F;johnthickstun.com&#x2F;docs&#x2F;transformers.pdf" rel="nofollow">https:&#x2F;&#x2F;johnthickstun.com&#x2F;docs&#x2F;transformers.pdf</a></div><br/><div id="38861251" class="c"><input type="checkbox" id="c-38861251" checked=""/><div class="controls bullet"><span class="by">wardedVibe</span><span>|</span><a href="#38860632">parent</a><span>|</span><a href="#38860689">next</a><span>|</span><label class="collapse" for="c-38861251">[-]</label><label class="expand" for="c-38861251">[1 more]</label></div><br/><div class="children"><div class="content">Thank god, I&#x27;ve had to cobble something like this together for my own notes a couple of times trying to parse papers and was never quite sure if I was missing something.</div><br/></div></div></div></div><div id="38860689" class="c"><input type="checkbox" id="c-38860689" checked=""/><div class="controls bullet"><span class="by">dogline</span><span>|</span><a href="#38860632">prev</a><span>|</span><a href="#38860335">next</a><span>|</span><label class="collapse" for="c-38860689">[-]</label><label class="expand" for="c-38860689">[5 more]</label></div><br/><div class="children"><div class="content">Six paragraphs in, and I already have questions.<p>&gt; Hello -&gt; [1,2,3,4] World -&gt; [2,3,4,5]<p>The vectors are random, but they look like they have a pattern here.  Does the 2 in both vector mean something?  Or, is it the entire set that makes it unique?</div><br/><div id="38860881" class="c"><input type="checkbox" id="c-38860881" checked=""/><div class="controls bullet"><span class="by">dan-robertson</span><span>|</span><a href="#38860689">parent</a><span>|</span><a href="#38861095">next</a><span>|</span><label class="collapse" for="c-38860881">[-]</label><label class="expand" for="c-38860881">[3 more]</label></div><br/><div class="children"><div class="content">The number reuse is just the author being a bit lazy. You could estimate how similar these vectors are by seeing if they point in similar directions or by calculating the angle between them. Here they are about 60° apart and somewhat the same direction, but a lot of this is that the author didn’t want to put in any negative numbers in the example so vectors end up being a bit more similar than they would be really.<p>That the numbers are reused isn’t meaningful here: a 1 in the first position is quite unrelated to a 1 in the second (as no convolutions are done over this vector)</div><br/><div id="38861126" class="c"><input type="checkbox" id="c-38861126" checked=""/><div class="controls bullet"><span class="by">dogline</span><span>|</span><a href="#38860689">root</a><span>|</span><a href="#38860881">parent</a><span>|</span><a href="#38861095">next</a><span>|</span><label class="collapse" for="c-38861126">[-]</label><label class="expand" for="c-38861126">[2 more]</label></div><br/><div class="children"><div class="content">Thank you.  I guess I need to back up.  This is a vector, not just an identifier, and direction and angle seem important.  I need to look up how the encoding is normally done, since this isn&#x27;t obvious if you haven&#x27;t worked in this domain before.</div><br/><div id="38861909" class="c"><input type="checkbox" id="c-38861909" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#38860689">root</a><span>|</span><a href="#38861126">parent</a><span>|</span><a href="#38861095">next</a><span>|</span><label class="collapse" for="c-38861909">[-]</label><label class="expand" for="c-38861909">[1 more]</label></div><br/><div class="children"><div class="content">The encoding is typically learned, and if possible is part of the ANN so that it can be adjusted along with the other parameters.<p>A good place to start on that topic is the word2vec paper.</div><br/></div></div></div></div></div></div><div id="38861095" class="c"><input type="checkbox" id="c-38861095" checked=""/><div class="controls bullet"><span class="by">smaddox</span><span>|</span><a href="#38860689">parent</a><span>|</span><a href="#38860881">prev</a><span>|</span><a href="#38860335">next</a><span>|</span><label class="collapse" for="c-38861095">[-]</label><label class="expand" for="c-38861095">[1 more]</label></div><br/><div class="children"><div class="content">That isn&#x27;t a very good example. The vectors for each token are randomly initialized with each element taken from the normal distribution. After training, similar words will have some cosine similarity, but almost never as much cosine similarity as [1,2,3,4] and [2,3,4,5].</div><br/></div></div></div></div><div id="38860335" class="c"><input type="checkbox" id="c-38860335" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38860689">prev</a><span>|</span><a href="#38862414">next</a><span>|</span><label class="collapse" for="c-38860335">[-]</label><label class="expand" for="c-38860335">[4 more]</label></div><br/><div class="children"><div class="content">Transformer tutorials might be the new monad tutorial. A hard concept to get, but one you need to struggle with (and practice some examples) to understand. So a bit like much of computer science :-).</div><br/><div id="38860430" class="c"><input type="checkbox" id="c-38860430" checked=""/><div class="controls bullet"><span class="by">hdhfjkrkrme</span><span>|</span><a href="#38860335">parent</a><span>|</span><a href="#38860633">next</a><span>|</span><label class="collapse" for="c-38860430">[-]</label><label class="expand" for="c-38860430">[1 more]</label></div><br/><div class="children"><div class="content">The moment you understand the Transformer you become incapable of explaining it.</div><br/></div></div><div id="38860633" class="c"><input type="checkbox" id="c-38860633" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#38860335">parent</a><span>|</span><a href="#38860430">prev</a><span>|</span><a href="#38860675">next</a><span>|</span><label class="collapse" for="c-38860633">[-]</label><label class="expand" for="c-38860633">[1 more]</label></div><br/><div class="children"><div class="content">Waiting for a blogpost titled &quot;You could have invented transformers&quot;.</div><br/></div></div><div id="38860675" class="c"><input type="checkbox" id="c-38860675" checked=""/><div class="controls bullet"><span class="by">csdvrx</span><span>|</span><a href="#38860335">parent</a><span>|</span><a href="#38860633">prev</a><span>|</span><a href="#38862414">next</a><span>|</span><label class="collapse" for="c-38860675">[-]</label><label class="expand" for="c-38860675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Transformer tutorials might be the new monad tutorial. A hard concept to get,<p>A hard concept?<p>But a monad is just a monoid in the category of endofunctors, so what&#x27;s the problem?</div><br/></div></div></div></div><div id="38862414" class="c"><input type="checkbox" id="c-38862414" checked=""/><div class="controls bullet"><span class="by">heisenburgzero</span><span>|</span><a href="#38860335">prev</a><span>|</span><a href="#38860776">next</a><span>|</span><label class="collapse" for="c-38862414">[-]</label><label class="expand" for="c-38862414">[5 more]</label></div><br/><div class="children"><div class="content">Not completely related. Does anyone know where I can find articles &#x2F; papers that discuss why transformers, while acting as merely &quot;next token predictor&quot; can handle questions with:
1. Unknown words (or subwords&#x2F;tokens) that are not seen in the training dataset.
Example: Create a table with &quot;sdsfs_ff&quot;, &quot;fsdf_value&quot; as columns in pandas.
2. Create examples(unseen in training dataset) and tell the LLM to provide similar output.<p>I have a feeling it should be a common question, but I just can&#x27;t find the keyword to search.<p>PS. If anyone has any links with thoroughly discussion about positional embedding, that would be great. I never got a satisfying answer about the usage of sine &#x2F; cosine and (multiplication vs addition)</div><br/><div id="38862578" class="c"><input type="checkbox" id="c-38862578" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#38862414">parent</a><span>|</span><a href="#38863036">next</a><span>|</span><label class="collapse" for="c-38862578">[-]</label><label class="expand" for="c-38862578">[3 more]</label></div><br/><div class="children"><div class="content">If I had to guess, single characters are able to be encoded as tokens, but there&#x27;s more &quot;bandwidth&quot; in the model being dedicated to handling them and there&#x27;s less semantic meaning encoded in them &quot;natively&quot; compared to tokens for concrete words.  If it decides to, it can recreate unknown sequences by copying over the tokens for the single letters or create them if it makes sense.</div><br/><div id="38862770" class="c"><input type="checkbox" id="c-38862770" checked=""/><div class="controls bullet"><span class="by">heisenburgzero</span><span>|</span><a href="#38862414">root</a><span>|</span><a href="#38862578">parent</a><span>|</span><a href="#38863036">next</a><span>|</span><label class="collapse" for="c-38862770">[-]</label><label class="expand" for="c-38862770">[2 more]</label></div><br/><div class="children"><div class="content">I think some earlier NLP applications have something called &quot;Unknown token&quot;, which they will replace any unseen word. But for recent implementations, I don&#x27;t think they are being used anymore.<p>It still baffles me why such stochastic parrot &#x2F; next token predictor, will recognize these &quot;Unseen combinations of tokens&quot; and reuse them in response.</div><br/><div id="38864576" class="c"><input type="checkbox" id="c-38864576" checked=""/><div class="controls bullet"><span class="by">stevenhuang</span><span>|</span><a href="#38862414">root</a><span>|</span><a href="#38862770">parent</a><span>|</span><a href="#38863036">next</a><span>|</span><label class="collapse" for="c-38864576">[-]</label><label class="expand" for="c-38864576">[1 more]</label></div><br/><div class="children"><div class="content">Everything falls into place once you understand that LLMs are indeed learning hierarchical concepts inherent in the structured data it has been trained on. These concepts exist in a high dimensional latent space. Within this space is the concept of nonsense&#x2F;gibberish&#x2F;placeholder, which your sequence of unseen tokens map to. Then it combines this with the concept of SQL tables, resulting in hopefully the intended answer.</div><br/></div></div></div></div></div></div><div id="38863036" class="c"><input type="checkbox" id="c-38863036" checked=""/><div class="controls bullet"><span class="by">thewarrior</span><span>|</span><a href="#38862414">parent</a><span>|</span><a href="#38862578">prev</a><span>|</span><a href="#38860776">next</a><span>|</span><label class="collapse" for="c-38863036">[-]</label><label class="expand" for="c-38863036">[1 more]</label></div><br/><div class="children"><div class="content">It’s not reproducing exact strings in the training data but patterns and patterns of patterns.<p>Next token prediction is more intelligent than it sounds</div><br/></div></div></div></div><div id="38860776" class="c"><input type="checkbox" id="c-38860776" checked=""/><div class="controls bullet"><span class="by">snaxsnaxsnax</span><span>|</span><a href="#38862414">prev</a><span>|</span><a href="#38861247">next</a><span>|</span><label class="collapse" for="c-38860776">[-]</label><label class="expand" for="c-38860776">[1 more]</label></div><br/><div class="children"><div class="content">Hmmm, yes, I know some of these words.</div><br/></div></div><div id="38861247" class="c"><input type="checkbox" id="c-38861247" checked=""/><div class="controls bullet"><span class="by">remexre</span><span>|</span><a href="#38860776">prev</a><span>|</span><a href="#38860619">next</a><span>|</span><label class="collapse" for="c-38861247">[-]</label><label class="expand" for="c-38861247">[1 more]</label></div><br/><div class="children"><div class="content">Should the line<p><pre><code>    Z_encoder_decoder = layer_norm(Z_encoder_decoder + Z)

</code></pre>
in Decoder step 7 instead be<p><pre><code>    Z_encoder_decoder = layer_norm(Z_encoder_decoder + Z_self_attention)
</code></pre>
? Also, is layer_norm missing in Decoder step 8...</div><br/></div></div><div id="38860619" class="c"><input type="checkbox" id="c-38860619" checked=""/><div class="controls bullet"><span class="by">bloopernova</span><span>|</span><a href="#38861247">prev</a><span>|</span><a href="#38863199">next</a><span>|</span><label class="collapse" for="c-38860619">[-]</label><label class="expand" for="c-38860619">[9 more]</label></div><br/><div class="children"><div class="content">Do LLMs use neural nets? If so, what makes up the &quot;neuron&quot;? i.e. Is there a code structure that underlies the neuron, or is it &quot;just&quot; fancy math?</div><br/><div id="38860673" class="c"><input type="checkbox" id="c-38860673" checked=""/><div class="controls bullet"><span class="by">osanseviero</span><span>|</span><a href="#38860619">parent</a><span>|</span><a href="#38860725">next</a><span>|</span><label class="collapse" for="c-38860673">[-]</label><label class="expand" for="c-38860673">[1 more]</label></div><br/><div class="children"><div class="content">Just math, and not even that fancy.<p>Let&#x27;s say you want to predict if you&#x27;ll pass an exam based on how many hours you studied (x1) and how many exercises you did (x2). A neuron will learn a weight for each variable (w1 and w2). If the model learns w1=0.5 and w2=1, the model will provide more importance to the # of exercises.<p>So if you study for 10 hours and only do 2 exercises, the model will do x1w1 + x2w2=10x0.5 + 2x1 = 7. The neuron then outputs that. This is a bit (but not much) simplified - we also have a bias term and an activation to process the output.<p>Congrats! We built our first neuron together! Have thousands of these neurons in connected layers, and you suddenly have a deep neural network. Have billions or trillions of them, you have an LLM :)</div><br/></div></div><div id="38860725" class="c"><input type="checkbox" id="c-38860725" checked=""/><div class="controls bullet"><span class="by">abrichr</span><span>|</span><a href="#38860619">parent</a><span>|</span><a href="#38860673">prev</a><span>|</span><a href="#38860662">next</a><span>|</span><label class="collapse" for="c-38860725">[-]</label><label class="expand" for="c-38860725">[1 more]</label></div><br/><div class="children"><div class="content">The “neuron” in a neural network is just a non linear function of the weighted sum of the inputs (plus a bias term).<p>See the “definition” section in <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Perceptron" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Perceptron</a> .</div><br/></div></div><div id="38860662" class="c"><input type="checkbox" id="c-38860662" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38860619">parent</a><span>|</span><a href="#38860725">prev</a><span>|</span><a href="#38860661">next</a><span>|</span><label class="collapse" for="c-38860662">[-]</label><label class="expand" for="c-38860662">[3 more]</label></div><br/><div class="children"><div class="content">Transformers can be considered a kind of neural network.<p>It’s mainly fancy math. With tools like PyTorch or tensorflow, you use python to describe a graph of computations which gets compiled down into optimized instructions.<p>There are some examples of people making transformers and other NN architectures in about 100 lines of code. I’d google for those to see what these things look like in code.<p>The training loop, data, and resulting weights are where the magic is.<p>The code is disappointingly simple.</div><br/><div id="38860708" class="c"><input type="checkbox" id="c-38860708" checked=""/><div class="controls bullet"><span class="by">bloopernova</span><span>|</span><a href="#38860619">root</a><span>|</span><a href="#38860662">parent</a><span>|</span><a href="#38860661">next</a><span>|</span><label class="collapse" for="c-38860708">[-]</label><label class="expand" for="c-38860708">[2 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; The code is disappointingly simple.
</code></pre>
I absolutely adore this sentence, it made me laugh to imagine coders or other folks looking at the code and thinking &quot;That&#x27;s it?!? But that&#x27;s simple!&quot;<p>Although it feels a little similar to some of the basic reactions that go to make up DNA: start with simple units that work together to form something much more complex.<p>(apologies for poor metaphors, I&#x27;m still trying to grasp some of the concepts involved with this)</div><br/><div id="38862920" class="c"><input type="checkbox" id="c-38862920" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#38860619">root</a><span>|</span><a href="#38860708">parent</a><span>|</span><a href="#38860661">next</a><span>|</span><label class="collapse" for="c-38862920">[-]</label><label class="expand" for="c-38862920">[1 more]</label></div><br/><div class="children"><div class="content">Yes neural networks, and even the math required to build them, are very simple calc 1 stuff generally.  It’s more coming up with these models that takes powerful intuition</div><br/></div></div></div></div></div></div><div id="38860661" class="c"><input type="checkbox" id="c-38860661" checked=""/><div class="controls bullet"><span class="by">theonlybutlet</span><span>|</span><a href="#38860619">parent</a><span>|</span><a href="#38860662">prev</a><span>|</span><a href="#38863199">next</a><span>|</span><label class="collapse" for="c-38860661">[-]</label><label class="expand" for="c-38860661">[3 more]</label></div><br/><div class="children"><div class="content">Yes to both, the &quot;neuron&quot; would basically be a weighted parameter.
A parameter is an expression, it&#x27;s a mathematical representation of a token and it&#x27;s probabilistic weighting (theyre translated from input or to output token lists entering and exiting the model). 
Usually tokens are  pre-set small groups of character combinations like &quot;if &quot; or &quot;cha&quot; that make up a word&#x2F;sentence.
The recorded path your value takes down the chain of probabilities would be the &quot;neural pathway&quot; within the wider &quot;neural network&quot;.<p>Someone please correct me if I&#x27;m wrong or my terminology is wrong.</div><br/><div id="38863112" class="c"><input type="checkbox" id="c-38863112" checked=""/><div class="controls bullet"><span class="by">pmayrgundter</span><span>|</span><a href="#38860619">root</a><span>|</span><a href="#38860661">parent</a><span>|</span><a href="#38863199">next</a><span>|</span><label class="collapse" for="c-38863112">[-]</label><label class="expand" for="c-38863112">[2 more]</label></div><br/><div class="children"><div class="content">This is all true in a neutral net, but Transformers aren&#x27;t Neural Nets in the traditional sense.  I was under that impression originally, but there&#x27;s not a back propagation or Hebbian learning here, which were the key bits of biomimicry that earned classic NNs their name.<p>Transformers do have coefficients that are fit, but that&#x27;s more broad.. could be used for any sort of regression or optimization, and not necessarily indicative of biological analogs.<p>So I think the terms &quot;learned model&quot; of &quot;weights&quot; are malapropisms for Transformers, carried over from deep nets because of structural similarities, like many layers, and the development workflow.<p>The functional units in Transformer&#x27;s layers have lost their orginal biological inspiration and functional analog.  The core function in Transformers is more like autoencoding&#x2F;decoding (concepts from info theory) and model&#x2F;grammar-free translation, with a unique attention based optimization.  Transformers were developed for translation.  The magic is smth like &quot;attending&quot; to important parts of the translation inputs&amp;outputs as tokens are generated, maybe as a kind of deviation on pure autoencoding, due to the bias from the .. learned model :) See I can&#x27;t even escape it.<p>Attention as a powerful systemic optimization is the actual closer bit of neuro&#x2F;bio-insporation here.. but more from Cog Psych than micro&#x2F;neuro anatomy.<p>Btw, not only is attention a key insight for Transformers, but it&#x27;s an interesting biographical note that the lead inventor of it, Jakob Uzkereit, went on to work on a bio-AI startup after Google.</div><br/><div id="38864515" class="c"><input type="checkbox" id="c-38864515" checked=""/><div class="controls bullet"><span class="by">theonlybutlet</span><span>|</span><a href="#38860619">root</a><span>|</span><a href="#38863112">parent</a><span>|</span><a href="#38863199">next</a><span>|</span><label class="collapse" for="c-38864515">[-]</label><label class="expand" for="c-38864515">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for your reply, you raise a very good point, transformer models are a lot more complex. I&#x27;d argue conceptually they&#x27;re the same, just the data and process is more abstracted. Autoencoded data implies using efficient representations, basically semantically abstracted data and opting for measures like back propagation through time.</div><br/></div></div></div></div></div></div></div></div><div id="38863199" class="c"><input type="checkbox" id="c-38863199" checked=""/><div class="controls bullet"><span class="by">dingclancy</span><span>|</span><a href="#38860619">prev</a><span>|</span><a href="#38860564">next</a><span>|</span><label class="collapse" for="c-38863199">[-]</label><label class="expand" for="c-38863199">[1 more]</label></div><br/><div class="children"><div class="content">I am loving the Quarto website. I see more Python users using Quarto for publishing.</div><br/></div></div><div id="38860564" class="c"><input type="checkbox" id="c-38860564" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#38863199">prev</a><span>|</span><a href="#38860179">next</a><span>|</span><label class="collapse" for="c-38860564">[-]</label><label class="expand" for="c-38860564">[10 more]</label></div><br/><div class="children"><div class="content">Does the human brain use transformers?</div><br/><div id="38860606" class="c"><input type="checkbox" id="c-38860606" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38864328">next</a><span>|</span><label class="collapse" for="c-38860606">[-]</label><label class="expand" for="c-38860606">[1 more]</label></div><br/><div class="children"><div class="content">Yes, through ie. services like openai&#x27;s chatgpt.</div><br/></div></div><div id="38864328" class="c"><input type="checkbox" id="c-38864328" checked=""/><div class="controls bullet"><span class="by">nostrademons</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38860606">prev</a><span>|</span><a href="#38860598">next</a><span>|</span><label class="collapse" for="c-38864328">[-]</label><label class="expand" for="c-38864328">[1 more]</label></div><br/><div class="children"><div class="content">Yes.  I still remember Optimus Prime and Bumblebee from my youth.</div><br/></div></div><div id="38860598" class="c"><input type="checkbox" id="c-38860598" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38864328">prev</a><span>|</span><a href="#38861120">next</a><span>|</span><label class="collapse" for="c-38860598">[-]</label><label class="expand" for="c-38860598">[1 more]</label></div><br/><div class="children"><div class="content">No, but they can both implement a language virtual machine which appears to be able to produce intelligent behaviour with unknown bounds.</div><br/></div></div><div id="38861120" class="c"><input type="checkbox" id="c-38861120" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38860598">prev</a><span>|</span><a href="#38860683">next</a><span>|</span><label class="collapse" for="c-38861120">[-]</label><label class="expand" for="c-38861120">[2 more]</label></div><br/><div class="children"><div class="content">I’m assuming you are asking if the brain uses transformer-like structures or otherwise exhibits similar behavior. I don’t know, but it does share some processes with simpler ML ideas, and I’d be very interested to see if it uses anything resembling a transformer.</div><br/><div id="38862080" class="c"><input type="checkbox" id="c-38862080" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#38860564">root</a><span>|</span><a href="#38861120">parent</a><span>|</span><a href="#38860683">next</a><span>|</span><label class="collapse" for="c-38862080">[-]</label><label class="expand" for="c-38862080">[1 more]</label></div><br/><div class="children"><div class="content">Forward-forward algorithm is more like the brain. As I understand, backpropagation transformers require storing data, doing calculations on that aggregate, and sending it back through, which no neural structures can do anything like.<p><a href="https:&#x2F;&#x2F;medium.com&#x2F;@Mosbeh_Barhoumi&#x2F;forward-forward-algorithm-ac24d0d9ffd" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;@Mosbeh_Barhoumi&#x2F;forward-forward-algorith...</a></div><br/></div></div></div></div><div id="38860683" class="c"><input type="checkbox" id="c-38860683" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38861120">prev</a><span>|</span><a href="#38860668">next</a><span>|</span><label class="collapse" for="c-38860683">[-]</label><label class="expand" for="c-38860683">[3 more]</label></div><br/><div class="children"><div class="content">Anyone telling you it does is a fraud.</div><br/><div id="38861263" class="c"><input type="checkbox" id="c-38861263" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#38860564">root</a><span>|</span><a href="#38860683">parent</a><span>|</span><a href="#38860668">next</a><span>|</span><label class="collapse" for="c-38861263">[-]</label><label class="expand" for="c-38861263">[2 more]</label></div><br/><div class="children"><div class="content">Here [1] are some &quot;frauds&quot; from Stanford University, Oxford University and University College London telling you exactly that.<p>From their abstract:<p>``One of the most exciting and promising novel architectures, the Transformer neural
network, was developed without the brain in mind. In this work, we show that
transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably
place and grid cells. Furthermore, we show that this result is no surprise since
it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the
neuroscience version.``<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.04035" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.04035</a></div><br/><div id="38862213" class="c"><input type="checkbox" id="c-38862213" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38860564">root</a><span>|</span><a href="#38861263">parent</a><span>|</span><a href="#38860668">next</a><span>|</span><label class="collapse" for="c-38862213">[-]</label><label class="expand" for="c-38862213">[1 more]</label></div><br/><div class="children"><div class="content">Making the claim that transformers are a good candidate model for certain neural pathways is a pretty different claim than saying the brain is literally using transformers.</div><br/></div></div></div></div></div></div><div id="38860668" class="c"><input type="checkbox" id="c-38860668" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38860564">parent</a><span>|</span><a href="#38860683">prev</a><span>|</span><a href="#38860179">next</a><span>|</span><label class="collapse" for="c-38860668">[-]</label><label class="expand" for="c-38860668">[1 more]</label></div><br/><div class="children"><div class="content">What?</div><br/></div></div></div></div><div id="38860179" class="c"><input type="checkbox" id="c-38860179" checked=""/><div class="controls bullet"><span class="by">leereeves</span><span>|</span><a href="#38860564">prev</a><span>|</span><a href="#38861116">next</a><span>|</span><label class="collapse" for="c-38860179">[-]</label><label class="expand" for="c-38860179">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The complexity comes from the number of steps and the number of parameters.<p>Yes, it seems like a transformer model simple enough for us to understand isn&#x27;t able to do anything interesting, and a transformer complex enough to do something interesting is too complex for us to understand.<p>I would love to study something in the middle, a model that is both simple enough to understand and complex enough to do something interesting.</div><br/><div id="38860239" class="c"><input type="checkbox" id="c-38860239" checked=""/><div class="controls bullet"><span class="by">calebkaiser</span><span>|</span><a href="#38860179">parent</a><span>|</span><a href="#38861116">next</a><span>|</span><label class="collapse" for="c-38860239">[-]</label><label class="expand" for="c-38860239">[2 more]</label></div><br/><div class="children"><div class="content">You might be interested, if you aren&#x27;t already familiar, in some of the work going on in the mechanistic interpretability field. Neel Nanda has a lot of approachable work on the topic: <a href="https:&#x2F;&#x2F;www.neelnanda.io&#x2F;mechanistic-interpretability" rel="nofollow">https:&#x2F;&#x2F;www.neelnanda.io&#x2F;mechanistic-interpretability</a></div><br/><div id="38860494" class="c"><input type="checkbox" id="c-38860494" checked=""/><div class="controls bullet"><span class="by">leereeves</span><span>|</span><a href="#38860179">root</a><span>|</span><a href="#38860239">parent</a><span>|</span><a href="#38861116">next</a><span>|</span><label class="collapse" for="c-38860494">[-]</label><label class="expand" for="c-38860494">[1 more]</label></div><br/><div class="children"><div class="content">I was not familiar with it, and that does look fascinating, thank you. If anyone else is interested, this guide &quot;Concrete Steps to Get Started in Transformer Mechanistic Interpretability&quot; on his site looks like a great place to start:<p><a href="https:&#x2F;&#x2F;www.neelnanda.io&#x2F;mechanistic-interpretability&#x2F;getting-started" rel="nofollow">https:&#x2F;&#x2F;www.neelnanda.io&#x2F;mechanistic-interpretability&#x2F;gettin...</a></div><br/></div></div></div></div></div></div><div id="38861116" class="c"><input type="checkbox" id="c-38861116" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38860179">prev</a><span>|</span><a href="#38863663">next</a><span>|</span><label class="collapse" for="c-38861116">[-]</label><label class="expand" for="c-38861116">[3 more]</label></div><br/><div class="children"><div class="content">I love and hate these.<p>I love them because they do give another resource at explaining models such as transformers and I think this one is pretty well done (note: you really need to do something about the equation in 4.2...)<p>First, the critique is coming from love. Great work, so I don&#x27;t want it to be taken as I&#x27;m saying anything it isn&#x27;t.<p>Why I hate these is that they are labeled as &quot;math behind&quot; but I think this is not quite fitting. This is the opposite of the complaint I made about the Introduction to DL post the other day[0]. The issue isn&#x27;t that there isn&#x27;t math, but contextually it is being labeled as a mathematical approach but I&#x27;m not seeing anything that distinguishes it as deeper than what you&#x27;d get from Karpathy&#x27;s videos or the Annotated Transformer (I like this more than illustrated). There&#x27;s nothing wrong with that, but just think it might mislead people, especially as there is a serious lack of places to find a much deeper mathematical explanation behind architectures and the naming makes it harder to find for those that are looking for that, because they&#x27;ll find these posts. Simply, complaint is about framing.<p>To be clear, the complaint is just about the subtitle, because the article is good and a useful resource for people seeking to learn attention and transformers. But let me try to clarify some of what would I personally (welcome to disagree, it is an opinion) more accurately be representative of &quot; demystifying all the math behind them&quot;:<p>- I would include a much deeper discussion of both embedding and positional embedding. The former you should at minimum be discussion how it is created and discussing the dequantization. This post may give a reader the impression that this is not taking place (there is ambiguity between distinction of embedding vs tokenization and embedding, this looks to just briefly mention tokenization. I specifically think a novice might take away that the dequantization is happening due to the positional encoding, and not in the embedding). The tokenization and embedding is a vastly underappreciated and incredibly important aspect of making discrete models work (not just LLMs or LMs. Principle is more general).<p>- Same goes for the positional embedding which I have only in a handful of cases seen discussed and taken rather matter of factly. For a mathematical explanation you do need to explain the idea behind generating unique signals for each position, explain why we need a a high frequency, and it is worth mentioning how this can be learnable (often with similar results, which is why most don&#x27;t bother), and other forms like rotational. The principle is far more general than even a Fourier Series (unmentioned!). The continuous aspect also matters a lot here, and we (often) don&#x27;t want discritized positional encoding. If this isn&#x27;t explained it feels rather arbitrary, and in some ways it is but others it isn&#x27;t.<p>- The attention mechanism is vastly under-explained, though I understand why. There are many approaches to tackle this, some from graphs, some from category theory, and many others. They&#x27;re all valuable pieces to the puzzle. But at minimum I think there needs to be a clear identification as to what the dot product is doing, the softmax, the scale (see softmax tempering), and why we then have the value. Their key-query-value names were not chosen at random and the database analogy is quite helpful. Maybe many don&#x27;t understand the relationship of dot products and angles between vectors? But this can even get complex as we would expect values to go to 0 in high dimensions (which they kinda do if you look at the attention matricies post learning which often look highly diagonal and why you can initialize them as diagonally spiked for sometimes faster training). This would be a great place to bring up how there might be some surprising aspects to the attention mechanism considering matrices represent affine transformations of data (linear) and we might not see the non-linearity here (softmax) or understand why softmax works better than other non-linears or normalizers (try it yourself!).<p>- There&#x27;s more but I&#x27;ve written a wall. So I&#x27;ll just say we can continue for the residuals (also see META&#x27;s 3 Things Everyone Should Know About Vision Transformers, in the Deit repo), why we have pre-norm as opposed to the original post-norm (which it looks like post norm is being used!), the residuals (knot theory can help here a bit), and why we have the linear layer (similarly the unknotting discussion helps, especially quantifying why we like a 4x ratio, but isn&#x27;t absolutely necessary).<p>Idk, are people interested in these things? I know most people aren&#x27;t, and there&#x27;s absolutely nothing wrong with that (you can still build strong models without this knowledge, but it is definitely helpful). I do feel that we often call these things black boxes but they aren&#x27;t completely opaque. They sure aren&#x27;t transparent, especially through scale, but they aren&#x27;t &quot;black&quot; either. (Allen-Zhu &amp; Li&#x27;s Physics of LLMs is a great resource btw and I&#x27;d love if other users posted&#x2F;referenced more things they liked. I purposefully didn&#x27;t link btw)<p>So, I do like the post, and I think it has good value (and certainly there is always value in teaching to learn!), but I disagree with the HN title and post&#x27;s subtitle.<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38834244">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38834244</a></div><br/><div id="38863749" class="c"><input type="checkbox" id="c-38863749" checked=""/><div class="controls bullet"><span class="by">thrtythreeforty</span><span>|</span><a href="#38861116">parent</a><span>|</span><a href="#38863628">next</a><span>|</span><label class="collapse" for="c-38863749">[-]</label><label class="expand" for="c-38863749">[1 more]</label></div><br/><div class="children"><div class="content">Can you link a resource that is able to adequately explain why they&#x27;re called Key, Query, and Value? Every explanation I&#x27;ve read eventually handwaved this. It feels like understanding why they&#x27;re named that is key (heh) to understanding the concept, rather than just blindly implementing matmul.</div><br/></div></div><div id="38863628" class="c"><input type="checkbox" id="c-38863628" checked=""/><div class="controls bullet"><span class="by">CanuckPro</span><span>|</span><a href="#38861116">parent</a><span>|</span><a href="#38863749">prev</a><span>|</span><a href="#38863663">next</a><span>|</span><label class="collapse" for="c-38863628">[-]</label><label class="expand" for="c-38863628">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Idk, are people interested in these things?<p>Yes, absolutely. Would be awesome to read deeper.</div><br/></div></div></div></div><div id="38863663" class="c"><input type="checkbox" id="c-38863663" checked=""/><div class="controls bullet"><span class="by">jongjong</span><span>|</span><a href="#38861116">prev</a><span>|</span><a href="#38861895">next</a><span>|</span><label class="collapse" for="c-38863663">[-]</label><label class="expand" for="c-38863663">[1 more]</label></div><br/><div class="children"><div class="content">As someone who has written an ANN from scratch and hasn&#x27;t used TensorFlow, I still find this description confusing.<p>I asked ChatGPT to explain how to modify a basic ANN to implement self-attention without using the terms Matrix or Vector and it gave me a really simple explanation. Though I haven&#x27;t tried to implement it yet.<p>I prefer to think of everything in terms of nodes, weights and layers. Matrices and vectors just makes it harder to relate to what&#x27;s happening in the ANN.<p>The way I&#x27;m used to writing ANNs, each input node is a scalar but the feed forward algorithm looks like vector-matrix multiplication since you multiply all the input nodes by the weights then sum them up... Anyway, I feel like I&#x27;m approaching these descriptions with the wrong mindset. Maybe I lack the necessary background.</div><br/></div></div><div id="38861895" class="c"><input type="checkbox" id="c-38861895" checked=""/><div class="controls bullet"><span class="by">Luechkt</span><span>|</span><a href="#38863663">prev</a><span>|</span><a href="#38861887">next</a><span>|</span><label class="collapse" for="c-38861895">[-]</label><label class="expand" for="c-38861895">[1 more]</label></div><br/><div class="children"><div class="content">I knew there was more than meets the eye.</div><br/></div></div><div id="38861887" class="c"><input type="checkbox" id="c-38861887" checked=""/><div class="controls bullet"><span class="by">bsenftner</span><span>|</span><a href="#38861895">prev</a><span>|</span><a href="#38860751">next</a><span>|</span><label class="collapse" for="c-38861887">[-]</label><label class="expand" for="c-38861887">[1 more]</label></div><br/><div class="children"><div class="content">Hard to <i>understand</i> when concepts are used without definition or introduction. The Encoder section just begins without any description of what it is or where is sets in an overall process. I grasp what the author is trying to do, but the post misses basic essay structures such as introducing ideas and explaining them before using them, rending the entire post confusing if one is not already a student and half understands the topic before reading.</div><br/></div></div><div id="38860751" class="c"><input type="checkbox" id="c-38860751" checked=""/><div class="controls bullet"><span class="by">adamnemecek</span><span>|</span><a href="#38861887">prev</a><span>|</span><a href="#38860386">next</a><span>|</span><label class="collapse" for="c-38860751">[-]</label><label class="expand" for="c-38860751">[2 more]</label></div><br/><div class="children"><div class="content">It’s a renormalization process. It can be modelled as a convolution in a Hopf algebra.</div><br/><div id="38862216" class="c"><input type="checkbox" id="c-38862216" checked=""/><div class="controls bullet"><span class="by">chpatrick</span><span>|</span><a href="#38860751">parent</a><span>|</span><a href="#38860386">next</a><span>|</span><label class="collapse" for="c-38862216">[-]</label><label class="expand" for="c-38862216">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s simple, monads are just monoids in the category of endofunctors...</div><br/></div></div></div></div><div id="38860386" class="c"><input type="checkbox" id="c-38860386" checked=""/><div class="controls bullet"><span class="by">nemo8551</span><span>|</span><a href="#38860751">prev</a><span>|</span><a href="#38860926">next</a><span>|</span><label class="collapse" for="c-38860386">[-]</label><label class="expand" for="c-38860386">[7 more]</label></div><br/><div class="children"><div class="content">There I was all excited to show off some of my electrical chops on HN.<p>Not today.</div><br/><div id="38860576" class="c"><input type="checkbox" id="c-38860576" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#38860386">parent</a><span>|</span><a href="#38862571">next</a><span>|</span><label class="collapse" for="c-38860576">[-]</label><label class="expand" for="c-38860576">[5 more]</label></div><br/><div class="children"><div class="content">Does mystified math lie beyond behind how the ratio of input and output voltages is equal to the ratio of the primary and secondary windings? Can it be derived from Maxwell&#x27;s equations?<p>Off to a search...</div><br/><div id="38860989" class="c"><input type="checkbox" id="c-38860989" checked=""/><div class="controls bullet"><span class="by">nihzm</span><span>|</span><a href="#38860386">root</a><span>|</span><a href="#38860576">parent</a><span>|</span><a href="#38860626">next</a><span>|</span><label class="collapse" for="c-38860989">[-]</label><label class="expand" for="c-38860989">[1 more]</label></div><br/><div class="children"><div class="content">Not really mystified in any sense of the word but for more precise calculations of circuit diagrams with transformers you can formulate a system of coupled ODEs which can be written in matrix form leading to the very nice mathematics of matrix differential equations.</div><br/></div></div><div id="38860626" class="c"><input type="checkbox" id="c-38860626" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#38860386">root</a><span>|</span><a href="#38860576">parent</a><span>|</span><a href="#38860989">prev</a><span>|</span><a href="#38862571">next</a><span>|</span><label class="collapse" for="c-38860626">[-]</label><label class="expand" for="c-38860626">[3 more]</label></div><br/><div class="children"><div class="content">I bet that an LLM (which uses transformers) can explain those aspects of a transformer to you.</div><br/><div id="38864651" class="c"><input type="checkbox" id="c-38864651" checked=""/><div class="controls bullet"><span class="by">nemo8551</span><span>|</span><a href="#38860386">root</a><span>|</span><a href="#38860626">parent</a><span>|</span><a href="#38861268">next</a><span>|</span><label class="collapse" for="c-38864651">[-]</label><label class="expand" for="c-38864651">[1 more]</label></div><br/><div class="children"><div class="content">I seen an LLM, or maybe another variant of “AI” [0] a while back that could aid design of electronic circuits by having a pool of data sheets added for referencing.<p>As you were querying specs for a board at component level it could give you a schematic, I think, with citations to the actual data sheets.<p>I suppose the same scale up could be used for systems that needed a varying number of specific power supplies.<p>[0] <a href="https:&#x2F;&#x2F;www.flux.ai&#x2F;p" rel="nofollow">https:&#x2F;&#x2F;www.flux.ai&#x2F;p</a></div><br/></div></div><div id="38861268" class="c"><input type="checkbox" id="c-38861268" checked=""/><div class="controls bullet"><span class="by">wardedVibe</span><span>|</span><a href="#38860386">root</a><span>|</span><a href="#38860626">parent</a><span>|</span><a href="#38864651">prev</a><span>|</span><a href="#38862571">next</a><span>|</span><label class="collapse" for="c-38861268">[-]</label><label class="expand" for="c-38861268">[1 more]</label></div><br/><div class="children"><div class="content">Or just read Wikipedia, which I&#x27;m sure it will crib from poorly... <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Transformer" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Transformer</a></div><br/></div></div></div></div></div></div></div></div><div id="38860926" class="c"><input type="checkbox" id="c-38860926" checked=""/><div class="controls bullet"><span class="by">naitgacem</span><span>|</span><a href="#38860386">prev</a><span>|</span><label class="collapse" for="c-38860926">[-]</label><label class="expand" for="c-38860926">[2 more]</label></div><br/><div class="children"><div class="content">Reading the title I thought this was about electrical transformers :p<p>Although this is HN but my background is still stronger.<p>And by the way, is it worth it to invest time to get some idea about this whole AI field? I&#x27;m from a compE background</div><br/><div id="38860978" class="c"><input type="checkbox" id="c-38860978" checked=""/><div class="controls bullet"><span class="by">dataking</span><span>|</span><a href="#38860926">parent</a><span>|</span><label class="collapse" for="c-38860978">[-]</label><label class="expand" for="c-38860978">[1 more]</label></div><br/><div class="children"><div class="content">&gt; is it worth it to invest time to get some idea about this whole AI field? I&#x27;m from a compE background<p>Might be worth thinking about how it will specifically affect your field of expertise. Jensen Huang says your job won&#x27;t be taken over by an AI but by a human using an AI.</div><br/></div></div></div></div></div></div></div></div></div></body></html>