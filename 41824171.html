<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728810068115" as="style"/><link rel="stylesheet" href="styles.css?v=1728810068115"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lifeiteng/OmniSenseVoice">Omni SenseVoice: High-Speed Speech Recognition with Words Timestamps</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>ringer007</span> | <span>16 comments</span></div><br/><div><div id="41824747" class="c"><input type="checkbox" id="c-41824747" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41825792">next</a><span>|</span><label class="collapse" for="c-41824747">[-]</label><label class="expand" for="c-41824747">[1 more]</label></div><br/><div class="children"><div class="content">Looks cool! Combine this with this new TTS that released today that looks really good and an LLM and you&#x27;d have a pretty good all-local voice assistant! <a href="https:&#x2F;&#x2F;github.com&#x2F;SWivid&#x2F;F5-TTS">https:&#x2F;&#x2F;github.com&#x2F;SWivid&#x2F;F5-TTS</a></div><br/></div></div><div id="41825792" class="c"><input type="checkbox" id="c-41825792" checked=""/><div class="controls bullet"><span class="by">steinvakt</span><span>|</span><a href="#41824747">prev</a><span>|</span><a href="#41824970">next</a><span>|</span><label class="collapse" for="c-41825792">[-]</label><label class="expand" for="c-41825792">[1 more]</label></div><br/><div class="children"><div class="content">How does the accuracy compare to Whisper?</div><br/></div></div><div id="41824970" class="c"><input type="checkbox" id="c-41824970" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#41825792">prev</a><span>|</span><a href="#41825133">next</a><span>|</span><label class="collapse" for="c-41824970">[-]</label><label class="expand" for="c-41824970">[8 more]</label></div><br/><div class="children"><div class="content">I’ve been building a production app on top of ASR and find the range of models kind of bewildering compared to LLMs and video. The commercial offerings seem to be custom or built on top of Whisper or maybe nvidia canary&#x2F;parakeet and then you have stuff like speechbrain that seems to run on top of lots of different open models for different tasks. Sometimes it’s genuinely hard to tell what’s a foundation model and what isn’t.<p>Separately, I wonder if this is the model Speechmatics uses.</div><br/><div id="41825570" class="c"><input type="checkbox" id="c-41825570" checked=""/><div class="controls bullet"><span class="by">woodson</span><span>|</span><a href="#41824970">parent</a><span>|</span><a href="#41825068">next</a><span>|</span><label class="collapse" for="c-41825570">[-]</label><label class="expand" for="c-41825570">[2 more]</label></div><br/><div class="children"><div class="content">There’s just not a single one-size-fits-all model&#x2F;pipeline. You choose the right one for the job, depending on whether you need streaming (i.e., low latency; words output right when they’re spoken), run on device (e.g. phone) or server, what languages&#x2F;dialects, conversational or more “produced” like a news broadcast or podcast, etc. Best way is to benchmark with data in your target domain.</div><br/><div id="41825711" class="c"><input type="checkbox" id="c-41825711" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#41824970">root</a><span>|</span><a href="#41825570">parent</a><span>|</span><a href="#41825068">next</a><span>|</span><label class="collapse" for="c-41825711">[-]</label><label class="expand" for="c-41825711">[1 more]</label></div><br/><div class="children"><div class="content">Sure, you&#x27;re just going to try lots of things and see what works best, but it&#x27;s confusing to be comparing things at such different levels of abstraction where a lot of the time you don&#x27;t even know what you&#x27;re comparing and it&#x27;s impossible to do apples-to-apples even on your own test data. If your need is &quot;speaker identification&quot;, you&#x27;re going to end up comparing commercial black boxes like Speechmatics (probably custom) vs commercial translucent boxes like Gladia (some custom blend of whisper + pyannote + etc) vs [asr_api]&#x2F;[some_specific_sepformer_model]. Like, I can observe that products I know to be built on top of whisper don&#x27;t seem to handle overlapping speaker diarization that well, but I don&#x27;t actually have any way of knowing if that&#x27;s got anything to do with whisper.</div><br/></div></div></div></div><div id="41825068" class="c"><input type="checkbox" id="c-41825068" checked=""/><div class="controls bullet"><span class="by">leetharris</span><span>|</span><a href="#41824970">parent</a><span>|</span><a href="#41825570">prev</a><span>|</span><a href="#41825133">next</a><span>|</span><label class="collapse" for="c-41825068">[-]</label><label class="expand" for="c-41825068">[5 more]</label></div><br/><div class="children"><div class="content">We released a new SOTA ASR as open source just a couple of weeks ago.  <a href="https:&#x2F;&#x2F;www.rev.com&#x2F;blog&#x2F;speech-to-text-technology&#x2F;introducing-reverb-open-source-asr-diarization" rel="nofollow">https:&#x2F;&#x2F;www.rev.com&#x2F;blog&#x2F;speech-to-text-technology&#x2F;introduci...</a><p>Take a look. We&#x27;ll be open sourcing more models very soon!</div><br/><div id="41825144" class="c"><input type="checkbox" id="c-41825144" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#41824970">root</a><span>|</span><a href="#41825068">parent</a><span>|</span><a href="#41825147">next</a><span>|</span><label class="collapse" for="c-41825144">[-]</label><label class="expand" for="c-41825144">[2 more]</label></div><br/><div class="children"><div class="content">&gt; These models are accessible under a non-commercial license.<p>That is not open source.</div><br/><div id="41825791" class="c"><input type="checkbox" id="c-41825791" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41824970">root</a><span>|</span><a href="#41825144">parent</a><span>|</span><a href="#41825147">next</a><span>|</span><label class="collapse" for="c-41825791">[-]</label><label class="expand" for="c-41825791">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. It is source available but not open source:<p><a href="https:&#x2F;&#x2F;opensource.org&#x2F;osd" rel="nofollow">https:&#x2F;&#x2F;opensource.org&#x2F;osd</a></div><br/></div></div></div></div><div id="41825147" class="c"><input type="checkbox" id="c-41825147" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#41824970">root</a><span>|</span><a href="#41825068">parent</a><span>|</span><a href="#41825144">prev</a><span>|</span><a href="#41825169">next</a><span>|</span><label class="collapse" for="c-41825147">[-]</label><label class="expand" for="c-41825147">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll check it out.<p>FWIW, in terms of benchmarking, I&#x27;m more interested in benchmarks against Gladia, Deepgram, Pyannote, and Speechmatics than whatever is built into the hyperscaler platforms. But I end up doing my own anyway so whatevs.<p>Also, you guys need any training data? I have &gt;10K hrs of conversational iso-audio :)</div><br/></div></div><div id="41825169" class="c"><input type="checkbox" id="c-41825169" checked=""/><div class="controls bullet"><span class="by">yalok</span><span>|</span><a href="#41824970">root</a><span>|</span><a href="#41825068">parent</a><span>|</span><a href="#41825147">prev</a><span>|</span><a href="#41825133">next</a><span>|</span><label class="collapse" for="c-41825169">[-]</label><label class="expand" for="c-41825169">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s great to hear! amazing performance of the model!<p>for voice chat bots, however, shorter input utterances are a norm (anywhere from 1-10 sec), with lots of silence in between, so this limitation is a bit sad:<p>&gt; On the Gigaspeech test suite, Rev’s research model is worse than other open-source models. The average segment length of this corpus is 5.7 seconds; these short segments are not a good match for the design of Rev’s model. These results demonstrate that despite its strong performance on long-form tests, Rev is not the best candidate for short-form recognition applications like voice search.</div><br/></div></div></div></div></div></div><div id="41825133" class="c"><input type="checkbox" id="c-41825133" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#41824970">prev</a><span>|</span><a href="#41825407">next</a><span>|</span><label class="collapse" for="c-41825133">[-]</label><label class="expand" for="c-41825133">[2 more]</label></div><br/><div class="children"><div class="content">Can it diarize?</div><br/><div id="41825401" class="c"><input type="checkbox" id="c-41825401" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#41825133">parent</a><span>|</span><a href="#41825407">next</a><span>|</span><label class="collapse" for="c-41825401">[-]</label><label class="expand" for="c-41825401">[1 more]</label></div><br/><div class="children"><div class="content">Apparently not. See <a href="https:&#x2F;&#x2F;github.com&#x2F;lifeiteng&#x2F;OmniSenseVoice&#x2F;blob&#x2F;main&#x2F;src&#x2F;omnisense&#x2F;models&#x2F;sensevoice.py">https:&#x2F;&#x2F;github.com&#x2F;lifeiteng&#x2F;OmniSenseVoice&#x2F;blob&#x2F;main&#x2F;src&#x2F;om...</a>. See also FunASR running SenseVoice but using Kaldi for speaker identification <a href="https:&#x2F;&#x2F;github.com&#x2F;modelscope&#x2F;FunASR&#x2F;blob&#x2F;cd684580991661b9a088361bea2d7f00735178d3&#x2F;funasr&#x2F;utils&#x2F;speaker_utils.py#L92">https:&#x2F;&#x2F;github.com&#x2F;modelscope&#x2F;FunASR&#x2F;blob&#x2F;cd684580991661b9a0...</a></div><br/></div></div></div></div><div id="41825407" class="c"><input type="checkbox" id="c-41825407" checked=""/><div class="controls bullet"><span class="by">deegles</span><span>|</span><a href="#41825133">prev</a><span>|</span><a href="#41825684">next</a><span>|</span><label class="collapse" for="c-41825407">[-]</label><label class="expand" for="c-41825407">[2 more]</label></div><br/><div class="children"><div class="content">Does it do diarization?</div><br/><div id="41825413" class="c"><input type="checkbox" id="c-41825413" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#41825407">parent</a><span>|</span><a href="#41825684">next</a><span>|</span><label class="collapse" for="c-41825413">[-]</label><label class="expand" for="c-41825413">[1 more]</label></div><br/><div class="children"><div class="content">Apparently not. See my reply to satvikpendem.</div><br/></div></div></div></div><div id="41825684" class="c"><input type="checkbox" id="c-41825684" checked=""/><div class="controls bullet"><span class="by">BLACK_hHOLE2729</span><span>|</span><a href="#41825407">prev</a><span>|</span><label class="collapse" for="c-41825684">[-]</label><label class="expand" for="c-41825684">[1 more]</label></div><br/><div class="children"><div class="content">T</div><br/></div></div></div></div></div></div></div></body></html>