<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722869859016" as="style"/><link rel="stylesheet" href="styles.css?v=1722869859016"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/2024/08/04/cortex-a73s-not-so-infinite-reordering-capacity/">Cortex A73&#x27;s Not-So-Infinite Reordering Capacity</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>ingve</span> | <span>32 comments</span></div><br/><div><div id="41157265" class="c"><input type="checkbox" id="c-41157265" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><label class="collapse" for="c-41157265">[-]</label><label class="expand" for="c-41157265">[31 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve recently been contemplating the idea of putting a small ALU with each register. Simplest would do just AND, OR, XOR. A bigger one might add and subtract. The idea is that any instruction that clobbered a source operand would only need one read port (and no write port) from the register file. As routing near registers gets more complicated it might make sense to put a bit of execution right there with the data.<p>Thoughts on this?</div><br/><div id="41160517" class="c"><input type="checkbox" id="c-41160517" checked=""/><div class="controls bullet"><span class="by">Tuna-Fish</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41160842">next</a><span>|</span><label class="collapse" for="c-41160517">[-]</label><label class="expand" for="c-41160517">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how registers work. Register names are not registers. Unless you are in the deepest of embedded, all operations that write to a register allocate a new one, and do not write to their input register.<p>edit: OoO primer, assuming x86_64 but everything else works the same way too:<p>Your cpu has hundreds of physical registers. There are 16 register names managed in the frontend. Whenever the frontend sees an instruction that writes to RAX, it allocates a fresh register that does not contain a value, sets it as pending, writes that register number under RAX in the register alias table (RAT), and sends the instruction forward. Once the instruction is in the scheduler, it waits until all it&#x27;s inputs are ready, and then issues to an execution unit. Once it gets executed, it writes it&#x27;s value to the register allocated for it and sets it as ready.<p>If you have an instruction that uses the same register name as input and output, those are guaranteed not to be the same register. Used registers get garbage collected once no name or pending instruction refers to them anymore.</div><br/></div></div><div id="41160842" class="c"><input type="checkbox" id="c-41160842" checked=""/><div class="controls bullet"><span class="by">peterfirefly</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41160517">prev</a><span>|</span><a href="#41157656">next</a><span>|</span><label class="collapse" for="c-41160842">[-]</label><label class="expand" for="c-41160842">[1 more]</label></div><br/><div class="children"><div class="content">Registers and ALUs are sort of already coupled like that in practice.<p>Longer, less wrong version: modern CPUs have forwarding networks with latches in them.  Those latches store ALU results.  Those results are (usually) the equivalent of the content-to-be of a specific version of a register -- and by register, I actually mean register name.<p>So, &quot;registers&quot; that are currently active get to live in the forwarding network where all the routing is and &quot;registers&quot; that aren&#x27;t as active get to live in the register file, away from the ALUs and the forwarding network.<p>(And the &quot;registers&quot; used in machine instructions are really just register <i>names</i>.  There&#x27;s a lot renaming going on in order to keep many versions (and potential versions) of register values live at the same time to enable superscalar execution and out-of-order execution.)</div><br/></div></div><div id="41157656" class="c"><input type="checkbox" id="c-41157656" checked=""/><div class="controls bullet"><span class="by">Findecanor</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41160842">prev</a><span>|</span><a href="#41157907">next</a><span>|</span><label class="collapse" for="c-41157656">[-]</label><label class="expand" for="c-41157656">[2 more]</label></div><br/><div class="children"><div class="content">I definitely think it is worth exploring other models than the traditional randomly accessed register file.<p>Your idea reminded me a bit of Scheduled Dataflow [0] architecture where every register is a dedicated input to a unit. Instead of an instruction having source and destination register parameters there are only destination registers.<p>The Mill does it the other way around: There are only source operands and the result is stored in each unit&#x27;s dedicated output register.<p>[0]. <a href="https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Scheduled-Dataflow%3A-Execution-Paradigm%2C-and-Kavi-Giorgi&#x2F;1250388ecf7d51ed97fb5da7b51af64c45553f8f" rel="nofollow">https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Scheduled-Dataflow%3A-...</a></div><br/><div id="41157767" class="c"><input type="checkbox" id="c-41157767" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41157656">parent</a><span>|</span><a href="#41157907">next</a><span>|</span><label class="collapse" for="c-41157767">[-]</label><label class="expand" for="c-41157767">[1 more]</label></div><br/><div class="children"><div class="content">The video where it&#x27;s revealed the belt in the Mill architecture is completely conceptual is something I randomly think of at night when trying to sleep. Always been fascinated by it.</div><br/></div></div></div></div><div id="41157907" class="c"><input type="checkbox" id="c-41157907" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41157656">prev</a><span>|</span><a href="#41158567">next</a><span>|</span><label class="collapse" for="c-41157907">[-]</label><label class="expand" for="c-41157907">[1 more]</label></div><br/><div class="children"><div class="content">A modern core has a bunch of resources (ALUs, register files and so on) to assign&#x2F;draw upon as dynamically needed.  Not every one is needed for every instruction of course.  In the old days when there was a single ALU, and maybe a single address calculator, that was that.<p>Now the resources can be scheduled in a very complex, out of order, and subinstruction fashion.  The chip designers guess what the instruction mix will likely be and hopefully make the right call as to how many Xs are required and how many Ys.  Too few and operations in flight will wait.  Too many and the chip becomes more complex for no benefit, and maybe those unused resources crowd out space for something else useful.<p>If you stick an ALU on every register you’re guaranteeing to use some area on something not used all the time.</div><br/></div></div><div id="41158567" class="c"><input type="checkbox" id="c-41158567" checked=""/><div class="controls bullet"><span class="by">ip26</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41157907">prev</a><span>|</span><a href="#41158000">next</a><span>|</span><label class="collapse" for="c-41158567">[-]</label><label class="expand" for="c-41158567">[1 more]</label></div><br/><div class="children"><div class="content">The entries in this register file would be larger &amp; slower, which means you will not be able to squeeze in as many. This reduces your performance.<p>Also, the hardware to distribute any entry as the second source to any other entry is effectively a read port, followed by a write port.</div><br/></div></div><div id="41158000" class="c"><input type="checkbox" id="c-41158000" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41158567">prev</a><span>|</span><a href="#41159742">next</a><span>|</span><label class="collapse" for="c-41158000">[-]</label><label class="expand" for="c-41158000">[1 more]</label></div><br/><div class="children"><div class="content">Onur Mutlu has a similar (definitely not same) idea of <i>Processing in Memory</i>. Basically the idea is to put some operations nearer to the data. Your idea is nearer to the register and his is in the memory controller nearer to memory.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2012.03112" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2012.03112</a></div><br/></div></div><div id="41159742" class="c"><input type="checkbox" id="c-41159742" checked=""/><div class="controls bullet"><span class="by">NohatCoder</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41158000">prev</a><span>|</span><a href="#41157575">next</a><span>|</span><label class="collapse" for="c-41159742">[-]</label><label class="expand" for="c-41159742">[1 more]</label></div><br/><div class="children"><div class="content">It is probably easier to add more functionality to existing ALUs. Various instruction sets have added &quot;free&quot; bonus operations, but one could go a step further and allow any two functions from a wide set to be combined, the intermediate value would not hit the registers, and thus save a store and a load relative to two individual instructions.</div><br/></div></div><div id="41157575" class="c"><input type="checkbox" id="c-41157575" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41159742">prev</a><span>|</span><a href="#41157529">next</a><span>|</span><label class="collapse" for="c-41157575">[-]</label><label class="expand" for="c-41157575">[3 more]</label></div><br/><div class="children"><div class="content">That breaks OoO users of the register before the operation.<p>Also, although the linked article complains about &quot;too many ports&quot;, remember that the useful size of the register file is ultimately limited by how many in-flight operations are possible, which is determined by pipeline depth and number of instructions between branches.</div><br/><div id="41157640" class="c"><input type="checkbox" id="c-41157640" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41157575">parent</a><span>|</span><a href="#41157529">next</a><span>|</span><label class="collapse" for="c-41157640">[-]</label><label class="expand" for="c-41157640">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; That breaks OoO users of the register before the operation.<p>How so? The register can be used the same as before but clobber operations don&#x27;t have to be sent over to a separate ALU and &quot;back&quot;.</div><br/><div id="41157662" class="c"><input type="checkbox" id="c-41157662" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41157640">parent</a><span>|</span><a href="#41157529">next</a><span>|</span><label class="collapse" for="c-41157662">[-]</label><label class="expand" for="c-41157662">[1 more]</label></div><br/><div class="children"><div class="content">If you have, say, &#x27;add r1, r2, r3; add r2, r2, 1&#x27; and want to do the latter instruction in-register-file, you can&#x27;t reorder them (e.g. if r2 is known before r3) as after having ran the second instruction the first ones r2 operand would be nowhere to be found. You&#x27;d need to track whether there&#x27;s any unfinished usages of each register (or maybe the simpler option of just tracking if it has been any operand), which isn&#x27;t traditionally required.<p>Perhaps a bigger issue is that, if you have a speculative decision (incl. all loads &amp; stores) between having written a register and the clobbering update, you can&#x27;t do it in-register too, as that&#x27;d make it impossible to rollback.</div><br/></div></div></div></div></div></div><div id="41157529" class="c"><input type="checkbox" id="c-41157529" checked=""/><div class="controls bullet"><span class="by">gen3</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41157575">prev</a><span>|</span><a href="#41158306">next</a><span>|</span><label class="collapse" for="c-41157529">[-]</label><label class="expand" for="c-41157529">[13 more]</label></div><br/><div class="children"><div class="content">It’s been a few years, but my understanding is that most time spent by the CPU is waiting for data, not logic. I wonder if there would be a real impact on execution speed</div><br/><div id="41158246" class="c"><input type="checkbox" id="c-41158246" checked=""/><div class="controls bullet"><span class="by">The_Colonel</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41157529">parent</a><span>|</span><a href="#41157629">next</a><span>|</span><label class="collapse" for="c-41158246">[-]</label><label class="expand" for="c-41158246">[11 more]</label></div><br/><div class="children"><div class="content">Most of the crazy parts of CPUs (out-of-order, speculative execution, branch predictors, cache hierarchy) are ways of trying to work around the slow memory. Improving the logic execution can allow going farther speculatively and thus pre-fetch sooner. Compressing instruction encoding can lower the need to fetch instructions.</div><br/><div id="41158512" class="c"><input type="checkbox" id="c-41158512" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158246">parent</a><span>|</span><a href="#41158651">next</a><span>|</span><label class="collapse" for="c-41158512">[-]</label><label class="expand" for="c-41158512">[6 more]</label></div><br/><div class="children"><div class="content">Most of those, except cache, are attempts to work around the bottleneck of single flow of control and thus limited available parallelism.</div><br/><div id="41158762" class="c"><input type="checkbox" id="c-41158762" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158512">parent</a><span>|</span><a href="#41159167">next</a><span>|</span><label class="collapse" for="c-41158762">[-]</label><label class="expand" for="c-41158762">[3 more]</label></div><br/><div class="children"><div class="content">Unfortunately all experience shows that both programmers and compilers are <i>much</i> worse at parallelizing code than CPUs are. There have been many attempts at architectures that allowed compilers or programmers to express code in more parallel ways (VLIW architectures, Intel&#x27;s Itanium, IBM&#x27;s Cell used in the PS3) and they all categorically failed.<p>Successful processors offer a sequential execution model, and handle the parallelism internally. Even CUDA is designed somewhat like this: you express your code in a largely linear fashion, and rely on the NVIDIA-created compiler and on the GPU itself to run it in parallel.</div><br/><div id="41159491" class="c"><input type="checkbox" id="c-41159491" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158762">parent</a><span>|</span><a href="#41159167">next</a><span>|</span><label class="collapse" for="c-41159491">[-]</label><label class="expand" for="c-41159491">[2 more]</label></div><br/><div class="children"><div class="content">CUDA is quite different. In CUDA you do not express parallel code in a linear fashion, a.k.a. sequential fashion, hoping that CUDA will determine the dependence chains and extract them from the sequential code and execute them in parallel.<p>The main feature of CUDA is that in order to describe an algorithm that is applied to an array, you just write the code that applies the algorithm to an element of that array, like writing only the body of a &quot;for&quot; loop.<p>Then the CUDA run-time will take care of creating an appropriate number of execution threads, taking into account the physical configuration of the available GPU, e.g. how many array elements can be processed by a single instruction, how many execution threads can share a single processing core, how many processing cores exist in the GPU, and so on. When there are more array elements than the GPU resources can process at once, CUDA will add some appropriate looping construct, to ensure the processing of the entire array.<p>The CUDA programmer writes the code that processes a single element array, informing thus the CUDA run-time that this code is independent of its replicas that process any other array element, except when the programmer references explicitly other array elements, which is normally avoided.<p>The task of a CPU able to do non-sequential instruction execution (a.k.a. out-of-order execution) and simultaneous initiation of multiple instructions (a.k.a. superscalar instruction execution) is quite different.<p>The main problem for such a CPU is the determination of the dependence relationships between instructions, based on examining the register numbers encoded in the instructions. Based on the detected dependencies and on the availability of the operands, the CPU can schedule the execution of the instructions, in parallel over multiple execution units.<p>There exists an open research problem, whether there is any better way to pass the information about the dependencies between instructions from the compiler, which already knows them, to the CPU that runs the machine code, otherwise than by using fake register numbers, whose purpose is only to express the dependencies, and which must be replaced for execution with the real numbers of the physical registers, by the renaming mechanism of the CPU.</div><br/><div id="41160330" class="c"><input type="checkbox" id="c-41160330" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41159491">parent</a><span>|</span><a href="#41159167">next</a><span>|</span><label class="collapse" for="c-41160330">[-]</label><label class="expand" for="c-41160330">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, CUDA is very different. But still, it&#x27;s another example where programmers just write sequential single flow of execution code, and it gets executed in parallel according to &quot;external&quot; rules.</div><br/></div></div></div></div></div></div><div id="41159167" class="c"><input type="checkbox" id="c-41159167" checked=""/><div class="controls bullet"><span class="by">The_Colonel</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158512">parent</a><span>|</span><a href="#41158762">prev</a><span>|</span><a href="#41158651">next</a><span>|</span><label class="collapse" for="c-41159167">[-]</label><label class="expand" for="c-41159167">[2 more]</label></div><br/><div class="children"><div class="content">Out-of-order execution doesn&#x27;t imply parallelism, it was designed from the beginning to work around the input data availability problem.<p>In speculative execution and branch predictors, prefetch may seem just as a nice bonus, but given that nowadays CPU performance is largely bottlenecked by memory access, prefetch resulting from these techniques will often come out as the dominant performance factor.</div><br/><div id="41160422" class="c"><input type="checkbox" id="c-41160422" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41159167">parent</a><span>|</span><a href="#41158651">next</a><span>|</span><label class="collapse" for="c-41160422">[-]</label><label class="expand" for="c-41160422">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still a form of parallelism, that could in principle be written into the program instead of being automatically implemented by the processor.<p>For example, in hand crafted assembly programs, it&#x27;s sometimes common to know how long a fetch operation lasts, and manually schedule operations such that they can be executed in parallel with the fetch operation.<p>Theoretically a high level language could also be designed to expose this kind of logic to the programmer. A program in such a language would be expressed as a set of very very short threads that can be interleaved by the compiler given precise knowledge of instruction timers.</div><br/></div></div></div></div></div></div><div id="41158651" class="c"><input type="checkbox" id="c-41158651" checked=""/><div class="controls bullet"><span class="by">_nalply</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158246">parent</a><span>|</span><a href="#41158512">prev</a><span>|</span><a href="#41157629">next</a><span>|</span><label class="collapse" for="c-41158651">[-]</label><label class="expand" for="c-41158651">[4 more]</label></div><br/><div class="children"><div class="content">Would it make sense to compress code and data with something like zstd and let the CPU decompress?<p>Of course this means a large change of how computers work but perhaps it is possible to make this opt-in (i.e. backwards compatible) for software?</div><br/><div id="41158793" class="c"><input type="checkbox" id="c-41158793" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158651">parent</a><span>|</span><a href="#41157629">next</a><span>|</span><label class="collapse" for="c-41158793">[-]</label><label class="expand" for="c-41158793">[3 more]</label></div><br/><div class="children"><div class="content">This would make memory read performance much, much more unpredictable, so it is a no-go from the start. And beyond that, the problem is not one of bandwidth, it is one of latency. This would increase bandwidth sometimes, but it would increase latency always, which is a terrible trade-off. Missed branch predictions would cost even more than they do today, for example.</div><br/><div id="41159057" class="c"><input type="checkbox" id="c-41159057" checked=""/><div class="controls bullet"><span class="by">The_Colonel</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158793">parent</a><span>|</span><a href="#41157629">next</a><span>|</span><label class="collapse" for="c-41159057">[-]</label><label class="expand" for="c-41159057">[2 more]</label></div><br/><div class="children"><div class="content">This idea isn&#x27;t about compressing in-flight, but in the instruction cache, so that more instructions will fit into the cache, and you don&#x27;t need to fetch as often (and thus incur latency) from main memory &#x2F; L2.<p>Zstd is impractical, but I can imagine some sort of storage efficient microcode? (current Intel CPUs store original x86 instructions in the L1 instruction cache).</div><br/><div id="41160059" class="c"><input type="checkbox" id="c-41160059" checked=""/><div class="controls bullet"><span class="by">simiones</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41159057">parent</a><span>|</span><a href="#41157629">next</a><span>|</span><label class="collapse" for="c-41160059">[-]</label><label class="expand" for="c-41160059">[1 more]</label></div><br/><div class="children"><div class="content">You then need extra memory to store the de-compressed instructions, since you can&#x27;t predict before running the decompression how many instructions you&#x27;ll get. And you still the problem of an unpredictably-sized instruction cache.<p>Plus, the larger the instruction cache is, the worse every branch mis-prediction is. As far as I know, the size of the instruction cache is not really limited because of space issues, it&#x27;s limited for precisely this reason.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41157629" class="c"><input type="checkbox" id="c-41157629" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41157529">parent</a><span>|</span><a href="#41158246">prev</a><span>|</span><a href="#41158306">next</a><span>|</span><label class="collapse" for="c-41157629">[-]</label><label class="expand" for="c-41157629">[1 more]</label></div><br/><div class="children"><div class="content">I wasn&#x27;t really thinking of faster execution speed overall. Just faster for a given number of ports on the register file. It may also eliminate the need for result forwarding hardware since the registers would just the ALU output latch.</div><br/></div></div></div></div><div id="41158306" class="c"><input type="checkbox" id="c-41158306" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#41157265">parent</a><span>|</span><a href="#41157529">prev</a><span>|</span><label class="collapse" for="c-41158306">[-]</label><label class="expand" for="c-41158306">[6 more]</label></div><br/><div class="children"><div class="content">Why stop there? Move the ALU to the RAM</div><br/><div id="41158394" class="c"><input type="checkbox" id="c-41158394" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158306">parent</a><span>|</span><a href="#41160493">next</a><span>|</span><label class="collapse" for="c-41158394">[-]</label><label class="expand" for="c-41158394">[1 more]</label></div><br/><div class="children"><div class="content">There are some proposals of that form: basically if you have a RAM interface that can support commands like &quot;fill this range of memory with this pattern&quot; or &quot;add this constant to all values in this range&quot; it can help speed up a decent amount of code, but also drastically reduce power consumption, as the memory interface is a pretty significant source of power drain on mobile systems. It does significantly complicate the interfaces involved, though, so it would require a lot of effort to implement.</div><br/></div></div><div id="41160493" class="c"><input type="checkbox" id="c-41160493" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158306">parent</a><span>|</span><a href="#41158394">prev</a><span>|</span><a href="#41159480">next</a><span>|</span><label class="collapse" for="c-41160493">[-]</label><label class="expand" for="c-41160493">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s already an x86-64 extension for this: RAO-INT (remote atomics).</div><br/></div></div><div id="41159480" class="c"><input type="checkbox" id="c-41159480" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158306">parent</a><span>|</span><a href="#41160493">prev</a><span>|</span><a href="#41158756">next</a><span>|</span><label class="collapse" for="c-41159480">[-]</label><label class="expand" for="c-41159480">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been doing the reverse and bringing the RAM to the ALU.</div><br/></div></div><div id="41158756" class="c"><input type="checkbox" id="c-41158756" checked=""/><div class="controls bullet"><span class="by">weinzierl</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158306">parent</a><span>|</span><a href="#41159480">prev</a><span>|</span><label class="collapse" for="c-41158756">[-]</label><label class="expand" for="c-41158756">[2 more]</label></div><br/><div class="children"><div class="content">This has been tried. I think the IBM System&#x2F;360 could do arithmetic directly in RAM.</div><br/><div id="41159446" class="c"><input type="checkbox" id="c-41159446" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41157265">root</a><span>|</span><a href="#41158756">parent</a><span>|</span><label class="collapse" for="c-41159446">[-]</label><label class="expand" for="c-41159446">[1 more]</label></div><br/><div class="children"><div class="content">err, any refs for that? I really doubt it but could well be wrong. I&#x27;m not aware of any mainstream arch that can&#x2F;could do that, that I can think of.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>