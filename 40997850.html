<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721379649402" as="style"/><link rel="stylesheet" href="styles.css?v=1721379649402"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/soupslurpr/Transcribro">Transcribro: On-device Accurate Speech-to-text</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>thebiblelover7</span> | <span>42 comments</span></div><br/><div><div id="40998961" class="c"><input type="checkbox" id="c-40998961" checked=""/><div class="controls bullet"><span class="by">james2doyle</span><span>|</span><a href="#41000911">next</a><span>|</span><label class="collapse" for="c-40998961">[-]</label><label class="expand" for="c-40998961">[12 more]</label></div><br/><div class="children"><div class="content">Looks similar to the new FUTO keyboard: <a href="https:&#x2F;&#x2F;voiceinput.futo.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;voiceinput.futo.org&#x2F;</a></div><br/><div id="40999143" class="c"><input type="checkbox" id="c-40999143" checked=""/><div class="controls bullet"><span class="by">iamjackg</span><span>|</span><a href="#40998961">parent</a><span>|</span><a href="#40999376">next</a><span>|</span><label class="collapse" for="c-40999143">[-]</label><label class="expand" for="c-40999143">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using this for a while (the voice input, not their keyboard) and it&#x27;s so refreshing to be able to just speak and have the output come out as fully formed, well punctuated sentences with proper capitalization.</div><br/><div id="40999578" class="c"><input type="checkbox" id="c-40999578" checked=""/><div class="controls bullet"><span class="by">james2doyle</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#40999143">parent</a><span>|</span><a href="#40999376">next</a><span>|</span><label class="collapse" for="c-40999578">[-]</label><label class="expand" for="c-40999578">[2 more]</label></div><br/><div class="children"><div class="content">I agree. No more &quot;speaking punctuation&quot;. Just talk as normal and it comes out fully formed</div><br/><div id="40999900" class="c"><input type="checkbox" id="c-40999900" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#40999578">parent</a><span>|</span><a href="#40999376">next</a><span>|</span><label class="collapse" for="c-40999900">[-]</label><label class="expand" for="c-40999900">[1 more]</label></div><br/><div class="children"><div class="content">I actually don&#x27;t mind speaking punctuation, in fact it kind of helps.  What I really hate is the middle-spot where we are right now, where it tries to place punctuation and sucks badly at it.</div><br/></div></div></div></div></div></div><div id="40999376" class="c"><input type="checkbox" id="c-40999376" checked=""/><div class="controls bullet"><span class="by">leobg</span><span>|</span><a href="#40998961">parent</a><span>|</span><a href="#40999143">prev</a><span>|</span><a href="#41000039">next</a><span>|</span><label class="collapse" for="c-40999376">[-]</label><label class="expand" for="c-40999376">[3 more]</label></div><br/><div class="children"><div class="content">Anything like that available for iOS?</div><br/><div id="41001378" class="c"><input type="checkbox" id="c-41001378" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#40999376">parent</a><span>|</span><a href="#41002685">next</a><span>|</span><label class="collapse" for="c-41001378">[-]</label><label class="expand" for="c-41001378">[1 more]</label></div><br/><div class="children"><div class="content">iOS already has on-device dictation built into the standard keyboard.<p>Years ago it got sent to the cloud, but as long as you have an iPhone from the past few years it&#x27;s on-device.</div><br/></div></div><div id="41002685" class="c"><input type="checkbox" id="c-41002685" checked=""/><div class="controls bullet"><span class="by">b33f</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#40999376">parent</a><span>|</span><a href="#41001378">prev</a><span>|</span><a href="#41000039">next</a><span>|</span><label class="collapse" for="c-41002685">[-]</label><label class="expand" for="c-41002685">[1 more]</label></div><br/><div class="children"><div class="content">Aiko is a free app for iOS and macOS that also uses whisper for local TTS</div><br/></div></div></div></div><div id="41000039" class="c"><input type="checkbox" id="c-41000039" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#40998961">parent</a><span>|</span><a href="#40999376">prev</a><span>|</span><a href="#41000911">next</a><span>|</span><label class="collapse" for="c-41000039">[-]</label><label class="expand" for="c-41000039">[5 more]</label></div><br/><div class="children"><div class="content">But open source, which is a pretty big difference</div><br/><div id="41000308" class="c"><input type="checkbox" id="c-41000308" checked=""/><div class="controls bullet"><span class="by">grandma_tea</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#41000039">parent</a><span>|</span><a href="#41000911">next</a><span>|</span><label class="collapse" for="c-41000308">[-]</label><label class="expand" for="c-41000308">[4 more]</label></div><br/><div class="children"><div class="content">FUTO and Transcribro are open source.</div><br/><div id="41000366" class="c"><input type="checkbox" id="c-41000366" checked=""/><div class="controls bullet"><span class="by">Humbly8967</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#41000308">parent</a><span>|</span><a href="#41000359">next</a><span>|</span><label class="collapse" for="c-41000366">[-]</label><label class="expand" for="c-41000366">[2 more]</label></div><br/><div class="children"><div class="content">No, FUTO made a new &quot;Source First License&quot;[1] that is not Open Source by the OSI definition.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;futo-org&#x2F;android-keyboard&#x2F;blob&#x2F;master&#x2F;LICENSE.md">https:&#x2F;&#x2F;github.com&#x2F;futo-org&#x2F;android-keyboard&#x2F;blob&#x2F;master&#x2F;LIC...</a></div><br/><div id="41001473" class="c"><input type="checkbox" id="c-41001473" checked=""/><div class="controls bullet"><span class="by">grandma_tea</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#41000366">parent</a><span>|</span><a href="#41000359">next</a><span>|</span><label class="collapse" for="c-41001473">[-]</label><label class="expand" for="c-41001473">[1 more]</label></div><br/><div class="children"><div class="content">Oh, that&#x27;s lame.</div><br/></div></div></div></div><div id="41000359" class="c"><input type="checkbox" id="c-41000359" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#40998961">root</a><span>|</span><a href="#41000308">parent</a><span>|</span><a href="#41000366">prev</a><span>|</span><a href="#41000911">next</a><span>|</span><label class="collapse" for="c-41000359">[-]</label><label class="expand" for="c-41000359">[1 more]</label></div><br/><div class="children"><div class="content">FUTO is not open source.<p><a href="https:&#x2F;&#x2F;gitlab.futo.org&#x2F;alex&#x2F;voiceinput&#x2F;-&#x2F;blob&#x2F;master&#x2F;LICENSE.md" rel="nofollow">https:&#x2F;&#x2F;gitlab.futo.org&#x2F;alex&#x2F;voiceinput&#x2F;-&#x2F;blob&#x2F;master&#x2F;LICENS...</a><p>&gt; FUTO Source First License 1.0<p>&gt; You may use or modify the software only for non-commercial purposes</div><br/></div></div></div></div></div></div></div></div><div id="41000911" class="c"><input type="checkbox" id="c-41000911" checked=""/><div class="controls bullet"><span class="by">yewenjie</span><span>|</span><a href="#40998961">prev</a><span>|</span><a href="#41000929">next</a><span>|</span><label class="collapse" for="c-41000911">[-]</label><label class="expand" for="c-41000911">[4 more]</label></div><br/><div class="children"><div class="content">Seems like Gboard is incompatible with it. Is there a good enough open source alternative to Gboard in 2024 that has smooth glide-typing and a similar layout?</div><br/><div id="41001131" class="c"><input type="checkbox" id="c-41001131" checked=""/><div class="controls bullet"><span class="by">SparkyMcUnicorn</span><span>|</span><a href="#41000911">parent</a><span>|</span><a href="#41000929">next</a><span>|</span><label class="collapse" for="c-41001131">[-]</label><label class="expand" for="c-41001131">[3 more]</label></div><br/><div class="children"><div class="content">Any of these should work.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;Helium314&#x2F;HeliBoard">https:&#x2F;&#x2F;github.com&#x2F;Helium314&#x2F;HeliBoard</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;openboard-team&#x2F;openboard">https:&#x2F;&#x2F;github.com&#x2F;openboard-team&#x2F;openboard</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;rkkr&#x2F;simple-keyboard">https:&#x2F;&#x2F;github.com&#x2F;rkkr&#x2F;simple-keyboard</a> (guessing, since AOSP Keyboard works and this is a fork)<p>Not open source: <a href="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;swiftkey" rel="nofollow">https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;swiftkey</a><p>Does not have glide&#x2F;swipe (reserved for symbols), but I just installed and giving it a shot: <a href="https:&#x2F;&#x2F;github.com&#x2F;Julow&#x2F;Unexpected-Keyboard">https:&#x2F;&#x2F;github.com&#x2F;Julow&#x2F;Unexpected-Keyboard</a></div><br/><div id="41003715" class="c"><input type="checkbox" id="c-41003715" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#41000911">root</a><span>|</span><a href="#41001131">parent</a><span>|</span><a href="#41002013">next</a><span>|</span><label class="collapse" for="c-41003715">[-]</label><label class="expand" for="c-41003715">[1 more]</label></div><br/><div class="children"><div class="content">My choice is <a href="https:&#x2F;&#x2F;github.com&#x2F;AnySoftKeyboard&#x2F;AnySoftKeyboard&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;AnySoftKeyboard&#x2F;AnySoftKeyboard&#x2F;</a><p>It does have glide typing, even.though I don&#x27;t use it.<p>It rather uses long-tap to access multiple symbols, and can be split or pushed to a corner on devices with a big screen.</div><br/></div></div><div id="41002013" class="c"><input type="checkbox" id="c-41002013" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#41000911">root</a><span>|</span><a href="#41001131">parent</a><span>|</span><a href="#41003715">prev</a><span>|</span><a href="#41000929">next</a><span>|</span><label class="collapse" for="c-41002013">[-]</label><label class="expand" for="c-41002013">[1 more]</label></div><br/><div class="children"><div class="content">Unexpected keyboard is unexpectedly awesome. Looks a bit dated, but boy does it have some functionality packed into it.</div><br/></div></div></div></div></div></div><div id="41000929" class="c"><input type="checkbox" id="c-41000929" checked=""/><div class="controls bullet"><span class="by">lawgimenez</span><span>|</span><a href="#41000911">prev</a><span>|</span><a href="#40998711">next</a><span>|</span><label class="collapse" for="c-41000929">[-]</label><label class="expand" for="c-41000929">[1 more]</label></div><br/><div class="children"><div class="content">This is cool, I get to read another Jetpack Compose codebase since I am halfway through migrating our app to Jetpack. So this helps a lot.</div><br/></div></div><div id="40998711" class="c"><input type="checkbox" id="c-40998711" checked=""/><div class="controls bullet"><span class="by">flax</span><span>|</span><a href="#41000929">prev</a><span>|</span><a href="#41002148">next</a><span>|</span><label class="collapse" for="c-40998711">[-]</label><label class="expand" for="c-40998711">[17 more]</label></div><br/><div class="children"><div class="content">Documentation severely lacking.  I wanted to know whether this does streaming or only batch, as well as examples for integrating with Android apps.</div><br/><div id="40998844" class="c"><input type="checkbox" id="c-40998844" checked=""/><div class="controls bullet"><span class="by">pants2</span><span>|</span><a href="#40998711">parent</a><span>|</span><a href="#41002148">next</a><span>|</span><label class="collapse" for="c-40998844">[-]</label><label class="expand" for="c-40998844">[16 more]</label></div><br/><div class="children"><div class="content">Considering it uses Whisper, it&#x27;s probably not streaming</div><br/><div id="40999140" class="c"><input type="checkbox" id="c-40999140" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40998844">parent</a><span>|</span><a href="#41002148">next</a><span>|</span><label class="collapse" for="c-40999140">[-]</label><label class="expand" for="c-40999140">[15 more]</label></div><br/><div class="children"><div class="content">I did some core work on TTS at Google, at several layers, and I&#x27;ve never quite understood what people mean by streaming vs. not.<p>In each and every case I&#x27;m familiar with, streaming means &quot;send the whole audio thus far to the inference engine, inference it, and send back the transcription&quot;<p>I have a Flutter library that does the same flow as this (though via ONNX, so I can cover all platforms), and Whisper + Silero is ~identical to the interfaces I used at Google.<p>If the idea is streaming is when each audio byte is only sent once to the server, there&#x27;s still an audio buffer accumulated -- its just on the server.</div><br/><div id="41000924" class="c"><input type="checkbox" id="c-41000924" checked=""/><div class="controls bullet"><span class="by">opprobium</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40999140">parent</a><span>|</span><a href="#40999161">next</a><span>|</span><label class="collapse" for="c-41000924">[-]</label><label class="expand" for="c-41000924">[8 more]</label></div><br/><div class="children"><div class="content">Streaming for TTS doesn&#x27;t matter but for speech to text it is more meaningful in interactive cases. In that case the user&#x27;s speech is arriving in real time and streaming can mean a couple levels of things:<p>- Overlap compute with the user speaking: Not having to wait until all the speech has been acquired can massively reduce latency at the end of speech and allow a larger model to be used. This doesn&#x27;t have to be the whole system, for instance an encoder can run in this fashion along audio as it comes in even if the final step of the system then runs in a non-streaming fashion.<p>- Produce partial results while the user is speaking: This can be just a UI nice to have, but it can also be much deeper, eg, a system can be activating on words or phrases in the input before the user is finished speaking which can dramatically change latency.<p>- Better segmentation: Whisper + Silero is just using VAD to make segments for Whisper, this is not at all the best you can do if you are actually decoding while you go. Looking at the results as you go allow you to make much better and faster segmentation decisions.</div><br/><div id="41001024" class="c"><input type="checkbox" id="c-41001024" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41000924">parent</a><span>|</span><a href="#40999161">next</a><span>|</span><label class="collapse" for="c-41001024">[-]</label><label class="expand" for="c-41001024">[7 more]</label></div><br/><div class="children"><div class="content">The only models that do what you&#x27;re poking at hostically are 4o (claimed) and that french company with the 7B one. They&#x27;re also bleeding edge, either unreleased or released and way wilder, ex. The french one interrupts too much, and screams back in an alien language occasionally.<p>Until these, you&#x27;d use echo cancellation to try and allow interruptible dialogue, and thats unsolved, you need a consistently cooperative chipset vendor for that (read: wasn&#x27;t possible even at scale, carrots, presumably sticks, and with nuch cajoling. So it works on iPhones consistently.)<p>The partial results are obtained by running inference on the entire audio so far, and silence is determined by VAD, on every stack I&#x27;ve seen that is described as streaming<p>I find it hard to believe that Google and Apple specifically, and every other audio stack I&#x27;ve seen, are choosing to do &quot;not the best they can at all&quot;</div><br/><div id="41001635" class="c"><input type="checkbox" id="c-41001635" checked=""/><div class="controls bullet"><span class="by">r2_pilot</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001024">parent</a><span>|</span><a href="#41001095">next</a><span>|</span><label class="collapse" for="c-41001635">[-]</label><label class="expand" for="c-41001635">[3 more]</label></div><br/><div class="children"><div class="content">Thank you for your insight. It confirms some of my suspicions working in this area (you wouldn&#x27;t happen to know anybody who makes anything more modern than the Respeaker  4-mic array?). My biggest problem is even with AEC, the voice output is triggering the VAD and so it continually thinks it&#x27;s getting interrupted by a human. My next attempt will be to try to only signal true VAD if there&#x27;s also sound coming from anywhere but behind, where the speaker is. It&#x27;s been an interesting challenge so far though.</div><br/><div id="41002966" class="c"><input type="checkbox" id="c-41002966" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001635">parent</a><span>|</span><a href="#41001934">next</a><span>|</span><label class="collapse" for="c-41002966">[-]</label><label class="expand" for="c-41002966">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not particularly experienced, but I did have good experiences with picovoice&#x27;s services. It&#x27;s a business specialised in programmatically available audio, tts, vad services etc.<p>They have a VAD that is trained on a 10 second clip of -your- voice, and it is then only activated by -your- voice. It works quite well in my experience, although it does add a little bit of additional latency before it starts detecting your voice (which is reasonably easy to overcome by keeping a 1s buffer of voice ready at all times. If the vad is active, just add the past 100-200ms of the buffer to the recorded audio. Works perfectly fine. It&#x27;s just that the UI showing &quot;voice detected&quot; or &quot;voice not detected&quot; might lag behind 100-200ms)<p>Source: I worked on a VAD + whisper + LLM demo project this year and ran into some VAD issues myself too.</div><br/></div></div><div id="41001934" class="c"><input type="checkbox" id="c-41001934" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001635">parent</a><span>|</span><a href="#41002966">prev</a><span>|</span><a href="#41001095">next</a><span>|</span><label class="collapse" for="c-41001934">[-]</label><label class="expand" for="c-41001934">[1 more]</label></div><br/><div class="children"><div class="content">Re: mic, alas, no, BigCo kinda sucked, I had to go way out of my way to get work on interesting stuff, it never mattered, and even when you did, you never got over the immediate wall of your own org, except for brief moments. i.e. never ever had anyone even close to knowing anything about the microphones we&#x27;d be using, they were shocked to hear what AEC was, even when what we were working on was a marketing tentpole for Pixel. Funny place.<p>I&#x27;m really glad you saw this. So, so, so much time and hope was wasted there on the Nth team of XX people saying &quot;how hard can it be? given physics and a lil ML, we can do $X&quot;, and inevitably reality was far more complicated, and it&#x27;s important to me to talk about it so other people get a sense it&#x27;s not them, it&#x27;s the problem. Even unlimited resources and your Nth fresh try can fail.<p>FWIW my mind&#x27;s been grinding on how I&#x27;d get my little Silero x Whisper gAssistant on device replica pulling off something akin to the gpt4o demo. I keep coming back to speaker ID: replace Silero with some newer models I&#x27;m seeing hit ONNX. Super handwave-y, but I can&#x27;t help thinking this does an end-around both AEC being shit on presumably most non-Apple devices, and poor interactions from trying to juggle two things operating differently (VAD and AEC). &quot;&quot;&quot;Just&quot;&quot;&quot; detect when there&#x27;s &gt;= 2 simultaneous speakers with &gt; 20% confidence --- of course, tons of bits missing from there, ideally you&#x27;d be resilient to ex. TV in background. Sigh. Tough problems.</div><br/></div></div></div></div><div id="41001095" class="c"><input type="checkbox" id="c-41001095" checked=""/><div class="controls bullet"><span class="by">opprobium</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001024">parent</a><span>|</span><a href="#41001635">prev</a><span>|</span><a href="#41001632">next</a><span>|</span><label class="collapse" for="c-41001095">[-]</label><label class="expand" for="c-41001095">[1 more]</label></div><br/><div class="children"><div class="content">This is exactly what Google ASR does. Give it a try and watch how the results flow back to you, it certainly is not waiting for VAD segment breaking. I should know.<p>Streaming used to be something people cared about more. VAD is always part of those systems as well, you want to use it to start segments and to hard cut-off, but it is just the starting off point. It&#x27;s kind of a big gap (to me) that&#x27;s missing in available models since Whisper came out, partly I think because it does add to the complexity of using the model, and latency has to be tuned&#x2F;traded-off with quality.</div><br/></div></div><div id="41001632" class="c"><input type="checkbox" id="c-41001632" checked=""/><div class="controls bullet"><span class="by">Nimitz14</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001024">parent</a><span>|</span><a href="#41001095">prev</a><span>|</span><a href="#40999161">next</a><span>|</span><label class="collapse" for="c-41001632">[-]</label><label class="expand" for="c-41001632">[2 more]</label></div><br/><div class="children"><div class="content">This is a complete non sequitur lol. FYI whisper is not a streaming model though it can, with some work, be adapted to be one.</div><br/><div id="41001905" class="c"><input type="checkbox" id="c-41001905" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41001632">parent</a><span>|</span><a href="#40999161">next</a><span>|</span><label class="collapse" for="c-41001905">[-]</label><label class="expand" for="c-41001905">[1 more]</label></div><br/><div class="children"><div class="content">You and I agree fully, then. IMHO it&#x27;s not too much work, at all, 400 LOC and someone else&#x27;s models. Of course, as in that old saw, the art is knowing exactly those models, knowing what ONNX is, etc. etc., that&#x27;s what makes it fast.<p>The non-sequitor is because I can&#x27;t feel out what&#x27;s going on from their perspective, the hedging left a huge range where they could have been saying &quot;I saw the gpt4o demo and theres another way that lets you have more natural conversation&quot; and &quot;hey think like an LSTM model, like Silero, there are voice recognizers that let you magically get a state and current transcription out&quot;, or in between, &quot;yeah in reality the models are f(audio bytes) =&gt; transcription&quot;, which appears to be closer to your position, given your &quot;it&#x27;s not a streaming model, though it can be adapted&quot;</div><br/></div></div></div></div></div></div></div></div><div id="40999161" class="c"><input type="checkbox" id="c-40999161" checked=""/><div class="controls bullet"><span class="by">iamjackg</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40999140">parent</a><span>|</span><a href="#41000924">prev</a><span>|</span><a href="#40999298">next</a><span>|</span><label class="collapse" for="c-40999161">[-]</label><label class="expand" for="c-40999161">[4 more]</label></div><br/><div class="children"><div class="content">I think in practical terms (at least for me):<p>- streaming == I talk and the text appears as I talk<p>- batched == I talk, and after I&#x27;m done talking some processing happens and the text gets populated</div><br/><div id="41000069" class="c"><input type="checkbox" id="c-41000069" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40999161">parent</a><span>|</span><a href="#40999298">next</a><span>|</span><label class="collapse" for="c-41000069">[-]</label><label class="expand" for="c-41000069">[3 more]</label></div><br/><div class="children"><div class="content">Gotcha, then, it&#x27;s &quot;not even wrong&quot; in the Pauli sense to say Whisper isn&#x27;t streaming</div><br/><div id="41000998" class="c"><input type="checkbox" id="c-41000998" checked=""/><div class="controls bullet"><span class="by">opprobium</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41000069">parent</a><span>|</span><a href="#40999298">next</a><span>|</span><label class="collapse" for="c-41000998">[-]</label><label class="expand" for="c-41000998">[2 more]</label></div><br/><div class="children"><div class="content">It is not streaming in the way people normally use this term. It&#x27;s a fuzzy notion but typically streaming means something encompassing:<p>- Processing and emitting results on something closer to word by word level
- Allowing partial results while the user is still speaking and mid-segment
- Not relying on an external segmenter to determine the chunking (and therefore also latency) of the output.</div><br/><div id="41001890" class="c"><input type="checkbox" id="c-41001890" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#41000998">parent</a><span>|</span><a href="#40999298">next</a><span>|</span><label class="collapse" for="c-41001890">[-]</label><label class="expand" for="c-41001890">[1 more]</label></div><br/><div class="children"><div class="content">This is fascinating because if your hint in another comment indicates you worked on this at Google, it&#x27;s entirely possible I have this all wrong because I&#x27;m missing the <i>actual ML</i> part - I wrote the client encoder &amp; server decoder for Opus and the client-side UI for the SODA launch, and I&#x27;m honestly really surprised to hear Google has different stuff. The client-side code loop AGSA used is 100% replicated, in my experience, by using Whisper.<p>I don&#x27;t want to make too strong of claims given NDAs (in reality, my failing memory :P) but I&#x27;m 99% sure inference on-device is just as fast as SODA. I don&#x27;t know what to say because I&#x27;m flummoxed, it makes sense to me that Whisper isn&#x27;t as good as SODA, and I don&#x27;t want to start banging the table about that its no different from a user or client perspective, I don&#x27;t think that&#x27;s fair. There&#x27;s a difference in model architecture and it matters. I think its at least a couple WER behind.<p>But then where&#x27;s the better STT solutions? Are all the obviously much better solutions really all locked up? Picovoice is the only closed solution I know of available for local dev, and per even them, it&#x27;s only better than the worst Whisper. Smallest is 70 MB in ONNX vs. 130 MB for next step up, both inference fine with ~600 ms latency from audio byte to mic to text on screen, ranging from WASM in web browser to 3 year old Android phone.</div><br/></div></div></div></div></div></div></div></div><div id="40999298" class="c"><input type="checkbox" id="c-40999298" checked=""/><div class="controls bullet"><span class="by">flax</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40999140">parent</a><span>|</span><a href="#40999161">prev</a><span>|</span><a href="#41002148">next</a><span>|</span><label class="collapse" for="c-40999298">[-]</label><label class="expand" for="c-40999298">[2 more]</label></div><br/><div class="children"><div class="content">&quot;streaming&quot; in this case is like another reply said: transcriptions appear as I talk.  Compared to not-streaming in which the service waits for silence, then processes the captured speech, then returns some transcription.<p>Is your Flutter library available?  And does it run locally?  I&#x27;m looking for a good Flutter streaming (in the sense above) speech recognition library.  vosk looks good, but it&#x27;s lacking some configurability such as selecting audio source.</div><br/><div id="40999560" class="c"><input type="checkbox" id="c-40999560" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40998711">root</a><span>|</span><a href="#40999298">parent</a><span>|</span><a href="#41002148">next</a><span>|</span><label class="collapse" for="c-40999560">[-]</label><label class="expand" for="c-40999560">[1 more]</label></div><br/><div class="children"><div class="content">FONNX, haven&#x27;t gone out of my way to make it trivial[1], but, it&#x27;s very good, battle tested on every single platform. (And yes runs locally)<p>[1] example app shows how to do everything, there&#x27;s basic doc, but man the amount of nonsense you need to know to pull it all together is just too hard to document without a specific Q. Do feel free to file an issue</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41002148" class="c"><input type="checkbox" id="c-41002148" checked=""/><div class="controls bullet"><span class="by">tmaly</span><span>|</span><a href="#40998711">prev</a><span>|</span><a href="#40998672">next</a><span>|</span><label class="collapse" for="c-41002148">[-]</label><label class="expand" for="c-41002148">[3 more]</label></div><br/><div class="children"><div class="content">I wish there was something where I could transcribe iPhone voice memos to text.<p>I would pay for an app that did this.</div><br/><div id="41002549" class="c"><input type="checkbox" id="c-41002549" checked=""/><div class="controls bullet"><span class="by">cee_el123</span><span>|</span><a href="#41002148">parent</a><span>|</span><a href="#41002231">next</a><span>|</span><label class="collapse" for="c-41002549">[-]</label><label class="expand" for="c-41002549">[1 more]</label></div><br/><div class="children"><div class="content">Google has an app called live transcribe on Android but there&#x27;s no iPhone version<p>This is an unaffiliated version looks like
<a href="https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;live-transcribe&#x2F;id1471473738" rel="nofollow">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;live-transcribe&#x2F;id1471473738</a></div><br/></div></div><div id="41002231" class="c"><input type="checkbox" id="c-41002231" checked=""/><div class="controls bullet"><span class="by">hidelooktropic</span><span>|</span><a href="#41002148">parent</a><span>|</span><a href="#41002549">prev</a><span>|</span><a href="#40998672">next</a><span>|</span><label class="collapse" for="c-41002231">[-]</label><label class="expand" for="c-41002231">[1 more]</label></div><br/><div class="children"><div class="content">The microphone icon on the keyboard does this.</div><br/></div></div></div></div><div id="40998672" class="c"><input type="checkbox" id="c-40998672" checked=""/><div class="controls bullet"><span class="by">crancher</span><span>|</span><a href="#41002148">prev</a><span>|</span><label class="collapse" for="c-40998672">[-]</label><label class="expand" for="c-40998672">[4 more]</label></div><br/><div class="children"><div class="content">Accrescent hype is comically overdone.</div><br/><div id="40999534" class="c"><input type="checkbox" id="c-40999534" checked=""/><div class="controls bullet"><span class="by">free_bip</span><span>|</span><a href="#40998672">parent</a><span>|</span><a href="#41002832">next</a><span>|</span><label class="collapse" for="c-40999534">[-]</label><label class="expand" for="c-40999534">[1 more]</label></div><br/><div class="children"><div class="content">I looked in the GitHub issues and there&#x27;s a closed issue for F-droid inclusion. The author states that F-droid &quot;Doesn&#x27;t meet their requirements&quot; but doesn&#x27;t elaborate. I wonder what F-droid is missing that they need so much?</div><br/></div></div><div id="41002832" class="c"><input type="checkbox" id="c-41002832" checked=""/><div class="controls bullet"><span class="by">mijoharas</span><span>|</span><a href="#40998672">parent</a><span>|</span><a href="#40999534">prev</a><span>|</span><a href="#40998776">next</a><span>|</span><label class="collapse" for="c-41002832">[-]</label><label class="expand" for="c-41002832">[1 more]</label></div><br/><div class="children"><div class="content">I only just saw it from this project.<p>I see the features listed[0] which seems like a reasonable feature set, but nothing unusual afaict.<p>If there has been a lot of hype can you tell me what people find compelling about it?<p>[0] <a href="https:&#x2F;&#x2F;accrescent.app&#x2F;" rel="nofollow">https:&#x2F;&#x2F;accrescent.app&#x2F;</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>