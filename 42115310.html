<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731488470162" as="style"/><link rel="stylesheet" href="styles.css?v=1731488470162"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://aidantr.github.io/files/AI_innovation.pdf">Artificial Intelligence, Scientific Discovery, and Product Innovation [pdf]</a> <span class="domain">(<a href="https://aidantr.github.io">aidantr.github.io</a>)</span></div><div class="subtext"><span>therabbithole</span> | <span>34 comments</span></div><br/><div><div id="42117134" class="c"><input type="checkbox" id="c-42117134" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#42117168">next</a><span>|</span><label class="collapse" for="c-42117134">[-]</label><label class="expand" for="c-42117134">[19 more]</label></div><br/><div class="children"><div class="content">From the conclusions:<p>&gt; I find that AI substantially boosts materials discovery, leading to an increase in patent filing and a rise in downstream product innovation. However, the technology is effective only when paired with sufficiently skilled scientists.<p>I can see the point here. Today I was exploring the possibility of some new algorithm. I asked Claude to generate some part which is well know (but there are not a lot of examples on the internet) and it hallucinated some function. In spite of being bad, it was sufficiently close to the solution that I could myself &quot;rehallucinate it&quot; from my side, and turn it into a creative solution. Of course, the hallucination would have been useless if I was not already an expert in the field.</div><br/><div id="42120694" class="c"><input type="checkbox" id="c-42120694" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42118622">next</a><span>|</span><label class="collapse" for="c-42120694">[-]</label><label class="expand" for="c-42120694">[2 more]</label></div><br/><div class="children"><div class="content">I came to the same conclusion a while back. LLMs are very useful when user expertise level is medium to high, and task complexity is low to medium. Why ? because it those scenarios, the user can use the LLM as a tool for brainstorming on drawing the first sketch before improving it. Human in the loop is the key and will stay key for the forceable future no matter what the autonomous AI agent gurus are saying.
<a href="https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;mistral-ai-strategy-openai" rel="nofollow">https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;mistral-ai-strategy-openai</a></div><br/><div id="42123178" class="c"><input type="checkbox" id="c-42123178" checked=""/><div class="controls bullet"><span class="by">euroderf</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42120694">parent</a><span>|</span><a href="#42118622">next</a><span>|</span><label class="collapse" for="c-42123178">[-]</label><label class="expand" for="c-42123178">[1 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s not so much an &quot;artificial intelligence&quot; as it is an &quot;intelligence amplifier&quot;, with the usual amplifier feedback loop.</div><br/></div></div></div></div><div id="42118622" class="c"><input type="checkbox" id="c-42118622" checked=""/><div class="controls bullet"><span class="by">vatys</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42120694">prev</a><span>|</span><a href="#42118820">next</a><span>|</span><label class="collapse" for="c-42118622">[-]</label><label class="expand" for="c-42118622">[6 more]</label></div><br/><div class="children"><div class="content">I wonder if the next generation of experts will be held back by use of AI tools.  Having learned things “the hard way” without AI tools may allow better judgement of these semi-reliable outputs.  A younger generation growing up in this era would not yet have that experience and may be more accepting of AI generated results.</div><br/><div id="42123613" class="c"><input type="checkbox" id="c-42123613" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118622">parent</a><span>|</span><a href="#42119693">next</a><span>|</span><label class="collapse" for="c-42123613">[-]</label><label class="expand" for="c-42123613">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Having learned things “the hard way” without AI tools may allow better judgement<p>I see a parallel in how web search replaced other skills like finding information in physical libraries. We might not do research the old way, but we learned new tricks for the new tools. We know when to rely on them and how much, how to tell useful from garbage. We don&#x27;t write by hand much, do computation in our heads much, but we type and compute more.</div><br/></div></div><div id="42119693" class="c"><input type="checkbox" id="c-42119693" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118622">parent</a><span>|</span><a href="#42123613">prev</a><span>|</span><a href="#42119255">next</a><span>|</span><label class="collapse" for="c-42119693">[-]</label><label class="expand" for="c-42119693">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure people said the same thing about compilers.<p>That&#x27;s how progress works. Clever people will still be clever, but maybe about slightly different things.</div><br/></div></div><div id="42119255" class="c"><input type="checkbox" id="c-42119255" checked=""/><div class="controls bullet"><span class="by">mkatx</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118622">parent</a><span>|</span><a href="#42119693">prev</a><span>|</span><a href="#42118820">next</a><span>|</span><label class="collapse" for="c-42119255">[-]</label><label class="expand" for="c-42119255">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, as a cs student, some professors allow use of LLM&#x27;s because it is what will be a part of the job going forward. I get that, and I use them for learning, as opposed to internet searches, but I still manually write my code and fully understand it, cause I don&#x27;t wanna miss out on those lessons. Otherwise I might not be able to verify an LLM&#x27;s output.</div><br/><div id="42120021" class="c"><input type="checkbox" id="c-42120021" checked=""/><div class="controls bullet"><span class="by">daveguy</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42119255">parent</a><span>|</span><a href="#42118820">next</a><span>|</span><label class="collapse" for="c-42120021">[-]</label><label class="expand" for="c-42120021">[2 more]</label></div><br/><div class="children"><div class="content">Excellent approach. You will be leagues ahead of someone who relies on LLM alone.</div><br/><div id="42121188" class="c"><input type="checkbox" id="c-42121188" checked=""/><div class="controls bullet"><span class="by">mkatx</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42120021">parent</a><span>|</span><a href="#42118820">next</a><span>|</span><label class="collapse" for="c-42121188">[-]</label><label class="expand" for="c-42121188">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. My favorite professor this semester constantly says &quot;hey, if you rely to much on the robot, and can&#x27;t do this yourself, you won&#x27;t get a job.&quot; I know some people are just here for the paper, but that makes me feel better when I&#x27;m having a hard time finding a new role..</div><br/></div></div></div></div></div></div></div></div><div id="42118820" class="c"><input type="checkbox" id="c-42118820" checked=""/><div class="controls bullet"><span class="by">prisenco</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42118622">prev</a><span>|</span><a href="#42117821">next</a><span>|</span><label class="collapse" for="c-42118820">[-]</label><label class="expand" for="c-42118820">[6 more]</label></div><br/><div class="children"><div class="content">I call this the &quot;babysitting problem.&quot;<p>If a model is right 99.99% of the time (which nobody has come close to), we still need something that understands what it&#x27;s doing enough to observe and catch that 0.01% where it&#x27;s wrong.<p>Because wrong at that level is often <i>dangerously</i> wrong.<p>This is explored (in an earlier context) in the 1983 paper &quot;Ironies of Automation&quot;.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ironies_of_Automation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ironies_of_Automation</a></div><br/><div id="42119793" class="c"><input type="checkbox" id="c-42119793" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118820">parent</a><span>|</span><a href="#42118890">next</a><span>|</span><label class="collapse" for="c-42119793">[-]</label><label class="expand" for="c-42119793">[3 more]</label></div><br/><div class="children"><div class="content">&gt; we still need something that understands what it&#x27;s doing enough to observe and catch that 0.01% where it&#x27;s wrong.<p>Nobody has figured out how to get a confidence metric out of the innards of a neural net. This is why chatbots seldom say &quot;I don&#x27;t know&quot;, but, instead, hallucinate something plausible.<p>Most of the attempts to fix this are hacks outside the LLM. Run several copies and compare. Ask for citations and check them.
Throw in more training data. Punish for wrong answers. None of those hacks work very well. The black box part is still not understood.<p>This is the elephant in the room of LLMs. If someone doesn&#x27;t crack this soon, AI Winter #3 will begin. There&#x27;s a lot of startup valuation which assumes this problem gets solved.</div><br/><div id="42120635" class="c"><input type="checkbox" id="c-42120635" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42119793">parent</a><span>|</span><a href="#42118890">next</a><span>|</span><label class="collapse" for="c-42120635">[-]</label><label class="expand" for="c-42120635">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  There&#x27;s a lot of startup valuation which assumes this problem gets solved.<p>Not just solved, but solved <i>soon.</i> I think this is an extremely difficult problem to solve to the point it&#x27;d involve new aspects of computer science to even approach correctly, but we seem to just think throwing more CPU and $$$ at the problem will work itself out. I myself am skeptical.</div><br/><div id="42120933" class="c"><input type="checkbox" id="c-42120933" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42120635">parent</a><span>|</span><a href="#42118890">next</a><span>|</span><label class="collapse" for="c-42120933">[-]</label><label class="expand" for="c-42120933">[1 more]</label></div><br/><div class="children"><div class="content">Is there any progress? About two years ago, there were people training neural nets to play games, looking for a representation of the game state inside the net, and claiming to find it. That doesn&#x27;t seem to be mentioned any more.<p>As for &quot;solved <i>soon</i>&quot;, the market can remain irrational longer than you can stay solvent. Look at Uber and Tesla, both counting on some kind of miracle to justify their market cap.</div><br/></div></div></div></div></div></div><div id="42118890" class="c"><input type="checkbox" id="c-42118890" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118820">parent</a><span>|</span><a href="#42119793">prev</a><span>|</span><a href="#42117821">next</a><span>|</span><label class="collapse" for="c-42118890">[-]</label><label class="expand" for="c-42118890">[2 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure humans make mistakes too and it happens rather frequently that nobody catches them until it’s too late. In most fields we’re okay with that because perfection is prohibitively expensive.</div><br/><div id="42118968" class="c"><input type="checkbox" id="c-42118968" checked=""/><div class="controls bullet"><span class="by">prisenco</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42118890">parent</a><span>|</span><a href="#42117821">next</a><span>|</span><label class="collapse" for="c-42118968">[-]</label><label class="expand" for="c-42118968">[1 more]</label></div><br/><div class="children"><div class="content">Obviously systems have always had to be resilient. But the point here is how dangerous a &quot;set it and forget it&quot; AI can be. Because the mistakes it makes, although fewer, are much more dangerous, unpredictable, and inscrutable than the mistakes a human would make.<p>Which means the people who catch these mistakes have to be operating at a very high level.<p>This means we need to resist getting lulled into a false sense of security with these systems, and we need to make sure we can still get people to a high level of experience and education.</div><br/></div></div></div></div></div></div><div id="42117821" class="c"><input type="checkbox" id="c-42117821" checked=""/><div class="controls bullet"><span class="by">darepublic</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42118820">prev</a><span>|</span><a href="#42121545">next</a><span>|</span><label class="collapse" for="c-42117821">[-]</label><label class="expand" for="c-42117821">[2 more]</label></div><br/><div class="children"><div class="content">I find proofreading the code gen ai less satisfying than writing it myself though it does depend on the nature of the function.  Migrating mindless mapping type functions to autocomplete is nice</div><br/><div id="42119303" class="c"><input type="checkbox" id="c-42119303" checked=""/><div class="controls bullet"><span class="by">mkatx</span><span>|</span><a href="#42117134">root</a><span>|</span><a href="#42117821">parent</a><span>|</span><a href="#42121545">next</a><span>|</span><label class="collapse" for="c-42119303">[-]</label><label class="expand" for="c-42119303">[1 more]</label></div><br/><div class="children"><div class="content">This is one big point I&#x27;ve subscribed to, I&#x27;d rather write the code and understand it that way, than read and try to understand code I did not write.<p>Also, I think it would be faster to write my own than try to fully understand others (LLM) code. I have developed my own ways of ensuring certain aspects of the code, like security, organization, and speed. Trying to knead out how those things are addressed in code I didn&#x27;t write takes me longer.<p>Edit; spelling</div><br/></div></div></div></div><div id="42121545" class="c"><input type="checkbox" id="c-42121545" checked=""/><div class="controls bullet"><span class="by">zeeshanm</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42117821">prev</a><span>|</span><a href="#42123095">next</a><span>|</span><label class="collapse" for="c-42121545">[-]</label><label class="expand" for="c-42121545">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I have experienced it, too. I was building a web crawler using Replit as an agent. I could have done that in 2 hours without LLM help but I wanted to see how the LLM would do it. I gave it a set of of instructions but the LLM could not execute on it. It later choose an alternative path but that also did not yield. I then gave an exact list of steps. Results were slightly better but not what I was expecting. Overall, it&#x27;s good to get something going but you still have to hold hands. It is not the best but also not the worst experience.</div><br/></div></div><div id="42123095" class="c"><input type="checkbox" id="c-42123095" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#42117134">parent</a><span>|</span><a href="#42121545">prev</a><span>|</span><a href="#42117168">next</a><span>|</span><label class="collapse" for="c-42123095">[-]</label><label class="expand" for="c-42123095">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I had similar experience where I ask why a bug was happening but it gave me some thing that looked wrong, but upon closer inspection it pointed to a vague general direction where I haven’t thought of and i solved my bug with its help.   The caveat is you still need to know your shit to decipher&#x2F;recognize it.</div><br/></div></div></div></div><div id="42117168" class="c"><input type="checkbox" id="c-42117168" checked=""/><div class="controls bullet"><span class="by">slopeloaf</span><span>|</span><a href="#42117134">prev</a><span>|</span><a href="#42119352">next</a><span>|</span><label class="collapse" for="c-42117168">[-]</label><label class="expand" for="c-42117168">[6 more]</label></div><br/><div class="children"><div class="content">“<i>Survey evidence
reveals that these gains come at a cost, however, as 82% of scientists report reduced
satisfaction with their work due to decreased creativity and skill underutilization.</i>”<p>What an interesting finding and not what I was expecting. Is this an issue with the UX&#x2F;tooling? Could we alleviate this with an interface that still incorporates the joy of problem solving.<p>I haven’t seen any research that Copilot and similar tools for programmers have a similar  reduction in satisfaction. Likely with how much the tools feel like an extension of traditional auto complete, and you still spend a lot of time “programming”. You haven’t abandoned your core skill.<p>Related: I often find myself disabling copilot when I have a fun problem I want the satisfaction of solving myself.</div><br/><div id="42118720" class="c"><input type="checkbox" id="c-42118720" checked=""/><div class="controls bullet"><span class="by">dennisy</span><span>|</span><a href="#42117168">parent</a><span>|</span><a href="#42118238">next</a><span>|</span><label class="collapse" for="c-42118720">[-]</label><label class="expand" for="c-42118720">[3 more]</label></div><br/><div class="children"><div class="content">I feel if people are finding programming as creative and interesting with AI as without there is a chance they actually prefer product management?<p>Half statement, half question… I have personally stopped using AI assistance in programming as I felt it was making my mind lazy, and I stopped learning.</div><br/><div id="42118914" class="c"><input type="checkbox" id="c-42118914" checked=""/><div class="controls bullet"><span class="by">aerhardt</span><span>|</span><a href="#42117168">root</a><span>|</span><a href="#42118720">parent</a><span>|</span><a href="#42119124">next</a><span>|</span><label class="collapse" for="c-42118914">[-]</label><label class="expand" for="c-42118914">[1 more]</label></div><br/><div class="children"><div class="content">The thing I like the most about AI coding is how it lowers the threshold of energy and motivation needed to start a task. Being able to write a detailed spec of what I want, or even discussing an attack plan (for high-level architecture or solution design) and getting an initial draft is game-changing for me. I usually take it from there, because as far as I can tell, it sucks after that point anyway.</div><br/></div></div><div id="42119124" class="c"><input type="checkbox" id="c-42119124" checked=""/><div class="controls bullet"><span class="by">rwyinuse</span><span>|</span><a href="#42117168">root</a><span>|</span><a href="#42118720">parent</a><span>|</span><a href="#42118914">prev</a><span>|</span><a href="#42118238">next</a><span>|</span><label class="collapse" for="c-42119124">[-]</label><label class="expand" for="c-42119124">[1 more]</label></div><br/><div class="children"><div class="content">As a programmer I feel that software development as in &quot;designing and building software products&quot; can be still be fun with AI. But what absolutely isn&#x27;t fun is feeding requirements written by someone else to ChatGPT &#x2F; Copilot and then just doing plumbing &#x2F; QA work to make sure it works. The kind of work junior devs would typically do feels devalued now.</div><br/></div></div></div></div><div id="42118238" class="c"><input type="checkbox" id="c-42118238" checked=""/><div class="controls bullet"><span class="by">gmaster1440</span><span>|</span><a href="#42117168">parent</a><span>|</span><a href="#42118720">prev</a><span>|</span><a href="#42118403">next</a><span>|</span><label class="collapse" for="c-42118238">[-]</label><label class="expand" for="c-42118238">[1 more]</label></div><br/><div class="children"><div class="content">AI appears to have automated aspects of the job scientists found most intellectually satisfying.<p>- Reduced creativity and ideation work (dropping from 39% to 16% of time)<p>- Increased focus on evaluating AI suggestions (rising to 40% of time)<p>- Feelings of skill underutilization</div><br/></div></div><div id="42118403" class="c"><input type="checkbox" id="c-42118403" checked=""/><div class="controls bullet"><span class="by">sourcepluck</span><span>|</span><a href="#42117168">parent</a><span>|</span><a href="#42118238">prev</a><span>|</span><a href="#42119352">next</a><span>|</span><label class="collapse" for="c-42118403">[-]</label><label class="expand" for="c-42118403">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Related: I often find myself disabling copilot when I have a fun problem I want the satisfaction of solving myself.<p>The way things seem to be going, I&#x27;d be worried management will find a way to monitor and try cut out this &quot;security risk&quot; in the coming months and years.</div><br/></div></div></div></div><div id="42119352" class="c"><input type="checkbox" id="c-42119352" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42117168">prev</a><span>|</span><a href="#42117649">next</a><span>|</span><label class="collapse" for="c-42119352">[-]</label><label class="expand" for="c-42119352">[1 more]</label></div><br/><div class="children"><div class="content"><i>&quot;The tool automates a majority of “idea
generation” tasks, reallocating scientists to the new task of evaluating model-suggested candidate
compounds. In the absence of AI, researchers devote nearly half their time to conceptualizing
potential materials. This falls to less than 16% after the tool’s introduction. Meanwhile, time spent
assessing candidate materials increases by 74%&quot;</i><p>So the AI is in charge, and mostly needs a bunch of lab assistants.<p><i>&quot;Machines should think. People should work.&quot;</i> - not a joke any more.</div><br/></div></div><div id="42117649" class="c"><input type="checkbox" id="c-42117649" checked=""/><div class="controls bullet"><span class="by">uxhacker</span><span>|</span><a href="#42119352">prev</a><span>|</span><a href="#42118340">next</a><span>|</span><label class="collapse" for="c-42117649">[-]</label><label class="expand" for="c-42117649">[2 more]</label></div><br/><div class="children"><div class="content">It’s interesting to see how this research emphasizes the continued need for human expertise, even in the era of advanced AI. It highlights that while AI can significantly boost productivity, the value of human judgment and domain knowledge remains crucial.</div><br/><div id="42118128" class="c"><input type="checkbox" id="c-42118128" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#42117649">parent</a><span>|</span><a href="#42118340">next</a><span>|</span><label class="collapse" for="c-42118128">[-]</label><label class="expand" for="c-42118128">[1 more]</label></div><br/><div class="children"><div class="content">Even Warren McCulloch and Walter Pitts were the two who originally modeled neurons with OR statements, realized it wasn&#x27;t sufficient for a full replacement.<p>Biological neurons have many features like active dendritic compartmentalization that perceptrons cannot duplicate.<p>They are different with different advantages and limitations.<p>We have also known about the specification and frame problems for a long time also.<p>Note that part of the reason for the split between the symbolic camp and statistical camp in the 90s was due to more practical models being possible with existential quantification.<p>There have been several papers on HN talking about a shift to universal quantification to get around limitations lately.<p>Unfortunately discussions about the limits of first order logic have historical challenges and adding in the limits of fragments of first order logic like grounding are compounded upon those challenges with cognitive dissonance.<p>While understanding the abilities of multi level perceptrons is challenging, there is a path of realizing the implications of an individual perceptron as a choice function that is useful for me.<p>The same limits that have been known for decades still hold in the general case for those who can figure a way to control their own cognitive dissonance, but they are just lenses.<p>As an industry we need to find ways to avoid the traps of the Brouwer–Hilbert controversy and unsettled questions and opaque definitions about the nature of intelligence to fully exploit the advantages.<p>Hopefully experience will tempor the fear and enthusiasm for AGI that has made it challenging to discuss the power and constraints of ML.<p>I know that even discussing dropping the a priori assumption of LEM with my brother who has a PhD in complex analysis is challenging.<p>But the platonic ideals simply don&#x27;t hold for non-trivial properties, and no matter if we are using ML or BoG Sat, the hard problems are too high in the polynomial hierarchy to make that assumption.</div><br/></div></div></div></div><div id="42118340" class="c"><input type="checkbox" id="c-42118340" checked=""/><div class="controls bullet"><span class="by">gmaster1440</span><span>|</span><a href="#42117649">prev</a><span>|</span><a href="#42116761">next</a><span>|</span><label class="collapse" for="c-42118340">[-]</label><label class="expand" for="c-42118340">[1 more]</label></div><br/><div class="children"><div class="content">How generalizable are these findings given the rapid pace of AI advancement? The paper studies a snapshot in time with current AI capabilities, but the relationship between human expertise and AI could look very different with more advanced models. I would love to have seen the paper:<p>- Examine how the human-AI relationship evolved as the AI system improved during the study period<p>- Theorize more explicitly about which aspects of human judgment might be more vs less persistent<p>- Consider how their findings might change with more capable AI systems</div><br/></div></div><div id="42116761" class="c"><input type="checkbox" id="c-42116761" checked=""/><div class="controls bullet"><span class="by">11101010001100</span><span>|</span><a href="#42118340">prev</a><span>|</span><a href="#42119721">next</a><span>|</span><label class="collapse" for="c-42116761">[-]</label><label class="expand" for="c-42116761">[1 more]</label></div><br/><div class="children"><div class="content">Any idea if the points raised here<p><a href="https:&#x2F;&#x2F;pubs.acs.org&#x2F;doi&#x2F;10.1021&#x2F;acs.chemmater.4c00643" rel="nofollow">https:&#x2F;&#x2F;pubs.acs.org&#x2F;doi&#x2F;10.1021&#x2F;acs.chemmater.4c00643</a><p>were considered in the analysis?</div><br/></div></div><div id="42119721" class="c"><input type="checkbox" id="c-42119721" checked=""/><div class="controls bullet"><span class="by">caycep</span><span>|</span><a href="#42116761">prev</a><span>|</span><a href="#42116651">next</a><span>|</span><label class="collapse" for="c-42119721">[-]</label><label class="expand" for="c-42119721">[1 more]</label></div><br/><div class="children"><div class="content">would there be a difference in accuracy of the statement if you replace AI w&#x2F; &quot;data science and statistical models&quot;?</div><br/></div></div><div id="42116651" class="c"><input type="checkbox" id="c-42116651" checked=""/><div class="controls bullet"><span class="by">newyankee</span><span>|</span><a href="#42119721">prev</a><span>|</span><a href="#42117082">next</a><span>|</span><label class="collapse" for="c-42116651">[-]</label><label class="expand" for="c-42116651">[1 more]</label></div><br/><div class="children"><div class="content">Well I hope it works well and fast enough. I cannot wait for my 10k cycles, 300 Wh&#x2F;kg batteries. 35% efficiency solar modules in market at cheap prices and plenty of nanotech breakthroughs that were promised yet we are still waiting on</div><br/></div></div><div id="42117082" class="c"><input type="checkbox" id="c-42117082" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42116651">prev</a><span>|</span><label class="collapse" for="c-42117082">[-]</label><label class="expand" for="c-42117082">[1 more]</label></div><br/><div class="children"><div class="content">Well damn, that’s a lot more specific and empirical than I was expecting given the title. Fascinating stuff, talk about a useful setup for studying the issue! “AI is useless to many but invaluable to some” (as mentioned in the abstract) is a great counterpoint to anti-AI luddites. No offense to any luddites on here ofc, the luddites were pretty darn woke for their time, all things considered</div><br/></div></div></div></div></div></div></div></body></html>