<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720083676209" as="style"/><link rel="stylesheet" href="styles.css?v=1720083676209"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.mattkeeter.com/blog/2023-01-25-branch/">Do not taunt happy fun branch predictor (2023)</a> <span class="domain">(<a href="https://www.mattkeeter.com">www.mattkeeter.com</a>)</span></div><div class="subtext"><span>fanf2</span> | <span>119 comments</span></div><br/><div><div id="40868098" class="c"><input type="checkbox" id="c-40868098" checked=""/><div class="controls bullet"><span class="by">allenrb</span><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40868098">[-]</label><label class="expand" for="c-40868098">[12 more]</label></div><br/><div class="children"><div class="content">Was summarizing this article for a group of friends who largely met during the Apple II days and wanted to repost a bit of that here:<p>The optimized code at the end takes 94 <i>nanoseconds</i> to sum an array of 1024 32-bit floating point numbers.<p>In 94 nanoseconds, our old friend the 1 MHz 6502, would be just starting to consider signaling the memory chips that maybe they ought to try digging up the first byte of the first instruction in the program.<p>Worth mentioning, that code is entirely dependent on running in cache. Otherwise even the mighty M1 Max in the post would still be stuck waiting on that first memory fetch. DRAM is slow. :-)</div><br/><div id="40869597" class="c"><input type="checkbox" id="c-40869597" checked=""/><div class="controls bullet"><span class="by">cmrdporcupine</span><span>|</span><a href="#40868098">parent</a><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40869597">[-]</label><label class="expand" for="c-40869597">[11 more]</label></div><br/><div class="children"><div class="content">Lucky our total L1 cache sizes are about as big as the entire addressable memory of the 6502.<p>We truly live in amazing times.</div><br/><div id="40870044" class="c"><input type="checkbox" id="c-40870044" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40869597">parent</a><span>|</span><a href="#40870938">next</a><span>|</span><label class="collapse" for="c-40870044">[-]</label><label class="expand" for="c-40870044">[4 more]</label></div><br/><div class="children"><div class="content">Truly. And I&#x27;m also always amazed by how much slower (in terms of wall time) modern software is than it ought to be. CPUs sure don&#x27;t feel three to four orders of magnitude faster than they were 50 years ago, because software has gotten four to five orders of magnitude more wasteful to compensate. Argh...</div><br/><div id="40872581" class="c"><input type="checkbox" id="c-40872581" checked=""/><div class="controls bullet"><span class="by">jonhohle</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40870044">parent</a><span>|</span><a href="#40870938">next</a><span>|</span><label class="collapse" for="c-40872581">[-]</label><label class="expand" for="c-40872581">[3 more]</label></div><br/><div class="children"><div class="content">I recently moved a project from a Phenom II 945 to an I7 8700. The project took around 1:30 to compile on the Phenom, 15s to compile on the I7. Others working on the project with even more modern systems are compiling in half that time.<p>The major advantage I had was running the same compilers, same interpreters and same tooling, just in better hardware.<p>On the other hand, I always felt KDE 2 and 3 were way more responsive on way less hardware than one of the modern versions or Gnome. Part of it is UI design - giving feedback that an operation is going to take some time immediately instead of blocking until the operation is done before doing anything.</div><br/><div id="40872814" class="c"><input type="checkbox" id="c-40872814" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40872581">parent</a><span>|</span><a href="#40870938">next</a><span>|</span><label class="collapse" for="c-40872814">[-]</label><label class="expand" for="c-40872814">[2 more]</label></div><br/><div class="children"><div class="content">Plenty of that software is fairly well optimized, but most software is not that optimized. Microsoft Teams, Discord, Slack, basically anything else that also uses Electron... it&#x27;s not UI design, it&#x27;s legitimately wasted work, and tons of it.</div><br/><div id="40873381" class="c"><input type="checkbox" id="c-40873381" checked=""/><div class="controls bullet"><span class="by">nikanj</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40872814">parent</a><span>|</span><a href="#40870938">next</a><span>|</span><label class="collapse" for="c-40873381">[-]</label><label class="expand" for="c-40873381">[1 more]</label></div><br/><div class="children"><div class="content">So many programmers saw &quot;Premature optimization is the root of all evil&quot; and thought it means &quot;Caring about performance makes you a heretic&quot;.<p>You can&#x27;t hotspot optimize a Fiat Multipla into an Formula 1 car. When every software you run creates a dozen factories to replace one for-loop, you get the modern desktop experience</div><br/></div></div></div></div></div></div></div></div><div id="40870938" class="c"><input type="checkbox" id="c-40870938" checked=""/><div class="controls bullet"><span class="by">Natsu</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40869597">parent</a><span>|</span><a href="#40870044">prev</a><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40870938">[-]</label><label class="expand" for="c-40870938">[6 more]</label></div><br/><div class="children"><div class="content">Now you&#x27;re making me wonder if there&#x27;s a 6502 emulator making use of that fact.</div><br/><div id="40871678" class="c"><input type="checkbox" id="c-40871678" checked=""/><div class="controls bullet"><span class="by">cmrdporcupine</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40870938">parent</a><span>|</span><a href="#40871068">prev</a><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40871678">[-]</label><label class="expand" for="c-40871678">[4 more]</label></div><br/><div class="children"><div class="content">Hah, I had the same thought. What kind of hacks can I do to convince the processor to keep as much of the emulator + opcodes in L1 as I can...</div><br/><div id="40871893" class="c"><input type="checkbox" id="c-40871893" checked=""/><div class="controls bullet"><span class="by">dhosek</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40871678">parent</a><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40871893">[-]</label><label class="expand" for="c-40871893">[3 more]</label></div><br/><div class="children"><div class="content">A bit of ignorance on my part, but would the L1 be holding the data <i>and</i> the instructions? In which case we would be trying to fit our entire 6502 emulator in less than 64K of memory alongside the emulated RAM&#x2F;ROM?</div><br/><div id="40873010" class="c"><input type="checkbox" id="c-40873010" checked=""/><div class="controls bullet"><span class="by">Someone</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40871893">parent</a><span>|</span><a href="#40872243">next</a><span>|</span><label class="collapse" for="c-40873010">[-]</label><label class="expand" for="c-40873010">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple_M1#CPU" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple_M1#CPU</a>:<p><i>“The high-performance cores have an unusually large 192 KB of L1 instruction cache and 128 KB of L1 data cache and share a 12 MB L2 cache; the energy-efficient cores have a 128 KB L1 instruction cache, 64 KB L1 data cache, and a shared 4 MB L2 cache.”</i><p>⇒ chances are you don’t even have to <i>try</i> to fit an emulator of a 8-bit machine and it memory into the L1 cache.</div><br/></div></div><div id="40872243" class="c"><input type="checkbox" id="c-40872243" checked=""/><div class="controls bullet"><span class="by">cmrdporcupine</span><span>|</span><a href="#40868098">root</a><span>|</span><a href="#40871893">parent</a><span>|</span><a href="#40873010">prev</a><span>|</span><a href="#40867763">next</a><span>|</span><label class="collapse" for="c-40872243">[-]</label><label class="expand" for="c-40872243">[1 more]</label></div><br/><div class="children"><div class="content">The CPU decides what goes in there and when. You can only pray and offer sacrifices and guess at when and how.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40867763" class="c"><input type="checkbox" id="c-40867763" checked=""/><div class="controls bullet"><span class="by">AshamedCaptain</span><span>|</span><a href="#40868098">prev</a><span>|</span><a href="#40866906">next</a><span>|</span><label class="collapse" for="c-40867763">[-]</label><label class="expand" for="c-40867763">[7 more]</label></div><br/><div class="children"><div class="content">The same thing was covered by Raymond Chen almost 2 decades ago:
<a href="https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;oldnewthing&#x2F;20041216-00&#x2F;?p=36973" rel="nofollow">https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;oldnewthing&#x2F;20041216-00&#x2F;?p=36...</a></div><br/><div id="40867972" class="c"><input type="checkbox" id="c-40867972" checked=""/><div class="controls bullet"><span class="by">electrodank</span><span>|</span><a href="#40867763">parent</a><span>|</span><a href="#40867880">next</a><span>|</span><label class="collapse" for="c-40867972">[-]</label><label class="expand" for="c-40867972">[3 more]</label></div><br/><div class="children"><div class="content">As someone who has the old dead tree version of Intel’s x86 and 64 architecture instruction set reference (the fat blue books), and in general as someone who carefully reads the data sheets and documentation and looks for guidance from the engineers and staff who wrote the said data sheets, I always have reservations when I hear that “intuitively you would expect X but Y happens.” There’s nothing intuitive about any of this except, maybe, a reasonable understanding of the semi-conductive nature of the silicon and the various dopants in the process. Unless you’ve seen the die schematic, the traces, and you know the paths, there is little to no reason to have any sort of expectations that Thing A is faster than Thing B unless the engineering staff and data sheets explicitly tell you.<p>There are exceptions, but just my 2c. Especially with ARM.</div><br/><div id="40869109" class="c"><input type="checkbox" id="c-40869109" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#40867763">root</a><span>|</span><a href="#40867972">parent</a><span>|</span><a href="#40868414">next</a><span>|</span><label class="collapse" for="c-40869109">[-]</label><label class="expand" for="c-40869109">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Intuitively&quot; here should be taken to mean approximately the same as &quot;naively&quot; – as in, the intuition that most of us learn at first that CPUs work (&quot;as if&quot;) by executing one instruction at a time, strictly mechanistically, exactly corresponding to the assembly code. The way a toy architecture on a first-year intro to microprocessors course – or indeed a 6502 or 8086 or 68000 – would do it. Which is to say, no pipelining, no superscalar, no prefetching, no out-of-order execution, no branch prediction, no speculative execution, and so on.</div><br/></div></div><div id="40868414" class="c"><input type="checkbox" id="c-40868414" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#40867763">root</a><span>|</span><a href="#40867972">parent</a><span>|</span><a href="#40869109">prev</a><span>|</span><a href="#40867880">next</a><span>|</span><label class="collapse" for="c-40868414">[-]</label><label class="expand" for="c-40868414">[1 more]</label></div><br/><div class="children"><div class="content">Respectfully, I disagree. CPU architecture optimization is in continuous dance with compiler optimization where the former tries to adapt to the patterns most commonly produced by the latter, and the latter tries to adjust its optimizations according to what performs the faster within the former.<p>Therefore, it is not unreasonable to make assumptions based on the premise of &quot;does this code look like something that could be reasonably produced by GCC&#x2F;LLVM?&quot;.<p>It is true that as cores get simpler and cheaper, they get more edge cases - something really big like Firestorm (A14&#x2F;M1) can afford to have very consistent and tight latencies for all of its SIMD instructions regardless of the element&#x2F;lane size and even hide complex dependencies or alignment artifacts wherever possible. But compare that with simpler and cheaper Neoverse N1, and it&#x27;s a different story entirely, where trivial algorithm changes lead to significant slowdown - ADDV Vn.16B is way slower than Vn.4H, so you have to work around it. This is only exacerbated if you look at much smaller cores.<p>LLVM and GCC deal with this by being able to use relatively precise knowledge of CPU&#x27;s (-mtune) fetch, reorder, load and store queue&#x2F;buffer depths, as well as latencies and dependency penalty cost of opcodes of the ISA it implements, and other details like loop alignment requirements, branch predictor limitations.<p>Generally, it&#x27;s difficult to do better in straight-line code with local data than such compilers assuming that whatever you are doing doesn&#x27;t make concessions that a compiler is not allowed to make.<p>Nonetheless, the mindset for writing a performant algorithm implementation is going to be the same as long as you are doing so for the same <i>class</i> of CPU cores - loop unrolling, using cmovs, and scheduling operations in advance, or ensuring that should spills happen, the load and store operations have matching arguments - all of that will be profitable on AMD&#x27;s Zen 4, Intel&#x27;s Golden Cove, Apple&#x27;s Firestorm or ARM&#x27;s Neoverse V3.</div><br/></div></div></div></div><div id="40867880" class="c"><input type="checkbox" id="c-40867880" checked=""/><div class="controls bullet"><span class="by">rkagerer</span><span>|</span><a href="#40867763">parent</a><span>|</span><a href="#40867972">prev</a><span>|</span><a href="#40869438">next</a><span>|</span><label class="collapse" for="c-40867880">[-]</label><label class="expand" for="c-40867880">[1 more]</label></div><br/><div class="children"><div class="content">He did, and that&#x27;s a fantastic article which is worth the read and provides good context for interpreting this post.<p>One thing this post adds is the simple rectification of replacing ret with another br instruction, so the pairs are again &quot;mirrored&quot;, and you get to have your cake and eat it too - slightly faster code without breaking the branch predictor.</div><br/></div></div><div id="40869438" class="c"><input type="checkbox" id="c-40869438" checked=""/><div class="controls bullet"><span class="by">bigstrat2003</span><span>|</span><a href="#40867763">parent</a><span>|</span><a href="#40867880">prev</a><span>|</span><a href="#40868409">next</a><span>|</span><label class="collapse" for="c-40869438">[-]</label><label class="expand" for="c-40869438">[1 more]</label></div><br/><div class="children"><div class="content">Raymond Chen is a treasure. I&#x27;m so glad that Microsoft gives him the leeway to write that blog, I have learned a ton from it.</div><br/></div></div><div id="40868409" class="c"><input type="checkbox" id="c-40868409" checked=""/><div class="controls bullet"><span class="by">rep_lodsb</span><span>|</span><a href="#40867763">parent</a><span>|</span><a href="#40869438">prev</a><span>|</span><a href="#40866906">next</a><span>|</span><label class="collapse" for="c-40868409">[-]</label><label class="expand" for="c-40868409">[1 more]</label></div><br/><div class="children"><div class="content">This seems no longer to be true for recent x86 processors: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40767676">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40767676</a></div><br/></div></div></div></div><div id="40866906" class="c"><input type="checkbox" id="c-40866906" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40867763">prev</a><span>|</span><a href="#40868263">next</a><span>|</span><label class="collapse" for="c-40866906">[-]</label><label class="expand" for="c-40866906">[43 more]</label></div><br/><div class="children"><div class="content">&gt; The SIMD code does come with one asterisk, though: because floating-point addition is not associative, and it performs the summation in a different order, it may not get the same result as straight-line code. In retrospect, this is likely why the compiler doesn&#x27;t generate SIMD instructions to compute the sum!<p>&gt; Does this matter for your use case? Only you can know!<p>Anything is possible of course, and the typical way of writing a loop to sum up an array is literally telling the computer to go element by element and accumulate the values.<p>But it seems pretty unlikely that doing, say, four accumulations in parallel with simd and then summing them up at the end is any more wrong than going element by element.<p>Summing floats should by default be taken to have error bounds, and any answer in those bounds is valid. If you know something special about the floats you are inputting, the language should have some means to explicitly encode that. It shouldn’t be the most basic loop, that’s the default case, so it should give the best performance.</div><br/><div id="40867464" class="c"><input type="checkbox" id="c-40867464" checked=""/><div class="controls bullet"><span class="by">lscharen</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40867217">next</a><span>|</span><label class="collapse" for="c-40867464">[-]</label><label class="expand" for="c-40867464">[4 more]</label></div><br/><div class="children"><div class="content">Surprisingly there are different algorithms for doing something as simple as summing up a list of numbers.<p>The naïve way of adding numbers one-by-one in a loop is an obvious way, but there are more sophisticated methods that give better bounds of the total accumulated error; Kahan summation[1] being one of the better-known ones.<p>Like most things, it can get complicated depending on the specific context.  For streaming data, adding numbers one at a time may be the only option.  But what if one could use a fixed-size buffer of N numbers?  When a new number arrives what should be done? Take a partial sum of some subset of the N numbers in the buffer and add that to a cumulative total? If a subset if chosen, how? Are there provable (improved) error bounds for the subset selection method?<p>Fun stuff.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kahan_summation_algorithm" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kahan_summation_algorithm</a></div><br/><div id="40867842" class="c"><input type="checkbox" id="c-40867842" checked=""/><div class="controls bullet"><span class="by">kardos</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867464">parent</a><span>|</span><a href="#40867217">next</a><span>|</span><label class="collapse" for="c-40867842">[-]</label><label class="expand" for="c-40867842">[3 more]</label></div><br/><div class="children"><div class="content">As far as I know, xsum [1] more or less solves the problem completely: order invariant and exact, at less than 2x the cost of the naive summation. Further speeding it up may be the only avenue left for improvement.<p>[1] <a href="https:&#x2F;&#x2F;gitlab.com&#x2F;radfordneal&#x2F;xsum" rel="nofollow">https:&#x2F;&#x2F;gitlab.com&#x2F;radfordneal&#x2F;xsum</a></div><br/><div id="40868382" class="c"><input type="checkbox" id="c-40868382" checked=""/><div class="controls bullet"><span class="by">lscharen</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867842">parent</a><span>|</span><a href="#40867217">next</a><span>|</span><label class="collapse" for="c-40868382">[-]</label><label class="expand" for="c-40868382">[2 more]</label></div><br/><div class="children"><div class="content">I was not aware of this (2015) work -- very nice!<p>A couple of pull-quotes from the paper to summarize:<p><i>Much work has been done on trying to improve the accuracy of summation. Some methods aim to somewhat improve accuracy at little computational cost, but do not guarantee that the result is the correctly rounded exact sum.</i><p><i>Many methods have been developed that instead compute the exact sum of a set of floating-point values, and then correctly round this exact sum to the closest floating-point value. This obviously would be preferable to any non-exact method, if the exact computation could be done sufficiently quickly</i><p><i>Exact summation methods fall into two classes — those implemented using standard floating point arithmetic operations available in hardware on most current processors, such as the methods of Zhu and Hayes (2010), and those that instead perform the summation with integer arithmetic, using a “superaccumulator”.</i><p><i>I present two new methods for exactly summing a set of floating-point numbers, and then correctly rounding to the nearest floating-point number. ...  One method uses a “small” superaccumulator with sixty-seven 64-bit chunks, each with 32-bit overlap with the next chunk, allowing carry propagation to be done infrequently. The small superaccumulator is used alone when summing a small number of terms. For big summations, a “large” superaccumulator is used as well. It consists of 4096 64-bit chunks, one for every possible combination of exponent bits and sign bit, plus counts of when each chunk needs to be transferred to the small superaccumulator.</i><p><i>On modern 64-bit processors, exactly summing a large array using this combination of large and small superaccumulators takes less than twice the time of simple, inexact, ordered summation, with a serial implementation </i></div><br/><div id="40869524" class="c"><input type="checkbox" id="c-40869524" checked=""/><div class="controls bullet"><span class="by">pacaro</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868382">parent</a><span>|</span><a href="#40867217">next</a><span>|</span><label class="collapse" for="c-40869524">[-]</label><label class="expand" for="c-40869524">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the summary. I kinda low-key love the idea of converting floats into a fixed point representation that covers the entire range represented by the float type. I mean the accumulator is only 32 KB, which is likely to be in L1 the entire time on modern hardware, and any given float is only going to need two 64 bit words,  + 13 bits (12 bits for offset, and 1 for sign) to be represented in this scheme.</div><br/></div></div></div></div></div></div></div></div><div id="40867217" class="c"><input type="checkbox" id="c-40867217" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40867464">prev</a><span>|</span><a href="#40866995">next</a><span>|</span><label class="collapse" for="c-40867217">[-]</label><label class="expand" for="c-40867217">[16 more]</label></div><br/><div class="children"><div class="content">It turns into a serious problem if the floats are of different magnitude. Consider [1e50, -1e50, 1e3, 1e3]. Evaluating it as (((1e50 + -1e50) + 1e3) + 1e3) gives 2e3, evaluating it as ((1e50 + 1e3) + (-1e50 + 1e3)) gives 0.<p>You get similar issues if you&#x27;re trying to add a large number of small-magnitude numbers to a single larger-magnitude number. (((1e3 + 1e3) + 1e3) ... + 1e50) is substantially different from (((1e50 + 1e3) + 1e3) ... + 1e3).</div><br/><div id="40867710" class="c"><input type="checkbox" id="c-40867710" checked=""/><div class="controls bullet"><span class="by">jandrese</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867217">parent</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40867710">[-]</label><label class="expand" for="c-40867710">[7 more]</label></div><br/><div class="children"><div class="content">Adding and subtracting numbers of wildly different magnitudes is always cursed.  If you&#x27;re doing this I&#x27;d say the majority of the time you are making an error.<p>Your equation ends up being like &quot;We calculated the diameter of the observable universe, but what if we added the Empire State Building to one side, how does that affect the result?&quot;</div><br/><div id="40867956" class="c"><input type="checkbox" id="c-40867956" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867710">parent</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40867956">[-]</label><label class="expand" for="c-40867956">[6 more]</label></div><br/><div class="children"><div class="content">It’s also what we do when incrementing a counter, if it’s a very big counter. Operations like that don’t have a physical meaning, but can happen in things like random number generators where it’s a way of mixing the bits. Or maybe allocating unique ids, if you started from a random number.</div><br/><div id="40868010" class="c"><input type="checkbox" id="c-40868010" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867956">parent</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40868010">[-]</label><label class="expand" for="c-40868010">[5 more]</label></div><br/><div class="children"><div class="content">Of course it is just an example so we shouldn’t nitpick you too much, but that sounds more like a job for an integer.</div><br/><div id="40869384" class="c"><input type="checkbox" id="c-40869384" checked=""/><div class="controls bullet"><span class="by">aardvark179</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868010">parent</a><span>|</span><a href="#40869202">next</a><span>|</span><label class="collapse" for="c-40869384">[-]</label><label class="expand" for="c-40869384">[1 more]</label></div><br/><div class="children"><div class="content">If all you’ve got is JS then every problem looks like a double.</div><br/></div></div><div id="40869202" class="c"><input type="checkbox" id="c-40869202" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868010">parent</a><span>|</span><a href="#40869384">prev</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40869202">[-]</label><label class="expand" for="c-40869202">[3 more]</label></div><br/><div class="children"><div class="content">Yes, absolutely. Though in JavaScript we often make do with the safe integer range. (I don’t know how fast BigInt is for 64 bit integers.)</div><br/><div id="40869262" class="c"><input type="checkbox" id="c-40869262" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40869202">parent</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40869262">[-]</label><label class="expand" for="c-40869262">[2 more]</label></div><br/><div class="children"><div class="content">I don’t know JavaScript so I’m sure to shoot my own foot here, but surely a BigInt who’s value can fit in 64 bits is just a normal 64 bit int (from hardware) with some extra bookkeeping around it on most platforms, right?</div><br/><div id="40870625" class="c"><input type="checkbox" id="c-40870625" checked=""/><div class="controls bullet"><span class="by">IainIreland</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40869262">parent</a><span>|</span><a href="#40868579">next</a><span>|</span><label class="collapse" for="c-40870625">[-]</label><label class="expand" for="c-40870625">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t speak for any other engines, but in SpiderMonkey a BigInt is a GC-managed object with a one-word header containing the sign bit, the length, and some GC bookkeeping bits, along with a second word that is either a single inline 64-bit digit, or a pointer to an array of 64-bit digits. So the memory overhead of a BigInt that fits in 64 bits is &quot;only&quot; 2x, but doing math with BigInt requires more work than a native integer because it needs to handle larger numbers, manually manage sign bits, and so on.<p>(<a href="https:&#x2F;&#x2F;searchfox.org&#x2F;mozilla-central&#x2F;source&#x2F;js&#x2F;src&#x2F;vm&#x2F;BigIntType.h#49-464" rel="nofollow">https:&#x2F;&#x2F;searchfox.org&#x2F;mozilla-central&#x2F;source&#x2F;js&#x2F;src&#x2F;vm&#x2F;BigIn...</a>)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40868579" class="c"><input type="checkbox" id="c-40868579" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867217">parent</a><span>|</span><a href="#40867710">prev</a><span>|</span><a href="#40867728">next</a><span>|</span><label class="collapse" for="c-40868579">[-]</label><label class="expand" for="c-40868579">[2 more]</label></div><br/><div class="children"><div class="content">Whether you care about the order or not depends on the intent of the programmer. I think the intent is usually to sum up the array for this sort of code. So, at first glance your first example looks more like a result of something like 0 +- 1e35 in double to me (added one to the exponent to avoid having to do math).<p>The intent of the programmer always has to be interpreted by the language. I’m saying the default interpretation should be one that doesn’t impose an ordering unless specifically requested. This is much more sympathetic to modern deeply parallel machines.</div><br/><div id="40868982" class="c"><input type="checkbox" id="c-40868982" checked=""/><div class="controls bullet"><span class="by">FreakLegion</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868579">parent</a><span>|</span><a href="#40867728">next</a><span>|</span><label class="collapse" for="c-40868982">[-]</label><label class="expand" for="c-40868982">[1 more]</label></div><br/><div class="children"><div class="content">Very often there&#x27;s no particular intent, other than to be consistent. You haven&#x27;t lived until you&#x27;ve traced discrepancies in an ML model deployed across a bunch of platforms back to which SIMD instructions each happens to support (usually squirreled away in some dependency).</div><br/></div></div></div></div><div id="40867728" class="c"><input type="checkbox" id="c-40867728" checked=""/><div class="controls bullet"><span class="by">mywittyname</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867217">parent</a><span>|</span><a href="#40868579">prev</a><span>|</span><a href="#40866995">next</a><span>|</span><label class="collapse" for="c-40867728">[-]</label><label class="expand" for="c-40867728">[6 more]</label></div><br/><div class="children"><div class="content">But you haven&#x27;t demonstrated that the SIMD approach produces a meaningfully different and more accurate approach than the naive method.<p>Just like processor magic made the theoretically more performant code perform worse, it&#x27;s possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate than the naive approach.<p>This is absolutely a situation that requires empirical testing.</div><br/><div id="40868037" class="c"><input type="checkbox" id="c-40868037" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867728">parent</a><span>|</span><a href="#40867809">next</a><span>|</span><label class="collapse" for="c-40868037">[-]</label><label class="expand" for="c-40868037">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate than the naive approach.<p>It absolutely is not. Floating-point addition is completely defined (save for some of the bits in NaN results), and no CPU will start reordering your addition instructions in a way that changes the result. Even if it&#x27;s an ordering that gives you better accuracy. Having SIMD do four (or more) of them in parallel does not change this.</div><br/></div></div><div id="40867809" class="c"><input type="checkbox" id="c-40867809" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867728">parent</a><span>|</span><a href="#40868037">prev</a><span>|</span><a href="#40867788">next</a><span>|</span><label class="collapse" for="c-40867809">[-]</label><label class="expand" for="c-40867809">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s possible that the processor has facilities for bucketing the data such that results from such a dataset are the same or more accurate<p>Not realistically.  The processor very much  needs to do what you tell it.</div><br/></div></div><div id="40867788" class="c"><input type="checkbox" id="c-40867788" checked=""/><div class="controls bullet"><span class="by">scaredginger</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867728">parent</a><span>|</span><a href="#40867809">prev</a><span>|</span><a href="#40866995">next</a><span>|</span><label class="collapse" for="c-40867788">[-]</label><label class="expand" for="c-40867788">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, no.<p>If I know what my data look like, I can choose an order of summation that reduces the error. I wouldn&#x27;t want the compiler by default to assume associativity and introduce bugs. There&#x27;s a reason this reordering is disabled by default</div><br/><div id="40868051" class="c"><input type="checkbox" id="c-40868051" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867788">parent</a><span>|</span><a href="#40866995">next</a><span>|</span><label class="collapse" for="c-40868051">[-]</label><label class="expand" for="c-40868051">[2 more]</label></div><br/><div class="children"><div class="content">Not the least that you should get the same result from your code every time, even if you compile it with a different compiler. Doesn&#x27;t matter if that result is somehow better or worse or “difference is so small that it doesn&#x27;t matter”; it needs to be exactly the same, every time.</div><br/><div id="40868928" class="c"><input type="checkbox" id="c-40868928" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868051">parent</a><span>|</span><a href="#40866995">next</a><span>|</span><label class="collapse" for="c-40868928">[-]</label><label class="expand" for="c-40868928">[1 more]</label></div><br/><div class="children"><div class="content">I think there’s often a disconnect in these discussions between people that work on libraries and people that work on the application code.<p>If you have written a library, the user will provide some inputs. While the rounding behavior of floating point operations is well defined, for arbitrary user input, you can’t usually guarantee that it’ll go either way. Therefore, you need to do the numerical analysis given users inputs from some range, if you want to be at all rigorous. This will give results with error bounds, not exact bit patterns.<p>If you want exact matches for your tests, maybe identify the bits that are essentially meaningless and write them to some arbitrary value.<p>Edit: that said I don’t think anybody particularly owns rigor on this front, given that most libraries don’t actually do the analysis, lol.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40866995" class="c"><input type="checkbox" id="c-40866995" checked=""/><div class="controls bullet"><span class="by">pjc50</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40867217">prev</a><span>|</span><a href="#40866993">next</a><span>|</span><label class="collapse" for="c-40866995">[-]</label><label class="expand" for="c-40866995">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Summing floats should by default be taken to have error bounds, and any answer in those bounds is valid. If you know something special about the floats you are inputting, the language should have some means to explicitly encode that. It shouldn’t be the most basic loop, that’s the default case, so it should give the best performance.<p>This is a lot of &quot;should&quot; for something that basically doesn&#x27;t happen. The only information you give is the order of arithmetic in the original expression.<p>It is a total nightmare if arithmetic is not stable between builds. Rebuilding the software and running it on the same input should not produce different results.<p>(Long ago I encountered the special Intel version of this: because the FPU used 80-bit registers internally but 64-bit in memory, changing when a register fill&#x2F;spill happened would change when your answer got rounded, and thereby change the results. You can set a global FPU flag at the start of the program to force rounding on every operation.)</div><br/><div id="40867654" class="c"><input type="checkbox" id="c-40867654" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40866995">parent</a><span>|</span><a href="#40867460">next</a><span>|</span><label class="collapse" for="c-40867654">[-]</label><label class="expand" for="c-40867654">[1 more]</label></div><br/><div class="children"><div class="content">It does happen in languages and libraries with a higher level of abstraction. MKL for example will do whatever it wants for accumulations (which practically means that it’ll take advantage of SIMD because that’s a big reason why people use the library) unless you specifically request otherwise via there “Conditional Numerical Reproducibility” flag.<p>I think that was the right way to do it. BLAS made the right decision by defining these things in terms of sums and dot products instead of step-by-step instructions.<p>It will always be possible to write programs that run differently on different hardware or with different optimization levels. If somebody is writing code for floating point computations and expects exact bit patterns—it is possible, of course, all the rounding behavior is clearly specified. But usually this is an error.</div><br/></div></div><div id="40867460" class="c"><input type="checkbox" id="c-40867460" checked=""/><div class="controls bullet"><span class="by">cwzwarich</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40866995">parent</a><span>|</span><a href="#40867654">prev</a><span>|</span><a href="#40866993">next</a><span>|</span><label class="collapse" for="c-40867460">[-]</label><label class="expand" for="c-40867460">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You can set a global FPU flag at the start of the program to force rounding on every operation<p>This doesn’t do quite the same thing. It still uses the wider exponent range of the 80-bit type.</div><br/></div></div></div></div><div id="40866993" class="c"><input type="checkbox" id="c-40866993" checked=""/><div class="controls bullet"><span class="by">throwaway260124</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40866995">prev</a><span>|</span><a href="#40867362">next</a><span>|</span><label class="collapse" for="c-40866993">[-]</label><label class="expand" for="c-40866993">[6 more]</label></div><br/><div class="children"><div class="content">Sorting the floats reduces the error. I think using multiple  accumulators reduces the accuracy then. And sorted data is not uncommon.<p>I think there is always a correct answer and the compiler shouldn’t make changes at least by default that are wrong.<p>But ways for the programmer to express his intent more clearly are always welcome.</div><br/><div id="40868036" class="c"><input type="checkbox" id="c-40868036" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40866993">parent</a><span>|</span><a href="#40867255">next</a><span>|</span><label class="collapse" for="c-40868036">[-]</label><label class="expand" for="c-40868036">[4 more]</label></div><br/><div class="children"><div class="content">Multiple accumulators increases accuracy.
See pairwise summation, for example.<p>SIMD sums are going to typically be much more accurate than a naive sum.</div><br/><div id="40868662" class="c"><input type="checkbox" id="c-40868662" checked=""/><div class="controls bullet"><span class="by">Chabsff</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868036">parent</a><span>|</span><a href="#40867255">next</a><span>|</span><label class="collapse" for="c-40868662">[-]</label><label class="expand" for="c-40868662">[3 more]</label></div><br/><div class="children"><div class="content">Not necessarily either. It&#x27;s not particularly hard to create a vector where in-order addition is the most accurate way to sum its terms. All you need is a sequence where the next term is close to the sum of all prior ones.<p>There just isn&#x27;t a one-size-fit-all solution to be had here.</div><br/><div id="40869840" class="c"><input type="checkbox" id="c-40869840" checked=""/><div class="controls bullet"><span class="by">kardos</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40868662">parent</a><span>|</span><a href="#40867255">next</a><span>|</span><label class="collapse" for="c-40869840">[-]</label><label class="expand" for="c-40869840">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There just isn&#x27;t a one-size-fit-all solution to be had here.<p>But there is: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40867842">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40867842</a></div><br/><div id="40871078" class="c"><input type="checkbox" id="c-40871078" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40869840">parent</a><span>|</span><a href="#40867255">next</a><span>|</span><label class="collapse" for="c-40871078">[-]</label><label class="expand" for="c-40871078">[1 more]</label></div><br/><div class="children"><div class="content">That’s a one size fits some solution. Not more than 2x as slower than native floats is pretty slow for cases where you don’t need the extra precision.<p>If might be the case that it is the best solution if you do need the extra precision. But that’s just one case, not all.</div><br/></div></div></div></div></div></div></div></div><div id="40867255" class="c"><input type="checkbox" id="c-40867255" checked=""/><div class="controls bullet"><span class="by">Chabsff</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40866993">parent</a><span>|</span><a href="#40868036">prev</a><span>|</span><a href="#40867362">next</a><span>|</span><label class="collapse" for="c-40867255">[-]</label><label class="expand" for="c-40867255">[1 more]</label></div><br/><div class="children"><div class="content">Not necessarily. If the array is large and the values are similar, using accumulators would yield a more accurate result than a single one.</div><br/></div></div></div></div><div id="40867362" class="c"><input type="checkbox" id="c-40867362" checked=""/><div class="controls bullet"><span class="by">RobotToaster</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40866993">prev</a><span>|</span><a href="#40866971">next</a><span>|</span><label class="collapse" for="c-40867362">[-]</label><label class="expand" for="c-40867362">[7 more]</label></div><br/><div class="children"><div class="content">&gt; this is likely why the compiler doesn&#x27;t generate SIMD instructions to compute the sum!<p>Isn&#x27;t this the type of thing ffast-math is supposed to enable?</div><br/><div id="40867659" class="c"><input type="checkbox" id="c-40867659" checked=""/><div class="controls bullet"><span class="by">not2b</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867362">parent</a><span>|</span><a href="#40868090">next</a><span>|</span><label class="collapse" for="c-40867659">[-]</label><label class="expand" for="c-40867659">[4 more]</label></div><br/><div class="children"><div class="content">-ffast-math can be read as -fwrong-math if the accuracy if the answers matters. For some applications accuracy might not matter much. But the differences you get by pretending that floating point math is associative can be enormous, and scientific and engineering code is often carefully designed to take the likely scale of values into account, and rearranging it is not a good idea.</div><br/><div id="40873060" class="c"><input type="checkbox" id="c-40873060" checked=""/><div class="controls bullet"><span class="by">rurban</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867659">parent</a><span>|</span><a href="#40868135">next</a><span>|</span><label class="collapse" for="c-40873060">[-]</label><label class="expand" for="c-40873060">[1 more]</label></div><br/><div class="children"><div class="content">Rearranging, like sorting before, is actually a good idea to minimize errors.</div><br/></div></div><div id="40868135" class="c"><input type="checkbox" id="c-40868135" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867659">parent</a><span>|</span><a href="#40873060">prev</a><span>|</span><a href="#40867867">next</a><span>|</span><label class="collapse" for="c-40868135">[-]</label><label class="expand" for="c-40868135">[1 more]</label></div><br/><div class="children"><div class="content">For code that&#x27;s been explicitly manually optimized already, indeed you wouldn&#x27;t want to turn on -ffast-math; and I&#x27;d hope anyone who has actually learned what benefits from manual optimization and how to properly do that would also at some point have read something about not coupling that with -ffast-math. But I really doubt such meaningfully-manually-optimized code is at all frequent, and where it isn&#x27;t it&#x27;s a rather simple improvement (potentially with using some subset flags to allow NaN or infinity if desired).</div><br/></div></div><div id="40867867" class="c"><input type="checkbox" id="c-40867867" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867659">parent</a><span>|</span><a href="#40868135">prev</a><span>|</span><a href="#40868090">next</a><span>|</span><label class="collapse" for="c-40867867">[-]</label><label class="expand" for="c-40867867">[1 more]</label></div><br/><div class="children"><div class="content">Assuming associativity is not anti-accuracy in general, it just gets in the way of certain clever algorithms.</div><br/></div></div></div></div><div id="40868090" class="c"><input type="checkbox" id="c-40868090" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867362">parent</a><span>|</span><a href="#40867659">prev</a><span>|</span><a href="#40867841">next</a><span>|</span><label class="collapse" for="c-40868090">[-]</label><label class="expand" for="c-40868090">[1 more]</label></div><br/><div class="children"><div class="content">Maybe the “fun safe math” flag could be used?</div><br/></div></div><div id="40867841" class="c"><input type="checkbox" id="c-40867841" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867362">parent</a><span>|</span><a href="#40868090">prev</a><span>|</span><a href="#40866971">next</a><span>|</span><label class="collapse" for="c-40867841">[-]</label><label class="expand" for="c-40867841">[1 more]</label></div><br/><div class="children"><div class="content">Fast math does a lot of risky things in addition to using basic math rules.</div><br/></div></div></div></div><div id="40866971" class="c"><input type="checkbox" id="c-40866971" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#40866906">parent</a><span>|</span><a href="#40867362">prev</a><span>|</span><a href="#40868263">next</a><span>|</span><label class="collapse" for="c-40866971">[-]</label><label class="expand" for="c-40866971">[5 more]</label></div><br/><div class="children"><div class="content">A lot of code relies on FP operations being deterministic, often within confines of specific ISA. Applying SIMD to loops with FP could have been a default but it breaks a lot of existing code, makes the output frequently straight-up non-deterministic and as a result is something that a programmer has to explicitly choose to use.<p>Moreover, many programmers may not be even aware of these, so when a `float Sum(float[] values)` starts to return something different, they may not have any way to know that it is the vectorization that makes it do so. Which is why, for example, .NET&#x27;s standard library will use SIMD for `integers.Sum()` but not for `floats.Sum()`.</div><br/><div id="40867272" class="c"><input type="checkbox" id="c-40867272" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40866971">parent</a><span>|</span><a href="#40868263">next</a><span>|</span><label class="collapse" for="c-40867272">[-]</label><label class="expand" for="c-40867272">[4 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of code relies on FP operations being deterministic, often within confines of specific ISA<p>How much of this is true in practice? I vaguely recall reading about a hard-to-diagnose bug where a seemingly unrelated code change meant that an intermediate value was no longer stored in the x87 extended-precision register but in memory instead, leading to a different result. Wouldn&#x27;t you run into stuff like that all the time?</div><br/><div id="40867525" class="c"><input type="checkbox" id="c-40867525" checked=""/><div class="controls bullet"><span class="by">mindcandy</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867272">parent</a><span>|</span><a href="#40868077">next</a><span>|</span><label class="collapse" for="c-40867525">[-]</label><label class="expand" for="c-40867525">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of code relies on FP operations being deterministic<p>A lot, but still quite the minority. People do run into situations where the same code with the same data produces slightly different results all the time because of changes in compiler, compiler settings, cpu arch, etc… They just don’t notice.<p>But, then they run into a situation where it matters and it’s a huge PITA to nail down.</div><br/><div id="40867884" class="c"><input type="checkbox" id="c-40867884" checked=""/><div class="controls bullet"><span class="by">kardos</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867525">parent</a><span>|</span><a href="#40868077">next</a><span>|</span><label class="collapse" for="c-40867884">[-]</label><label class="expand" for="c-40867884">[1 more]</label></div><br/><div class="children"><div class="content">Yes this is exactly it. The gold standard is bit-4-bit matching when shifting code between systems. If you move your code to a new system and get different results --&gt; is it due to different summing order, or something else wrong? By ruling out the former you&#x27;re more likely to get the bit-4-bit match and thus avoid a lot of debugging effort -- or spend it solving a real bug.</div><br/></div></div></div></div><div id="40868077" class="c"><input type="checkbox" id="c-40868077" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#40866906">root</a><span>|</span><a href="#40867272">parent</a><span>|</span><a href="#40867525">prev</a><span>|</span><a href="#40868263">next</a><span>|</span><label class="collapse" for="c-40868077">[-]</label><label class="expand" for="c-40868077">[1 more]</label></div><br/><div class="children"><div class="content">This is one of many reasons why we generally don&#x27;t use the x87 registers anymore.</div><br/></div></div></div></div></div></div></div></div><div id="40868263" class="c"><input type="checkbox" id="c-40868263" checked=""/><div class="controls bullet"><span class="by">mrinterweb</span><span>|</span><a href="#40866906">prev</a><span>|</span><a href="#40866726">next</a><span>|</span><label class="collapse" for="c-40868263">[-]</label><label class="expand" for="c-40868263">[3 more]</label></div><br/><div class="children"><div class="content">Classic SNL reference: &quot;Do not taunt happy fun ball&quot;<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GmqeZl8OI2M" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GmqeZl8OI2M</a></div><br/><div id="40868315" class="c"><input type="checkbox" id="c-40868315" checked=""/><div class="controls bullet"><span class="by">rhussmann</span><span>|</span><a href="#40868263">parent</a><span>|</span><a href="#40868737">next</a><span>|</span><label class="collapse" for="c-40868315">[-]</label><label class="expand" for="c-40868315">[1 more]</label></div><br/><div class="children"><div class="content">If happy fun branch predictor starts to smoke, seek shelter immediately.</div><br/></div></div><div id="40868737" class="c"><input type="checkbox" id="c-40868737" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#40868263">parent</a><span>|</span><a href="#40868315">prev</a><span>|</span><a href="#40866726">next</a><span>|</span><label class="collapse" for="c-40868737">[-]</label><label class="expand" for="c-40868737">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Happy Fun Ball has been shipped to our troops in Saudi Arabia and is also being dropped by our warplanes in Iraq.<p>&quot;What YEAR is it!?&quot; &#x2F;robin-williams-in-jumanji</div><br/></div></div></div></div><div id="40866726" class="c"><input type="checkbox" id="c-40866726" checked=""/><div class="controls bullet"><span class="by">jcranmer</span><span>|</span><a href="#40868263">prev</a><span>|</span><a href="#40870289">next</a><span>|</span><label class="collapse" for="c-40866726">[-]</label><label class="expand" for="c-40866726">[7 more]</label></div><br/><div class="children"><div class="content">&gt; After checking for loop termination, we fall through into the foo function (without a branch!)<p>Literally just reading this line made me go &quot;well, there&#x27;s your problem.&quot; I thought this was going to be something deep about fancy branch predictor heuristics, but it turns out to be a violation of basic heuristics.<p>Folks, don&#x27;t think you&#x27;re going to get amazing speedups by using mismatched call&#x2F;ret instructions. The branch predictor keeping a shadow stack of return addresses is something that&#x27;s been around for decades.</div><br/><div id="40869287" class="c"><input type="checkbox" id="c-40869287" checked=""/><div class="controls bullet"><span class="by">chasil</span><span>|</span><a href="#40866726">parent</a><span>|</span><a href="#40867003">next</a><span>|</span><label class="collapse" for="c-40869287">[-]</label><label class="expand" for="c-40869287">[1 more]</label></div><br/><div class="children"><div class="content">On the one hand, a design goal of RISC is to improve the performance of compiled code at the expense of most other things. As such, this sort of hazard should be documented, but the designers should be able to assume that anyone directly writing assembler has read the documentation.<p>On the other hand, Sophie Wilson wrote an implementation of BBC BASIC for the original ARM (but it didn&#x27;t have a branch predictor). While that is 32-bit and plays by different rules, I wonder how AArch64 slows down code when the architectural assumptions change.</div><br/></div></div><div id="40867003" class="c"><input type="checkbox" id="c-40867003" checked=""/><div class="controls bullet"><span class="by">adwn</span><span>|</span><a href="#40866726">parent</a><span>|</span><a href="#40869287">prev</a><span>|</span><a href="#40866872">next</a><span>|</span><label class="collapse" for="c-40867003">[-]</label><label class="expand" for="c-40867003">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s great that you&#x27;re so knowledgeable about branch predictor behavior, but many people aren&#x27;t and for them this is new, maybe even valuable, information.<p>I guess this article&#x27;s just not for you then, and that&#x27;s okay.</div><br/><div id="40870007" class="c"><input type="checkbox" id="c-40870007" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40866726">root</a><span>|</span><a href="#40867003">parent</a><span>|</span><a href="#40866872">next</a><span>|</span><label class="collapse" for="c-40870007">[-]</label><label class="expand" for="c-40870007">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the complaint is that the article exists,  it&#x27;s that it perhaps needs more context.  The article does not present the level of skill assumed about the reader or of the author,  so comments like these help put that in perspective.<p>The commentary from &quot;old salts&quot; isn&#x27;t meant to insult or discourage you but to inform your world view with hard earned experience.<p>It all has a value that&#x27;s greater than the sum of it&#x27;s parts and there&#x27;s no good reason to be critical or reactionary about it.</div><br/></div></div></div></div><div id="40866872" class="c"><input type="checkbox" id="c-40866872" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#40866726">parent</a><span>|</span><a href="#40867003">prev</a><span>|</span><a href="#40866974">next</a><span>|</span><label class="collapse" for="c-40866872">[-]</label><label class="expand" for="c-40866872">[1 more]</label></div><br/><div class="children"><div class="content">And yet they also showed how they did actually accomplish this and other optimizations. It’s an informative read.</div><br/></div></div><div id="40866974" class="c"><input type="checkbox" id="c-40866974" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#40866726">parent</a><span>|</span><a href="#40866872">prev</a><span>|</span><a href="#40870289">next</a><span>|</span><label class="collapse" for="c-40866974">[-]</label><label class="expand" for="c-40866974">[2 more]</label></div><br/><div class="children"><div class="content">And this will screw up program execution more profoundly (i.e.crash) on systems with architectural shadow call stacks as a security feature.</div><br/><div id="40867926" class="c"><input type="checkbox" id="c-40867926" checked=""/><div class="controls bullet"><span class="by">astrobe_</span><span>|</span><a href="#40866726">root</a><span>|</span><a href="#40866974">parent</a><span>|</span><a href="#40870289">next</a><span>|</span><label class="collapse" for="c-40867926">[-]</label><label class="expand" for="c-40867926">[1 more]</label></div><br/><div class="children"><div class="content">Speaking of &quot;security feature&quot;, this insanely complex behavior (for a CPU) is a recipe for disasters like Specter and Meltdown.</div><br/></div></div></div></div></div></div><div id="40870289" class="c"><input type="checkbox" id="c-40870289" checked=""/><div class="controls bullet"><span class="by">croemer</span><span>|</span><a href="#40866726">prev</a><span>|</span><a href="#40869515">next</a><span>|</span><label class="collapse" for="c-40870289">[-]</label><label class="expand" for="c-40870289">[3 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t miss the 2023! The article really is already a little outdated: since Rust 1.78, the compiler uses some more aggressive loop unrolling (and a little bit of SIMD): <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;zhbobW7rr" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;zhbobW7rr</a><p>OP wrote: &quot;Looking at the assembly, it&#x27;s doing some loop unrolling.&quot;, linking to <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;Kv77abW6c" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;Kv77abW6c</a>, which is using &quot;Rust Nightly&quot;, a moving target. By now, there&#x27;s more loop unrolling.<p>Loop unrolling started with Rust 1.59: <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;5PTnWrWf7" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;5PTnWrWf7</a><p>Update: The code on Github shows they were using Rust version 1.67.0-nightly, 2022-11-27.</div><br/><div id="40870433" class="c"><input type="checkbox" id="c-40870433" checked=""/><div class="controls bullet"><span class="by">croemer</span><span>|</span><a href="#40870289">parent</a><span>|</span><a href="#40871186">next</a><span>|</span><label class="collapse" for="c-40870433">[-]</label><label class="expand" for="c-40870433">[1 more]</label></div><br/><div class="children"><div class="content">Rust 1.67.0, which is likely what OP was looking at, gives: <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;4Y61d9seh" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;4Y61d9seh</a><p>I ran the benchmarks locally on the same hardware, using latest nightly Rust 1.81 (aggressive loop unrolling): no difference. Same speed as 1.5 years ago.</div><br/></div></div><div id="40871186" class="c"><input type="checkbox" id="c-40871186" checked=""/><div class="controls bullet"><span class="by">mkeeter</span><span>|</span><a href="#40870289">parent</a><span>|</span><a href="#40870433">prev</a><span>|</span><a href="#40869515">next</a><span>|</span><label class="collapse" for="c-40871186">[-]</label><label class="expand" for="c-40871186">[1 more]</label></div><br/><div class="children"><div class="content">Good catch, I&#x27;ve updated the link to select Rust 1.67 specifically!</div><br/></div></div></div></div><div id="40869515" class="c"><input type="checkbox" id="c-40869515" checked=""/><div class="controls bullet"><span class="by">trealira</span><span>|</span><a href="#40870289">prev</a><span>|</span><a href="#40866666">next</a><span>|</span><label class="collapse" for="c-40869515">[-]</label><label class="expand" for="c-40869515">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised they didn&#x27;t try something less clever to optimize their code first. The assembly code could be rewritten like this, so the test requires one branch at the bottom of the loop instead of two (one to jump to the top and one to branch conditionally), as well as one instead of two ALU operations per loop for X1 (one subtraction to compare X1 to zero, and one to decrement X1, as opposed to using the result of the latter).<p><pre><code>      stp   x29, x30, [sp, #-16]!
      fmov s0, #0.0

      cbnz x1, exit &#x2F;&#x2F; Skip loop if x1 == 0.
  loop:
      ldr s1, [x0], #4
  
      bl foo
      &#x2F;&#x2F; Decrement x1. If x1 != 0, repeat the loop.
      subs x1, x1, #1
      b.ne loop
      &#x2F;&#x2F; Fall through to exit after the loop finishes.
  exit:
      ldp   x29, x30, [sp], #16
      ret
  
  foo:
      &#x2F;&#x2F; ...
      ret

</code></pre>
Going further, you could just inline foo and omit the RET instruction without doing any trickery with mismatched BL and RET instructions.<p>I haven&#x27;t benchmarked this, though, so I don&#x27;t actually know how much this speeds the code up.</div><br/><div id="40870441" class="c"><input type="checkbox" id="c-40870441" checked=""/><div class="controls bullet"><span class="by">trealira</span><span>|</span><a href="#40869515">parent</a><span>|</span><a href="#40866666">next</a><span>|</span><label class="collapse" for="c-40870441">[-]</label><label class="expand" for="c-40870441">[1 more]</label></div><br/><div class="children"><div class="content">Typo: that line with &quot;cbnz&quot; should be &quot;cbz&quot;. The CBZ instruction branches to a label if a register is zero, and CBNZ branches if the register isn&#x27;t zero.</div><br/></div></div></div></div><div id="40866666" class="c"><input type="checkbox" id="c-40866666" checked=""/><div class="controls bullet"><span class="by">CrazyStat</span><span>|</span><a href="#40869515">prev</a><span>|</span><a href="#40868133">next</a><span>|</span><label class="collapse" for="c-40866666">[-]</label><label class="expand" for="c-40866666">[2 more]</label></div><br/><div class="children"><div class="content">(2023)<p>Discussion at the time: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34520498">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34520498</a></div><br/><div id="40867793" class="c"><input type="checkbox" id="c-40867793" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#40866666">parent</a><span>|</span><a href="#40868133">next</a><span>|</span><label class="collapse" for="c-40867793">[-]</label><label class="expand" for="c-40867793">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! Macroexpanded:<p><i>Do not taunt happy fun branch predictor</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34520498">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34520498</a> - Jan 2023 (171 comments)<p>(Reposts are fine after a year or so; links to past threads are just to satisfy extra-curious readers)</div><br/></div></div></div></div><div id="40868133" class="c"><input type="checkbox" id="c-40868133" checked=""/><div class="controls bullet"><span class="by">monitron</span><span>|</span><a href="#40866666">prev</a><span>|</span><a href="#40871303">next</a><span>|</span><label class="collapse" for="c-40868133">[-]</label><label class="expand" for="c-40868133">[5 more]</label></div><br/><div class="children"><div class="content">This was a lovely article. I only wish the author wouldn’t have kept switching units (between µs and ns) making it hard to scan the tables for comparison.</div><br/><div id="40870498" class="c"><input type="checkbox" id="c-40870498" checked=""/><div class="controls bullet"><span class="by">cshimmin</span><span>|</span><a href="#40868133">parent</a><span>|</span><a href="#40869690">next</a><span>|</span><label class="collapse" for="c-40870498">[-]</label><label class="expand" for="c-40870498">[2 more]</label></div><br/><div class="children"><div class="content">They also switched from C to Rust halfway through the article, which was a bit jarring...</div><br/><div id="40871250" class="c"><input type="checkbox" id="c-40871250" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#40868133">root</a><span>|</span><a href="#40870498">parent</a><span>|</span><a href="#40869690">next</a><span>|</span><label class="collapse" for="c-40871250">[-]</label><label class="expand" for="c-40871250">[1 more]</label></div><br/><div class="children"><div class="content">It looks like that was an addendum that was added later and also benchmarked against the original C version</div><br/></div></div></div></div><div id="40869690" class="c"><input type="checkbox" id="c-40869690" checked=""/><div class="controls bullet"><span class="by">dmccarty</span><span>|</span><a href="#40868133">parent</a><span>|</span><a href="#40870498">prev</a><span>|</span><a href="#40871303">next</a><span>|</span><label class="collapse" for="c-40869690">[-]</label><label class="expand" for="c-40869690">[2 more]</label></div><br/><div class="children"><div class="content">1000ns = 1us :)</div><br/><div id="40869815" class="c"><input type="checkbox" id="c-40869815" checked=""/><div class="controls bullet"><span class="by">carl_dr</span><span>|</span><a href="#40868133">root</a><span>|</span><a href="#40869690">parent</a><span>|</span><a href="#40871303">next</a><span>|</span><label class="collapse" for="c-40869815">[-]</label><label class="expand" for="c-40869815">[1 more]</label></div><br/><div class="children"><div class="content">We know.<p>On a phone at normal reading distance, with the articles styling, it’s really hard to tell the difference between n and u without zooming, and the decimal points get lost - scanning the tables is hard.</div><br/></div></div></div></div></div></div><div id="40871303" class="c"><input type="checkbox" id="c-40871303" checked=""/><div class="controls bullet"><span class="by">Taniwha</span><span>|</span><a href="#40868133">prev</a><span>|</span><a href="#40866815">next</a><span>|</span><label class="collapse" for="c-40871303">[-]</label><label class="expand" for="c-40871303">[2 more]</label></div><br/><div class="children"><div class="content">I was working on an x86 clone back in the 90s (sadly never saw the light of day), one of the things I did early on was to write code to emulate various potential microarchitectural designs by capturing long streams of real world instructions - our real bugbear was one of the C++ compilers (used to compile a popular web browser from memory) that did virtual method dispatch by pushing an address onto the stack and returning to it - broke return predictors every time</div><br/><div id="40872223" class="c"><input type="checkbox" id="c-40872223" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40871303">parent</a><span>|</span><a href="#40866815">next</a><span>|</span><label class="collapse" for="c-40872223">[-]</label><label class="expand" for="c-40872223">[1 more]</label></div><br/><div class="children"><div class="content">I was confused as to why a compiler might do that.<p>Surely a jump to register would always be faster than writing it out to memory.<p>Then I remembered we are probably talking about 16bit code (for Win16), and that far pointers were a major thing. And turns out there is no &quot;far jump to register&quot; instruction in x86. The far jump instruction requires the 32bit pointer to be in memory.  I guess some clever compiler engineer came up with a trick to use two pushes and a far return instruction to avoid needing to allocate a temporary 32bit variable on the stack.<p>But that raises a deeper question: Why is this compiler using this clever &quot;far jump to value in register&quot; trick for virtual method dispatch? The full 32bit far pointer should already be sitting in the vtable, presumably it just loaded it from there? It would be a lot faster to just use the proper far jump instruction directly on the value in the vtable rather than loading it and writing it back out to the stack.<p>I suspect this compiler was deficient, and missing the optimisation that would avoid the need for this &quot;clever trick&quot; most of the time.</div><br/></div></div></div></div><div id="40866815" class="c"><input type="checkbox" id="c-40866815" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#40871303">prev</a><span>|</span><a href="#40868420">next</a><span>|</span><label class="collapse" for="c-40866815">[-]</label><label class="expand" for="c-40866815">[20 more]</label></div><br/><div class="children"><div class="content">Tangential question, perhaps a dumb one: why do most hardware schedulers try to predict the load on their own, instead of letting users explicitly signal their intent? It&#x27;s everywhere, from CPUs to storage.</div><br/><div id="40866958" class="c"><input type="checkbox" id="c-40866958" checked=""/><div class="controls bullet"><span class="by">pjc50</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40867383">next</a><span>|</span><label class="collapse" for="c-40866958">[-]</label><label class="expand" for="c-40866958">[3 more]</label></div><br/><div class="children"><div class="content">The user doesn&#x27;t know the capabilities of the system. In particular, anything compiled in is set in stone: you don&#x27;t know the capabilities of systems yet unbuilt. New systems don&#x27;t sell well unless they make existing code run faster, and sell badly if they require you to rebuild everything and make it non-backwards-compatible.<p>The peak example of &quot;let the user do the scheduling&quot; was Itanium, which had a VLIW system which scheduled three instructions at once. It was a huge commercial failure, and allowed AMD to instead define the instruction set people wanted: X64 is IA32 but wider and with more registers, but not substantially different and certainly not as weird as Itanium.</div><br/><div id="40867405" class="c"><input type="checkbox" id="c-40867405" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40866958">parent</a><span>|</span><a href="#40867383">next</a><span>|</span><label class="collapse" for="c-40867405">[-]</label><label class="expand" for="c-40867405">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve lost count of the times I&#x27;ve sped up some existing code by removing the hand-optimized assembly and just used a plain C implementation or similar. Sure, it was hand-optimized assembly, but for a 10+ year old CPU.<p>If you&#x27;re going to do hand-optimized code for a given platform, include the baseline code and measure at runtime to pick the implementation.</div><br/><div id="40868613" class="c"><input type="checkbox" id="c-40868613" checked=""/><div class="controls bullet"><span class="by">patmorgan23</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867405">parent</a><span>|</span><a href="#40867383">next</a><span>|</span><label class="collapse" for="c-40868613">[-]</label><label class="expand" for="c-40868613">[1 more]</label></div><br/><div class="children"><div class="content">Hand optimized assembly was necessary 30 years ago, and a good for several optimizations 20 years ago. But today&#x27;s computers are SO FAST, it&#x27;s just not necessary in most situations.</div><br/></div></div></div></div></div></div><div id="40867383" class="c"><input type="checkbox" id="c-40867383" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40866958">prev</a><span>|</span><a href="#40866913">next</a><span>|</span><label class="collapse" for="c-40867383">[-]</label><label class="expand" for="c-40867383">[5 more]</label></div><br/><div class="children"><div class="content">You should look into the history of Itanium, it was designed around the idea that the compiler would do pretty much exactly that. It looked great on paper, but in practice nobody figured out how to actually <i>write</i> a compiler capable of doing it without constantly running into weird edge cases.<p>X86 does have &quot;prefetch&quot; instructions, which tell the CPU that you want to use some data in the near future. There are also &quot;branch hint&quot; instructions which tell the CPU if a branch is usually taken or not. The problem is that they tend to make your code <i>slower</i>: the CPU is already more than capable of predicting it by itself, and the extra instructions slow down the overall execution because they take up cache space and have to be decoded too.</div><br/><div id="40869803" class="c"><input type="checkbox" id="c-40869803" checked=""/><div class="controls bullet"><span class="by">muziq</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867383">parent</a><span>|</span><a href="#40867634">next</a><span>|</span><label class="collapse" for="c-40869803">[-]</label><label class="expand" for="c-40869803">[1 more]</label></div><br/><div class="children"><div class="content">VLIW, they’re still out there, doing mad stuff.. VLIW is cool and as a DSP programmer I love&#x2F;live that time a VLIW comes my way :)<p><a href="https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2023&#x2F;10&#x2F;04&#x2F;qualcomms-hexagon-dsp-and-now-npu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2023&#x2F;10&#x2F;04&#x2F;qualcomms-hexagon-dsp-...</a></div><br/></div></div><div id="40867634" class="c"><input type="checkbox" id="c-40867634" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867383">parent</a><span>|</span><a href="#40869803">prev</a><span>|</span><a href="#40866913">next</a><span>|</span><label class="collapse" for="c-40867634">[-]</label><label class="expand" for="c-40867634">[3 more]</label></div><br/><div class="children"><div class="content">VLIW is pretty successful for loopy DSP and now AI&#x2F;ML. However, Itanium was trying to work for general purpose code and then as you say, it constantly ran into weird edge cases. It <i>seemed</i> as if VLIW succumbed to the Peter Principle, it had risen to its level of incompetence. But as long as you use it appropriately, VLIW is a best practice and LLVM supports it.<p>BTW, CS252 at Berkeley and Onur Mutlu&#x27;s ETH lectures give a conventionally disparaging view of VLIW without pointing out its successes.</div><br/><div id="40867874" class="c"><input type="checkbox" id="c-40867874" checked=""/><div class="controls bullet"><span class="by">bbatha</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867634">parent</a><span>|</span><a href="#40866913">next</a><span>|</span><label class="collapse" for="c-40867874">[-]</label><label class="expand" for="c-40867874">[2 more]</label></div><br/><div class="children"><div class="content">Adding on, VLIW is only successful in AI&#x2F;ML because GPUs are incapable of doing branching in a good way let alone prediction. I would guess the same story applies to DSPs. If someone figures out how to stick a branch predictor in those pipelines Im guessing the VLIW nature of those platforms will disappear overnight.</div><br/><div id="40868397" class="c"><input type="checkbox" id="c-40868397" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867874">parent</a><span>|</span><a href="#40866913">next</a><span>|</span><label class="collapse" for="c-40868397">[-]</label><label class="expand" for="c-40868397">[1 more]</label></div><br/><div class="children"><div class="content">The defining character of VLIW is to have the brilliant compiler software schedule dumb parallel hardware instructions <i>statically</i> and then not depend on power&#x2F;transistor expensive dynamic branch prediction and OOO execution.<p>In a perfect VLIW world that would mean you don&#x27;t spend any transistors or power on branch prediction or out of order instruction searches. Indeed the original VLIW paper [1] spends vastly most its paragraphs on solving the (hard) compiler instruction scheduling problem with trace scheduling which is still used. The VLIW hardware itself is dead simple.<p>[1] <a href="https:&#x2F;&#x2F;safari.ethz.ch&#x2F;architecture&#x2F;fall2022&#x2F;lib&#x2F;exe&#x2F;fetch.php?media=p140-fisher.pdf" rel="nofollow">https:&#x2F;&#x2F;safari.ethz.ch&#x2F;architecture&#x2F;fall2022&#x2F;lib&#x2F;exe&#x2F;fetch.p...</a><p>So if VLIW fits the problem it has fantastic performance characteristics. If it doesn&#x27;t fit, and far and away most don&#x27;t, then VLIW is terrible. VLIW is very brittle.<p>I need to make a caveat about the Mill CPU which is a VLIW but I see I&#x27;ve written too much already.</div><br/></div></div></div></div></div></div></div></div><div id="40866913" class="c"><input type="checkbox" id="c-40866913" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40867383">prev</a><span>|</span><a href="#40866876">next</a><span>|</span><label class="collapse" for="c-40866913">[-]</label><label class="expand" for="c-40866913">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s supported by some CPUs: the linux kernel has likely&#x2F;unlikely macros to indicate whether a branch is expected to be taken or not in the common case (which uses GCC attributes which allow this to be propagated through to codegen). It&#x27;s just that it&#x27;s generally less effective: firstly because not all branches get annotated, some that are annotated are annotated incorrectly, and in a lot of cases the branching behaviour is data-dependent enough that you can&#x27;t make an optimal static prediction at all.</div><br/></div></div><div id="40866876" class="c"><input type="checkbox" id="c-40866876" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40866913">prev</a><span>|</span><a href="#40872331">next</a><span>|</span><label class="collapse" for="c-40866876">[-]</label><label class="expand" for="c-40866876">[1 more]</label></div><br/><div class="children"><div class="content">1. &quot;Explicitly signaling your intent&quot; takes space and time. Decoding isn&#x27;t free, and even if there were no other downsides you&#x27;d want to be careful with that change.<p>2. It&#x27;s a bit historical. Early CPUs didn&#x27;t have a RAM&#x2F;CPU discrepancy and didn&#x27;t need pipelining. Code wasn&#x27;t written to account for pipelining. As CPUs got a little faster relative to RAM, you added a few prediction mechanisms so that most consumers and workloads could actually use your brand new 2x faster gigaterrawatthournewton CPUs without having to rewrite all their code. Iterate 10-20 generations, where most software has never been written to care about branch prediction and where modern languages don&#x27;t even expose the concept, and you have the current status quo.</div><br/></div></div><div id="40872331" class="c"><input type="checkbox" id="c-40872331" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40866876">prev</a><span>|</span><a href="#40867751">next</a><span>|</span><label class="collapse" for="c-40872331">[-]</label><label class="expand" for="c-40872331">[1 more]</label></div><br/><div class="children"><div class="content">Because it can&#x27;t actually see that return instruction until way too late.<p>Apple M1 CPU here loads and decodes 8 instructions per cycle, and the instruction cache access, plus the decoding takes multiple cycles. I don&#x27;t know exactly how many cycles (more cycles allow for bigger instruction caches, and Apple gave the M1 a massive 192KB instruction cache), but the absolute minimum is 3 cycles.<p>And until the instruction is decoded, it has no idea that there is even a return instruction there.<p>3 cycles at 8 instructions per cycle is a full 24 instructions, so the M1 CPU will be a full 24 instructions past the return before it even knows the return exists. The loop body in this article is only 7 instructions long, so overrunning by an extra 24 instructions on every iteration of the loop would be a massive performance hit.<p>What actually happens is that the branch predictor remembers the fact that there is a return at that address, and on the very next cycle after starting the icache fetch of the return instruction, it pops the return address of it&#x27;s return address prediction stack and starts fetching code from there.<p>For short functions, the branch predictor might need to follow the call on one cycle, and the return on the next cycle. The call instruction hasn&#x27;t even finished decoding yet, but the branch predictor has already executed both the call and the return.</div><br/></div></div><div id="40867751" class="c"><input type="checkbox" id="c-40867751" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40872331">prev</a><span>|</span><a href="#40866846">next</a><span>|</span><label class="collapse" for="c-40867751">[-]</label><label class="expand" for="c-40867751">[2 more]</label></div><br/><div class="children"><div class="content">GCC has the _builtin_expect macro to give hint for branch prediction. C++ has added something similar recently       .</div><br/><div id="40869242" class="c"><input type="checkbox" id="c-40869242" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867751">parent</a><span>|</span><a href="#40866846">next</a><span>|</span><label class="collapse" for="c-40869242">[-]</label><label class="expand" for="c-40869242">[1 more]</label></div><br/><div class="children"><div class="content">These are usually for the compiler rather than the CPU e.g. I don&#x27;t want my error-handling code inlined! (But the compiler can&#x27;t work this out without a hint)</div><br/></div></div></div></div><div id="40866846" class="c"><input type="checkbox" id="c-40866846" checked=""/><div class="controls bullet"><span class="by">082349872349872</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40867751">prev</a><span>|</span><a href="#40867204">next</a><span>|</span><label class="collapse" for="c-40866846">[-]</label><label class="expand" for="c-40866846">[3 more]</label></div><br/><div class="children"><div class="content">In this case, I&#x27;d consider BL (call) a fairly explicit signal of intent to RET?</div><br/><div id="40867017" class="c"><input type="checkbox" id="c-40867017" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40866846">parent</a><span>|</span><a href="#40867204">next</a><span>|</span><label class="collapse" for="c-40867017">[-]</label><label class="expand" for="c-40867017">[2 more]</label></div><br/><div class="children"><div class="content">Yep. For returns, the more important thing in the article, the &quot;ret&quot;[0] instruction behaves exactly identically to &quot;br x30&quot;[1], just with the hint that it&#x27;s expected to match a &quot;bl&quot;.<p>On x86 things are less pretty as call&#x2F;ret push&#x2F;pop the ip from the stack, with no non-matching-hinted versions, but having such would also just not be particularly useful as unpaired call&#x2F;ret would result in the stack pointer continually drifting without manual fixup (at which point jmp is just clearly better).<p>[0]: <a href="https:&#x2F;&#x2F;developer.arm.com&#x2F;documentation&#x2F;dui0802&#x2F;a&#x2F;A64-General-Instructions&#x2F;RET" rel="nofollow">https:&#x2F;&#x2F;developer.arm.com&#x2F;documentation&#x2F;dui0802&#x2F;a&#x2F;A64-Genera...</a><p>[1]: <a href="https:&#x2F;&#x2F;developer.arm.com&#x2F;documentation&#x2F;dui0802&#x2F;a&#x2F;A64-General-Instructions&#x2F;BR?lang=en" rel="nofollow">https:&#x2F;&#x2F;developer.arm.com&#x2F;documentation&#x2F;dui0802&#x2F;a&#x2F;A64-Genera...</a></div><br/><div id="40868610" class="c"><input type="checkbox" id="c-40868610" checked=""/><div class="controls bullet"><span class="by">LegionMammal978</span><span>|</span><a href="#40866815">root</a><span>|</span><a href="#40867017">parent</a><span>|</span><a href="#40867204">next</a><span>|</span><label class="collapse" for="c-40868610">[-]</label><label class="expand" for="c-40868610">[1 more]</label></div><br/><div class="children"><div class="content">On 32-bit x86, there is the trap of trying to use call&#x2F;pop to get the absolute instruction pointer. It will work correctly, but it will mess up any call stack prediction and cause great performance penalties. Hence why compiler-generated EIP shims use call&#x2F;mov&#x2F;ret instead. (But this is not such a big issue in x86-64 with its RIP-relative addressing.)</div><br/></div></div></div></div></div></div><div id="40867204" class="c"><input type="checkbox" id="c-40867204" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40866846">prev</a><span>|</span><a href="#40867328">next</a><span>|</span><label class="collapse" for="c-40867204">[-]</label><label class="expand" for="c-40867204">[1 more]</label></div><br/><div class="children"><div class="content">Often, but not always, optimal scheduling is data dependent so it can&#x27;t be statically computed at compile time.</div><br/></div></div><div id="40867328" class="c"><input type="checkbox" id="c-40867328" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40867204">prev</a><span>|</span><a href="#40867366">next</a><span>|</span><label class="collapse" for="c-40867328">[-]</label><label class="expand" for="c-40867328">[1 more]</label></div><br/><div class="children"><div class="content">They want to be able to guess long, long, before actually executing the instructions.</div><br/></div></div><div id="40867366" class="c"><input type="checkbox" id="c-40867366" checked=""/><div class="controls bullet"><span class="by">hindsightbias</span><span>|</span><a href="#40866815">parent</a><span>|</span><a href="#40867328">prev</a><span>|</span><a href="#40868420">next</a><span>|</span><label class="collapse" for="c-40867366">[-]</label><label class="expand" for="c-40867366">[1 more]</label></div><br/><div class="children"><div class="content">We could solve a lot of problems if every user had to take EE180.</div><br/></div></div></div></div><div id="40868420" class="c"><input type="checkbox" id="c-40868420" checked=""/><div class="controls bullet"><span class="by">nayuki</span><span>|</span><a href="#40866815">prev</a><span>|</span><a href="#40868130">next</a><span>|</span><label class="collapse" for="c-40868420">[-]</label><label class="expand" for="c-40868420">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Why do we need a special function return instruction? Functionally, BR LR would do the same job as RET. Using RET tells the processor that this is a function return.<p>I&#x27;m not sure this is a good design. Those two opcodes perform the same logic function but have different branch prediction hints.<p>Meanwhile, there are other cases where an existing instruction is reinterpreted with new semantics:<p>* On x86, `XCHG eax, eax` is `NOP`.<p>* On x86, `XOR reg, reg` is `MOV reg, 0` and breaks dependencies for the purposes of register renaming.<p>* On x86, various examples of macro-op fusion and micro-op fusion.<p>* On various RISC architectures, `ADD r1, r0, 1234` is `MOV r1, 1234`.<p>* On some RISC architectures, conditionally branching if r0 == 0 is the only way to express an unconditional branch.<p>I see no reason why `BR LR` can&#x27;t be the standard function return instruction and involve the branch predictor.</div><br/><div id="40869050" class="c"><input type="checkbox" id="c-40869050" checked=""/><div class="controls bullet"><span class="by">zerohp</span><span>|</span><a href="#40868420">parent</a><span>|</span><a href="#40868130">next</a><span>|</span><label class="collapse" for="c-40869050">[-]</label><label class="expand" for="c-40869050">[1 more]</label></div><br/><div class="children"><div class="content">In AArch64, `BR LR` and `RET` do not perform the same logic when FEAT_BTI (Branch Target Identification) is present.</div><br/></div></div></div></div><div id="40868130" class="c"><input type="checkbox" id="c-40868130" checked=""/><div class="controls bullet"><span class="by">samatman</span><span>|</span><a href="#40868420">prev</a><span>|</span><a href="#40868791">next</a><span>|</span><label class="collapse" for="c-40868130">[-]</label><label class="expand" for="c-40868130">[1 more]</label></div><br/><div class="children"><div class="content">Everything I know, or need to know, about branch prediction, I learned from James Mickens.<p><a href="https:&#x2F;&#x2F;scholar.harvard.edu&#x2F;files&#x2F;mickens&#x2F;files&#x2F;theslowwinter.pdf" rel="nofollow">https:&#x2F;&#x2F;scholar.harvard.edu&#x2F;files&#x2F;mickens&#x2F;files&#x2F;theslowwinte...</a></div><br/></div></div><div id="40868791" class="c"><input type="checkbox" id="c-40868791" checked=""/><div class="controls bullet"><span class="by">38</span><span>|</span><a href="#40868130">prev</a><span>|</span><a href="#40866964">next</a><span>|</span><label class="collapse" for="c-40868791">[-]</label><label class="expand" for="c-40868791">[1 more]</label></div><br/><div class="children"><div class="content">&gt; const float f = *data++;<p>cursed code. people might say &quot;oh that&#x27;s normal idiomatic C&quot;, I don&#x27;t care. I am glad Go does not allow code like this</div><br/></div></div><div id="40866964" class="c"><input type="checkbox" id="c-40866964" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#40868791">prev</a><span>|</span><a href="#40866916">next</a><span>|</span><label class="collapse" for="c-40866964">[-]</label><label class="expand" for="c-40866964">[4 more]</label></div><br/><div class="children"><div class="content">Yeah. This effect is why, also, using a bare CALL without a RET ends up being a slow way to get the program counter on 32-bit x86, which lacks native PC-relative addressing: it confuses the CPU&#x27;s tracking of calls and returns. Basically, you always want to balance them. No exceptions.</div><br/><div id="40867230" class="c"><input type="checkbox" id="c-40867230" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40866964">parent</a><span>|</span><a href="#40866916">next</a><span>|</span><label class="collapse" for="c-40867230">[-]</label><label class="expand" for="c-40867230">[3 more]</label></div><br/><div class="children"><div class="content">Wasn&#x27;t an article posted a few days ago showing that CPUs special case. CALL+0 not to update the prediction stack as it was commonly used to get IP?</div><br/><div id="40868391" class="c"><input type="checkbox" id="c-40868391" checked=""/><div class="controls bullet"><span class="by">rep_lodsb</span><span>|</span><a href="#40866964">root</a><span>|</span><a href="#40867230">parent</a><span>|</span><a href="#40868632">next</a><span>|</span><label class="collapse" for="c-40868391">[-]</label><label class="expand" for="c-40868391">[1 more]</label></div><br/><div class="children"><div class="content">Yes: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40767676">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40767676</a></div><br/></div></div><div id="40868632" class="c"><input type="checkbox" id="c-40868632" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#40866964">root</a><span>|</span><a href="#40867230">parent</a><span>|</span><a href="#40868391">prev</a><span>|</span><a href="#40866916">next</a><span>|</span><label class="collapse" for="c-40868632">[-]</label><label class="expand" for="c-40868632">[1 more]</label></div><br/><div class="children"><div class="content">Okay, fair enough. It <i>used</i> to be a pessimization before CPUs recognized that pattern. :-)</div><br/></div></div></div></div></div></div><div id="40866916" class="c"><input type="checkbox" id="c-40866916" checked=""/><div class="controls bullet"><span class="by">petsounds</span><span>|</span><a href="#40866964">prev</a><span>|</span><a href="#40869145">next</a><span>|</span><label class="collapse" for="c-40866916">[-]</label><label class="expand" for="c-40866916">[2 more]</label></div><br/><div class="children"><div class="content">The title of this article is a reference to &quot;Happy Fun Ball&quot;, my favorite SNL skit: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GmqeZl8OI2M" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GmqeZl8OI2M</a></div><br/></div></div></div></div></div></div></div></body></html>