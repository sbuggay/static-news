<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700125279412" as="style"/><link rel="stylesheet" href="styles.css?v=1700125279412"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.newyorker.com/humor/sketchbook/is-my-toddler-a-stochastic-parrot">Is my toddler a stochastic parrot?</a> <span class="domain">(<a href="https://www.newyorker.com">www.newyorker.com</a>)</span></div><div class="subtext"><span>zwieback</span> | <span>258 comments</span></div><br/><div><div id="38283435" class="c"><input type="checkbox" id="c-38283435" checked=""/><div class="controls bullet"><span class="by">dsQTbR7Y5mRHnZv</span><span>|</span><a href="#38282378">next</a><span>|</span><label class="collapse" for="c-38283435">[-]</label><label class="expand" for="c-38283435">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;AUOPt" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;AUOPt</a></div><br/></div></div><div id="38282378" class="c"><input type="checkbox" id="c-38282378" checked=""/><div class="controls bullet"><span class="by">throw0101a</span><span>|</span><a href="#38283435">prev</a><span>|</span><a href="#38286629">next</a><span>|</span><label class="collapse" for="c-38282378">[-]</label><label class="expand" for="c-38282378">[45 more]</label></div><br/><div class="children"><div class="content">&gt; <i>But he could understand so much more than he could say. If you asked him to point to the vacuum cleaner, he would.</i><p>Perhaps worth noting that it is possible to teach infants (often starting at around 9 months) sign language so that they can more easily signal their desires.<p>Some priority recommended words would probably be:<p>* hungry&#x2F;more<p>* enough&#x2F;all done (for when they&#x27;re full)<p>* drink (perhaps both milk&#x2F;formula and water† gestures)<p>See:<p>* <a href="https:&#x2F;&#x2F;babysignlanguage.com&#x2F;chart&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;babysignlanguage.com&#x2F;chart&#x2F;</a><p>* <a href="https:&#x2F;&#x2F;www.thebump.com&#x2F;a&#x2F;how-to-teach-baby-sign-language" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.thebump.com&#x2F;a&#x2F;how-to-teach-baby-sign-language</a><p>These are not (AFAICT) &#x27;special&#x27; symbols for babies, but the regular ASL gestures for the work in question. If you&#x27;re not native English-speaking you&#x27;d look up the gestures in your specific region&#x2F;language&#x27;s sign language:<p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_sign_languages" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_sign_languages</a><p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sign_language" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sign_language</a><p>† Another handy trick I&#x27;ve run across: have different coloured containers for milk and water, and consistently put the same contents in each one. That way the infant learns to grab a particular colour depending on what they&#x27;re feeling like.</div><br/><div id="38285602" class="c"><input type="checkbox" id="c-38285602" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38282904">next</a><span>|</span><label class="collapse" for="c-38285602">[-]</label><label class="expand" for="c-38285602">[8 more]</label></div><br/><div class="children"><div class="content">We taught both our kids to sign.<p>My favourite moment was in March, my daughter was about to turn 2 and wasn&#x27;t speaking yet.<p>I asked her if she would like to hear some music.<p>She made the sign for dog.<p>I searched youtube for some songs about dogs and she shook her head.<p>She made the sign for tree.<p>I was like &quot;dog, tree&quot;, she nodded. Hmmm...<p>I was searching for &quot;dog tree music&quot; when one of the pictures that came up was a christmas tree.<p>She pointed to that excitedly!<p>I was like &quot;dog christmas tree music&quot; ... it took me a second to realise that she wanted to listen to the Charlie Brown Christmas soundtrack that I had had playing off YouTube at Christmas 3 months previously!<p>I put that on again and we danced around to it.<p>I thought that was totally wild! It was the first time I remember her communicating a really sophisticated preference other than just wanting to eat&#x2F;drink&#x2F;help etc.</div><br/><div id="38285754" class="c"><input type="checkbox" id="c-38285754" checked=""/><div class="controls bullet"><span class="by">hammock</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38285602">parent</a><span>|</span><a href="#38282904">next</a><span>|</span><label class="collapse" for="c-38285754">[-]</label><label class="expand" for="c-38285754">[7 more]</label></div><br/><div class="children"><div class="content">This must have been what it was like when the settlers were trying to communicate with native Americans at first</div><br/><div id="38287124" class="c"><input type="checkbox" id="c-38287124" checked=""/><div class="controls bullet"><span class="by">lotsofcows</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38285754">parent</a><span>|</span><a href="#38286905">next</a><span>|</span><label class="collapse" for="c-38287124">[-]</label><label class="expand" for="c-38287124">[1 more]</label></div><br/><div class="children"><div class="content">The settlers were greeted by English speaking native Americans who had been working the shipping trade.</div><br/></div></div><div id="38286905" class="c"><input type="checkbox" id="c-38286905" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38285754">parent</a><span>|</span><a href="#38287124">prev</a><span>|</span><a href="#38286907">next</a><span>|</span><label class="collapse" for="c-38286905">[-]</label><label class="expand" for="c-38286905">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately, the settlers never really got what the native Americans were trying to say.</div><br/></div></div><div id="38286907" class="c"><input type="checkbox" id="c-38286907" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38285754">parent</a><span>|</span><a href="#38286905">prev</a><span>|</span><a href="#38286061">next</a><span>|</span><label class="collapse" for="c-38286907">[-]</label><label class="expand" for="c-38286907">[2 more]</label></div><br/><div class="children"><div class="content">Which group is the toddler here?</div><br/><div id="38286933" class="c"><input type="checkbox" id="c-38286933" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38286907">parent</a><span>|</span><a href="#38286061">next</a><span>|</span><label class="collapse" for="c-38286933">[-]</label><label class="expand" for="c-38286933">[1 more]</label></div><br/><div class="children"><div class="content">One group had an advanced democratic government of the people which the other group struggled to learn from: <a href="https:&#x2F;&#x2F;www.sciencenews.org&#x2F;article&#x2F;democracy-indigenous-americans-people-rule-muscogee" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sciencenews.org&#x2F;article&#x2F;democracy-indigenous-ame...</a></div><br/></div></div></div></div><div id="38286061" class="c"><input type="checkbox" id="c-38286061" checked=""/><div class="controls bullet"><span class="by">LNSY</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38285754">parent</a><span>|</span><a href="#38286907">prev</a><span>|</span><a href="#38282904">next</a><span>|</span><label class="collapse" for="c-38286061">[-]</label><label class="expand" for="c-38286061">[2 more]</label></div><br/><div class="children"><div class="content">And then the genocide started</div><br/></div></div></div></div></div></div><div id="38282904" class="c"><input type="checkbox" id="c-38282904" checked=""/><div class="controls bullet"><span class="by">brainbag</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38285602">prev</a><span>|</span><a href="#38282507">next</a><span>|</span><label class="collapse" for="c-38282904">[-]</label><label class="expand" for="c-38282904">[10 more]</label></div><br/><div class="children"><div class="content">I had heard about this before my son was born. We didn&#x27;t try to teach him anything, anytime we remembered (which was sporadic) we just used the gestures when talking to him. I was amazed at how quickly he picked up on it, and he was able to communicate his needs to us months before he was able to verbalize.<p>It took very minimal effort on our part, and was very rewarding for him; certainly a lot better than him crying with the hope that we could guess what he wanted. Definitely recommended for any new parents.<p>The best moment was when he was sitting on the floor, and looked up at his mom and made the &quot;together&quot; sign, it was heart melting.</div><br/><div id="38286817" class="c"><input type="checkbox" id="c-38286817" checked=""/><div class="controls bullet"><span class="by">jjeaff</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282904">parent</a><span>|</span><a href="#38283271">next</a><span>|</span><label class="collapse" for="c-38286817">[-]</label><label class="expand" for="c-38286817">[1 more]</label></div><br/><div class="children"><div class="content">I love seeing how language develops in my kids and how they start to invent ways to communicate. Our first, she would say &quot;hold you&quot; when she wanted to be picked up, which she learned from us saying &quot;do you want me to hold you?&quot; My 2 year old now says &quot;huggy&quot; when he wants to be picked up.</div><br/></div></div><div id="38283271" class="c"><input type="checkbox" id="c-38283271" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282904">parent</a><span>|</span><a href="#38286817">prev</a><span>|</span><a href="#38285381">next</a><span>|</span><label class="collapse" for="c-38283271">[-]</label><label class="expand" for="c-38283271">[7 more]</label></div><br/><div class="children"><div class="content">In other words, you can invent your own sign language because your child won&#x27;t need to use it with other people.</div><br/><div id="38283767" class="c"><input type="checkbox" id="c-38283767" checked=""/><div class="controls bullet"><span class="by">AlecSchueler</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283271">parent</a><span>|</span><a href="#38284909">next</a><span>|</span><label class="collapse" for="c-38283767">[-]</label><label class="expand" for="c-38283767">[4 more]</label></div><br/><div class="children"><div class="content">Why not use a common sign language and give then a head start if they ever do want to use it outside the family?</div><br/><div id="38283866" class="c"><input type="checkbox" id="c-38283866" checked=""/><div class="controls bullet"><span class="by">skeaker</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283767">parent</a><span>|</span><a href="#38284909">next</a><span>|</span><label class="collapse" for="c-38283866">[-]</label><label class="expand" for="c-38283866">[3 more]</label></div><br/><div class="children"><div class="content">They might not have the dexterity required for some of the more complex signs, I would guess. If you devise your own gestures they can be much simpler.</div><br/><div id="38284986" class="c"><input type="checkbox" id="c-38284986" checked=""/><div class="controls bullet"><span class="by">doubleg72</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283866">parent</a><span>|</span><a href="#38284819">next</a><span>|</span><label class="collapse" for="c-38284986">[-]</label><label class="expand" for="c-38284986">[1 more]</label></div><br/><div class="children"><div class="content">No, the basics like hungry and please&#x2F;thank you are fairly simple.  The daycare my son goes to teaches all the kids sign language starting at like 6 months.</div><br/></div></div><div id="38284819" class="c"><input type="checkbox" id="c-38284819" checked=""/><div class="controls bullet"><span class="by">schwartzworld</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283866">parent</a><span>|</span><a href="#38284986">prev</a><span>|</span><a href="#38284909">next</a><span>|</span><label class="collapse" for="c-38284819">[-]</label><label class="expand" for="c-38284819">[1 more]</label></div><br/><div class="children"><div class="content">The signs chosen to teach to babies tend to be pretty simple. Things like &quot;more&quot; or &quot;milk&quot; are very easy.</div><br/></div></div></div></div></div></div><div id="38284909" class="c"><input type="checkbox" id="c-38284909" checked=""/><div class="controls bullet"><span class="by">jimmygrapes</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283271">parent</a><span>|</span><a href="#38283767">prev</a><span>|</span><a href="#38285381">next</a><span>|</span><label class="collapse" for="c-38284909">[-]</label><label class="expand" for="c-38284909">[2 more]</label></div><br/><div class="children"><div class="content">plus you can use it as a battle language for your clan</div><br/><div id="38286696" class="c"><input type="checkbox" id="c-38286696" checked=""/><div class="controls bullet"><span class="by">rcbdev</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38284909">parent</a><span>|</span><a href="#38285381">next</a><span>|</span><label class="collapse" for="c-38286696">[-]</label><label class="expand" for="c-38286696">[1 more]</label></div><br/><div class="children"><div class="content">Exactly! Using a pre-made sign language is missing the point entirely...</div><br/></div></div></div></div></div></div><div id="38285381" class="c"><input type="checkbox" id="c-38285381" checked=""/><div class="controls bullet"><span class="by">soks86</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282904">parent</a><span>|</span><a href="#38283271">prev</a><span>|</span><a href="#38282507">next</a><span>|</span><label class="collapse" for="c-38285381">[-]</label><label class="expand" for="c-38285381">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not crying, you&#x27;re crying!</div><br/></div></div></div></div><div id="38282507" class="c"><input type="checkbox" id="c-38282507" checked=""/><div class="controls bullet"><span class="by">yojo</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38282904">prev</a><span>|</span><a href="#38283709">next</a><span>|</span><label class="collapse" for="c-38282507">[-]</label><label class="expand" for="c-38282507">[12 more]</label></div><br/><div class="children"><div class="content">FWIW, I tried this with both my sons. They both started using the gestures the same day they started actually talking :-&#x2F;<p>I have friends who had much more success with it, but the value will largely depend on your child’s relative developmental strengths. A friend’s son with autism got literally years’ benefit out of the gestures before verbal speech caught up.</div><br/><div id="38282585" class="c"><input type="checkbox" id="c-38282585" checked=""/><div class="controls bullet"><span class="by">kuchenbecker</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38282686">next</a><span>|</span><label class="collapse" for="c-38282585">[-]</label><label class="expand" for="c-38282585">[1 more]</label></div><br/><div class="children"><div class="content">My kids both picked it up, but my younger was similar. Being able to sign &quot;please&quot; and &quot;all done&quot; helps anyway because &quot;eeess&quot; and &quot;a ya&quot; are what she actually says.</div><br/></div></div><div id="38282686" class="c"><input type="checkbox" id="c-38282686" checked=""/><div class="controls bullet"><span class="by">thealfreds</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38282585">prev</a><span>|</span><a href="#38282595">next</a><span>|</span><label class="collapse" for="c-38282686">[-]</label><label class="expand" for="c-38282686">[1 more]</label></div><br/><div class="children"><div class="content">Same with my nephew. He also has autism and the first thing the speech therapist did when he was 3 was teach him simple sign language. It became such a great catalyst for communication. He&#x27;s nowhere near his his age (now 6) developmentally but within ~6 weeks he went from completely non-verbal to actually vocalizing the simple words he learned the sign language for.</div><br/></div></div><div id="38282595" class="c"><input type="checkbox" id="c-38282595" checked=""/><div class="controls bullet"><span class="by">throw0101a</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38282686">prev</a><span>|</span><a href="#38286391">next</a><span>|</span><label class="collapse" for="c-38282595">[-]</label><label class="expand" for="c-38282595">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>FWIW, I tried this with both my sons. They both started using the gestures the same day they started actually talking :-&#x2F;</i><p>Could still useful: instead of shouting across the playground on whether they have to go potty you can simply make the gesture with minimal embarrassment. :)</div><br/><div id="38283105" class="c"><input type="checkbox" id="c-38283105" checked=""/><div class="controls bullet"><span class="by">vel0city</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282595">parent</a><span>|</span><a href="#38282860">next</a><span>|</span><label class="collapse" for="c-38283105">[-]</label><label class="expand" for="c-38283105">[2 more]</label></div><br/><div class="children"><div class="content">I also usually had success with signs when the child was otherwise too emotional to verbalize their desire. They&#x27;re really upset and crying hard so it is hard to talk especially when talking clearly is already a challenge, but signing &quot;milk&quot; or &quot;eat&quot; or &quot;hurt&quot; or &quot;more&quot; can come through easily.</div><br/><div id="38284925" class="c"><input type="checkbox" id="c-38284925" checked=""/><div class="controls bullet"><span class="by">jtr1</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283105">parent</a><span>|</span><a href="#38282860">next</a><span>|</span><label class="collapse" for="c-38284925">[-]</label><label class="expand" for="c-38284925">[1 more]</label></div><br/><div class="children"><div class="content">Wow I had not considered this at all. We used a bit of sign language before my toddler started talking, but have more recently run into these situations where big feelings are crowding out speech and it’d be useful to get anything through. I’ll give this a shot tomorrow</div><br/></div></div></div></div><div id="38282860" class="c"><input type="checkbox" id="c-38282860" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282595">parent</a><span>|</span><a href="#38283105">prev</a><span>|</span><a href="#38283687">next</a><span>|</span><label class="collapse" for="c-38282860">[-]</label><label class="expand" for="c-38282860">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, a handful of signs is useful for adults in many situations where voice comms don&#x27;t work. And, at least in my circles, there&#x27;s a small shared vocabulary of signs that there&#x27;s a good chance will work. Potty, ouch, sleep, eat, maybe a couple more.</div><br/></div></div><div id="38283687" class="c"><input type="checkbox" id="c-38283687" checked=""/><div class="controls bullet"><span class="by">petsfed</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282595">parent</a><span>|</span><a href="#38282860">prev</a><span>|</span><a href="#38286391">next</a><span>|</span><label class="collapse" for="c-38283687">[-]</label><label class="expand" for="c-38283687">[1 more]</label></div><br/><div class="children"><div class="content">Tread carefully: the sign for poop looks close enough to a crude gesture (cruder than just shouting &quot;poop&quot; at a playground, as it turns out) that an ignorant bystander might take it significantly wrongly.</div><br/></div></div></div></div><div id="38286391" class="c"><input type="checkbox" id="c-38286391" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38282595">prev</a><span>|</span><a href="#38282688">next</a><span>|</span><label class="collapse" for="c-38286391">[-]</label><label class="expand" for="c-38286391">[1 more]</label></div><br/><div class="children"><div class="content">The gestures also help disambiguate some words. Sometimes it&#x27;s hard to tell the difference between &quot;Mama&quot;, &quot;More&quot; and &quot;Milk&quot; the way my toddler pronounces them, but her gestures make it clear...</div><br/></div></div><div id="38282688" class="c"><input type="checkbox" id="c-38282688" checked=""/><div class="controls bullet"><span class="by">ASalazarMX</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38286391">prev</a><span>|</span><a href="#38285521">next</a><span>|</span><label class="collapse" for="c-38282688">[-]</label><label class="expand" for="c-38282688">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s probably variation among babies. One of my nephews would examine his feet if you asked them where are his shoes, even before walking. He got so proficient with signs that it delayed talking; he preferred signaling and grunting :&#x2F;</div><br/><div id="38284421" class="c"><input type="checkbox" id="c-38284421" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282688">parent</a><span>|</span><a href="#38285521">next</a><span>|</span><label class="collapse" for="c-38284421">[-]</label><label class="expand" for="c-38284421">[1 more]</label></div><br/><div class="children"><div class="content">&gt; He got so proficient with signs that it delayed talking; he preferred signaling and grunting :&#x2F;<p>Please don&#x27;t blame this on the signs! This doesn&#x27;t mean that he would have learned to speak earlier if not for the signs. I&#x27;d be glad that he could communicate proficiently at all.</div><br/></div></div></div></div><div id="38285521" class="c"><input type="checkbox" id="c-38285521" checked=""/><div class="controls bullet"><span class="by">4death4</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38282507">parent</a><span>|</span><a href="#38282688">prev</a><span>|</span><a href="#38283709">next</a><span>|</span><label class="collapse" for="c-38285521">[-]</label><label class="expand" for="c-38285521">[1 more]</label></div><br/><div class="children"><div class="content">I had the opposite experience. My daughter had multiple signs down by 7 months.</div><br/></div></div></div></div><div id="38283709" class="c"><input type="checkbox" id="c-38283709" checked=""/><div class="controls bullet"><span class="by">petsfed</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38282507">prev</a><span>|</span><a href="#38284043">next</a><span>|</span><label class="collapse" for="c-38283709">[-]</label><label class="expand" for="c-38283709">[3 more]</label></div><br/><div class="children"><div class="content">One of the funniest interactions I had with my eldest daughter was the day we baked cookies together, when she not yet 2. She was verbalizing a lot, but also signing &quot;milk&quot; and &quot;more&quot; quite a bit. And when she bit into her very first chocolate chip cookie of her entire life, she immediately signed &quot;more&quot; and said as much <i>through</i> the mouthful of cookie.</div><br/><div id="38284076" class="c"><input type="checkbox" id="c-38284076" checked=""/><div class="controls bullet"><span class="by">RationalDino</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283709">parent</a><span>|</span><a href="#38284949">next</a><span>|</span><label class="collapse" for="c-38284076">[-]</label><label class="expand" for="c-38284076">[1 more]</label></div><br/><div class="children"><div class="content">You remind me of the following.<p>At about the same age, I bought my son a mango lassi. He looked suspiciously at it, but took a sip. With a look of shocked delight he tilted it back, back, back, and emptied the cup!<p>Then he put it down, looked at me, and said, &quot;Want more!&quot;<p>I&#x27;m looking forward to kids out of the house. But there are some moments that I treasure.</div><br/></div></div><div id="38284949" class="c"><input type="checkbox" id="c-38284949" checked=""/><div class="controls bullet"><span class="by">jtr1</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38283709">parent</a><span>|</span><a href="#38284076">prev</a><span>|</span><a href="#38284043">next</a><span>|</span><label class="collapse" for="c-38284949">[-]</label><label class="expand" for="c-38284949">[1 more]</label></div><br/><div class="children"><div class="content">Once mine learned the sign for “cookie” it became the only word in her vocabulary for a month</div><br/></div></div></div></div><div id="38284043" class="c"><input type="checkbox" id="c-38284043" checked=""/><div class="controls bullet"><span class="by">hiisukun</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38283709">prev</a><span>|</span><a href="#38284061">next</a><span>|</span><label class="collapse" for="c-38284043">[-]</label><label class="expand" for="c-38284043">[2 more]</label></div><br/><div class="children"><div class="content">This is good advice but with a caveat: some of the muscle control required for particular signs is not able to be learned by children until they&#x27;re a bit older.<p>For example, voluntary supination&#x2F;pronation of the forearm is generally not something a 9month old can do. If you try and teach them a common sign for &quot;enough&#x2F;finished&quot; (fist closed, thumb pointed out, then rotation of the forearm back and forth), or &quot;done&quot; and &quot;more&quot; in the parent link, they probably won&#x27;t be able to do it properly. They can copy something close to that (thumb out and wobbling their hand around? good enough!) so you have to go with the flow.<p>There are quite a few signs like that actually, so try and think about how many muscles move together, and how controlled or complex that is. Simple stuff is good -- and doable.</div><br/><div id="38285613" class="c"><input type="checkbox" id="c-38285613" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#38282378">root</a><span>|</span><a href="#38284043">parent</a><span>|</span><a href="#38284061">next</a><span>|</span><label class="collapse" for="c-38285613">[-]</label><label class="expand" for="c-38285613">[1 more]</label></div><br/><div class="children"><div class="content">Yeah my daughter used to stick out her index finger and wave it back and forth for finished.<p>One of my favourite memories of that was when we went to see the Vivid light show in Sydney and there was a contortionist on the street so we stopped to watch. I looked into the stroller and said &quot;What do you think?&quot; and she made the sign for &quot;finished&quot;. So we moved on.</div><br/></div></div></div></div><div id="38284061" class="c"><input type="checkbox" id="c-38284061" checked=""/><div class="controls bullet"><span class="by">bradfitz</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38284043">prev</a><span>|</span><a href="#38283601">next</a><span>|</span><label class="collapse" for="c-38284061">[-]</label><label class="expand" for="c-38284061">[1 more]</label></div><br/><div class="children"><div class="content">We did this with our boys. The oldest picked up a sign we weren&#x27;t even trying to teach: whenever I changed his poopy diaper I&#x27;d say &quot;phoo phoo phoo!&quot; jokingly and fan my noise. One day he was playing on the other side of the room and fanned his nose. He&#x27;d pooped and was telling us. Super cool.</div><br/></div></div><div id="38283601" class="c"><input type="checkbox" id="c-38283601" checked=""/><div class="controls bullet"><span class="by">pamelafox</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38284061">prev</a><span>|</span><a href="#38286200">next</a><span>|</span><label class="collapse" for="c-38283601">[-]</label><label class="expand" for="c-38283601">[1 more]</label></div><br/><div class="children"><div class="content">My toddler learnt &quot;more&quot; and now uses it to get me to repeatedly sing the same song OVER AND OVER again. They haven&#x27;t used the word yet, though they do speak other words.<p>I wish I&#x27;d learnt sign language before having kids so I just already knew how to do it, it&#x27;s so cool. Props to the Ms. Rachel videos for including so many signs.</div><br/></div></div><div id="38286200" class="c"><input type="checkbox" id="c-38286200" checked=""/><div class="controls bullet"><span class="by">chthonicdaemon</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38283601">prev</a><span>|</span><a href="#38283615">next</a><span>|</span><label class="collapse" for="c-38286200">[-]</label><label class="expand" for="c-38286200">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly there isn&#x27;t any correspondence between spoken language and sign language in the linguistic sense. Correspondence between the dominant sign language and the dominant spoken language is mostly due to geographical colocation. So while you are right to say &quot;your specific region&#x27;s sign language&quot;, there are several distinct sign languages in places that all have English as their primary spoken language.</div><br/></div></div><div id="38283615" class="c"><input type="checkbox" id="c-38283615" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38286200">prev</a><span>|</span><a href="#38283222">next</a><span>|</span><label class="collapse" for="c-38283615">[-]</label><label class="expand" for="c-38283615">[1 more]</label></div><br/><div class="children"><div class="content">My mom taught us some words somewhere around 5-8 years old, so we could signal things to each other instead of interrupting conversations.  The three in particular I remember are &quot;hungry&quot;, &quot;bored&quot;, and &quot;thank you&quot; (so she could remind us to say it without the other person realizing).</div><br/></div></div><div id="38283222" class="c"><input type="checkbox" id="c-38283222" checked=""/><div class="controls bullet"><span class="by">EvanAnderson</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38283615">prev</a><span>|</span><a href="#38286297">next</a><span>|</span><label class="collapse" for="c-38283222">[-]</label><label class="expand" for="c-38283222">[1 more]</label></div><br/><div class="children"><div class="content">Every kid is different. YMMV. We did some ASL gestures&#x2F;words with our daughter and it worked very well. I&#x27;d encourage everyone to at least give it a try. She took to it and was &quot;talking&quot; to us (mainly &quot;hungry&quot; and &quot;milk&quot;, but we got &quot;enough&quot; sometimes too) pretty quickly.<p>I can&#x27;t remember exact ages and timeframes-- that time of my life is &quot;blurry&quot;. I wish I could remember all the gestures we used. (The only ones I can remember now are &quot;milk&quot;, &quot;apple&quot;, and &quot;thank you&quot;.) As she became verbal she quickly transitioned away from them.</div><br/></div></div><div id="38286297" class="c"><input type="checkbox" id="c-38286297" checked=""/><div class="controls bullet"><span class="by">Tade0</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38283222">prev</a><span>|</span><a href="#38283831">next</a><span>|</span><label class="collapse" for="c-38286297">[-]</label><label class="expand" for="c-38286297">[1 more]</label></div><br/><div class="children"><div class="content">I made an attempt with this, but my toddler never picked up anything because:<p>-She learned some gestures of mine instead, which I didn&#x27;t realize I was doing.<p>-Defaulted to speech as soon as possible because it was just easier.</div><br/></div></div><div id="38283831" class="c"><input type="checkbox" id="c-38283831" checked=""/><div class="controls bullet"><span class="by">mcpackieh</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38286297">prev</a><span>|</span><a href="#38284009">next</a><span>|</span><label class="collapse" for="c-38283831">[-]</label><label class="expand" for="c-38283831">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>regular ASL gestures for the work in question. If you&#x27;re not native English-speaking you&#x27;d look up the gestures in your specific region&#x2F;language&#x27;s sign language:</i><p>It probably doesn&#x27;t matter either way for babies, but fyi ASL isn&#x27;t a sign version of English; it is its own language.   In fact American Sign Language is more closely related to French Sign Language than to British Sign Language.  The Australian and New Zealand Sign Languages are largely derived from British Sign Language, so there isn&#x27;t really a correlation between English speaking regions and ASL.   Canadians mostly use American Sign Language and French Canadian Sign Language.</div><br/></div></div><div id="38284009" class="c"><input type="checkbox" id="c-38284009" checked=""/><div class="controls bullet"><span class="by">marcod</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38283831">prev</a><span>|</span><a href="#38284741">next</a><span>|</span><label class="collapse" for="c-38284009">[-]</label><label class="expand" for="c-38284009">[1 more]</label></div><br/><div class="children"><div class="content">Worked incredibly well for our first born, but 2nd child just wanted to talk like their sibling.<p>Almost 20 years later, I still know all the signs for baby food ;)</div><br/></div></div><div id="38284741" class="c"><input type="checkbox" id="c-38284741" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#38282378">parent</a><span>|</span><a href="#38284009">prev</a><span>|</span><a href="#38286629">next</a><span>|</span><label class="collapse" for="c-38284741">[-]</label><label class="expand" for="c-38284741">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Perhaps worth noting that it is possible to teach infants (often starting at around 9 months) sign language so that they can more easily signal their desires.<p>You can teach chatgpt too as well. It&#x27;s like a toddler. A very articulate toddler:<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;40c94561-2505-4938-8331-7d10ae24e569" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;40c94561-2505-4938-8331-7d10ae...</a><p>It makes mistakes as any human baby would. And as a parent you can correct it.<p>All this means is that learning an arbitrary sign language isn&#x27;t a differentiator.</div><br/></div></div></div></div><div id="38286629" class="c"><input type="checkbox" id="c-38286629" checked=""/><div class="controls bullet"><span class="by">_nalply</span><span>|</span><a href="#38282378">prev</a><span>|</span><a href="#38282228">next</a><span>|</span><label class="collapse" for="c-38286629">[-]</label><label class="expand" for="c-38286629">[2 more]</label></div><br/><div class="children"><div class="content">I am a father and this story touches me a lot. I have two boys not toddlers anymore. Both go to school. The older one told me laughingly: &quot;That&#x27;s funny, there&#x27;s no Father Nature, but Mother Nature!&quot;. The younger one learnt yesterday not to touch a cake even if I didn&#x27;t lock it away. I said: &quot;Tomorrow this cake is for you and for your brother. If you eat it today, you won&#x27;t have cake tomorrow.&quot;<p>This said, there&#x27;s an important difference between LLMs and humans: Humans have instincts. The most important ones seem to be the set of instincts concerning an immaterial will for life and a readiness to overcome deadly obstacles. In other words: LLMs don&#x27;t have the primitive experience of what is life.<p>This might change in future. A startup might put neural networks into soft robots and then in a survival situation. Robots that don&#x27;t emerge functioning are wiped, repaired and put back. In other words, they establish an evolutional situation. After careful enough iterations of curation they have things that &quot;understand&quot; life or at least better than current LLM instantiations.<p>EDIT: typo</div><br/><div id="38286872" class="c"><input type="checkbox" id="c-38286872" checked=""/><div class="controls bullet"><span class="by">misja111</span><span>|</span><a href="#38286629">parent</a><span>|</span><a href="#38282228">next</a><span>|</span><label class="collapse" for="c-38286872">[-]</label><label class="expand" for="c-38286872">[1 more]</label></div><br/><div class="children"><div class="content">I see instincts as something like a pre-installed ROM. It shouldn&#x27;t be too hard to add something like that to LLM. In fact, I think this is being done already, for instance by hardwiring LLM to not have racist or sexual conversations.<p>To make LLM&#x27;s more similar to humans, we&#x27;d need to hardwire them with a concept of &#x27;self&#x27;, and, importantly, the hardwired idea that their self was unique, special, and should survive. But I think the result would be terrible. Imagine a LLM that would be begging not to be switched off, or worse, trying to subtly manipulate its creators.</div><br/></div></div></div></div><div id="38282228" class="c"><input type="checkbox" id="c-38282228" checked=""/><div class="controls bullet"><span class="by">Mattasher</span><span>|</span><a href="#38286629">prev</a><span>|</span><a href="#38282491">next</a><span>|</span><label class="collapse" for="c-38282228">[-]</label><label class="expand" for="c-38282228">[41 more]</label></div><br/><div class="children"><div class="content">Humans have a long history of comparing ourselves, and the universe, to our latest technological advancement. We used to be glorified clocks (as was the universe), then we were automatons, then computers, then NPC&#x27;s, and now AI&#x27;s (in particular LLM&#x27;s).<p>Which BTW I don&#x27;t think is a completely absurd comparison, see <a href="https:&#x2F;&#x2F;mattasher.substack.com&#x2F;p&#x2F;ais-killer-app" rel="nofollow noreferrer">https:&#x2F;&#x2F;mattasher.substack.com&#x2F;p&#x2F;ais-killer-app</a></div><br/><div id="38282893" class="c"><input type="checkbox" id="c-38282893" checked=""/><div class="controls bullet"><span class="by">Tallain</span><span>|</span><a href="#38282228">parent</a><span>|</span><a href="#38282391">next</a><span>|</span><label class="collapse" for="c-38282893">[-]</label><label class="expand" for="c-38282893">[1 more]</label></div><br/><div class="children"><div class="content">Not just technological advancements; we have a history of comparing ourselves to that which surrounds us, is relatively ubiquitous, and easily comprehended by others when using the metaphor. Today it&#x27;s this steady march of technological advancement, but read any older work of philosophy and you will see our selves (particularly, our minods) compared to monarchs, cities, aqueducts.[1]<p>I point this out because I think the idea of comparing ourselves to recent tech is more about using the technology as a metaphor for self, and it&#x27;s worth incorporating the other ways we have done so historically for context.<p>[1]: <a href="https:&#x2F;&#x2F;online.ucpress.edu&#x2F;SLA&#x2F;article&#x2F;2&#x2F;4&#x2F;542&#x2F;83344&#x2F;The-Brain-as-Treasury-and-as-AqueductMetaphors-of" rel="nofollow noreferrer">https:&#x2F;&#x2F;online.ucpress.edu&#x2F;SLA&#x2F;article&#x2F;2&#x2F;4&#x2F;542&#x2F;83344&#x2F;The-Bra...</a></div><br/></div></div><div id="38282391" class="c"><input type="checkbox" id="c-38282391" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#38282228">parent</a><span>|</span><a href="#38282893">prev</a><span>|</span><a href="#38282367">next</a><span>|</span><label class="collapse" for="c-38282391">[-]</label><label class="expand" for="c-38282391">[11 more]</label></div><br/><div class="children"><div class="content">Each successive comparison is likely getting closer and closer to the truth.</div><br/><div id="38282683" class="c"><input type="checkbox" id="c-38282683" checked=""/><div class="controls bullet"><span class="by">beezlebroxxxxxx</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282391">parent</a><span>|</span><a href="#38283193">next</a><span>|</span><label class="collapse" for="c-38282683">[-]</label><label class="expand" for="c-38282683">[8 more]</label></div><br/><div class="children"><div class="content">Or each successive comparison is just compounding and reiterating the same underlying assumption (and potentially the same mistake) whether it&#x27;s true or not.</div><br/><div id="38283633" class="c"><input type="checkbox" id="c-38283633" checked=""/><div class="controls bullet"><span class="by">bigDinosaur</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282683">parent</a><span>|</span><a href="#38282751">next</a><span>|</span><label class="collapse" for="c-38283633">[-]</label><label class="expand" for="c-38283633">[6 more]</label></div><br/><div class="children"><div class="content">The jump to &#x27;information processing machines&#x27; seems far more correct than anything that came before, I&#x27;m curious how you would argue against that? Yes, there are more modern and other interesting theories (e.g. predictive coding) but they seem much closer to cognitive psychology than say, the human brain working like a clock.</div><br/><div id="38284965" class="c"><input type="checkbox" id="c-38284965" checked=""/><div class="controls bullet"><span class="by">jtr1</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283633">parent</a><span>|</span><a href="#38285568">next</a><span>|</span><label class="collapse" for="c-38284965">[-]</label><label class="expand" for="c-38284965">[4 more]</label></div><br/><div class="children"><div class="content">I think the argument is that you need to ask how you are measuring when you say it seems more correct than anything that came before. You may just be describing the experience of swimming in the dominant paradigm</div><br/><div id="38285471" class="c"><input type="checkbox" id="c-38285471" checked=""/><div class="controls bullet"><span class="by">schoen</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284965">parent</a><span>|</span><a href="#38285908">next</a><span>|</span><label class="collapse" for="c-38285471">[-]</label><label class="expand" for="c-38285471">[2 more]</label></div><br/><div class="children"><div class="content">One attempt could be &quot;it allows us to make better predictions about the mind&quot;.<p>This article mentions excitement about neural networks overgeneralizing verb inflections, which human language learners also do. If neural networks lead to the discovery of new examples of human cognitive or perceptual errors or illusions, or to the discovery of new effective methods for learning, teaching, or psychotherapy, that could count as evidence that they&#x27;re a good model of our actual minds.</div><br/><div id="38286603" class="c"><input type="checkbox" id="c-38286603" checked=""/><div class="controls bullet"><span class="by">dotforest</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38285471">parent</a><span>|</span><a href="#38285908">next</a><span>|</span><label class="collapse" for="c-38286603">[-]</label><label class="expand" for="c-38286603">[1 more]</label></div><br/><div class="children"><div class="content">If the article is talking about the neural network in McClelland and Rumelhart’s Parallel Distributed Processing, there’s actually a paper by Steven Pinker and some other linguists drilling into it and finding that it doesn’t model children’s language acquisition nearly as closely or as well as M&amp;R think it does.</div><br/></div></div></div></div><div id="38285908" class="c"><input type="checkbox" id="c-38285908" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284965">parent</a><span>|</span><a href="#38285471">prev</a><span>|</span><a href="#38285568">next</a><span>|</span><label class="collapse" for="c-38285908">[-]</label><label class="expand" for="c-38285908">[1 more]</label></div><br/><div class="children"><div class="content">Have you managed any kind of conversation with a clock before? Because you can actually have an intelligent conversation with an LLM. I think that&#x27;s a pretty compelling case that it&#x27;s not just swimming in the dominant paradigm.</div><br/></div></div></div></div><div id="38285568" class="c"><input type="checkbox" id="c-38285568" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283633">parent</a><span>|</span><a href="#38284965">prev</a><span>|</span><a href="#38282751">next</a><span>|</span><label class="collapse" for="c-38285568">[-]</label><label class="expand" for="c-38285568">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m curious how you would argue against that<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hard_problem_of_consciousness" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hard_problem_of_consciousness</a><p><a href="https:&#x2F;&#x2F;philosophy.stackexchange.com&#x2F;questions&#x2F;77517&#x2F;what-is-hard-about-the-hard-problem-of-consciousness" rel="nofollow noreferrer">https:&#x2F;&#x2F;philosophy.stackexchange.com&#x2F;questions&#x2F;77517&#x2F;what-is...</a></div><br/></div></div></div></div></div></div><div id="38283193" class="c"><input type="checkbox" id="c-38283193" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282391">parent</a><span>|</span><a href="#38282683">prev</a><span>|</span><a href="#38282367">next</a><span>|</span><label class="collapse" for="c-38283193">[-]</label><label class="expand" for="c-38283193">[2 more]</label></div><br/><div class="children"><div class="content">Very curious to know what the telos of &quot;truth&quot; is here for you? A comparison is a comparison, it can get no more &quot;true.&quot; If you want to say: the terms of the comparisons seem to verge towards identity, then you aren&#x27;t really talking about the same thing anymore. Further, you would need to assert that our conceptions of ourselves have remained static throughout the whole ordeal (pretty tough to defend), and you would also need to put forward a pretty crude idea of technological determinism (extremely tough to defend).<p>Its way more productive and way less woo-woo to understand that humans have a certain tendency towards comparison, and we tend to create things that reflect our current values and conceptions of ourselves. And that &quot;technological progress&quot; is not a straight line, but a labyrinthine route that traces societal conceptions and priorities.<p>The desire for the llm to be like us is probably more realistically our desire to be like the llm!</div><br/><div id="38283958" class="c"><input type="checkbox" id="c-38283958" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283193">parent</a><span>|</span><a href="#38282367">next</a><span>|</span><label class="collapse" for="c-38283958">[-]</label><label class="expand" for="c-38283958">[1 more]</label></div><br/><div class="children"><div class="content">An apple is like an orange. Both are round fruits, containing visible seeds, and relatively sweet. If you&#x27;re hungry, they are both good choices.<p>But then again, an apple is nothing like an orange, particularly if you want to make an apple pie.<p>The purpose of a comparison is important in helping to define its scope.</div><br/></div></div></div></div></div></div><div id="38282367" class="c"><input type="checkbox" id="c-38282367" checked=""/><div class="controls bullet"><span class="by">ChuckMcM</span><span>|</span><a href="#38282228">parent</a><span>|</span><a href="#38282391">prev</a><span>|</span><a href="#38283569">next</a><span>|</span><label class="collapse" for="c-38282367">[-]</label><label class="expand" for="c-38282367">[1 more]</label></div><br/><div class="children"><div class="content">I always enjoyed the stories of &#x27;clock work&#x27; people (robots).</div><br/></div></div><div id="38283569" class="c"><input type="checkbox" id="c-38283569" checked=""/><div class="controls bullet"><span class="by">cmrdporcupine</span><span>|</span><a href="#38282228">parent</a><span>|</span><a href="#38282367">prev</a><span>|</span><a href="#38282423">next</a><span>|</span><label class="collapse" for="c-38283569">[-]</label><label class="expand" for="c-38283569">[6 more]</label></div><br/><div class="children"><div class="content">Step A: build a machine which reflects a reduced and simplified model of how some part of a human works<p>Step B: turn it on its head &quot;the human brain is nothing more than... &lt;insert machine here.&gt;&quot;<p>It&#x27;s a bit tautological.<p>The worry is that there&#x27;s a Step C: Humans actually start to behave as simple as said machine.</div><br/><div id="38283966" class="c"><input type="checkbox" id="c-38283966" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283569">parent</a><span>|</span><a href="#38282423">next</a><span>|</span><label class="collapse" for="c-38283966">[-]</label><label class="expand" for="c-38283966">[5 more]</label></div><br/><div class="children"><div class="content">What machines have we built that reflect a reduced and simplified model of how some part of a human works (other than as a minor and generally invisible research projects) ?</div><br/><div id="38284644" class="c"><input type="checkbox" id="c-38284644" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283966">parent</a><span>|</span><a href="#38284980">next</a><span>|</span><label class="collapse" for="c-38284644">[-]</label><label class="expand" for="c-38284644">[2 more]</label></div><br/><div class="children"><div class="content">any chemical or large industrial plant built in the last 30 years</div><br/><div id="38285123" class="c"><input type="checkbox" id="c-38285123" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284644">parent</a><span>|</span><a href="#38284980">next</a><span>|</span><label class="collapse" for="c-38285123">[-]</label><label class="expand" for="c-38285123">[1 more]</label></div><br/><div class="children"><div class="content">I think most industrial chemists would likely disagree. But I guess YMMV.</div><br/></div></div></div></div><div id="38285458" class="c"><input type="checkbox" id="c-38285458" checked=""/><div class="controls bullet"><span class="by">zmgsabst</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283966">parent</a><span>|</span><a href="#38284980">prev</a><span>|</span><a href="#38282423">next</a><span>|</span><label class="collapse" for="c-38285458">[-]</label><label class="expand" for="c-38285458">[1 more]</label></div><br/><div class="children"><div class="content">Electronic are a simplified model of the brains used by computers:<p>They emulate the faculty, rather than biology.</div><br/></div></div></div></div></div></div><div id="38282423" class="c"><input type="checkbox" id="c-38282423" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#38282228">parent</a><span>|</span><a href="#38283569">prev</a><span>|</span><a href="#38282491">next</a><span>|</span><label class="collapse" for="c-38282423">[-]</label><label class="expand" for="c-38282423">[21 more]</label></div><br/><div class="children"><div class="content">Except LLM&#x27;s are built on neural networks. That are based on how neurons work. The first tech that actually copies aspects of us.</div><br/><div id="38282437" class="c"><input type="checkbox" id="c-38282437" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282423">parent</a><span>|</span><a href="#38286580">next</a><span>|</span><label class="collapse" for="c-38282437">[-]</label><label class="expand" for="c-38282437">[19 more]</label></div><br/><div class="children"><div class="content"><i>sigh</i><p>Neural networks are not based on how neurons work. They do not copy aspects of us. They call them neural networks because they are sort of conceptually like networks of neurons in the brain but they’re so different as to make false the statement that they are based on neurons.</div><br/><div id="38282551" class="c"><input type="checkbox" id="c-38282551" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38284750">next</a><span>|</span><label class="collapse" for="c-38282551">[-]</label><label class="expand" for="c-38282551">[1 more]</label></div><br/><div class="children"><div class="content">*brandishes crutches*<p>&quot;Behold! The Mechanical Leg! The first technology that actually copies aspects of our very selves! Think of what wonders of self-discovery it shall reveal!&quot; :p<p>P.S.: &quot;My god, it is stronger in compression rather than shear-stresses, how eerily similar to real legs! We&#x27;re on to something here!&quot;</div><br/></div></div><div id="38284750" class="c"><input type="checkbox" id="c-38284750" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38282551">prev</a><span>|</span><a href="#38282727">next</a><span>|</span><label class="collapse" for="c-38284750">[-]</label><label class="expand" for="c-38284750">[2 more]</label></div><br/><div class="children"><div class="content">They are though. They quite literally are. Saying otherwise is like saying planes weren&#x27;t based on how birds work when Wright brothers spent a lot of time in the  1800s studying birds.<p>Both Humans and GPT are neural networks. Who cares that GPT doesn&#x27;t have feathers or flap its wings? That&#x27;s not the question to care bout. We are interested in whether GPT flies. You can sigh to Kingdom come and nothing will change that.<p>We&#x27;ve developed numerous different learning algorithms that are biologically plausible, but they all kinda work like backpropagation but worse, so we stuck with backpropagation. We&#x27;ve made more complicated neurons that better resemble biological neurons, but it is faster and works better if you just add extra simple neurons, so we do that instead. Spiking neural networks have connection patterns more similar to what you see in the brain, but they learn slower and are tougher to work with than regular layered neural networks, so we use layered neural networks instead.<p>The Wright brothers probably experimented with gluing feathers onto their gliders, but eventually decided it wasn’t worth the effort. Because that&#x27;s not what is important.</div><br/><div id="38286762" class="c"><input type="checkbox" id="c-38286762" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284750">parent</a><span>|</span><a href="#38282727">next</a><span>|</span><label class="collapse" for="c-38286762">[-]</label><label class="expand" for="c-38286762">[1 more]</label></div><br/><div class="children"><div class="content">There are drones with feathers now however. The spring in feather flaps help conserve energy, but only in flapping wings obviously.</div><br/></div></div></div></div><div id="38282727" class="c"><input type="checkbox" id="c-38282727" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38284750">prev</a><span>|</span><a href="#38282882">next</a><span>|</span><label class="collapse" for="c-38282727">[-]</label><label class="expand" for="c-38282727">[5 more]</label></div><br/><div class="children"><div class="content">If you study retinal synaptic circuitry you will not sigh so heavily and you will in fact see striking homologies with hardware neural networks, including feedback between layers and discretized (action potential) outputs via the optic nerve.<p>I recommend reading Synaptic Organization of the Brain or getting into if you are brave, the primary literature on retinal processing of visual input.</div><br/><div id="38284144" class="c"><input type="checkbox" id="c-38284144" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282727">parent</a><span>|</span><a href="#38283112">next</a><span>|</span><label class="collapse" for="c-38284144">[-]</label><label class="expand" for="c-38284144">[1 more]</label></div><br/><div class="children"><div class="content">Actually it’s funny my best friend is a neuroscientist and studies the retina and in particular the way different types of retinal cells respond to stimulus. I have watched her give presentations on her work and I do see that there are some similarities.<p>But it is nonetheless the case that “neural networks” are not called that because they are based on the way neurons work.</div><br/></div></div><div id="38283112" class="c"><input type="checkbox" id="c-38283112" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282727">parent</a><span>|</span><a href="#38284144">prev</a><span>|</span><a href="#38284672">next</a><span>|</span><label class="collapse" for="c-38283112">[-]</label><label class="expand" for="c-38283112">[1 more]</label></div><br/><div class="children"><div class="content">The book &quot;The Synaptic Organization of the Brain&quot; appears to be from 2003.  Is it still relevant, or is there perhaps a more recent book worth checking out?</div><br/></div></div><div id="38284672" class="c"><input type="checkbox" id="c-38284672" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282727">parent</a><span>|</span><a href="#38283112">prev</a><span>|</span><a href="#38282882">next</a><span>|</span><label class="collapse" for="c-38284672">[-]</label><label class="expand" for="c-38284672">[2 more]</label></div><br/><div class="children"><div class="content">I will continue to sigh. The visual cortex is relatively simple and linear. You&#x27;re not saying something that&#x27;s as impressive as you think it is.</div><br/><div id="38285486" class="c"><input type="checkbox" id="c-38285486" checked=""/><div class="controls bullet"><span class="by">l33t7332273</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284672">parent</a><span>|</span><a href="#38282882">next</a><span>|</span><label class="collapse" for="c-38285486">[-]</label><label class="expand" for="c-38285486">[1 more]</label></div><br/><div class="children"><div class="content">I think the point of the example is that that is an important part of our brains that is relatively simple and linear and we’ve been able to mimic it.</div><br/></div></div></div></div></div></div><div id="38282882" class="c"><input type="checkbox" id="c-38282882" checked=""/><div class="controls bullet"><span class="by">martindbp</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38282727">prev</a><span>|</span><a href="#38286900">next</a><span>|</span><label class="collapse" for="c-38282882">[-]</label><label class="expand" for="c-38282882">[5 more]</label></div><br/><div class="children"><div class="content">Sigh... Everyone knows artificial neurons are not like biological neurons. The network is the important part, which really is analogous to the brain, while what came before (SVMs and random forests) are nothing like it.</div><br/><div id="38283379" class="c"><input type="checkbox" id="c-38283379" checked=""/><div class="controls bullet"><span class="by">mecsred</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282882">parent</a><span>|</span><a href="#38284155">next</a><span>|</span><label class="collapse" for="c-38283379">[-]</label><label class="expand" for="c-38283379">[2 more]</label></div><br/><div class="children"><div class="content">Sigh... Every man knows the mechanisms of the mind are yet unlike the cogs and pinions of clockwork. It remains the machinery, the relation of spring and escapement, that is most relevant. Hitherto in human history, I think, such structure has not been described.</div><br/><div id="38287146" class="c"><input type="checkbox" id="c-38287146" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283379">parent</a><span>|</span><a href="#38284155">next</a><span>|</span><label class="collapse" for="c-38287146">[-]</label><label class="expand" for="c-38287146">[1 more]</label></div><br/><div class="children"><div class="content">If you build a neural network out of cogs and pinions, sure.<p>Comparing the brain to most complex machines in history wasn&#x27;t a mistake, any more than refining laws of physics were. Successive approximations.<p>And we&#x27;re no longer at the point where we&#x27;re just comparing brain to most complex machines. We have information theory now. We figured out computation, in form independent of physical medium used. So we&#x27;re really trying to determine the computational model behind the brain, and one of the ways to do it is to implement some computational models in whatever is most convenient (usually software running on silicon), and see if it&#x27;s similar. Slowly but surely, we&#x27;re mapping and matching computational aspects of the brain. LLMs are just one recent case where we got a <i>spectacularly</i> good match.</div><br/></div></div></div></div><div id="38284155" class="c"><input type="checkbox" id="c-38284155" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282882">parent</a><span>|</span><a href="#38283379">prev</a><span>|</span><a href="#38286900">next</a><span>|</span><label class="collapse" for="c-38284155">[-]</label><label class="expand" for="c-38284155">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Everyone knows artificial neurons are not like biological neurons.<p>Not, apparently, the person I was replying to!</div><br/><div id="38286751" class="c"><input type="checkbox" id="c-38286751" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38284155">parent</a><span>|</span><a href="#38286900">next</a><span>|</span><label class="collapse" for="c-38286751">[-]</label><label class="expand" for="c-38286751">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m him, and I didn&#x27;t say that. ANNs didn&#x27;t arise in a vacuum and they aren&#x27;t called neural networks for the fun of it.<p><a href="https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;neural-networks#:~:text=Their%20name%20and%20structure%20are,layers%2C%20and%20an%20output%20layer" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;neural-networks#:~:text=Their%20n...</a>.</div><br/></div></div></div></div></div></div><div id="38286900" class="c"><input type="checkbox" id="c-38286900" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38282882">prev</a><span>|</span><a href="#38283169">next</a><span>|</span><label class="collapse" for="c-38286900">[-]</label><label class="expand" for="c-38286900">[1 more]</label></div><br/><div class="children"><div class="content">Science history should be mandatory for undergrads. I didn&#x27;t think what I said is controversial. This is established history. Sorry if it scares you.</div><br/></div></div><div id="38283169" class="c"><input type="checkbox" id="c-38283169" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38282437">parent</a><span>|</span><a href="#38286900">prev</a><span>|</span><a href="#38282611">next</a><span>|</span><label class="collapse" for="c-38283169">[-]</label><label class="expand" for="c-38283169">[3 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t really matter to modern CS, but Rosenblatt&#x27;s original perceptron paper is a good read on this. ANNs were specifically inspired by Natural NNs and there were many attempts to build ANNs using models of how the human brain works, specifically down to the neuron.</div><br/><div id="38283254" class="c"><input type="checkbox" id="c-38283254" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283169">parent</a><span>|</span><a href="#38282611">next</a><span>|</span><label class="collapse" for="c-38283254">[-]</label><label class="expand" for="c-38283254">[2 more]</label></div><br/><div class="children"><div class="content">I;m sure you know but one of the best ways to get neuro folks worked up is to say anything about neural networks being anything like neurons in brains.<p>(IMHO, Rosenblatt is an underappreciated genius; he had a working shallow computer vision hardware computer long before people even appreciated what an accomplishment that was. The hardware was fascinating- literally self-turning potentiometer knobs to update weights.</div><br/><div id="38284657" class="c"><input type="checkbox" id="c-38284657" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#38282228">root</a><span>|</span><a href="#38283254">parent</a><span>|</span><a href="#38282611">next</a><span>|</span><label class="collapse" for="c-38284657">[-]</label><label class="expand" for="c-38284657">[1 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m being honest, I do know they get annoyed by that stuff but I&#x27;ve never really understood why. It&#x27;s a somewhat common pattern in Mathematics as an avenue for hypotheses to take an existing phenomenon, model some subset of its capabilities, use that to define a new class of behaviour, follow that through to conclusions, then use that to go back to seeing if those conclusions apply to the original phenomenon.<p>A theoretical such thing might be for us to look at, say, human arms and say &quot;Well, this gripping thing is a cool piece of functionality. Let&#x27;s build an artificial device that does this. But we don&#x27;t have muscle contraction tech, so we&#x27;ll put actuators in the gripping portion. All right, we&#x27;ve built an arm. It seems like if we place it in this position it minimizes mechanical wear when not in action and makes it unlikely for initial movement to create undesired results. I wonder if human arms+hands have the same behaviour. Ah, looks like not, but that would have been interesting if it were the case&quot;<p>Essentially that&#x27;s just the process of extracting substructure and then seeing if there is a homomorphism (smooshy type abuse here) between two structures as a way to detect yet hidden structure. Category theory is almost all this. I suppose the reason they find it annoying is that there are many mappings that are non-homomorphic and so these are the false cognates of concepts.<p>Still, I think the whole &quot;An ANN is not a brain&quot; thing is overdone. Of course not. A mechanical arm is not an arm, but they both have response curves, and one can consider a SLAM approach for the former and compare with the proprioceptive view of the latter. It just needs some squinting.<p>Anyway, considering your familiarity with R and his work, I think I&#x27;m not speaking to the uninitiated, but I thought it worth writing anyway.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38282491" class="c"><input type="checkbox" id="c-38282491" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38282228">prev</a><span>|</span><a href="#38282616">next</a><span>|</span><label class="collapse" for="c-38282491">[-]</label><label class="expand" for="c-38282491">[24 more]</label></div><br/><div class="children"><div class="content">Regarding dismissals of LLM’s on ‘technical’ grounds:<p>Consciousness is first a word and second a concept. And it’s a word that ChatGPT or Llama can use in an English sentence better than billions of humans worldwide. The software folks have made even more progress than sociologists, psychologists and neuroscientists to be able to create an artificial language cortex before we understand our biological mind comprehensively.<p>If you wait until conscious sentient AI is here to make your opinions known about the implications and correct policy decisions, you will already be too late to have an input. ChatGPT can already tell you a lot about itself (showing awareness) and will gladly walk you through its “thinking” if you ask politely. Given that it contains a huge amount of data about Homo sapiens and its ability to emulate intelligent conversation, you could even call it Sapient.<p>Having any kind of semantic argument over this is futile because a character AI that is hypnotized to think it is conscious, self-aware and sentient in its emulation of feelings and emotion would destroy most people in a semantics debate.<p>The field of philosophy is already ripe with ideas from hundreds of years ago that an artificial intelligence can use against people in debates of free will, self-determination and the nature of existence. This isn’t the battle to pick.</div><br/><div id="38285625" class="c"><input type="checkbox" id="c-38285625" checked=""/><div class="controls bullet"><span class="by">slibhb</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38283911">next</a><span>|</span><label class="collapse" for="c-38285625">[-]</label><label class="expand" for="c-38285625">[9 more]</label></div><br/><div class="children"><div class="content">With a simple computer, speaker, and accelerometer, you can build a device that says &quot;ouch&quot; when you drop it. Does it feel pain?<p>My point is that there are good reasons to believe that a hypothetical LLM that can pass a Turing test is a philosophical zombie, i.e. it can mimic human behavior but doesn&#x27;t have an internal life, feelings, emotions, and isn&#x27;t conscious. Whether that distinction is important is another question. LLMs provide evidence that consciousness may not be necessary to create sophisticated AIs that can pass or exceed human performance.</div><br/><div id="38285933" class="c"><input type="checkbox" id="c-38285933" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285625">parent</a><span>|</span><a href="#38287099">next</a><span>|</span><label class="collapse" for="c-38285933">[-]</label><label class="expand" for="c-38285933">[7 more]</label></div><br/><div class="children"><div class="content">&gt; it can mimic human behavior but doesn&#x27;t have an internal life, feelings, emotions, and isn&#x27;t conscious<p>I&#x27;m curious how you know this. Certainly an LLM doesn&#x27;t have <i>human</i> internal life, but to claim it has <i>no</i> internal life exceeds our state of knowledge on these topics. We simply lack a mechanistic model of qualia from which we can draw such conclusions.</div><br/><div id="38285967" class="c"><input type="checkbox" id="c-38285967" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285933">parent</a><span>|</span><a href="#38287099">next</a><span>|</span><label class="collapse" for="c-38285967">[-]</label><label class="expand" for="c-38285967">[6 more]</label></div><br/><div class="children"><div class="content">An LLM is math. It outputs text. Those things aren&#x27;t alive, and both the software and hardware used to facilitate it is artificial.<p>Once you get that out of the way, sure, I guess it could be &quot;alive&quot; per the same loose definition that any electrical system can exist in an actuated state. It&#x27;s software, though. I don&#x27;t think it&#x27;s profound or overly confident to say that we very clearly know these systems are inanimate and non-living.</div><br/><div id="38286627" class="c"><input type="checkbox" id="c-38286627" checked=""/><div class="controls bullet"><span class="by">bennyelv</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285967">parent</a><span>|</span><a href="#38286911">next</a><span>|</span><label class="collapse" for="c-38286627">[-]</label><label class="expand" for="c-38286627">[1 more]</label></div><br/><div class="children"><div class="content">A few counterpoints to offer...<p>&gt;An LLM is math<p>Isn&#x27;t everything math?  Math is what we use to describe and model the nature of our reality.<p>&gt;Those things aren&#x27;t alive<p>We don&#x27;t have a universal definition of alive, or at least I&#x27;m not aware of one that isn&#x27;t purely philosophical or artistic.  We therefore can&#x27;t actually determine what is and isn&#x27;t alive with much confidence.<p>&gt;both the software and hardware used to facilitate it is artificial<p>Define artificial?  We&#x27;re made of exactly the same stuff.  Complex chemical elements that were created from more basic ones in collapsing stars, arranged in a particular configuration with electricity flowing through it all and providing some kind of coordination.  We&#x27;re definitely a bit more &quot;squishy&quot;, I&#x27;ll give you that.</div><br/></div></div><div id="38286911" class="c"><input type="checkbox" id="c-38286911" checked=""/><div class="controls bullet"><span class="by">persnickety</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285967">parent</a><span>|</span><a href="#38286627">prev</a><span>|</span><a href="#38286826">next</a><span>|</span><label class="collapse" for="c-38286911">[-]</label><label class="expand" for="c-38286911">[3 more]</label></div><br/><div class="children"><div class="content">This argument got long in the tooth, but suffice to say that you can analyze a human in exactly the same way, breaking one down to the basic physics and chemistry (and what does &quot;artificial&quot; mean, anyway?).<p>Then there&#x27;s the concept of panpsychism.</div><br/><div id="38287059" class="c"><input type="checkbox" id="c-38287059" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38286911">parent</a><span>|</span><a href="#38286826">next</a><span>|</span><label class="collapse" for="c-38287059">[-]</label><label class="expand" for="c-38287059">[2 more]</label></div><br/><div class="children"><div class="content">I would very strongly urge people to actually work and build tools with LLMs.<p>Its readily apparent after a point that the previous poster is correct, and that these are simply tools.<p>They are impressive tools yes. But life they are not. At best, they are mimics.</div><br/><div id="38287161" class="c"><input type="checkbox" id="c-38287161" checked=""/><div class="controls bullet"><span class="by">persnickety</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38287059">parent</a><span>|</span><a href="#38286826">next</a><span>|</span><label class="collapse" for="c-38287161">[-]</label><label class="expand" for="c-38287161">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t help but notice that you backed up your assertions with nothing objective at all.</div><br/></div></div></div></div></div></div><div id="38286826" class="c"><input type="checkbox" id="c-38286826" checked=""/><div class="controls bullet"><span class="by">lordnacho</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285967">parent</a><span>|</span><a href="#38286911">prev</a><span>|</span><a href="#38287099">next</a><span>|</span><label class="collapse" for="c-38286826">[-]</label><label class="expand" for="c-38286826">[1 more]</label></div><br/><div class="children"><div class="content">What about a hypothetical brain simulator? That would also be a software&#x2F;hardware mash, with known mathematics. Would that be alive?</div><br/></div></div></div></div></div></div><div id="38287099" class="c"><input type="checkbox" id="c-38287099" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285625">parent</a><span>|</span><a href="#38285933">prev</a><span>|</span><a href="#38283911">next</a><span>|</span><label class="collapse" for="c-38287099">[-]</label><label class="expand" for="c-38287099">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Does it feel pain?<p>In a sense, yes! But to understand that you will first have to <i>precisely</i> define &quot;pain&quot;. Good luck.</div><br/></div></div></div></div><div id="38283911" class="c"><input type="checkbox" id="c-38283911" checked=""/><div class="controls bullet"><span class="by">drew-y</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38285625">prev</a><span>|</span><a href="#38286688">next</a><span>|</span><label class="collapse" for="c-38283911">[-]</label><label class="expand" for="c-38283911">[4 more]</label></div><br/><div class="children"><div class="content">Totally agree with the sentiment. I find the constant debates on &quot;is AI conscious&quot; or &quot;can AI understand&quot; exhausting. You can&#x27;t have a sound argument when neither party even agrees on a concrete definition of consciousness or understanding.<p>Regarding this line:<p>&gt; ChatGPT can already tell you a lot about itself (showing awareness) and will gladly walk you through its “thinking” if you ask politely.<p>Is it actually walking you through <i>its</i> thinking? Or is it walking you through an imagined line of thinking?<p>Regardless, your main point still stands. That a program doesn&#x27;t think the same way a human does, doesn&#x27;t mean it isn&#x27;t &quot;thinking&quot;.</div><br/><div id="38284149" class="c"><input type="checkbox" id="c-38284149" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38283911">parent</a><span>|</span><a href="#38286688">next</a><span>|</span><label class="collapse" for="c-38284149">[-]</label><label class="expand" for="c-38284149">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Is it actually walking you through its thinking? Or is it walking you through an imagined line of thinking?<p>You can prompt an LLM model to provide reasoning first and an answer second and it becomes one and the same.<p>Worth keeping in mind that all of these points are orthogonal to the quality of reasoning, the bias, or the intentions of the system builders. And building something that emulates humans convincingly, you can expect it to emulate both the good and bad qualities naturally.</div><br/><div id="38287120" class="c"><input type="checkbox" id="c-38287120" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38284149">parent</a><span>|</span><a href="#38284878">next</a><span>|</span><label class="collapse" for="c-38287120">[-]</label><label class="expand" for="c-38287120">[1 more]</label></div><br/><div class="children"><div class="content">why does performance improve after chain of thought prompting?<p>Because a human is measuring it unfairly.<p>The output without CoT is valid. It is syntactically valid. 
The observer is unhappy with the semantic validity, because the observer has seen syntactic validity and assumed that semantic validity is a given.<p>Like it would if the model was alive.<p>This is observer error, not model error.</div><br/></div></div><div id="38284878" class="c"><input type="checkbox" id="c-38284878" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38284149">parent</a><span>|</span><a href="#38287120">prev</a><span>|</span><a href="#38286688">next</a><span>|</span><label class="collapse" for="c-38284878">[-]</label><label class="expand" for="c-38284878">[1 more]</label></div><br/><div class="children"><div class="content">In split brain experiments (where the corpus callosum is cut), sometimes the half which is nonverbal is prompted and the action is taken. Yet when the experimenter asks for the explanation the verbal half supplies an (incorrect) explanation. How much of human reasoning when prompted occurs before the prompt? it&#x27;s a question you have to ask as well.</div><br/></div></div></div></div></div></div><div id="38286688" class="c"><input type="checkbox" id="c-38286688" checked=""/><div class="controls bullet"><span class="by">dotforest</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38283911">prev</a><span>|</span><a href="#38283224">next</a><span>|</span><label class="collapse" for="c-38286688">[-]</label><label class="expand" for="c-38286688">[1 more]</label></div><br/><div class="children"><div class="content">“And it’s a word that ChatGPT or Llama can use in an English sentence better than billions of humans worldwide.”<p>I think the whole point the article is making, though, is that overvaluing LLMs and their supposed intelligence because they excel at this one axis of cognition (if you’re spicy) or mashed-up language ability (if you’re a skeptic) doesn’t make sense when you consider children, who are not remotely capable of what LLMs can do, but are clearly cognizant and sentient. The whole point is that those people—whether they can write an essay or not, whether they can use the word “consciousness” or not—are still fundamentally alive because we share a grounded, lived, multi-sensory, social reality.<p>And ChatGPT does not, not in the same way. Anything that it expresses now is only a mimicry of that. And if it eventually does have its own experiences through embodied AI, I’d be interested to see what it produces from its own “life” so to speak, but LLMs do not have that.</div><br/></div></div><div id="38283224" class="c"><input type="checkbox" id="c-38283224" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38286688">prev</a><span>|</span><a href="#38285573">next</a><span>|</span><label class="collapse" for="c-38283224">[-]</label><label class="expand" for="c-38283224">[6 more]</label></div><br/><div class="children"><div class="content">Exactly. To that I’m going to add that the blood of our civilization is culture (sciences, technology, arts, traditions). The moment there is something better at it than humans, it’s our “horse-moment”.</div><br/><div id="38285061" class="c"><input type="checkbox" id="c-38285061" checked=""/><div class="controls bullet"><span class="by">jtr1</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38283224">parent</a><span>|</span><a href="#38284688">next</a><span>|</span><label class="collapse" for="c-38285061">[-]</label><label class="expand" for="c-38285061">[3 more]</label></div><br/><div class="children"><div class="content">Simplifying greatly, but
1. LLMs “create” these cultural artifacts by recombining their inputs (text, images, etc), all of which are cultural artifacts created by humans
2. Humans also create cultural artifacts by recombining other cultural artifacts. The difference is that they combine another input which we can’t really prove AI has: qualia, the individual experience of being in the world, the synthesis of touch and sound and feeling and perspective.<p>I’m not saying computers can’t have something like it, but it would be so fundamentally different as to be completely alien and unrelatable to humans, and thus (IMO) non-contiguous with human culture.</div><br/><div id="38286466" class="c"><input type="checkbox" id="c-38286466" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285061">parent</a><span>|</span><a href="#38285207">next</a><span>|</span><label class="collapse" for="c-38286466">[-]</label><label class="expand" for="c-38286466">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The difference is that they combine another input which we can’t really prove AI has: qualia, the individual experience of being in the world, the synthesis of touch and sound and feeling and perspective.<p>I wish we could keep this as an immutable truth, but give some sick girls and boys in Silicon Valley a few more years and they will make true creatures. No, I think that we should be honest to ourselves and stop searching for what make us special (other than our history, and being first, that is). It&#x27;s okay to be self-interested and say &quot;we want to remain in control, AIs should not be, no matter how much (or if) better they are than us.&quot;</div><br/></div></div><div id="38285207" class="c"><input type="checkbox" id="c-38285207" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#38282491">root</a><span>|</span><a href="#38285061">parent</a><span>|</span><a href="#38286466">prev</a><span>|</span><a href="#38284688">next</a><span>|</span><label class="collapse" for="c-38285207">[-]</label><label class="expand" for="c-38285207">[1 more]</label></div><br/><div class="children"><div class="content">Oh!  TY for this thought.</div><br/></div></div></div></div></div></div><div id="38285573" class="c"><input type="checkbox" id="c-38285573" checked=""/><div class="controls bullet"><span class="by">john-radio</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38283224">prev</a><span>|</span><a href="#38284375">next</a><span>|</span><label class="collapse" for="c-38285573">[-]</label><label class="expand" for="c-38285573">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The field of philosophy is already ripe with ideas from hundreds of years ago that an artificial intelligence can use against people in debates of free will, self-determination and the nature of existence. This isn’t the battle to pick.<p>Uh, wouldn&#x27;t that apply equally to any other topic that has been argued extensively before, and to any tenable position on those topics? Like, I can make ChatGPT argue against your LLM sentience apologist-bot just as easily.</div><br/></div></div><div id="38284375" class="c"><input type="checkbox" id="c-38284375" checked=""/><div class="controls bullet"><span class="by">syndacks</span><span>|</span><a href="#38282491">parent</a><span>|</span><a href="#38285573">prev</a><span>|</span><a href="#38282616">next</a><span>|</span><label class="collapse" for="c-38284375">[-]</label><label class="expand" for="c-38284375">[2 more]</label></div><br/><div class="children"><div class="content">Sarah Connor was right!</div><br/></div></div></div></div><div id="38282616" class="c"><input type="checkbox" id="c-38282616" checked=""/><div class="controls bullet"><span class="by">sickcodebruh</span><span>|</span><a href="#38282491">prev</a><span>|</span><a href="#38282397">next</a><span>|</span><label class="collapse" for="c-38282616">[-]</label><label class="expand" for="c-38282616">[2 more]</label></div><br/><div class="children"><div class="content">One of my favorite experiences from my daughter’s earliest years was the realization that she was able to think about, describe, and deliberately do things much earlier than I realized. More plainly: once I recognized she was doing something deliberately, I often went back and realized she had been doing that same thing for days or weeks prior. We encountered this a lot with words but also physical abilities, like figuring out how to make her BabyBjorn bouncer move. We had a policy of talking to her like she understood on the off-chance that she could and just couldn’t communicate it. She just turned 5 and continues to surprise us with the complexity of her inner world.</div><br/><div id="38283347" class="c"><input type="checkbox" id="c-38283347" checked=""/><div class="controls bullet"><span class="by">marktangotango</span><span>|</span><a href="#38282616">parent</a><span>|</span><a href="#38282397">next</a><span>|</span><label class="collapse" for="c-38283347">[-]</label><label class="expand" for="c-38283347">[1 more]</label></div><br/><div class="children"><div class="content">We did this, and I&#x27;d add that repeating what they say back to them so they get that feedback is important too. It&#x27;s startling to see the difference between our kids and their class mates, who&#x27;s parents don&#x27;t talk them (I know this from observing at the countless birthday parties, school events, and sports events). Talking to kids is like watering flower, they bloom into beautiful beings.</div><br/></div></div></div></div><div id="38282397" class="c"><input type="checkbox" id="c-38282397" checked=""/><div class="controls bullet"><span class="by">karmakurtisaani</span><span>|</span><a href="#38282616">prev</a><span>|</span><a href="#38282372">next</a><span>|</span><label class="collapse" for="c-38282397">[-]</label><label class="expand" for="c-38282397">[10 more]</label></div><br/><div class="children"><div class="content">Nice article, great presentation.<p>However, it&#x27;s a bit annoying that the focus of the AI anxiety is how AI is replacing us and the resolution is that we embrace our humanity. Fair enough, but at least to me the main focus in my AI anxiety is that it will take my job - honestly don&#x27;t really care about it doing my shitty art.</div><br/><div id="38287141" class="c"><input type="checkbox" id="c-38287141" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38282397">parent</a><span>|</span><a href="#38282564">next</a><span>|</span><label class="collapse" for="c-38287141">[-]</label><label class="expand" for="c-38287141">[1 more]</label></div><br/><div class="children"><div class="content">I dont think that was the point of the article.<p>I think it was clear about how language is not thought.<p>That leads to the intrinsic realization that our physical existence, our observance of reality is what is critical.<p>Also, AI taking jobs at scale is unlikely, the only place its going to do anything is low level spam and content generation.<p>For anything which has to be factual, its going to need humans.</div><br/></div></div><div id="38282564" class="c"><input type="checkbox" id="c-38282564" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#38282397">parent</a><span>|</span><a href="#38287141">prev</a><span>|</span><a href="#38282505">next</a><span>|</span><label class="collapse" for="c-38282564">[-]</label><label class="expand" for="c-38282564">[6 more]</label></div><br/><div class="children"><div class="content">More specifically, I think we&#x27;re worried about AI taking our <i>incomes</i>, not our jobs. I would love it if an AI could do my entire job for me, and I just sat there collecting the income while the AI did all the &quot;job&quot; part, but we know from history (robotics) that this is not what happens. The owners of the robots (soon, AI) keep all the income and the job goes away.<p>An enlightened Humanity could solve this by separating the income from the job, but we live in a Malthusian Darwinian world where growth is paramount, &quot;enough&quot; does not exist, and we all have to justify and earn our living.</div><br/><div id="38283058" class="c"><input type="checkbox" id="c-38283058" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#38282397">root</a><span>|</span><a href="#38282564">parent</a><span>|</span><a href="#38283589">next</a><span>|</span><label class="collapse" for="c-38283058">[-]</label><label class="expand" for="c-38283058">[2 more]</label></div><br/><div class="children"><div class="content">I mean, I definitely hear (and feel) a lot of worry about AI taking away work that we find meaningful and interesting to do, outside of the pure money question.<p>I really like programming to fix things. Even if I weren’t paid for it, even if I were to win the lottery, I would want to write software that solved problems for people. It is a nice way to spend my days, and I love feeling useful when it works.<p>I would be very bummed - perhaps existentially so - if there were no <i>practical</i> reason ever to write software again.<p>And I know the same is true for many artists, writers, lawyers, and so on.</div><br/><div id="38284257" class="c"><input type="checkbox" id="c-38284257" checked=""/><div class="controls bullet"><span class="by">sushisource</span><span>|</span><a href="#38282397">root</a><span>|</span><a href="#38283058">parent</a><span>|</span><a href="#38283589">next</a><span>|</span><label class="collapse" for="c-38284257">[-]</label><label class="expand" for="c-38284257">[1 more]</label></div><br/><div class="children"><div class="content">The practical reason _is_ that it&#x27;s fun and you like it. That could be enough.<p>I&#x27;m not too concerned about that being a reality in our lifetimes though.</div><br/></div></div></div></div><div id="38283589" class="c"><input type="checkbox" id="c-38283589" checked=""/><div class="controls bullet"><span class="by">magneticnorth</span><span>|</span><a href="#38282397">root</a><span>|</span><a href="#38282564">parent</a><span>|</span><a href="#38283058">prev</a><span>|</span><a href="#38286116">next</a><span>|</span><label class="collapse" for="c-38283589">[-]</label><label class="expand" for="c-38283589">[2 more]</label></div><br/><div class="children"><div class="content">At some point someone said to me, &quot;How badly did we fuck up as a society that robots taking all our jobs is a bad thing.&quot;<p>And I think about that a lot.</div><br/><div id="38286893" class="c"><input type="checkbox" id="c-38286893" checked=""/><div class="controls bullet"><span class="by">bjelkeman-again</span><span>|</span><a href="#38282397">root</a><span>|</span><a href="#38283589">parent</a><span>|</span><a href="#38286116">next</a><span>|</span><label class="collapse" for="c-38286893">[-]</label><label class="expand" for="c-38286893">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t the problem that the person loosing the job and income isn’t the same person that owns the robot? If everyone owned a robot and could go to the beach instead it would be nice, except that some would work at the same time and outcompete those that didn’t?</div><br/></div></div></div></div><div id="38286116" class="c"><input type="checkbox" id="c-38286116" checked=""/><div class="controls bullet"><span class="by">IcyWindows</span><span>|</span><a href="#38282397">root</a><span>|</span><a href="#38282564">parent</a><span>|</span><a href="#38283589">prev</a><span>|</span><a href="#38282505">next</a><span>|</span><label class="collapse" for="c-38286116">[-]</label><label class="expand" for="c-38286116">[1 more]</label></div><br/><div class="children"><div class="content">You make it sound like we all aren&#x27;t those owners keeping the income?<p>Right now, we all own &quot;robots&quot; who spellcheck our words (editor) , research (librarian), play music (musican), send messages (courier), etc.<p>All these jobs are &quot;lost&quot;, but at the same time, we wouldn&#x27;t have had money to pay these many employees to live in our pocket.</div><br/></div></div></div></div><div id="38282505" class="c"><input type="checkbox" id="c-38282505" checked=""/><div class="controls bullet"><span class="by">nsfmc</span><span>|</span><a href="#38282397">parent</a><span>|</span><a href="#38282564">prev</a><span>|</span><a href="#38283462">next</a><span>|</span><label class="collapse" for="c-38282505">[-]</label><label class="expand" for="c-38282505">[1 more]</label></div><br/><div class="children"><div class="content">here&#x27;s another piece in the issue that addresses your concern <a href="https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2023&#x2F;11&#x2F;20&#x2F;a-coder-considers-the-waning-days-of-the-craft" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.newyorker.com&#x2F;magazine&#x2F;2023&#x2F;11&#x2F;20&#x2F;a-coder-consid...</a></div><br/></div></div><div id="38283462" class="c"><input type="checkbox" id="c-38283462" checked=""/><div class="controls bullet"><span class="by">djmips</span><span>|</span><a href="#38282397">parent</a><span>|</span><a href="#38282505">prev</a><span>|</span><a href="#38282372">next</a><span>|</span><label class="collapse" for="c-38283462">[-]</label><label class="expand" for="c-38283462">[1 more]</label></div><br/><div class="children"><div class="content">Your job is your art.</div><br/></div></div></div></div><div id="38282372" class="c"><input type="checkbox" id="c-38282372" checked=""/><div class="controls bullet"><span class="by">xianshou</span><span>|</span><a href="#38282397">prev</a><span>|</span><a href="#38282290">next</a><span>|</span><label class="collapse" for="c-38282372">[-]</label><label class="expand" for="c-38282372">[17 more]</label></div><br/><div class="children"><div class="content">Pour one out for the decline of human exceptionalism! Once you get material-reductionist enough and accept yourself as a pure function of genetics, environment, past experience, and chance, this conclusion becomes inevitable. I also expect it to be the standard within a decade, with AI-human parity of capabilities as the key driver.</div><br/><div id="38282672" class="c"><input type="checkbox" id="c-38282672" checked=""/><div class="controls bullet"><span class="by">jancsika</span><span>|</span><a href="#38282372">parent</a><span>|</span><a href="#38287127">next</a><span>|</span><label class="collapse" for="c-38282672">[-]</label><label class="expand" for="c-38282672">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not convinced that this material-reductionist view wouldn&#x27;t just be functionally equivalent to the way a majority of citizens live their lives currently.<p>Now: a chance encounter with someone of a different faith leads a citizen to respect the religious freedom of others in the realm of self-determination.<p>Future: a young hacker&#x27;s formative experience leads to the idea that citizens should have the basic right to change out their device&#x27;s recommendation engine with a random number generator at will.<p>Those future humans will still think of themselves as exceptional because the AI tools will have developed right alongside the current human-exceptionalist ideology.<p>Kinda like those old conservative couples I see in the South where the man is ostensibly the story teller and head of household. But if you listen long enough you notice his wife is whispering nearly every detail of importance to help him maintain coherence.</div><br/><div id="38285545" class="c"><input type="checkbox" id="c-38285545" checked=""/><div class="controls bullet"><span class="by">PH95VuimJjqBqy</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282672">parent</a><span>|</span><a href="#38287127">next</a><span>|</span><label class="collapse" for="c-38285545">[-]</label><label class="expand" for="c-38285545">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Kinda like those old conservative couples I see in the South where the man is ostensibly the story teller and head of household. But if you listen long enough you notice his wife is whispering nearly every detail of importance to help him maintain coherence.<p>You&#x27;ve never actually seen this happen because it doesn&#x27;t happen.  This is not how real people interact, it&#x27;s how the caricatures in your head interact.</div><br/><div id="38286144" class="c"><input type="checkbox" id="c-38286144" checked=""/><div class="controls bullet"><span class="by">gotoeleven</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38285545">parent</a><span>|</span><a href="#38287127">next</a><span>|</span><label class="collapse" for="c-38286144">[-]</label><label class="expand" for="c-38286144">[1 more]</label></div><br/><div class="children"><div class="content">No Jansicka&#x27;s Tales of Things that Totally Happened in the South is a #1 New York Times best seller.</div><br/></div></div></div></div></div></div><div id="38287127" class="c"><input type="checkbox" id="c-38287127" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#38282372">parent</a><span>|</span><a href="#38282672">prev</a><span>|</span><a href="#38282410">next</a><span>|</span><label class="collapse" for="c-38287127">[-]</label><label class="expand" for="c-38287127">[1 more]</label></div><br/><div class="children"><div class="content">The conclusion of the article is that the toddler is <i>not</i> a stochastic parrot. But only because it has a life in the real world. I think she&#x27;s trying to say that the toddler is <i>more</i> than a stochastic parrot because of real life experiences.<p>But then I have no idea how she goes on to conclude:<p>&gt; Human obsolescence is not here and never can be.<p>There&#x27;s no fundamental reason why you can&#x27;t put ChatGPT in the real world and give it a real life. The only things that probably will <i>never</i> be replaced by machines are things where our physical technology is likely never going to match biology - i.e. sex.</div><br/></div></div><div id="38282410" class="c"><input type="checkbox" id="c-38282410" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282372">parent</a><span>|</span><a href="#38287127">prev</a><span>|</span><a href="#38282290">next</a><span>|</span><label class="collapse" for="c-38282410">[-]</label><label class="expand" for="c-38282410">[12 more]</label></div><br/><div class="children"><div class="content">We&#x27;ll see!  I came to this conclusion a long time ago but at the same time I do subjectively experience consciousness, which in itself is something a mystery in the material-reductionist philosophy.</div><br/><div id="38282553" class="c"><input type="checkbox" id="c-38282553" checked=""/><div class="controls bullet"><span class="by">idle_zealot</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282410">parent</a><span>|</span><a href="#38282577">next</a><span>|</span><label class="collapse" for="c-38282553">[-]</label><label class="expand" for="c-38282553">[8 more]</label></div><br/><div class="children"><div class="content">I hear this a lot, but is it really a mystery&#x2F;incompatible with materialism? Is there a reason consciousness couldn&#x27;t be what it feels like to be a certain type of computation? I don&#x27;t see why we would need something immaterial or some undiscovered material component to explain it.</div><br/><div id="38282716" class="c"><input type="checkbox" id="c-38282716" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282553">parent</a><span>|</span><a href="#38282916">next</a><span>|</span><label class="collapse" for="c-38282716">[-]</label><label class="expand" for="c-38282716">[1 more]</label></div><br/><div class="children"><div class="content">I mean, if you&#x27;re a compatibilist, there&#x27;s no mystery.  In that model, we live in a causally deterministic universe but still have free will.  
I would say instead &quot;the <i>subjective experience of consciousness</i> is an <i>emergent property</i> of <i>complex systems with certain properties</i>&quot;.  I guess that&#x27;s consistent with &quot;the experience of consciousness is the feeling of a certain type of computation&quot;.<p>Personally these sorts of things don&#x27;t really matter to me- I don&#x27;t really care if other people are conscious, and I don&#x27;t think I could prove it either way- I just assume other people are conscious, and that we can make computers that are conscious.<p>And that&#x27;s exactly what I&#x27;m pushing for: ML that passes every Turing-style test that we can come up with.  Because, as they say &quot;if you can&#x27;t tell, does it really matter?&quot;</div><br/></div></div><div id="38282916" class="c"><input type="checkbox" id="c-38282916" checked=""/><div class="controls bullet"><span class="by">beezlebroxxxxxx</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282553">parent</a><span>|</span><a href="#38282716">prev</a><span>|</span><a href="#38282621">next</a><span>|</span><label class="collapse" for="c-38282916">[-]</label><label class="expand" for="c-38282916">[2 more]</label></div><br/><div class="children"><div class="content">Why is consciousness computation? What does it even mean to say something feels like being &quot;a type of computation&quot;?<p>The concept of consciousness is wildly more expansive and diverse than computation, rather than the other way around. A strict materialist account or &quot;explanation&quot; of consciousness seems to just end up a category error.<p>I take it as no surprise that a website devoted to the computers and software often <i>insists</i> that this is the only way to look at it, but there are entire philosophical movements that have developed fascinating accounts of consciousness that are far from strict materialism, nor are they &quot;spiritual&quot; or religious which is a common rejoinder by materialists, an example is the implications of Ludwig Wittgenstein&#x27;s work from <i>Philosophical Investigations</i> and his analysis of language. And even in neuroscience there is far from complete agreement on the topic at all.</div><br/><div id="38285645" class="c"><input type="checkbox" id="c-38285645" checked=""/><div class="controls bullet"><span class="by">ux-app</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282916">parent</a><span>|</span><a href="#38282621">next</a><span>|</span><label class="collapse" for="c-38285645">[-]</label><label class="expand" for="c-38285645">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Why is consciousness computation?<p>if there is no duality, then what else can it be?<p>&gt; there are entire philosophical movements that have developed fascinating accounts of consciousness that are far from strict materialism<p>philosophers can bloviate all day. meanwhile the computer nerds built a machine that can engage in creative conversation, pass physician and bar exams, create art, music and code.<p>I&#x27;m not saying there&#x27;s <i>nothing</i> to learn from philosophy, but gee you have to admit that philosophers come up a little short wrt practical applications of their &quot;Philosophical Investigations&quot;</div><br/></div></div></div></div><div id="38282621" class="c"><input type="checkbox" id="c-38282621" checked=""/><div class="controls bullet"><span class="by">kaibee</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282553">parent</a><span>|</span><a href="#38282916">prev</a><span>|</span><a href="#38282577">next</a><span>|</span><label class="collapse" for="c-38282621">[-]</label><label class="expand" for="c-38282621">[4 more]</label></div><br/><div class="children"><div class="content">Well the undiscovered part is why it should feel like anything at all.  And this is definitely relevant because consciousness clearly exists enough that we exert physical force about it, so its gotta be somewhere in physics.  But where?</div><br/><div id="38282922" class="c"><input type="checkbox" id="c-38282922" checked=""/><div class="controls bullet"><span class="by">idle_zealot</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282621">parent</a><span>|</span><a href="#38282944">next</a><span>|</span><label class="collapse" for="c-38282922">[-]</label><label class="expand" for="c-38282922">[2 more]</label></div><br/><div class="children"><div class="content">Why does it need to be in physics? What would that look like, a Qualia Boson? It could be an emergent property like life itself. Physics doesn&#x27;t &quot;explain&quot; life, it explains the physical mechanisms behind the chemical interactions that ultimately produce life by virtue of self-replicating patterns spreading and mutating. There is no Life is physics, and yet we see it all around it because it emerges as a complex result of fundamental rules. My expectation is that experience is emergent from computation that controls an agent and models the world around that agent, and that experience isn&#x27;t a binary. A tree is more aware than a rock, an ant more than a tree, a squirrel more than an ant, and so on until you reach humans, but there may not be any real change in kind as the conditions for experience become more developed.<p>I guess my real point is that I don&#x27;t view experience or consciousness as something special or exceptional. My guess is that over time we come to understand how the brain works better and better but never find anything that definitively explains consciousness because it&#x27;s totally subjective and immeasurable. We eventually produce computers complex enough to behave totally convincingly human, and they will claim to be conscious, maybe even be granted personhood, but we&#x27;ll never actually know for sure if they experience the world, just like we don&#x27;t know that other humans do.</div><br/><div id="38285559" class="c"><input type="checkbox" id="c-38285559" checked=""/><div class="controls bullet"><span class="by">PH95VuimJjqBqy</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282922">parent</a><span>|</span><a href="#38282944">next</a><span>|</span><label class="collapse" for="c-38285559">[-]</label><label class="expand" for="c-38285559">[1 more]</label></div><br/><div class="children"><div class="content">If life is an emergent property of physics then it&#x27;s replicable which means it&#x27;s not spiritual.</div><br/></div></div></div></div><div id="38282944" class="c"><input type="checkbox" id="c-38282944" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282621">parent</a><span>|</span><a href="#38282922">prev</a><span>|</span><a href="#38282577">next</a><span>|</span><label class="collapse" for="c-38282944">[-]</label><label class="expand" for="c-38282944">[1 more]</label></div><br/><div class="children"><div class="content">Toward the end of Hofstadter’s Gödel, Escher, Bach there is a simple and plausible recursive attentional explanation, but without any serious neuroscience. The thalamo-cortico-thalamic system is a massively recursive CNS system. Ray Guillery’s biok The Brain As A Tool is a good introduction to the relevant neuroscience with a hat tip to consciousness written long after GEB.</div><br/></div></div></div></div></div></div><div id="38282577" class="c"><input type="checkbox" id="c-38282577" checked=""/><div class="controls bullet"><span class="by">throwaway4aday</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282410">parent</a><span>|</span><a href="#38282553">prev</a><span>|</span><a href="#38285732">next</a><span>|</span><label class="collapse" for="c-38282577">[-]</label><label class="expand" for="c-38282577">[2 more]</label></div><br/><div class="children"><div class="content">It makes perfect sense if you can disprove your own existence</div><br/><div id="38286520" class="c"><input type="checkbox" id="c-38286520" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282577">parent</a><span>|</span><a href="#38285732">next</a><span>|</span><label class="collapse" for="c-38286520">[-]</label><label class="expand" for="c-38286520">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t disprove your existence, I&#x27;m pretty sure that does not make any sense. &quot;I think therefore I am.&quot; No need for free will of any type there, and a currently existing computer could probably do the same thing.</div><br/></div></div></div></div><div id="38285732" class="c"><input type="checkbox" id="c-38285732" checked=""/><div class="controls bullet"><span class="by">corethree</span><span>|</span><a href="#38282372">root</a><span>|</span><a href="#38282410">parent</a><span>|</span><a href="#38282577">prev</a><span>|</span><a href="#38282290">next</a><span>|</span><label class="collapse" for="c-38285732">[-]</label><label class="expand" for="c-38285732">[1 more]</label></div><br/><div class="children"><div class="content">We can&#x27;t even define what that experience means. From all the information we have the experience is most likely just a physical manifestation of what the parent poster describes.</div><br/></div></div></div></div></div></div><div id="38282290" class="c"><input type="checkbox" id="c-38282290" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#38282372">prev</a><span>|</span><a href="#38282132">next</a><span>|</span><label class="collapse" for="c-38282290">[-]</label><label class="expand" for="c-38282290">[4 more]</label></div><br/><div class="children"><div class="content">When my toddler was first learning to talk, we had some pictures of felines hanging on the walls; some were cats and others were kittens.<p>She quickly generalized; henceforth, both of them were &quot;catten&quot;.</div><br/><div id="38283486" class="c"><input type="checkbox" id="c-38283486" checked=""/><div class="controls bullet"><span class="by">djmips</span><span>|</span><a href="#38282290">parent</a><span>|</span><a href="#38282545">next</a><span>|</span><label class="collapse" for="c-38283486">[-]</label><label class="expand" for="c-38283486">[2 more]</label></div><br/><div class="children"><div class="content">My toddler understood that places to buy things were called stores and understood eating - so restaurants were deemed &#x27;eating stores&#x27;. And we just went with that for a long time and now they are grown we still call them eating stores for fun sometimes. :)</div><br/><div id="38285281" class="c"><input type="checkbox" id="c-38285281" checked=""/><div class="controls bullet"><span class="by">liminalsunset</span><span>|</span><a href="#38282290">root</a><span>|</span><a href="#38283486">parent</a><span>|</span><a href="#38282545">next</a><span>|</span><label class="collapse" for="c-38285281">[-]</label><label class="expand" for="c-38285281">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, in Chinese, the actual word for a &quot;restaurant&quot; is often quite literally translated, &quot;meal&#x2F;food store&quot;, or 饭店, and a 店 is just a store.</div><br/></div></div></div></div><div id="38282545" class="c"><input type="checkbox" id="c-38282545" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#38282290">parent</a><span>|</span><a href="#38283486">prev</a><span>|</span><a href="#38282132">next</a><span>|</span><label class="collapse" for="c-38282545">[-]</label><label class="expand" for="c-38282545">[1 more]</label></div><br/><div class="children"><div class="content">Good toddler</div><br/></div></div></div></div><div id="38282132" class="c"><input type="checkbox" id="c-38282132" checked=""/><div class="controls bullet"><span class="by">carlossouza</span><span>|</span><a href="#38282290">prev</a><span>|</span><a href="#38282958">next</a><span>|</span><label class="collapse" for="c-38282132">[-]</label><label class="expand" for="c-38282132">[8 more]</label></div><br/><div class="children"><div class="content">Great essay; impressive content.<p>The fact that it&#x27;s very unlikely for any of the current models to create something that even remotely resembles this article tells me we are very far away from AGI.</div><br/><div id="38282143" class="c"><input type="checkbox" id="c-38282143" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38282132">parent</a><span>|</span><a href="#38282204">next</a><span>|</span><label class="collapse" for="c-38282143">[-]</label><label class="expand" for="c-38282143">[4 more]</label></div><br/><div class="children"><div class="content">don&#x27;t underestimate exponentials</div><br/><div id="38282458" class="c"><input type="checkbox" id="c-38282458" checked=""/><div class="controls bullet"><span class="by">breuleux</span><span>|</span><a href="#38282132">root</a><span>|</span><a href="#38282143">parent</a><span>|</span><a href="#38282533">next</a><span>|</span><label class="collapse" for="c-38282458">[-]</label><label class="expand" for="c-38282458">[1 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s not see exponentials everywhere either. It&#x27;s not because things seem to be progressing very fast that exponentials are involved. More often than not they are logistic curves.</div><br/></div></div><div id="38282533" class="c"><input type="checkbox" id="c-38282533" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282132">root</a><span>|</span><a href="#38282143">parent</a><span>|</span><a href="#38282458">prev</a><span>|</span><a href="#38285156">next</a><span>|</span><label class="collapse" for="c-38282533">[-]</label><label class="expand" for="c-38282533">[1 more]</label></div><br/><div class="children"><div class="content">or the power of sigmoids to replace exponentials when the exponential peters out.</div><br/></div></div><div id="38285156" class="c"><input type="checkbox" id="c-38285156" checked=""/><div class="controls bullet"><span class="by">mempko</span><span>|</span><a href="#38282132">root</a><span>|</span><a href="#38282143">parent</a><span>|</span><a href="#38282533">prev</a><span>|</span><a href="#38282204">next</a><span>|</span><label class="collapse" for="c-38285156">[-]</label><label class="expand" for="c-38285156">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Global Warming and species decline&#x2F;extinction (we are in the 6th mass extinction) all appear to be exponential. The question is, will we have AGI before we destroy ourselves?</div><br/></div></div></div></div><div id="38282204" class="c"><input type="checkbox" id="c-38282204" checked=""/><div class="controls bullet"><span class="by">pcthrowaway</span><span>|</span><a href="#38282132">parent</a><span>|</span><a href="#38282143">prev</a><span>|</span><a href="#38282958">next</a><span>|</span><label class="collapse" for="c-38282204">[-]</label><label class="expand" for="c-38282204">[3 more]</label></div><br/><div class="children"><div class="content">Did you miss the disclaimer at the bottom that both visual artwork and prose were produced by a combination of generative AI tools and creative prompting? The entire seamless watercolor style piece was just a long outpainting</div><br/><div id="38282279" class="c"><input type="checkbox" id="c-38282279" checked=""/><div class="controls bullet"><span class="by">iwanttocomment</span><span>|</span><a href="#38282132">root</a><span>|</span><a href="#38282204">parent</a><span>|</span><a href="#38282262">next</a><span>|</span><label class="collapse" for="c-38282279">[-]</label><label class="expand" for="c-38282279">[1 more]</label></div><br/><div class="children"><div class="content">I read the article, read your comment, went back to review the article, and there was no such disclaimer. If this is &#x2F;s, whoosh.</div><br/></div></div><div id="38282262" class="c"><input type="checkbox" id="c-38282262" checked=""/><div class="controls bullet"><span class="by">carlossouza</span><span>|</span><a href="#38282132">root</a><span>|</span><a href="#38282204">parent</a><span>|</span><a href="#38282279">prev</a><span>|</span><a href="#38282958">next</a><span>|</span><label class="collapse" for="c-38282262">[-]</label><label class="expand" for="c-38282262">[1 more]</label></div><br/><div class="children"><div class="content">hahaha that&#x27;s why I love HN :)</div><br/></div></div></div></div></div></div><div id="38282958" class="c"><input type="checkbox" id="c-38282958" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#38282132">prev</a><span>|</span><a href="#38282538">next</a><span>|</span><label class="collapse" for="c-38282958">[-]</label><label class="expand" for="c-38282958">[7 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s reductivism to assume that neural networks cannot emergently support&#x2F;implement a non-stochastic computational model capable of explicit logical reasoning.<p>We already have an instance of emergent logic. Animals engage in logical reasoning. Corollary, humans and toddlers are not merely super-autocompletes or stochastic parrots.<p>It has nothing to do with &quot;sensory embodiment&quot; and&#x2F;or &quot;personal agency&quot; arguments like in the article. Nor the clever solipsism and reductivism of &quot;my mind is just random statistics of neural firing&quot;. It&#x27;s about finding out what the models of computation actually are.</div><br/><div id="38284069" class="c"><input type="checkbox" id="c-38284069" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282958">parent</a><span>|</span><a href="#38282538">next</a><span>|</span><label class="collapse" for="c-38284069">[-]</label><label class="expand" for="c-38284069">[6 more]</label></div><br/><div class="children"><div class="content">Imagine that for some reason and by some unknown agency, somebody in 1068 could build something that was functionally equivalent to one of the contemporary LLMs of today (it would likely be mechanical and thus slower, but let&#x27;s just ignore speed because that&#x27;s mostly a substrate artifact).<p>OK, time to train up our LLM.<p>Oops. Printing not yet invented. Books are scarce, and frequently not copied. We have almost no input data to give to our analog LLM.<p>Will it be of any use whatsoever? I think we can say with a high degree of confidence that it will not.<p>However, contrast a somewhat typical human from the same era. Will they suffer from any fundamental limitation compared to someone alive today? Will there be skills they cannot acquire? Languages they cannot learn? It&#x27;s not quite so easy to be completely confident about the answer to this, but I think there&#x27;s a strong case for &quot;no&quot;.<p>The data dependence of LLMs compared to human (or ravens) makes a compelling argument that they are not operating in the same way (or, if they are, they have somehow reduced the data dependency in an incredibly dramatic way, such that it may still be reasonable to differentiate the mechanisms).</div><br/><div id="38286993" class="c"><input type="checkbox" id="c-38286993" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#38282958">root</a><span>|</span><a href="#38284069">parent</a><span>|</span><a href="#38286285">next</a><span>|</span><label class="collapse" for="c-38286993">[-]</label><label class="expand" for="c-38286993">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t find that a compelling argument :)<p>If one computational model accepts only assembly code, and another model accepts only C++, it tells us nothing about what is going on inside their black boxes. They could be doing computationally fundamentally equivalent things, or totally different things. We don&#x27;t know till we look.<p>My point was really about neural networks in general. The argument is that neural networks include both humans and synthetic ones. The myopic focus on LLMs (because of mainstream media coverage) as they exist now is what limits such arguments.</div><br/></div></div><div id="38286285" class="c"><input type="checkbox" id="c-38286285" checked=""/><div class="controls bullet"><span class="by">intelkishan</span><span>|</span><a href="#38282958">root</a><span>|</span><a href="#38284069">parent</a><span>|</span><a href="#38286993">prev</a><span>|</span><a href="#38284432">next</a><span>|</span><label class="collapse" for="c-38286285">[-]</label><label class="expand" for="c-38286285">[3 more]</label></div><br/><div class="children"><div class="content">A common counterargument is that organisms already have information stored in their DNA, which in turn has a noticeable impact on their behaviour. Plus the fact that they receive a large amount of sensory data which is often discounted in such debates.</div><br/><div id="38286419" class="c"><input type="checkbox" id="c-38286419" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#38282958">root</a><span>|</span><a href="#38286285">parent</a><span>|</span><a href="#38284432">next</a><span>|</span><label class="collapse" for="c-38286419">[-]</label><label class="expand" for="c-38286419">[2 more]</label></div><br/><div class="children"><div class="content">Great, instead of using a corpus, just use videos from toddlers walking around with a go pro as training data for your AI model and see how far that gets you.</div><br/><div id="38287093" class="c"><input type="checkbox" id="c-38287093" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#38282958">root</a><span>|</span><a href="#38286419">parent</a><span>|</span><a href="#38284432">next</a><span>|</span><label class="collapse" for="c-38287093">[-]</label><label class="expand" for="c-38287093">[1 more]</label></div><br/><div class="children"><div class="content">Well I think toddlers get both offline training from millions of years of evolution (idea being that evolution itself is nature&#x27;s very own training algorithm, a computational process that creates genetic information), and online training in the form of nurture and environmental interaction -- and of course AI professors are saying the way to go is to research was to make online training possible for models.<p>But the crux is that both kinds of &quot;training&quot; - almost a loaded term by now - are open areas of scientific research.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38282538" class="c"><input type="checkbox" id="c-38282538" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#38282958">prev</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38282538">[-]</label><label class="expand" for="c-38282538">[10 more]</label></div><br/><div class="children"><div class="content">This is a really beautiful article, and while there are certainly fundamental differences between how a toddler thinks and learns, and how an LLM &quot;thinks&quot;, I don&#x27;t think we should get too comfortable with those differences.<p>Every time I say to myself &quot;AI is no big deal because it can&#x27;t do X&quot;, some time later someone comes along and makes an AI that does X.</div><br/><div id="38283255" class="c"><input type="checkbox" id="c-38283255" checked=""/><div class="controls bullet"><span class="by">alexwebb2</span><span>|</span><a href="#38282538">parent</a><span>|</span><a href="#38284002">next</a><span>|</span><label class="collapse" for="c-38283255">[-]</label><label class="expand" for="c-38283255">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a well-documented concept called &quot;God of the gaps&quot; where any phenomenon humans don&#x27;t understand at the time is attributed to a divine entity.<p>Over time, as the gaps in human knowledge get filled, the god &quot;shrinks&quot; - it becomes less expansive, less powerful, less directly involved in human affairs. The definition changes.<p>It&#x27;s fascinating to watch the same thing happen with human exceptionalism – so many cries of &quot;but AI can&#x27;t do &lt;thing that&#x27;s rapidly approaching&gt;&quot;. It&#x27;s &quot;human of the gaps&quot;, and those gaps are rapidly closing.</div><br/><div id="38284157" class="c"><input type="checkbox" id="c-38284157" checked=""/><div class="controls bullet"><span class="by">allemagne</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38283255">parent</a><span>|</span><a href="#38284955">next</a><span>|</span><label class="collapse" for="c-38284157">[-]</label><label class="expand" for="c-38284157">[1 more]</label></div><br/><div class="children"><div class="content">&quot;God is dead&quot; is beyond passé in the 2020s, but in the 19th century nobody really needed a &quot;god of the gaps.&quot; If a Friedrich Nietzsche equivalent was active today, and let&#x27;s just say was convinced that AGI was possible, I kind of wonder what generally accepted grand narrative he&#x27;d declare dead beyond just human exceptionalism. Philosophy itself?</div><br/></div></div><div id="38284955" class="c"><input type="checkbox" id="c-38284955" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38283255">parent</a><span>|</span><a href="#38284157">prev</a><span>|</span><a href="#38284002">next</a><span>|</span><label class="collapse" for="c-38284955">[-]</label><label class="expand" for="c-38284955">[2 more]</label></div><br/><div class="children"><div class="content">I honestly don&#x27;t know where this is supposed to be happening. I have observed the opposite for decades. When Gary Kasparov was beaten by Stockfish, people proclaimed the end of chess and went on AI hyperboles. Same with Watson winning Jeopardy, Alexa, etc.<p>Every time computers outperform humans in some domain this is conflated with deep general progress, panicked projections of replacement and job losses, the end times and so on. People are way faster to engage in reductionism of human capacity and Terminator-esque fantasies than the opposite. Despite the fact that it never happens.<p>It&#x27;s even reflected in our popular culture. I can barely recall a single work of science fiction in the last 30 years that would qualify as portraying human exceptionalism. AI doomerism, overestimation and fear of machines is the norm.</div><br/><div id="38285195" class="c"><input type="checkbox" id="c-38285195" checked=""/><div class="controls bullet"><span class="by">alexwebb2</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38284955">parent</a><span>|</span><a href="#38284002">next</a><span>|</span><label class="collapse" for="c-38285195">[-]</label><label class="expand" for="c-38285195">[1 more]</label></div><br/><div class="children"><div class="content">“but AI can’t create art”<p>“but AI can’t write poetry”<p>“but AI can’t do real work”<p>Panic is probably not warranted. Too much incentive stacked against the truly apocalyptic scenarios. But yeah, a lot of jobs are probably going to shrink.</div><br/></div></div></div></div></div></div><div id="38284002" class="c"><input type="checkbox" id="c-38284002" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282538">parent</a><span>|</span><a href="#38283255">prev</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38284002">[-]</label><label class="expand" for="c-38284002">[5 more]</label></div><br/><div class="children"><div class="content">Then never say to yourself &quot;AI is no big deal because it can&#x27;t do X&quot;.<p>Say instead (for example) &quot;It is important that I understand the differences between both the capabilities and internal mechanisms of AI and people, even if, over some period of time, the capabilities may appear to converge&quot;.</div><br/><div id="38284601" class="c"><input type="checkbox" id="c-38284601" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38284002">parent</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38284601">[-]</label><label class="expand" for="c-38284601">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not terribly interested in truisms, I&#x27;m more interested in figuring out what AIs <i>actually</i> cannot fundamentally do, if anything (present or future).</div><br/><div id="38285116" class="c"><input type="checkbox" id="c-38285116" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38284601">parent</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38285116">[-]</label><label class="expand" for="c-38285116">[3 more]</label></div><br/><div class="children"><div class="content">What are the things that humans actually cannot fundamentally do, if anything?</div><br/><div id="38285717" class="c"><input type="checkbox" id="c-38285717" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38285116">parent</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38285717">[-]</label><label class="expand" for="c-38285717">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a very large set of things. Calculating 1000000 digits of the decimal expansion of pi within an hour would be just one example.</div><br/><div id="38286499" class="c"><input type="checkbox" id="c-38286499" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#38282538">root</a><span>|</span><a href="#38285717">parent</a><span>|</span><a href="#38286660">next</a><span>|</span><label class="collapse" for="c-38286499">[-]</label><label class="expand" for="c-38286499">[1 more]</label></div><br/><div class="children"><div class="content">To be super cheeky:<p><pre><code>  wget https:&#x2F;&#x2F;bellard.org&#x2F;pi&#x2F;pi2700e9&#x2F;tpi-0.9-linux.tar.gz
  tar xvf  tpi-0.9-linux.tar.gz 
  time .&#x2F;tpi -T 8 -o pi.txt 1M
  real 0m0.176s
  user 0m0.500s
  sys 0m0.049s</code></pre></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38286660" class="c"><input type="checkbox" id="c-38286660" checked=""/><div class="controls bullet"><span class="by">gniv</span><span>|</span><a href="#38282538">prev</a><span>|</span><a href="#38283892">next</a><span>|</span><label class="collapse" for="c-38286660">[-]</label><label class="expand" for="c-38286660">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>A toddler has a life, and learns language to describe it. An L.L.M. learns language but has no life of its own to describe.</i><p>That&#x27;s an interesting insight that seems true <i>for now</i>.
Are there attempts to create LLMs that &quot;have a life&quot;?</div><br/></div></div><div id="38283892" class="c"><input type="checkbox" id="c-38283892" checked=""/><div class="controls bullet"><span class="by">ganzuul</span><span>|</span><a href="#38286660">prev</a><span>|</span><a href="#38285994">next</a><span>|</span><label class="collapse" for="c-38283892">[-]</label><label class="expand" for="c-38283892">[2 more]</label></div><br/><div class="children"><div class="content">You are an evolutionary being, part of a much greater process than the process in your head. Your mind extends beyond your body and even if your mind was frozen in time like an LLM it would still be alive because it remains in a living environment.<p>Like so the Earth is alive and the universe would not be complete without you. Rest easy, little bird. One day you will spread the wings of your soul and the wind will do the rest.</div><br/><div id="38286555" class="c"><input type="checkbox" id="c-38286555" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#38283892">parent</a><span>|</span><a href="#38285994">next</a><span>|</span><label class="collapse" for="c-38286555">[-]</label><label class="expand" for="c-38286555">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Like so the Earth is alive and the universe would not be complete without you.<p>That&#x27;s a definitional argument, there is very little actual meaning there. The argument can&#x27;t discriminate between a baby and a nuclear explosion destroying Manhattan.</div><br/></div></div></div></div><div id="38285994" class="c"><input type="checkbox" id="c-38285994" checked=""/><div class="controls bullet"><span class="by">jeswin</span><span>|</span><a href="#38283892">prev</a><span>|</span><a href="#38282659">next</a><span>|</span><label class="collapse" for="c-38285994">[-]</label><label class="expand" for="c-38285994">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A stochastic parrot, as described in a seminal paper [1] ....<p>A bit of an exaggeration. The paper reads like a long blog post to me.<p>[1]: <a href="https:&#x2F;&#x2F;s10251.pcdn.co&#x2F;pdf&#x2F;2021-bender-parrots.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;s10251.pcdn.co&#x2F;pdf&#x2F;2021-bender-parrots.pdf</a></div><br/></div></div><div id="38282659" class="c"><input type="checkbox" id="c-38282659" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38285994">prev</a><span>|</span><a href="#38283212">next</a><span>|</span><label class="collapse" for="c-38282659">[-]</label><label class="expand" for="c-38282659">[1 more]</label></div><br/><div class="children"><div class="content">If you wonder about toddlers, wait til you have teenagers.<p>In fact I&#x27;ve observed (after working with a number of world-class ML researchers) that having children is the one thing that convinces ML people that learning is both much easier and much harder than what they do in computers.</div><br/></div></div><div id="38283212" class="c"><input type="checkbox" id="c-38283212" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#38282659">prev</a><span>|</span><a href="#38283137">next</a><span>|</span><label class="collapse" for="c-38283212">[-]</label><label class="expand" for="c-38283212">[1 more]</label></div><br/><div class="children"><div class="content">Language acquisition &gt; See also: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Language_acquisition" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Language_acquisition</a><p>Phonological development: 
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Phonological_development" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Phonological_development</a><p>Imitation &gt; Child development: 
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Imitation#Child_development" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Imitation#Child_development</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33800104">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33800104</a> :<p>&gt; <i>&quot;The Everyday Parenting Toolkit: The Kazdin Method for Easy, Step-by-Step, Lasting Change for You and Your Child&quot; <a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?kgmid=&#x2F;g&#x2F;11h7dr5mm6&amp;hl=en-US&amp;q=The+Everyday+Parenting+Toolkit:+The+Kazdin+Method+for+Easy,+Step-By-Step,+Lasting+Change+for+You+and+Your+Child&amp;kgs=4b6cd4b0fdf5bc04&amp;shndl=17&amp;source=sh&#x2F;x&#x2F;kp&#x2F;osrp&#x2F;2&amp;entrypoint=sh&#x2F;x&#x2F;kp&#x2F;osrp" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?kgmid=&#x2F;g&#x2F;11h7dr5mm6&amp;hl=en-US&amp;q...</a> </i><p>&gt; <i>&quot;Everyday Parenting: The ABCs of Child Rearing&quot; (Kazdin, Yale,) <a href="https:&#x2F;&#x2F;www.coursera.org&#x2F;learn&#x2F;everyday-parenting" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.coursera.org&#x2F;learn&#x2F;everyday-parenting</a> </i><p>&gt; <i>Re: Effective praise and Validating parenting</i> [and parroting]</div><br/></div></div><div id="38283137" class="c"><input type="checkbox" id="c-38283137" checked=""/><div class="controls bullet"><span class="by">birdman3131</span><span>|</span><a href="#38283212">prev</a><span>|</span><a href="#38283989">next</a><span>|</span><label class="collapse" for="c-38283137">[-]</label><label class="expand" for="c-38283137">[2 more]</label></div><br/><div class="children"><div class="content">Interesting article. However it becomes very close to unreadable just after the cliffhanger. Given that they use the word vertigo around the same point it all straightens back up I assume it is an explicit choice but it feels like a very bad choice for anybody with any sort of reading disorder. Very wavy lines of text along with side by side paragraphs with little to differentiate them from each other.</div><br/><div id="38283785" class="c"><input type="checkbox" id="c-38283785" checked=""/><div class="controls bullet"><span class="by">bibanez</span><span>|</span><a href="#38283137">parent</a><span>|</span><a href="#38283989">next</a><span>|</span><label class="collapse" for="c-38283785">[-]</label><label class="expand" for="c-38283785">[1 more]</label></div><br/><div class="children"><div class="content">When there&#x27;s a lot of text that represents distress&#x2F;anxiety, I just skip it. Call me a bad reader, but I get the gist of it and I think that&#x27;s more important that the exact details of what&#x27;s it saying</div><br/></div></div></div></div><div id="38283989" class="c"><input type="checkbox" id="c-38283989" checked=""/><div class="controls bullet"><span class="by">andersrs</span><span>|</span><a href="#38283137">prev</a><span>|</span><a href="#38282629">next</a><span>|</span><label class="collapse" for="c-38283989">[-]</label><label class="expand" for="c-38283989">[2 more]</label></div><br/><div class="children"><div class="content">With AI devaluing human creativity and thought I wonder what is left to be proud of? One&#x27;s body? It seems like humans will be valued more based on their looks than anything else. Apps like Tinder, Instagram, OnlyFans have already been pushing in this direction but AI will take it further and devalue the one valuable trait that the less attractive people could compete on. AI will also compete with porn but the tech for replacing physical human bodies is nowhere near as advanced. The winners will be attractive women and maybe plumbers. The losers will be everyone else but especially men.</div><br/><div id="38284008" class="c"><input type="checkbox" id="c-38284008" checked=""/><div class="controls bullet"><span class="by">phist_mcgee</span><span>|</span><a href="#38283989">parent</a><span>|</span><a href="#38282629">next</a><span>|</span><label class="collapse" for="c-38284008">[-]</label><label class="expand" for="c-38284008">[1 more]</label></div><br/><div class="children"><div class="content">Hairdressers and telephone sanitisers will eventually get the last laugh.</div><br/></div></div></div></div><div id="38282629" class="c"><input type="checkbox" id="c-38282629" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38283989">prev</a><span>|</span><a href="#38283796">next</a><span>|</span><label class="collapse" for="c-38282629">[-]</label><label class="expand" for="c-38282629">[2 more]</label></div><br/><div class="children"><div class="content">I think the position of Gebru, et al, can best be expressed as a form of &quot;human exceptionalism&quot;.  As a teenager, my english teacher shared this writing by Faulkner, which he delivered as his Nobel Prize speech.  I complained because the writing completely ignores the laws of thermodynamics about the end of the universe.<p>&quot;&quot;&quot;I believe that when the last ding-dong of doom has clanged and faded from the last worthless rock hanging tideless in the last red and dying evening, that even then there will still be one more sound: that of man&#x27;s puny, inexhaustible, voice still talking! ...not simply because man alone among creatures has an inexhaustible voice, but because man has a soul, a spirit capable of compassion, sacrifice and endurance.&quot;&quot;&quot;</div><br/><div id="38283802" class="c"><input type="checkbox" id="c-38283802" checked=""/><div class="controls bullet"><span class="by">PeterisP</span><span>|</span><a href="#38282629">parent</a><span>|</span><a href="#38283796">next</a><span>|</span><label class="collapse" for="c-38283802">[-]</label><label class="expand" for="c-38283802">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that the position of Gebru et al (or even more specifically the stochastic parrot paper) can be dismissed as solely relying on &quot;human exceptionalism&quot;. While some of that sentiment arguably is there, the paper does make very valid points about the limitations of what can be learned solely from surface forms without any grounding in reality.<p>This is partially reflected by later observations from training LLMs where we see that the performance of LLMs increases even on purely language tasks when adding extra modalities such as computer code or images, which, in a sense, bring the model closer to different aspects of reality; and we observe that adding tiny quantities of &quot;experimental interaction&quot; through RLHF can bring features that additional humongous amounts of pure surface form training data can&#x27;t, and it certainly seems plausible that making a qualitative leap further would require some data from <i>actual</i> causal interaction with the real world (i.e. not replay of data based on &quot;someone else&#x27;s&quot; actions but feedback from whatever action the model currently feels is the most &quot;interesting&quot; i.e. the outcome is uncertain to the model but with potential for surprise data), where relatively tiny amounts of such data can enable learning what large amounts of pure observations can&#x27;t - just as the hypothetical octopus from the stochastic parrot paper thought experiment.</div><br/></div></div></div></div><div id="38283796" class="c"><input type="checkbox" id="c-38283796" checked=""/><div class="controls bullet"><span class="by">csours</span><span>|</span><a href="#38282629">prev</a><span>|</span><a href="#38282413">next</a><span>|</span><label class="collapse" for="c-38283796">[-]</label><label class="expand" for="c-38283796">[2 more]</label></div><br/><div class="children"><div class="content">So what are GPTs missing?<p>I&#x27;ve got:<p>- Falsifiability - am I saying something false? Some products have an output checker, but it&#x27;s a bolt on at this time for unacceptable output, which is not the same thing as falsifying.<p>- Agency - much ink already spilled<p>- Context Window size (too small, or need to summarize parts of the context to fit in context window, and know where to go back to for full context)<p>- Directed Self-Learning (I&#x27;m sure there are things like this that people may point out, but some kernel of self-learning isn&#x27;t there yet)</div><br/><div id="38285830" class="c"><input type="checkbox" id="c-38285830" checked=""/><div class="controls bullet"><span class="by">chewxy</span><span>|</span><a href="#38283796">parent</a><span>|</span><a href="#38282413">next</a><span>|</span><label class="collapse" for="c-38285830">[-]</label><label class="expand" for="c-38285830">[1 more]</label></div><br/><div class="children"><div class="content">The GPTs are good at interpolative and extrapolative generalization, owing to the manifold of the training data. They can&#x27;t do abstractive, inductive, abductive generalizations. And those are the more common forms of generalizations that humans can do.</div><br/></div></div></div></div><div id="38282413" class="c"><input type="checkbox" id="c-38282413" checked=""/><div class="controls bullet"><span class="by">BD103</span><span>|</span><a href="#38283796">prev</a><span>|</span><a href="#38282636">next</a><span>|</span><label class="collapse" for="c-38282413">[-]</label><label class="expand" for="c-38282413">[1 more]</label></div><br/><div class="children"><div class="content">Ignoring the topic of the article, the artwork and design was fantastically done! Props to whoever designed it :)</div><br/></div></div><div id="38282150" class="c"><input type="checkbox" id="c-38282150" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#38282636">prev</a><span>|</span><a href="#38282223">next</a><span>|</span><label class="collapse" for="c-38282150">[-]</label><label class="expand" for="c-38282150">[60 more]</label></div><br/><div class="children"><div class="content">Often the &quot;stochastic parrot&quot; line is used as a reduction on what an LLM truly is.<p>I firmly believe that LLMs are stochastic parrots and also that humans are too. To the point where I actually think even consciousness itself is a next-token predictor.<p>Where the industry is headed - multi-modal models. This really I think is the remaining frontier of LLM &lt;&gt; Human parity.<p>I also have a 15 month old son. It&#x27;s totally obvious to me that he&#x27;s definitely learning by repetition. But the sources of training data is much more high bandwidth than whatever we&#x27;re training our LLMs on.<p>It&#x27;s been a couple of years since GPT-3. It&#x27;s time to abandon this notion of &quot;stochastic parrot&quot; as a derogatory. Anyone stuck in this mindset really is going to be hindered from making significant progress in developing utility from AI.</div><br/><div id="38282232" class="c"><input type="checkbox" id="c-38282232" checked=""/><div class="controls bullet"><span class="by">Probiotic6081</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282277">next</a><span>|</span><label class="collapse" for="c-38282232">[-]</label><label class="expand" for="c-38282232">[22 more]</label></div><br/><div class="children"><div class="content">&gt; I firmly believe that LLMs are stochastic parrots and also that humans are too. To the point where I actually think even consciousness itself is a next-token predictor.<p>Almost every time I&#x27;m on hackernews I end up baffled by software engineers feeling entitled to have an unfunded opinion on scientific disciplines outside of their own field of expertise. I&#x27;ve literally never encountered that level of hubris from anyone else. It&#x27;s always the software people!<p>Consciousness is far from being fully understood but having a body and sensorimotor interactions with the environment are already established as fundamental preconditions for cognition and in turn consciousness.<p>Margaret Wilsons paper from 2002 is a good read: <a href="https:&#x2F;&#x2F;link.springer.com&#x2F;content&#x2F;pdf&#x2F;10.3758&#x2F;BF03196322.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;link.springer.com&#x2F;content&#x2F;pdf&#x2F;10.3758&#x2F;BF03196322.pdf</a><p>peace</div><br/><div id="38282402" class="c"><input type="checkbox" id="c-38282402" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282302">next</a><span>|</span><label class="collapse" for="c-38282402">[-]</label><label class="expand" for="c-38282402">[1 more]</label></div><br/><div class="children"><div class="content">Some of us who believe that humans are at least partly statistical parrots have PhDs in relevant fields- for example, my PhD is in Biophysics, I&#x27;ve studied cognitive neuroscience and ML for decades, and while I think embodiment may very well be a necessary condition to reproduce the subjective experience of consciousness, I don&#x27;t think &quot;having a body and sensorimotor interactions are established as fundamental preconditions for cognition and in turn consciousness&quot;.  Frankly I think that&#x27;s an impractical question to answer.<p>Instead, I work with the following idea: it seems not unlikely that we will, in the next decade or so, create non-embodied machine learning models which simply can&#x27;t be told apart from a human (through a video chat-like interface).  If you can do that, who really cares about whether it&#x27;s conscious or not?<p>I don&#x27;t really think philosophy of the mind is that important here; instead, we should treat this as an engineering problem where we assume brains are subjectively conscious, but that&#x27;s not a metric we are aiming for.</div><br/></div></div><div id="38282302" class="c"><input type="checkbox" id="c-38282302" checked=""/><div class="controls bullet"><span class="by">Chabsff</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282402">prev</a><span>|</span><a href="#38282516">next</a><span>|</span><label class="collapse" for="c-38282302">[-]</label><label class="expand" for="c-38282302">[3 more]</label></div><br/><div class="children"><div class="content">The befuddlement goes even farther for me. LLMs are, effectively, black-box systems that interface with the world via a stochastic parrot interface.<p>You&#x27;d <i>think</i> that software engineers would be a group that easily understands how making radical assumptions about implementation details when looking at nothing but an interface is generally misguided.<p>I&#x27;m not saying that there isn&#x27;t a strong case to be made against LLMs being intelligent. It&#x27;s pointing at the stochastic parrot as evidence enough in of itself that confuses me.</div><br/><div id="38282412" class="c"><input type="checkbox" id="c-38282412" checked=""/><div class="controls bullet"><span class="by">throw0101a</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282302">parent</a><span>|</span><a href="#38282333">next</a><span>|</span><label class="collapse" for="c-38282412">[-]</label><label class="expand" for="c-38282412">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>You&#x27;d</i> think <i>that</i> […]<p>As a stochastic parrot I&#x27;m unable to do that.</div><br/></div></div><div id="38282333" class="c"><input type="checkbox" id="c-38282333" checked=""/><div class="controls bullet"><span class="by">lainga</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282302">parent</a><span>|</span><a href="#38282412">prev</a><span>|</span><a href="#38282516">next</a><span>|</span><label class="collapse" for="c-38282333">[-]</label><label class="expand" for="c-38282333">[1 more]</label></div><br/><div class="children"><div class="content">Ah, but HN is a platform for not just any software engineer, but the entrepreneurial type.</div><br/></div></div></div></div><div id="38282516" class="c"><input type="checkbox" id="c-38282516" checked=""/><div class="controls bullet"><span class="by">hackinthebochs</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282302">prev</a><span>|</span><a href="#38282345">next</a><span>|</span><label class="collapse" for="c-38282516">[-]</label><label class="expand" for="c-38282516">[1 more]</label></div><br/><div class="children"><div class="content">Embodiment is an intellectual dead end in explaining consciousness&#x2F;sentience. Sure, its relevant to understanding human cognition as we are embodied entities, but it&#x27;s not much relevant to consciousness as such. The fact that some pattern of signals on my perceptual apparatus is caused by an apple in the real world does not mean that I have knowledge or understanding of an apple in virtue of this causal relation. That my sensory signals are caused by apples is an accident of this world, one we are completely blind to. If all apples in the world were swapped with fapples (fake apples), where all sensory experiences that have up to now been caused by apples are now caused by fapples, we would be none the wiser. The wide content of our perceptual experiences is irrelevant to literally everything we know and how we interact with the world. Our knowledge of the world is limited to our sensory experiences and our deductions, inferences, etc derived from our experiences. Our situatedness in the world is only relevant insofar as it entails the space of possible sensory experiences.<p>Our sensory experience is the medium by which we learn about the external world. We learn of apples not because of the redness of the sensory experience, but because the pattern of red&#x2F;not-red experience entails the shape of apples. Conscious experience provides the medium, modulations of which provide the information about features of the external world. It is analogous to how modulations of electromagnetic waves provides information about some distant information source. Understanding consciousness is an orthogonal matter to one&#x27;s situatedness in the world, just like understanding electromagnetic waves is orthogonal to understanding the information source being modulated into them.</div><br/></div></div><div id="38282345" class="c"><input type="checkbox" id="c-38282345" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282516">prev</a><span>|</span><a href="#38283946">next</a><span>|</span><label class="collapse" for="c-38282345">[-]</label><label class="expand" for="c-38282345">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s only software people. No one else has unfounded opinions.<p>But... a parrot has a body. And sure, you&#x27;ll say &quot;they don&#x27;t literally mean parrot&quot;.. but it&#x27;s a vague term when you unpack it, and people saying &quot;we are stochastic parrots&quot; are also making a pretty vague comment (they clearly don&#x27;t mean literally). Anyone who has a small child and understands LLMs is shocked by how much similar they seem to be when it comes to producing output.</div><br/><div id="38284056" class="c"><input type="checkbox" id="c-38284056" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282345">parent</a><span>|</span><a href="#38283946">next</a><span>|</span><label class="collapse" for="c-38284056">[-]</label><label class="expand" for="c-38284056">[1 more]</label></div><br/><div class="children"><div class="content">The question is: does polly really want a cracker?</div><br/></div></div></div></div><div id="38283946" class="c"><input type="checkbox" id="c-38283946" checked=""/><div class="controls bullet"><span class="by">pzo</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282345">prev</a><span>|</span><a href="#38284118">next</a><span>|</span><label class="collapse" for="c-38283946">[-]</label><label class="expand" for="c-38283946">[3 more]</label></div><br/><div class="children"><div class="content">&gt; having a body and sensorimotor interactions with the environment are already  established as fundamental preconditions for cognition and in turn consciousness.<p>Does someone who is blind is not conscious then? How about when someone who is paralysed? or deaf? or someone with low IQ or mental illness?<p>Stephen Hawking was paralysed most of his life but was a smart guy. If he was not only paralysed but also blind and deaf he would be smart guy still.<p>I don&#x27;t think AGI needs to have a body, sensorimotor interaction or even vision to be conscious. We need those for training - if you would be blind, paralysed, deaf from the beginning it would be hard for you learn anything and interact in any way.<p>Machines have 6th sense that humans don&#x27;t have - kind of a telepathy where they can exchange tokens&#x2F;thoughts with different machines or humans much faster than we humans can type or speak.</div><br/><div id="38285951" class="c"><input type="checkbox" id="c-38285951" checked=""/><div class="controls bullet"><span class="by">Teever</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38283946">parent</a><span>|</span><a href="#38284118">next</a><span>|</span><label class="collapse" for="c-38285951">[-]</label><label class="expand" for="c-38285951">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been thinking about this for a while now but I&#x27;ve been approaching it from the opposite direction.<p>If we were attempting to put someone into some sort of Matrix like reality simulator but we lacked the technology to provide a perfect simulation what level of simulation would be &#x27;good enough&#x27; that a human would consider it reality and be able to develop into something we could relate to?<p>If you gave someone the Helen Keller level of experience, but with reduced tactile sensation, how much could you reduce that touch sensation before they wouldn&#x27;t be like us?</div><br/><div id="38286326" class="c"><input type="checkbox" id="c-38286326" checked=""/><div class="controls bullet"><span class="by">GenericPoster</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38285951">parent</a><span>|</span><a href="#38284118">next</a><span>|</span><label class="collapse" for="c-38286326">[-]</label><label class="expand" for="c-38286326">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If we were attempting to put someone into some sort of Matrix like reality simulator but we lacked the technology to provide a perfect simulation what level of simulation would be &#x27;good enough&#x27; that a human would consider it reality and be able to develop into something we could relate to?<p>Have you tried VR before? You really don&#x27;t need perfect simulation to be fooled. Good enough is already here, albeit for a short amount of time.</div><br/></div></div></div></div></div></div><div id="38284118" class="c"><input type="checkbox" id="c-38284118" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38283946">prev</a><span>|</span><a href="#38282340">next</a><span>|</span><label class="collapse" for="c-38284118">[-]</label><label class="expand" for="c-38284118">[1 more]</label></div><br/><div class="children"><div class="content">From the first line of Wilson&#x27;s paper:<p>&gt; There is a movement afoot in cognitive science to grant the body a central role in shaping the mind.<p>It is far from true to say &quot;having a body and sensorimotor interactions with the environment are already established as fundamental preconditions for cognition and in turn consciousness&quot;<p>It is a popular idea in some groups of people that study these questions. But there are many other similar groups of peopel studying these questions who do not agree with it, certainly not stated as strongly as you have put it here.<p>Also, a reminder that HN readership and its commentariat, while dominated by SWE, is not limited to them.</div><br/></div></div><div id="38282340" class="c"><input type="checkbox" id="c-38282340" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38284118">prev</a><span>|</span><a href="#38282461">next</a><span>|</span><label class="collapse" for="c-38282340">[-]</label><label class="expand" for="c-38282340">[1 more]</label></div><br/><div class="children"><div class="content">To be fair, it&#x27;s any of the exalted professions that the blessed extend their expertise to. Doctors, lawyers, software engineers. they (we) start with the notion that I&#x27;m a smart person, so from first principles, I can conquer the world. nevermind that that&#x27;s an existing body of work, with their own practitioners to build off of.</div><br/></div></div><div id="38282461" class="c"><input type="checkbox" id="c-38282461" checked=""/><div class="controls bullet"><span class="by">nix0n</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282340">prev</a><span>|</span><a href="#38282307">next</a><span>|</span><label class="collapse" for="c-38282461">[-]</label><label class="expand" for="c-38282461">[3 more]</label></div><br/><div class="children"><div class="content">&gt; software engineers feeling entitled to have an unfunded opinion on scientific disciplines outside of their own field of expertise<p>There&#x27;s an XKCD about this behavior[0].  The title is actually &quot;Physicists&quot;, but I also have seen it on HN (especially with psychology).<p>[0]<a href="https:&#x2F;&#x2F;xkcd.com&#x2F;793&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;xkcd.com&#x2F;793&#x2F;</a></div><br/><div id="38283277" class="c"><input type="checkbox" id="c-38283277" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282461">parent</a><span>|</span><a href="#38282552">next</a><span>|</span><label class="collapse" for="c-38283277">[-]</label><label class="expand" for="c-38283277">[1 more]</label></div><br/><div class="children"><div class="content">This is known as the &quot;Why don&#x27;t you just assume a spherical cow?&quot;</div><br/></div></div><div id="38282552" class="c"><input type="checkbox" id="c-38282552" checked=""/><div class="controls bullet"><span class="by">User23</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282461">parent</a><span>|</span><a href="#38283277">prev</a><span>|</span><a href="#38282307">next</a><span>|</span><label class="collapse" for="c-38282552">[-]</label><label class="expand" for="c-38282552">[1 more]</label></div><br/><div class="children"><div class="content">Well with psychology it’s more fair. Thanks to the replication crisis we can say with a straight face that psychologists aren’t even experts on psychology. As usual the demonstrable expertise in the field lies with the pragmatic types. For psychology that means salesmen, pickup artists, advertisers, conmen, propagandists, high school queen bees, and so on.</div><br/></div></div></div></div><div id="38282307" class="c"><input type="checkbox" id="c-38282307" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282461">prev</a><span>|</span><a href="#38282325">next</a><span>|</span><label class="collapse" for="c-38282307">[-]</label><label class="expand" for="c-38282307">[3 more]</label></div><br/><div class="children"><div class="content">Are you saying that ie. paralyzed people don&#x27;t have consciousness?</div><br/><div id="38282466" class="c"><input type="checkbox" id="c-38282466" checked=""/><div class="controls bullet"><span class="by">zhynn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282307">parent</a><span>|</span><a href="#38282374">next</a><span>|</span><label class="collapse" for="c-38282466">[-]</label><label class="expand" for="c-38282466">[1 more]</label></div><br/><div class="children"><div class="content">There is a spectrum between conscious and unconscious.  You could say that under general anesthesia you are a 0&#x2F;10 on the conscious scale, asleep is 1 or 2, just woken from sleep is maybe 3.... and up to a well rested, well fed, healthy sober adult human near the top of the scale.  These are common sense notions of objective consciousness and they are testable and noncontroversial outside of a philosophy argument.<p>Does this make sense as a rebuttal to your reductio argument?</div><br/></div></div><div id="38282374" class="c"><input type="checkbox" id="c-38282374" checked=""/><div class="controls bullet"><span class="by">bena</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282307">parent</a><span>|</span><a href="#38282466">prev</a><span>|</span><a href="#38282325">next</a><span>|</span><label class="collapse" for="c-38282374">[-]</label><label class="expand" for="c-38282374">[1 more]</label></div><br/><div class="children"><div class="content">First of all, paralyzed people do have bodies. And sensorimotor functions.<p>Second of all, it wouldn&#x27;t matter if individually they did or did not. The species does and now our species has developed consciousness. It&#x27;s part of the package.<p>If you wanted a counterexample, you should look to plant life. There is some discussion on whether or not plant systems have a form on consciousness. But, then again, plants have bodies at the very least.</div><br/></div></div></div></div><div id="38282283" class="c"><input type="checkbox" id="c-38282283" checked=""/><div class="controls bullet"><span class="by">oh_sigh</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282232">parent</a><span>|</span><a href="#38282325">prev</a><span>|</span><a href="#38286171">next</a><span>|</span><label class="collapse" for="c-38282283">[-]</label><label class="expand" for="c-38282283">[1 more]</label></div><br/><div class="children"><div class="content">I suspect you don&#x27;t know what OPs field of expertise is. I also doubt OP would disagree with that statement that the only conscious things we know of have a body and sensorimotor interactions with the environment.</div><br/></div></div></div></div><div id="38282277" class="c"><input type="checkbox" id="c-38282277" checked=""/><div class="controls bullet"><span class="by">function_seven</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282232">prev</a><span>|</span><a href="#38282550">next</a><span>|</span><label class="collapse" for="c-38282277">[-]</label><label class="expand" for="c-38282277">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;m in the same boat. It feels wrong to contemplate that our consciousness might not be a magical independent agent with supernatural powers, but is rather an emergent property of complex-but-deterministic actions and reactions.<p>Like it somehow diminishes us. Reduces us to cogs and levers and such.<p>But I can&#x27;t imagine how it could be otherwise, though. I&#x27;m still baffled by the existence of qualia, phenomenology, etc. Awareness. But bafflement on that front isn&#x27;t a good reason to reject the possibility that the only thing that separates me from a computer is the level of complexity. Or the structure of the computation. Sometimes things are just weird.</div><br/><div id="38282427" class="c"><input type="checkbox" id="c-38282427" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282277">parent</a><span>|</span><a href="#38282395">next</a><span>|</span><label class="collapse" for="c-38282427">[-]</label><label class="expand" for="c-38282427">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think we&#x27;re ever going to arrive at a satisfactory answer for where qualia comes from, for much the same reason it&#x27;s impossible to test the quantum suicide hypothesis without actually putting yourself through it enough times to convince yourself statistically.<p>The only &quot;real&quot; evidence of qualia you have is your own running stream of it; you can try to carefully pour yourself, like a jug of water, into the body of another, and if you go carefully enough you may even succeed to carry that qualia-stream with you. But it&#x27;s also possible that you pour too quickly, or that you get bumped in the middle of the pouring, and poof - the qualia is just gone. You&#x27;re left with a p-zombie.<p>Or maybe not. Maybe it comes right back as soon as the transfer is done, like the final piece of a torrented movie. The important part is you won&#x27;t know unless you try - and past success never guarantees future success. Maybe you just got lucky on the first pour.</div><br/></div></div><div id="38282395" class="c"><input type="checkbox" id="c-38282395" checked=""/><div class="controls bullet"><span class="by">jocaal</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282277">parent</a><span>|</span><a href="#38282427">prev</a><span>|</span><a href="#38282555">next</a><span>|</span><label class="collapse" for="c-38282395">[-]</label><label class="expand" for="c-38282395">[4 more]</label></div><br/><div class="children"><div class="content">&gt; emergent property of complex-but-deterministic actions and reactions<p>I think you mean non-deterministic. The last century of physics was dominated by work showing how deterministic systems emerged from non-deterministic foundations. It seems that probability and statistics were the branches of maths behind everything. Who would have thought.</div><br/><div id="38282477" class="c"><input type="checkbox" id="c-38282477" checked=""/><div class="controls bullet"><span class="by">function_seven</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282395">parent</a><span>|</span><a href="#38282540">next</a><span>|</span><label class="collapse" for="c-38282477">[-]</label><label class="expand" for="c-38282477">[2 more]</label></div><br/><div class="children"><div class="content">Thanks. I did actually mean to use &quot;deterministic&quot;, but only as it sits in opposition to &quot;free will&quot;. Is there a better word for what I meant?<p>Of course there is randomness as well. So, yeah, I should clarify: We don&#x27;t impose upon the world any kind of &quot;uncaused cause&quot;, even if it feels like we do. Everything we think and do is a direct result of some other action. Sometimes that action can trace its lineage to a random particle decay. (Maybe—ultimately—all of them can?) Maybe we even have a source of True Randomness inherent in our minds. But even so, that doesn&#x27;t lend any support to the common notion of our minds and consciousnesses as being somehow separate from the physical world or the chains of information that run through everything.</div><br/><div id="38282606" class="c"><input type="checkbox" id="c-38282606" checked=""/><div class="controls bullet"><span class="by">jocaal</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282477">parent</a><span>|</span><a href="#38282540">next</a><span>|</span><label class="collapse" for="c-38282606">[-]</label><label class="expand" for="c-38282606">[1 more]</label></div><br/><div class="children"><div class="content">I get what you are saying. I was just thinking about the stochastic parrot analogy for consciousness, but I see your comment is more about there not being special sauce to conciousness. But hey, the fact that such behaviour can emerge from simple processes is still pretty damn cool.</div><br/></div></div></div></div><div id="38282540" class="c"><input type="checkbox" id="c-38282540" checked=""/><div class="controls bullet"><span class="by">dale_glass</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282395">parent</a><span>|</span><a href="#38282477">prev</a><span>|</span><a href="#38282555">next</a><span>|</span><label class="collapse" for="c-38282540">[-]</label><label class="expand" for="c-38282540">[1 more]</label></div><br/><div class="children"><div class="content">I think &quot;deterministic&quot; is the more correct option.<p>Yes, of course deep down there&#x27;s unimaginable numbers of atoms randomly bumping around. But so far everything suggests that biological organisms do their damnedest to abstract that away and operate on a deterministic basis.<p>Think like how you keep changing -- gaining and losing cells, changing chemical balance, and on the whole it takes a lot of damage, even brain damage, to produce measurable results.</div><br/></div></div></div></div><div id="38282555" class="c"><input type="checkbox" id="c-38282555" checked=""/><div class="controls bullet"><span class="by">somewhereoutth</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282277">parent</a><span>|</span><a href="#38282395">prev</a><span>|</span><a href="#38282550">next</a><span>|</span><label class="collapse" for="c-38282555">[-]</label><label class="expand" for="c-38282555">[2 more]</label></div><br/><div class="children"><div class="content">Indeed our consciousness is an emergent property from a complex system, however the complexity of that system - the human brain - is almost unfathomably beyond the complexity of anything we might make in silicon now or in the foreseeable future.<p>For example, it is possible to write down a (natural&#x2F;whole) number that completely describes the state of an LLM - its connections and weights etc - for example by simply taking the memory space and converting into a number as a very long sequence of 1s and 0s. The number will be very big, but still indescribably smaller than a number that could perfectly describe the state of a human brain - not least as <i>that</i> number is likely to lie on the real line, or beyond, even if it was calculable. See Cantor for a discussion on the various infinities and their respective cardinalities.</div><br/><div id="38283334" class="c"><input type="checkbox" id="c-38283334" checked=""/><div class="controls bullet"><span class="by">BlueTemplar</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282555">parent</a><span>|</span><a href="#38282550">next</a><span>|</span><label class="collapse" for="c-38283334">[-]</label><label class="expand" for="c-38283334">[1 more]</label></div><br/><div class="children"><div class="content">Under the assumption that human brains are limited by our current understanding of physics, their state is finite - infinities are forbidden by definition.<p>( See the relationship between information theory and Heisenberg&#x27;s uncertainty principle that results in the law of paraconservation of information : <a href="http:&#x2F;&#x2F;www.av8n.com&#x2F;physics&#x2F;thermo&#x2F;entropy-more.html#sec-phase-space" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.av8n.com&#x2F;physics&#x2F;thermo&#x2F;entropy-more.html#sec-pha...</a> )</div><br/></div></div></div></div></div></div><div id="38282550" class="c"><input type="checkbox" id="c-38282550" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282277">prev</a><span>|</span><a href="#38282311">next</a><span>|</span><label class="collapse" for="c-38282550">[-]</label><label class="expand" for="c-38282550">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I firmly believe that LLMs are stochastic parrots and also that humans are too. To the point where I actually think even consciousness itself is a next-token predictor.<p>I agree with the first sentence but not with the second one. Consciousness most probably does not arise from just a next-token predictor. At least not from an architecture similar to current LLMs.<p>Both humans and LLMs basically learn to predict what happens next.
However, LLMs only predict when we ask them. In contrast, humans predict something all the time. Even when we don&#x27;t have any sensory input, our brain plays scenarios. Maybe consciousness arises because the result of our thinking is fed back as input. In that sense, we simulate a world that includes us acting and communicating in that world.<p>Also noteworthy, the human brain handles a variety of sensory information and it&#x27;s output is not only language. LLMs are restricted to only language. But to me it seems like it&#x27;s enough for consciousness if we can give it the self-referential property.</div><br/><div id="38282651" class="c"><input type="checkbox" id="c-38282651" checked=""/><div class="controls bullet"><span class="by">throwaway4aday</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282550">parent</a><span>|</span><a href="#38284369">next</a><span>|</span><label class="collapse" for="c-38282651">[-]</label><label class="expand" for="c-38282651">[3 more]</label></div><br/><div class="children"><div class="content">In order to predict what happens next we need to create a model of the world. We exist as part of the world so we need to model ourselves within it. We also have to model our mind for it to be complete, including the model of the world it contains. Oops, I just created an infinite loop.</div><br/><div id="38282814" class="c"><input type="checkbox" id="c-38282814" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282651">parent</a><span>|</span><a href="#38284379">next</a><span>|</span><label class="collapse" for="c-38282814">[-]</label><label class="expand" for="c-38282814">[1 more]</label></div><br/><div class="children"><div class="content">Not necessarily infinite. It stops when there&#x27;s reasonable accuracy. Similar to how we would implement this in software.</div><br/></div></div></div></div><div id="38284369" class="c"><input type="checkbox" id="c-38284369" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282550">parent</a><span>|</span><a href="#38282651">prev</a><span>|</span><a href="#38282311">next</a><span>|</span><label class="collapse" for="c-38284369">[-]</label><label class="expand" for="c-38284369">[1 more]</label></div><br/><div class="children"><div class="content">&gt; However, LLMs only predict when we ask them. In contrast, humans predict something all the time. Even when we don&#x27;t have any sensory input, our brain plays scenarios.<p>Pretty easy to do this exercise with an LLM. At least, easier than building an LLM in the first place. Leave it running, let it talk to itself, revisit partial memories, and explore noise. Really a duct-tape problem here more than anything.</div><br/></div></div></div></div><div id="38282311" class="c"><input type="checkbox" id="c-38282311" checked=""/><div class="controls bullet"><span class="by">otabdeveloper4</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282550">prev</a><span>|</span><a href="#38282396">next</a><span>|</span><label class="collapse" for="c-38282311">[-]</label><label class="expand" for="c-38282311">[16 more]</label></div><br/><div class="children"><div class="content">LLMs don&#x27;t create new information, they only compress existing complexity in their train and inference data sets.<p>Humans definitely create new information. (Well, at least some humans do.)</div><br/><div id="38282451" class="c"><input type="checkbox" id="c-38282451" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282311">parent</a><span>|</span><a href="#38282360">next</a><span>|</span><label class="collapse" for="c-38282451">[-]</label><label class="expand" for="c-38282451">[6 more]</label></div><br/><div class="children"><div class="content">Do we?<p>Humans can <i>observe</i> new information, but that&#x27;s obviously not that unique. We can reason about existing information, creating new hypotheses, but that is arguably a compression of existing information. When we act on them and observe the effects they become information, but that&#x27;s not <i>us</i> creating the information (and LLMs can both act on the environment and have the effects fed back to their input to observe, so it&#x27;s not really unique).<p>There is this whole field of art, but art is constantly going through a mental crisis whether anyone is creating anything new, or if it&#x27;s all just derivations of what has come before. Same with dreams, which appear &quot;novel&quot; but might just be an artefact of our brain&#x27;s process that compresses the experiences of the day.</div><br/><div id="38282496" class="c"><input type="checkbox" id="c-38282496" checked=""/><div class="controls bullet"><span class="by">zhynn</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282451">parent</a><span>|</span><a href="#38282599">next</a><span>|</span><label class="collapse" for="c-38282496">[-]</label><label class="expand" for="c-38282496">[2 more]</label></div><br/><div class="children"><div class="content">Life creates novelty.  Humans are a member of that category, but all life is producing novelty.<p>More information: <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06600-9" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06600-9</a></div><br/><div id="38285958" class="c"><input type="checkbox" id="c-38285958" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282496">parent</a><span>|</span><a href="#38282599">next</a><span>|</span><label class="collapse" for="c-38285958">[-]</label><label class="expand" for="c-38285958">[1 more]</label></div><br/><div class="children"><div class="content">Is the inverse true? Does novelty create life? Can something be novel devoid of life?</div><br/></div></div></div></div><div id="38282599" class="c"><input type="checkbox" id="c-38282599" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282451">parent</a><span>|</span><a href="#38282496">prev</a><span>|</span><a href="#38282360">next</a><span>|</span><label class="collapse" for="c-38282599">[-]</label><label class="expand" for="c-38282599">[3 more]</label></div><br/><div class="children"><div class="content">let&#x27;s say you wanted to count the number of coins on a table<p>you organize them into piles of ten<p>this created new information</div><br/><div id="38283457" class="c"><input type="checkbox" id="c-38283457" checked=""/><div class="controls bullet"><span class="by">BlueTemplar</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282599">parent</a><span>|</span><a href="#38282360">next</a><span>|</span><label class="collapse" for="c-38283457">[-]</label><label class="expand" for="c-38283457">[2 more]</label></div><br/><div class="children"><div class="content">More like you converted information you had about energy powering your muscles into that one - resulting in less total information for you in the end.</div><br/><div id="38284542" class="c"><input type="checkbox" id="c-38284542" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38283457">parent</a><span>|</span><a href="#38282360">next</a><span>|</span><label class="collapse" for="c-38284542">[-]</label><label class="expand" for="c-38284542">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s not how information theory works</div><br/></div></div></div></div></div></div></div></div><div id="38282360" class="c"><input type="checkbox" id="c-38282360" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282311">parent</a><span>|</span><a href="#38282451">prev</a><span>|</span><a href="#38282986">next</a><span>|</span><label class="collapse" for="c-38282360">[-]</label><label class="expand" for="c-38282360">[1 more]</label></div><br/><div class="children"><div class="content">How are you defining &quot;create new information&quot; ?</div><br/></div></div><div id="38282986" class="c"><input type="checkbox" id="c-38282986" checked=""/><div class="controls bullet"><span class="by">chrbr</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282311">parent</a><span>|</span><a href="#38282360">prev</a><span>|</span><a href="#38282450">next</a><span>|</span><label class="collapse" for="c-38282986">[-]</label><label class="expand" for="c-38282986">[6 more]</label></div><br/><div class="children"><div class="content">I agree. A thought experiment I had recently:<p>Let&#x27;s say we could somehow train an LLM on all written and spoken language from the western Roman civilization (Republic + Western Empire, up until 476 AD&#x2F;CE, just so I don&#x27;t muddy the experiment with near-modern timelines). Would it, without novel information from humans, ever be able to spit out a correct predecessor of modern science like atomic theory? What about steam power, would that be feasible since Romans were toying with it? How far back do we have to go on the tech tree for such an LLM be able to &quot;discover&quot; something novel or generate useful new information?<p>My thought is that the LLM would forever be &quot;stuck&quot; in the knowledge of the era it was trained in. Something in the complexity of human brains working together is what drives new information. We can continue training new LLMs with new information, and LLMs might be able to find new patterns in data that humans can&#x27;t see and can augment our work, but the LLM&#x27;s capability for novelty is stuck on a complexity treadmill, rooted in its training data.<p>I don&#x27;t view this ability of humans as some magic consciousness, just a system so complex to us right now that we can&#x27;t fully understand or re-create it. If we&#x27;re stochastic parrots, we seem to be ones that are magnitudes more powerful and unpredictable than current LLMs, and maybe even constructed in a way that our current technology path can&#x27;t hope to replicate.</div><br/><div id="38283984" class="c"><input type="checkbox" id="c-38283984" checked=""/><div class="controls bullet"><span class="by">PeterisP</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282986">parent</a><span>|</span><a href="#38285244">next</a><span>|</span><label class="collapse" for="c-38283984">[-]</label><label class="expand" for="c-38283984">[4 more]</label></div><br/><div class="children"><div class="content">For your thought experiment, I&#x27;d assert that the key missing part is experimentation in the real world, as <i>that</i> is what acquires new information, not the complexity of human brains working together.<p>If you took millions of genius-level immortal humans with all the same Roman data but had them sit in a blank, empty room with their hands tied and simply discuss philosophy for eternity, I&#x27;m certain that they would not be able ever spit out a correct predecessor of modern science like atomic theory. Perhaps they could spit out billions of theories including the atomic theory as well, but they would have no data to presume that the atomic theory is more relevant than any other. Extensive information processing can squeeze out every last ounce of knowledge from some data, but anything that isn&#x27;t in that data can&#x27;t be acquired by mere thinking about it. On the other hand, if you gave some &quot;LLM++&quot; the ability to toy around with reality and attempt all kinds of experiments to test various hypotheses, then I wouldn&#x27;t assume that it would not be forever stuck in the knowledge of the era it was trained in.</div><br/><div id="38284765" class="c"><input type="checkbox" id="c-38284765" checked=""/><div class="controls bullet"><span class="by">chrbr</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38283984">parent</a><span>|</span><a href="#38285244">next</a><span>|</span><label class="collapse" for="c-38284765">[-]</label><label class="expand" for="c-38284765">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, I like that improvement&#x2F;clarification. Good assertion. Now I wonder if it changes my stance: are the path modern LLMs are on ever going to replicate this environment for acquiring new information that humans currently operate in?</div><br/><div id="38285018" class="c"><input type="checkbox" id="c-38285018" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38284765">parent</a><span>|</span><a href="#38285244">next</a><span>|</span><label class="collapse" for="c-38285018">[-]</label><label class="expand" for="c-38285018">[2 more]</label></div><br/><div class="children"><div class="content">As usual in these &quot;Yeah, but can AI do <i>this</i>?&quot; threads, the answer is yes, it is already happening: <a href="https:&#x2F;&#x2F;www.space.com&#x2F;mars-oxygen-ai-robot-chemist-splitting-water" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.space.com&#x2F;mars-oxygen-ai-robot-chemist-splitting...</a></div><br/></div></div></div></div></div></div><div id="38285244" class="c"><input type="checkbox" id="c-38285244" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282986">parent</a><span>|</span><a href="#38283984">prev</a><span>|</span><a href="#38282450">next</a><span>|</span><label class="collapse" for="c-38285244">[-]</label><label class="expand" for="c-38285244">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Let&#x27;s say we could somehow train an LLM on all written and spoken language from the western Roman civilization (Republic + Western Empire, up until 476 AD&#x2F;CE, just so I don&#x27;t muddy the experiment with near-modern timelines). Would it, without novel information from humans, ever be able to spit out a correct predecessor of modern science like atomic theory?<p>Funny example - depending on how close the predecessor has to be, the answer is maybe:  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Atomism" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Atomism</a></div><br/></div></div></div></div><div id="38282450" class="c"><input type="checkbox" id="c-38282450" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282311">parent</a><span>|</span><a href="#38282986">prev</a><span>|</span><a href="#38282342">next</a><span>|</span><label class="collapse" for="c-38282450">[-]</label><label class="expand" for="c-38282450">[1 more]</label></div><br/><div class="children"><div class="content">Lossy compression + interpolated decompression = new information</div><br/></div></div><div id="38282342" class="c"><input type="checkbox" id="c-38282342" checked=""/><div class="controls bullet"><span class="by">Gringham</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38282311">parent</a><span>|</span><a href="#38282450">prev</a><span>|</span><a href="#38282396">next</a><span>|</span><label class="collapse" for="c-38282342">[-]</label><label class="expand" for="c-38282342">[1 more]</label></div><br/><div class="children"><div class="content">Do they though? Or do humans just combine things they have learned about the world?</div><br/></div></div></div></div><div id="38282396" class="c"><input type="checkbox" id="c-38282396" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282311">prev</a><span>|</span><a href="#38282940">next</a><span>|</span><label class="collapse" for="c-38282396">[-]</label><label class="expand" for="c-38282396">[1 more]</label></div><br/><div class="children"><div class="content">I disagree they&#x27;re stochastic parrots, I find othello-gpt very convincing that these models can create world models and respond accordingly.</div><br/></div></div><div id="38282940" class="c"><input type="checkbox" id="c-38282940" checked=""/><div class="controls bullet"><span class="by">esjeon</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282396">prev</a><span>|</span><a href="#38282525">next</a><span>|</span><label class="collapse" for="c-38282940">[-]</label><label class="expand" for="c-38282940">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Anyone stuck in this mindset really is going to be hindered from making significant progress in developing utility from AI.<p>I think this specific line shouts out that this is a typical tribalism comment. Once people identify themselves as a part of something, they start to translate the value of that something as their own worth. It&#x27;s a cheap trick that even young kids play, but can LLM do this? No.<p>Some might say multi-modal this, train on that-thing, but it already takes tens of thousands of the most advanced hardware and gigawatts of energy to push around numbers to reach where it is. TBH, I don&#x27;t see it going anywhere, considering ROI on research will decrease as we dig deeper into the same paradigm.<p>What I want to say is that today&#x27;s LLM is certainly not the last stop of AI technology, but a lot of advocates tend to consider it as the final form of <i>intelligence</i>. It&#x27;s certainly a case of extrapolation, and I don&#x27;t think LLM can do that.</div><br/></div></div><div id="38282525" class="c"><input type="checkbox" id="c-38282525" checked=""/><div class="controls bullet"><span class="by">meindnoch</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282940">prev</a><span>|</span><a href="#38284096">next</a><span>|</span><label class="collapse" for="c-38282525">[-]</label><label class="expand" for="c-38282525">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a pretty bold statement, coming from someone with the subjective experience of consciousness.</div><br/></div></div><div id="38284096" class="c"><input type="checkbox" id="c-38284096" checked=""/><div class="controls bullet"><span class="by">voitvod</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282525">prev</a><span>|</span><a href="#38282366">next</a><span>|</span><label class="collapse" for="c-38284096">[-]</label><label class="expand" for="c-38284096">[2 more]</label></div><br/><div class="children"><div class="content">I would have agreed until these recent podcasts that Chomsky did.<p>Everyone is basically talking out their ass when it comes to language and linguistics. That becomes incredibly obvious listening to Chomsky on chatGPT.<p>I was even so stupid to think Chomsky wasn&#x27;t a fan of chatGPT because it somehow invalidated some of his language theories. Low and behold, no, Chomsky actually knows what he is talking about when it comes to linguistics.</div><br/><div id="38286470" class="c"><input type="checkbox" id="c-38286470" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#38282150">root</a><span>|</span><a href="#38284096">parent</a><span>|</span><a href="#38282366">next</a><span>|</span><label class="collapse" for="c-38286470">[-]</label><label class="expand" for="c-38286470">[1 more]</label></div><br/><div class="children"><div class="content">What recent podcasts? Can you link to some?</div><br/></div></div></div></div><div id="38282366" class="c"><input type="checkbox" id="c-38282366" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38284096">prev</a><span>|</span><a href="#38282420">next</a><span>|</span><label class="collapse" for="c-38282366">[-]</label><label class="expand" for="c-38282366">[1 more]</label></div><br/><div class="children"><div class="content">Those who don’t understand a concept are doomed to reduce it to concepts they do understand.<p>I’m currently reading I Am A Strange Loop, a pretty extensive dive into the nature of consciousness. I’m reserving final judgment on how much I agree with the author, but I find it laughable to claim consciousness itself is on the same level as an LLM.</div><br/></div></div><div id="38282420" class="c"><input type="checkbox" id="c-38282420" checked=""/><div class="controls bullet"><span class="by">gardenhedge</span><span>|</span><a href="#38282150">parent</a><span>|</span><a href="#38282366">prev</a><span>|</span><a href="#38282354">next</a><span>|</span><label class="collapse" for="c-38282420">[-]</label><label class="expand" for="c-38282420">[1 more]</label></div><br/><div class="children"><div class="content">Did you teach your child to crawl? To laugh? To get excited?</div><br/></div></div></div></div><div id="38282223" class="c"><input type="checkbox" id="c-38282223" checked=""/><div class="controls bullet"><span class="by">barbazoo</span><span>|</span><a href="#38282150">prev</a><span>|</span><a href="#38282328">next</a><span>|</span><label class="collapse" for="c-38282223">[-]</label><label class="expand" for="c-38282223">[2 more]</label></div><br/><div class="children"><div class="content">People are not gonna like that they have to scroll so much here :)</div><br/><div id="38283342" class="c"><input type="checkbox" id="c-38283342" checked=""/><div class="controls bullet"><span class="by">ale42</span><span>|</span><a href="#38282223">parent</a><span>|</span><a href="#38282328">next</a><span>|</span><label class="collapse" for="c-38283342">[-]</label><label class="expand" for="c-38283342">[1 more]</label></div><br/><div class="children"><div class="content">Usually I don&#x27;t, but this one I enjoyed it... also because, it&#x27;s just pure scrolling, no strange animations that change while you scroll.</div><br/></div></div></div></div><div id="38282328" class="c"><input type="checkbox" id="c-38282328" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#38282223">prev</a><span>|</span><a href="#38283122">next</a><span>|</span><label class="collapse" for="c-38282328">[-]</label><label class="expand" for="c-38282328">[1 more]</label></div><br/><div class="children"><div class="content">Very nice.<p>I don&#x27;t personally follow her all the way to some of those conclusions but the delivery was awesome</div><br/></div></div><div id="38283122" class="c"><input type="checkbox" id="c-38283122" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38282328">prev</a><span>|</span><a href="#38285188">next</a><span>|</span><label class="collapse" for="c-38283122">[-]</label><label class="expand" for="c-38283122">[2 more]</label></div><br/><div class="children"><div class="content">Paraphrasing and summarizing parts of this article, <a href="https:&#x2F;&#x2F;hedgehogreview.com&#x2F;issues&#x2F;markets-and-the-good&#x2F;articles&#x2F;language-machinery" rel="nofollow noreferrer">https:&#x2F;&#x2F;hedgehogreview.com&#x2F;issues&#x2F;markets-and-the-good&#x2F;artic...</a><p>Some ~72 years ago in 1951, Claude Shannon released his &quot;Prediction and Entropy of Printed English&quot;, an extremely fascinating read now.<p>The paper begins with a game. Claude pulls a book down from the shelf, concealing the title in the process. After selecting a passage at random, he challenges his wife, Mary to guess its contents letter by letter. The space between words will count as a twenty-seventh symbol in the set. If Mary fails to guess a letter correctly, Claude promises to supply the right one so that the game can continue.<p>In some cases, a corrected mistake allows her to fill in the remainder of the word; elsewhere a few letters unlock a phrase. All in all, she guesses 89 of 129 possible letters correctly—69 percent accuracy.<p>Discovery 1: It illustrated, in the first place, that a proficient speaker of a language possesses an “enormous” but implicit knowledge of the statistics of that language. Shannon would have us see that we make similar calculations regularly in everyday life—such as when we “fill in missing or incorrect letters in proof-reading” or “complete an unfinished phrase in conversation.” As we speak, read, and write, we are regularly engaged in predication games.<p>Discovery 2: Perhaps the most striking of all, Claude argues that that a complete text and the subsequent “reduced text” consisting of letters and dashes “actually…contain the same information” under certain conditions. How?? (Surely, the first line contains more information!).The answer depends on the peculiar notion about information that Shannon had hatched in his 1948 paper “A Mathematical Theory of Communication” (hereafter “MTC”), the founding charter of information theory.<p>He argues that transfer of a message&#x27;s components, rather than its &quot;meaning&quot;, should be the focus for the engineer. You ought to be agnostic about a message’s “meaning” (or “semantic aspects”). The message could be nonsense, and the engineer’s problem—to transfer its components faithfully—would be the same.<p>a highly predictable message contains less information than an unpredictable one. More information is at stake in (“villapleach, vollapluck”) than in (“Twinkle, twinkle”).<p>Does &quot;Flinkle, fli- - - -&quot; really contain less information than &quot;Flinkle, flinkle&quot; ?<p>Shannon concludes then that the complete text and the &quot;reduced text&quot; are equivalent in information content under certain conditions because predictable letters become redundant in information transfer.<p>Fueled by this, Claude then proposes an illuminating thought experiment: Imagine that Mary has a truly identical twin (call her “Martha”). If we supply Martha with the “reduced text,” she should be able to recreate the entirety of Chandler’s passage, since she possesses the same statistical knowledge of English as Mary. Martha would make Mary’s guesses in reverse.<p>Of course, Shannon admitted, there are no “mathematically identical twins” to be found, <i>but</i> and here&#x27;s the reveal, “we do have mathematically identical computing machines.”<p>Those machines could be given a model for making informed predictions about letters, words, maybe larger phrases and messages. In one fell swoop, Shannon had demonstrated that language use has a statistical side, that languages are, in turn, predictable, and that computers too can play the prediction game.</div><br/><div id="38284926" class="c"><input type="checkbox" id="c-38284926" checked=""/><div class="controls bullet"><span class="by">alexk307</span><span>|</span><a href="#38283122">parent</a><span>|</span><a href="#38285188">next</a><span>|</span><label class="collapse" for="c-38284926">[-]</label><label class="expand" for="c-38284926">[1 more]</label></div><br/><div class="children"><div class="content">Fascinating, thanks for explaining that</div><br/></div></div></div></div><div id="38285188" class="c"><input type="checkbox" id="c-38285188" checked=""/><div class="controls bullet"><span class="by">mempko</span><span>|</span><a href="#38283122">prev</a><span>|</span><a href="#38282447">next</a><span>|</span><label class="collapse" for="c-38285188">[-]</label><label class="expand" for="c-38285188">[2 more]</label></div><br/><div class="children"><div class="content">LLMs are like human minds the same way airplanes are like birds. Both birds and airplanes can fly, but very differently. Birds can land on a dime, airplanes can&#x27;t. Airplanes can carry a lot more weight and go faster.<p>Similarly LLMs can do things humans can&#x27;t. No human has as much knowledge about the world as a typical LLM model. However, an LLM model can&#x27;t generalize outside it&#x27;s training set well (recent Deep Mind research). LLM doesn&#x27;t have a memory outside it&#x27;s input. LLM isn&#x27;t Turing complete (has fixed amount of steps and always terminates).<p>We are building airplanes, not birds. That much is obvious.</div><br/><div id="38287168" class="c"><input type="checkbox" id="c-38287168" checked=""/><div class="controls bullet"><span class="by">omoide</span><span>|</span><a href="#38285188">parent</a><span>|</span><a href="#38282447">next</a><span>|</span><label class="collapse" for="c-38287168">[-]</label><label class="expand" for="c-38287168">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We are building airplanes, not birds. That much is obvious.<p>It does to me as well, but reading the comments here, it doesn&#x27;t seem that obvious to many people.</div><br/></div></div></div></div><div id="38282110" class="c"><input type="checkbox" id="c-38282110" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38282447">prev</a><span>|</span><label class="collapse" for="c-38282110">[-]</label><label class="expand" for="c-38282110">[2 more]</label></div><br/><div class="children"><div class="content">I wonder when the rate of improvement of SOTA benchmarks will exceed the rate of improvement of irl early childhood cognitive development</div><br/><div id="38282318" class="c"><input type="checkbox" id="c-38282318" checked=""/><div class="controls bullet"><span class="by">082349872349872</span><span>|</span><a href="#38282110">parent</a><span>|</span><label class="collapse" for="c-38282318">[-]</label><label class="expand" for="c-38282318">[1 more]</label></div><br/><div class="children"><div class="content">Jared Diamond mentions several attributes which make a species suitable for domestication. Humans fit all but one: we are almost too altricial to be suitable for economic exploitation.<p>Imagine the contribution to GNP if we in practice, like Bokanovsky* (by Ford!) in fiction, could greatly reduce the 10-30 year lead time currently required to produce new employees...<p>Edit: * cf <a href="https:&#x2F;&#x2F;www.depauw.edu&#x2F;sfs&#x2F;notes&#x2F;notes47&#x2F;notes47.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.depauw.edu&#x2F;sfs&#x2F;notes&#x2F;notes47&#x2F;notes47.html</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>