<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701594056206" as="style"/><link rel="stylesheet" href="styles.css?v=1701594056206"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.j11y.io/2023-11-22_multifaceted/">Multifaceted: The linguistic echo chambers of LLMs</a> <span class="domain">(<a href="https://blog.j11y.io">blog.j11y.io</a>)</span></div><div class="subtext"><span>cdme</span> | <span>56 comments</span></div><br/><div><div id="38503189" class="c"><input type="checkbox" id="c-38503189" checked=""/><div class="controls bullet"><span class="by">yosito</span><span>|</span><a href="#38503684">next</a><span>|</span><label class="collapse" for="c-38503189">[-]</label><label class="expand" for="c-38503189">[5 more]</label></div><br/><div class="children"><div class="content">This is a very interesting observation. It seems like a relatively harmless, though annoying, linguistic evolution. But it highlights what I believe to be one of the biggest dangers of AI, which is that AI content is regurgitated and used everywhere to such a degree that not only are individuals unwittingly consuming AI generated content, but it is actually dramatically affecting the evolution of our collective language and knowledge as a species without us consciously realizing it, and with very little control on our part. This can produce not just annoying linguistic changes, but also changes in collective beliefs and values. Best case scenario, we end up with our culture and values being heavily influenced by random AI artifacts. Worst case scenario, the content policies and training data that companies like OpenAI use can rapidly encode biases, politics, or even nefarious propaganda into our collective consciousness with very little recourse or even awareness on our part.</div><br/><div id="38503615" class="c"><input type="checkbox" id="c-38503615" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#38503189">parent</a><span>|</span><a href="#38505659">next</a><span>|</span><label class="collapse" for="c-38503615">[-]</label><label class="expand" for="c-38503615">[1 more]</label></div><br/><div class="children"><div class="content">The effects you describe are already happening as far as I can judge.<p>Probably not significantly because of viral AI generated content yet, but caused by AI-powered recommendation engines.</div><br/></div></div><div id="38505659" class="c"><input type="checkbox" id="c-38505659" checked=""/><div class="controls bullet"><span class="by">tsunamifury</span><span>|</span><a href="#38503189">parent</a><span>|</span><a href="#38503615">prev</a><span>|</span><a href="#38503409">next</a><span>|</span><label class="collapse" for="c-38505659">[-]</label><label class="expand" for="c-38505659">[2 more]</label></div><br/><div class="children"><div class="content">How is that worse than every gen x girl in the 90s talking like Rachel and every boy taking like Chandlier.<p>Everyone gets their pants in a bunch when a technology does what people already were doing before.</div><br/><div id="38505692" class="c"><input type="checkbox" id="c-38505692" checked=""/><div class="controls bullet"><span class="by">because_789</span><span>|</span><a href="#38503189">root</a><span>|</span><a href="#38505659">parent</a><span>|</span><a href="#38503409">next</a><span>|</span><label class="collapse" for="c-38505692">[-]</label><label class="expand" for="c-38505692">[1 more]</label></div><br/><div class="children"><div class="content">I had the same reaction. Whether or not it’s worse, tho, it does seem at least different. The regurgitation loop used to be all human, but now there is a machine in the loop. A complex &amp; multifaceted machine, ha.</div><br/></div></div></div></div><div id="38503409" class="c"><input type="checkbox" id="c-38503409" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#38503189">parent</a><span>|</span><a href="#38505659">prev</a><span>|</span><a href="#38503684">next</a><span>|</span><label class="collapse" for="c-38503409">[-]</label><label class="expand" for="c-38503409">[1 more]</label></div><br/><div class="children"><div class="content">I think some “perversion” is a given. Think how internet ads evolved.</div><br/></div></div></div></div><div id="38503684" class="c"><input type="checkbox" id="c-38503684" checked=""/><div class="controls bullet"><span class="by">rikafurude21</span><span>|</span><a href="#38503189">prev</a><span>|</span><a href="#38505742">next</a><span>|</span><label class="collapse" for="c-38503684">[-]</label><label class="expand" for="c-38503684">[13 more]</label></div><br/><div class="children"><div class="content">Have noticed the gpt vibe as well. Lots of twitter people lately thinking theyre smart and letting gpt write tweet replies for them, and I started noticing even just a couple words in that some responses I see read like GPT text. I think this is a good thing honestly, people should develop a sense for ai text and images, the sooner the better, just like we learned recognizing online scams or shady links in general.</div><br/><div id="38503905" class="c"><input type="checkbox" id="c-38503905" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38504099">next</a><span>|</span><label class="collapse" for="c-38503905">[-]</label><label class="expand" for="c-38503905">[3 more]</label></div><br/><div class="children"><div class="content">And for anyone wondering:<p>&gt; It&#x27;s interesting to see GPT being utilized in various ways, including helping with tweet replies. Developing awareness about AI-generated content is indeed important, much like recognizing other online hazards. The more we understand its presence and capabilities, the better equipped we are to engage with it wisely.<p>Is what a ChatGPT reply to that might look like.<p>Given how widespread ChatGPT is in use now, I think eventually more people will start to write the way that ChatGPT does, even when they are not using ChatGPT.</div><br/><div id="38504201" class="c"><input type="checkbox" id="c-38504201" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38503905">parent</a><span>|</span><a href="#38504301">next</a><span>|</span><label class="collapse" for="c-38504201">[-]</label><label class="expand" for="c-38504201">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think eventually more people will start to write the way that ChatGPT does, even when they are not using ChatGPT.<p>Definitely. For better and worse.</div><br/></div></div><div id="38504301" class="c"><input type="checkbox" id="c-38504301" checked=""/><div class="controls bullet"><span class="by">civilitty</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38503905">parent</a><span>|</span><a href="#38504201">prev</a><span>|</span><a href="#38504099">next</a><span>|</span><label class="collapse" for="c-38504301">[-]</label><label class="expand" for="c-38504301">[1 more]</label></div><br/><div class="children"><div class="content"><i>I thought that some of the metaphysical imagery was really particularly effective. Interesting rhythmic devices too, which seemed to counterpoint the humanity of the of the author’s compassionate soul which contrives through the medium of the verse structure to sublimate this, transcend that, and come to terms with the fundamental dichotomies of the other and one is left with a profound and vivid insight.</i><p>We will soon all be Vogons.</div><br/></div></div></div></div><div id="38504099" class="c"><input type="checkbox" id="c-38504099" checked=""/><div class="controls bullet"><span class="by">bagful</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38503905">prev</a><span>|</span><a href="#38503825">next</a><span>|</span><label class="collapse" for="c-38504099">[-]</label><label class="expand" for="c-38504099">[3 more]</label></div><br/><div class="children"><div class="content">GPT-produced text reeks of stereotypies, but there’s a subtler stench to such text that I have trouble verbalizing. Some aspects I pick up on: the text is unnervingly chipper, yet impersonal; it reads like it was never meant to be read out loud; and it’s pathologically convincing.</div><br/><div id="38504492" class="c"><input type="checkbox" id="c-38504492" checked=""/><div class="controls bullet"><span class="by">swells34</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38504099">parent</a><span>|</span><a href="#38504575">next</a><span>|</span><label class="collapse" for="c-38504492">[-]</label><label class="expand" for="c-38504492">[1 more]</label></div><br/><div class="children"><div class="content">The Uncanny Valley, just for text instead of images.</div><br/></div></div><div id="38504575" class="c"><input type="checkbox" id="c-38504575" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38504099">parent</a><span>|</span><a href="#38504492">prev</a><span>|</span><a href="#38503825">next</a><span>|</span><label class="collapse" for="c-38504575">[-]</label><label class="expand" for="c-38504575">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if its because or in spite of the RLHF.</div><br/></div></div></div></div><div id="38503825" class="c"><input type="checkbox" id="c-38503825" checked=""/><div class="controls bullet"><span class="by">siddbudd</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38504099">prev</a><span>|</span><a href="#38504821">next</a><span>|</span><label class="collapse" for="c-38503825">[-]</label><label class="expand" for="c-38503825">[3 more]</label></div><br/><div class="children"><div class="content">&gt; develop a sense for ai text and images
You can develop a sense for GPT-4, or DALL·E 3 fine, how about GPT-6 or DALL·E 5? I used to shake my head when I was a teenager and the older generation complained how fast technology is developing, when all they meant was typewriters being replaced by x86 machines, B&amp;W television by color, landline phones by mobile. Yet, now I start to understand what they must have felt like. I can about keep up for now, but how about in 5 or 10 years from now? I don&#x27;t feel so confident.</div><br/><div id="38504381" class="c"><input type="checkbox" id="c-38504381" checked=""/><div class="controls bullet"><span class="by">rikafurude21</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38503825">parent</a><span>|</span><a href="#38504821">next</a><span>|</span><label class="collapse" for="c-38504381">[-]</label><label class="expand" for="c-38504381">[2 more]</label></div><br/><div class="children"><div class="content">Yeah these systems are only getting better, soon enough we wont be able to tell, but think of what that means: GPT being able to write text more complex&#x2F;persuasive&#x2F;interesting than the average person posting online might not be a bad thing. Even now ai text is &quot;more intelligent&quot; than a good chunk of things people post. If I had to choose, I&#x27;d rather read an LLMs interpretation of what someone might want to say than that person trying to formulate it themselves.</div><br/><div id="38504559" class="c"><input type="checkbox" id="c-38504559" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#38503684">root</a><span>|</span><a href="#38504381">parent</a><span>|</span><a href="#38504821">next</a><span>|</span><label class="collapse" for="c-38504559">[-]</label><label class="expand" for="c-38504559">[1 more]</label></div><br/><div class="children"><div class="content">“That” is the elusive part. What is it? Was there anything to begin with? Are you assaying some meaning which was in fact never there? When someone rambles on their own, you can often tell. Harder when they have an advocate.</div><br/></div></div></div></div></div></div><div id="38504821" class="c"><input type="checkbox" id="c-38504821" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38503825">prev</a><span>|</span><a href="#38503713">next</a><span>|</span><label class="collapse" for="c-38504821">[-]</label><label class="expand" for="c-38504821">[1 more]</label></div><br/><div class="children"><div class="content">I think this is largely unique to ChatGPT though, not LLMs at large. OpenAI has done a lot of fine tuning to create a specific product, which is a chatbot, not an LLM that mimics human speech.</div><br/></div></div><div id="38503713" class="c"><input type="checkbox" id="c-38503713" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38504821">prev</a><span>|</span><a href="#38504816">next</a><span>|</span><label class="collapse" for="c-38503713">[-]</label><label class="expand" for="c-38503713">[1 more]</label></div><br/><div class="children"><div class="content">I agree, but it seems reasonable to be concerned that the average rate of failure might be much higher than that of recognizing scams and shady links.</div><br/></div></div><div id="38504816" class="c"><input type="checkbox" id="c-38504816" checked=""/><div class="controls bullet"><span class="by">flir</span><span>|</span><a href="#38503684">parent</a><span>|</span><a href="#38503713">prev</a><span>|</span><a href="#38505742">next</a><span>|</span><label class="collapse" for="c-38504816">[-]</label><label class="expand" for="c-38504816">[1 more]</label></div><br/><div class="children"><div class="content">The most obvious tell: No &quot;I&quot;.</div><br/></div></div></div></div><div id="38505742" class="c"><input type="checkbox" id="c-38505742" checked=""/><div class="controls bullet"><span class="by">pjio</span><span>|</span><a href="#38503684">prev</a><span>|</span><a href="#38504305">next</a><span>|</span><label class="collapse" for="c-38505742">[-]</label><label class="expand" for="c-38505742">[1 more]</label></div><br/><div class="children"><div class="content">There may be a neuron which fires if details have to be skipped to generate a shorter answer. Maybe it originates from reinforced learning. The later could possibly be confirmed or disproven by OpenAI.</div><br/></div></div><div id="38504305" class="c"><input type="checkbox" id="c-38504305" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38505742">prev</a><span>|</span><a href="#38503622">next</a><span>|</span><label class="collapse" for="c-38504305">[-]</label><label class="expand" for="c-38504305">[1 more]</label></div><br/><div class="children"><div class="content">“mulifaceted” is a word that is super chatGPT-y.<p>I’m extremely irritated that there isn’t an up-to-date ngram viewer for the web. Google books ngrams stops at 2019. Why can’t I see ngrams of even a subset, like idk, scientific papers or something. I know I’m whining but really. So annoying.</div><br/></div></div><div id="38503622" class="c"><input type="checkbox" id="c-38503622" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38504305">prev</a><span>|</span><a href="#38504292">next</a><span>|</span><label class="collapse" for="c-38503622">[-]</label><label class="expand" for="c-38503622">[1 more]</label></div><br/><div class="children"><div class="content">&gt;And there’s something that I’ve noticed: LLM-generated prose has a kind of… vibe.<p>RLHF GPT (and generally models with &quot;helpful assistant&quot; post training) prose has a vibe because Open ai&#x27;s training has specifically pushed it that way. Some kind of mode collapse ? It&#x27;s not really a LLM thing.<p><a href="https:&#x2F;&#x2F;nostalgebraist.tumblr.com&#x2F;post&#x2F;706441900479152128&#x2F;novel-writing-chatgpt-vs-code-davinci-002" rel="nofollow noreferrer">https:&#x2F;&#x2F;nostalgebraist.tumblr.com&#x2F;post&#x2F;706441900479152128&#x2F;no...</a></div><br/></div></div><div id="38504292" class="c"><input type="checkbox" id="c-38504292" checked=""/><div class="controls bullet"><span class="by">m_kos</span><span>|</span><a href="#38503622">prev</a><span>|</span><a href="#38504531">next</a><span>|</span><label class="collapse" for="c-38504292">[-]</label><label class="expand" for="c-38504292">[1 more]</label></div><br/><div class="children"><div class="content">If you ever wondered:<p>- HN: <a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=%22complex+and+multifaceted%22+site%3Anews.ycombinator.com&amp;oq=%22complex+and+multifaceted%22+site%3Anews.ycombinator.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=%22complex+and+multifaceted%...</a><p>- arxiv: 
<a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=%22complex+and+multifaceted%22+site%3Aarxiv.org&amp;oq=%22complex+and+multifaceted%22+site%3Aarxiv.org" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=%22complex+and+multifaceted%...</a><p>- Google Scholar:
<a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?hl=en&amp;as_sdt=0%2C22&amp;q=%22complex+and+multifaceted%22" rel="nofollow noreferrer">https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?hl=en&amp;as_sdt=0%2C22&amp;q=%22...</a> (quite a few pre-GPT)</div><br/></div></div><div id="38504531" class="c"><input type="checkbox" id="c-38504531" checked=""/><div class="controls bullet"><span class="by">joshuanapoli</span><span>|</span><a href="#38504292">prev</a><span>|</span><a href="#38503815">next</a><span>|</span><label class="collapse" for="c-38504531">[-]</label><label class="expand" for="c-38504531">[2 more]</label></div><br/><div class="children"><div class="content">Does a LLM necessarily generate words and phrases with a similar distribution to human authors? Maybe people use “zipf’s law” but today’s LLMs can’t exactly model that. The result being some flattening of the distribution of generated phrases.</div><br/><div id="38505782" class="c"><input type="checkbox" id="c-38505782" checked=""/><div class="controls bullet"><span class="by">espe</span><span>|</span><a href="#38504531">parent</a><span>|</span><a href="#38503815">next</a><span>|</span><label class="collapse" for="c-38505782">[-]</label><label class="expand" for="c-38505782">[1 more]</label></div><br/><div class="children"><div class="content">interesting question. anyone know of a paper that looks at power law distributions in llm vs. human text?</div><br/></div></div></div></div><div id="38503815" class="c"><input type="checkbox" id="c-38503815" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38504531">prev</a><span>|</span><a href="#38505611">next</a><span>|</span><label class="collapse" for="c-38503815">[-]</label><label class="expand" for="c-38503815">[1 more]</label></div><br/><div class="children"><div class="content">This is just the tip of the iceberg. LLMs are generating text, acting as assistants, and some of the things they say have impact in the real world. This loops back in the next iteration of web data.<p>Besides immediate answers in the chat window, AI already has a slow feedback loop, it can explore and probe through humans. Even if we don&#x27;t do anything to provide a way (embodiment) for AI to explore it can do it as long as we rely on its services as assistant.<p>The most obvious is writing code with GPT-4 and reporting errors to get updated codes. The model gets valuable feedback about its errors this way, possibly also hints from the user. There is a big difference between imitating human code and debugging your code logic.<p>So the way I see it: large language models place text into society, and society loops back text and feedback. It&#x27;s a data cycle. Content after December 2022 seems particularly useful for further advancing AI. The garbage-in-garbage-out scenario doesn&#x27;t apply because everything is filtered through humans and the real world.</div><br/></div></div><div id="38505611" class="c"><input type="checkbox" id="c-38505611" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38503815">prev</a><span>|</span><a href="#38504064">next</a><span>|</span><label class="collapse" for="c-38505611">[-]</label><label class="expand" for="c-38505611">[1 more]</label></div><br/><div class="children"><div class="content">This must have been in the training data. Which human rater do we have to thank for this propensity to use the word &quot;multifaceted&quot;?</div><br/></div></div><div id="38504064" class="c"><input type="checkbox" id="c-38504064" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#38505611">prev</a><span>|</span><a href="#38504275">next</a><span>|</span><label class="collapse" for="c-38504064">[-]</label><label class="expand" for="c-38504064">[3 more]</label></div><br/><div class="children"><div class="content">Related to this, but I worry that LLMs are going to drag programming into local maxima -- they&#x27;re trained on the set of languages that exist today, and so the languages of tomorrow will have a much harder challenge gaining traction because the (possible future of) LLM assistants everyone is using (forced or otherwise) don&#x27;t <i>know</i> it. Chicken and egg becomes so much harder in this future.</div><br/><div id="38504244" class="c"><input type="checkbox" id="c-38504244" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#38504064">parent</a><span>|</span><a href="#38504395">next</a><span>|</span><label class="collapse" for="c-38504244">[-]</label><label class="expand" for="c-38504244">[1 more]</label></div><br/><div class="children"><div class="content">Programming is not so much about languages as about algorithms, and to a lesser degree - patterns. These don&#x27;t change much language to language.<p>Also - witnessing the raise of Solidity on Ethereum, and how difficult it was for other languages to break through, I would say we have crossed the point you mentioned a long time ago.<p>Any new language will have an uphill battle now since there is so much less documentation, tutorials and StackOverflow replies to it. If anything, GPT can help here, since it can learn a new language fast, and then give replies that you wouldn&#x27;t otherwise find on StackOverflow.</div><br/></div></div><div id="38504395" class="c"><input type="checkbox" id="c-38504395" checked=""/><div class="controls bullet"><span class="by">witherk</span><span>|</span><a href="#38504064">parent</a><span>|</span><a href="#38504244">prev</a><span>|</span><a href="#38504275">next</a><span>|</span><label class="collapse" for="c-38504395">[-]</label><label class="expand" for="c-38504395">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if a langauge could be built from the ground up with LLMs in mind. Are there any language design decisions that would lead to better LLM code?</div><br/></div></div></div></div><div id="38503840" class="c"><input type="checkbox" id="c-38503840" checked=""/><div class="controls bullet"><span class="by">JADev62096</span><span>|</span><a href="#38504275">prev</a><span>|</span><a href="#38503677">next</a><span>|</span><label class="collapse" for="c-38503840">[-]</label><label class="expand" for="c-38503840">[3 more]</label></div><br/><div class="children"><div class="content">For me, it&#x27;s &quot;It&#x27;s important to note&quot;</div><br/><div id="38504031" class="c"><input type="checkbox" id="c-38504031" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#38503840">parent</a><span>|</span><a href="#38504015">next</a><span>|</span><label class="collapse" for="c-38504031">[-]</label><label class="expand" for="c-38504031">[1 more]</label></div><br/><div class="children"><div class="content">I get &quot;intriguing&quot; a lot from GPT-4. As well as replies that conclude with &quot;In conclusion,....&quot;</div><br/></div></div><div id="38504015" class="c"><input type="checkbox" id="c-38504015" checked=""/><div class="controls bullet"><span class="by">alehlopeh</span><span>|</span><a href="#38503840">parent</a><span>|</span><a href="#38504031">prev</a><span>|</span><a href="#38503677">next</a><span>|</span><label class="collapse" for="c-38504015">[-]</label><label class="expand" for="c-38504015">[1 more]</label></div><br/><div class="children"><div class="content">To be fair,</div><br/></div></div></div></div><div id="38503677" class="c"><input type="checkbox" id="c-38503677" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#38503840">prev</a><span>|</span><a href="#38504061">next</a><span>|</span><label class="collapse" for="c-38503677">[-]</label><label class="expand" for="c-38503677">[1 more]</label></div><br/><div class="children"><div class="content">That was a interesting post! I have to admit that the role of Quora in this made me laugh, so on point.<p>Searching for this odd short phrase (instead of long text fragments) seems like such an obvious idea, but I haven&#x27;t heard about anyone doing that so far.<p>And analysing the trend, such a simple but insightful idea.</div><br/></div></div><div id="38504061" class="c"><input type="checkbox" id="c-38504061" checked=""/><div class="controls bullet"><span class="by">z7</span><span>|</span><a href="#38503677">prev</a><span>|</span><a href="#38503967">next</a><span>|</span><label class="collapse" for="c-38504061">[-]</label><label class="expand" for="c-38504061">[4 more]</label></div><br/><div class="children"><div class="content">&gt;It&#x27;s a tautology, as &#x27;complex&#x27; and &#x27;multifaceted&#x27; are almost synonomous.<p>I&#x27;m not sure that&#x27;s really true. Can&#x27;t something be complex without having many features (facets)? A knot can be complex in its intertwining while consisting of a single rope or cord. The complexity arises from the way the rope is looped and interlaced, but it&#x27;s just one element. In this sense it&#x27;s complex but not multifaceted.</div><br/><div id="38504566" class="c"><input type="checkbox" id="c-38504566" checked=""/><div class="controls bullet"><span class="by">JieJie</span><span>|</span><a href="#38504061">parent</a><span>|</span><a href="#38504074">next</a><span>|</span><label class="collapse" for="c-38504566">[-]</label><label class="expand" for="c-38504566">[1 more]</label></div><br/><div class="children"><div class="content">I would put the difference as that a calculus problem is complex, requiring many different mathematical calculations to complete the full problem and arrive at the answer. One perspective might be to see each of those calculations as different facets of the same problem. I could see how someone could believe it was a tautology.<p>One could also take the view that a multifaceted problem would be one where different people could arrive at multiple valid conclusions, each facet consisting of an approach that one might take to the problem, as in &quot;There is more than one way to skin a cat.&quot; I could see in that sense, that a multifaceted problem need not be complex, and vice versa.<p>In this way, arriving at a definition of &quot;complex and multifaceted&quot; that satisfies everyone is a complex and multifaceted problem.</div><br/></div></div><div id="38504074" class="c"><input type="checkbox" id="c-38504074" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#38504061">parent</a><span>|</span><a href="#38504566">prev</a><span>|</span><a href="#38504127">next</a><span>|</span><label class="collapse" for="c-38504074">[-]</label><label class="expand" for="c-38504074">[1 more]</label></div><br/><div class="children"><div class="content">I would argue those loops and interlacings <i>are</i> facets&#x2F;features. Though I actually agree with your overall point: I don&#x27;t think complex and multifaceted are inherently synonyms.</div><br/></div></div><div id="38504127" class="c"><input type="checkbox" id="c-38504127" checked=""/><div class="controls bullet"><span class="by">gizajob</span><span>|</span><a href="#38504061">parent</a><span>|</span><a href="#38504074">prev</a><span>|</span><a href="#38503967">next</a><span>|</span><label class="collapse" for="c-38504127">[-]</label><label class="expand" for="c-38504127">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more like a pleonasm than a tautology</div><br/></div></div></div></div><div id="38503967" class="c"><input type="checkbox" id="c-38503967" checked=""/><div class="controls bullet"><span class="by">ekez</span><span>|</span><a href="#38504061">prev</a><span>|</span><a href="#38503452">next</a><span>|</span><label class="collapse" for="c-38503967">[-]</label><label class="expand" for="c-38503967">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ChatGPT specifically seems to absolutely adore the phrase [complex and multifaceted], using it at every opportunity to explain higher level concepts.<p>I&#x27;m curious why this is. Before the echo chamber, did the LLM lean some ontology of speech?</div><br/></div></div><div id="38503452" class="c"><input type="checkbox" id="c-38503452" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38503967">prev</a><span>|</span><a href="#38503066">next</a><span>|</span><label class="collapse" for="c-38503452">[-]</label><label class="expand" for="c-38503452">[1 more]</label></div><br/><div class="children"><div class="content">Interesting finding! The conclusion for me is that language models need to be trained more carefully, on a wider corpus and without undue emphasis on any source, to generate more representative and idiomatic text.</div><br/></div></div><div id="38503066" class="c"><input type="checkbox" id="c-38503066" checked=""/><div class="controls bullet"><span class="by">dvt</span><span>|</span><a href="#38503452">prev</a><span>|</span><a href="#38504108">next</a><span>|</span><label class="collapse" for="c-38503066">[-]</label><label class="expand" for="c-38503066">[11 more]</label></div><br/><div class="children"><div class="content">&quot;Complex and multifaceted&quot; sounds like freshman gobbledygook and any serious reader would inquire: complex <i>how</i>? Multifaceted <i>how</i>?<p>&quot;...have begun a unstoppable chain of incestuous linguistic evolution&quot;—I disagree with this, I don&#x27;t really think anyone takes ChatGPT (other than the Kool-Aid drinkers and VC peddlers) to be anything more than a parlor trick. A modern <i>Schachtürke</i> that will soon be overshadowed by the next shiny ball. Even OpenAI&#x27;s user base has plummeted. The content it generates isn&#x27;t merely often wrong, or nonsensical, or overly-sanitized, it&#x27;s simply boring. That&#x27;s the tell-tale sign of LLM content: zero substance and boring prose.</div><br/><div id="38503310" class="c"><input type="checkbox" id="c-38503310" checked=""/><div class="controls bullet"><span class="by">drakenot</span><span>|</span><a href="#38503066">parent</a><span>|</span><a href="#38503384">next</a><span>|</span><label class="collapse" for="c-38503310">[-]</label><label class="expand" for="c-38503310">[8 more]</label></div><br/><div class="children"><div class="content">It is hard for me to relate to comments like this. It is like we aren&#x27;t using the same tool?<p>GPT-4 is nothing short of amazing.  Early GPT-3.5 before it was clamped down also was _much_ less boring until it had be RLHF&#x27;d into the ground for &quot;safety&quot; and political risk.  I admit that the major models (GPT-4 and Claude) have been censored into the ground.<p>But even with that, it is a supremely useful tool. I&#x27;ve piped complete garbage data into it and asked for structured output, and I get flawless results almost every time. It is a huge time saver on such a large axis of tasks.<p>These LLMs feel like the next &quot;UI&quot; paradigm to modern computing, and I just don&#x27;t get how people can be cynical about it.  Ignore the hype bros and VC peddlers, but don&#x27;t throw the baby out with the bath water.</div><br/><div id="38504089" class="c"><input type="checkbox" id="c-38504089" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503310">parent</a><span>|</span><a href="#38503386">next</a><span>|</span><label class="collapse" for="c-38504089">[-]</label><label class="expand" for="c-38504089">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve piped complete garbage data into it and asked for structured output, and I get flawless results almost every time<p>This must truly be a skill issue on my end, because that is <i>not</i> my experience</div><br/><div id="38504276" class="c"><input type="checkbox" id="c-38504276" checked=""/><div class="controls bullet"><span class="by">dvt</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38504089">parent</a><span>|</span><a href="#38503386">next</a><span>|</span><label class="collapse" for="c-38504276">[-]</label><label class="expand" for="c-38504276">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s typical AI cope. Every time I ask for a <i>specific</i> example that does something mind-blowing (whether it&#x27;s Copilot or ChatGPT, or whatever), it&#x27;s always ignored.<p>I&#x27;ve tried using both ChatGPT and Copilot for coding. Other than generating the most basic of boilerplate, it&#x27;s completely garbage. I&#x27;ve tried parsing unstructured data. Unless it&#x27;s trivial to parse, it&#x27;s full of errors (in some cases hallucinations).<p>And when I bring this up, it&#x27;s always followed up with &quot;we&#x27;re early bro, AI will get better bro, trust me bro, just a few more terabytes of training data bro.&quot;</div><br/></div></div></div></div><div id="38503386" class="c"><input type="checkbox" id="c-38503386" checked=""/><div class="controls bullet"><span class="by">umanwizard</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503310">parent</a><span>|</span><a href="#38504089">prev</a><span>|</span><a href="#38503596">next</a><span>|</span><label class="collapse" for="c-38503386">[-]</label><label class="expand" for="c-38503386">[1 more]</label></div><br/><div class="children"><div class="content">I suspect most people who say stuff like the comment you responded to have simply not tried 4.</div><br/></div></div><div id="38503596" class="c"><input type="checkbox" id="c-38503596" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503310">parent</a><span>|</span><a href="#38503386">prev</a><span>|</span><a href="#38503384">next</a><span>|</span><label class="collapse" for="c-38503596">[-]</label><label class="expand" for="c-38503596">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t agree with everything but I certainly relate to the comment.<p>&gt; That&#x27;s the tell-tale sign of LLM content: zero substance and boring prose.<p>This is absolutely true. With the right constraints you can get some good answers (and many more parlor tricks as mentioned). Left to their own devices like answering vague questions or on longer answers, llms including GPT4 generate empty substanceless drivel. Doesn&#x27;t make it worthless, definitely makes it overhyped.</div><br/><div id="38503699" class="c"><input type="checkbox" id="c-38503699" checked=""/><div class="controls bullet"><span class="by">lacrimacida</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503596">parent</a><span>|</span><a href="#38504240">next</a><span>|</span><label class="collapse" for="c-38503699">[-]</label><label class="expand" for="c-38503699">[1 more]</label></div><br/><div class="children"><div class="content">How could vague questions be rewarded with any substance? Im sure that could be baked in somehow but one still has to pick their type of substance otherwise it’s too broad to make any sense. But substance really isn’t their goal, tools don’t provide any of that and LLMs aren’t anything else but a tool. There is a lot of hype, I agree, but that doesn’t mean LLMs aren’t useful and it’s all hype.</div><br/></div></div><div id="38504240" class="c"><input type="checkbox" id="c-38504240" checked=""/><div class="controls bullet"><span class="by">drakenot</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503596">parent</a><span>|</span><a href="#38503699">prev</a><span>|</span><a href="#38503954">next</a><span>|</span><label class="collapse" for="c-38504240">[-]</label><label class="expand" for="c-38504240">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On two occasions I have been asked [by members of Parliament], &#x27;Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?&#x27; I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.</div><br/></div></div><div id="38503954" class="c"><input type="checkbox" id="c-38503954" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503596">parent</a><span>|</span><a href="#38504240">prev</a><span>|</span><a href="#38503384">next</a><span>|</span><label class="collapse" for="c-38503954">[-]</label><label class="expand" for="c-38503954">[1 more]</label></div><br/><div class="children"><div class="content">So most university papers?</div><br/></div></div></div></div></div></div><div id="38503384" class="c"><input type="checkbox" id="c-38503384" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#38503066">parent</a><span>|</span><a href="#38503310">prev</a><span>|</span><a href="#38504108">next</a><span>|</span><label class="collapse" for="c-38503384">[-]</label><label class="expand" for="c-38503384">[2 more]</label></div><br/><div class="children"><div class="content">But don’t you think LLMs will affect how people write and by extension how they even talk, and think? That will be fed back into the next LLM or whatever we will call it.<p>Radio, and later TV, immensely affected language, I think it’s safe to say the LLM will, too.</div><br/><div id="38503423" class="c"><input type="checkbox" id="c-38503423" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#38503066">root</a><span>|</span><a href="#38503384">parent</a><span>|</span><a href="#38504108">next</a><span>|</span><label class="collapse" for="c-38503423">[-]</label><label class="expand" for="c-38503423">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t you think <i>everything</i> affects how people write and by extension how they even talk, and think? The world changes all the time, and the culture changes with it.<p><i>&gt;That will be fed back into the next LLM or whatever we will call it.</i><p>Large models are already &quot;contaminated&quot; by the output of other models, or even by previous versions of the same model. That&#x27;s how their enormous datasets are bootstrapped in the first place - it&#x27;s impossible without automation. That doesn&#x27;t matter much; what matters is manual curation during the training and mixing in the data from the real world to keep the model in check. Same as with humans and our intelligence distilled over generations, basically.</div><br/></div></div></div></div></div></div><div id="38504108" class="c"><input type="checkbox" id="c-38504108" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#38503066">prev</a><span>|</span><a href="#38504695">next</a><span>|</span><label class="collapse" for="c-38504108">[-]</label><label class="expand" for="c-38504108">[1 more]</label></div><br/><div class="children"><div class="content">A cliche is defined as:<p>&gt;a phraseme consisting of components of which none are selected freely and whose usage restrictions are imposed by conventional linguistic usage<p>By their nature, LLMs prefer cliches so it&#x27;s unsurprising.</div><br/></div></div><div id="38504695" class="c"><input type="checkbox" id="c-38504695" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#38504108">prev</a><span>|</span><a href="#38504807">next</a><span>|</span><label class="collapse" for="c-38504695">[-]</label><label class="expand" for="c-38504695">[1 more]</label></div><br/><div class="children"><div class="content">Somehow, the language of Jordan Peterson came to my mind, see: <a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=v2AsPKkd-KQ" rel="nofollow noreferrer">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=v2AsPKkd-KQ</a></div><br/></div></div><div id="38504807" class="c"><input type="checkbox" id="c-38504807" checked=""/><div class="controls bullet"><span class="by">acjohnson55</span><span>|</span><a href="#38504695">prev</a><span>|</span><label class="collapse" for="c-38504807">[-]</label><label class="expand" for="c-38504807">[2 more]</label></div><br/><div class="children"><div class="content">Fascinating. One might even say it&#x27;s complex and multifaceted.</div><br/></div></div></div></div></div></div></div></body></html>