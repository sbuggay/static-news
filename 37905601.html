<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697533267604" as="style"/><link rel="stylesheet" href="styles.css?v=1697533267604"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://guanjunwu.github.io/4dgs/">4D Gaussian Splatting for Real-Time Dynamic Scene Rendering</a> <span class="domain">(<a href="https://guanjunwu.github.io">guanjunwu.github.io</a>)</span></div><div class="subtext"><span>lattalayta</span> | <span>59 comments</span></div><br/><div><div id="37906591" class="c"><input type="checkbox" id="c-37906591" checked=""/><div class="controls bullet"><span class="by">arijun</span><span>|</span><a href="#37908120">next</a><span>|</span><label class="collapse" for="c-37906591">[-]</label><label class="expand" for="c-37906591">[1 more]</label></div><br/><div class="children"><div class="content">This looks great! The main potential use for this must be for VR video with 6 degrees of freedom. What they have now does an incredible job of conveying space, but feels a bit limiting when your view doesn’t translate with you.</div><br/></div></div><div id="37908120" class="c"><input type="checkbox" id="c-37908120" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#37906591">prev</a><span>|</span><a href="#37907025">next</a><span>|</span><label class="collapse" for="c-37908120">[-]</label><label class="expand" for="c-37908120">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know if the pixel overdraw of the GS scene is consistent from every view angle? I&#x27;m asking because I would assume there is inconsistent GS density but the paper doesn&#x27;t give a range of FPS measurements or 99th percentile or anything like that.</div><br/><div id="37911934" class="c"><input type="checkbox" id="c-37911934" checked=""/><div class="controls bullet"><span class="by">kookamamie</span><span>|</span><a href="#37908120">parent</a><span>|</span><a href="#37907025">next</a><span>|</span><label class="collapse" for="c-37911934">[-]</label><label class="expand" for="c-37911934">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty certain it is not - consider surfaces seen in steep angles, vs. ones seen perpendicularly. If we assume no culling or pruning occurs for the splats, steep angles result in way more overdraw.</div><br/></div></div></div></div><div id="37907025" class="c"><input type="checkbox" id="c-37907025" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#37908120">prev</a><span>|</span><a href="#37907041">next</a><span>|</span><label class="collapse" for="c-37907025">[-]</label><label class="expand" for="c-37907025">[4 more]</label></div><br/><div class="children"><div class="content">This gives me hope that one day we&#x27;ll have a holodeck. Holy crap! The applications for this are pretty broad. From safety (scene reconstruction from video sources) to real-estate, to hollywood and video games. I&#x27;m just blown away. Will we eventually see 4D GS AR&#x2F;XR scenes we can walk about? I feel like that would make the perfect VR sherlock holmes game.</div><br/><div id="37908141" class="c"><input type="checkbox" id="c-37908141" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#37907025">parent</a><span>|</span><a href="#37907440">next</a><span>|</span><label class="collapse" for="c-37908141">[-]</label><label class="expand" for="c-37908141">[1 more]</label></div><br/><div class="children"><div class="content">Why wouldn&#x27;t you be able to walk about now?  They already have examples with free camera movement.  To make it an XR scene, you just need to render two cameras and pipe it into a headset.</div><br/></div></div><div id="37907440" class="c"><input type="checkbox" id="c-37907440" checked=""/><div class="controls bullet"><span class="by">waynecochran</span><span>|</span><a href="#37907025">parent</a><span>|</span><a href="#37908141">prev</a><span>|</span><a href="#37911582">next</a><span>|</span><label class="collapse" for="c-37907440">[-]</label><label class="expand" for="c-37907440">[1 more]</label></div><br/><div class="children"><div class="content">One more step towards the next simulation level.</div><br/></div></div><div id="37911582" class="c"><input type="checkbox" id="c-37911582" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#37907025">parent</a><span>|</span><a href="#37907440">prev</a><span>|</span><a href="#37907041">next</a><span>|</span><label class="collapse" for="c-37911582">[-]</label><label class="expand" for="c-37911582">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t the scenes static?</div><br/></div></div></div></div><div id="37907041" class="c"><input type="checkbox" id="c-37907041" checked=""/><div class="controls bullet"><span class="by">nialv7</span><span>|</span><a href="#37907025">prev</a><span>|</span><a href="#37906807">next</a><span>|</span><label class="collapse" for="c-37907041">[-]</label><label class="expand" for="c-37907041">[1 more]</label></div><br/><div class="children"><div class="content">Holy heck this is going to fundamentally change media production</div><br/></div></div><div id="37906807" class="c"><input type="checkbox" id="c-37906807" checked=""/><div class="controls bullet"><span class="by">mortenjorck</span><span>|</span><a href="#37907041">prev</a><span>|</span><a href="#37909089">next</a><span>|</span><label class="collapse" for="c-37906807">[-]</label><label class="expand" for="c-37906807">[17 more]</label></div><br/><div class="children"><div class="content">Hard to believe the original Gaussian Splatting paper is still less than three months old, given the explosion of new techniques in recent weeks. It&#x27;s wild to see the state of the art in environment and object capture suddenly advancing this quickly – beyond the obvious applications like real estate, I wonder what else GS will end up transforming.</div><br/><div id="37907398" class="c"><input type="checkbox" id="c-37907398" checked=""/><div class="controls bullet"><span class="by">bane</span><span>|</span><a href="#37906807">parent</a><span>|</span><a href="#37908398">next</a><span>|</span><label class="collapse" for="c-37907398">[-]</label><label class="expand" for="c-37907398">[14 more]</label></div><br/><div class="children"><div class="content">To be at risk of an &quot;AcKchYuALly&quot;. Gaussian Splatting has been around since at least the early 90s. There&#x27;s even a few old games made with the technique.<p>The paper I think your referring to made the interesting leap that a 3d radiance field could be rerendered out as a field of Gaussian splats, <i>and</i> that this would probably run faster in modern GPU pipelines for real-time performance. It looks like they also have the nice property of being able to be shifted around in memory quickly hence the animation property seen here.</div><br/><div id="37908297" class="c"><input type="checkbox" id="c-37908297" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907398">parent</a><span>|</span><a href="#37912105">next</a><span>|</span><label class="collapse" for="c-37908297">[-]</label><label class="expand" for="c-37908297">[2 more]</label></div><br/><div class="children"><div class="content">If you want to be pedantic, the paper made the leap it did because of differentiable rendering which necessarily needs a differentiable representation of primitives - so they use Gaussians. It’s entirely novel and set in a nascent field (neural rendering). Gaussians happen to be further representable as easily rasterized primitives. Though some considerable work was put into making this performant. Everyone who keeps saying this has been around since the 90s is missing the context of the very modern differentiable rendering literature.</div><br/></div></div><div id="37912105" class="c"><input type="checkbox" id="c-37912105" checked=""/><div class="controls bullet"><span class="by">verytrivial</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907398">parent</a><span>|</span><a href="#37908297">prev</a><span>|</span><a href="#37907458">next</a><span>|</span><label class="collapse" for="c-37912105">[-]</label><label class="expand" for="c-37912105">[1 more]</label></div><br/><div class="children"><div class="content">I remember a 4k demo that used translucent triangles (I think? my brain is showing me circles, so perhaps a fixed set of sizes and fast blit with alpha.) This created moving volumetric light and shadows around some geometric shapes, some pillars I think. Very smeary&#x2F;ghostly with overdrawn shapes, but the effect was startling given it was on a 486.  It didn&#x27;t render full frames, but moved the model and just kept splatting.</div><br/></div></div><div id="37907458" class="c"><input type="checkbox" id="c-37907458" checked=""/><div class="controls bullet"><span class="by">constantlm</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907398">parent</a><span>|</span><a href="#37912105">prev</a><span>|</span><a href="#37907446">next</a><span>|</span><label class="collapse" for="c-37907458">[-]</label><label class="expand" for="c-37907458">[4 more]</label></div><br/><div class="children"><div class="content">Could you point us to some examples of old games using this technique? Would be awesome to see.</div><br/><div id="37907540" class="c"><input type="checkbox" id="c-37907540" checked=""/><div class="controls bullet"><span class="by">doormatt</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907458">parent</a><span>|</span><a href="#37907446">next</a><span>|</span><label class="collapse" for="c-37907540">[-]</label><label class="expand" for="c-37907540">[3 more]</label></div><br/><div class="children"><div class="content">Ecstatica - <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dnOXk3QJWN8">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dnOXk3QJWN8</a></div><br/><div id="37909132" class="c"><input type="checkbox" id="c-37909132" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907540">parent</a><span>|</span><a href="#37907446">next</a><span>|</span><label class="collapse" for="c-37909132">[-]</label><label class="expand" for="c-37909132">[2 more]</label></div><br/><div class="children"><div class="content">Is this really splatting gaussians? Or is it rendering ellipsoids?</div><br/><div id="37909843" class="c"><input type="checkbox" id="c-37909843" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37909132">parent</a><span>|</span><a href="#37907446">next</a><span>|</span><label class="collapse" for="c-37909843">[-]</label><label class="expand" for="c-37909843">[1 more]</label></div><br/><div class="children"><div class="content">It was just ellipsoids. I don’t know if any game specifically used Gaussians. But, the idea of splatting points, Gaussians, ellipsoids and a variety of other shapes has been around for at least 20 years.<p>The novelty of the paper was in using the differentiability of Gaussians to enable fitting splats to incrementally match all of the target photos simultaneously. So, it’s a new way to generate the splats from photos rather than modeling them by hand.</div><br/></div></div></div></div></div></div></div></div><div id="37907446" class="c"><input type="checkbox" id="c-37907446" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907398">parent</a><span>|</span><a href="#37907458">prev</a><span>|</span><a href="#37907964">next</a><span>|</span><label class="collapse" for="c-37907446">[-]</label><label class="expand" for="c-37907446">[3 more]</label></div><br/><div class="children"><div class="content">Interesting! Can you please name some of these old games made with Gaussian Splatting? I would be interested to play, to get a sense why polygons won in that round (and likely to lose in this one).</div><br/><div id="37910307" class="c"><input type="checkbox" id="c-37910307" checked=""/><div class="controls bullet"><span class="by">chaboud</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907446">parent</a><span>|</span><a href="#37907716">next</a><span>|</span><label class="collapse" for="c-37910307">[-]</label><label class="expand" for="c-37910307">[1 more]</label></div><br/><div class="children"><div class="content">I used additive gaussian fields (restricted by bounding regions) for this back in the late 90&#x27;s for audio visualizations in a ripper&#x2F;player called &quot;Siren&quot; (back when we actually thought we could charge money for something like that).<p>The technique worked well on non-accelerated (CPU only) hardware of the era, with the additive approach saving the pain of needing to keep a z buffer or fragment list.<p>Gaussian voxel reconstruction is useful in medical and GIS settings, which, if memory serves, is where Kyle Freeman from Novalogic drew on for his work on Comanche.  As far as I know, that was the first commercial game with voxel rendering...  It&#x27;s been a bit since I played it, but the swimming jaggies make me think that it was Manhattan distance height map offset by planar traversal (kinda like Doom raycasting) or some similar trick.  I don&#x27;t recall any intersections or overhangs, but, to be fair, I was a middle schooler when Comanche came out.<p>It also ran fine on my weak sauce PC.<p>Once acceleration hit, transformation of triangles with fixed-function pipelines took over.  The ability to push textured triangles with minimal per-pixel value adjustment took over.  Slowly but surely we&#x27;ve swing back to high ALU balance (albeit via massive stream parallelism).  We&#x27;ve shifted from heavy list&#x2F;vertex transformers to giant array multiply&#x2F;add processors.<p>It&#x27;s a pretty great time to be a processing nerd.</div><br/></div></div><div id="37907716" class="c"><input type="checkbox" id="c-37907716" checked=""/><div class="controls bullet"><span class="by">otteromkram</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907446">parent</a><span>|</span><a href="#37910307">prev</a><span>|</span><a href="#37907964">next</a><span>|</span><label class="collapse" for="c-37907716">[-]</label><label class="expand" for="c-37907716">[1 more]</label></div><br/><div class="children"><div class="content">From another user:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dnOXk3QJWN8">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dnOXk3QJWN8</a></div><br/></div></div></div></div><div id="37907964" class="c"><input type="checkbox" id="c-37907964" checked=""/><div class="controls bullet"><span class="by">kelseyfrog</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907398">parent</a><span>|</span><a href="#37907446">prev</a><span>|</span><a href="#37908398">next</a><span>|</span><label class="collapse" for="c-37907964">[-]</label><label class="expand" for="c-37907964">[3 more]</label></div><br/><div class="children"><div class="content">The point of Gaussian Splatting for me is that it is a learned representation. It&#x27;s odd that others view it primarily as a drawing sprites.<p>I&#x27;m curious, would you classify particle effects drawn with quads as 4D gaussian splatting too?</div><br/><div id="37908209" class="c"><input type="checkbox" id="c-37908209" checked=""/><div class="controls bullet"><span class="by">bane</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37907964">parent</a><span>|</span><a href="#37908398">next</a><span>|</span><label class="collapse" for="c-37908209">[-]</label><label class="expand" for="c-37908209">[2 more]</label></div><br/><div class="children"><div class="content">Well, in the old days, you just put the splats in your 3d space, they weren&#x27;t really sprites (in the strict sense that they didn&#x27;t use dedicated sprite hardware). They&#x27;re really interesting thing is that they&#x27;re being used here to render the learned representation, but there&#x27;s nothing particularly special about them or new or AI&#x2F;ML about them.<p>You could &quot;model&quot; 3d objects with the gaussians by just putting a bunch together. It was a way to produce fast rendering 3d images without using a bunch of polygons. The results back then were...left behind by other techniques.<p>There&#x27;s a massive back catalog of computer graphics work on the technique, it&#x27;s usually just easiest to use the search tools and search back for all dates leading up to say...2021 and you&#x27;ll find tons of normal old stuff like CS 302 - Computer Graphics courseware slides or whatever on the technique.<p><a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=gaussian+splat+-site%3Apinterest.*&amp;sca_esv=573896841&amp;hl=en&amp;sxsrf=AM9HkKmpdTVJGgCrENkavpKV_rTlshXClA%3A1697499680577&amp;source=lnt&amp;tbs=cdr%3A1%2Ccd_min%3A12%2F1%2F1989%2Ccd_max%3A2%2F1%2F2021&amp;tbm=" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=gaussian+splat+-site%3Apinte...</a></div><br/><div id="37909364" class="c"><input type="checkbox" id="c-37909364" checked=""/><div class="controls bullet"><span class="by">ezconnect</span><span>|</span><a href="#37906807">root</a><span>|</span><a href="#37908209">parent</a><span>|</span><a href="#37908398">next</a><span>|</span><label class="collapse" for="c-37909364">[-]</label><label class="expand" for="c-37909364">[1 more]</label></div><br/><div class="children"><div class="content">Being old and seeing the new generations amazed by the reapplication of what was discovered and used decades ago in a novel way amazes me.</div><br/></div></div></div></div></div></div></div></div><div id="37908398" class="c"><input type="checkbox" id="c-37908398" checked=""/><div class="controls bullet"><span class="by">atonalfreerider</span><span>|</span><a href="#37906807">parent</a><span>|</span><a href="#37907398">prev</a><span>|</span><a href="#37907966">next</a><span>|</span><label class="collapse" for="c-37908398">[-]</label><label class="expand" for="c-37908398">[1 more]</label></div><br/><div class="children"><div class="content">This one was released today as well. Works out of the box:
<a href="https:&#x2F;&#x2F;github.com&#x2F;JonathonLuiten&#x2F;Dynamic3DGaussians">https:&#x2F;&#x2F;github.com&#x2F;JonathonLuiten&#x2F;Dynamic3DGaussians</a></div><br/></div></div></div></div><div id="37909089" class="c"><input type="checkbox" id="c-37909089" checked=""/><div class="controls bullet"><span class="by">raytopia</span><span>|</span><a href="#37906807">prev</a><span>|</span><a href="#37908960">next</a><span>|</span><label class="collapse" for="c-37909089">[-]</label><label class="expand" for="c-37909089">[5 more]</label></div><br/><div class="children"><div class="content">With tech like this I&#x27;m starting to wonder if realistic games are going to become normalized and what will happen as a result.<p>Also has anyone been working on solving the &quot;blurry&quot; look these splats have up close?</div><br/><div id="37910860" class="c"><input type="checkbox" id="c-37910860" checked=""/><div class="controls bullet"><span class="by">TheRoque</span><span>|</span><a href="#37909089">parent</a><span>|</span><a href="#37910022">next</a><span>|</span><label class="collapse" for="c-37910860">[-]</label><label class="expand" for="c-37910860">[2 more]</label></div><br/><div class="children"><div class="content">But if I&#x27;m not mistaken, this technique still requires to get a ton of pictures from many angles ? It&#x27;s fine for visiting an apartment or watching a cooking video in 3D, but how possibly can you apply this to a videogame that has much more degrees of freedom ? Are you gonna scan an entire city with a drone to create a GTA-like ?</div><br/><div id="37911085" class="c"><input type="checkbox" id="c-37911085" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37909089">root</a><span>|</span><a href="#37910860">parent</a><span>|</span><a href="#37910022">next</a><span>|</span><label class="collapse" for="c-37911085">[-]</label><label class="expand" for="c-37911085">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We introduce the 4D Gaussian Splatting (4D-GS) to achieve real-time dynamic scene rendering while also enjoying high training and storage efficiency.<p>This seems to be a rendering efficiency innovation, not particular to scanning.<p>That means it applies to artificially generated environments, whether photo realistic or stylized, and whether based on a real environment or a completely fictional one.<p>But of course, any photorealistic, extremely faithful to the smallest detail, rendering of a real place is going to involve a lot of scanning. That is true for any kind of rendering.</div><br/></div></div></div></div><div id="37910022" class="c"><input type="checkbox" id="c-37910022" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#37909089">parent</a><span>|</span><a href="#37910860">prev</a><span>|</span><a href="#37908960">next</a><span>|</span><label class="collapse" for="c-37910022">[-]</label><label class="expand" for="c-37910022">[2 more]</label></div><br/><div class="children"><div class="content">Each Gaussian &quot;splat&quot; is literally a little blurry blob. The way to make it sharper is to increase the resolution - i.e. increase the number of splats, decrease the size of each one. This increases both training time and render time though.</div><br/><div id="37910038" class="c"><input type="checkbox" id="c-37910038" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#37909089">root</a><span>|</span><a href="#37910022">parent</a><span>|</span><a href="#37908960">next</a><span>|</span><label class="collapse" for="c-37910038">[-]</label><label class="expand" for="c-37910038">[1 more]</label></div><br/><div class="children"><div class="content">&gt; realistic games<p>That said, games don&#x27;t have to be super realistic to be fun. E.g. I could imagine a game based on GS at &quot;Minecraft resolution&quot;.</div><br/></div></div></div></div></div></div><div id="37908960" class="c"><input type="checkbox" id="c-37908960" checked=""/><div class="controls bullet"><span class="by">KaoruAoiShiho</span><span>|</span><a href="#37909089">prev</a><span>|</span><a href="#37908010">next</a><span>|</span><label class="collapse" for="c-37908960">[-]</label><label class="expand" for="c-37908960">[1 more]</label></div><br/><div class="children"><div class="content">Feel like this changes everything, trying it out right now...</div><br/></div></div><div id="37908010" class="c"><input type="checkbox" id="c-37908010" checked=""/><div class="controls bullet"><span class="by">heurist</span><span>|</span><a href="#37908960">prev</a><span>|</span><a href="#37906504">next</a><span>|</span><label class="collapse" for="c-37908010">[-]</label><label class="expand" for="c-37908010">[3 more]</label></div><br/><div class="children"><div class="content">After reconstruction, is there any way to scan for a particular condition in the model, and map it onto the 3D structure? For instance, find the broken cookie, or find a surface matching some input image.</div><br/><div id="37910472" class="c"><input type="checkbox" id="c-37910472" checked=""/><div class="controls bullet"><span class="by">dwallin</span><span>|</span><a href="#37908010">parent</a><span>|</span><a href="#37910053">next</a><span>|</span><label class="collapse" for="c-37910472">[-]</label><label class="expand" for="c-37910472">[1 more]</label></div><br/><div class="children"><div class="content">Seem fairly tractable to use Segment Anything or a similar method to derive plausible semantic clusters of splats.</div><br/></div></div><div id="37910053" class="c"><input type="checkbox" id="c-37910053" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#37908010">parent</a><span>|</span><a href="#37910472">prev</a><span>|</span><a href="#37906504">next</a><span>|</span><label class="collapse" for="c-37910053">[-]</label><label class="expand" for="c-37910053">[1 more]</label></div><br/><div class="children"><div class="content">I suspect typical point-cloud feature extraction techniques would work. Things like identify planar regions, from that join connecting planar regions into clusters, etc.<p>The time component is super interesting here though!</div><br/></div></div></div></div><div id="37906504" class="c"><input type="checkbox" id="c-37906504" checked=""/><div class="controls bullet"><span class="by">jjcm</span><span>|</span><a href="#37908010">prev</a><span>|</span><a href="#37907032">next</a><span>|</span><label class="collapse" for="c-37906504">[-]</label><label class="expand" for="c-37906504">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see a machine learning model trained on the resulting data of this. It&#x27;d be crazy to see if it can effectively learn and generate realistic looking video as an output.</div><br/></div></div><div id="37907032" class="c"><input type="checkbox" id="c-37907032" checked=""/><div class="controls bullet"><span class="by">syntaxing</span><span>|</span><a href="#37906504">prev</a><span>|</span><a href="#37907317">next</a><span>|</span><label class="collapse" for="c-37907032">[-]</label><label class="expand" for="c-37907032">[11 more]</label></div><br/><div class="children"><div class="content">Does anyone have a video or post that explains the optimization part for the original paper? I understand most of it but that part and can’t seem to wrap my head around it.</div><br/><div id="37907934" class="c"><input type="checkbox" id="c-37907934" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#37907032">parent</a><span>|</span><a href="#37907057">next</a><span>|</span><label class="collapse" for="c-37907934">[-]</label><label class="expand" for="c-37907934">[8 more]</label></div><br/><div class="children"><div class="content">Just glossed over the paper but it seems, in principle, simple enough (though rather brilliant IMHO).<p>Essentially they&#x27;re doing what you do when you train a neural network, only that instead of adjusting weights connecting &quot;neurons&quot;, you adjust the shape and position of gaussians, and the coefficients of spherical harmonics for the colors.<p>This requires the rendering step to be differentiable, so that you can back-propagate the error between the rendering and the ground-truth image.<p>The next key step is to every N iterations adjust the number of gaussians. Either fill in details by cloning a gaussian in an area which is undercovered, or split a gaussian in an area which is overcovered.<p>They use the gradient of the view-space position to determine if more detail is needed, ie those gaussians which the optimizer wants to move significantly over the screen seems to be in a region with not enough detail.<p>They then use the covariance of the gaussians to determine to split or to clone. Gaussians with large variance get split, the others cloned.<p>They also remove gaussians which are almost entirely transparent, no point in keeping those around.<p>That&#x27;s my understanding at least, after a first time gloss-through.</div><br/><div id="37908054" class="c"><input type="checkbox" id="c-37908054" checked=""/><div class="controls bullet"><span class="by">webdood90</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37907934">parent</a><span>|</span><a href="#37907057">next</a><span>|</span><label class="collapse" for="c-37908054">[-]</label><label class="expand" for="c-37908054">[7 more]</label></div><br/><div class="children"><div class="content">You:<p>&gt; Essentially they&#x27;re doing what you do when you train a neural network, only that instead of adjusting weights connecting &quot;neurons&quot;, you adjust the shape and position of gaussians, and the coefficients of spherical harmonics for the colors.<p>My brain:<p>&gt; They&#x27;re providing inverse reactive current to generate unilateral phase detractors, automatically synchronizing cardinal gram meters.</div><br/><div id="37908490" class="c"><input type="checkbox" id="c-37908490" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37908054">parent</a><span>|</span><a href="#37908355">next</a><span>|</span><label class="collapse" for="c-37908490">[-]</label><label class="expand" for="c-37908490">[4 more]</label></div><br/><div class="children"><div class="content">Heh. For those that haven&#x27;t dabbled much with neural nets, the key aspect here is the backpropagation[1]. If you want to optimize a process, you typically change the parameters (turn a knob or change a number) and see how the output reacts. If it changed too much you reduce the parameter etc. This is a forwards process.<p>The idea in backpropogation is instead to mathematically relate a change in output to a change in the parameters. You figure out how much you need to change the parameters to change the output a desired amount. Hence the &quot;back&quot; in the name, since you want to control the output, &quot;steering&quot; it in the direction you want, and to do so you go backwards through the process to figure out how much you need to change the parameters.<p>Instead of &quot;if I turn the knob 15 degrees the temperature goes up 20 degrees&quot;, you want &quot;in order to increase the temperature 20 degrees the knob must be turned 15 degrees&quot;.<p>By comparing the output with a reference, you get how much the output needs to change to match the reference, and by using the backpropagation technique you can then relate that to how much you need to change the parameters.<p>In neural nets the parameters are the so-called weights of the connections between the layers in the model. However the idea is quite general so here they&#x27;ve applied it to optimizing the size, shape, position and color of (gaussian) blobs, which when rendered on top of each other blend to form an image.<p>Changing a blobs position say might make it better for one pixel but worse for another. So instead of doing a big change in parameters, you do small iterative steps. This is the so-called training phase. Over time the hope is that the output error decreases steadily.<p>edit: while backpropagation is quite general as such, as I alluded to earlier, it does require that the operation behaves sufficiently nice, so to speak. That&#x27;s one reason for using gaussians over say spheres. Gaussians have nice smooth properties. Spheres have an edge, the surface, which introduces a sudden change. Backpropagation works best with smooth changes.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Backpropagation" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Backpropagation</a></div><br/><div id="37910757" class="c"><input type="checkbox" id="c-37910757" checked=""/><div class="controls bullet"><span class="by">flakes</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37908490">parent</a><span>|</span><a href="#37910090">next</a><span>|</span><label class="collapse" for="c-37910757">[-]</label><label class="expand" for="c-37910757">[1 more]</label></div><br/><div class="children"><div class="content">Thank you. This was much more approachable for someone like myself that has little background (a few undergrad courses) in both machine learning and computer vision concepts.</div><br/></div></div><div id="37910090" class="c"><input type="checkbox" id="c-37910090" checked=""/><div class="controls bullet"><span class="by">ewngzen</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37908490">parent</a><span>|</span><a href="#37910757">prev</a><span>|</span><a href="#37908355">next</a><span>|</span><label class="collapse" for="c-37910090">[-]</label><label class="expand" for="c-37910090">[2 more]</label></div><br/><div class="children"><div class="content">I was just about to ask why not use a sphere? since it could be thought of as a nn, it will be into NN someday. guess the splitting and merge can be compared with dropout then.</div><br/><div id="37911734" class="c"><input type="checkbox" id="c-37911734" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37910090">parent</a><span>|</span><a href="#37908355">next</a><span>|</span><label class="collapse" for="c-37911734">[-]</label><label class="expand" for="c-37911734">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m no expert, but my immediate thoughts are that evaluating a gaussian blob is very simple, it&#x27;s just an exponential of a distance. The edge of a sphere makes it more complicated to compute, hence slower.<p>For backpropagation, the differentials of a gaussian is smooth while it&#x27;s not for a sphere, again because of the edge.<p>Now, if you want to use a sphere you probably will do something like using an opacity falloff similar to ReLU[1], making it transparent at the edge.<p>This should make smooth enough as such I guess, but I imagine you still have the more complicated rendering. Though I may be mistaken.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rectifier_(neural_networks)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rectifier_(neural_networks)</a></div><br/></div></div></div></div></div></div><div id="37908355" class="c"><input type="checkbox" id="c-37908355" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37908054">parent</a><span>|</span><a href="#37908490">prev</a><span>|</span><a href="#37908376">next</a><span>|</span><label class="collapse" for="c-37908355">[-]</label><label class="expand" for="c-37908355">[1 more]</label></div><br/><div class="children"><div class="content">I still continue to read comments like those though - there is a chance I might make sense of a word! But I did find myself laughing as I read the original post thinking about how this sounds like a word salad.</div><br/></div></div><div id="37908376" class="c"><input type="checkbox" id="c-37908376" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#37907032">root</a><span>|</span><a href="#37908054">parent</a><span>|</span><a href="#37908355">prev</a><span>|</span><a href="#37907057">next</a><span>|</span><label class="collapse" for="c-37908376">[-]</label><label class="expand" for="c-37908376">[1 more]</label></div><br/><div class="children"><div class="content">The object that’s being optimized are the parameters of a 3D Gaussian, just imagine a blob changing shape. That’s optimized instead of optimizing a neural network</div><br/></div></div></div></div></div></div><div id="37907057" class="c"><input type="checkbox" id="c-37907057" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#37907032">parent</a><span>|</span><a href="#37907934">prev</a><span>|</span><a href="#37907266">next</a><span>|</span><label class="collapse" for="c-37907057">[-]</label><label class="expand" for="c-37907057">[1 more]</label></div><br/><div class="children"><div class="content">What parts confuse you? There are a few steps in optimization. There are lots of papers on differentiable rendering, but the pruining of gaussians and the actual treatment of gaussians, I don&#x27;t think there&#x27;s a blog post.</div><br/></div></div></div></div><div id="37907317" class="c"><input type="checkbox" id="c-37907317" checked=""/><div class="controls bullet"><span class="by">MrTrvp</span><span>|</span><a href="#37907032">prev</a><span>|</span><a href="#37906785">next</a><span>|</span><label class="collapse" for="c-37907317">[-]</label><label class="expand" for="c-37907317">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me the Deja Vu movie and how they maneuver angles.</div><br/></div></div><div id="37906785" class="c"><input type="checkbox" id="c-37906785" checked=""/><div class="controls bullet"><span class="by">Cieric</span><span>|</span><a href="#37907317">prev</a><span>|</span><a href="#37910571">next</a><span>|</span><label class="collapse" for="c-37906785">[-]</label><label class="expand" for="c-37906785">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been slowly building my own rendering and training on a non cuda library (trying with vulkan&#x2F;spirv) I&#x27;m curious how many cameras they used here though.</div><br/></div></div><div id="37910571" class="c"><input type="checkbox" id="c-37910571" checked=""/><div class="controls bullet"><span class="by">xrguy</span><span>|</span><a href="#37906785">prev</a><span>|</span><a href="#37907086">next</a><span>|</span><label class="collapse" for="c-37910571">[-]</label><label class="expand" for="c-37910571">[1 more]</label></div><br/><div class="children"><div class="content">i like how galaxies look like ellipsoids if you zoom out</div><br/></div></div><div id="37907086" class="c"><input type="checkbox" id="c-37907086" checked=""/><div class="controls bullet"><span class="by">ge96</span><span>|</span><a href="#37910571">prev</a><span>|</span><a href="#37908571">next</a><span>|</span><label class="collapse" for="c-37907086">[-]</label><label class="expand" for="c-37907086">[4 more]</label></div><br/><div class="children"><div class="content">Wondering when this technique will be used for meal calorie counters</div><br/><div id="37907322" class="c"><input type="checkbox" id="c-37907322" checked=""/><div class="controls bullet"><span class="by">MattRix</span><span>|</span><a href="#37907086">parent</a><span>|</span><a href="#37908571">next</a><span>|</span><label class="collapse" for="c-37907322">[-]</label><label class="expand" for="c-37907322">[3 more]</label></div><br/><div class="children"><div class="content">Not seeing how that is related?</div><br/><div id="37907439" class="c"><input type="checkbox" id="c-37907439" checked=""/><div class="controls bullet"><span class="by">ge96</span><span>|</span><a href="#37907086">root</a><span>|</span><a href="#37907322">parent</a><span>|</span><a href="#37907376">next</a><span>|</span><label class="collapse" for="c-37907439">[-]</label><label class="expand" for="c-37907439">[1 more]</label></div><br/><div class="children"><div class="content">The wobbling made me think of photogramettery&#x2F;estimating volume with a camera paired with some visual model to detect peas or whatever. Without a concrete dimension though eg. lidar not sure how accurate.</div><br/></div></div><div id="37907376" class="c"><input type="checkbox" id="c-37907376" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#37907086">root</a><span>|</span><a href="#37907322">parent</a><span>|</span><a href="#37907439">prev</a><span>|</span><a href="#37908571">next</a><span>|</span><label class="collapse" for="c-37907376">[-]</label><label class="expand" for="c-37907376">[1 more]</label></div><br/><div class="children"><div class="content">That cookie looks delicious</div><br/></div></div></div></div></div></div><div id="37908571" class="c"><input type="checkbox" id="c-37908571" checked=""/><div class="controls bullet"><span class="by">vavooom</span><span>|</span><a href="#37907086">prev</a><span>|</span><a href="#37909261">next</a><span>|</span><label class="collapse" for="c-37908571">[-]</label><label class="expand" for="c-37908571">[1 more]</label></div><br/><div class="children"><div class="content">This is just incredible technology</div><br/></div></div><div id="37909261" class="c"><input type="checkbox" id="c-37909261" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#37908571">prev</a><span>|</span><a href="#37907631">next</a><span>|</span><label class="collapse" for="c-37909261">[-]</label><label class="expand" for="c-37909261">[1 more]</label></div><br/><div class="children"><div class="content">Combine this with state of the art VR tech (something with good eye tracking and 4k per eye) and we&#x27;re living in the future.</div><br/></div></div><div id="37907631" class="c"><input type="checkbox" id="c-37907631" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#37909261">prev</a><span>|</span><label class="collapse" for="c-37907631">[-]</label><label class="expand" for="c-37907631">[3 more]</label></div><br/><div class="children"><div class="content">Well, Rule 34 is about to happen.  And &quot;splatting&quot; is already a decent name...</div><br/><div id="37908165" class="c"><input type="checkbox" id="c-37908165" checked=""/><div class="controls bullet"><span class="by">crtified</span><span>|</span><a href="#37907631">parent</a><span>|</span><a href="#37907734">next</a><span>|</span><label class="collapse" for="c-37908165">[-]</label><label class="expand" for="c-37908165">[1 more]</label></div><br/><div class="children"><div class="content">Ha! Or Rule 34a, &quot;every sufficiently observed phenomenon, has just become somebody&#x27;s new fetish&quot;.<p>Although actually, and on a slightly more innocent (but just as edgy!) note, the thing that immediately popped into my head upon reading &quot;4D Gaussian Splatting&quot;, was the music from the 1992 Future Crew demo Unreal, and the image of it&#x27;s inter-scene title screens. [&quot;IYKYK&quot;, but basically, that famous old PC demo consists of several short sections, each showcasing a particular coding&#x2F;graphical technique - each section prefaced by a title screen which named the effect being showcased.]<p>YT of Unreal demo, as citation for this <i>highly-important</i> observation : <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=InrGJ7C9B3s">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=InrGJ7C9B3s</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>