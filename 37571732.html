<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695200461593" as="style"/><link rel="stylesheet" href="styles.css?v=1695200461593"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.symphony.run/">Show HN: Symphony – Use GPT-4 to call functions in sequence</a> <span class="domain">(<a href="https://www.symphony.run">www.symphony.run</a>)</span></div><div class="subtext"><span>jrmyphlmn</span> | <span>20 comments</span></div><br/><div><div id="37580072" class="c"><input type="checkbox" id="c-37580072" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#37580585">next</a><span>|</span><label class="collapse" for="c-37580072">[-]</label><label class="expand" for="c-37580072">[7 more]</label></div><br/><div class="children"><div class="content">Nice. Just to point out, calling a sequence of functions is what GPT-4 does automatically if you keep feeding it the responses and it is clear to it that is necessary given it&#x27;s instructions.<p>So the main point of this seems to be extracting the interface from the module and converting it into the OpenAI API call&#x27;s functions format.<p>It&#x27;s a good idea. But for me I would rather just have an npm package with a function like<p><pre><code>  extractFunctions(srcFilename)
</code></pre>
which I could then use inside of my own project which already handles the rest of it.</div><br/><div id="37581397" class="c"><input type="checkbox" id="c-37581397" checked=""/><div class="controls bullet"><span class="by">jrmyphlmn</span><span>|</span><a href="#37580072">parent</a><span>|</span><a href="#37580781">next</a><span>|</span><label class="collapse" for="c-37581397">[-]</label><label class="expand" for="c-37581397">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! You&#x27;re right; the main focus right now is extraction.<p>One aspect I&#x27;m excited about is the possibility of rendering the JSON outputs from these function calls into UI components, as previewed here: <a href="https:&#x2F;&#x2F;symphony.run&#x2F;showcase" rel="nofollow noreferrer">https:&#x2F;&#x2F;symphony.run&#x2F;showcase</a>. Using a function&#x27;s type definitions is a nice starting point to embed interfaces into the conversation.<p>Additionally, I hope to make the toolkit language-agnostic. I&#x27;d like to incorporate some of my .py and .rs scripts to make them ready for use as well. Not sure if packaging it as an npm package would go against that objective, but will definitely consider :)</div><br/></div></div><div id="37580781" class="c"><input type="checkbox" id="c-37580781" checked=""/><div class="controls bullet"><span class="by">lukasb</span><span>|</span><a href="#37580072">parent</a><span>|</span><a href="#37581397">prev</a><span>|</span><a href="#37580300">next</a><span>|</span><label class="collapse" for="c-37580781">[-]</label><label class="expand" for="c-37580781">[2 more]</label></div><br/><div class="children"><div class="content">Well, this knows when to stop calling GPT-4, which seems non-trivial.</div><br/><div id="37581051" class="c"><input type="checkbox" id="c-37581051" checked=""/><div class="controls bullet"><span class="by">wyozi</span><span>|</span><a href="#37580072">root</a><span>|</span><a href="#37580781">parent</a><span>|</span><a href="#37580300">next</a><span>|</span><label class="collapse" for="c-37581051">[-]</label><label class="expand" for="c-37581051">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT does this automatically, if you pass in `function_call: &quot;auto&quot;`</div><br/></div></div></div></div><div id="37580300" class="c"><input type="checkbox" id="c-37580300" checked=""/><div class="controls bullet"><span class="by">andrewguenther</span><span>|</span><a href="#37580072">parent</a><span>|</span><a href="#37580781">prev</a><span>|</span><a href="#37580585">next</a><span>|</span><label class="collapse" for="c-37580300">[-]</label><label class="expand" for="c-37580300">[3 more]</label></div><br/><div class="children"><div class="content">Yep. I built this for Python recently and it uses introspection to automatically build this same info. It&#x27;s maybe 100 lines in total? The OpenAI API is pretty amazing.</div><br/><div id="37581435" class="c"><input type="checkbox" id="c-37581435" checked=""/><div class="controls bullet"><span class="by">jrmyphlmn</span><span>|</span><a href="#37580072">root</a><span>|</span><a href="#37580300">parent</a><span>|</span><a href="#37580472">next</a><span>|</span><label class="collapse" for="c-37581435">[-]</label><label class="expand" for="c-37581435">[1 more]</label></div><br/><div class="children"><div class="content">That sounds great! I&#x27;m currently working on adding support for .py files as well – open to PRs :)</div><br/></div></div><div id="37580472" class="c"><input type="checkbox" id="c-37580472" checked=""/><div class="controls bullet"><span class="by">amrrs</span><span>|</span><a href="#37580072">root</a><span>|</span><a href="#37580300">parent</a><span>|</span><a href="#37581435">prev</a><span>|</span><a href="#37580585">next</a><span>|</span><label class="collapse" for="c-37580472">[-]</label><label class="expand" for="c-37580472">[1 more]</label></div><br/><div class="children"><div class="content">Have you packaged or shared your codebase? If so would love to see it!</div><br/></div></div></div></div></div></div><div id="37580585" class="c"><input type="checkbox" id="c-37580585" checked=""/><div class="controls bullet"><span class="by">justanotheratom</span><span>|</span><a href="#37580072">prev</a><span>|</span><a href="#37579883">next</a><span>|</span><label class="collapse" for="c-37580585">[-]</label><label class="expand" for="c-37580585">[1 more]</label></div><br/><div class="children"><div class="content">I tried TypeChat for my use case and ended up defining functions as typescript data types. This approach sounds much better, and leverages the newer OpenAI function calling, which should be more reliable I would think. Thanks for creating+sharing.<p><a href="https:&#x2F;&#x2F;microsoft.github.io&#x2F;TypeChat&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;microsoft.github.io&#x2F;TypeChat&#x2F;</a></div><br/></div></div><div id="37579883" class="c"><input type="checkbox" id="c-37579883" checked=""/><div class="controls bullet"><span class="by">mkmk</span><span>|</span><a href="#37580585">prev</a><span>|</span><a href="#37580269">next</a><span>|</span><label class="collapse" for="c-37579883">[-]</label><label class="expand" for="c-37579883">[6 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m understanding correctly, this makes all of the functions available to gpt-4 at once and then gpt-4 decides which one to use, right? What are the limits on the number and length of functions, and is there any way to choose only a subject of the functions to share for a given user query?</div><br/><div id="37581633" class="c"><input type="checkbox" id="c-37581633" checked=""/><div class="controls bullet"><span class="by">jrmyphlmn</span><span>|</span><a href="#37579883">parent</a><span>|</span><a href="#37579995">next</a><span>|</span><label class="collapse" for="c-37581633">[-]</label><label class="expand" for="c-37581633">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right!<p>IIRC, only the function signatures (or descriptions) are counted as part of the context window so you could add as many till you exceed that limit. Since the contents of the function itself are not counted, your function can be whatever length.<p>&gt; is there any way to choose only a subject of the functions to share for a given user query?<p>As of now, no. I can see why this may be a problem soon since right now all functions are available for gpt-4 and each call can become expensive pretty quickly if you send like 50 functions every time.<p>I&#x27;m not sure how to address this yet, but I&#x27;d like to think of it as some form of fine-tuning that happens after having a few conversations. Will keep you in the loop!</div><br/></div></div><div id="37579995" class="c"><input type="checkbox" id="c-37579995" checked=""/><div class="controls bullet"><span class="by">NickNaraghi</span><span>|</span><a href="#37579883">parent</a><span>|</span><a href="#37581633">prev</a><span>|</span><a href="#37579930">next</a><span>|</span><label class="collapse" for="c-37579995">[-]</label><label class="expand" for="c-37579995">[3 more]</label></div><br/><div class="children"><div class="content">Pretty cool that this is a recreation of expert systems, which was a dominant approach to building AIs for decades :)</div><br/><div id="37580040" class="c"><input type="checkbox" id="c-37580040" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#37579883">root</a><span>|</span><a href="#37579995">parent</a><span>|</span><a href="#37579930">next</a><span>|</span><label class="collapse" for="c-37580040">[-]</label><label class="expand" for="c-37580040">[2 more]</label></div><br/><div class="children"><div class="content">Expert systems except it&#x27;s like 400 times more expensive to run.</div><br/><div id="37580587" class="c"><input type="checkbox" id="c-37580587" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37579883">root</a><span>|</span><a href="#37580040">parent</a><span>|</span><a href="#37579930">next</a><span>|</span><label class="collapse" for="c-37580587">[-]</label><label class="expand" for="c-37580587">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but also 400 times (at least...) more versatile <i>and</i> more error prone.<p>Determinism was one of the things that the expert systems of old did reasonably well. The current incarnation feels like playing Russian Roulette but with three bullets rather than just one.</div><br/></div></div></div></div></div></div><div id="37579930" class="c"><input type="checkbox" id="c-37579930" checked=""/><div class="controls bullet"><span class="by">nurple</span><span>|</span><a href="#37579883">parent</a><span>|</span><a href="#37579995">prev</a><span>|</span><a href="#37580269">next</a><span>|</span><label class="collapse" for="c-37579930">[-]</label><label class="expand" for="c-37579930">[1 more]</label></div><br/><div class="children"><div class="content">Sure, give the LLM a discovery function. If you&#x27;re trying to figure out what tools to give the LLM based on user input, you&#x27;re probably squandering the main power of the pattern.</div><br/></div></div></div></div><div id="37580269" class="c"><input type="checkbox" id="c-37580269" checked=""/><div class="controls bullet"><span class="by">swozey</span><span>|</span><a href="#37579883">prev</a><span>|</span><a href="#37580429">next</a><span>|</span><label class="collapse" for="c-37580269">[-]</label><label class="expand" for="c-37580269">[3 more]</label></div><br/><div class="children"><div class="content">Is there still an absolutely pathetic amount of GPT4 calls per day? I pay the $20 to chatgpt but I never ever pick GPT4 because 10 minutes into an AI directed conversation I&#x27;ll get the &quot;sorry ur out of gpt4 today&quot; message. The only time I wind up using that limit is when I don&#x27;t even realize it&#x27;s using it. I have no idea what the difference actually is because its limit is to low for me to even consider relying on over 3.5.</div><br/><div id="37580393" class="c"><input type="checkbox" id="c-37580393" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#37580269">parent</a><span>|</span><a href="#37581882">next</a><span>|</span><label class="collapse" for="c-37580393">[-]</label><label class="expand" for="c-37580393">[1 more]</label></div><br/><div class="children"><div class="content">Try using the API. There are multiple open source ChatGPT clones or terminal clients. The API limits are not a problem for an individual.</div><br/></div></div><div id="37581882" class="c"><input type="checkbox" id="c-37581882" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#37580269">parent</a><span>|</span><a href="#37580393">prev</a><span>|</span><a href="#37580429">next</a><span>|</span><label class="collapse" for="c-37581882">[-]</label><label class="expand" for="c-37581882">[1 more]</label></div><br/><div class="children"><div class="content">No it&#x27;s been OK the last month or 2</div><br/></div></div></div></div></div></div></div></div></div></body></html>