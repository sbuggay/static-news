<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729414851290" as="style"/><link rel="stylesheet" href="styles.css?v=1729414851290"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.scientificamerican.com/article/you-dont-need-words-to-think/">Language is not essential for the cognitive processes that underlie thought</a> <span class="domain">(<a href="https://www.scientificamerican.com">www.scientificamerican.com</a>)</span></div><div class="subtext"><span>orcul</span> | <span>202 comments</span></div><br/><div><div id="41891004" class="c"><input type="checkbox" id="c-41891004" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#41890003">next</a><span>|</span><label class="collapse" for="c-41891004">[-]</label><label class="expand" for="c-41891004">[1 more]</label></div><br/><div class="children"><div class="content">All: please don&#x27;t comment based on your first response to an inevitably shallow title. That leads to generic discussion, which we&#x27;re trying to avoid on HN. <i>Specific</i> discussion of what&#x27;s new or different in an article is a much better basis for interesting conversation.<p>Since we all have language and opinions about it, the risk of genericness is high with a title like this. It&#x27;s like this with threads about other universal topics too, such as food or health.</div><br/></div></div><div id="41890003" class="c"><input type="checkbox" id="c-41890003" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41891004">prev</a><span>|</span><a href="#41891068">next</a><span>|</span><label class="collapse" for="c-41890003">[-]</label><label class="expand" for="c-41890003">[96 more]</label></div><br/><div class="children"><div class="content">This is an important result.<p>The actual paper [1] says that functional MRI (which is measuring which parts of the brain are active by sensing blood flow) indicates that different brain hardware is used for non-language and language functions.
This has been suspected for years, but now there&#x27;s an experimental result.<p>What this tells us for AI is that we need something else besides LLMs. It&#x27;s not clear what that something else is. But, as the paper mentions, the low-end mammals and the corvids lack language but have some substantial problem-solving capability. That&#x27;s seen down at squirrel and crow size, where the brains are tiny. So if someone figures out to do this, it will probably take less hardware than an LLM.<p>This is the next big piece we need for AI. No idea how to do this, but it&#x27;s the right question to work on.<p>[1] <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-024-07522-w.epdf?sharing_token=1BwycCwx1wQ2Sfnub1-o0NRgN0jAjWel9jnR3ZoTv0MYYopL5qENCL5gCQ3HDKyBWf6AQLs-HC3fMMzU9skb40K1DK-HWblYUyHTAQuuliWeLXeg5lXVNFOTa3fVek1R0et9kPjIgQljFd2wX1hSlqWjpOKSrRjz8t2mUDQ6Vr6DlhIlAndISxjxnRU2FPd2XMQFK5UDTh5Osiq6IYOksvy1nGE68d0y9YuJvr4Zrok%3D&amp;tracking_referrer=www.scientificamerican.com" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-024-07522-w.epdf?shar...</a></div><br/><div id="41894031" class="c"><input type="checkbox" id="c-41894031" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41892068">next</a><span>|</span><label class="collapse" for="c-41894031">[-]</label><label class="expand" for="c-41894031">[1 more]</label></div><br/><div class="children"><div class="content">Most pre-deep learning architectures had separate modules like &quot;language model&quot;, &quot;knowledge base&quot; and &quot;inference component&quot;.<p>Then LLMs came along, and ML folks got rather too excited that they contain implicit knowledge (which, of course, is required to deal with ambiguity).
Then the new aspiration as &quot;all in one&quot; and &quot;bigger is better&quot;, not analyzing what components are needed and how to orchestrate their interplay.<p>From an engineering (rather than science) point of view, the &quot;end-to-end black box&quot; approach is perhaps misguided, because the result will be a non-transparent system by definition. Individual sub-models should be connected in a way that retains control (e.g. in dialog agents, SRI&#x27;s Open Agent Architecture was a random example of such &quot;glue&quot; to tie components together, to name but one).<p>Regarding the science, I do believe language adds to the power of thinking; while (other) animals can of course solve simple problems without language, language permits us to define layers of abstractions (by defining and sharing new concepts) that goes beyond simple, non-linguistic thoughts. Programming languages (created by us humans somewhat in the image of human language) and the language of mathematics are two examples where we push this even further (beyond the definition of new named concepts, to also define new &quot;DSL&quot; syntax) - but all of these could not come into beying without human language: all formal specs and all axioms are ultimately and can only be formulated in human language. So without language, we would likely be stuck at a very simple point of development, individually and collectively.<p>EDIT: 2 typos fixed</div><br/></div></div><div id="41892068" class="c"><input type="checkbox" id="c-41892068" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41894031">prev</a><span>|</span><a href="#41891228">next</a><span>|</span><label class="collapse" for="c-41892068">[-]</label><label class="expand" for="c-41892068">[21 more]</label></div><br/><div class="children"><div class="content">When you look at how humans play chess they employ several different cognitive strategies.  Memorization, calculation, strategic thinking, heuristics, and learned experience.<p>When the first chess engines came out they only employed one of these: calculation.  It wasn&#x27;t until relatively recently that we had computer programs that could perform all of them.  But it turns out that if you scale that up with enough compute you can achieve superhuman results with calculation alone.<p>It&#x27;s not clear to me that LLMs sufficiently scaled won&#x27;t achieve superhuman performance on general cognitive tasks even if there are things humans do which they can&#x27;t.<p>The other thing I&#x27;d point out is that all language is essentially synthetic training data.  Humans invented language as a way to transfer their internal thought processes to other humans.  It makes sense that the process of thinking and the process of translating those thoughts into and out of language would be distinct.</div><br/><div id="41893580" class="c"><input type="checkbox" id="c-41893580" checked=""/><div class="controls bullet"><span class="by">senand</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892068">parent</a><span>|</span><a href="#41892323">next</a><span>|</span><label class="collapse" for="c-41893580">[-]</label><label class="expand" for="c-41893580">[1 more]</label></div><br/><div class="children"><div class="content">This seems quite reasonable, but I recently heard a podcast (<a href="https:&#x2F;&#x2F;www.preposterousuniverse.com&#x2F;podcast&#x2F;2024&#x2F;06&#x2F;24&#x2F;280-francois-chollet-on-deep-learning-and-the-meaning-of-intelligence&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.preposterousuniverse.com&#x2F;podcast&#x2F;2024&#x2F;06&#x2F;24&#x2F;280-...</a>) that LLMs are more likely to be very good at navigating what they have been trained on, but very poor at abstract reasoning and discovering new areas outside of their training. As a single human, you don&#x27;t notice, as the training material is greater than everything we could ever learn.<p>After all, that&#x27;s what Artificial General Intelligence would at least in part be about: finding and proving new math theorems, creating new poetry, making new scientific discoveries, etc.<p>There is even a new challenge that&#x27;s been proposed: <a href="https:&#x2F;&#x2F;arcprize.org&#x2F;blog&#x2F;launch" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;blog&#x2F;launch</a><p>&gt; It makes sense that the process of thinking and the process of translating those thoughts into and out of language would be distinct<p>Yes, indeed. And LLMs seem to be very good at _simulating_ the translation of thought into language. They don&#x27;t actually do it, at least not like humans do.</div><br/></div></div><div id="41892323" class="c"><input type="checkbox" id="c-41892323" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892068">parent</a><span>|</span><a href="#41893580">prev</a><span>|</span><a href="#41892675">next</a><span>|</span><label class="collapse" for="c-41892323">[-]</label><label class="expand" for="c-41892323">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not clear to me that LLMs sufficiently scaled won&#x27;t achieve superhuman performance on general cognitive tasks<p>If &quot;general cognitive tasks&quot; means &quot;I give you a prompt in some form, and you give me an incredible response of some form &quot; (forms may differ or be the same) then it is hard to disagree with you.<p>But if by &quot;general cognitive task&quot; you mean &quot;all the cognitive things that human do&quot;, then it is really hard to see why you would have any confidence that LLMs have any hope of achieving superhuman performance at these things.</div><br/><div id="41893022" class="c"><input type="checkbox" id="c-41893022" checked=""/><div class="controls bullet"><span class="by">jhrmnn</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892323">parent</a><span>|</span><a href="#41892675">next</a><span>|</span><label class="collapse" for="c-41893022">[-]</label><label class="expand" for="c-41893022">[2 more]</label></div><br/><div class="children"><div class="content">Even in cognitive tasks expressed via language, something like a memory feels necessary. At which point it’s not a LLM as in a generic language model. It would become a language model conditioned on the memory state.</div><br/><div id="41893745" class="c"><input type="checkbox" id="c-41893745" checked=""/><div class="controls bullet"><span class="by">ddingus</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893022">parent</a><span>|</span><a href="#41892675">next</a><span>|</span><label class="collapse" for="c-41893745">[-]</label><label class="expand" for="c-41893745">[1 more]</label></div><br/><div class="children"><div class="content">More than a memory.<p>Needs to be a closed loop, running on its own.<p>We get its attention, and it responds, or frankly if we did manage any sort of sentience, even a simulation of it, then the fact is it may not respond.<p>To me, that is the real test.</div><br/></div></div></div></div></div></div><div id="41892675" class="c"><input type="checkbox" id="c-41892675" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892068">parent</a><span>|</span><a href="#41892323">prev</a><span>|</span><a href="#41892362">next</a><span>|</span><label class="collapse" for="c-41892675">[-]</label><label class="expand" for="c-41892675">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not clear to me that LLMs sufficiently scaled won&#x27;t achieve superhuman performance<p>To some extent this is true.<p>To calculate A + B you could for example generate A, B for trillions of combinations and encode that within the network. And it would calculate this faster than any human could.<p>But that&#x27;s not intelligence. And Apple&#x27;s research showed that LLMs are simply inferring relationships based on the tokens it has access to. Which you can throw off by adding useless information or trying to abstract A + B.</div><br/><div id="41893161" class="c"><input type="checkbox" id="c-41893161" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892675">parent</a><span>|</span><a href="#41892362">next</a><span>|</span><label class="collapse" for="c-41893161">[-]</label><label class="expand" for="c-41893161">[1 more]</label></div><br/><div class="children"><div class="content">&gt; To calculate A + B you could for example generate A, B for trillions of combinations and encode that within the network. And it would calculate this faster than any human could.<p>I don&#x27;t feel like this is a very meaningful argument because if you can do that generation then you must already have a superhuman machine for that task.</div><br/></div></div></div></div><div id="41892362" class="c"><input type="checkbox" id="c-41892362" checked=""/><div class="controls bullet"><span class="by">nox101</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892068">parent</a><span>|</span><a href="#41892675">prev</a><span>|</span><a href="#41893389">next</a><span>|</span><label class="collapse" for="c-41892362">[-]</label><label class="expand" for="c-41892362">[13 more]</label></div><br/><div class="children"><div class="content">It sounds like you think this research is wrong? (it claims llms can not reason)<p><a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;ai&#x2F;2024&#x2F;10&#x2F;llms-cant-perform-genuine-logical-reasoning-apple-researchers-suggest&#x2F;" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;ai&#x2F;2024&#x2F;10&#x2F;llms-cant-perform-genuine...</a><p>or do you maybe think no logical reasoning is needed to do everything a human can do? Tho humans seem to be able to do logical reasoning</div><br/><div id="41892408" class="c"><input type="checkbox" id="c-41892408" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892362">parent</a><span>|</span><a href="#41892707">next</a><span>|</span><label class="collapse" for="c-41892408">[-]</label><label class="expand" for="c-41892408">[2 more]</label></div><br/><div class="children"><div class="content">It says &quot;current&quot; LLMs can&#x27;t &quot;genuinely&quot; reason. Also, one of the researchers then posted an internship for someone to work on LLM reasoning.<p>I think the paper should&#x27;ve included controls, because we don&#x27;t know how strong the result is. They certainly may have proven that humans can&#x27;t reason either.</div><br/><div id="41892660" class="c"><input type="checkbox" id="c-41892660" checked=""/><div class="controls bullet"><span class="by">mannykannot</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892408">parent</a><span>|</span><a href="#41892707">next</a><span>|</span><label class="collapse" for="c-41892660">[-]</label><label class="expand" for="c-41892660">[1 more]</label></div><br/><div class="children"><div class="content">If they had human controls, they might well show that some humans can’t do any better, but based on how they generated test cases, it seems unlikely to me that doing so would prove that humans cannot reason (of course, if that’s actually the case, we cannot trust ourselves to devise, execute and interpret these tests in the first place!)<p>Some people will use any limitation of LLMs to deny there is anything to see here, while others will call this ‘moving the goalposts’, but the most interesting questions, I believe, involve figuring out what the differences are, putting aside the question of whether LLMs are or are not AGIs.</div><br/></div></div></div></div><div id="41892707" class="c"><input type="checkbox" id="c-41892707" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892362">parent</a><span>|</span><a href="#41892408">prev</a><span>|</span><a href="#41892803">next</a><span>|</span><label class="collapse" for="c-41892707">[-]</label><label class="expand" for="c-41892707">[1 more]</label></div><br/><div class="children"><div class="content">The later.<p>While I generally <i>do</i> suspect that we need to invent some new technique in the realm of AI in order for software to do everything a human can do, I use analogies like chess engines to caution myself from certainty.</div><br/></div></div><div id="41892803" class="c"><input type="checkbox" id="c-41892803" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892362">parent</a><span>|</span><a href="#41892707">prev</a><span>|</span><a href="#41893389">next</a><span>|</span><label class="collapse" for="c-41892803">[-]</label><label class="expand" for="c-41892803">[9 more]</label></div><br/><div class="children"><div class="content">I’ll pop in with a friendly “that research is definitely wrong”. If they want to prove that LLMs can’t reason, shouldn’t they stringently define that word somewhere in their paper? As it stands, they’re proving something small (some of today’s LLMs have XYZ weaknesses) and claiming something big (humans have an ineffable calculator-soul).<p>LLMs absolutely 100% can reason, if we take the dictionary definition; it’s trivial to show their ability to answer non-memorized questions, and the only way to do that is <i>some</i> sort of reasoning. I personally don’t think they’re the most efficient tool for deliberative derivation of concepts, but I also think any sort of categorical prohibition is anti-scientific. What is the brain other than a neural network?<p>Even if we accept the most fringe, anthropocentric theories like Penrose &amp; Hammerhoff’s quantum tubules, that’s just a neural network with fancy weights. How could we possibly hope to forbid digital recreations of our brains from “truly” or “really” mimicking them?</div><br/><div id="41893782" class="c"><input type="checkbox" id="c-41893782" checked=""/><div class="controls bullet"><span class="by">ddingus</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892803">parent</a><span>|</span><a href="#41893282">next</a><span>|</span><label class="collapse" for="c-41893782">[-]</label><label class="expand" for="c-41893782">[1 more]</label></div><br/><div class="children"><div class="content">Can they reason, or is the volume of training data sufficient for them to match relationships up to appropriate expressions?<p>Basically, if humans have had meaningful discussions about it, the product of their reasoning is there for the LLM, right?<p>Seems to me, the &quot;how many R&#x27;s are there in the word &quot;strawberry&quot; problem is very suggestive of the idea LLM systems cannot reason.  If they could, the question is not difficult.<p>The fact is humans may never have actually discussed that topic in any meaningful way captured in the training data.<p>And because of that and how specific the question is, the LLM has no clear relationships to map into a response.  It just does best case, whatever the math deemed best.<p>Seems plausible enough to support the opinion LLM&#x27;S cannot reason.<p>What we do know is LLMs can work with anything expressed in terms of relationships between words.<p>There is a ton of reasoning templates contained in that data.<p>Put another way:<p>Maybe LLM systems are poor at deduction, save for examples contained in the data.  But there are a ton of examples!<p>So this is hard to notice.<p>Maybe LLM systems are fantastic at inference!  And so those many examples get mapped to the prompt at hand very well.<p>And we do notice that and see it like real thinking, not just some horribly complex surface containing a bazillion relationships...</div><br/></div></div><div id="41893282" class="c"><input type="checkbox" id="c-41893282" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892803">parent</a><span>|</span><a href="#41893782">prev</a><span>|</span><a href="#41893179">next</a><span>|</span><label class="collapse" for="c-41893282">[-]</label><label class="expand" for="c-41893282">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Even if we accept the most fringe, anthropocentric theories like Penrose &amp; Hammerhoff’s quantum tubules, that’s just a neural network with fancy weights.<p>First, while it is a fringe idea with little backing it, it&#x27;s far from the most fringe.<p>Secondly, it is not at all known that animal brains are accurately modeled as an ANN, any more so than any other Turing-compatible system can be modeled as an ANN. Biological neurons are themselves small computers, like all living cells in general, with not fully understood capabilities. The way biological neurons are connected is far more complex than a weight in an ANN. And I&#x27;m not talking about fantasy quantum effects in microtubules, I&#x27;m talking about well-established biology, with many kinds of synapses, some of which are &quot;multicast&quot; in a spatially distinct area instead of connected to specific neurons. And about the non-neuronal glands which are known to change neuron behavior and so on.<p>How critical any of these differences are to cognition is anyone&#x27;s guess at this time. But dismissing them and reducing the brain to a bigger NN is not wise.</div><br/><div id="41893426" class="c"><input type="checkbox" id="c-41893426" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893282">parent</a><span>|</span><a href="#41893179">next</a><span>|</span><label class="collapse" for="c-41893426">[-]</label><label class="expand" for="c-41893426">[3 more]</label></div><br/><div class="children"><div class="content">It is my understanding that Penrose doesn’t claim that brains are needed for cognition, just that brains are needed for a somewhat nebulous „conscious experience“, which need not have any observable effects. I think that it’s fairly uncontroversial that a machine  can produce behavior that is indistinguishable from human intelligence over some finite observation time. The Chinese room speaks Chinese, even if it lacks understanding for some definitions of the term.</div><br/><div id="41893950" class="c"><input type="checkbox" id="c-41893950" checked=""/><div class="controls bullet"><span class="by">jstanley</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893426">parent</a><span>|</span><a href="#41893179">next</a><span>|</span><label class="collapse" for="c-41893950">[-]</label><label class="expand" for="c-41893950">[2 more]</label></div><br/><div class="children"><div class="content">But conscious experience does produce observable effects.<p>For that not to be the case, you&#x27;d have to take the position that humans <i>experience consciousness</i> and they <i>talk about consciousness</i> but that there is no causal link between the two! It&#x27;s just a coincidence that the things you find yourself saying about consciousness line up with your internal experience?<p><a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;fdEWWr8St59bXLbQr&#x2F;zombies-zombies" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;fdEWWr8St59bXLbQr&#x2F;zombies-zo...</a></div><br/><div id="41893995" class="c"><input type="checkbox" id="c-41893995" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893950">parent</a><span>|</span><a href="#41893179">next</a><span>|</span><label class="collapse" for="c-41893995">[-]</label><label class="expand" for="c-41893995">[1 more]</label></div><br/><div class="children"><div class="content">That philosophers talk about p-zombies seems like evidence to me that at least some of them don&#x27;t believe that consciousness needs to have observable effects that can&#x27;t be explained without consciousness. I don&#x27;t say that I believe that too. I don&#x27;t believe that there is anything particularly special about brains.</div><br/></div></div></div></div></div></div></div></div><div id="41893179" class="c"><input type="checkbox" id="c-41893179" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892803">parent</a><span>|</span><a href="#41893282">prev</a><span>|</span><a href="#41893265">next</a><span>|</span><label class="collapse" for="c-41893179">[-]</label><label class="expand" for="c-41893179">[2 more]</label></div><br/><div class="children"><div class="content">Chasing our own tail with concepts like &quot;reasoning&quot;. Let&#x27;s move the concept a bit - &quot;search&quot;. Can LLMs search for novel ideas and discoveries? They do under the right circumstances. You got to provide idea testing environments, the missing ingredient. Search and learn, it&#x27;s what humans do and AI can do as well.<p>The whole issue with &quot;reasoning&quot; is that is an incompletely defined concept. Over what domain, what problem space, and what kind of experimental access do we define &quot;reasoning&quot;? Search is better as a concept because it comes packed with all these things, and without conceptual murkiness. Search is scientifically studied to a greater extent.<p>I don&#x27;t think we doubt LLMs can learn given training data, we already accuse them of being mere interpolators or parrots. And we can agree to some extent the LLMs can recombine concepts correctly. So they got down the learning part.<p>And for the searching part, we can probably agree its a matter of access to the search space not AI. It&#x27;s an environment problem, and even a social one. Search is usually more extended than the lifetime of any agent, so it has to be a cultural process, where language plays a central role.<p>When you break reasoning&#x2F;progress&#x2F;intelligence into &quot;search and learn&quot; it becomes much more tractable and useful. We can also make more grounded predictions on AI, considering the needs for search that are implied, not just the needs for learning.<p>How much search did AlphaZero need to beat us at go? How much search did humans pack in our 200K years history over 10,000 generations? What was the cost of that journey of search? That kind of questions. In my napkin estimations we solved 1:10000 of the problem by learning, search is 10000x to a million times harder.</div><br/><div id="41893284" class="c"><input type="checkbox" id="c-41893284" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893179">parent</a><span>|</span><a href="#41893265">next</a><span>|</span><label class="collapse" for="c-41893284">[-]</label><label class="expand" for="c-41893284">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t breakdown cognition into just &quot;search&quot; and &quot;learn&quot; without either ridiculously overloading those concepts or leaving a ton out.</div><br/></div></div></div></div><div id="41893265" class="c"><input type="checkbox" id="c-41893265" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892803">parent</a><span>|</span><a href="#41893179">prev</a><span>|</span><a href="#41893389">next</a><span>|</span><label class="collapse" for="c-41893265">[-]</label><label class="expand" for="c-41893265">[1 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs absolutely 100% can reason, if we take the dictionary definition; it’s trivial to show their ability to answer non-memorized questions, and the only way to do that is some sort of reasoning.<p>Um... What? That is a huge leap to make.<p>&#x27;Reasoning&#x27; is a specific type of thought process and humans regularly make complicated decisions without doing it. We uses hunches and intuition and gut feelings. We make all kinds of snap assessments that we don&#x27;t have time to reason through. As such, answering novel questions doesn&#x27;t necessarily show a system is capable of reasoning.<p>I see absolutely nothing resumbling an argument for humans having an &quot;ineffable calculator soul&quot;, I think that might be you projecting. There is no &#x27;categorical prohibition&#x27;, only an analysis of the current flaws of specific models.<p>Personally, my skepticism about imminent AGI has to do believing we may be underestimating the complexity of the software running on our brain. We&#x27;ve reached the point where we can create digital &quot;brains&quot;, or atleast portions of them. We may be missing some other pieces of a digital brain, or we may just not have the right software to run on it yet. I suspect it is both but that we&#x27;ll have fully functional digital brains well before we figure out the software to run on them.</div><br/></div></div></div></div></div></div><div id="41893389" class="c"><input type="checkbox" id="c-41893389" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892068">parent</a><span>|</span><a href="#41892362">prev</a><span>|</span><a href="#41891228">next</a><span>|</span><label class="collapse" for="c-41893389">[-]</label><label class="expand" for="c-41893389">[1 more]</label></div><br/><div class="children"><div class="content">Sure, when humans use multiple skill to address a specific problem, you can sometimes outperform them by scaling a spefic one of those skills.<p>When it comes to general intelligence, I think we are trying to run before we can walk. We can&#x27;t even make a computer with a basic, animal level understanding of the world. Yet we are trying to take a tool that was developed on top of system that already had an understanding of the world and use it to work backwards to give computers an understanding of the world.<p>I&#x27;m pretty skeptical that we&#x27;re going to succeed at this. I think you have to be able to teach a computer to climb a tree or hunt (subhuman AGI) before you can create superhuman AGI.</div><br/></div></div></div></div><div id="41891228" class="c"><input type="checkbox" id="c-41891228" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41892068">prev</a><span>|</span><a href="#41893960">next</a><span>|</span><label class="collapse" for="c-41891228">[-]</label><label class="expand" for="c-41891228">[20 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs<p>Not to over-hype LLMs, but I don&#x27;t see why this results says this. AI doesn&#x27;t need to do things the same way as evolved intelligence has.</div><br/><div id="41891547" class="c"><input type="checkbox" id="c-41891547" checked=""/><div class="controls bullet"><span class="by">awongh</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41891338">next</a><span>|</span><label class="collapse" for="c-41891547">[-]</label><label class="expand" for="c-41891547">[11 more]</label></div><br/><div class="children"><div class="content">One reason might that LLMs are successful because of the architecture, but also, just as importantly because they can be trained over a volume and diversity of human thought that’s encapsulated in language (that is on the internet). Where are we going to find the equivalent data set that will train this other kind of thinking?<p>Open AI O1 seems to be trained on mostly synthetic data, but it makes intuitive sense that LLMs work so well because we had the data lying around already.</div><br/><div id="41892641" class="c"><input type="checkbox" id="c-41892641" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891547">parent</a><span>|</span><a href="#41891903">next</a><span>|</span><label class="collapse" for="c-41892641">[-]</label><label class="expand" for="c-41892641">[4 more]</label></div><br/><div class="children"><div class="content">&gt; One reason might that LLMs are successful because of the architecture, but also, just as importantly because they can be trained over a volume and diversity of human thought that’s encapsulated in language (that is on the internet). Where are we going to find the equivalent data set that will train this other kind of thinking?<p>Probably by putting simulated animals into simulated environments where they have to survive and thrive.<p>Working at animal level is uncool, but necessary for progress. I had this argument with Rod Brooks a few decades back. He had some good artificial insects, and wanted to immediately jump to human level, with a project called Cog.[1] I asked him why he didn&#x27;t go for mouse level AI next. He said &quot;Because I don&#x27;t want to go down in history as the inventor of the world&#x27;s greatest artificial mouse.&quot;<p>Cog was a dud, and Brooks goes down in history as the inventor of the world&#x27;s first good robotic vacuum cleaner.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cog_(project)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cog_(project)</a></div><br/><div id="41893222" class="c"><input type="checkbox" id="c-41893222" checked=""/><div class="controls bullet"><span class="by">at_a_remove</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892641">parent</a><span>|</span><a href="#41891903">next</a><span>|</span><label class="collapse" for="c-41893222">[-]</label><label class="expand" for="c-41893222">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Where are we going to find the equivalent data set that will train this other kind of thinking?&quot;<p>Just a personal opinion, but in my shitty <i>When H.A.R.L.I.E. Was One</i> (and others) unpublished fiction pastiche (ripoff, really), I had the nascent AI stumble upon Cyc as its base for the world and &quot;thinking about how to think.&quot;<p>I never thought that Cyc was enough, but I do think that something Cyc-like is necessary as a component, a seed for growth, until the AI begins to make the transition from the formally defined, vastly interrelated frames and facts in Cyc to being able to growth further and understand the much less formal knowledgebase you might find in, say Wikipedia.<p>Full agreement with your animal model is only sensible.  If you think about macaques, they have a limited range of vocalization once they hit adulthood.  Noe that the mothers almost never make a noise at their babies.  Lacking language, when a mother wants to train an infant, <i>she hurts it</i>.  (Shades of <i>Blindsight</i> there)  She picks up the infant, grasps it firmly, and nips at it.  The baby tries to get away, but the mother holds it and keeps at it.  Their communication is pain.  Many animals do this.  But they also learn threat displays, the <i>promise</i> of pain, which goes beyond mere carrot and stick.<p>The more sophisticated multicellular animals (let us say birds, reptiles, mammals) have to learn to model the behavior of other animals in their environment: to prey on them, to avoid being prey.  A pond is here.  Other animals will also come to drink.  I could attack them and eat them.  And with the macaques, &quot;I must scare the baby and pain it a bit because I no longer want to breastfeed it.&quot;<p>Somewhere along the line, modeling other animals (in-species or out-species) hits some sort of self-reflection and the recursion begins.  That, I think, is a crucial loop to create the kind of intelligence we seek.  Here I nod to Egan&#x27;s <i>Diaspora</i>.<p>Looping back to your original point about the training data, I don&#x27;t think that loop is <i>sufficient</i> for an AGI to do anything but think about itself, and that&#x27;s where something like Cyc would serve as a framework for it to enter into the knowledge that it isn&#x27;t merely <i>cogito ergo sum</i>ming in a void, but that it is part of a world with rules stable enough that it might reason, rather than &quot;merely&quot; statistically infer.  And as part of the world (or your simulated environment), it can engage in new loops, feedback between its actions and results.</div><br/><div id="41893712" class="c"><input type="checkbox" id="c-41893712" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893222">parent</a><span>|</span><a href="#41893698">next</a><span>|</span><label class="collapse" for="c-41893712">[-]</label><label class="expand" for="c-41893712">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A pond is here. Other animals will also come to drink. I could attack them and eat them.<p>Is that the dominant chain, or is the simpler “I’ve seen animals here before that I have eaten” or “I’ve seen animals I have eaten in a place that smelled&#x2F;looked&#x2F;sounded&#x2F;felt like this” sufficient to explain the behavior?</div><br/></div></div><div id="41893698" class="c"><input type="checkbox" id="c-41893698" checked=""/><div class="controls bullet"><span class="by">jamiek88</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893222">parent</a><span>|</span><a href="#41893712">prev</a><span>|</span><a href="#41891903">next</a><span>|</span><label class="collapse" for="c-41893698">[-]</label><label class="expand" for="c-41893698">[1 more]</label></div><br/><div class="children"><div class="content">I like your premise! And will check out Harlie!</div><br/></div></div></div></div></div></div><div id="41891903" class="c"><input type="checkbox" id="c-41891903" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891547">parent</a><span>|</span><a href="#41892641">prev</a><span>|</span><a href="#41892004">next</a><span>|</span><label class="collapse" for="c-41891903">[-]</label><label class="expand" for="c-41891903">[4 more]</label></div><br/><div class="children"><div class="content">I think the data is way more important for the success of LLMs than the architecture although I do think there&#x27;s something important in the GPT architecture in particular. See this talk for why: [1]<p>Warning, watch out for waving hands: The way I see it is that cognition involves forming an abstract representation of the world and then reasoning about that representation. It seems obvious that non-human animals do this without language. So it seems likely that humans do too and then language is layered on top as a turbo boost. However, it also seems plausible that you could build an abstract representation of the world through studying a vast amount of human language and that&#x27;ll be a good approximation of the real-world too and furthermore it seems possible that reasoning about that abstract representation can take place in the depths of the layers of a large transformer. So it&#x27;s not clear to me that we&#x27;re limited by the data we have or necessarily need a different type of data to build a general AI although that&#x27;ll likely help build a better world model. It&#x27;s also not clear that an LLM is incapable of the type of reasoning that animals apply to their abstract world representations.<p>[1] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;yBL7J0kgldU?si=38Jjw_dgxCxhiu7R" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;yBL7J0kgldU?si=38Jjw_dgxCxhiu7R</a></div><br/><div id="41893977" class="c"><input type="checkbox" id="c-41893977" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891903">parent</a><span>|</span><a href="#41893306">next</a><span>|</span><label class="collapse" for="c-41893977">[-]</label><label class="expand" for="c-41893977">[1 more]</label></div><br/><div class="children"><div class="content">I agree we are not limited with the data set size: all humans learn the language with the much smaller language training set (just look at kids and compare them to LLMs).<p>OTOH, humans (and animals) do get other data feeds (visual, context, touch&#x2F;pain, smell, internal balance &quot;sensors&quot;...) that we develop as we grow and tie that to learning about language.<p>Obviously, LLMs won&#x27;t replicate that since even adults struggle to describe these verbally.</div><br/></div></div><div id="41893306" class="c"><input type="checkbox" id="c-41893306" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891903">parent</a><span>|</span><a href="#41893977">prev</a><span>|</span><a href="#41892004">next</a><span>|</span><label class="collapse" for="c-41893306">[-]</label><label class="expand" for="c-41893306">[2 more]</label></div><br/><div class="children"><div class="content">&gt; However, it also seems plausible that you could build an abstract representation of the world through studying a vast amount of human language and that&#x27;ll be a good approximation of the real-world too and furthermore it seems possible that reasoning about that abstract representation can take place in the depths of the layers of a large transformer.<p>While I agree this is possible, I don&#x27;t see why you&#x27;d think it&#x27;s likely. I would instead say that I think it&#x27;s <i>unlikely</i>.<p>Human communication relies on many assumptions of a shared model of the world that are rarely if ever discussed explicitly, and without which certain concepts or at least phrases become ambiguous or hard to understand.</div><br/><div id="41893943" class="c"><input type="checkbox" id="c-41893943" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41893306">parent</a><span>|</span><a href="#41892004">next</a><span>|</span><label class="collapse" for="c-41893943">[-]</label><label class="expand" for="c-41893943">[1 more]</label></div><br/><div class="children"><div class="content">GP argument seems to be about &quot;thinking&quot; when restricted to knowledge through language, and &quot;possible&quot; is not the same as &quot;likely&quot; or &quot;unlikely&quot; — you are not really disagreeing, since either means &quot;possible&quot;.</div><br/></div></div></div></div></div></div><div id="41892004" class="c"><input type="checkbox" id="c-41892004" checked=""/><div class="controls bullet"><span class="by">BurningFrog</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891547">parent</a><span>|</span><a href="#41891903">prev</a><span>|</span><a href="#41892690">next</a><span>|</span><label class="collapse" for="c-41892004">[-]</label><label class="expand" for="c-41892004">[1 more]</label></div><br/><div class="children"><div class="content">Videos are a rich set of non verbal data that could be used to train AIs.<p>Feed it all the video ever recorded, hook it up to web cams, telescopes, etc. This says a lot about how the universe works, without using a single word.</div><br/></div></div><div id="41892690" class="c"><input type="checkbox" id="c-41892690" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891547">parent</a><span>|</span><a href="#41892004">prev</a><span>|</span><a href="#41891338">next</a><span>|</span><label class="collapse" for="c-41892690">[-]</label><label class="expand" for="c-41892690">[1 more]</label></div><br/><div class="children"><div class="content">I always start with God’s design thinking it is best. That’s our diverse, mixed-signal, brain architecture followed by a good upbringing. That means we need to train brain-like architectures in the same way we train children. So, we’ll need whatever data they needed. Multiple streams for different upbringings, too.<p>The data itself will be most senses collecting raw data about the world most of the day for 18 years. It might require a camera on the kid’s head which I don’t like. I think people letting a team record their life is more likely. Split the project up among many families running in parallel, 1-4 per grade&#x2F;year. It would probably cost a few million a year.<p>(Note: Parent changes might require an integration step during AI training or showing different ones in the early years.)<p>The training system would rapidly scan this information in. It might not be faster than human brains. If it is, we can create them quickly. That’s the passive learning part, though.<p>Human training involves asking lots of questions based on internal data, random exploration (esp play) with reinforcement, introspection&#x2F;meditation, and so on. Self-driven, generative activities whose outputs become inputs into the brain system.  This training regiment will probably need periodic breaks from passive learning to ask questions or play which requires human supervision.<p>Enough of this will probably produce… disobedient, unpredictable children. ;) Eventually, we’ll learn how to do AI parenting where the offspring are well-behaved, effective servants. Those will be fine-tuned for practical applications. Later, many more will come online which are trained by different streams of life experience, schooling methods, etc.<p>That was my theory. I still don’t like recording people’s lives to train AI’s. I just thought it was the only way to build brain-like AI’s and likely to happen (see Twitch).<p>My LLM concept was to do the same thing with K-12 education resources, stories, kids games, etc. Parents already could tell us exactly what to use to gradually build them up since they did that for their kids year by year. Then, several career tracts layering different college books and skill areas. I think it would be cheaper than GPT-4 with good performance.</div><br/></div></div></div></div><div id="41891338" class="c"><input type="checkbox" id="c-41891338" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41891547">prev</a><span>|</span><a href="#41891540">next</a><span>|</span><label class="collapse" for="c-41891338">[-]</label><label class="expand" for="c-41891338">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t need to, but evolved intelligence is the only intelligence we know of.<p>Similar reason we look for markers of Earth-based life on alien planets: it&#x27;s the only example we&#x27;ve got of it existing.</div><br/></div></div><div id="41891540" class="c"><input type="checkbox" id="c-41891540" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41891338">prev</a><span>|</span><a href="#41892032">next</a><span>|</span><label class="collapse" for="c-41891540">[-]</label><label class="expand" for="c-41891540">[1 more]</label></div><br/><div class="children"><div class="content">Ok, but at least it suggests that this other thing might be more efficient in some ways.</div><br/></div></div><div id="41892032" class="c"><input type="checkbox" id="c-41892032" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41891540">prev</a><span>|</span><a href="#41891277">next</a><span>|</span><label class="collapse" for="c-41892032">[-]</label><label class="expand" for="c-41892032">[1 more]</label></div><br/><div class="children"><div class="content">Title doesn&#x27;t mean bullet trains can&#x27;t fly, but do imply what call flights could be more than moving fast, and effects of wings might be worth discussing.</div><br/></div></div><div id="41891277" class="c"><input type="checkbox" id="c-41891277" checked=""/><div class="controls bullet"><span class="by">weard_beard</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41892032">prev</a><span>|</span><a href="#41891924">next</a><span>|</span><label class="collapse" for="c-41891277">[-]</label><label class="expand" for="c-41891277">[4 more]</label></div><br/><div class="children"><div class="content">To a point. If you drill down this far into the fundamentals of cognition you begin to define it. Otherwise you may as well call a cantaloupe sentient</div><br/><div id="41891297" class="c"><input type="checkbox" id="c-41891297" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891277">parent</a><span>|</span><a href="#41891924">next</a><span>|</span><label class="collapse" for="c-41891297">[-]</label><label class="expand" for="c-41891297">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think anyone defines AI as &quot;doing the thing that biological brains do&quot; though, we define it in terms of capabilities of the system.</div><br/><div id="41892416" class="c"><input type="checkbox" id="c-41892416" checked=""/><div class="controls bullet"><span class="by">weard_beard</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891297">parent</a><span>|</span><a href="#41891924">next</a><span>|</span><label class="collapse" for="c-41892416">[-]</label><label class="expand" for="c-41892416">[2 more]</label></div><br/><div class="children"><div class="content">I think if you gave it the same biological inputs as a biological brain you would quickly see the lack of capabilities in any man made system.</div><br/><div id="41893199" class="c"><input type="checkbox" id="c-41893199" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892416">parent</a><span>|</span><a href="#41891924">next</a><span>|</span><label class="collapse" for="c-41893199">[-]</label><label class="expand" for="c-41893199">[1 more]</label></div><br/><div class="children"><div class="content">Okay, but does that help us reach any meaningful conclusions?  For example, okay some AI system doesn&#x27;t have the capabilities of an auditory cortex or somatosensory cortex.  Is there a reason for me to think it needs that?</div><br/></div></div></div></div></div></div></div></div><div id="41891924" class="c"><input type="checkbox" id="c-41891924" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891228">parent</a><span>|</span><a href="#41891277">prev</a><span>|</span><a href="#41893960">next</a><span>|</span><label class="collapse" for="c-41891924">[-]</label><label class="expand" for="c-41891924">[1 more]</label></div><br/><div class="children"><div class="content">in the high entropy world we have, we are forced to assume that the first thing that arises as a stable pattern is inevitably the most likely, and the most likely to work. there is no other pragmatic conclusion to draw.<p>for more, see &quot;Assembly Theory&quot;</div><br/></div></div></div></div><div id="41893960" class="c"><input type="checkbox" id="c-41893960" checked=""/><div class="controls bullet"><span class="by">reverius42</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891228">prev</a><span>|</span><a href="#41893748">next</a><span>|</span><label class="collapse" for="c-41893960">[-]</label><label class="expand" for="c-41893960">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly though for AI, this doesn’t necessarily mean we need a different model architecture. A single large multimodal transformer might be capable of a lot that an LLM is not (besides the multimodality).</div><br/></div></div><div id="41893748" class="c"><input type="checkbox" id="c-41893748" checked=""/><div class="controls bullet"><span class="by">afiodorov</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893960">prev</a><span>|</span><a href="#41893400">next</a><span>|</span><label class="collapse" for="c-41893748">[-]</label><label class="expand" for="c-41893748">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs<p>I am not convinced it follows. Sure LLMs don’t seem complete however there’s a lot of unspoken inference going on in LLMs that don’t map into a language directly already - the inner layers of the deep neural net that operates on abstract neurons.</div><br/></div></div><div id="41893400" class="c"><input type="checkbox" id="c-41893400" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893748">prev</a><span>|</span><a href="#41893534">next</a><span>|</span><label class="collapse" for="c-41893400">[-]</label><label class="expand" for="c-41893400">[1 more]</label></div><br/><div class="children"><div class="content">You seem to be conflating &quot;different hardware&quot; with proof that &quot;language hardware&quot; uses &quot;software&quot; equivalent to LLMs.<p>LLMs basically become practical when you simply scale compute up, and maybe both regions are &quot;general compute&quot;, but language ends up on the &quot;GPU&quot; out of pure necessity.<p>So to me, these are entirely distinct questions: is the language region able to do general cognitive operations? What happens when you need to spell out &quot;ubiquitous&quot; or declense a foreign word in a language with declension (which you don&#x27;t have memory patterns for)?<p>I agree it seems obvious that for better efficiency (size of training data, parameter count, compute ability), human brains use different approach than LLMs today (in a sibling comment, I bring up an example of my kids at 2yo having a better grasp of language rules than ChatGPT with 100x more training data).<p>But let&#x27;s dive deeper in understanding what each of these regions <i>can</i> do before we decide to compare to or apply stuff from AI&#x2F;CS.</div><br/></div></div><div id="41893534" class="c"><input type="checkbox" id="c-41893534" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893400">prev</a><span>|</span><a href="#41891639">next</a><span>|</span><label class="collapse" for="c-41893534">[-]</label><label class="expand" for="c-41893534">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What this tells us for AI is that we need something else besides LLMs.<p>No this is not true. For two reasons.<p>1. We call these things LLMs and we train it with language but we can also train it with images.<p>2. We also know LLMs develop a sort of understanding that goes beyond language EVEN when the medium used for training is exclusively language.<p>The naming of LLMs is throwing you off. You can call it a Large Language Model but this does not mean that everything about LLMs are exclusively tied only to language.<p>Additionally we don&#x27;t even know if the LLM is even remotely similar to the way human brains process language.<p>No such conclusion can be drawn from this experiment.</div><br/></div></div><div id="41891639" class="c"><input type="checkbox" id="c-41891639" checked=""/><div class="controls bullet"><span class="by">NeuroCoder</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893534">prev</a><span>|</span><a href="#41893732">next</a><span>|</span><label class="collapse" for="c-41891639">[-]</label><label class="expand" for="c-41891639">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not convinced the result is as important here as the methods. Separating language from complex cognition when evaluating individuals is difficult. But many of the people I&#x27;ve met in neuroscience that study language and cognitive processes do not hold the opinion that one is absolutely reliant on the other in all cases. It may have been a strong argument a while ago, but everytime I&#x27;ve seen a presentation on this relationship it&#x27;s been to emphasize the influence culture and language inevitably have on how we think about things. I&#x27;m sure some people believe that one cannot have complex thoughts without language, but most people in speech neuro I&#x27;ve met in language processing research find the idea ridiculous enough they wouldn&#x27;t bother spending a few years on that kind of project just to disapprove a theory.<p>On the other hand, further understanding how to engage complex cognitive processes in nonverbal individuals is extremely useful and difficult to accomplish.</div><br/></div></div><div id="41893732" class="c"><input type="checkbox" id="c-41893732" checked=""/><div class="controls bullet"><span class="by">ddingus</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891639">prev</a><span>|</span><a href="#41892518">next</a><span>|</span><label class="collapse" for="c-41893732">[-]</label><label class="expand" for="c-41893732">[1 more]</label></div><br/><div class="children"><div class="content">We should look to the animals.<p>Higher order faculties aside, animals seem like us, just simpler.<p>The higher functioning ones appear to have this missing thing too.  We can see it in action. Perhaps all of them do and it is just harder for us when the animal thinks very differently or maybe does not think as much, feeling more, for example.<p>----<p>Now, about that thing... and the controversy:<p>Given an organism, or machine for this discussion, is of sufficiently robust design and complexity that it can precisely differentiate itself from everything else, it is a being.<p>This thing we are missing is an emergent property, or artifact that can or maybe always does present when a state of being also presents.<p>We have not created a machine of this degree yet.<p>Mother nature has.<p>The reason for emergence is a being can differentiate sensory input as being from within, such as pain, or touch, and from without, such as light or motion.<p>Another way to express this is closed loop vs open loop.<p>A being is a closed loop system.  It can experience cause and effect.  It can be the cause.  It can be the effect.<p>A lot comes from this closed loop.<p>There can be the concept of the self and it has real meaning due to the being knowing what is of itself or something, everything else.<p>This may be what forms consciousness.  Consciousness may require a closed loop, and organism of sufficient complexity to be able to perceive itself.<p>That is the gist of it.<p>These systems we make are fantastic pieces.  They can pattern match and identify relationships between the data given in amazing ways.<p>But they are open loop.  They are not beings.  They cannot determine what is part of them, what they even are,or anything really.<p>I am both consistently amazed and dismayed at what we can get LLM systems to do.<p>They are tantalizingly close!<p>We found a piece of how all this works and we are exploiting the cral out of it.  Ok fine.  Humans are really good at that.<p>But it will all taper off.  There are real limits because we will eventually find the end goal will be to map out the whole problem space.<p>Who has tried computing that?  It is basically all possible human thought.  Not going to happen.<p>More is needed.<p>And that &quot;more&quot; can arrive at thoughts without having first seen a few bazillion to choose from.</div><br/></div></div><div id="41892518" class="c"><input type="checkbox" id="c-41892518" checked=""/><div class="controls bullet"><span class="by">sidewndr46</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893732">prev</a><span>|</span><a href="#41891063">next</a><span>|</span><label class="collapse" for="c-41892518">[-]</label><label class="expand" for="c-41892518">[1 more]</label></div><br/><div class="children"><div class="content">I believe what this tells is that thought requires blood flow in the brain of mammals.<p>Stepping back a level, it may only actually tell us that MRIs measure blood flow.</div><br/></div></div><div id="41891063" class="c"><input type="checkbox" id="c-41891063" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41892518">prev</a><span>|</span><a href="#41890470">next</a><span>|</span><label class="collapse" for="c-41891063">[-]</label><label class="expand" for="c-41891063">[5 more]</label></div><br/><div class="children"><div class="content">Is it important? To who? Anyone with half a brain is aware that language isn&#x27;t the only way to think. I can think my way through all kinds of things in 3-d space without a single word uttered in any internal monologue and I&#x27;m not remotely unique - this kind of thing is put in all kinds of math and iq&#x27;ish like tests one takes as a child.</div><br/><div id="41891439" class="c"><input type="checkbox" id="c-41891439" checked=""/><div class="controls bullet"><span class="by">voxl</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891063">parent</a><span>|</span><a href="#41890470">next</a><span>|</span><label class="collapse" for="c-41891439">[-]</label><label class="expand" for="c-41891439">[4 more]</label></div><br/><div class="children"><div class="content">Before you say things this patiently dumb you should probably wonder what question the researchers are actually interested in and why your average experience isn&#x27;t sufficient proof.</div><br/><div id="41892583" class="c"><input type="checkbox" id="c-41892583" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891439">parent</a><span>|</span><a href="#41891491">next</a><span>|</span><label class="collapse" for="c-41892583">[-]</label><label class="expand" for="c-41892583">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s &quot;patently&quot; and maybe understand the definition of &quot;average&quot; before using it.<p>Once you&#x27;ve figured out how to use language, explain why this is important and to who. Then maybe what the upshot will be. The fact that someone has proven something to be true doesn&#x27;t make it important.<p>The comment I replied to made it sound like it&#x27;s important to the field of AI. It is not. Almost zero serious researchers think LLMs all by themselves are &quot;enough&quot;. People are working on all manner of models and systems incorporating all kinds of things &quot;not LLM&quot;. Practically no one who actually works in AI reads this paper and changes anything, because it only proves something they already believed to be true and act accordingly.</div><br/></div></div><div id="41891491" class="c"><input type="checkbox" id="c-41891491" checked=""/><div class="controls bullet"><span class="by">gotoeleven</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891439">parent</a><span>|</span><a href="#41892583">prev</a><span>|</span><a href="#41891908">next</a><span>|</span><label class="collapse" for="c-41891491">[-]</label><label class="expand" for="c-41891491">[1 more]</label></div><br/><div class="children"><div class="content">I am 3-d rotating this comment in my head right now</div><br/></div></div><div id="41891908" class="c"><input type="checkbox" id="c-41891908" checked=""/><div class="controls bullet"><span class="by">orhmeh09</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891439">parent</a><span>|</span><a href="#41891491">prev</a><span>|</span><a href="#41890470">next</a><span>|</span><label class="collapse" for="c-41891908">[-]</label><label class="expand" for="c-41891908">[1 more]</label></div><br/><div class="children"><div class="content">*patently</div><br/></div></div></div></div></div></div><div id="41890470" class="c"><input type="checkbox" id="c-41890470" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891063">prev</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41890470">[-]</label><label class="expand" for="c-41890470">[13 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs.<p>Basically we need Multimodal LLM&#x27;s 
(terrible naming as it&#x27;s not an LLM then but still).</div><br/><div id="41890645" class="c"><input type="checkbox" id="c-41890645" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890470">parent</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41890645">[-]</label><label class="expand" for="c-41890645">[12 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know what we need. Nor does anybody else, yet. But we know what it has to <i>do</i>. Basically what a small mammal or a corvid does.<p>There&#x27;s been progress. Look at this 2020 work on neural net controlled drone acrobatics.[1] That&#x27;s going in the right direction.<p>[1] <a href="https:&#x2F;&#x2F;rpg.ifi.uzh.ch&#x2F;docs&#x2F;RSS20_Kaufmann.pdf" rel="nofollow">https:&#x2F;&#x2F;rpg.ifi.uzh.ch&#x2F;docs&#x2F;RSS20_Kaufmann.pdf</a></div><br/><div id="41891715" class="c"><input type="checkbox" id="c-41891715" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890645">parent</a><span>|</span><a href="#41890769">next</a><span>|</span><label class="collapse" for="c-41891715">[-]</label><label class="expand" for="c-41891715">[2 more]</label></div><br/><div class="children"><div class="content">I think you may underestimate what these models do.<p>Proper multimodal models natively consider whatever input you give them, store the useful information in an abstracted form (i.e not just text), building it&#x27;s world model, and then output in whatever format you want it to.
It&#x27;s no different to a mammals, just the inputs are perhaps different. Instead of relying on senses, they rely on text, video, images and sound.<p>In theory you could connect it to a robot and it could gather real world data much like a human, but would potentially be limited to the number of sensors&#x2F;nerves it has. (on the plus side it has access to all recorded data and much faster read&#x2F;write than a human).</div><br/></div></div><div id="41890769" class="c"><input type="checkbox" id="c-41890769" checked=""/><div class="controls bullet"><span class="by">fuzzfactor</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890645">parent</a><span>|</span><a href="#41891715">prev</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41890769">[-]</label><label class="expand" for="c-41890769">[9 more]</label></div><br/><div class="children"><div class="content">You could say language is just the &quot;communication module&quot; but there has got to be another whole underlying interface where non-verbal thoughts are modulated&#x2F;demodulated to conform to the language expected to be used when communication may or may not be on the agenda.</div><br/><div id="41891786" class="c"><input type="checkbox" id="c-41891786" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890769">parent</a><span>|</span><a href="#41891635">next</a><span>|</span><label class="collapse" for="c-41891786">[-]</label><label class="expand" for="c-41891786">[1 more]</label></div><br/><div class="children"><div class="content">As far as I understand it, it&#x27;s just output and speaking is just enclosed in tags, that the body can act on, much like inline code output from an LLM.<p>e.g. the neural electrochemical output has a specific sequence that triggers the production of a certain hormone in your pituitary gland for e.g. and the hormone travels to the relevant body function activating&#x2F;stopping it.</div><br/></div></div><div id="41891635" class="c"><input type="checkbox" id="c-41891635" checked=""/><div class="controls bullet"><span class="by">NoMoreNicksLeft</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890769">parent</a><span>|</span><a href="#41891786">prev</a><span>|</span><a href="#41891260">next</a><span>|</span><label class="collapse" for="c-41891635">[-]</label><label class="expand" for="c-41891635">[2 more]</label></div><br/><div class="children"><div class="content">In these discussions, I always knee-jerk into thinking &quot;why don&#x27;t they just look inward on their own minds&quot;. But the truth is, most people don&#x27;t have much to gaze upon internally... they&#x27;re the meat equivalent of an LLM that can sort of sound like it makes sense. These are the people always bragging about how they have an &quot;internal monologue&quot; and that those that don&#x27;t are aliens or psychotics or something.<p>The only reason humans have that &quot;communication model&quot; is because that&#x27;s how you model other humans you speak to. It&#x27;s a faculty for rehearsing what you&#x27;re going to say to other people, and how they&#x27;ll respond to it. If you have any profound thoughts at all, you find that your spoken language is deficient to even transcribe your thoughts, some &quot;mental tokens&quot; have no short phrases that even describe them.<p>The only real thoughts you have are non-verbal. You can see this sometimes in stupid schoolchildren who have learned all the correct words to regurgitate, but those never really clicked for them. The mildly clever teachers always assume that if they thoroughly practice the terminology, it will eventually be linked with the concepts themselves and they&#x27;ll have fully learned it. What&#x27;s really happening is that there&#x27;s not enough mental machinery underneath for those words to ever be anything to link up with.</div><br/><div id="41891718" class="c"><input type="checkbox" id="c-41891718" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891635">parent</a><span>|</span><a href="#41891260">next</a><span>|</span><label class="collapse" for="c-41891718">[-]</label><label class="expand" for="c-41891718">[1 more]</label></div><br/><div class="children"><div class="content">This view represents one possible subjective experience of the world. But there are many different possible ways a human brain can learn to experience the world.<p>I am a sensoral thinker, I often think and internally express myself in purely images or sounds. There are, however, some kinds of thoughts I&#x27;ve learned I can only fully engage with if I speak to myself out loud or at least inside of my head.<p>The most appropriate mode of thought depends upon the task at hand. People don&#x27;t typically brag about having internal monologues. They&#x27;re just sharing their own subjective internal experience, which is no less valid than a chiefly nonverbal one.</div><br/></div></div></div></div><div id="41891260" class="c"><input type="checkbox" id="c-41891260" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890769">parent</a><span>|</span><a href="#41891635">prev</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41891260">[-]</label><label class="expand" for="c-41891260">[5 more]</label></div><br/><div class="children"><div class="content">Well said! This is a great restatement of the core setup of the Chomskian “Generative Grammar” school, and I think it’s an undeniably productive one. I haven’t read this researchers full paper, but I would be sad (tho not shocked…) if it didn’t cite Chomsky up front. Beyond your specific point re:interfaces—which I recommend the OG <i>Syntactic Structures</i> for more commentary on—he’s been saying what she’s saying here for about half a century. He’s too humble&#x2F;empirical to ever say it without qualifiers, but IMO the truth is clear when viewed holistically: language is a byproduct of hierarchical thought, not the progenitor.<p>This (awesome!) researcher would likely disagree with what I’ve just said based on this early reference:<p><pre><code>  In the early 2000s I really was drawn to the hypothesis that maybe humans have some special machinery that is especially well suited for computing hierarchical structures.
</code></pre>
…with the implication that they’re not, actually. But I think that’s an absurd overcorrection for anthropological bias — humans are uniquely capable of a whole host of tasks, and the gradation is clearly a qualitative one. No ape has ever asked a question, just like no plant has ever conceptualized a goal, and no rock has ever computed indirect reactions to stimuli.</div><br/><div id="41891737" class="c"><input type="checkbox" id="c-41891737" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891260">parent</a><span>|</span><a href="#41891350">next</a><span>|</span><label class="collapse" for="c-41891737">[-]</label><label class="expand" for="c-41891737">[1 more]</label></div><br/><div class="children"><div class="content">I think one big problem is that people understand LLMs as text-generation models, when really they&#x27;re just sequence prediction models, which is a highly versatile, but data-hungry, architecture for encoding relationships and knowledge. LLMs are tuned for text input and output, but they just work on numbers and the general transformer architecture is highly generalizable.</div><br/></div></div><div id="41891350" class="c"><input type="checkbox" id="c-41891350" checked=""/><div class="controls bullet"><span class="by">slibhb</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891260">parent</a><span>|</span><a href="#41891737">prev</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41891350">[-]</label><label class="expand" for="c-41891350">[3 more]</label></div><br/><div class="children"><div class="content">Chomsky is shockingly <i>un</i>humble. I admire him but he&#x27;s a jerk who treats people who disagree with him with contempt. It&#x27;s fun to read him doing this but it&#x27;s uncollegiate (to say the least).<p>Also, calling &quot;generative grammar&quot; productive seems wrong to me. It&#x27;s been around for half a century -- what tools has it produced? At some point theory needs to come into contact with empirical reality. As far as I know, generative grammar has just never gotten to this point.</div><br/><div id="41891409" class="c"><input type="checkbox" id="c-41891409" checked=""/><div class="controls bullet"><span class="by">keybored</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891350">parent</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41891409">[-]</label><label class="expand" for="c-41891409">[2 more]</label></div><br/><div class="children"><div class="content">Who has he mistreated?</div><br/><div id="41892788" class="c"><input type="checkbox" id="c-41892788" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891409">parent</a><span>|</span><a href="#41890104">next</a><span>|</span><label class="collapse" for="c-41892788">[-]</label><label class="expand" for="c-41892788">[1 more]</label></div><br/><div class="children"><div class="content">Nobody, people are just crying because Chomsky calls them out, rationally, on their intellectual and&#x2F;or political bullshit, and this behavior is known as projection.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41890104" class="c"><input type="checkbox" id="c-41890104" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41890470">prev</a><span>|</span><a href="#41892738">next</a><span>|</span><label class="collapse" for="c-41890104">[-]</label><label class="expand" for="c-41890104">[10 more]</label></div><br/><div class="children"><div class="content">Brain size isn&#x27;t necessarily a very good correlate of intelligence. For example dolphins and elephants have bigger brains than humans, and sperm whales have much bigger brains (5x by volume). Neanderthals also had bigger brains than modern humans, but are not thought to have been more intelligent.<p>A crow has a small brain, but also has very small neurons, so ends up having 1.5B neurons, similar to a dog or some monkeys.</div><br/><div id="41891770" class="c"><input type="checkbox" id="c-41891770" checked=""/><div class="controls bullet"><span class="by">kridsdale1</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890104">parent</a><span>|</span><a href="#41893391">next</a><span>|</span><label class="collapse" for="c-41891770">[-]</label><label class="expand" for="c-41891770">[3 more]</label></div><br/><div class="children"><div class="content">Don’t assume whales are less intelligent than humans. They’re tuned for their environment. They won’t assemble machines with their flippers but let’s toss you naked in the pacific and see if you can communicate and collaborate with peers 200km away on complex hunting strategies.</div><br/><div id="41892573" class="c"><input type="checkbox" id="c-41892573" checked=""/><div class="controls bullet"><span class="by">batch12</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891770">parent</a><span>|</span><a href="#41893391">next</a><span>|</span><label class="collapse" for="c-41892573">[-]</label><label class="expand" for="c-41892573">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s toss a whale on land and see if it can communicate and collaborate with peers 10 ft away on anything. I don&#x27;t think being tuned to communicate underwater makes them more intelligent than humans.</div><br/><div id="41893553" class="c"><input type="checkbox" id="c-41893553" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892573">parent</a><span>|</span><a href="#41893391">next</a><span>|</span><label class="collapse" for="c-41893553">[-]</label><label class="expand" for="c-41893553">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think being tuned to communicate underwater makes them more intelligent than humans.<p>Your responding to a claim that was never made. The claim was don&#x27;t assume humans are smarter than whales. Nobody said whales are more intelligent than humans. He just said don&#x27;t assume.</div><br/></div></div></div></div></div></div><div id="41893391" class="c"><input type="checkbox" id="c-41893391" checked=""/><div class="controls bullet"><span class="by">yurimo</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890104">parent</a><span>|</span><a href="#41891770">prev</a><span>|</span><a href="#41892722">next</a><span>|</span><label class="collapse" for="c-41893391">[-]</label><label class="expand" for="c-41893391">[1 more]</label></div><br/><div class="children"><div class="content">Right, but what is also important to remember is while size is important what is also key here is the complexity of a neural circuits. Human brain has a lot more connections and is much more complex.</div><br/></div></div><div id="41892722" class="c"><input type="checkbox" id="c-41892722" checked=""/><div class="controls bullet"><span class="by">FL33TW00D</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890104">parent</a><span>|</span><a href="#41893391">prev</a><span>|</span><a href="#41890265">next</a><span>|</span><label class="collapse" for="c-41892722">[-]</label><label class="expand" for="c-41892722">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably more relevant to compare intraspecies rather than interspecies.<p>And it turns out that human brain volume and intelligence are moderately-highly correlated [1][2]!<p>[1]: <a href="https:&#x2F;&#x2F;pmc.ncbi.nlm.nih.gov&#x2F;articles&#x2F;PMC7440690&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pmc.ncbi.nlm.nih.gov&#x2F;articles&#x2F;PMC7440690&#x2F;</a>
[2]: <a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S0160289604001357?via%3Dihub" rel="nofollow">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S01602...</a></div><br/></div></div><div id="41890265" class="c"><input type="checkbox" id="c-41890265" checked=""/><div class="controls bullet"><span class="by">card_zero</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890104">parent</a><span>|</span><a href="#41892722">prev</a><span>|</span><a href="#41892738">next</a><span>|</span><label class="collapse" for="c-41890265">[-]</label><label class="expand" for="c-41890265">[4 more]</label></div><br/><div class="children"><div class="content">Not sure neuron number correlates to smarts, either.<p><a href="https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;gut-second-brain&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;gut-second-brain&#x2F;</a><p>There are 100 million in my gut, but it doesn&#x27;t solve any problems that aren&#x27;t about poop, as far as I know.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_animals_by_number_of_neurons" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_animals_by_number_of_n...</a><p>If the suspiciously round number is accurate, this puts the human gut somewhere between a golden hamster and ansell&#x27;s mole-rat, and about level with a short-palated fruit bat.</div><br/><div id="41890535" class="c"><input type="checkbox" id="c-41890535" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890265">parent</a><span>|</span><a href="#41890966">next</a><span>|</span><label class="collapse" for="c-41890535">[-]</label><label class="expand" for="c-41890535">[2 more]</label></div><br/><div class="children"><div class="content">Agreed. It&#x27;s architecture that matters, although for a given brain architecture (e.g. species) there might be benefits to scale. mega-brain vs pea-brain.<p>I was just pointing out that a crow&#x27;s brain is built on a more advanced process node than our own. Smaller transistors.</div><br/><div id="41890612" class="c"><input type="checkbox" id="c-41890612" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890535">parent</a><span>|</span><a href="#41890966">next</a><span>|</span><label class="collapse" for="c-41890612">[-]</label><label class="expand" for="c-41890612">[1 more]</label></div><br/><div class="children"><div class="content">That makes sense. Birds are very weight-limited, so there&#x27;s evolutionary pressure to keep the mass of the control system down.</div><br/></div></div></div></div><div id="41890966" class="c"><input type="checkbox" id="c-41890966" checked=""/><div class="controls bullet"><span class="by">readthenotes1</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41890265">parent</a><span>|</span><a href="#41890535">prev</a><span>|</span><a href="#41892738">next</a><span>|</span><label class="collapse" for="c-41890966">[-]</label><label class="expand" for="c-41890966">[1 more]</label></div><br/><div class="children"><div class="content">I suspect there is more going on with your gut neurons then you would expect. If nothing else, the vagus nerve I had to direct communication link.<p>I like to think that it is my gut brain that is telling me that it&#x27;s okay to have that ice cream...</div><br/></div></div></div></div></div></div><div id="41892738" class="c"><input type="checkbox" id="c-41892738" checked=""/><div class="controls bullet"><span class="by">yarg</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41890104">prev</a><span>|</span><a href="#41891749">next</a><span>|</span><label class="collapse" for="c-41892738">[-]</label><label class="expand" for="c-41892738">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs.<p>Perhaps, but the relative success of trained LLMs acting with apparent generalised understanding may indicate that it is simply the interface that is really an LLM post training;<p>That the deeper into the network you go (the further from the linguistic context), the less things become about words and linguist structure specifically and the more it becomes about things and relations in general.<p>(This also means that multiple interfaces can be integrated, sometimes making translation possible, e.g.: image &lt;=&gt; tree&lt;string&gt;)</div><br/></div></div><div id="41891749" class="c"><input type="checkbox" id="c-41891749" checked=""/><div class="controls bullet"><span class="by">red75prime</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41892738">prev</a><span>|</span><a href="#41892576">next</a><span>|</span><label class="collapse" for="c-41891749">[-]</label><label class="expand" for="c-41891749">[3 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs<p>You mean besides a few layers of LLMs near input and output that deal with tokens? We have the rest of the layers.</div><br/><div id="41891764" class="c"><input type="checkbox" id="c-41891764" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891749">parent</a><span>|</span><a href="#41892576">next</a><span>|</span><label class="collapse" for="c-41891764">[-]</label><label class="expand" for="c-41891764">[2 more]</label></div><br/><div class="children"><div class="content">Those &quot;few layers&quot; sum up all of linguistics.<p>1. Syntax<p>2. Semantics<p>3. Pragmatics<p>4. Semiotics<p>These are the layers you need to solve.<p>Saussure already pointed out these issues over a century ago, and Linguists turned ML Researchers like Stuart Russell and Paul Smolensky tried in vain to resolve this.<p>It basically took 60 years just to crack syntax at scale, and the other layers are still fairly far away.<p>Furthermore, Syntax is not a solved problem yet in most languages.<p>Try communicating with GPT-4o in colloquial Bhojpuri, Koshur, or Dogri, let alone much less represented languages and dialects.</div><br/><div id="41892949" class="c"><input type="checkbox" id="c-41892949" checked=""/><div class="controls bullet"><span class="by">sojournerc</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891764">parent</a><span>|</span><a href="#41892576">next</a><span>|</span><label class="collapse" for="c-41892949">[-]</label><label class="expand" for="c-41892949">[1 more]</label></div><br/><div class="children"><div class="content">Linguistics is not living! Language does not capture reality! So no matter how much you solve you&#x27;re no closer to AGI</div><br/></div></div></div></div></div></div><div id="41892576" class="c"><input type="checkbox" id="c-41892576" checked=""/><div class="controls bullet"><span class="by">agentcoops</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891749">prev</a><span>|</span><a href="#41891262">next</a><span>|</span><label class="collapse" for="c-41892576">[-]</label><label class="expand" for="c-41892576">[1 more]</label></div><br/><div class="children"><div class="content">For those interested in the history, this is in fact the Neural Network research path that predated LLMs. Not just in the sense that Hinton et al and the core of the &quot;Parallel Distributed Processing&quot;&#x2F;Connectionist school were always opposed to Chomsky&#x27;s identification of brain-thought-language, but that the original early 2000s NSF grant awarded to Werbos, Ng, LeCun et al was for &quot;Deep Learning in the Mammalian Visual Cortex.&quot; In their research program, mouse intelligence was posited as the first major challenge.</div><br/></div></div><div id="41891262" class="c"><input type="checkbox" id="c-41891262" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41892576">prev</a><span>|</span><a href="#41893555">next</a><span>|</span><label class="collapse" for="c-41891262">[-]</label><label class="expand" for="c-41891262">[9 more]</label></div><br/><div class="children"><div class="content">LLM as a term is becoming quite broad; a multi-modal transformer-based model with function calling &#x2F; ReAct finetuning still gets called an LLM, but this scaffolding might be all that’s needed.<p>I’d be extremely surprised if AI recapitulates the same developmental path as humans did; evolution vs. next-token prediction on an existing corpus are completely different objective functions and loss landscapes.</div><br/><div id="41891539" class="c"><input type="checkbox" id="c-41891539" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891262">parent</a><span>|</span><a href="#41893555">next</a><span>|</span><label class="collapse" for="c-41891539">[-]</label><label class="expand" for="c-41891539">[8 more]</label></div><br/><div class="children"><div class="content">I asked both OpenAI and Claude the same difficult programming question.  Each gave a nearly identical response down to the variable names and example values.<p>I then looked it up and they had each copy&#x2F;pasted the same Stack overflow answer.<p>Furthermore, the answer was extremely wrong, the language I used was superficially similar to the source material, but the programming concepts were entirely different.<p>What this tells me is there is clearly no “reasoning” happening whatsoever with either model, despite marketing claiming as such.</div><br/><div id="41893601" class="c"><input type="checkbox" id="c-41893601" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891539">parent</a><span>|</span><a href="#41891817">next</a><span>|</span><label class="collapse" for="c-41893601">[-]</label><label class="expand" for="c-41893601">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What this tells me is there is clearly no “reasoning” happening whatsoever with either model, despite marketing claiming as such.<p>Not true. You yourself have failed at reasoning here.<p>The problem with your logic is that you failed to identify the instances where LLMs have succeeded with reasoning. So if LLMs both fail and succeed it just means that LLMs are capable of reasoning and capable of being utterly wrong.<p>It&#x27;s almost cliche at this point. Tons of people see the LLM fail and ignore the successes then they openly claim from a couple anecdotal examples that LLMs can&#x27;t reason period.<p>Like how is that even logical? You have contradictory evidence therefore the LLM must be capable of BOTH failing and succeeding in reason. That&#x27;s the most logical answer.</div><br/></div></div><div id="41891817" class="c"><input type="checkbox" id="c-41891817" checked=""/><div class="controls bullet"><span class="by">vundercind</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891539">parent</a><span>|</span><a href="#41893601">prev</a><span>|</span><a href="#41892309">next</a><span>|</span><label class="collapse" for="c-41891817">[-]</label><label class="expand" for="c-41891817">[1 more]</label></div><br/><div class="children"><div class="content">They don’t <i>wonder</i>. They’d happily produce entire novels of (garbage) text if trained on gibberish. They wouldn’t be confused. They wouldn’t hope to puzzle out the meaning. There is none, and they work just fine anyway. Same for real language. There’s no meaning, to them (there’s not really a “to” either).<p>The most interesting thing about LLMs is probably how much relational information turns out to be encoded in large bodies of our writing, in ways that fancy statistical methods can access. LLMs aren’t thinking, or even in the same ballpark as thinking.</div><br/></div></div><div id="41892309" class="c"><input type="checkbox" id="c-41892309" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891539">parent</a><span>|</span><a href="#41891817">prev</a><span>|</span><a href="#41891778">next</a><span>|</span><label class="collapse" for="c-41892309">[-]</label><label class="expand" for="c-41892309">[3 more]</label></div><br/><div class="children"><div class="content">Humans copy&#x2F;paste from SO too. Does that prove humans can’t reason?</div><br/><div id="41893032" class="c"><input type="checkbox" id="c-41893032" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892309">parent</a><span>|</span><a href="#41892339">next</a><span>|</span><label class="collapse" for="c-41893032">[-]</label><label class="expand" for="c-41893032">[1 more]</label></div><br/><div class="children"><div class="content">If you don’t read or understand the code, then no, you aren’t reasoning.<p>The condition of “some people are bad at thing” does not equal “computer better at thing than people”, but I see this argument all the time in LLM&#x2F;AI discourse.</div><br/></div></div><div id="41892339" class="c"><input type="checkbox" id="c-41892339" checked=""/><div class="controls bullet"><span class="by">fuzzfactor</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892309">parent</a><span>|</span><a href="#41893032">prev</a><span>|</span><a href="#41891778">next</a><span>|</span><label class="collapse" for="c-41892339">[-]</label><label class="expand" for="c-41892339">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Does that prove humans can’t reason?<p>It could be said not as well as the ones that don&#x27;t need SO.</div><br/></div></div></div></div><div id="41891778" class="c"><input type="checkbox" id="c-41891778" checked=""/><div class="controls bullet"><span class="by">alphan0n</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891539">parent</a><span>|</span><a href="#41892309">prev</a><span>|</span><a href="#41893555">next</a><span>|</span><label class="collapse" for="c-41891778">[-]</label><label class="expand" for="c-41891778">[2 more]</label></div><br/><div class="children"><div class="content">What was the question?</div><br/><div id="41892237" class="c"><input type="checkbox" id="c-41892237" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41891778">parent</a><span>|</span><a href="#41893555">next</a><span>|</span><label class="collapse" for="c-41892237">[-]</label><label class="expand" for="c-41892237">[1 more]</label></div><br/><div class="children"><div class="content">Had to do with connection pooling.</div><br/></div></div></div></div></div></div></div></div><div id="41893555" class="c"><input type="checkbox" id="c-41893555" checked=""/><div class="controls bullet"><span class="by">agumonkey</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891262">prev</a><span>|</span><a href="#41891507">next</a><span>|</span><label class="collapse" for="c-41893555">[-]</label><label class="expand" for="c-41893555">[1 more]</label></div><br/><div class="children"><div class="content">At times I had impaired brain function (lots of soft neurological issues, finger control, memory loss, balance issues) but surprisingly the core area responsible for mathematical reasoning was spared .. that was a strange sensation, almost schizophrenic.<p>And yeah it seems that core primitives of intelligence exist very low in our brains. And with people like Michael Levin, there may even be a root beside nervous systems.</div><br/></div></div><div id="41891507" class="c"><input type="checkbox" id="c-41891507" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41893555">prev</a><span>|</span><a href="#41892137">next</a><span>|</span><label class="collapse" for="c-41891507">[-]</label><label class="expand" for="c-41891507">[1 more]</label></div><br/><div class="children"><div class="content">My first thought as well - “AGI via LLM” implies that our grey matter is merely a substrate for executing language tasks: just swap out bio-neurons for a few H100s and viola, super intelligence.</div><br/></div></div><div id="41892137" class="c"><input type="checkbox" id="c-41892137" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#41890003">parent</a><span>|</span><a href="#41891507">prev</a><span>|</span><a href="#41891068">next</a><span>|</span><label class="collapse" for="c-41892137">[-]</label><label class="expand" for="c-41892137">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What this tells us for AI is that we need something else besides LLMs.<p>Humans not taking this approach doesn’t mean that AI cannot.</div><br/><div id="41892429" class="c"><input type="checkbox" id="c-41892429" checked=""/><div class="controls bullet"><span class="by">earslap</span><span>|</span><a href="#41890003">root</a><span>|</span><a href="#41892137">parent</a><span>|</span><a href="#41891068">next</a><span>|</span><label class="collapse" for="c-41892429">[-]</label><label class="expand" for="c-41892429">[1 more]</label></div><br/><div class="children"><div class="content">Not only that but also LLMs &quot;think&quot; in a latent representation that is several layers deep. Sure, the first and last layers make it look like it is doing token wrangling, but what is happening in the middle layers is mostly a mystery. First layer deals directly with the tokens because that is the data we are observing (a &quot;shadow&quot; of the world) and last layer also deals with tokens because we want to understand what the network is &quot;thinking&quot; so it is a human specific lossy decoder (we can and do remove that translator and plug the latent representations to other networks to train them in tandem). There is no reason to believe that the other layers are &quot;thinking in language&quot;.</div><br/></div></div></div></div></div></div><div id="41891068" class="c"><input type="checkbox" id="c-41891068" checked=""/><div class="controls bullet"><span class="by">fjfaase</span><span>|</span><a href="#41890003">prev</a><span>|</span><a href="#41891613">next</a><span>|</span><label class="collapse" for="c-41891068">[-]</label><label class="expand" for="c-41891068">[12 more]</label></div><br/><div class="children"><div class="content">As some who has a dis-harmonic intelligence profile, this has been obvious for a very long time. In the family of my mother there are several individuals struggling with language while excelling in the field of exact sciences. I very strongly suspect that my non-verbal (performal) IQ is much higher (around 130) than my verbal IQ (around 100). I have struggled my whole life to express my ideas with language. I consider myself an abstract visual thinker. I do not think in pictures, but in abstract structures. During my life, I have met several people, especially among software engineers, who seem to be similar to me. I also feel that people who are strong verbal thinkers have the greatest resistance against idea that language is not essential for higher cognitive processes.</div><br/><div id="41892035" class="c"><input type="checkbox" id="c-41892035" checked=""/><div class="controls bullet"><span class="by">tines</span><span>|</span><a href="#41891068">parent</a><span>|</span><a href="#41891193">next</a><span>|</span><label class="collapse" for="c-41892035">[-]</label><label class="expand" for="c-41892035">[2 more]</label></div><br/><div class="children"><div class="content">&gt; As some who has a dis-harmonic intelligence profile, this has been obvious for a very long time. In the family of my mother there are several individuals struggling with language while excelling in the field of exact sciences. I very strongly suspect that my non-verbal (performal) IQ is much higher (around 130) than my verbal IQ (around 100)<p>I used to rationalize to myself along similar lines for a long time, then I realized that I&#x27;m just not as smart as I thought I was.</div><br/><div id="41893313" class="c"><input type="checkbox" id="c-41893313" checked=""/><div class="controls bullet"><span class="by">NemoNobody</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41892035">parent</a><span>|</span><a href="#41891193">next</a><span>|</span><label class="collapse" for="c-41893313">[-]</label><label class="expand" for="c-41893313">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a brilliant genius according to IQ tests. Think me arrogant or conceited or whatever - that is literally the truth, fact - proven many times in the educational system (I was homeschooled and didn&#x27;t follow any sort of curriculum and was allowed to do whatever I wanted bc I kept testing higher than almost everyone) and just for kicks also - the last time I took an IQ test I was in my late 20s and a friend and I had a bet about who could score higher completely stoned off of our ass. We rolled enough blunts apiece that we could be continuously smoking marijuana as we took the IQ test, which followed several bongs finished between the two of us. I was so high that I couldn&#x27;t keep the numbers straight on one of the number pattern questions - it was ridiculous. I scored 124, my lowest &quot;serious&quot; attempt ever - all of this is 100% true. I need anyone to believe me - take this how you will but I have an opinion that is a bit different.<p>I&#x27;m brilliant - I&#x27;ve read volumes of encyclopedias,  my hobbies include comparative theology, etymology, quantum mechanics and predicting the future with high accuracy (I only mention stuff I&#x27;m certain of tho ;) but so much so it disturbs my friends and family.<p>The highest I scored was in the 160s as a teenager but I truly believe they were over compensating for my age - only as an adult have I learned most children are stupid and they maybe in fact didn&#x27;t over compensate. I am different than anyone else I&#x27;ve ever personally met - I fundamentally see the world different.<p>All of that is true but that&#x27;s a rather flawed way of assessing intelligence - fr. I&#x27;m being serious. The things we know can free us as much as they can trap us - knowledge alone doesn&#x27;t make a man successful, wealthy, happy or even healthy - I&#x27;m living evidence of this. That doesn&#x27;t cut it as a metric for prediction of much. There are other qualities that are far more valuable in the societal sense.<p>Every Boss I&#x27;ve ever worked for has been dumber than me - each one I&#x27;ve learned invaluable stuff from. I was a boss once - in my day I owned and self taught&#x2F;created an entire social network much like FB was a few years ago, mine obviously didn&#x27;t take off and now I&#x27;m a very capable bum. Maybe someday something I&#x27;m tinkering with will make me millions but prolly not, for many reasons, I could write books if I wanted ;)<p>At the end of the day, the facts are what they are - there is an optimal level of intelligence that is obviously higher than the bottom but is nowhere near the top tier, very likely near that 100 IQ baseline. What separates us all is our capabilities - mostly stuff we can directly control, like learning a trade.<p>A Master Plumber is a genius plumber by another name and that can and obviously is most often, learned genius. What you sus about yourself is truth - don&#x27;t doubt that. No IQ test ever told me I lacked the tenacity of the C average student that would employ me someday - they can&#x27;t actually measure the extent of our dedicated capacity.<p>I kno more than most people ever have before or rn presently - I don&#x27;t know as much about plumbing as an apprentice with 2 years of a trade school dedicated to plumbing and a year or two of experience in the field, that&#x27;s the reality of it. I could learn the trade - I could learn most every trade, but I won&#x27;t. That&#x27;s life. I can tell you how you the ancients plumbed bc that piqued my curiosity and I kno far more about Roman plumbing than I do how a modern city sewer system works. That&#x27;s also life.<p>It isn&#x27;t what we kno or how fast we can learn it - it&#x27;s what we do that defines us.<p>Become more capable if you feel looked down on - this is the way bc even if what you hone your capabilities of can be replicated by others most won&#x27;t even try.<p>That&#x27;s my rant about this whole intelligence perception we currently have as a society. Having 100 IQ is nowhere near the barrier that having 150 IQ is.<p>Rant aside, to the article - how isn&#x27;t this obvious? I mean feelings literally exist - not just the warm fuzzy ones, like the literal feeling of existence. Does a monkey&#x27;s mind require words to interpret pain or pleasure for example. Do I need to know what &quot;fire&quot; or &quot;hot&quot; is in a verbal context to sufficiently understand &quot;burn&quot; - words exists to convey to to others what doesn&#x27;t need to be conveyed to us. That&#x27;s their function. Communication. To facilitate communication with our social brethren we adopt them fundamentally as our Lego blocks for understanding the world - we pretend that words comprising language are the ideas themselves. A banana is a  - the word is the fruit, they are the same in our minds but if I erase the word banana and all it&#x27;s meaning of the fruit and I randomly encounter a banana - I still can taste it. No words necessary.<p>Also, you can think without words, deliberately and consciously - even absentmindedly.<p>And LLMs can&#x27;t reason ;)<p>Truthfully, the reality is that a 100 IQ normal human is far more capable than any AI I&#x27;ve been given access to - in almost every metric I attempted to asses I ultimately didn&#x27;t even bother as it was so obvious that humans are functionally superior.<p>When AI can reason - you, and everyone else, will kno it. It will be self evident.<p>Anyways, tldr: ppl are smarter than given credit for, smarter and much more capable - IQ is real and matters but far less than we are led to believe. People are awesome - the epitome of biological life on Earth and we do a lot of amazing things and anyone can be amazing.<p>I hate it when the Hacker News collective belittles itself - don&#x27;t do that. I rant here bc it&#x27;s one of the most interesting places I&#x27;ve found and I care about what all of you think far more than I care about your IQ scores.</div><br/></div></div></div></div><div id="41891193" class="c"><input type="checkbox" id="c-41891193" checked=""/><div class="controls bullet"><span class="by">eliaspro</span><span>|</span><a href="#41891068">parent</a><span>|</span><a href="#41892035">prev</a><span>|</span><a href="#41892129">next</a><span>|</span><label class="collapse" for="c-41891193">[-]</label><label class="expand" for="c-41891193">[2 more]</label></div><br/><div class="children"><div class="content">Growing up, I never used words or even sentences for thinking.<p>The abstract visualizations I could build in my mind where comparable to semi-transparent buildings that I could freely spin, navigate and bend to connect relations.<p>In my mid-twenties, someone introduced me to the concept of people using words for mental processes, which was completely foreign to me up to this point.<p>For some reason, this made my brain move more and more towards this language-based model and at the same time, I felt like I was losing the capacity for complex abstract thoughts.<p>Still to this day I (unsuccessfully) try to revive this and unlearn the language in my head, which feels like it imposes a huge barrier and limits my mental capacity to the capabilities of what the language my brain uses at the given time (mostly EN, partially DE) allows to express.</div><br/><div id="41892795" class="c"><input type="checkbox" id="c-41892795" checked=""/><div class="controls bullet"><span class="by">ryandv</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41891193">parent</a><span>|</span><a href="#41892129">next</a><span>|</span><label class="collapse" for="c-41892795">[-]</label><label class="expand" for="c-41892795">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of my experiences working with a software developer transplanted from the humanities who was highly articulate and capable of producing language <i>about</i> programming, yet seemed to not be able to write many actual computer programs themselves.<p>I think that I ultimately developed an obsessive need to cite all my ideas against the literature and formulate natural language arguments for my claims to avoid being bludgeoned over the head with wordcelry and being seen as inferior for my lesser verbal fluency despite having written software for years at that point, since early childhood, and even studied computer science.</div><br/></div></div></div></div><div id="41892129" class="c"><input type="checkbox" id="c-41892129" checked=""/><div class="controls bullet"><span class="by">makeitdouble</span><span>|</span><a href="#41891068">parent</a><span>|</span><a href="#41891193">prev</a><span>|</span><a href="#41893304">next</a><span>|</span><label class="collapse" for="c-41892129">[-]</label><label class="expand" for="c-41892129">[1 more]</label></div><br/><div class="children"><div class="content">I think people who can manipulate complex structures but struggle with language tend to see language in a more formal way, putting more effort into understanding its structure and inner working.<p>Basically what to most people is so obvious that it becomes transparent (&quot;air&quot;) isn&#x27;t to us, which apparently is an incredible gift for becoming a language researcher. Or a programmer.</div><br/></div></div><div id="41893304" class="c"><input type="checkbox" id="c-41893304" checked=""/><div class="controls bullet"><span class="by">bertylicious</span><span>|</span><a href="#41891068">parent</a><span>|</span><a href="#41892129">prev</a><span>|</span><a href="#41891928">next</a><span>|</span><label class="collapse" for="c-41893304">[-]</label><label class="expand" for="c-41893304">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I very strongly suspect that my non-verbal (performal) IQ is much higher (around 130) than my verbal IQ (around 100).<p>I very strongly suspect that you&#x27;re overestimating yourself.</div><br/></div></div><div id="41891928" class="c"><input type="checkbox" id="c-41891928" checked=""/><div class="controls bullet"><span class="by">kerblang</span><span>|</span><a href="#41891068">parent</a><span>|</span><a href="#41893304">prev</a><span>|</span><a href="#41891613">next</a><span>|</span><label class="collapse" for="c-41891928">[-]</label><label class="expand" for="c-41891928">[5 more]</label></div><br/><div class="children"><div class="content">&gt; During my life, I have met several people, especially among software engineers, who seem to be similar to me<p>This begs a question though: Since programming is mostly done with language - admittedly primitive&#x2F;pidgin ones - why isn&#x27;t that a struggle? Not sure if you&#x27;re a programmer yourself, but if so do you prefer certain programming languages for some sense of &quot;less-verbalness&quot; or does it even matter?<p>Just wondering, not attacking your claim per se.</div><br/><div id="41892060" class="c"><input type="checkbox" id="c-41892060" checked=""/><div class="controls bullet"><span class="by">alserio</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41891928">parent</a><span>|</span><a href="#41892075">next</a><span>|</span><label class="collapse" for="c-41892060">[-]</label><label class="expand" for="c-41892060">[2 more]</label></div><br/><div class="children"><div class="content">The idea that programming languages and natural languages are processed with the same wetware should be testable with something like the tests described in this submission.
I don&#x27;t expect it to be true, but only expecting something is not science</div><br/><div id="41892495" class="c"><input type="checkbox" id="c-41892495" checked=""/><div class="controls bullet"><span class="by">dleeftink</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41892060">parent</a><span>|</span><a href="#41892075">next</a><span>|</span><label class="collapse" for="c-41892495">[-]</label><label class="expand" for="c-41892495">[1 more]</label></div><br/><div class="children"><div class="content">Some progress has been made in this area, see [0], [1], [2] and [3], observing both similarities and dissimilarities in terms of language processing:<p>Siegmund, J., Kästner, C., Apel, S., Parnin, C., Bethmann, A., Leich, T. &amp; Brechmann, A. (2014). Understanding understanding source code with functional magnetic resonance imaging. In Proceedings of the 36th International Conference on Software Engineering (pp. 378-389).<p>Peitek, N., Siegmund, J., Apel, S., Kästner, C., Parnin, C., Bethmann, A. &amp; Brechmann, A. (2018). A look into programmers’ heads. IEEE Transactions on Software Engineering, 46(4), 442-462.<p>Krueger, R., Huang, Y., Liu, X., Santander, T., Weimer, W., &amp; Leach, K. (2020). Neurological divide: An fMRI study of prose and code writing. In Proceedings of the ACM&#x2F;IEEE 42nd International Conference on Software Engineering (pp. 678-690).<p>Peitek, N., Apel, S., Parnin, C., Brechmann, A. &amp; Siegmund, J. (2021). Program comprehension and code complexity metrics: An fmri study. In 2021 IEEE&#x2F;ACM 43rd International Conference on Software Engineering (ICSE) (pp. 524-536). IEEE.<p>[0]: <a href="https:&#x2F;&#x2F;www.frontiersin.org&#x2F;10.3389&#x2F;conf.fninf.2014.18.00040&#x2F;event_abstract" rel="nofollow">https:&#x2F;&#x2F;www.frontiersin.org&#x2F;10.3389&#x2F;conf.fninf.2014.18.00040...</a><p>[1]: <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;8425769" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;8425769</a><p>[2]: <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;abs&#x2F;10.1145&#x2F;3377811.3380348" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;abs&#x2F;10.1145&#x2F;3377811.3380348</a><p>[3]: <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;9402005" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;9402005</a></div><br/></div></div></div></div><div id="41892075" class="c"><input type="checkbox" id="c-41892075" checked=""/><div class="controls bullet"><span class="by">makeitdouble</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41891928">parent</a><span>|</span><a href="#41892060">prev</a><span>|</span><a href="#41892066">next</a><span>|</span><label class="collapse" for="c-41892075">[-]</label><label class="expand" for="c-41892075">[1 more]</label></div><br/><div class="children"><div class="content">I see your general point on needing language proficiency to program, but I think it&#x27;s just a very low requirement.<p>Parent isn&#x27;t saying they can&#x27;t handle language (and we wouldn&#x27;t have this discussion in the first place), just that they better handle complexity and structure in non verbal ways.<p>To get back to programming, I think this do apply to most of us. Most of us probably don&#x27;t think in ruby or JS, we have a higher vision of what we want to build and &quot;flatten&quot; it into words that can be parsed and executed. It&#x27;s of course more obvious for people writing in say basic or assembly, some conversion has to happen at some point.</div><br/></div></div><div id="41892066" class="c"><input type="checkbox" id="c-41892066" checked=""/><div class="controls bullet"><span class="by">superb_dev</span><span>|</span><a href="#41891068">root</a><span>|</span><a href="#41891928">parent</a><span>|</span><a href="#41892075">prev</a><span>|</span><a href="#41891613">next</a><span>|</span><label class="collapse" for="c-41892066">[-]</label><label class="expand" for="c-41892066">[1 more]</label></div><br/><div class="children"><div class="content">A programming language has a ton more rules and way less ambiguity than a speaking language.</div><br/></div></div></div></div></div></div><div id="41891613" class="c"><input type="checkbox" id="c-41891613" checked=""/><div class="controls bullet"><span class="by">orwin</span><span>|</span><a href="#41891068">prev</a><span>|</span><a href="#41891901">next</a><span>|</span><label class="collapse" for="c-41891613">[-]</label><label class="expand" for="c-41891613">[4 more]</label></div><br/><div class="children"><div class="content">I will add an anecdata, then ask a question.<p>I could enter what we all here call the &quot;Zone&quot; quite often when i was young (once while doing math :D). I still can, but rarely on purpose, and rarely while coding. I have a lot of experience in this state, and i can clearly say that a marker of entering the zone is that your thoughts are not &quot;limited&quot; by language anymore and the impression of clarity and really fast thinking. This is why i never thought that language was required for thinking.<p>Now the question: would it be possible to scan the brain of people while they enter the zone? I know it isn&#x27;t a state you can reach on command, but isn&#x27;t it worth to try? understand the mechanism of this state? And maybe understand where our thought start?</div><br/><div id="41891620" class="c"><input type="checkbox" id="c-41891620" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#41891613">parent</a><span>|</span><a href="#41892210">next</a><span>|</span><label class="collapse" for="c-41891620">[-]</label><label class="expand" for="c-41891620">[1 more]</label></div><br/><div class="children"><div class="content">Also known as “Flow”.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Flow_(psychology)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Flow_(psychology)</a></div><br/></div></div><div id="41892210" class="c"><input type="checkbox" id="c-41892210" checked=""/><div class="controls bullet"><span class="by">riiii</span><span>|</span><a href="#41891613">parent</a><span>|</span><a href="#41891620">prev</a><span>|</span><a href="#41891901">next</a><span>|</span><label class="collapse" for="c-41892210">[-]</label><label class="expand" for="c-41892210">[2 more]</label></div><br/><div class="children"><div class="content">Nice idea. In the zone, I don&#x27;t think about the code. I am the code and the code is me.<p>That is, until the code refuses to work. Then the code is a bitch and I need a break.</div><br/><div id="41892253" class="c"><input type="checkbox" id="c-41892253" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#41891613">root</a><span>|</span><a href="#41892210">parent</a><span>|</span><a href="#41891901">next</a><span>|</span><label class="collapse" for="c-41892253">[-]</label><label class="expand" for="c-41892253">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense.  If I am the code and the code is me, and the code doesn&#x27;t work, then I&#x27;m done working too.</div><br/></div></div></div></div></div></div><div id="41891901" class="c"><input type="checkbox" id="c-41891901" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#41891613">prev</a><span>|</span><a href="#41892701">next</a><span>|</span><label class="collapse" for="c-41891901">[-]</label><label class="expand" for="c-41891901">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; They’re basically the first model organism for researchers studying the neuroscience of language. They are not a biological organism, but until these models came about, we just didn’t have anything other than the human brain that does language.<p>I think this is completely wrong-headed. It&#x27;s like saying that until cars came about we just didn&#x27;t have anything other than animals that could move around under its own power, therefore in order to understand how animals move around we should go and study cars. There is a great gulf of unsubstantiated assumptions between observing the behaviour of a technological artifact, like a car or a statistical language model, and thinking we can learn something useful from it about human or more generally animal faculties.<p>I am really taken aback that this is a serious suggestion: study large language models as in-silico models of human linguistic ability. Just putting it down in writing like that rings alarm bells all over the place.</div><br/></div></div><div id="41892701" class="c"><input type="checkbox" id="c-41892701" checked=""/><div class="controls bullet"><span class="by">ryandv</span><span>|</span><a href="#41891901">prev</a><span>|</span><a href="#41893710">next</a><span>|</span><label class="collapse" for="c-41892701">[-]</label><label class="expand" for="c-41892701">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth noting the precise and narrow sense in which the term &quot;language&quot; is used throughout these studies: it is those particular &quot;word sequences&quot; that activate particular regions in the brain&#x27;s left hemisphere, to the exclusion of other forms of symbolic representation such as mathematical notation. Indeed, in two of the studies cited, [0] [1] subjects with language deficits or brain lesions in areas associated with the &quot;language network&quot; are asked to perform on various mathematical tasks involving algebraic expressions [0] or Arabic numerals [1]:<p>&gt; DA was impaired in solving simple addition, subtraction, division or multiplication problems, but could correctly simplify abstract expressions such as (b×a)÷(a×b) or (a+b)+(b+a) and make correct judgements whether abstract algebraic equations like b − a = a − b or (d÷c)+a=(d+a)÷(c+a) were true or false.<p>&gt; Sensitivity to the structural properties of numerical expressions was also evaluated with bracket problems, some requiring the computation of a set of expressions with embedded brackets: for example, 90  [(3  17)  3].<p>Discussions of whether or not these sorts of algebraic or numerical expressions constitute a &quot;language of mathematics&quot; aside (despite them not engaging the same brain regions and structures associated with the word &quot;language&quot;); it may be the case that these sorts of word sequences and symbols processed by structures in the brain&#x27;s left hemisphere are not <i>essential</i> for thought, but can still serve as a useful psychotechnology or &quot;bicycle of the mind&quot; to accelerate and leverage its innate capabilities. In a similar fashion to how this sort of mathematical notation allows for more concise and precise expression of mathematical objects (contrast &quot;the number that is thrice of three and seventeen less of ninety&quot;) and serves to amplify our mathematical capacities, language can perhaps be seen as a force multiplier; I have doubts whether those suffering from aphasia or an agrammatic condition would be able to rise to the heights of cognitive performance.<p>[0] <a href="https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;17306848&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;17306848&#x2F;</a><p>[1] <a href="https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;15713804&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;15713804&#x2F;</a></div><br/></div></div><div id="41893710" class="c"><input type="checkbox" id="c-41893710" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41892701">prev</a><span>|</span><a href="#41893609">next</a><span>|</span><label class="collapse" for="c-41893710">[-]</label><label class="expand" for="c-41893710">[2 more]</label></div><br/><div class="children"><div class="content">I can think without language about all the things that I have experienced directly through some of my senses, but there is a huge number of things that I have never experienced directly and about which I can think only using language.<p>I doubt that this is different for other people. I believe that those people who claim that they never think using language are never thinking about the abstract or remote things about which I think using language.<p>For instance, I can think about a model of CPU without naming it, if it has been included in some of the many computers that I have used during the years, by recalling an image of the computer, or of its motherboard, or of the CPU package, or recalling some experiences when running programs on that computer, how slow or how responsive that felt, and so on.<p>I cannot think about a CPU that I have never used, e.g. Intel 11900K, without naming it.<p>Similarly, I can think without language about the planet Jupiter, which I have seen directly many times, or even about the planet Neptune, which I have never seen with my eyes, but I have seen in photographs, but I cannot think otherwise than with words about some celestial bodies that I have never seen.<p>The same for verbs, some verbs name actions about which I can think by recalling images or sounds or smells or tactile feelings that correspond with typical results of those actions. Other verbs are too abstract, so I can think about the corresponding action only using the word that names it.<p>For some abstract concepts, one could imagine a sequence of images, sounds etc. that would suggest them, but that would be like a pantomime puzzle and it would be a too slow way of thinking.<p>I can look at a wood plank thrown over a precipice and I can conclude that it may be safe to walk on it without language, but if I were to design a bridge guaranteed to resist to the weight of some trucks passing on it, I could not do that design without thinking with language.<p>Therefore I believe that language is absolutely essential for complex abstract thinking, even if there are alternative ways of thinking that may be sufficient even most of the time for some people.</div><br/><div id="41893891" class="c"><input type="checkbox" id="c-41893891" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#41893710">parent</a><span>|</span><a href="#41893609">next</a><span>|</span><label class="collapse" for="c-41893891">[-]</label><label class="expand" for="c-41893891">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but there is a huge number of things that I have never experienced directly and about which I can think only using language.<p>This makes me think of the Tao Te Ching, which opens with (translation dependent, of course)<p><pre><code>   The Tao that can be spoken is not the eternal Tao
   The name that can be named is not the eternal name</code></pre></div><br/></div></div></div></div><div id="41893609" class="c"><input type="checkbox" id="c-41893609" checked=""/><div class="controls bullet"><span class="by">Peteragain</span><span>|</span><a href="#41893710">prev</a><span>|</span><a href="#41891276">next</a><span>|</span><label class="collapse" for="c-41893609">[-]</label><label class="expand" for="c-41893609">[1 more]</label></div><br/><div class="children"><div class="content">I know a little about this area and there is certainly a movement (glacial) away from thinking that thinking uses symbols, distributed or not. The argument cannot be made in a popular science article and so such articles inevitably fall back on popular ideas of what thinking is. The alternatives: the embodied nature of reasoning is one direction and many talk of an &quot;enacivist&quot; approach. There are certainly some kinds of thinking that require symbols, but a surprisingly large and diverse range of intelligent behaviour can be done by just wiring stuff up. Interestingly, a significant amount  seems amenable to a mechanism based on &quot;glorified auto-complete&quot; (cf Hinton) and I have written something on the sociological variant - something readable I hope - arxiv.org&#x2F;abs&#x2F;2402.08403</div><br/></div></div><div id="41891276" class="c"><input type="checkbox" id="c-41891276" checked=""/><div class="controls bullet"><span class="by">mmooss</span><span>|</span><a href="#41893609">prev</a><span>|</span><a href="#41893607">next</a><span>|</span><label class="collapse" for="c-41891276">[-]</label><label class="expand" for="c-41891276">[1 more]</label></div><br/><div class="children"><div class="content">A concept in every human culture - i.e., created in every culture, not passed from one to some others - is <i>mentalese</i> [0]: &quot;A universal non-verbal system of concepts, etc., conceived of as an innate representational system resembling language, which is the medium of thought and underlies the ability to learn and use a language.&quot; [1]<p>If you look up &#x27;mentalese&#x27; you can find a bunch written about it. There&#x27;s an in-depth article by Daniel Gregory and Peter Langland-Hassan, in the incredible Stanford Encyclopedia of Philosophy, on <i>Inner Speech</i> (admittedly, I&#x27;m taking a leap to think they mean precisely the same thing). [2]<p>[0] Steven Pinker, <i>The Blank Slate: The Modern Denial of Human Nature</i> (2002)<p>[1] Oxford English Dictionary<p>[2] <a href="https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;inner-speech&#x2F;" rel="nofollow">https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;inner-speech&#x2F;</a></div><br/></div></div><div id="41893607" class="c"><input type="checkbox" id="c-41893607" checked=""/><div class="controls bullet"><span class="by">keepamovin</span><span>|</span><a href="#41891276">prev</a><span>|</span><a href="#41892481">next</a><span>|</span><label class="collapse" for="c-41893607">[-]</label><label class="expand" for="c-41893607">[1 more]</label></div><br/><div class="children"><div class="content">When I was in junior high, I remember a friend saying to me “you can’t think in images, you think in words.” She insisted, and couldn’t believe that I actually thought in images a lot of the time. she was pretty smart and creative.<p>But I thought in images and I still do in part. so I don’t think you need words to think.<p>I thought the people who did were overly computerized, maybe thinking in an over defined way.</div><br/></div></div><div id="41892481" class="c"><input type="checkbox" id="c-41892481" checked=""/><div class="controls bullet"><span class="by">Tagbert</span><span>|</span><a href="#41893607">prev</a><span>|</span><a href="#41893324">next</a><span>|</span><label class="collapse" for="c-41892481">[-]</label><label class="expand" for="c-41892481">[3 more]</label></div><br/><div class="children"><div class="content">I’ve been hearing&#x2F;reading about people who don’t have an inner monologue. Their experience of cognition is not verbally-based.<p><a href="https:&#x2F;&#x2F;www.cbc.ca&#x2F;news&#x2F;canada&#x2F;saskatchewan&#x2F;inner-monologue-experience-science-1.5486969" rel="nofollow">https:&#x2F;&#x2F;www.cbc.ca&#x2F;news&#x2F;canada&#x2F;saskatchewan&#x2F;inner-monologue-...</a></div><br/><div id="41893938" class="c"><input type="checkbox" id="c-41893938" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#41892481">parent</a><span>|</span><a href="#41892833">next</a><span>|</span><label class="collapse" for="c-41893938">[-]</label><label class="expand" for="c-41893938">[1 more]</label></div><br/><div class="children"><div class="content">As one of those people most of the time (communicating with other people is the main exception), I still find it astounding that it&#x27;s hard for some people to understand.<p>Take riding a bike: I presume even people with an overactive inner monologue aren&#x27;t constantly planning their actions (brakes, steering, turns) in words. Then just extend that out to most other stuff.</div><br/></div></div><div id="41892833" class="c"><input type="checkbox" id="c-41892833" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41892481">parent</a><span>|</span><a href="#41893938">prev</a><span>|</span><a href="#41893324">next</a><span>|</span><label class="collapse" for="c-41892833">[-]</label><label class="expand" for="c-41892833">[1 more]</label></div><br/><div class="children"><div class="content">Honestly, for some of us the idea that all your thoughts have to filter through language sounds very tedious.<p>I want to remind everyone that your experiences are unique and do not necessarily translate to all other people.</div><br/></div></div></div></div><div id="41893324" class="c"><input type="checkbox" id="c-41893324" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41892481">prev</a><span>|</span><a href="#41892133">next</a><span>|</span><label class="collapse" for="c-41893324">[-]</label><label class="expand" for="c-41893324">[1 more]</label></div><br/><div class="children"><div class="content">While getting confirmation of this relationship (or lack of it) is exciting, none of this is surprising: language is a tool we &quot;developed&quot; further through our cognitive processes, but ultimately other primates use language as well.<p>The one thing I wonder is if it&#x27;s mostly &quot;code duplication&quot;: iow, would we be able to develop language by using a different region of the brain, or do we actually do cognitive processes in the language part too?<p>In other words, is this simply deciding to send language processing to the GPU even if we could do it with the CPU (to illustrate my point)?<p>How would one even devise an experiment to prove or disprove this?<p>To me it seems obvious that our language generation and processing regions really involve cognition as well, as languages are very much rule based (even of they came up in reverse: first language then rules): could we get both regions to light up in brain imaging when we get to tricky words that we aren&#x27;t sure how to spell or adapt to context like declensions of foreign words<p>&gt; But you can build these models that are trained on only particular kinds of linguistic input or are trained on speech inputs as opposed to textual inputs.<p>As someone from this side of the &quot;fence&quot; (mathematics and CS, though currently obly a practicing software engineer), I don&#x27;t think LLMs provide this opportunity that is in any way comparable to human minds.<p>Comparing performance of small kids developing their language skills (I&#x27;ve only had two, but one is enough to prove by contradiction) to LLMs (in particular for Serbian), LLMs like ChatGPT had a much broader vocabulary, but kids were much better at figuring out complex language rules with very limited number of inputs (noticed by them making mistakes on exceptions by following a &quot;rule&quot; at 2 years of age or younger).<p>The amount of training input GenAI needs is multiple orders of magnitude larger compared to young kids.<p>Though it&#x27;s not a fair comparison: kids learn language by listening, immitation, watching, smelling, hearing and in context (you&#x27;ll talk about bread at breakfast).<p>So let&#x27;s be careful in considering LLMs a model of a human language process.</div><br/></div></div><div id="41892133" class="c"><input type="checkbox" id="c-41892133" checked=""/><div class="controls bullet"><span class="by">shsbdncudx</span><span>|</span><a href="#41893324">prev</a><span>|</span><a href="#41891290">next</a><span>|</span><label class="collapse" for="c-41892133">[-]</label><label class="expand" for="c-41892133">[1 more]</label></div><br/><div class="children"><div class="content">When we eventually nail agi, I think we will look at llm’s as nothing more than the interface to ai, how we interact with it, but we won’t consider it to be ai.</div><br/></div></div><div id="41891290" class="c"><input type="checkbox" id="c-41891290" checked=""/><div class="controls bullet"><span class="by">aniijbod</span><span>|</span><a href="#41892133">prev</a><span>|</span><a href="#41889857">next</a><span>|</span><label class="collapse" for="c-41891290">[-]</label><label class="expand" for="c-41891290">[2 more]</label></div><br/><div class="children"><div class="content">Thought and language are intertwined in ways we don’t fully grasp. The fact that certain cognitive tasks, like comprehension, can proceed without engaging traditional language-related brain regions doesn&#x27;t mean thought doesn&#x27;t use language—it just means we might not yet understand how it does. Thought could employ other forms of linguistic-like processes that Fedorenko&#x27;s experiments, or even current brain-imaging techniques, fail to capture.<p>There could be functional redundancies or alternative systems at play that we haven&#x27;t identified, systems that allow thought to access linguistic capabilities even when the specialized language areas are offline or unnecessary. The question of what &quot;language in thought&quot; looks like remains open, particularly in tasks requiring comprehension. This underscores the need for further exploration into how thought operates and what role, if any, latent or alternative linguistic functionalities play when conventional language regions aren&#x27;t active.<p>In short, we may have a good understanding of language in isolation, but not necessarily in its broader role within the cognitive architecture that governs thought, comprehension, and meaning-making.</div><br/><div id="41891481" class="c"><input type="checkbox" id="c-41891481" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#41891290">parent</a><span>|</span><a href="#41889857">next</a><span>|</span><label class="collapse" for="c-41891481">[-]</label><label class="expand" for="c-41891481">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The fact that certain cognitive tasks, like comprehension, can proceed without engaging traditional language-related brain regions doesn&#x27;t mean thought doesn&#x27;t use language<p>All other things being equal, its is a reason to provisionally reject the hypothesis that those kinds of thought use language as introducing entities (the ties between those kinds of thought and language) into the model of reality being generated that are not needed to explain any observed phenomenon.</div><br/></div></div></div></div><div id="41889857" class="c"><input type="checkbox" id="c-41889857" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#41891290">prev</a><span>|</span><a href="#41889627">next</a><span>|</span><label class="collapse" for="c-41889857">[-]</label><label class="expand" for="c-41889857">[10 more]</label></div><br/><div class="children"><div class="content">&gt;You can ask whether people who have these severe language impairments can perform tasks that require thinking. You can ask them to solve some math problems or to perform a social reasoning test, and all of the instructions, of course, have to be nonverbal because they can’t understand linguistic information anymore. Scientists have a lot of experience working with populations that don’t have language—studying preverbal infants or studying nonhuman animal species. So it’s definitely possible to convey instructions in a way that’s nonverbal. And the key finding from this line of work is that there are people with severe language impairments who nonetheless seem totally fine on all cognitive tasks that we’ve tested them on so far.<p>They should start with what is their definition of language. To me it&#x27;s any mean you can use to communicate some information to someone else and they generally get a correct inference of what kind of representations and responses are expected is the definition of a language. Whether it&#x27;s uttered words, a series of gestures, subtle pheromones or a slap in your face, that&#x27;s all languages.<p>For the same reason I find extremely odd that the hypothesis that animals don&#x27;t have any form of language is even considered as a serious claim in introduction.<p>Anyone can prove anything and its contrary about language if the term is given whatever meaning is needed for premises to match with the conclusion.</div><br/><div id="41890078" class="c"><input type="checkbox" id="c-41890078" checked=""/><div class="controls bullet"><span class="by">GavinMcG</span><span>|</span><a href="#41889857">parent</a><span>|</span><a href="#41890279">next</a><span>|</span><label class="collapse" for="c-41890078">[-]</label><label class="expand" for="c-41890078">[3 more]</label></div><br/><div class="children"><div class="content">Just as a data point, my guess is that a very small minority of English-language speakers would define the term as broadly as you do, at least in a context relating the concept to analytical thought processes. At the very least, I think most people expect that language is used actively, such that pheromones wouldn’t fall within the definition. (And actually, that’s reflected when you say language is a means “you can <i>use</i>”.) Likewise, a slap in the face certainly can be interpreted, but slapping doesn’t seem like a <i>means</i> of communicating in general—because a slap only communicates one thing.</div><br/><div id="41892900" class="c"><input type="checkbox" id="c-41892900" checked=""/><div class="controls bullet"><span class="by">dleeftink</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41890078">parent</a><span>|</span><a href="#41890426">next</a><span>|</span><label class="collapse" for="c-41892900">[-]</label><label class="expand" for="c-41892900">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure it&#x27;s that fringe. Popular addages such as &#x27;language is a vehicle for thought&#x27; and &#x27;the pen is mightier than the sword&#x27; reveal that language is sometimes implied to be tool-like, with many of our unspoken acts carrying linguistic meaning (e.g. ghosting, not answering a call, sign language, gesturing, nodding, etc.).<p>Even tools present us a certain &#x27;language&#x27;, talking to us via beeps, blinks and buzzes, and are having increasingly interesting discussions amongst themselves (e.g. subreddit simulator, agent based modeling). Recent philosophers of technology as Mark Coeckelbergh present a comprehensive argument for why we need to move away from the tool&#x2F;language barrier [0], and has been part in informing the EC Expert Group on AI [1].<p>[0]: <a href="https:&#x2F;&#x2F;www.taylorfrancis.com&#x2F;books&#x2F;mono&#x2F;10.4324&#x2F;9781315528571&#x2F;using-words-things-mark-coeckelbergh" rel="nofollow">https:&#x2F;&#x2F;www.taylorfrancis.com&#x2F;books&#x2F;mono&#x2F;10.4324&#x2F;97813155285...</a><p>[1]: <a href="https:&#x2F;&#x2F;philtech.univie.ac.at&#x2F;news&#x2F;news-about-publicatons-etc&#x2F;news&#x2F;mark-coeckelbergh-appointed-member-of-eu-high-level-expert-group-on-ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;philtech.univie.ac.at&#x2F;news&#x2F;news-about-publicatons-et...</a></div><br/></div></div><div id="41890426" class="c"><input type="checkbox" id="c-41890426" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41890078">parent</a><span>|</span><a href="#41892900">prev</a><span>|</span><a href="#41890279">next</a><span>|</span><label class="collapse" for="c-41890426">[-]</label><label class="expand" for="c-41890426">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also doubtful that thinking about the concept of analytical thought processes is something most humans do either, at least not in these terms and this perspective.<p>Should we expect experts in cognitive science exposing their view in a scientific publication to stick to the narrowest median view of language though? All the more when in the same article you quote people like Russell who certainly didn&#x27;t have a naïve definition of language when expressing a point of view on the matter.<p>And slapping in general can definitely communicate far more than a single thing depending on many parameters. See <a href="https:&#x2F;&#x2F;www.33rdsquare.com&#x2F;is-a-slap-disrespectful-a-nuanced-analysis&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.33rdsquare.com&#x2F;is-a-slap-disrespectful-a-nuanced...</a> for a text exploring some of nuances of the meaning it can encompasse. But even a kid can get that slap could perfectly have all the potential to create a fully doubly articulated language, as The Croods 2 creators funnily have put in scene. :D</div><br/></div></div></div></div><div id="41890279" class="c"><input type="checkbox" id="c-41890279" checked=""/><div class="controls bullet"><span class="by">ryandv</span><span>|</span><a href="#41889857">parent</a><span>|</span><a href="#41890078">prev</a><span>|</span><a href="#41890114">next</a><span>|</span><label class="collapse" for="c-41890279">[-]</label><label class="expand" for="c-41890279">[1 more]</label></div><br/><div class="children"><div class="content">They do, in the first section of the journal article itself:<p>&gt; Do any forms of thought—our knowledge of the world and ability to reason over these knowledge representations—require language (that is, representations and computations that sup-port our ability to generate and interpret meaningfully structured word sequences)?<p>Emphasis on &quot;word sequences,&quot; to the exclusion of, e.g. body language or sign language. They go on to discuss some of the brain structures involved in the production and interpretation of these word sequences:<p>&gt; Language production and language understanding are sup-ported by an interconnected set of brain areas in the left hemisphere, often referred to as the ‘language network&#x27;.<p>It is these brain areas that form the basis of their testable claims regarding language.<p>&gt; Anyone can prove anything and its contrary about language if the term is given whatever meaning is needed for premises to match with the conclusion.<p>This is why &quot;coming to terms&quot; on the definitions of words and what you mean by them should be the first step in any serious discussion if you aim to have any hope in hell of communicating precisely; it is also why you should be skeptical of political actors that insist on redefining the meanings of (especially well-known) terms in order to push an agenda. Confusing a term with its actual referent is exceedingly commonplace in modern day.</div><br/></div></div><div id="41890114" class="c"><input type="checkbox" id="c-41890114" checked=""/><div class="controls bullet"><span class="by">throwaway19972</span><span>|</span><a href="#41889857">parent</a><span>|</span><a href="#41890279">prev</a><span>|</span><a href="#41889627">next</a><span>|</span><label class="collapse" for="c-41890114">[-]</label><label class="expand" for="c-41890114">[5 more]</label></div><br/><div class="children"><div class="content">&gt; For the same reason I find extremely odd that the hypothesis that animals don&#x27;t have any form of language is even considered as a serious claim in introduction.<p>I guess I&#x27;ve always just assumed it refers to some feature that&#x27;s uniquely human—notably, recursive grammars.</div><br/><div id="41890640" class="c"><input type="checkbox" id="c-41890640" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41890114">parent</a><span>|</span><a href="#41891259">next</a><span>|</span><label class="collapse" for="c-41890640">[-]</label><label class="expand" for="c-41890640">[2 more]</label></div><br/><div class="children"><div class="content">Not all human languages exhibits recursion though:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pirah%C3%A3_language" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pirah%C3%A3_language</a><p>And recursion as the unique trait for human language differentiation is not necessarily completely consensual <a href="https:&#x2F;&#x2F;omseeth.github.io&#x2F;blog&#x2F;2024&#x2F;recursive_language&#x2F;" rel="nofollow">https:&#x2F;&#x2F;omseeth.github.io&#x2F;blog&#x2F;2024&#x2F;recursive_language&#x2F;</a><p>Also, let&#x27;s recall that in its broader meaning, the scientific consensus is that humans are animals and they evolved through the same basic mechanism as all other life forms that is evolution. So even assuming that evolution made some unique language hability emerge in humans, it&#x27;s most likely that they share most language traits with other species and that there is more things to learn from them that what would be possible if it&#x27;s assumed they can&#x27;t have a language and thoughts.</div><br/><div id="41892205" class="c"><input type="checkbox" id="c-41892205" checked=""/><div class="controls bullet"><span class="by">throwaway19972</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41890640">parent</a><span>|</span><a href="#41891259">next</a><span>|</span><label class="collapse" for="c-41892205">[-]</label><label class="expand" for="c-41892205">[1 more]</label></div><br/><div class="children"><div class="content">Does any other living entity have recursive grammars? It seems uniquely human.<p>It seems that the second link may indicate otherwise but I&#x27;m still pretty skeptical. This requires extraordinary evidence. Furthermore there may be a more practical limit of &quot;stack size&quot; or &quot;context size&quot; that effectively exceptionalizes humans (especially considering the size and proportional energy consumption of our brains).</div><br/></div></div></div></div><div id="41891259" class="c"><input type="checkbox" id="c-41891259" checked=""/><div class="controls bullet"><span class="by">earleybird</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41890114">parent</a><span>|</span><a href="#41890640">prev</a><span>|</span><a href="#41889627">next</a><span>|</span><label class="collapse" for="c-41891259">[-]</label><label class="expand" for="c-41891259">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m inclined to believe that of the animals that exhibit varying degrees of self awareness, they have mental structures isomorphic to a recursive grammar.  As such, perhaps using a recursive grammar is not distinctly a human trait.</div><br/><div id="41892213" class="c"><input type="checkbox" id="c-41892213" checked=""/><div class="controls bullet"><span class="by">throwaway19972</span><span>|</span><a href="#41889857">root</a><span>|</span><a href="#41891259">parent</a><span>|</span><a href="#41889627">next</a><span>|</span><label class="collapse" for="c-41892213">[-]</label><label class="expand" for="c-41892213">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that recursive grammar is linked to self awareness. Certainly not strongly. Many animals that don&#x27;t appear to have ability to interpret recursive grammar seem to have self awareness.</div><br/></div></div></div></div></div></div></div></div><div id="41889627" class="c"><input type="checkbox" id="c-41889627" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#41889857">prev</a><span>|</span><a href="#41891282">next</a><span>|</span><label class="collapse" for="c-41889627">[-]</label><label class="expand" for="c-41889627">[1 more]</label></div><br/><div class="children"><div class="content">I like Temple Grandin&#x27;s &quot;Thinking the Way Animals Do&quot;:<p><a href="https:&#x2F;&#x2F;www.grandin.com&#x2F;references&#x2F;thinking.animals.html" rel="nofollow">https:&#x2F;&#x2F;www.grandin.com&#x2F;references&#x2F;thinking.animals.html</a></div><br/></div></div><div id="41891282" class="c"><input type="checkbox" id="c-41891282" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#41889627">prev</a><span>|</span><a href="#41892948">next</a><span>|</span><label class="collapse" for="c-41891282">[-]</label><label class="expand" for="c-41891282">[2 more]</label></div><br/><div class="children"><div class="content">When I was 13 or so, a friend asked me, &quot;So, you speak three languages. Which one do you think in?&quot; and the question left me speechless, because until that moment I hadn&#x27;t considered that people think in words. It seemed a very inefficient way to go about things!<p>Much later, I did begin to think mostly in words, and (perhaps for unrelated reasons?) my thinking became much less efficient.<p>Also related, I experienced temporarily enhanced cognition while under the influence of entheogens. My thoughts, which normally fade within seconds, became stretched out, so that I could stack up to 7 layers of thought on top of each other and examine them simultaneously.<p>I remember feeling greatly diminished, mentally, once that ability went away.</div><br/><div id="41892296" class="c"><input type="checkbox" id="c-41892296" checked=""/><div class="controls bullet"><span class="by">etcd</span><span>|</span><a href="#41891282">parent</a><span>|</span><a href="#41892948">next</a><span>|</span><label class="collapse" for="c-41892296">[-]</label><label class="expand" for="c-41892296">[1 more]</label></div><br/><div class="children"><div class="content">With the drugs were you able to be more efficient for example code quicker, or was it more like better insights. Or perhaps both?</div><br/></div></div></div></div><div id="41892948" class="c"><input type="checkbox" id="c-41892948" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#41891282">prev</a><span>|</span><a href="#41892933">next</a><span>|</span><label class="collapse" for="c-41892948">[-]</label><label class="expand" for="c-41892948">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m wondering about the &quot;non-verbal language&quot; that scientists use to communicate with people affected by aphasia. What makes a brain with aphasia understand it? Do brains have dedicated circuitry to process words? (as opposed to, say, sounds which are a more general concept)</div><br/></div></div><div id="41892933" class="c"><input type="checkbox" id="c-41892933" checked=""/><div class="controls bullet"><span class="by">upghost</span><span>|</span><a href="#41892948">prev</a><span>|</span><a href="#41891451">next</a><span>|</span><label class="collapse" for="c-41892933">[-]</label><label class="expand" for="c-41892933">[2 more]</label></div><br/><div class="children"><div class="content">Well this comment is about the article not LLMs so I doubt it will have much in the way of legs, but this work has already been covered extensively and to a fascinating depth by Jaak Panksepp [1].<p>His work explores the neuropsychology of emotions WAIT DON&#x27;T GO they are actually the <i>substrate of consciousness</i>,
NOT the other way around.<p>We have 7 primary affective processes (measurable hardware level emotions) and they are not what you think[2]. They are considered primary because they are <i>sublinguistic</i>.  For instance, witnessing the color red is a primary experience, you cannot explain in words the color red to <i>someone who has not ever seen it before</i>.<p>His work is a really fascinating read if you ever want to take a break from puters for a minute and learn how people work.<p>PS the reason this sort of research isn&#x27;t more widely known is because the behaviorist school was so incredibly dominant since the 1970s they made it completely taboo to discuss subjective experience in the realm of scientific discourse. In fact the emotions we are usually taught are not based on emotional states but on muscle contractions in the face! Not being allowed to talk about emotions in psychological studies or the inner process of the mind is kinda crazy when you think about it. So only recently with neuroimaging has it suddenly become ok to acknowledge that things happen in the brain independent of externally observable behavior.<p>[1] <a href="https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;6EYULdP" rel="nofollow">https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;6EYULdP</a><p>[2] 
  - seeking
  - fear
  - anxiety and grief
  - rage
  - lust
  - play!!!
  - caring<p>[3] if this sounds familiar at all it&#x27;s because Jordan Peterson cites Jaak Panksep all the time.  Well 50% of the time, the other 50% is CG Jung and the final
50% is the book of Exodus for some reason.</div><br/><div id="41892951" class="c"><input type="checkbox" id="c-41892951" checked=""/><div class="controls bullet"><span class="by">sebmellen</span><span>|</span><a href="#41892933">parent</a><span>|</span><a href="#41891451">next</a><span>|</span><label class="collapse" for="c-41892951">[-]</label><label class="expand" for="c-41892951">[1 more]</label></div><br/><div class="children"><div class="content">Fascinating comment and I’m glad I caught it! Thank you!</div><br/></div></div></div></div><div id="41891451" class="c"><input type="checkbox" id="c-41891451" checked=""/><div class="controls bullet"><span class="by">mannyv</span><span>|</span><a href="#41892933">prev</a><span>|</span><a href="#41891019">next</a><span>|</span><label class="collapse" for="c-41891451">[-]</label><label class="expand" for="c-41891451">[1 more]</label></div><br/><div class="children"><div class="content">Imo just like in computers, language can make certain thoughts easier to think.</div><br/></div></div><div id="41891019" class="c"><input type="checkbox" id="c-41891019" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#41891451">prev</a><span>|</span><a href="#41892090">next</a><span>|</span><label class="collapse" for="c-41891019">[-]</label><label class="expand" for="c-41891019">[1 more]</label></div><br/><div class="children"><div class="content">I think we need to distinguish between the language e.g. the native language the person uses like English and the concept of language. Your information exchanging binary messages over PCI bus is also part of a language.</div><br/></div></div><div id="41892090" class="c"><input type="checkbox" id="c-41892090" checked=""/><div class="controls bullet"><span class="by">gibsonf1</span><span>|</span><a href="#41891019">prev</a><span>|</span><a href="#41892581">next</a><span>|</span><label class="collapse" for="c-41892090">[-]</label><label class="expand" for="c-41892090">[1 more]</label></div><br/><div class="children"><div class="content">The key to human intelligence are concepts. We just use whatever language we choose to symbolize the concepts.</div><br/></div></div><div id="41889721" class="c"><input type="checkbox" id="c-41889721" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#41892581">prev</a><span>|</span><a href="#41889942">next</a><span>|</span><label class="collapse" for="c-41889721">[-]</label><label class="expand" for="c-41889721">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;PsUeX" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;PsUeX</a></div><br/></div></div><div id="41889942" class="c"><input type="checkbox" id="c-41889942" checked=""/><div class="controls bullet"><span class="by">kaiwen1</span><span>|</span><a href="#41889721">prev</a><span>|</span><a href="#41889794">next</a><span>|</span><label class="collapse" for="c-41889942">[-]</label><label class="expand" for="c-41889942">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s what Helen Keller had to say about this in _The World I Live In_:<p>&quot;Before my teacher came to me, I did not know that I am. I lived in a world that was a no-world. I cannot hope to describe adequately that unconscious, yet conscious time of nothingness. I did not know that I knew aught, or that I lived or acted or desired. I had neither will nor intellect. I was carried along to objects and acts by a certain blind natural impetus. I had a mind which caused me to feel anger, satisfaction, desire. These two facts led those about me to suppose that I willed and thought. I can remember all this, not because I knew that it was so, but because I have tactual memory. It enables me to remember that I never contracted my forehead in the act of thinking. I never viewed anything beforehand or chose it. I also recall tactually the fact that never in a start of the body or a heart-beat did I feel that I loved or cared for anything. My inner life, then, was a blank without past, present, or future, without hope or anticipation, without wonder or joy or faith.<p>It was not night—it was not day.<p>.      .      .      .      .<p>But vacancy absorbing space,
And fixedness, without a place;
There were no stars—no earth—no time—
No check—no change—no good—no crime.<p>My dormant being had no idea of God or immortality, no fear of death.<p>I remember, also through touch, that I had a power of association. I felt tactual jars like the stamp of a foot, the opening of a window or its closing, the slam of a door. After repeatedly smelling rain and feeling the discomfort of wetness, I acted like those about me: I ran to shut the window. But that was not thought in any sense. It was the same kind of association that makes animals take shelter from the rain. From the same instinct of aping others, I folded the clothes that came from the laundry, and put mine away, fed the turkeys, sewed bead-eyes on my doll&#x27;s face, and did many other things of which I have the tactual remembrance. When I wanted anything I liked,—ice-cream, for instance, of which I was very fond,—I had a delicious taste on my tongue (which, by the way, I never have now), and in my hand I felt the turning of the freezer. I made the sign, and my mother knew I wanted ice-cream. I &quot;thought&quot; and desired in my fingers. If I had made a man, I should certainly have put the brain and soul in his finger-tips. From reminiscences like these I conclude that it is the opening of the two faculties, freedom of will, or choice, and rationality, or the power of thinking from one thing to another, which makes it possible to come into being first as a child, afterwards as a man.<p>Since I had no power of thought, I did not compare one mental state with another. So I was not conscious of any change or process going on in my brain when my teacher began to instruct me. I merely felt keen delight in obtaining more easily what I wanted by means of the finger motions she taught me. I thought only of objects, and only objects I wanted. It was the turning of the freezer on a larger scale. When I learned the meaning of &quot;I&quot; and &quot;me&quot; and found that I was something, I began to think. Then consciousness first existed for me. Thus it was not the sense of touch that brought me knowledge. It was the awakening of my soul that first rendered my senses their value, their cognizance of objects, names, qualities, and properties. Thought made me conscious of love, joy, and all the emotions. I was eager to know, then to understand, afterward to reflect on what I knew and understood, and the blind impetus, which had before driven me hither and thither at the dictates of my sensations, vanished forever.<p>I cannot represent more clearly than any one else the gradual and subtle changes from first impressions to abstract ideas. But I know that my physical ideas, that is, ideas derived from material objects, appear to me first an idea similar to those of touch. Instantly they pass into intellectual meanings. Afterward the meaning finds expression in what is called &quot;inner speech.&quot; When I was a child, my inner speech was inner spelling. Although I am even now frequently caught spelling to myself on my fingers, yet I talk to myself, too, with my lips, and it is true that when I first learned to speak, my mind discarded the finger-symbols and began to articulate. However, when I try to recall what some one has said to me, I am conscious of a hand spelling into mine.<p>It has often been asked what were my earliest impressions of the world in which I found myself. But one who thinks at all of his first impressions knows what a riddle this is. Our impressions grow and change unnoticed, so that what we suppose we thought as children may be quite different from what we actually experienced in our childhood. I only know that after my education began the world which came within my reach was all alive. I spelled to my blocks and my dogs. I sympathized with plants when the flowers were picked, because I thought it hurt them, and that they grieved for their lost blossoms. It was two years before I could be made to believe that my dogs did not understand what I said, and I always apologized to them when I ran into or stepped on them.<p>As my experiences broadened and deepened, the indeterminate, poetic feelings of childhood began to fix themselves in definite thoughts. Nature—the world I could touch—was folded and filled with myself. I am inclined to believe those philosophers who declare that we know nothing but our own feelings and ideas. With a little ingenious reasoning one may see in the material world simply a mirror, an image of permanent mental sensations. In either sphere self-knowledge is the condition and the limit of our consciousness. That is why, perhaps, many people know so little about what is beyond their short range of experience. They look within themselves—and find nothing! Therefore they conclude that there is nothing outside themselves, either.<p>However that may be, I came later to look for an image of my emotions and sensations in others. I had to learn the outward signs of inward feelings. The start of fear, the suppressed, controlled tensity of pain, the beat of happy muscles in others, had to be perceived and compared with my own experiences before I could trace them back to the intangible soul of another. Groping, uncertain, I at last found my identity, and after seeing my thoughts and feelings repeated in others, I gradually constructed my world of men and of God. As I read and study, I find that this is what the rest of the race has done. Man looks within himself and in time finds the measure and the meaning of the universe.&quot;</div><br/></div></div><div id="41889794" class="c"><input type="checkbox" id="c-41889794" checked=""/><div class="controls bullet"><span class="by">codersfocus</span><span>|</span><a href="#41889942">prev</a><span>|</span><a href="#41889815">next</a><span>|</span><label class="collapse" for="c-41889794">[-]</label><label class="expand" for="c-41889794">[2 more]</label></div><br/><div class="children"><div class="content">While not essential for thought, language is a very important tool in shaping and sharing thoughts.<p>Another related tool is religion (for emotions instead of thoughts,) which funnily enough faces the same divergence language does.<p>Right now society that calls itself &quot;secular&quot; simply does not understand the role of religion, and its importance in society.<p>To be clear, I don&#x27;t belong to any religion, I am saying one needs to be invented for people who are currently &quot;secular.&quot;<p>In fact, you have the disorganized aspects of religion already. All one needs to spot these are to look at the aspects that attempt to systematize or control our feelings. Mass media, celebrities for example.<p>Instead of letting capitalistic forces create a pseudoreligion for society, it&#x27;s better if people come together and organize something healthier, intentionally.</div><br/><div id="41890673" class="c"><input type="checkbox" id="c-41890673" checked=""/><div class="controls bullet"><span class="by">akomtu</span><span>|</span><a href="#41889794">parent</a><span>|</span><a href="#41889815">next</a><span>|</span><label class="collapse" for="c-41890673">[-]</label><label class="expand" for="c-41890673">[1 more]</label></div><br/><div class="children"><div class="content">Materialism is such a religion. It&#x27;s sciency and emotion-free, so it appeals to the secular minds.</div><br/></div></div></div></div><div id="41889815" class="c"><input type="checkbox" id="c-41889815" checked=""/><div class="controls bullet"><span class="by">habitue</span><span>|</span><a href="#41889794">prev</a><span>|</span><a href="#41891055">next</a><span>|</span><label class="collapse" for="c-41889815">[-]</label><label class="expand" for="c-41889815">[7 more]</label></div><br/><div class="children"><div class="content">Language may not be essential for thought, (most of us have the experience of an idea occurring to us that we struggle to put into words), but language acts as a regularization mechanism on thoughts.<p>Serializing much higher dimensional freeform thoughts into language is a very lossy process, and this kinda ensures that mostly only the core bits get translated. Think of times when someone gets an idea you&#x27;re trying to convey, but you realize they&#x27;re missing some critical context you forgot to share. It takes some activation energy to add that bit of context, so if it seems like they mostly get what you&#x27;re saying, you skip it. Over time, transferring ideas from one person to the next, they tend towards a very compressed form because language is expensive.<p>This process also works on your own thoughts. Thinking out loud performs a similar role, it compresses the hell out of the thought or else it remains inexpressible. Now imagine repeated stages of compressing through language, allowing ideas to form from that compressed form, and then compressing those ideas in turn. It&#x27;s a bit of a recursive process and language is in the middle of it.</div><br/><div id="41890458" class="c"><input type="checkbox" id="c-41890458" checked=""/><div class="controls bullet"><span class="by">pazimzadeh</span><span>|</span><a href="#41889815">parent</a><span>|</span><a href="#41890360">next</a><span>|</span><label class="collapse" for="c-41890458">[-]</label><label class="expand" for="c-41890458">[3 more]</label></div><br/><div class="children"><div class="content">Communication of thought is a whole different question. Either way you&#x27;re making a lot of strong claims without support?<p>&gt; this kinda ensures that mostly only the core bits get translated<p>The kinda is doing a lot here. Many times the very act of trying to communicate a thought colors&#x2F;corrupts the main point and gives only one perspective or a snapshot of the overall thought. There&#x27;s a reason why they say a picture is worth a thousand words. Except the mind can conjure much more than a static picture. The mind can also hold the idea and the exceptions to the idea in one coherent model. For me this can be especially apparent when taking psychedelics and finding that trying to communicate some thoughts with words requires constant babbling to keep refining the last few sentences, ad libidum. There are exceptions of course, like for simple ideas.</div><br/><div id="41890984" class="c"><input type="checkbox" id="c-41890984" checked=""/><div class="controls bullet"><span class="by">habitue</span><span>|</span><a href="#41889815">root</a><span>|</span><a href="#41890458">parent</a><span>|</span><a href="#41890360">next</a><span>|</span><label class="collapse" for="c-41890984">[-]</label><label class="expand" for="c-41890984">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Many times the very act of trying to communicate a thought colors&#x2F;corrupts the main point and gives only one perspective or a snapshot of the overall thought. There&#x27;s a reason why they say a picture is worth a thousand words.<p>Yeah! Sometimes the thought isnt compressible and language doesnt help. But a lot of times it is, and it does</div><br/><div id="41892110" class="c"><input type="checkbox" id="c-41892110" checked=""/><div class="controls bullet"><span class="by">pazimzadeh</span><span>|</span><a href="#41889815">root</a><span>|</span><a href="#41890984">parent</a><span>|</span><a href="#41890360">next</a><span>|</span><label class="collapse" for="c-41892110">[-]</label><label class="expand" for="c-41892110">[1 more]</label></div><br/><div class="children"><div class="content">Does language actually &#x27;help&#x27;, or is it just the best we have? e.g. would running a thought through language have any benefit in a world where telepathy existed</div><br/></div></div></div></div></div></div><div id="41890360" class="c"><input type="checkbox" id="c-41890360" checked=""/><div class="controls bullet"><span class="by">ujikoluk</span><span>|</span><a href="#41889815">parent</a><span>|</span><a href="#41890458">prev</a><span>|</span><a href="#41890579">next</a><span>|</span><label class="collapse" for="c-41890360">[-]</label><label class="expand" for="c-41890360">[1 more]</label></div><br/><div class="children"><div class="content">Yes, dimension reduction.</div><br/></div></div><div id="41890579" class="c"><input type="checkbox" id="c-41890579" checked=""/><div class="controls bullet"><span class="by">akomtu</span><span>|</span><a href="#41889815">parent</a><span>|</span><a href="#41890360">prev</a><span>|</span><a href="#41891055">next</a><span>|</span><label class="collapse" for="c-41890579">[-]</label><label class="expand" for="c-41890579">[2 more]</label></div><br/><div class="children"><div class="content">Imo, that&#x27;s the essense of reasoning. Limited memory and slow communication channels force us to create compact, but expressive models of reality. LLMs, on the other hand, have all the memory in the world and their model of reality is a piece-wise interpolation of the huge training dataset. Why invent grammar rules if you can keep the entire dictionary in mind?</div><br/><div id="41892332" class="c"><input type="checkbox" id="c-41892332" checked=""/><div class="controls bullet"><span class="by">mcswell</span><span>|</span><a href="#41889815">root</a><span>|</span><a href="#41890579">parent</a><span>|</span><a href="#41891055">next</a><span>|</span><label class="collapse" for="c-41892332">[-]</label><label class="expand" for="c-41892332">[1 more]</label></div><br/><div class="children"><div class="content">Why do LLMs (or rather similar models that draw pictures) keep getting the number of fingers on the human hand wrong, or show two people&#x27;s arms or legs merging?  Or in computer-created videos, fail at object preservation?  It seems to me they do <i>not</i> have a model of the world, only an imperfect model of pictures they&#x27;ve seen.</div><br/></div></div></div></div></div></div><div id="41891055" class="c"><input type="checkbox" id="c-41891055" checked=""/><div class="controls bullet"><span class="by">jostmey</span><span>|</span><a href="#41889815">prev</a><span>|</span><a href="#41885384">next</a><span>|</span><label class="collapse" for="c-41891055">[-]</label><label class="expand" for="c-41891055">[2 more]</label></div><br/><div class="children"><div class="content">Progress with LLMs would seem to support the title. The language abilities of LLMs does not seem to lead to higher thought, so there must be additional processes that are required for higher thought or process that don’t depend on language</div><br/><div id="41892305" class="c"><input type="checkbox" id="c-41892305" checked=""/><div class="controls bullet"><span class="by">mcswell</span><span>|</span><a href="#41891055">parent</a><span>|</span><a href="#41885384">next</a><span>|</span><label class="collapse" for="c-41892305">[-]</label><label class="expand" for="c-41892305">[1 more]</label></div><br/><div class="children"><div class="content">You may be right, but there is another hypothesis that would need to be rejected:  at question is whether LLMs &quot;do&quot; language the same way we do.  For certain they learn language much differently, with orders of magnitude more input data.  It could be that they just string sentence fragments together, whereas (by hypothesis) we construct sentences hierarchically.  The internal representation of semantics might also be different, more compositional in humans.<p>If I had time and free use of an LLM, I&#x27;d like to investigate how well it understands constructional synonymy, like &quot;the red car&quot; and &quot;the car that is red&quot; and &quot;John saw a car on the street yesterday.  It was red.&quot;  I guess models that can draw pictures can be used to test this sort of thing--surely someone has looked into this?</div><br/></div></div></div></div><div id="41885384" class="c"><input type="checkbox" id="c-41885384" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#41891055">prev</a><span>|</span><a href="#41889520">next</a><span>|</span><label class="collapse" for="c-41885384">[-]</label><label class="expand" for="c-41885384">[40 more]</label></div><br/><div class="children"><div class="content">For those who can’t and don’t think in words this is unsurprising.</div><br/><div id="41889769" class="c"><input type="checkbox" id="c-41889769" checked=""/><div class="controls bullet"><span class="by">cassianoleal</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41890199">next</a><span>|</span><label class="collapse" for="c-41889769">[-]</label><label class="expand" for="c-41889769">[3 more]</label></div><br/><div class="children"><div class="content">I remember back in school, a language teacher once was trying to convey the importance of language.  One of his main arguments was that we needed words and languages in order to think.  I still recall my disbelief.<p>I spent the next few days trying to understand how that process worked.  I would force myself to think in words and sentences.  It was incredibly limiting!  So slow and lacking in images, in abstract relationships between ideas and sensations.<p>It took me another few years to realise that many people actually depend on those structures in order to produce any thought and idea.</div><br/><div id="41891285" class="c"><input type="checkbox" id="c-41891285" checked=""/><div class="controls bullet"><span class="by">bonoboTP</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889769">parent</a><span>|</span><a href="#41889984">next</a><span>|</span><label class="collapse" for="c-41891285">[-]</label><label class="expand" for="c-41891285">[1 more]</label></div><br/><div class="children"><div class="content">I think people are just using the word &quot;think&quot; differently. They may have picked up a different meaning for that verb than you. For them, thinking == inner vocalization. It&#x27;s just a different definition. They would not call imagining things or daydreaming or musing or planning action steps as &quot;thinking&quot;.<p>Also, many people simply repeat facts they were told. &quot;We need words to think&quot; is simply a phrase this person learned, a fact to recite in school settings. It doesn&#x27;t mean they deeply reflected on this statement or compared it with their experience.</div><br/></div></div><div id="41889984" class="c"><input type="checkbox" id="c-41889984" checked=""/><div class="controls bullet"><span class="by">truculent</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889769">parent</a><span>|</span><a href="#41891285">prev</a><span>|</span><a href="#41890199">next</a><span>|</span><label class="collapse" for="c-41889984">[-]</label><label class="expand" for="c-41889984">[1 more]</label></div><br/><div class="children"><div class="content">I once realised that, for me, subvocalising thoughts was a way to keep something &quot;in RAM&quot;, while some other thoughts went elsewhere, or developed something else. Perhaps slower speed helps in that respect?</div><br/></div></div></div></div><div id="41890199" class="c"><input type="checkbox" id="c-41890199" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41889769">prev</a><span>|</span><a href="#41889604">next</a><span>|</span><label class="collapse" for="c-41890199">[-]</label><label class="expand" for="c-41890199">[2 more]</label></div><br/><div class="children"><div class="content">Right, I think it&#x27;s less than 50% of people that have an &quot;inner voice&quot; - using language to think.<p>Other animals with at best very limited language, are still highly intelligent and capable of reasoning - apes, dogs, rats, crows, ...</div><br/><div id="41892337" class="c"><input type="checkbox" id="c-41892337" checked=""/><div class="controls bullet"><span class="by">mcswell</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41890199">parent</a><span>|</span><a href="#41889604">next</a><span>|</span><label class="collapse" for="c-41892337">[-]</label><label class="expand" for="c-41892337">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Highly intelligent&quot; is not a word to be used with apes, dogs, rats or crows.</div><br/></div></div></div></div><div id="41889604" class="c"><input type="checkbox" id="c-41889604" checked=""/><div class="controls bullet"><span class="by">kjkjadksj</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41890199">prev</a><span>|</span><a href="#41889753">next</a><span>|</span><label class="collapse" for="c-41889604">[-]</label><label class="expand" for="c-41889604">[1 more]</label></div><br/><div class="children"><div class="content">Could you imagine the impossibility of riding a bike if you had to consciously put words to every action before you did it?</div><br/></div></div><div id="41889753" class="c"><input type="checkbox" id="c-41889753" checked=""/><div class="controls bullet"><span class="by">Razengan</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41889604">prev</a><span>|</span><a href="#41889537">next</a><span>|</span><label class="collapse" for="c-41889753">[-]</label><label class="expand" for="c-41889753">[23 more]</label></div><br/><div class="children"><div class="content">Can you <i>count</i> without using a &quot;language&quot;?<p>Try it now: Tap your hand on the desk randomly. Can you recall how many times you did it without &quot;saying&quot; a sequence in your head like &quot;1, 2, 3&quot; or &quot;A, B, C&quot; etc?<p>If yes, how far can you count? With a language it&#x27;s effectively infinite. You could theoretically go up to &quot;1 million 5 hundred 43 thousand, 2 hundred and 10&quot; and effortlessly know what comes next.</div><br/><div id="41889888" class="c"><input type="checkbox" id="c-41889888" checked=""/><div class="controls bullet"><span class="by">datameta</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41889923">next</a><span>|</span><label class="collapse" for="c-41889888">[-]</label><label class="expand" for="c-41889888">[4 more]</label></div><br/><div class="children"><div class="content">I can remember the sequence of sounds and like a delay line repeat that sequence in my head. This becomes easier the more distinguishable the taps are or the more of a cadence variability there is. But if it is a longer sequence I compress it by remembering an analogue like so: doo doo da doo da doo da da doo (reminiscent of morse code, or a kind of auditory binary). Would we consider this language? I think in the colloquial sense no, but it is essentially a machine language equivalent.<p>For context I have both abstract &quot;multimedia&quot; thought processes and hypervisor-like internal narrative depending on the nature of the experience or task.</div><br/><div id="41890373" class="c"><input type="checkbox" id="c-41890373" checked=""/><div class="controls bullet"><span class="by">card_zero</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889888">parent</a><span>|</span><a href="#41891526">next</a><span>|</span><label class="collapse" for="c-41890373">[-]</label><label class="expand" for="c-41890373">[1 more]</label></div><br/><div class="children"><div class="content">Do you also have some noise for mathematical operations, such as raising a number to a power, and for equals? So doo doo da <i>ugh</i> doo doo <i>feh</i> doo doo da doo da doo da da doo?<p>...maybe I do this sometimes myself. Remembering the proper names of things is effort.</div><br/></div></div><div id="41891526" class="c"><input type="checkbox" id="c-41891526" checked=""/><div class="controls bullet"><span class="by">pineaux</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889888">parent</a><span>|</span><a href="#41890373">prev</a><span>|</span><a href="#41889923">next</a><span>|</span><label class="collapse" for="c-41891526">[-]</label><label class="expand" for="c-41891526">[2 more]</label></div><br/><div class="children"><div class="content">I think this is what language is. It&#x27;s a sequence rememberance system.</div><br/><div id="41891876" class="c"><input type="checkbox" id="c-41891876" checked=""/><div class="controls bullet"><span class="by">Razengan</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41891526">parent</a><span>|</span><a href="#41889923">next</a><span>|</span><label class="collapse" for="c-41891876">[-]</label><label class="expand" for="c-41891876">[1 more]</label></div><br/><div class="children"><div class="content">Oh no… That would vindicate the chatbots..</div><br/></div></div></div></div></div></div><div id="41889923" class="c"><input type="checkbox" id="c-41889923" checked=""/><div class="controls bullet"><span class="by">jwarden</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41889888">prev</a><span>|</span><a href="#41889829">next</a><span>|</span><label class="collapse" for="c-41889923">[-]</label><label class="expand" for="c-41889923">[2 more]</label></div><br/><div class="children"><div class="content">I can. But I do this by visualizing the taps as a group. I don&#x27;t have to label them with a number. I can see them in my mind, thus recalling the taps. If I tap with any sort of rhythm I can see the rhythm in the way they are laid out in my mind and this helps with recollection.<p>If I want to translate this knowledge into a number, I need to count the taps I am seeing in my head. At that point I do need to think of the word for the number.<p>I could even do computations on these items in my mind, imagine dividing them into two groups for instance, without ever having to link them to words until I am ready to do something with the result, such as write down the number of items in each group.</div><br/><div id="41892813" class="c"><input type="checkbox" id="c-41892813" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889923">parent</a><span>|</span><a href="#41889829">next</a><span>|</span><label class="collapse" for="c-41892813">[-]</label><label class="expand" for="c-41892813">[1 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s like how I memorize sheet music, visual groups and subgroups of notes, and yet sheet music is formally linguistic nevertheless. So in such debates I think a tricky pitfall to avoid is that all data structures are essentially linguistic as well.</div><br/></div></div></div></div><div id="41889829" class="c"><input type="checkbox" id="c-41889829" checked=""/><div class="controls bullet"><span class="by">j_bum</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41889923">prev</a><span>|</span><a href="#41890908">next</a><span>|</span><label class="collapse" for="c-41889829">[-]</label><label class="expand" for="c-41889829">[3 more]</label></div><br/><div class="children"><div class="content">This is highly anecdotal, but when I lift weights, I  have an “intuition” about the number of reps I’ve performed without consciously counting them.<p>An example of this would be when I’m lifting weights with a friend and am lost in the set&#x2F;focusing on mind-muscle connection, and as a result I forget to count my reps. I am usually quite accurate when I verify with my lifting partner the number of reps done&#x2F;remaining.<p>As OP mentioned, many people have <i>no</i> internal speech, otherwise known as anendophasia, yet can still do everything anyone with an internal dialogue can do.<p>Similarly for me, I can do “mental object rotation” tasks even though I have aphantasia.</div><br/><div id="41889915" class="c"><input type="checkbox" id="c-41889915" checked=""/><div class="controls bullet"><span class="by">datameta</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889829">parent</a><span>|</span><a href="#41889874">next</a><span>|</span><label class="collapse" for="c-41889915">[-]</label><label class="expand" for="c-41889915">[1 more]</label></div><br/><div class="children"><div class="content">Can you expand on your last sentence? The notion is fascinating to me.</div><br/></div></div><div id="41889874" class="c"><input type="checkbox" id="c-41889874" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889829">parent</a><span>|</span><a href="#41889915">prev</a><span>|</span><a href="#41890908">next</a><span>|</span><label class="collapse" for="c-41889874">[-]</label><label class="expand" for="c-41889874">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I have an “intuition” about the number of reps I’ve performed without consciously counting them.</i><p>This is known as subitising.</div><br/></div></div></div></div><div id="41890908" class="c"><input type="checkbox" id="c-41890908" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41889829">prev</a><span>|</span><a href="#41892853">next</a><span>|</span><label class="collapse" for="c-41890908">[-]</label><label class="expand" for="c-41890908">[3 more]</label></div><br/><div class="children"><div class="content">I don’t make a sound or word in my mind but I definitely keep track of the number.  My thinking is definitely structured and there are things in my thoughts but there is no words or voice. I also can’t see images in my mind either. I’ve no idea what an inner monologue or the minds eye is like. I have however over the years found ways to produce these experiences in a way of my own. I found for instance some rough visualization was helpful in doing multi variate calculus but it’s very difficult and took a lot of practice. I’ve also been able to simulate language in my mind to help me practice difficult conversations but it’s really difficult and not distinct.<p>I would note though I have a really difficult time with arithmetic and mechanical tasks like counting. Mostly I just lose attention. Perhaps an inner voice would help if it became something that kept a continuity of thought.</div><br/><div id="41891254" class="c"><input type="checkbox" id="c-41891254" checked=""/><div class="controls bullet"><span class="by">bonoboTP</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41890908">parent</a><span>|</span><a href="#41891894">next</a><span>|</span><label class="collapse" for="c-41891254">[-]</label><label class="expand" for="c-41891254">[1 more]</label></div><br/><div class="children"><div class="content">Can you draft a sentence (with all the words precisely determined) in your mind before you say it or you write it down? Can you &quot;rehearse&quot; saying it without moving your tongue or mouth? If yes, that&#x27;s pretty much an &quot;inner voice&quot;.</div><br/></div></div><div id="41891894" class="c"><input type="checkbox" id="c-41891894" checked=""/><div class="controls bullet"><span class="by">Razengan</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41890908">parent</a><span>|</span><a href="#41891254">prev</a><span>|</span><a href="#41892853">next</a><span>|</span><label class="collapse" for="c-41891894">[-]</label><label class="expand" for="c-41891894">[1 more]</label></div><br/><div class="children"><div class="content">This is So unrelatable lol. Imagine how different alien minds would be!!</div><br/></div></div></div></div><div id="41892853" class="c"><input type="checkbox" id="c-41892853" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41890908">prev</a><span>|</span><a href="#41891243">next</a><span>|</span><label class="collapse" for="c-41892853">[-]</label><label class="expand" for="c-41892853">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Can you count without using a &quot;language&quot;?<p>Yes. Seriously, these kind of questions are so surprising. It tells you that everyone&#x27;s experience is just a little different.</div><br/></div></div><div id="41891243" class="c"><input type="checkbox" id="c-41891243" checked=""/><div class="controls bullet"><span class="by">bonoboTP</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41892853">prev</a><span>|</span><a href="#41889806">next</a><span>|</span><label class="collapse" for="c-41891243">[-]</label><label class="expand" for="c-41891243">[2 more]</label></div><br/><div class="children"><div class="content">I can imagine the numbers as figures (I mean that the shape of the characters 1, 2 etc), or the patterns on a dice in sequence.<p>This is a parallel stream, because if I count with imagined pictures, then I can speak and listen to someone talking without it disturbing the process. If I do it with subvocalization, then doing other speech&#x2F;language related things would disturb the counting.</div><br/><div id="41891283" class="c"><input type="checkbox" id="c-41891283" checked=""/><div class="controls bullet"><span class="by">aeonik</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41891243">parent</a><span>|</span><a href="#41889806">next</a><span>|</span><label class="collapse" for="c-41891283">[-]</label><label class="expand" for="c-41891283">[1 more]</label></div><br/><div class="children"><div class="content">Wow I&#x27;ve never tried this before, and I feel like this is way easier than using words.</div><br/></div></div></div></div><div id="41889806" class="c"><input type="checkbox" id="c-41889806" checked=""/><div class="controls bullet"><span class="by">kachnuv_ocasek</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41891243">prev</a><span>|</span><a href="#41890312">next</a><span>|</span><label class="collapse" for="c-41889806">[-]</label><label class="expand" for="c-41889806">[4 more]</label></div><br/><div class="children"><div class="content">Interestingly, I feel like I can &quot;feel&quot; small numbers (up to 4 or 5) easier than than thinking about them as objects in a language.</div><br/><div id="41889907" class="c"><input type="checkbox" id="c-41889907" checked=""/><div class="controls bullet"><span class="by">082349872349872</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889806">parent</a><span>|</span><a href="#41889976">next</a><span>|</span><label class="collapse" for="c-41889907">[-]</label><label class="expand" for="c-41889907">[2 more]</label></div><br/><div class="children"><div class="content">By feel, I can without language or counting, play mostly<p><pre><code>  X . . X . . X . . . X . X . . .
</code></pre>
and every so often switch out for variations, eg:<p><pre><code>  X . . X . . X . X . . . X . . .
</code></pre>
or<p><pre><code>  X . . . X . . . . . X . X . . .
</code></pre>
but I&#x27;m no good for playing polyrhythms, which many other people can do, and I believe they must also do so more by feel than by counting.</div><br/><div id="41890131" class="c"><input type="checkbox" id="c-41890131" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889907">parent</a><span>|</span><a href="#41889976">next</a><span>|</span><label class="collapse" for="c-41890131">[-]</label><label class="expand" for="c-41890131">[1 more]</label></div><br/><div class="children"><div class="content">Practice a few polyrhythms, get used to things like:<p><pre><code>  X . X X X . X . X X X .
  A . . A . . A . . A . .
  B . B . B . B . B . B .
</code></pre>
and:<p><pre><code>  X . . X . X X X . X X . X . X X . . X . X X . . X X . X X . X . . X . X X . . X X . X . . X . . X X X X . . X X X X . . X . . X . X X . . X X . X . . X . X X . X X . . X X . X . . X X . X . X X . X X X . X . .
  A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . . A . . . .
  B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . . B . . . . . .
  C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . . C . .
</code></pre>
Learn to do them with one limb (or finger) per line, and also with all the lines on the same limb (or finger). And then suddenly, they&#x27;ll start to feel intuitive, and you&#x27;ll be able to do them by feel. (It&#x27;s a bit like scales.)</div><br/></div></div></div></div><div id="41889976" class="c"><input type="checkbox" id="c-41889976" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889806">parent</a><span>|</span><a href="#41889907">prev</a><span>|</span><a href="#41890312">next</a><span>|</span><label class="collapse" for="c-41889976">[-]</label><label class="expand" for="c-41889976">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a well known phenomenon! I will drop this link here in case you are not familiar with it:<p><a href="https:&#x2F;&#x2F;www.sciencealert.com&#x2F;theres-a-big-difference-in-how-your-brain-processes-the-numbers-4-and-5" rel="nofollow">https:&#x2F;&#x2F;www.sciencealert.com&#x2F;theres-a-big-difference-in-how-...</a></div><br/></div></div></div></div><div id="41890312" class="c"><input type="checkbox" id="c-41890312" checked=""/><div class="controls bullet"><span class="by">nemo</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41889806">prev</a><span>|</span><a href="#41890509">next</a><span>|</span><label class="collapse" for="c-41890312">[-]</label><label class="expand" for="c-41890312">[2 more]</label></div><br/><div class="children"><div class="content">Many animals can do some form of counting of small numbers where there&#x27;s no connection to language possible.</div><br/><div id="41892346" class="c"><input type="checkbox" id="c-41892346" checked=""/><div class="controls bullet"><span class="by">mcswell</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41890312">parent</a><span>|</span><a href="#41890509">next</a><span>|</span><label class="collapse" for="c-41892346">[-]</label><label class="expand" for="c-41892346">[1 more]</label></div><br/><div class="children"><div class="content">One, two, ...many.</div><br/></div></div></div></div><div id="41890509" class="c"><input type="checkbox" id="c-41890509" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889753">parent</a><span>|</span><a href="#41890312">prev</a><span>|</span><a href="#41889537">next</a><span>|</span><label class="collapse" for="c-41890509">[-]</label><label class="expand" for="c-41890509">[1 more]</label></div><br/><div class="children"><div class="content">An important note. If you&#x27;re hearing your voice in your head doing this, that&#x27;s subvocalisation and it&#x27;s basically just saying it out loud, the instruction is still sent to your vocal chords<p>It&#x27;s the equivalent of &lt;thinking&gt; tags for LLM output.</div><br/></div></div></div></div><div id="41889537" class="c"><input type="checkbox" id="c-41889537" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41889753">prev</a><span>|</span><a href="#41889526">next</a><span>|</span><label class="collapse" for="c-41889537">[-]</label><label class="expand" for="c-41889537">[9 more]</label></div><br/><div class="children"><div class="content">How would someone think in words? You mean the words in the pictures or...?</div><br/><div id="41889661" class="c"><input type="checkbox" id="c-41889661" checked=""/><div class="controls bullet"><span class="by">vivekd</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889537">parent</a><span>|</span><a href="#41889619">next</a><span>|</span><label class="collapse" for="c-41889661">[-]</label><label class="expand" for="c-41889661">[6 more]</label></div><br/><div class="children"><div class="content">I think in words.  For me during thought there is a literal voice in my putting my thoughts into words.</div><br/><div id="41889779" class="c"><input type="checkbox" id="c-41889779" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889661">parent</a><span>|</span><a href="#41891617">next</a><span>|</span><label class="collapse" for="c-41889779">[-]</label><label class="expand" for="c-41889779">[1 more]</label></div><br/><div class="children"><div class="content">I have the standard internal monologue many people report, but I&#x27;ve never put much stock in the &quot;words are <i>necessary</i> for thought&quot; because while I think a lot in words, I also do a lot of thinking in not-words.<p>We recently put the project I&#x27;ve been working on for the last year out into the field for the first time. As was fully expected, some bugs emerged. I needed to solve one of them. I designed a system in my head for spawning off child processes based on the parent process to do certain distinct types of work in a way that gives us access to OS process-level controls over the work, and then got about halfway through implementing it. Little to none of this design involved &quot;words&quot;. I can&#x27;t even say it involved much &quot;visualization&quot; either, except maybe in a very loose sense. It&#x27;s hard to describe in words how I didn&#x27;t use words but I&#x27;ve been programming for long enough that I pretty much just directly work in system-architecture space for such designs, especially relatively small ones like that that are just a couple day&#x27;s work.<p>Things like pattern language advocates aren&#x27;t wrong that it can still be useful to put such things into words, especially for communication purposes, but I know through direct personal experience that words are not a <i>necessary</i> component of even quite complicated thought.<p>&quot;Subjective experience reports are always tricky, jerf. How do you know that you aren&#x27;t fooling yourself about not using words?&quot; A good and reasonable question, to which my answer is, I don&#x27;t even <i>have</i> words for the sort of design I was doing. Some, from the aforementioned pattern languages, yes, but not in general. So I don&#x27;t think I was just fooling myself on the grounds that even if I tried to serialize what I did directly into English, a transliteration rather than a translation, I don&#x27;t think I could. I don&#x27;t have one.<p>I&#x27;m also not claiming to be special. I don&#x27;t know the percentages but I&#x27;m sure many people do this too.</div><br/></div></div><div id="41891617" class="c"><input type="checkbox" id="c-41891617" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889661">parent</a><span>|</span><a href="#41889779">prev</a><span>|</span><a href="#41889777">next</a><span>|</span><label class="collapse" for="c-41891617">[-]</label><label class="expand" for="c-41891617">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m an idiot. I thought this meant, for some reason unknown to me... written words, something I couldn&#x27;t imagine being able to think in. Spoken words, sure.</div><br/></div></div><div id="41889777" class="c"><input type="checkbox" id="c-41889777" checked=""/><div class="controls bullet"><span class="by">BarryMilo</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889661">parent</a><span>|</span><a href="#41891617">prev</a><span>|</span><a href="#41892338">next</a><span>|</span><label class="collapse" for="c-41889777">[-]</label><label class="expand" for="c-41889777">[1 more]</label></div><br/><div class="children"><div class="content">Are there really people who don&#x27;t know about inner monologues?</div><br/></div></div><div id="41892338" class="c"><input type="checkbox" id="c-41892338" checked=""/><div class="controls bullet"><span class="by">perryizgr8</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889661">parent</a><span>|</span><a href="#41889777">prev</a><span>|</span><a href="#41890037">next</a><span>|</span><label class="collapse" for="c-41892338">[-]</label><label class="expand" for="c-41892338">[1 more]</label></div><br/><div class="children"><div class="content">So if you want to look at your phone there&#x27;s a voice going &quot;I shall pick up my phone and swipe the lock away now.&quot;? Trying to understand if ALL thinking is in words or some subset.</div><br/></div></div><div id="41890037" class="c"><input type="checkbox" id="c-41890037" checked=""/><div class="controls bullet"><span class="by">binary132</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889661">parent</a><span>|</span><a href="#41892338">prev</a><span>|</span><a href="#41889619">next</a><span>|</span><label class="collapse" for="c-41890037">[-]</label><label class="expand" for="c-41890037">[1 more]</label></div><br/><div class="children"><div class="content">Like, at the speed of speech?</div><br/></div></div></div></div><div id="41889619" class="c"><input type="checkbox" id="c-41889619" checked=""/><div class="controls bullet"><span class="by">mjochim</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889537">parent</a><span>|</span><a href="#41889661">prev</a><span>|</span><a href="#41889526">next</a><span>|</span><label class="collapse" for="c-41889619">[-]</label><label class="expand" for="c-41889619">[2 more]</label></div><br/><div class="children"><div class="content">By &quot;hearing&quot; words, sentences, dialogues in their mind. Just like imagining a picture, but audio instead.</div><br/><div id="41889719" class="c"><input type="checkbox" id="c-41889719" checked=""/><div class="controls bullet"><span class="by">Teever</span><span>|</span><a href="#41885384">root</a><span>|</span><a href="#41889619">parent</a><span>|</span><a href="#41889526">next</a><span>|</span><label class="collapse" for="c-41889719">[-]</label><label class="expand" for="c-41889719">[1 more]</label></div><br/><div class="children"><div class="content">but words, sentences, and dialogues are all features of language.</div><br/></div></div></div></div></div></div><div id="41889526" class="c"><input type="checkbox" id="c-41889526" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41885384">parent</a><span>|</span><a href="#41889537">prev</a><span>|</span><a href="#41889520">next</a><span>|</span><label class="collapse" for="c-41889526">[-]</label><label class="expand" for="c-41889526">[1 more]</label></div><br/><div class="children"><div class="content">absolutely !</div><br/></div></div></div></div><div id="41889520" class="c"><input type="checkbox" id="c-41889520" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41885384">prev</a><span>|</span><label class="collapse" for="c-41889520">[-]</label><label class="expand" for="c-41889520">[1 more]</label></div><br/><div class="children"><div class="content">more proof that we need more than LLMs to build LRMs:
<a href="https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;drop-o1-preview-try-this-alternative" rel="nofollow">https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;drop-o1-preview-try-this-alternati...</a></div><br/></div></div></div></div></div></div></div></body></html>