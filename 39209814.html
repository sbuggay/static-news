<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706778072749" as="style"/><link rel="stylesheet" href="styles.css?v=1706778072749"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://deepseekcoder.github.io/">DeepSeek Coder: Let the Code Write Itself</a> <span class="domain">(<a href="https://deepseekcoder.github.io">deepseekcoder.github.io</a>)</span></div><div class="subtext"><span>fintechie</span> | <span>49 comments</span></div><br/><div><div id="39211923" class="c"><input type="checkbox" id="c-39211923" checked=""/><div class="controls bullet"><span class="by">rickstanley</span><span>|</span><a href="#39211055">next</a><span>|</span><label class="collapse" for="c-39211923">[-]</label><label class="expand" for="c-39211923">[18 more]</label></div><br/><div class="children"><div class="content">Hello, I would like to take this opportunity and ask for help here, about using A.I. with my own codebase.<p>Context: 
I missed [almost] the entire A.I. wave, but I knew that one day I would have to learn something about and&#x2F;or use it. That day has come. I&#x27;m allocated in one team, that is migrating to another engine, let&#x27;s say &quot;engine A → engine B&quot;. We are looking from the perspective of A, to map the entries for B (inbound), and after the request to B is returned, we map back to A&#x27;s model (outbound). This is a chore, and much of the work is repetitive, but it comes with its edge cases that we need to look out for and unfortunately there isn&#x27;t a solid foundation of patterns apart from the Domain-driven design (DDD) thing. It seemed like a good use case for an A.I.<p>Attempts: I began by asking to ChatGPT and Bard, with questions similar to: &quot;how to train LLM on own codebase&quot; and &quot;how to get started with prompt engineering using own codebase&quot;.<p>I concluded that, fine-tuning is expensive, for large models, unrealistic for my RTX 3060 with 6Gb VRAM, no surprise there; so, I searched here, in Hacker News, for keywords like &quot;llama&quot;, &quot;fine-tuning&quot;, &quot;local machine&quot;, etc, and I found out about ollama and DeepSeek.<p>I tried both ollama and DeepSeek, the former was slow but not as slow as the latter, which was <i>dead slow</i>, using a 13B model. I tried the 6&#x2F;7B model (I think it was codellama) and I got reasonable results and speed. After feeding it some data, I was on my way to try and train on the codebase when a friend of mine came and suggested that I use Retrieval-Augmented Generation (RAG), I have yet to try it, with a setup Langchain + Ollama.<p>Any thoughts, suggestions or experiences to share?<p>I&#x27;d appreciate it.</div><br/><div id="39212923" class="c"><input type="checkbox" id="c-39212923" checked=""/><div class="controls bullet"><span class="by">WeMoveOn</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212298">next</a><span>|</span><label class="collapse" for="c-39212923">[-]</label><label class="expand" for="c-39212923">[1 more]</label></div><br/><div class="children"><div class="content">&gt; much of the work is repetitive, but it comes with its edge cases<p>for the repetitive stuff, just use copilot embedded in whatever editor you use.<p>the edge cases are tricky, to actually avoid these the model would need an understanding of both the use case (which is easy to describe to the model) and the code base itself (which is difficult, since description&#x2F;docstring is not enough to capture the complex behaviors that can arise from interactions between parts of your codebase).<p>idk how you would train&#x2F;finetune a model to somehow have this understanding of your code base, I doubt just doing next token prediction would help, you&#x27;d likely have to create chat data discussing the intricacies of your code base and do DPO&#x2F;RLFH to bake it into your model.<p>look into techniques like qlora that&#x27;ll reduce the needed memory during tuning. look into platforms like vast ai to rent GPUs for cheap.<p>RAG&#x2F;Agents could be useful but probably not. could store info about functions in your codebase such as the signature, the function it calls, its docstring, and known edge cases associated with it. if you don&#x27;t have docstrings using a LLM to generate them is feasible.</div><br/></div></div><div id="39212298" class="c"><input type="checkbox" id="c-39212298" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212923">prev</a><span>|</span><a href="#39212341">next</a><span>|</span><label class="collapse" for="c-39212298">[-]</label><label class="expand" for="c-39212298">[2 more]</label></div><br/><div class="children"><div class="content">You could try using aider [0], which is my open source ai coding tool. You need an OpenAI API key, and aider supports any of the GPT 3.5 or 4 models. Aider has features that make it work well with existing code bases, like git integration and a &quot;repository map&quot;. The repo map is used to send GPT-4 a distilled map of your code base, focused specifically on the coding task at hand [1]. This provides useful context so that GPT can understand the relevant parts of the larger code base when making a specific change.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;paul-gauthier&#x2F;aider">https:&#x2F;&#x2F;github.com&#x2F;paul-gauthier&#x2F;aider</a><p>[1] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;repomap.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;repomap.html</a></div><br/><div id="39213920" class="c"><input type="checkbox" id="c-39213920" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212298">parent</a><span>|</span><a href="#39212341">next</a><span>|</span><label class="collapse" for="c-39213920">[-]</label><label class="expand" for="c-39213920">[1 more]</label></div><br/><div class="children"><div class="content">I second this. Great tool. I always plug your tool in these threads too when relevant. The tree-sitter repo map was a great change. Thank you.</div><br/></div></div></div></div><div id="39212341" class="c"><input type="checkbox" id="c-39212341" checked=""/><div class="controls bullet"><span class="by">rickstanley</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212298">prev</a><span>|</span><a href="#39212219">next</a><span>|</span><label class="collapse" for="c-39212341">[-]</label><label class="expand" for="c-39212341">[1 more]</label></div><br/><div class="children"><div class="content">Ever since I started doing this exercise, I&#x27;ve been excited about the future, with LLMs helping us.<p>Now I definitely share Linus&#x27; sentiment [1] on this topic.<p>It would be incredible to feed an A.I. some code and request a bug tracking from it.<p>[1]: <a href="https:&#x2F;&#x2F;blog.mathieuacher.com&#x2F;LinusTorvaldsLLM&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.mathieuacher.com&#x2F;LinusTorvaldsLLM&#x2F;</a></div><br/></div></div><div id="39212219" class="c"><input type="checkbox" id="c-39212219" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212341">prev</a><span>|</span><a href="#39213702">next</a><span>|</span><label class="collapse" for="c-39212219">[-]</label><label class="expand" for="c-39212219">[2 more]</label></div><br/><div class="children"><div class="content">Unclear exactly what you are expecting to do here, but in any case you shouldn&#x27;t need to train on your own codebase.<p>The idea is you put your code into the best possible model (GPT4) and tell it what you want and it generates code.</div><br/><div id="39212244" class="c"><input type="checkbox" id="c-39212244" checked=""/><div class="controls bullet"><span class="by">rickstanley</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212219">parent</a><span>|</span><a href="#39213702">next</a><span>|</span><label class="collapse" for="c-39212244">[-]</label><label class="expand" for="c-39212244">[1 more]</label></div><br/><div class="children"><div class="content">My goal is to (1) try running an A.I. locally and see if it works, out curiosity, and (2) delve into A.I. concepts. I do not intend to use it as the definitive tool to code for me, and maybe I shouldn&#x27;t.<p>Realistically, since we are in a Azure ecosystem, I would use Codex to try out a solution.</div><br/></div></div></div></div><div id="39213702" class="c"><input type="checkbox" id="c-39213702" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212219">prev</a><span>|</span><a href="#39212847">next</a><span>|</span><label class="collapse" for="c-39213702">[-]</label><label class="expand" for="c-39213702">[1 more]</label></div><br/><div class="children"><div class="content">If the code to write is repetitive, then just write some code that does it; no AI needed.<p>Presumably what matters in this project is correctness, not how many unnecessary cycles you can burn.</div><br/></div></div><div id="39212847" class="c"><input type="checkbox" id="c-39212847" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39213702">prev</a><span>|</span><a href="#39212190">next</a><span>|</span><label class="collapse" for="c-39212847">[-]</label><label class="expand" for="c-39212847">[2 more]</label></div><br/><div class="children"><div class="content">Is writing the code the hard part, or is ensuring what you&#x27;ve written is correct the hard part? I&#x27;d guess the latter and AI will not ensure the code is correct.<p>Can you record input and output at some layers of your system and then use that data to test the ported code? Make sure the inputs produce the same outputs.</div><br/><div id="39213369" class="c"><input type="checkbox" id="c-39213369" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212847">parent</a><span>|</span><a href="#39212190">next</a><span>|</span><label class="collapse" for="c-39213369">[-]</label><label class="expand" for="c-39213369">[1 more]</label></div><br/><div class="children"><div class="content">Yes, and I also imagine some kind of AI thing would be useful for reading logs and writing other tests that document what the system does in a nice bdd style.<p>But you still have to read the tests and decide if that&#x27;s what you want the code to do, and make sure the descriptions aren&#x27;t gobbledygook.</div><br/></div></div></div></div><div id="39212190" class="c"><input type="checkbox" id="c-39212190" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212847">prev</a><span>|</span><a href="#39212078">next</a><span>|</span><label class="collapse" for="c-39212190">[-]</label><label class="expand" for="c-39212190">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We are looking from the perspective of A, to map the entries for B (inbound), and after the request to B is returned, we map back to A&#x27;s model (outbound). This is a chore, and much of the work is repetitive, but it comes with its edge cases that we need to look out for and unfortunately there isn&#x27;t a solid foundation of patterns apart from the Domain-driven design (DDD) thing.<p>This sounds like a job for protobufs or some kind of serialization solution.  And you already know there are dragons here, so letting a LLM try and solve this is just going to mean more rework&#x2F;validation for you.<p>If you don&#x27;t understand the problem space, hire a consultant.  LLMs are not consultants (yet).  Either way, I&#x27;d quit wasting time on trying to feed your codebase into a LLM and just do the work.</div><br/><div id="39212213" class="c"><input type="checkbox" id="c-39212213" checked=""/><div class="controls bullet"><span class="by">rickstanley</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212190">parent</a><span>|</span><a href="#39212078">next</a><span>|</span><label class="collapse" for="c-39212213">[-]</label><label class="expand" for="c-39212213">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. I would be interesting though, to see how things plays out. Fortunately, it&#x27;s no a requirement, just a &quot;side quest&quot;.</div><br/></div></div></div></div><div id="39212078" class="c"><input type="checkbox" id="c-39212078" checked=""/><div class="controls bullet"><span class="by">mhb</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212190">prev</a><span>|</span><a href="#39212484">next</a><span>|</span><label class="collapse" for="c-39212078">[-]</label><label class="expand" for="c-39212078">[4 more]</label></div><br/><div class="children"><div class="content">Maybe this is not relevant to you, but would it make any sense to first try Copilot with IntelliJ or Visual Studio?</div><br/><div id="39212101" class="c"><input type="checkbox" id="c-39212101" checked=""/><div class="controls bullet"><span class="by">high_priest</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212078">parent</a><span>|</span><a href="#39212484">next</a><span>|</span><label class="collapse" for="c-39212101">[-]</label><label class="expand" for="c-39212101">[3 more]</label></div><br/><div class="children"><div class="content">Copilot has such a narrow input space, that it is not going to help in this case.
Here, just saved you $$</div><br/><div id="39213763" class="c"><input type="checkbox" id="c-39213763" checked=""/><div class="controls bullet"><span class="by">hackstack</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212101">parent</a><span>|</span><a href="#39213208">next</a><span>|</span><label class="collapse" for="c-39213763">[-]</label><label class="expand" for="c-39213763">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by this? I’ve been getting great mileage out of copilot, especially since learning about the @workspace keyword.<p>Could you quantify your criticism a bit more? (genuinely asking)</div><br/></div></div><div id="39213208" class="c"><input type="checkbox" id="c-39213208" checked=""/><div class="controls bullet"><span class="by">imp0cat</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212101">parent</a><span>|</span><a href="#39213763">prev</a><span>|</span><a href="#39212484">next</a><span>|</span><label class="collapse" for="c-39213208">[-]</label><label class="expand" for="c-39213208">[1 more]</label></div><br/><div class="children"><div class="content">You can use @workspace to tell him to ingest more of your workspace as required.</div><br/></div></div></div></div></div></div><div id="39212484" class="c"><input type="checkbox" id="c-39212484" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#39211923">parent</a><span>|</span><a href="#39212078">prev</a><span>|</span><a href="#39211055">next</a><span>|</span><label class="collapse" for="c-39212484">[-]</label><label class="expand" for="c-39212484">[2 more]</label></div><br/><div class="children"><div class="content">&gt; much of the work is repetitive, but it comes with its edge cases that we need to look out for<p>Then don&#x27;t use AI for it.<p>Bluntly.<p>This is a poor use-case; it doesn&#x27;t matter what model you use, you&#x27;ll get a disappointing result.<p>These are the domains where using AI coding currently shines:<p>1) You&#x27;re approaching a new well established domain (eg. building an android app in kotlin), and you already know how to build things &#x2F; apps, but not specifically that exact domain.<p>Example: How do I do X but for an android app in kotlin?<p>2) You&#x27;re building out a generic scaffold for a project and need some tedious (but generic) work done.<p>Example: <a href="https:&#x2F;&#x2F;github.com&#x2F;smol-ai&#x2F;developer">https:&#x2F;&#x2F;github.com&#x2F;smol-ai&#x2F;developer</a><p>3) You have a standard, but specific question regarding your code, and although related Q&#x2F;A answers exist, nothing seems to specifically target the issue you&#x27;re having.<p>Example: My nginx configuration is giving me [SPECIFIC ERROR] for [CONFIG FILE]. What&#x27;s wrong and how can I fix it?<p>The domains where it <i>does not work</i> are:<p>1) You have some generic code with domain&#x2F;company&#x2F;whatever specific edge cases.<p>The edge cases, broadly speaking, no matter how well documented, will not be handled well by the model.<p>Edge cases are exactly that; edge cases; the common medium of &#x27;how to x&#x27; does not cover edge cases; the edge cases will not be covered and the results will require you to review and complete them manually.<p>2) You have some specific piece of code you want to refactor &#x27;to solve xxx&#x27;, but the code is <i>not covered well by tests</i>.<p>LLMs struggle to refactor existing code, and the difficulty is proportional to the code length. There are technical reasons for this (mainly randomizing token weights), but tldr; it&#x27;s basically a crap shot.<p>Might work. Might not. If you have no tests who knows? You have to manually verify both the new functionality <i>and the old functionality</i>, but maybe it helps a bit, at scale, for trivial problems.<p>3) You&#x27;re doing something obscure or using a new library &#x2F; new version of the library.<p>The LLM will have no context for this, and will generate rubbish &#x2F; old deprecated content.<p>Obscure requirements have an unfortunate tendency to mimic the few training examples that exist, and may generate verbatim copies, depending on the model you use.<p>...<p>So. Concrete advice:<p>1) <i>sigh~</i><p>&gt; a friend of mine came and suggested that I use Retrieval-Augmented Generation (RAG), I have yet to try it, with a setup Langchain + Ollama.<p>Ignore this advice. RAG and langchain are not the solutions you are looking for.<p>2) Use a normal coding assistant like copilot.<p>This is the most effective way to use AI right now.<p>There are some frameworks that let you use open source models if you don&#x27;t want to use openAI.<p>3) Do not attempt to bulk generate code.<p>AI coding isn&#x27;t at that level. Right now, the tooling is primitive, and large scale coherent code generation is... not <i>impossible</i>, but it is difficult (see below).<p>You will be more effective using an existing proven path that uses &#x27;copilot&#x27; style helpers.<p>However...<p>...if you <i>do</i> want to pursue code generation, here&#x27;s a broad blueprint to follow:<p>- decompose your task into steps<p>- decompose you steps in functions<p>- generate or write <i>tests</i> and <i>function</i> definitions<p>- generate an api specification (eg. .d.ts file) for your function definitions<p>- for each function definition, generate the code for the function passing the <i>api specification</i> in as the context. eg. &quot;Given functions x, y, z with the specs... ; generate an implementation of q that does ...&quot;.<p>- repeated generate multiple outputs for the above until you get one that passes the <i>tests</i> you wrote.<p>This approach broadly scales to reasonably complex problems, so long as you partition your problem into module sized chunks.<p>I personally like to put something like &quot;you&#x27;re building a library&#x2F;package to do xxx&quot; or &quot;as a one file header&quot; as a top level in the prompt, as it seems to link into the &#x27;this should be isolated and a package&#x27; style of output.<p>However, I will caveat this with two points:<p>1) You generate a lot of code this way, and that&#x27;s expensive if you use a charge-per-completion API.<p>2) The results are not always <i>coherent</i> and functions tend to (depending on the model, eg. 7B mistral) inline implementations for &#x27;trivial&#x27; functions instead of using functions (eg. if you define Vector::add, the model will 50&#x2F;50 just go a = new Vector(a.x + b.x, a.y + b.y)).<p>I&#x27;ve found that the current models other than GPT4 are prone to incoherence as the problem size scales.<p>7B models, specifically, perform significantly worse than larger models.</div><br/><div id="39213862" class="c"><input type="checkbox" id="c-39213862" checked=""/><div class="controls bullet"><span class="by">eurekin</span><span>|</span><a href="#39211923">root</a><span>|</span><a href="#39212484">parent</a><span>|</span><a href="#39211055">next</a><span>|</span><label class="collapse" for="c-39213862">[-]</label><label class="expand" for="c-39213862">[1 more]</label></div><br/><div class="children"><div class="content">Very well researched!<p>I&#x27;d add the MR review use case.<p>I have limited success with feeding a LLM (dolphin finetune of mixtral) a content of a merge request coming from my team. It was few thousand lines of added integration test code and I just couldn&#x27;t be bothered&#x2F;had little time to really delve.<p>I slapped the diff and used about 10 prompt strategies to get anything meaningful. So my first initial impressions were: clearly it was finetuned on too short responses. It kept putting in &quot;etc.&quot;, &quot;and other input parameters&quot;, &quot;and other relevant information&quot;. At one point I was ready to give up; it clearly hallucinated.<p>Or that&#x27;s what I thought: turned out there was some new edge case of a existing functionality added that was added, without ever me noticing (despite being on the same meetings).<p>I think it actually saved me a lot of hours or pestering other team members.</div><br/></div></div></div></div></div></div><div id="39211055" class="c"><input type="checkbox" id="c-39211055" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#39211923">prev</a><span>|</span><a href="#39211808">next</a><span>|</span><label class="collapse" for="c-39211055">[-]</label><label class="expand" for="c-39211055">[1 more]</label></div><br/><div class="children"><div class="content">Been using DeepSeek Coder 33B Q8 on my work laptop for a bit now. I like it, but am still finding myself going to GPT-4&#x27;s API for the more nuanced things.<p>They just released a v1.5 (<a href="https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;deepseek-coder-7b-instruct-v1.5" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;deepseek-coder-7b-instruc...</a>), but for some reason, they reduced the context length from ~16k to ~4k.</div><br/></div></div><div id="39211808" class="c"><input type="checkbox" id="c-39211808" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#39211055">prev</a><span>|</span><a href="#39211362">next</a><span>|</span><label class="collapse" for="c-39211808">[-]</label><label class="expand" for="c-39211808">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been playing with the 1.3b model for continue.dev&#x27;s autocomplete and it&#x27;s quite impressive. One unclear part is whether the license really permits commercial usage, but regardless it&#x27;s exciting to see the construction of more complex datasets. They mention that training on multiple tasks (FIM + normal completion) improves performance...wonder whether training to output diffs would be equally helpful (this is the holy grail needed to generate changes in O(diff length) time)</div><br/><div id="39212716" class="c"><input type="checkbox" id="c-39212716" checked=""/><div class="controls bullet"><span class="by">DeepSeek</span><span>|</span><a href="#39211808">parent</a><span>|</span><a href="#39212361">next</a><span>|</span><label class="collapse" for="c-39212716">[-]</label><label class="expand" for="c-39212716">[1 more]</label></div><br/><div class="children"><div class="content">Hello sestinj, I work at DeepSeek, and I&#x27;m glad to hear that our models work for you! 
DeepSeek-Coder models are under a permissive license that allows for both research and unrestricted commercial use. We claim no rights on and take no responsibility from the output generated by the model induced by user prompts.
Feel free to deploy and use DeepSeek models for any creative projects. We are a starup company and would like to concentrate on building better models, so it would be best if the users can help create a healthy ecosystem.
Should you have any questions or requirements, I&#x27;m always happy to support.</div><br/></div></div><div id="39212361" class="c"><input type="checkbox" id="c-39212361" checked=""/><div class="controls bullet"><span class="by">explorigin</span><span>|</span><a href="#39211808">parent</a><span>|</span><a href="#39212716">prev</a><span>|</span><a href="#39211362">next</a><span>|</span><label class="collapse" for="c-39212361">[-]</label><label class="expand" for="c-39212361">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This code repository is licensed under the MIT License. The use of DeepSeek Coder models is subject to the Model License. DeepSeek Coder supports commercial use.<p>Says so on <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;deepseek-coder-6.7b-instruct#4-license" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;deepseek-coder-6.7b-instr...</a><p>They have their own license to prevent things like propaganda or military use.</div><br/></div></div></div></div><div id="39211362" class="c"><input type="checkbox" id="c-39211362" checked=""/><div class="controls bullet"><span class="by">elwebmaster</span><span>|</span><a href="#39211808">prev</a><span>|</span><a href="#39213120">next</a><span>|</span><label class="collapse" for="c-39211362">[-]</label><label class="expand" for="c-39211362">[17 more]</label></div><br/><div class="children"><div class="content">Mixtral &gt; Codellama &gt; DeepSeek Coder. Very weird model, writes super long comments on one line, definitely not at the level of Codellama, benchmarks be damned.</div><br/><div id="39213480" class="c"><input type="checkbox" id="c-39213480" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39212838">next</a><span>|</span><label class="collapse" for="c-39213480">[-]</label><label class="expand" for="c-39213480">[1 more]</label></div><br/><div class="children"><div class="content">Just curious, why do you think your evaluation is the opposite of what is shown in this evaluation? <a href="https:&#x2F;&#x2F;evalplus.github.io&#x2F;leaderboard.html" rel="nofollow">https:&#x2F;&#x2F;evalplus.github.io&#x2F;leaderboard.html</a></div><br/></div></div><div id="39212838" class="c"><input type="checkbox" id="c-39212838" checked=""/><div class="controls bullet"><span class="by">apawloski</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39213480">prev</a><span>|</span><a href="#39211794">next</a><span>|</span><label class="collapse" for="c-39212838">[-]</label><label class="expand" for="c-39212838">[1 more]</label></div><br/><div class="children"><div class="content">Which mixtral are you using with ollama? I have 32GB M1 MacBook Pro and can’t seem to load it &#x2F; get any time-realistic responses</div><br/></div></div><div id="39211794" class="c"><input type="checkbox" id="c-39211794" checked=""/><div class="controls bullet"><span class="by">chrisweekly</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39212838">prev</a><span>|</span><a href="#39212138">next</a><span>|</span><label class="collapse" for="c-39211794">[-]</label><label class="expand" for="c-39211794">[4 more]</label></div><br/><div class="children"><div class="content">tangent: I often have a hard time disambiguating the &quot;&gt;&quot; in comparisons like yours:
(A) greater than (ie, Mixtral
superior to DeepSeek, w&#x2F; Codellama in between)
vs  
(B) arrow&#x2F;sequence (ie, start w&#x2F; Mixtral, progress to Codellama, finally land on DeepSeek as the culmination).<p>I&#x27;d love to hear of a less ambiguous way to represent these.</div><br/><div id="39212069" class="c"><input type="checkbox" id="c-39212069" checked=""/><div class="controls bullet"><span class="by">mcny</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39211794">parent</a><span>|</span><a href="#39211839">next</a><span>|</span><label class="collapse" for="c-39212069">[-]</label><label class="expand" for="c-39212069">[1 more]</label></div><br/><div class="children"><div class="content">I personally use a -&gt; b -&gt; c for sequence, a &gt; b &gt;&gt; c for nested hierarchy.<p>In this context, I read it as a is better than b which is better than c.</div><br/></div></div><div id="39211839" class="c"><input type="checkbox" id="c-39211839" checked=""/><div class="controls bullet"><span class="by">mooreds</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39211794">parent</a><span>|</span><a href="#39212069">prev</a><span>|</span><a href="#39212138">next</a><span>|</span><label class="collapse" for="c-39211839">[-]</label><label class="expand" for="c-39211839">[2 more]</label></div><br/><div class="children"><div class="content">How does<p>Mixtral &gt;= Codellama &gt;= DeepSeek<p>Work for you?</div><br/><div id="39211878" class="c"><input type="checkbox" id="c-39211878" checked=""/><div class="controls bullet"><span class="by">illusive4080</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39211839">parent</a><span>|</span><a href="#39212138">next</a><span>|</span><label class="collapse" for="c-39211878">[-]</label><label class="expand" for="c-39211878">[1 more]</label></div><br/><div class="children"><div class="content">Sadly that implies that all 3 could be equal or very close to equal.</div><br/></div></div></div></div></div></div><div id="39212138" class="c"><input type="checkbox" id="c-39212138" checked=""/><div class="controls bullet"><span class="by">high_priest</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39211794">prev</a><span>|</span><a href="#39212565">next</a><span>|</span><label class="collapse" for="c-39212138">[-]</label><label class="expand" for="c-39212138">[5 more]</label></div><br/><div class="children"><div class="content">Mixtral looks interesting, but I haven&#x27;t dabbled in locally hosted LLMs.<p>Would you mind linking to a concise text which could lead me through setting up Mixtral on my own machine?</div><br/><div id="39213320" class="c"><input type="checkbox" id="c-39213320" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39212138">parent</a><span>|</span><a href="#39212200">next</a><span>|</span><label class="collapse" for="c-39213320">[-]</label><label class="expand" for="c-39213320">[1 more]</label></div><br/><div class="children"><div class="content">Had zero experience, too. Turns out ollama does everything, literally. You just tell it to run a model and wait a bit for it to download. One (1) shell command total.</div><br/></div></div><div id="39212200" class="c"><input type="checkbox" id="c-39212200" checked=""/><div class="controls bullet"><span class="by">findjashua</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39212138">parent</a><span>|</span><a href="#39213320">prev</a><span>|</span><a href="#39212664">next</a><span>|</span><label class="collapse" for="c-39212200">[-]</label><label class="expand" for="c-39212200">[1 more]</label></div><br/><div class="children"><div class="content">LM Studio is the easiest way to do it</div><br/></div></div><div id="39212664" class="c"><input type="checkbox" id="c-39212664" checked=""/><div class="controls bullet"><span class="by">elwebmaster</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39212138">parent</a><span>|</span><a href="#39212200">prev</a><span>|</span><a href="#39212422">next</a><span>|</span><label class="collapse" for="c-39212664">[-]</label><label class="expand" for="c-39212664">[1 more]</label></div><br/><div class="children"><div class="content">Ollama gui in WSL2</div><br/></div></div></div></div><div id="39212565" class="c"><input type="checkbox" id="c-39212565" checked=""/><div class="controls bullet"><span class="by">maxlamb</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39212138">prev</a><span>|</span><a href="#39211393">next</a><span>|</span><label class="collapse" for="c-39212565">[-]</label><label class="expand" for="c-39212565">[1 more]</label></div><br/><div class="children"><div class="content">Is Mixtral better overall or for coding specifically (or both)?</div><br/></div></div><div id="39211393" class="c"><input type="checkbox" id="c-39211393" checked=""/><div class="controls bullet"><span class="by">findjashua</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39212565">prev</a><span>|</span><a href="#39211457">next</a><span>|</span><label class="collapse" for="c-39211393">[-]</label><label class="expand" for="c-39211393">[2 more]</label></div><br/><div class="children"><div class="content">do you find Mixtral to be better than the new 70B one that Meta released a couple days back as well?</div><br/><div id="39211834" class="c"><input type="checkbox" id="c-39211834" checked=""/><div class="controls bullet"><span class="by">findjashua</span><span>|</span><a href="#39211362">root</a><span>|</span><a href="#39211393">parent</a><span>|</span><a href="#39211457">next</a><span>|</span><label class="collapse" for="c-39211834">[-]</label><label class="expand" for="c-39211834">[1 more]</label></div><br/><div class="children"><div class="content">did a comparison on LM Studio - the answers are eerily similar, but Mixtral is way way faster. Codellama-70B is slow to the point of being unusable.<p>(M1 Max, 64 GB RAM)</div><br/></div></div></div></div><div id="39211457" class="c"><input type="checkbox" id="c-39211457" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#39211362">parent</a><span>|</span><a href="#39211393">prev</a><span>|</span><a href="#39212435">next</a><span>|</span><label class="collapse" for="c-39211457">[-]</label><label class="expand" for="c-39211457">[1 more]</label></div><br/><div class="children"><div class="content">Reduce the repetition penalty to 1 and that should fix it.</div><br/></div></div></div></div><div id="39213120" class="c"><input type="checkbox" id="c-39213120" checked=""/><div class="controls bullet"><span class="by">chii</span><span>|</span><a href="#39211362">prev</a><span>|</span><a href="#39211853">next</a><span>|</span><label class="collapse" for="c-39213120">[-]</label><label class="expand" for="c-39213120">[1 more]</label></div><br/><div class="children"><div class="content">Just tried it by asking how to create a game that is turn based, using an ECS system, and how to add a decision tree, and a save&#x2F;load system, in the language Haxe.<p>It outputs relatively correct haxe code, but it did halucinate that there is a library called &#x27;haxe-tiled&#x27; to read tmx map files...</div><br/></div></div><div id="39211853" class="c"><input type="checkbox" id="c-39211853" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#39213120">prev</a><span>|</span><a href="#39210894">next</a><span>|</span><label class="collapse" for="c-39211853">[-]</label><label class="expand" for="c-39211853">[2 more]</label></div><br/><div class="children"><div class="content">I’ve been using their 7B with tabbyML.<p>Works well but closer to a very smart code complete rather than generating much novel blocks of code</div><br/><div id="39211874" class="c"><input type="checkbox" id="c-39211874" checked=""/><div class="controls bullet"><span class="by">illusive4080</span><span>|</span><a href="#39211853">parent</a><span>|</span><a href="#39210894">next</a><span>|</span><label class="collapse" for="c-39211874">[-]</label><label class="expand" for="c-39211874">[1 more]</label></div><br/><div class="children"><div class="content">Fells like all Gen AI is ‘very good code complete’ because if you give it a broad problem it’ll make mistakes.</div><br/></div></div></div></div><div id="39210894" class="c"><input type="checkbox" id="c-39210894" checked=""/><div class="controls bullet"><span class="by">byyoung3</span><span>|</span><a href="#39211853">prev</a><span>|</span><a href="#39210056">next</a><span>|</span><label class="collapse" for="c-39210894">[-]</label><label class="expand" for="c-39210894">[2 more]</label></div><br/><div class="children"><div class="content">looks like code llama 70B outperforms on humaneval I believe</div><br/><div id="39211432" class="c"><input type="checkbox" id="c-39211432" checked=""/><div class="controls bullet"><span class="by">SparkyMcUnicorn</span><span>|</span><a href="#39210894">parent</a><span>|</span><a href="#39210056">next</a><span>|</span><label class="collapse" for="c-39211432">[-]</label><label class="expand" for="c-39211432">[1 more]</label></div><br/><div class="children"><div class="content">Looks like even deepseek-coder 1.3b benchmarks higher than CodeLlama 70b.<p><a href="https:&#x2F;&#x2F;evalplus.github.io&#x2F;leaderboard.html" rel="nofollow">https:&#x2F;&#x2F;evalplus.github.io&#x2F;leaderboard.html</a></div><br/></div></div></div></div><div id="39210056" class="c"><input type="checkbox" id="c-39210056" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39210894">prev</a><span>|</span><a href="#39212798">next</a><span>|</span><label class="collapse" for="c-39210056">[-]</label><label class="expand" for="c-39210056">[2 more]</label></div><br/><div class="children"><div class="content">In the benchmarks, are they using the base GPT-4, or are they using a GPT like Grimoire which will be better at coding? If they aren&#x27;t using Grimoire, isn&#x27;t it unfair to compare their fine tuned model to base GPT-4?</div><br/><div id="39210223" class="c"><input type="checkbox" id="c-39210223" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#39210056">parent</a><span>|</span><a href="#39212798">next</a><span>|</span><label class="collapse" for="c-39210223">[-]</label><label class="expand" for="c-39210223">[1 more]</label></div><br/><div class="children"><div class="content">Is it unfair if GPT4 still beats them handily?</div><br/></div></div></div></div></div></div></div></div></div></body></html>