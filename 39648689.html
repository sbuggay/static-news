<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709974863926" as="style"/><link rel="stylesheet" href="styles.css?v=1709974863926"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2403.00801">Self-Retrieval: Building an information retrieval system with one LLM</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>PaulHoule</span> | <span>13 comments</span></div><br/><div><div id="39650380" class="c"><input type="checkbox" id="c-39650380" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#39649241">next</a><span>|</span><label class="collapse" for="c-39650380">[-]</label><label class="expand" for="c-39650380">[1 more]</label></div><br/><div class="children"><div class="content">I like methods of this flavour, pioneered as I understand it by Fabio Petroni. Very elegant, particularly because you can change the distribution over substrings in O(params) time instead of O(index size).<p>What&#x27;s funny about them is that it&#x27;s a fairly involved procedure that turns your language model into an actual stochastic parrot, both showing that such a model useful and demonstrating that the original parrot concept was rather ill conceived.</div><br/></div></div><div id="39649241" class="c"><input type="checkbox" id="c-39649241" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39650380">prev</a><span>|</span><a href="#39649612">next</a><span>|</span><label class="collapse" for="c-39649241">[-]</label><label class="expand" for="c-39649241">[6 more]</label></div><br/><div class="children"><div class="content">This sounds like an interesting way to ensure accurate quotes:<p>&gt;  To accurately generate the exact passages in the given corpus, we employ a trie-based constrained decoding algorithm (Chen et al., 2020; Cao et al., 2021; Lu et al., 2021) in which the generated tokens can be constrained in the dynamic vocabulary. Specifically, instead of generating a token from the entire target vocabulary at each step, we use a prefix tree (trie) to constraint the target vocabulary and ensure that the generated content is within the corpus. During the construction of trie, we remove stop words from the initial token to improve semantic representation of the trie.</div><br/><div id="39650004" class="c"><input type="checkbox" id="c-39650004" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39649241">parent</a><span>|</span><a href="#39649365">next</a><span>|</span><label class="collapse" for="c-39650004">[-]</label><label class="expand" for="c-39650004">[1 more]</label></div><br/><div class="children"><div class="content">Indeed.<p>Use trie constraint for quotes.<p>Use BNF for grammar languages (json, python etc).<p>Projects like llama.cpp&#x2F;ollama should make it automatic&#x2F;dynamic, just rely on triple quote sections where you enter those constraint modes automatically.<p>Ie. every time you enter into section starting with &quot;```json&quot; you automatically switch to JSON BNF.<p>Every time you enter into &quot;```json:Foo&quot; you enter JSON BNF + JSON-SCHEMA for Foo object definition.<p>&quot;```python&quot; for python grammar etc.<p>&quot;```quote:documentRef&quot; you enter trie based constraints.<p>&quot;```llm:otherllm&quot; you enter other llm.<p>&quot;```whatever:whatever&quot; you enter whatever you want.<p>If you want just json output you start output with &quot;```json&quot; and that&#x27;s it.<p>As its all inference time it could be plugin based, ie:<p>1. character based - given input (from the start of opening &quot;```foo&quot;) it returns allowed next characters, or<p>2. token based - same as above but returns allowed native tokens (not sure how performance would behave here, would it be acceptable?)<p>IMHO also very interesting area would be exploring stable AST representations for programming languages (a&#x27;la darklang I believe?) – where variable names are detached from AST itself, ie. differently named functions that otherwise have the same structure have precisely the same AST representation. This would dramatically reduce space to navigate around.<p>ps. [0] in case somebody else is interested<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;issues&#x2F;3019">https:&#x2F;&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;issues&#x2F;3019</a></div><br/></div></div><div id="39649365" class="c"><input type="checkbox" id="c-39649365" checked=""/><div class="controls bullet"><span class="by">mmoskal</span><span>|</span><a href="#39649241">parent</a><span>|</span><a href="#39650004">prev</a><span>|</span><a href="#39649745">next</a><span>|</span><label class="collapse" for="c-39649365">[-]</label><label class="expand" for="c-39649365">[3 more]</label></div><br/><div class="children"><div class="content">This kind of low level strategies can be tried on many models using AICI, including the substring one <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;aici&#x2F;blob&#x2F;main&#x2F;controllers&#x2F;aici_abi&#x2F;src&#x2F;substring.rs">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;aici&#x2F;blob&#x2F;main&#x2F;controllers&#x2F;aici...</a></div><br/><div id="39649604" class="c"><input type="checkbox" id="c-39649604" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39649241">root</a><span>|</span><a href="#39649365">parent</a><span>|</span><a href="#39649745">next</a><span>|</span><label class="collapse" for="c-39649604">[-]</label><label class="expand" for="c-39649604">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if anyone has tried giving an LLM a tool that ensures that it copies a quote from a document accurately? It seems like it would be a pretty simple way to avoid some hallucinations.</div><br/><div id="39649637" class="c"><input type="checkbox" id="c-39649637" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39649241">root</a><span>|</span><a href="#39649604">parent</a><span>|</span><a href="#39649745">next</a><span>|</span><label class="collapse" for="c-39649637">[-]</label><label class="expand" for="c-39649637">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it would be good for extractive QA</div><br/></div></div></div></div></div></div><div id="39649745" class="c"><input type="checkbox" id="c-39649745" checked=""/><div class="controls bullet"><span class="by">threatripper</span><span>|</span><a href="#39649241">parent</a><span>|</span><a href="#39649365">prev</a><span>|</span><a href="#39649612">next</a><span>|</span><label class="collapse" for="c-39649745">[-]</label><label class="expand" for="c-39649745">[1 more]</label></div><br/><div class="children"><div class="content">Is that the same method that is used to generate valid JSON by disallowing any token that would cause a syntax error?</div><br/></div></div></div></div><div id="39649612" class="c"><input type="checkbox" id="c-39649612" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#39649241">prev</a><span>|</span><a href="#39650153">next</a><span>|</span><label class="collapse" for="c-39649612">[-]</label><label class="expand" for="c-39649612">[4 more]</label></div><br/><div class="children"><div class="content">This is interesting, but unless I&#x27;m misreading the paper, it looks like they&#x27;re training an LLM on the corpus. I can easily see why that would result in better performance than an off-the-shelf embeddings model, but... it won&#x27;t work for a corpus that changes frequently, since you&#x27;ll constantly have to retrain the LLM. That&#x27;s sort of the point of RAG: how do you get the right information into an LLM as context, for data that changes so frequently that you can&#x27;t directly train on it?</div><br/><div id="39650169" class="c"><input type="checkbox" id="c-39650169" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#39649612">parent</a><span>|</span><a href="#39650353">next</a><span>|</span><label class="collapse" for="c-39650169">[-]</label><label class="expand" for="c-39650169">[1 more]</label></div><br/><div class="children"><div class="content">There are some interesting corpora that I would like to search smartly, that shouldn&#x27;t change too often. For instance &quot;all Norwegian newspapers printed before 1980&quot;.</div><br/></div></div><div id="39650353" class="c"><input type="checkbox" id="c-39650353" checked=""/><div class="controls bullet"><span class="by">HellsMaddy</span><span>|</span><a href="#39649612">parent</a><span>|</span><a href="#39650169">prev</a><span>|</span><a href="#39649927">next</a><span>|</span><label class="collapse" for="c-39650353">[-]</label><label class="expand" for="c-39650353">[1 more]</label></div><br/><div class="children"><div class="content">This was my takeaway as well. None of the other retrieval methods this paper benchmarks against are specifically trained on the corpus. I think it would be more fair to compare &quot;Self-Retrieval&quot; against models which have been fine-tuned on the corpus.</div><br/></div></div><div id="39649927" class="c"><input type="checkbox" id="c-39649927" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#39649612">parent</a><span>|</span><a href="#39650353">prev</a><span>|</span><a href="#39650153">next</a><span>|</span><label class="collapse" for="c-39649927">[-]</label><label class="expand" for="c-39649927">[1 more]</label></div><br/><div class="children"><div class="content">I’m also not sure with this method if tje LLM can exactly cite its source, which is another great benefit of RAG</div><br/></div></div></div></div><div id="39650153" class="c"><input type="checkbox" id="c-39650153" checked=""/><div class="controls bullet"><span class="by">tinco</span><span>|</span><a href="#39649612">prev</a><span>|</span><label class="collapse" for="c-39650153">[-]</label><label class="expand" for="c-39650153">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Specifically, we treat each original sentence in the document as an index and the document itself as the object of the index, allowing the LLM to memorize documents and build indexes through self-supervised learning&quot;<p>This is clever, I haven&#x27;t seen an effective way to train an LLM to search a document yet and I can imagine this being very effective. I suppose this relies on the over fitting you get when fine tuning on a very small dataset.</div><br/></div></div></div></div></div></div></div></body></html>