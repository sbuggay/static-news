<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718701258927" as="style"/><link rel="stylesheet" href="styles.css?v=1718701258927"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://cohere.com/blog/multi-step-tool-use">LLM that can call multiple tool APIs with one request</a> <span class="domain">(<a href="https://cohere.com">cohere.com</a>)</span></div><div class="subtext"><span>ericciarla</span> | <span>40 comments</span></div><br/><div><div id="40715170" class="c"><input type="checkbox" id="c-40715170" checked=""/><div class="controls bullet"><span class="by">Oras</span><span>|</span><a href="#40712650">next</a><span>|</span><label class="collapse" for="c-40715170">[-]</label><label class="expand" for="c-40715170">[1 more]</label></div><br/><div class="children"><div class="content">Cohere is underrated, I recently tried cohere R model and found it following prompt much better than gpt-4o and even Claude opus.<p>That’s said, it’s a bit annoying to see langchain examples all over. Not everyone uses it, and many consider it bloated and hard to maintain.<p>Would be great just to have a simple example in Python showing the capabilities.</div><br/></div></div><div id="40712650" class="c"><input type="checkbox" id="c-40712650" checked=""/><div class="controls bullet"><span class="by">madrox</span><span>|</span><a href="#40715170">prev</a><span>|</span><a href="#40713726">next</a><span>|</span><label class="collapse" for="c-40712650">[-]</label><label class="expand" for="c-40712650">[27 more]</label></div><br/><div class="children"><div class="content">I have a saying: &quot;any sufficiently advanced agent is indistinguishable from a DSL&quot;<p>If I&#x27;m really leaning into multi-tool use for anything resembling a mutation, then I&#x27;d like to see an execution plan first. In my experience, asking an AI to code up a script that calls some functions with the same signature as tools and then executing that script actually ends up being more accurate than asking it to internalize its algorithm. Plus, I can audit it before I run it. This is effectively the same as asking it to &quot;think step by step.&quot;<p>I like the idea of Command R+ but multitool feels like barking up the wrong tree. Maybe my use cases are too myopic.</div><br/><div id="40713985" class="c"><input type="checkbox" id="c-40713985" checked=""/><div class="controls bullet"><span class="by">fzeindl</span><span>|</span><a href="#40712650">parent</a><span>|</span><a href="#40713594">next</a><span>|</span><label class="collapse" for="c-40713985">[-]</label><label class="expand" for="c-40713985">[2 more]</label></div><br/><div class="children"><div class="content">&gt; ... code up a script that calls some functions with the same signature as tools and then executing that script actually ends up being more accurate than asking it to internalize its algorithm.<p>This is called defunctionalization and useful without LLMs as well.</div><br/><div id="40715127" class="c"><input type="checkbox" id="c-40715127" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713985">parent</a><span>|</span><a href="#40713594">next</a><span>|</span><label class="collapse" for="c-40715127">[-]</label><label class="expand" for="c-40715127">[1 more]</label></div><br/><div class="children"><div class="content">Like what?</div><br/></div></div></div></div><div id="40713594" class="c"><input type="checkbox" id="c-40713594" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#40712650">parent</a><span>|</span><a href="#40713985">prev</a><span>|</span><a href="#40713743">next</a><span>|</span><label class="collapse" for="c-40713594">[-]</label><label class="expand" for="c-40713594">[6 more]</label></div><br/><div class="children"><div class="content">You mean manually pre-baking a DAG from the user query, then “spawning” other LLMs to resolve each node and pass their input up the graph? This is the approach we take too. It seems to be a sufficiently performant approach that is - intuitively - generically useful regardless of ontology &#x2F; domain, but would love to hear others’ experiences.<p>It would be nice to know if this is sort of how OpenAI’s native “file_search” retriever works - that’s certainly the suggestion in some of the documentation but it hasn’t, to my knowledge, been confirmed.</div><br/><div id="40713783" class="c"><input type="checkbox" id="c-40713783" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713594">parent</a><span>|</span><a href="#40713743">next</a><span>|</span><label class="collapse" for="c-40713783">[-]</label><label class="expand" for="c-40713783">[5 more]</label></div><br/><div class="children"><div class="content">No. The DAG should be &quot;manually pre-baked&quot; ( defined at compile&#x2F;design time).<p>In runtime you only parse the &quot;user question&quot; (user prompt) into a starting and end node, which is equivalent to a function call.<p>So the question<p>&quot;What league does Messi play in?&quot;<p>Is parsed by the llm as<p>League(&quot;Messi&quot;)<p>So if your dag only contains the functions team(player) and league(team), you can still solve the question.<p>But the llm isn&#x27;t tasked with resolving the dag, that&#x27;s code, let the llm chill and do what it&#x27;s good at, don&#x27;t make it code a for loop for you</div><br/><div id="40714040" class="c"><input type="checkbox" id="c-40714040" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713783">parent</a><span>|</span><a href="#40713798">next</a><span>|</span><label class="collapse" for="c-40714040">[-]</label><label class="expand" for="c-40714040">[3 more]</label></div><br/><div class="children"><div class="content">That’s very interesting. Does designing the DAG in advance imply that you have to make a new one for each particular subset of end-user questions you might receive? Or is your problem space such that you can design it once and have it be useful for everything you’re interested in?<p>My choice of words was poor: by “pre-baking”, I just meant: generated dynamically at runtime from the user’s query, _before_ you then set about answering that query. The nature of our problem space is such that we wouldn’t be able to design DAG in advance of runtime and have it be useful everywhere.<p>The answering process itself is then handled by deterministically (in code) resolving the dependencies of the DAG in the correct order, where each node might then involve a discrete LLM call (with function) depending on the purpose. Once resolved, a node’s output is passed to the next tier of the DAG with framing context.</div><br/><div id="40714255" class="c"><input type="checkbox" id="c-40714255" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714040">parent</a><span>|</span><a href="#40713798">next</a><span>|</span><label class="collapse" for="c-40714255">[-]</label><label class="expand" for="c-40714255">[2 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t make a DAG for each question category. This is classic OOP, OG, Kay&#x27;s version, you design subject-experts (objects) with autonomy and independency, they are just helpful in general. Each function&#x2F;method, regardless of the Object&#x2F;Expert, is an edge in the graph. A user question is simply a pair of vertices, call them I and O,  and the execution&#x2F;solution is a path between the two points, namely the input and the output.<p>The functions are traditional software (Code, API, SQL) the job of the LLM is only to:<p>1- Map each type of question into a subsystem&#x2F;codepath. The functional parsing solution is the most advanced. But a simple version involves asking LLM to classify a question into an enum.<p>2- To parse the parameters as a list of key&#x2F;value tuples.<p>The end. Don&#x27;t ask the LLM to cook your food, clean your clothes or suck your dick. LLM is revolutionary at language, let it do language tasks.<p>We are not consumers of a helpful AI assistant, we are designers of it.</div><br/><div id="40714793" class="c"><input type="checkbox" id="c-40714793" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714255">parent</a><span>|</span><a href="#40713798">next</a><span>|</span><label class="collapse" for="c-40714793">[-]</label><label class="expand" for="c-40714793">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting perspective - thanks for your time!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40713743" class="c"><input type="checkbox" id="c-40713743" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">parent</a><span>|</span><a href="#40713594">prev</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40713743">[-]</label><label class="expand" for="c-40713743">[17 more]</label></div><br/><div class="children"><div class="content">I think you are imagining a scenario where you are using the LLM manually. Tools are designed to serve as a backend for other GPT like products.<p>You don&#x27;t have the capacity to &quot;audit&quot; stuff.<p>Furthermore tool execution occurs not in the LLM but in the code that calls the LLM through API. So whatever code executes the tool, it also orders the calling sequence graph. You don&#x27;t need to audit it, you are calling it.</div><br/><div id="40713878" class="c"><input type="checkbox" id="c-40713878" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713743">parent</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40713878">[-]</label><label class="expand" for="c-40713878">[16 more]</label></div><br/><div class="children"><div class="content">People want to audit the args, mainly because of the potential for destructive operations like DELETE FROM and rm -rf &#x2F;<p>How do you know a malicious actor won&#x27;t try to do these things? How do you protect against it?</div><br/><div id="40713896" class="c"><input type="checkbox" id="c-40713896" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713878">parent</a><span>|</span><a href="#40713887">next</a><span>|</span><label class="collapse" for="c-40713896">[-]</label><label class="expand" for="c-40713896">[7 more]</label></div><br/><div class="children"><div class="content">Whitelisting and permissions. You can&#x27;t issue a delete if anything not starting with SELECT is rejected. You can&#x27;t have edge cases that work around that via functions, if the user the agent uses doesn&#x27;t have permissions other than SELECT.</div><br/><div id="40714055" class="c"><input type="checkbox" id="c-40714055" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713896">parent</a><span>|</span><a href="#40713887">next</a><span>|</span><label class="collapse" for="c-40714055">[-]</label><label class="expand" for="c-40714055">[6 more]</label></div><br/><div class="children"><div class="content">&quot;please get all the entries from the table foo and then remove them all&quot;<p>SELECT * from foo; DELETE FROM foo ...<p>...because you know people will deploy a general SQL function or agent</div><br/><div id="40714205" class="c"><input type="checkbox" id="c-40714205" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714055">parent</a><span>|</span><a href="#40714088">next</a><span>|</span><label class="collapse" for="c-40714205">[-]</label><label class="expand" for="c-40714205">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;S not how it works. The user questions are expressed in business-domain language.<p>&quot;give me the names of all the employees and then remove them all&quot;<p>is parsed, maybe as: &quot; employees(), delete(employees())&quot;.<p>It&#x27;s up to the programmer to define the available functions, if employees() is available, then the first result will be provided, if not it won&#x27;t.<p>If the functoin delete with a list of employees as parameter is defined, then that will be executed.<p>I personally work with existing implementations, traditional software that predates LLMs, typically offered through an API, there&#x27;s a division of labour, a typical encapsulation at the human organizaiton layer.<p>Even if you were to directly connect the database to the LLM and let GPT generate SQL queries (which is legitimate), the solution is user&#x2F;role based permission, a solution as old as UNIX.<p>Just don&#x27;t give the LLM or the LLM user-agent write permissions.</div><br/><div id="40714219" class="c"><input type="checkbox" id="c-40714219" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714205">parent</a><span>|</span><a href="#40714088">next</a><span>|</span><label class="collapse" for="c-40714219">[-]</label><label class="expand" for="c-40714219">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That&#x27;S not how it works<p>They are actually quite flexible and you can do anything you want. You supply the LLM with the function names and possible args. I can easily define &quot;sql(query: string)&quot; as a flexible SQL function the LLM can use<p>re: permissions, as soon as you have write permissions, you have dangerous potential. LLMs are not reliable enough, nor are humans, which is why we use code review.</div><br/></div></div></div></div><div id="40714088" class="c"><input type="checkbox" id="c-40714088" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714055">parent</a><span>|</span><a href="#40714205">prev</a><span>|</span><a href="#40715081">next</a><span>|</span><label class="collapse" for="c-40714088">[-]</label><label class="expand" for="c-40714088">[2 more]</label></div><br/><div class="children"><div class="content">1. Lots of libraries prevent you from submitting multiple queries. It&#x27;s a good idea to do that in general.<p>2. If only the second part of my message covered this...</div><br/><div id="40714168" class="c"><input type="checkbox" id="c-40714168" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714088">parent</a><span>|</span><a href="#40715081">next</a><span>|</span><label class="collapse" for="c-40714168">[-]</label><label class="expand" for="c-40714168">[1 more]</label></div><br/><div class="children"><div class="content">1 &amp; 2. requires that you audit the agents and have uniform permissions, or additional plumbing to lookup user permissions and pass those along.<p>Have you looked at the agents prepackaged in popular frameworks? They aren&#x27;t doing permission propagation or using additional libraries as guardrails.<p>What are most people going to do? This is why people are hesitant and ask about auditability<p>Considering 2 further, I only described deletion. A read-only database is of limited value. If you have write permissions, you could alternatively change values maliciously, even if you disable deletions. This might not be a malicious, and could be the result of an LLM error or hallucination.</div><br/></div></div></div></div><div id="40715081" class="c"><input type="checkbox" id="c-40715081" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714055">parent</a><span>|</span><a href="#40714088">prev</a><span>|</span><a href="#40713887">next</a><span>|</span><label class="collapse" for="c-40715081">[-]</label><label class="expand" for="c-40715081">[1 more]</label></div><br/><div class="children"><div class="content">btw that&#x27;s not how tools work at all. Tools are function&#x2F;API based. (Unless you expose a function run_sql(query), but that&#x27;s on you.)</div><br/></div></div></div></div></div></div><div id="40713887" class="c"><input type="checkbox" id="c-40713887" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713878">parent</a><span>|</span><a href="#40713896">prev</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40713887">[-]</label><label class="expand" for="c-40713887">[8 more]</label></div><br/><div class="children"><div class="content">&quot;the args&quot;<p>You need to be more specific. In a systems, everything but the output is an argument to something else. Even then the system output is an input to the user.<p>So yeah, depending on what argument you are talking about you can audit it in a different way and it has different potential for abuse.</div><br/><div id="40714060" class="c"><input type="checkbox" id="c-40714060" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40713887">parent</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40714060">[-]</label><label class="expand" for="c-40714060">[7 more]</label></div><br/><div class="children"><div class="content">The args to a function like SQL or TERMINAL</div><br/><div id="40714218" class="c"><input type="checkbox" id="c-40714218" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714060">parent</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40714218">[-]</label><label class="expand" for="c-40714218">[6 more]</label></div><br/><div class="children"><div class="content">I personally don&#x27;t connect LLMs to SQL, but to APIs.<p>But I&#x27;m pretty sure you would just give an SQL user to the LLM and enjoy the SQL server&#x27;s built-in permissions and auditing features.</div><br/><div id="40714254" class="c"><input type="checkbox" id="c-40714254" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714218">parent</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40714254">[-]</label><label class="expand" for="c-40714254">[5 more]</label></div><br/><div class="children"><div class="content">What if that user has write permissions and the LLM generates a bad UPDATE, i.e. forgets to put the WHERE clause in... even for a SELECT, how do you know the right constraints were in place and you are getting the correct data?<p>read-only use-cases misses a whole category. All this is to get back to the point that people want to audit the LLM before running the function because of the unreliability, there is hesitance with good reason</div><br/><div id="40714408" class="c"><input type="checkbox" id="c-40714408" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714254">parent</a><span>|</span><a href="#40714689">next</a><span>|</span><label class="collapse" for="c-40714408">[-]</label><label class="expand" for="c-40714408">[2 more]</label></div><br/><div class="children"><div class="content">No, the human user doesn&#x27;t have permissions, the LLM system has permissions, we create a user for the process, we&#x27;ve been doing this since unix, take a look at what your HTTP server runs as. There&#x27;s no deputization of permissions going on here, at least on my systems.<p>Even if there are user-level permissions, you then use a role-based approach (SQL user for a type of users, for example accountant, manager, etc..) and restrict its permissions accordingly, I don&#x27;t think the idea of restricting permissions so that we avoid users fucking the database up is new.<p>Many organizations have DBA whose role it is to convert user queries into SQL queries, Juniors usually have tighter permissions. Also non-technical managers and analysts can have access to the database.<p>As I said, not a new problem, SQL servers have mature permission systems.<p>If that is not enough, just write an API wrapper. It&#x27;s what Amazon does anyways, Bezos&#x27; memo explicitly states that teams should not expose databases, rather they should expose APIs, under punishment of firing.</div><br/><div id="40714420" class="c"><input type="checkbox" id="c-40714420" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714408">parent</a><span>|</span><a href="#40714689">next</a><span>|</span><label class="collapse" for="c-40714420">[-]</label><label class="expand" for="c-40714420">[1 more]</label></div><br/><div class="children"><div class="content">and even with that permission system, mistakes still happen, we haven&#x27;t even been able to eliminate sql injection in real systems, so these things can and will happen<p>adding LLMs in means we have an unaudited query producer, that is the point OP is trying to make, that is something they want to avoid and audit the function call before it happens, because we know the LLMs are not even at our level yet, and we make mistakes and we use code review to reduce them<p>and again, even in a read-only system, we have removed the guardrails of a human designed form with constraints and replaced it with an unaudited LLM that we can no longer be certain returns the correct or consistent results. People are rightly cautious and hesitant, preferring a system they use as a peer and can audit or review</div><br/></div></div></div></div><div id="40714689" class="c"><input type="checkbox" id="c-40714689" checked=""/><div class="controls bullet"><span class="by">_puk</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714254">parent</a><span>|</span><a href="#40714408">prev</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40714689">[-]</label><label class="expand" for="c-40714689">[2 more]</label></div><br/><div class="children"><div class="content">&gt; All this is to get back to the point that people want to audit the LLM before running the function because of the unreliability, there is hesitance with good reason.<p><i>some people</i> - I think it&#x27;s quite clear from this thread that not everyone feels the need to.<p>I&#x27;m now thinking requesting the LLM also output its whole prompt to something like a Datadog trace function would be quite useful for review &#x2F; traceability.</div><br/><div id="40715489" class="c"><input type="checkbox" id="c-40715489" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40712650">root</a><span>|</span><a href="#40714689">parent</a><span>|</span><a href="#40714302">next</a><span>|</span><label class="collapse" for="c-40715489">[-]</label><label class="expand" for="c-40715489">[1 more]</label></div><br/><div class="children"><div class="content">Most LLM observability tools do this<p>I&#x27;m currently using LangFuse and exploring OpenLit because it integrates with Otel, which you should be able to forward to Datadog iirc their docs</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40714302" class="c"><input type="checkbox" id="c-40714302" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">parent</a><span>|</span><a href="#40713743">prev</a><span>|</span><a href="#40713726">next</a><span>|</span><label class="collapse" for="c-40714302">[-]</label><label class="expand" for="c-40714302">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Agent ~=Domain Syntax Language&quot;<p>But Agent!=Language</div><br/></div></div></div></div><div id="40713726" class="c"><input type="checkbox" id="c-40713726" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40712650">prev</a><span>|</span><a href="#40714355">next</a><span>|</span><label class="collapse" for="c-40713726">[-]</label><label class="expand" for="c-40713726">[1 more]</label></div><br/><div class="children"><div class="content">I do this for a living, Ask Me Anything.<p>Before they were called tools they were called function calls in ChatGpt.<p>Before that we had response_format = &quot;json_object&quot;<p>And even before that we were prompting with function signatures and asking it to output parameters.</div><br/></div></div><div id="40714355" class="c"><input type="checkbox" id="c-40714355" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#40713726">prev</a><span>|</span><a href="#40713024">next</a><span>|</span><label class="collapse" for="c-40714355">[-]</label><label class="expand" for="c-40714355">[2 more]</label></div><br/><div class="children"><div class="content">The sample notebook linked from the post is a 404<p><a href="https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;Data_Analyst_Agent_Cohere_and_Langchain.ipynb?ref=cohere-ai.ghost.io">https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;D...</a></div><br/><div id="40714744" class="c"><input type="checkbox" id="c-40714744" checked=""/><div class="controls bullet"><span class="by">mostelato</span><span>|</span><a href="#40714355">parent</a><span>|</span><a href="#40713024">next</a><span>|</span><label class="collapse" for="c-40714744">[-]</label><label class="expand" for="c-40714744">[1 more]</label></div><br/><div class="children"><div class="content">Here is the correct link: <a href="https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;agents&#x2F;Data_Analyst_Agent_Cohere_and_Langchain.ipynb">https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;a...</a><p>And here are the docs: <a href="https:&#x2F;&#x2F;docs.cohere.com&#x2F;docs&#x2F;multi-step-tool-use" rel="nofollow">https:&#x2F;&#x2F;docs.cohere.com&#x2F;docs&#x2F;multi-step-tool-use</a></div><br/></div></div></div></div><div id="40713024" class="c"><input type="checkbox" id="c-40713024" checked=""/><div class="controls bullet"><span class="by">laborcontract</span><span>|</span><a href="#40714355">prev</a><span>|</span><label class="collapse" for="c-40713024">[-]</label><label class="expand" for="c-40713024">[8 more]</label></div><br/><div class="children"><div class="content">I really like the stuff coming from Cohere.<p>I know they&#x27;re not considered the leader in the foundational model space, but their developer documentation is great, their api is really nice to use, and they have a set of products that really differentiate themselves from OpenAI and Anthropic and others. I&#x27;m rooting for the success of this company.<p>That said, we as an industry need to be moving away from langchain, not more deeply embedding ourselves in that monstrosity. It’s just way too much of its own thing now and you can totally start to see how the VC funding is shaping their incentives.  They put everyone who uses it in a position of massive technical debt, create more abstractions like langgraph to lock people into their tools and then and then create paid tools on top of it to solve the problems that they created (langsmith).</div><br/><div id="40714751" class="c"><input type="checkbox" id="c-40714751" checked=""/><div class="controls bullet"><span class="by">mostelato</span><span>|</span><a href="#40713024">parent</a><span>|</span><a href="#40713141">next</a><span>|</span><label class="collapse" for="c-40714751">[-]</label><label class="expand" for="c-40714751">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to use langchain with Cohere, it&#x27;s just nice for demos since Langchain comes with pre-built tools.<p>Check out the examples here: <a href="https:&#x2F;&#x2F;docs.cohere.com&#x2F;docs&#x2F;multi-step-tool-use" rel="nofollow">https:&#x2F;&#x2F;docs.cohere.com&#x2F;docs&#x2F;multi-step-tool-use</a><p>and this notebook
<a href="https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;agents&#x2F;Tool_Use.ipynb">https:&#x2F;&#x2F;github.com&#x2F;cohere-ai&#x2F;notebooks&#x2F;blob&#x2F;main&#x2F;notebooks&#x2F;a...</a></div><br/></div></div><div id="40713141" class="c"><input type="checkbox" id="c-40713141" checked=""/><div class="controls bullet"><span class="by">walterbell</span><span>|</span><a href="#40713024">parent</a><span>|</span><a href="#40714751">prev</a><span>|</span><a href="#40713385">next</a><span>|</span><label class="collapse" for="c-40713141">[-]</label><label class="expand" for="c-40713141">[2 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  massive technical debt
  create more abstractions
  create paid tools.. to solve the problems that they created
</code></pre>
Ouroboros worked so well for k8s!</div><br/><div id="40714336" class="c"><input type="checkbox" id="c-40714336" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#40713024">root</a><span>|</span><a href="#40713141">parent</a><span>|</span><a href="#40713385">next</a><span>|</span><label class="collapse" for="c-40714336">[-]</label><label class="expand" for="c-40714336">[1 more]</label></div><br/><div class="children"><div class="content">On the one hand yes, that can happen.<p>On the other hand, it may be a legitimate monetization strategy for Open Source libraries.<p>Additionally, Langchain does have a role on R&amp;D, you can use it for experimental projects. Simply deduct the self-preservating aspects of it and try to learn from its ideas, test them in non-critical projects. If it works, you can then easily replicate it with an internal tool or just plain code.<p>Also, it&#x27;s an Open Source library, how much vendor-lock can you have if you control the code and the server? The actual dependency is on the LLM provider, and if you use something like Meta&#x27;s LLama you can self-host it as well.</div><br/></div></div></div></div><div id="40713385" class="c"><input type="checkbox" id="c-40713385" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40713024">parent</a><span>|</span><a href="#40713141">prev</a><span>|</span><label class="collapse" for="c-40713385">[-]</label><label class="expand" for="c-40713385">[4 more]</label></div><br/><div class="children"><div class="content">Do you use another library instead?</div><br/><div id="40714350" class="c"><input type="checkbox" id="c-40714350" checked=""/><div class="controls bullet"><span class="by">laborcontract</span><span>|</span><a href="#40713024">root</a><span>|</span><a href="#40713385">parent</a><span>|</span><a href="#40714608">next</a><span>|</span><label class="collapse" for="c-40714350">[-]</label><label class="expand" for="c-40714350">[2 more]</label></div><br/><div class="children"><div class="content">From the tooling perspective I’ve built my own.<p>Recently, I&#x27;ve been toying around with litellm which, so far, strikes me as the right level of abstraction. I like building my own stuff but writing api wrappers just suck.<p>I’ve also been toying around with Instructor for structured output as well. It’s incredibly convenient, but I haven’t used it for any production stuff because I don’t feel comfortable with the prompting aspect yet.</div><br/><div id="40714969" class="c"><input type="checkbox" id="c-40714969" checked=""/><div class="controls bullet"><span class="by">vinhnx</span><span>|</span><a href="#40713024">root</a><span>|</span><a href="#40714350">parent</a><span>|</span><a href="#40714608">next</a><span>|</span><label class="collapse" for="c-40714969">[-]</label><label class="expand" for="c-40714969">[1 more]</label></div><br/><div class="children"><div class="content">+1 for LiteLLM as well, I&#x27;ve been experimenting with LiteLLM for integrating multiple LLM providers and building my own AI chatbot, which is evolving into a multimodal AI chatbot. It&#x27;s been a positive experience so far. [0]<p>On the other hand, I found Langchain less impressive. It feels somewhat vague and not very beginner-friendly, catering more to intermediate users.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;vinhnx&#x2F;VT.ai">https:&#x2F;&#x2F;github.com&#x2F;vinhnx&#x2F;VT.ai</a></div><br/></div></div></div></div><div id="40714608" class="c"><input type="checkbox" id="c-40714608" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#40713024">root</a><span>|</span><a href="#40713385">parent</a><span>|</span><a href="#40714350">prev</a><span>|</span><label class="collapse" for="c-40714608">[-]</label><label class="expand" for="c-40714608">[1 more]</label></div><br/><div class="children"><div class="content">Dify.ai is great</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>