<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722070848590" as="style"/><link rel="stylesheet" href="styles.css?v=1722070848590"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.mattstuchlik.com/2024/07/21/fastest-memory-read.html">Counting bytes faster than you&#x27;d think possible</a> <span class="domain">(<a href="https://blog.mattstuchlik.com">blog.mattstuchlik.com</a>)</span></div><div class="subtext"><span>asicsp</span> | <span>28 comments</span></div><br/><div><div id="41080758" class="c"><input type="checkbox" id="c-41080758" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41082191">next</a><span>|</span><label class="collapse" for="c-41080758">[-]</label><label class="expand" for="c-41080758">[1 more]</label></div><br/><div class="children"><div class="content">My own solution which is ~1ms faster uses some other pattern that was found experimentally, but I cannot seem to get it to go any faster by tuning the parameters, and the #1 spot remains slightly out of reach.<p>Alexander Monakov has called the attention of the highload Telegram chat to this paper[0], saying:<p><pre><code>  Haswell is tricky for memory bw tuning, as even at fixed core frequency, uncore frequency is not fixed, and depends on factors such as hardware-measured stall cycles:

  &gt; According to the respective patent [15], the uncore frequency depends on the stall cycles of the cores, the EPB of the cores, and c-states

  &gt; ... uncore frequencies–in addition to EPB and stall cycles–depend on the core frequency of the fastest active core on the system. Moreover, the uncore frequency is also a target of power limitations.
</code></pre>
So one wonders if it&#x27;s not really a matter of reading the RAM in the right pattern to appease the prefetchers but of using values in the right pattern to create the right pattern of stalls to get the highest frequency.<p>[0]: <a href="https:&#x2F;&#x2F;tu-dresden.de&#x2F;zih&#x2F;forschung&#x2F;ressourcen&#x2F;dateien&#x2F;projekte&#x2F;firestarter&#x2F;2015_hackenberg_hppac.pdf?lang=en" rel="nofollow">https:&#x2F;&#x2F;tu-dresden.de&#x2F;zih&#x2F;forschung&#x2F;ressourcen&#x2F;dateien&#x2F;proje...</a></div><br/></div></div><div id="41082191" class="c"><input type="checkbox" id="c-41082191" checked=""/><div class="controls bullet"><span class="by">sYnfo</span><span>|</span><a href="#41080758">prev</a><span>|</span><a href="#41084825">next</a><span>|</span><label class="collapse" for="c-41082191">[-]</label><label class="expand" for="c-41082191">[2 more]</label></div><br/><div class="children"><div class="content">FYI vien [0] figured out that simply compiling with &quot;-static -fno-pie&quot; and _exit(0)-ing at the end puts the solution presented here to 15000 points and hence #4 on the leaderboard. Pretty funny.<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;user?id=vient">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;user?id=vient</a></div><br/><div id="41083548" class="c"><input type="checkbox" id="c-41083548" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#41082191">parent</a><span>|</span><a href="#41084825">next</a><span>|</span><label class="collapse" for="c-41083548">[-]</label><label class="expand" for="c-41083548">[1 more]</label></div><br/><div class="children"><div class="content">Optimizing the leftovers loop to<p><pre><code>    #pragma clang loop vectorize(enable)
    #pragma clang loop interleave(enable)
    for (; offset &lt; length; offset += 4) {
        const auto x = ((uint32_t\*)start)[offset &#x2F; 4];
        count += ((x &amp; 0xFF) == 0x7F);
        count += ((x &amp; 0xFF00) == 0x7F00);
        count += ((x &amp; 0xFF0000) == 0x7F0000);
        count += ((x &amp; 0xFF000000) == 0x7F000000);
    }
</code></pre>
also gives some points. It&#x27;d probably be more if I could be bothered to break apart your assembly. :)</div><br/></div></div></div></div><div id="41084825" class="c"><input type="checkbox" id="c-41084825" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#41082191">prev</a><span>|</span><a href="#41081319">next</a><span>|</span><label class="collapse" for="c-41084825">[-]</label><label class="expand" for="c-41084825">[3 more]</label></div><br/><div class="children"><div class="content">Usually, it&#x27;s fair game to use all of the information presented in an exam-style question to derive your answer.<p>With that in mind, I propose the following solution.<p>`print(976563)`</div><br/><div id="41084886" class="c"><input type="checkbox" id="c-41084886" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41084825">parent</a><span>|</span><a href="#41081319">next</a><span>|</span><label class="collapse" for="c-41084886">[-]</label><label class="expand" for="c-41084886">[2 more]</label></div><br/><div class="children"><div class="content">You can submit that, it will fail.</div><br/></div></div></div></div><div id="41081319" class="c"><input type="checkbox" id="c-41081319" checked=""/><div class="controls bullet"><span class="by">dinobones</span><span>|</span><a href="#41084825">prev</a><span>|</span><a href="#41081736">next</a><span>|</span><label class="collapse" for="c-41081319">[-]</label><label class="expand" for="c-41081319">[8 more]</label></div><br/><div class="children"><div class="content">Is there a path forward for compilers to eek out these optimization gains eventually? Is there even a path?<p>550x gains with some C ++ &#x2F; mixed gnarly low level assembly vs standard C++ is pretty shocking to me.</div><br/><div id="41082387" class="c"><input type="checkbox" id="c-41082387" checked=""/><div class="controls bullet"><span class="by">monktastic1</span><span>|</span><a href="#41081319">parent</a><span>|</span><a href="#41081429">next</a><span>|</span><label class="collapse" for="c-41082387">[-]</label><label class="expand" for="c-41082387">[1 more]</label></div><br/><div class="children"><div class="content">FYI, &quot;eke.&quot; &quot;Eek&quot; is an expression of alarm or surprise.</div><br/></div></div><div id="41081429" class="c"><input type="checkbox" id="c-41081429" checked=""/><div class="controls bullet"><span class="by">vient</span><span>|</span><a href="#41081319">parent</a><span>|</span><a href="#41082387">prev</a><span>|</span><a href="#41081736">next</a><span>|</span><label class="collapse" for="c-41081429">[-]</label><label class="expand" for="c-41081429">[6 more]</label></div><br/><div class="children"><div class="content">Note that &quot;standard C++&quot; solution uses std::cin while optimized one uses mmap - completely different things, a lot of speed comes just from that. Would&#x27;ve been nice to compare with solution having optimized input and otherwise standard summing loop.</div><br/><div id="41081485" class="c"><input type="checkbox" id="c-41081485" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41081319">root</a><span>|</span><a href="#41081429">parent</a><span>|</span><a href="#41081736">next</a><span>|</span><label class="collapse" for="c-41081485">[-]</label><label class="expand" for="c-41081485">[5 more]</label></div><br/><div class="children"><div class="content">For a solution that contains this stuff<p><pre><code>  const u8 *file_lo;
  file_lo = (const u8*)mmap(0,250000000ull,PROT_READ,MAP_PRIVATE|MAP_POPULATE,0,0);
  const u8 *file_hi = file_lo + 250000000ull;
  u64 count = 0;
  while (file_lo &lt; file_hi) {
    if (*file_lo == 127) {
        ++count;
    }
    file_lo++;
  }
</code></pre>
I got a bit under 54ms. The solution in the article runs in a bit under 16ms.</div><br/><div id="41081630" class="c"><input type="checkbox" id="c-41081630" checked=""/><div class="controls bullet"><span class="by">vient</span><span>|</span><a href="#41081319">root</a><span>|</span><a href="#41081485">parent</a><span>|</span><a href="#41084969">next</a><span>|</span><label class="collapse" for="c-41081630">[-]</label><label class="expand" for="c-41081630">[3 more]</label></div><br/><div class="children"><div class="content">Nice. Did some quick tests with your code on site, got score of ~34000 - best solution is around 14700, so this one is only 2.3 times slower.<p>Used clang with -Ofast -march=native -static. Funnily, gcc gets only 54000 with the same options, 1.6 times slower.</div><br/><div id="41081735" class="c"><input type="checkbox" id="c-41081735" checked=""/><div class="controls bullet"><span class="by">vient</span><span>|</span><a href="#41081319">root</a><span>|</span><a href="#41081630">parent</a><span>|</span><a href="#41084969">next</a><span>|</span><label class="collapse" for="c-41081735">[-]</label><label class="expand" for="c-41081735">[2 more]</label></div><br/><div class="children"><div class="content">Wow, changing `count` type from uint64_t to uint32_t or int radically changes results - now gcc gets 26500 and clang gets 25000, that&#x27;s just 1.7 times slower than current best solution.<p>So you can get 25k with following code, clang -Ofast -std=c++17 -march=native -static<p><pre><code>    #include &lt;iostream&gt;
    #include &lt;cstdint&gt;
    #include &lt;sys&#x2F;mman.h&gt;
    #include &lt;unistd.h&gt;

    int main() {
      auto file_lo = (const uint8_t*)mmap(0,250000000ull,PROT_READ,MAP_PRIVATE|MAP_POPULATE,STDIN_FILENO,0);
      int count = 0;
      for (uint32_t i = 0; i &lt; 250000000; ++i) {
        if (file_lo[i] == 127) {
            ++count;
        }
      }
      std::cout &lt;&lt; count &lt;&lt; std::endl;
      _exit(0);
      return 0;
    }</code></pre></div><br/><div id="41081780" class="c"><input type="checkbox" id="c-41081780" checked=""/><div class="controls bullet"><span class="by">sYnfo</span><span>|</span><a href="#41081319">root</a><span>|</span><a href="#41081735">parent</a><span>|</span><a href="#41084969">next</a><span>|</span><label class="collapse" for="c-41081780">[-]</label><label class="expand" for="c-41081780">[1 more]</label></div><br/><div class="children"><div class="content">Neat! I&#x27;ll add the best solution without explicit SIMD&#x2F;asm in this thread to the post after I wake up, it&#x27;s a great datapoint.</div><br/></div></div></div></div></div></div><div id="41084969" class="c"><input type="checkbox" id="c-41084969" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41081319">root</a><span>|</span><a href="#41081485">parent</a><span>|</span><a href="#41081630">prev</a><span>|</span><a href="#41081736">next</a><span>|</span><label class="collapse" for="c-41084969">[-]</label><label class="expand" for="c-41084969">[1 more]</label></div><br/><div class="children"><div class="content">Bit rusty here but what if you replaced<p><pre><code>    if (*file_lo == 127) {
        ++count;
</code></pre>
with<p><pre><code>    count += (*file_lo == 127);
</code></pre>
That might save you the occasional branch mis-prediction, and might possibly open up some hardware-level loop optimisations. Any difference?</div><br/></div></div></div></div></div></div></div></div><div id="41081736" class="c"><input type="checkbox" id="c-41081736" checked=""/><div class="controls bullet"><span class="by">lumb63</span><span>|</span><a href="#41081319">prev</a><span>|</span><a href="#41080718">next</a><span>|</span><label class="collapse" for="c-41081736">[-]</label><label class="expand" for="c-41081736">[3 more]</label></div><br/><div class="children"><div class="content">Does anyone have any tips for similar wizardry-level SIMD optimization on ARM?</div><br/><div id="41081931" class="c"><input type="checkbox" id="c-41081931" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41081736">parent</a><span>|</span><a href="#41082870">next</a><span>|</span><label class="collapse" for="c-41081931">[-]</label><label class="expand" for="c-41081931">[1 more]</label></div><br/><div class="children"><div class="content">If you learn AVX2 programming via highload, my impression is that NEON is quite similar. The main difference is the lack of movemask. You can read these[0] articles[1] about what to do instead.<p>For SVE, prior to very recent versions of SVE, there was no tblq (pshufb equivalent) so I didn&#x27;t have much hope for using it for general-purpose programming, though of course it would be fine for stuff like TFA.<p>[0]: <a href="https:&#x2F;&#x2F;community.arm.com&#x2F;arm-community-blogs&#x2F;b&#x2F;infrastructure-solutions-blog&#x2F;posts&#x2F;porting-x86-vector-bitmask-optimizations-to-arm-neon" rel="nofollow">https:&#x2F;&#x2F;community.arm.com&#x2F;arm-community-blogs&#x2F;b&#x2F;infrastructu...</a><p>[1]: <a href="https:&#x2F;&#x2F;www.corsix.org&#x2F;content&#x2F;whirlwind-tour-aarch64-vector-instructions" rel="nofollow">https:&#x2F;&#x2F;www.corsix.org&#x2F;content&#x2F;whirlwind-tour-aarch64-vector...</a></div><br/></div></div><div id="41082870" class="c"><input type="checkbox" id="c-41082870" checked=""/><div class="controls bullet"><span class="by">TinkersW</span><span>|</span><a href="#41081736">parent</a><span>|</span><a href="#41081931">prev</a><span>|</span><a href="#41080718">next</a><span>|</span><label class="collapse" for="c-41082870">[-]</label><label class="expand" for="c-41082870">[1 more]</label></div><br/><div class="children"><div class="content">It isn&#x27;t as wide on ARM so the gains will be smaller(most ARM is only 128 bit wide neon)</div><br/></div></div></div></div><div id="41080718" class="c"><input type="checkbox" id="c-41080718" checked=""/><div class="controls bullet"><span class="by">rini17</span><span>|</span><a href="#41081736">prev</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41080718">[-]</label><label class="expand" for="c-41080718">[6 more]</label></div><br/><div class="children"><div class="content">Can this optimization be applied to matmult for us, critters who are running llama on cpu? XD</div><br/><div id="41080900" class="c"><input type="checkbox" id="c-41080900" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#41080718">parent</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41080900">[-]</label><label class="expand" for="c-41080900">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this really helps: It&#x27;s a trick to drive maximum possible memory bandwidth in service of a single executing thread which can process data as fast as it&#x27;s being delivered.<p>A parallel matrix multiply running across every core shouldn&#x27;t have any trouble maximizing memory bandwidth utilization.</div><br/><div id="41080976" class="c"><input type="checkbox" id="c-41080976" checked=""/><div class="controls bullet"><span class="by">owlbite</span><span>|</span><a href="#41080718">root</a><span>|</span><a href="#41080900">parent</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41080976">[-]</label><label class="expand" for="c-41080976">[4 more]</label></div><br/><div class="children"><div class="content">KV-cache based LLM inference is normally significantly memory bound on the matrix-vector multiply. This is (part of) why the quantization-based approaches are so popular.</div><br/><div id="41081396" class="c"><input type="checkbox" id="c-41081396" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#41080718">root</a><span>|</span><a href="#41080976">parent</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41081396">[-]</label><label class="expand" for="c-41081396">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s memory bound <i>and</i> single threaded?</div><br/><div id="41081580" class="c"><input type="checkbox" id="c-41081580" checked=""/><div class="controls bullet"><span class="by">rini17</span><span>|</span><a href="#41080718">root</a><span>|</span><a href="#41081396">parent</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41081580">[-]</label><label class="expand" for="c-41081580">[2 more]</label></div><br/><div class="children"><div class="content">I found it memory bound so that it was fastest with 6 threads on my 8 thread xeon.</div><br/><div id="41083045" class="c"><input type="checkbox" id="c-41083045" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#41080718">root</a><span>|</span><a href="#41081580">parent</a><span>|</span><a href="#41084940">next</a><span>|</span><label class="collapse" for="c-41083045">[-]</label><label class="expand" for="c-41083045">[1 more]</label></div><br/><div class="children"><div class="content">Right: So this trick probably doesn’t help much. You only need prefetch when there isn’t enough fetch otherwise.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41084940" class="c"><input type="checkbox" id="c-41084940" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41080718">prev</a><span>|</span><a href="#41082281">next</a><span>|</span><label class="collapse" for="c-41084940">[-]</label><label class="expand" for="c-41084940">[3 more]</label></div><br/><div class="children"><div class="content">&quot;The solution presented here is ~550x faster than the following naive program.&quot;<p><pre><code>   ... std::cin &gt;&gt; v; ...
</code></pre>
Oh come on! That&#x27;s I&#x2F;O for every item, I&#x27;m surprised it&#x27;s not even slower.</div><br/><div id="41085094" class="c"><input type="checkbox" id="c-41085094" checked=""/><div class="controls bullet"><span class="by">BoardsOfCanada</span><span>|</span><a href="#41084940">parent</a><span>|</span><a href="#41082281">next</a><span>|</span><label class="collapse" for="c-41085094">[-]</label><label class="expand" for="c-41085094">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, how does the proposed solution solve the problem as stated: &quot;Print the number of bytes whose value equals 127 in a 250MB stream of bytes uniformly sampled from [0, 255] <i>sent to standard input</i>.&quot;</div><br/><div id="41085110" class="c"><input type="checkbox" id="c-41085110" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41084940">root</a><span>|</span><a href="#41085094">parent</a><span>|</span><a href="#41082281">next</a><span>|</span><label class="collapse" for="c-41085110">[-]</label><label class="expand" for="c-41085110">[1 more]</label></div><br/><div class="children"><div class="content">When stdin is a file, as it is in this case, you can mmap it.</div><br/></div></div></div></div></div></div><div id="41082281" class="c"><input type="checkbox" id="c-41082281" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#41084940">prev</a><span>|</span><label class="collapse" for="c-41082281">[-]</label><label class="expand" for="c-41082281">[1 more]</label></div><br/><div class="children"><div class="content">Le met hazard a guess: that blog post was <i>not</i> written by a LLM!?</div><br/></div></div></div></div></div></div></div></body></html>