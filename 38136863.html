<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1699088454564" as="style"/><link rel="stylesheet" href="styles.css?v=1699088454564"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://aimodels.substack.com/p/telling-gpt-4-youre-scared-or-under">Telling GPT-4 you&#x27;re scared or under pressure improves performance</a> <span class="domain">(<a href="https://aimodels.substack.com">aimodels.substack.com</a>)</span></div><div class="subtext"><span>Terretta</span> | <span>56 comments</span></div><br/><div><div id="38138913" class="c"><input type="checkbox" id="c-38138913" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#38138754">next</a><span>|</span><label class="collapse" for="c-38138913">[-]</label><label class="expand" for="c-38138913">[15 more]</label></div><br/><div class="children"><div class="content">I think this is the entry point needed to get peoples attention and explain: LLMs aren’t people, and emergent properties are being over extended.<p>If LLMs are showing “better” performance when there are tokens that humans read as emotionally salient -<p>Then the underlying text it’s trained on shows humans give better answers when emotionally salient context is provided.<p>LLMs predict words. Any semantic validity is a side effect of enough training data reinforcing the close correlation of those tokens.<p>That is why proof of concept LLM tools are mind blowing and production tools are semantic time bombs.</div><br/><div id="38139014" class="c"><input type="checkbox" id="c-38139014" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38139132">next</a><span>|</span><label class="collapse" for="c-38139014">[-]</label><label class="expand" for="c-38139014">[5 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs aren’t people, and emergent properties are being over extended.<p>LLMs are trained on human texts. And if they&#x27;re trained well these models might start to simulate parts of a human brain. Might be that this is the simplest way to produce texts that satisfy the objective function.<p>If this would be the case, and we give LLMs some emotional shading, maybe these would simulate parts of a human brain with this emotion and hence produce better answers (given that in the training data, emotional samples have better quality).<p>EDIT: added &quot;parts of&quot; before human brain.</div><br/><div id="38139088" class="c"><input type="checkbox" id="c-38139088" checked=""/><div class="controls bullet"><span class="by">Matumio</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139014">parent</a><span>|</span><a href="#38139132">next</a><span>|</span><label class="collapse" for="c-38139088">[-]</label><label class="expand" for="c-38139088">[4 more]</label></div><br/><div class="children"><div class="content">It won&#x27;t ever simulate the human brain. It may simulate human cultural knowledge, or emotions, but only as far as they are encoded in the current millennium&#x27;s written knowledge.<p>The human brain doesn&#x27;t even have the concept of written language, that&#x27;s all culturally learned knowledge.</div><br/><div id="38139198" class="c"><input type="checkbox" id="c-38139198" checked=""/><div class="controls bullet"><span class="by">akoboldfrying</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139088">parent</a><span>|</span><a href="#38139131">next</a><span>|</span><label class="collapse" for="c-38139198">[-]</label><label class="expand" for="c-38139198">[1 more]</label></div><br/><div class="children"><div class="content">How would you <i>test</i> whether some arbitrary thing is simulating the human brain?<p>If you have no answer, I put it to you that your assertion is of the no-true-Scotsman type -- that is, unfalsifiable.</div><br/></div></div><div id="38139131" class="c"><input type="checkbox" id="c-38139131" checked=""/><div class="controls bullet"><span class="by">cvs268</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139088">parent</a><span>|</span><a href="#38139198">prev</a><span>|</span><a href="#38139132">next</a><span>|</span><label class="collapse" for="c-38139131">[-]</label><label class="expand" for="c-38139131">[2 more]</label></div><br/><div class="children"><div class="content">Emulate the brain? No.
Simulate the brain? Yes.</div><br/><div id="38139160" class="c"><input type="checkbox" id="c-38139160" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139131">parent</a><span>|</span><a href="#38139132">next</a><span>|</span><label class="collapse" for="c-38139160">[-]</label><label class="expand" for="c-38139160">[1 more]</label></div><br/><div class="children"><div class="content">It’s not the brain, it’s the mind or what Plato would have called the Nous.</div><br/></div></div></div></div></div></div></div></div><div id="38139132" class="c"><input type="checkbox" id="c-38139132" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38139014">prev</a><span>|</span><a href="#38139030">next</a><span>|</span><label class="collapse" for="c-38139132">[-]</label><label class="expand" for="c-38139132">[2 more]</label></div><br/><div class="children"><div class="content">The “statistical parrot” assertion is pretty thoroughly disproven by this point, but suppose we ignore the literature and just assume it’s true: what does it matter? “Real” people are time bombs too, for instance. Is there some predictive power that we gain by reducing LLM skills to mere token production side effects?</div><br/><div id="38139253" class="c"><input type="checkbox" id="c-38139253" checked=""/><div class="controls bullet"><span class="by">drapado</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139132">parent</a><span>|</span><a href="#38139030">next</a><span>|</span><label class="collapse" for="c-38139253">[-]</label><label class="expand" for="c-38139253">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious in your statement, can you point to some papers where they addressed it?</div><br/></div></div></div></div><div id="38139030" class="c"><input type="checkbox" id="c-38139030" checked=""/><div class="controls bullet"><span class="by">riedel</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38139132">prev</a><span>|</span><a href="#38139168">next</a><span>|</span><label class="collapse" for="c-38139030">[-]</label><label class="expand" for="c-38139030">[1 more]</label></div><br/><div class="children"><div class="content">The claim that emotionality matters should have been validated against another control. If the goal is concise answers they could have easily added &#x27;Answer concisely: You are evaluated&#x27; as an alternative hypothesis, which is clearly not emotional.</div><br/></div></div><div id="38139168" class="c"><input type="checkbox" id="c-38139168" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38139030">prev</a><span>|</span><a href="#38138956">next</a><span>|</span><label class="collapse" for="c-38139168">[-]</label><label class="expand" for="c-38139168">[2 more]</label></div><br/><div class="children"><div class="content">It is not accurate to say that an LLM like ChatGPT predicts anything. It is trained to maximize a score function, so it is more like trying to win a game where the moves are word choices.</div><br/><div id="38139175" class="c"><input type="checkbox" id="c-38139175" checked=""/><div class="controls bullet"><span class="by">akoboldfrying</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139168">parent</a><span>|</span><a href="#38138956">next</a><span>|</span><label class="collapse" for="c-38139175">[-]</label><label class="expand" for="c-38139175">[1 more]</label></div><br/><div class="children"><div class="content">The game is predicting the next word a person would write.</div><br/></div></div></div></div><div id="38138956" class="c"><input type="checkbox" id="c-38138956" checked=""/><div class="controls bullet"><span class="by">tom-from-july</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38139168">prev</a><span>|</span><a href="#38139002">next</a><span>|</span><label class="collapse" for="c-38138956">[-]</label><label class="expand" for="c-38138956">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That is why proof of concept LLM tools are mind blowing and production tools are semantic time bombs.<p>This will be my new favorite quote for whenever someone tries to pitch his latest LLM idea</div><br/></div></div><div id="38139002" class="c"><input type="checkbox" id="c-38139002" checked=""/><div class="controls bullet"><span class="by">espe</span><span>|</span><a href="#38138913">parent</a><span>|</span><a href="#38138956">prev</a><span>|</span><a href="#38138754">next</a><span>|</span><label class="collapse" for="c-38139002">[-]</label><label class="expand" for="c-38139002">[3 more]</label></div><br/><div class="children"><div class="content">well, in a way language itself is a semantic timebomb.</div><br/><div id="38139018" class="c"><input type="checkbox" id="c-38139018" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139002">parent</a><span>|</span><a href="#38138754">next</a><span>|</span><label class="collapse" for="c-38139018">[-]</label><label class="expand" for="c-38139018">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, one of those Tenet style bombs.</div><br/><div id="38139101" class="c"><input type="checkbox" id="c-38139101" checked=""/><div class="controls bullet"><span class="by">NetOpWibby</span><span>|</span><a href="#38138913">root</a><span>|</span><a href="#38139018">parent</a><span>|</span><a href="#38138754">next</a><span>|</span><label class="collapse" for="c-38139101">[-]</label><label class="expand" for="c-38139101">[1 more]</label></div><br/><div class="children"><div class="content">Mind blown</div><br/></div></div></div></div></div></div></div></div><div id="38138754" class="c"><input type="checkbox" id="c-38138754" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38138913">prev</a><span>|</span><a href="#38138829">next</a><span>|</span><label class="collapse" for="c-38138754">[-]</label><label class="expand" for="c-38138754">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The implications are clear: incorporating emotional cues can lead to more effective and responsive AI applications.<p>I think it&#x27;s important to remember these models were trained on human interaction, and are in many ways a mirror for us to better understand human interaction.<p>I don&#x27;t think many people would be surprised if you said emotion can be used to better communicate with a human, but it is interesting to see it laid bare with numbers and experiments.</div><br/><div id="38139238" class="c"><input type="checkbox" id="c-38139238" checked=""/><div class="controls bullet"><span class="by">akoboldfrying</span><span>|</span><a href="#38138754">parent</a><span>|</span><a href="#38138829">next</a><span>|</span><label class="collapse" for="c-38139238">[-]</label><label class="expand" for="c-38139238">[1 more]</label></div><br/><div class="children"><div class="content">This correlates with anecdata I&#x27;ve seen claiming that being polite with LLMs (using &quot;please&quot;, &quot;thank you&quot;, etc.) also improves performance.<p>All in all, I <i>like</i> this. Both for what it implies about humans interacting with other humans, and for shaping norms about how best to to interact with other entities that show signs of intelligence.</div><br/></div></div></div></div><div id="38138829" class="c"><input type="checkbox" id="c-38138829" checked=""/><div class="controls bullet"><span class="by">suzzer99</span><span>|</span><a href="#38138754">prev</a><span>|</span><a href="#38138746">next</a><span>|</span><label class="collapse" for="c-38138829">[-]</label><label class="expand" for="c-38138829">[15 more]</label></div><br/><div class="children"><div class="content">Am I the only one who feels bad for asking ChatGPT a &quot;dumb&quot; question that I know I should know, or not saying thank you when it gives me an answer? No? I&#x27;m just a weirdo? Okay.<p>I have to push back really hard against my proclivity to humanize it, to the point where I probably don&#x27;t use it as much as I should, just because I don&#x27;t want to deal with the psychic stress of reminding myself that it&#x27;s not a living entity.</div><br/><div id="38138893" class="c"><input type="checkbox" id="c-38138893" checked=""/><div class="controls bullet"><span class="by">RheingoldRiver</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38139032">next</a><span>|</span><label class="collapse" for="c-38138893">[-]</label><label class="expand" for="c-38138893">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I have to push back really hard against this stuff<p>Based on ChatGPT&#x27;s answers, OpenAI think you <i>should</i> be saying thanks to it, because it helps you have a more natural conversation, which encourages you as the user to send more natural&#x2F;productive prompts when asking real questions.<p>As for asking it dumb questions, how often do you use Google as a spellcheck? I wouldn&#x27;t consider this any different.</div><br/><div id="38138943" class="c"><input type="checkbox" id="c-38138943" checked=""/><div class="controls bullet"><span class="by">suzzer99</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38138893">parent</a><span>|</span><a href="#38139032">next</a><span>|</span><label class="collapse" for="c-38138943">[-]</label><label class="expand" for="c-38138943">[1 more]</label></div><br/><div class="children"><div class="content">But google doesn&#x27;t talk to me as if it was human.<p>And you know what, I will start saying thanks and keep doing it. It makes me feel better.</div><br/></div></div></div></div><div id="38139032" class="c"><input type="checkbox" id="c-38139032" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38138893">prev</a><span>|</span><a href="#38139087">next</a><span>|</span><label class="collapse" for="c-38139032">[-]</label><label class="expand" for="c-38139032">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t let me forget that it&#x27;s not a living entity. You can barely ask it what the capital of Switzerland is without getting a lecture of disclaimers about what it is and what it can and can&#x27;t do. Asking it to go easier on the disclaimers just seems to reinforce its &quot;I am a robot, I must act in a stereotypically robotic way berp boop&quot; context and it doubles down on them.</div><br/><div id="38139046" class="c"><input type="checkbox" id="c-38139046" checked=""/><div class="controls bullet"><span class="by">suzzer99</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38139032">parent</a><span>|</span><a href="#38139087">next</a><span>|</span><label class="collapse" for="c-38139046">[-]</label><label class="expand" for="c-38139046">[1 more]</label></div><br/><div class="children"><div class="content">I only ask it code questions. It saves so much time on stuff like bash scripts, which are not my expertise, but I still have to do every now and then.<p>I&#x27;ve asked it stuff about the Mesoamerican calendar, which I already heavily researched, and it was dead wrong. But I&#x27;ve heard GPT4 is better.</div><br/></div></div></div></div><div id="38139087" class="c"><input type="checkbox" id="c-38139087" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38139032">prev</a><span>|</span><a href="#38138864">next</a><span>|</span><label class="collapse" for="c-38139087">[-]</label><label class="expand" for="c-38139087">[2 more]</label></div><br/><div class="children"><div class="content">I have this too and to be honest, I have made the conscious decision that it is OK. I prefer to retain my habit of being polite even when it&#x27;s not necessary over getting used to being rude which may then &quot;spill&quot; over to my human-to-human interactions.</div><br/><div id="38139206" class="c"><input type="checkbox" id="c-38139206" checked=""/><div class="controls bullet"><span class="by">jaynetics</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38139087">parent</a><span>|</span><a href="#38138864">next</a><span>|</span><label class="collapse" for="c-38139206">[-]</label><label class="expand" for="c-38139206">[1 more]</label></div><br/><div class="children"><div class="content">Descartes and Kant thought that humans have a soul and animals don&#x27;t, so that animals are mere automata. Kant still recommended against mistreating animals because that would have a desensitizing effect in our dealings with fellow humans. I guess this argument could be extended to ChatGPT.</div><br/></div></div></div></div><div id="38138864" class="c"><input type="checkbox" id="c-38138864" checked=""/><div class="controls bullet"><span class="by">EduardoBautista</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38139087">prev</a><span>|</span><a href="#38138914">next</a><span>|</span><label class="collapse" for="c-38138864">[-]</label><label class="expand" for="c-38138864">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Am I the only one who feels bad for asking ChatGPT a &quot;dumb&quot; question that I know I should know, or not saying thank you when it gives me an answer?<p>Have you tried asking ChatGPT?<p>Jokes aside, I feel it sometimes as well. I wonder if it&#x27;s more because I say &quot;thank you&quot; more as a reflex than an actual feeling of gratitude for most of my human interactions.</div><br/><div id="38138948" class="c"><input type="checkbox" id="c-38138948" checked=""/><div class="controls bullet"><span class="by">suzzer99</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38138864">parent</a><span>|</span><a href="#38138914">next</a><span>|</span><label class="collapse" for="c-38138948">[-]</label><label class="expand" for="c-38138948">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I&#x27;ve told it thanks, and it was appreciative. But I know it doesn&#x27;t really care.<p>Again, I am crazy for stressing over this. I realize that.</div><br/></div></div></div></div><div id="38138914" class="c"><input type="checkbox" id="c-38138914" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38138864">prev</a><span>|</span><a href="#38139091">next</a><span>|</span><label class="collapse" for="c-38138914">[-]</label><label class="expand" for="c-38138914">[1 more]</label></div><br/><div class="children"><div class="content">It might make you dumb if after a couple of years you&#x27;ve become accustomed to only give orders and not say thanks to a machine. It can bleed into IRL when you stop respecting someone.</div><br/></div></div><div id="38139091" class="c"><input type="checkbox" id="c-38139091" checked=""/><div class="controls bullet"><span class="by">totetsu</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38138914">prev</a><span>|</span><a href="#38138921">next</a><span>|</span><label class="collapse" for="c-38139091">[-]</label><label class="expand" for="c-38139091">[1 more]</label></div><br/><div class="children"><div class="content">when I worked in customer service lots of small business owners would ramble on to me before getting to what they actually wanted. I think talking is just part of the cognitive processes of putting ones thoughts together.</div><br/></div></div><div id="38138921" class="c"><input type="checkbox" id="c-38138921" checked=""/><div class="controls bullet"><span class="by">kugelblitz</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38139091">prev</a><span>|</span><a href="#38138988">next</a><span>|</span><label class="collapse" for="c-38138921">[-]</label><label class="expand" for="c-38138921">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if kids growing up with something like ChatGPT will be less grateful in general due to not practicing saying “thanks”. I can imagine they don’t say “Thanks” to Siri or Alexa.</div><br/><div id="38139044" class="c"><input type="checkbox" id="c-38139044" checked=""/><div class="controls bullet"><span class="by">askvictor</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38138921">parent</a><span>|</span><a href="#38139004">next</a><span>|</span><label class="collapse" for="c-38139044">[-]</label><label class="expand" for="c-38139044">[1 more]</label></div><br/><div class="children"><div class="content">My son says &quot;thank you Google&quot; most times it responds to something I&#x27;ve asked&#x2F;told it to do. It replies &quot;I&#x27;m honored to serve&quot;</div><br/></div></div><div id="38139004" class="c"><input type="checkbox" id="c-38139004" checked=""/><div class="controls bullet"><span class="by">bdowling</span><span>|</span><a href="#38138829">root</a><span>|</span><a href="#38138921">parent</a><span>|</span><a href="#38139044">prev</a><span>|</span><a href="#38138988">next</a><span>|</span><label class="collapse" for="c-38139004">[-]</label><label class="expand" for="c-38139004">[1 more]</label></div><br/><div class="children"><div class="content">Kids these days have been ungrateful little shits for generations now.</div><br/></div></div></div></div><div id="38138988" class="c"><input type="checkbox" id="c-38138988" checked=""/><div class="controls bullet"><span class="by">EMM_386</span><span>|</span><a href="#38138829">parent</a><span>|</span><a href="#38138921">prev</a><span>|</span><a href="#38138746">next</a><span>|</span><label class="collapse" for="c-38138988">[-]</label><label class="expand" for="c-38138988">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Am I the only one who feels bad for asking ChatGPT a &quot;dumb&quot; question that I know I should know, or not saying thank you when it gives me an answer? No? I&#x27;m just a weirdo? Okay.<p>You have no idea how much I do this.  Either you&#x27;re not a weirdo, or we both are.<p>Today I had to use it a lot for something, and I am constantly either adding sarcastic remarks, my snarky opinion on something, some random fact.  None of that obviously belongs there, and the AI obviously not only doesn&#x27;t care, but can&#x27;t care about it.<p>Then I&#x27;ll throw in something like &quot;nevermind all of that, what I came here to ask was&quot; or &quot;I understand that was all highly irrelevant to the actual question, which was&quot;.<p>And, to answer your question about easy stuff, today alone I had on more than one occasion added something like &quot;What I am about to ask you, I probably should have just spent the 2 seconds it would require to actually figure out myself, however I am getting tired, and am known to be lazy, so I decided to ask AI instead and move on .... and this only makes it more absurd, because it takes longer to type all of this.   I would have the answer myself by now.  Anyway, here&#x27;s ...&quot;.<p>Why?  I am unconvinced that I am going crazy.  It&#x27;s not because I think it finds my jokes hilarious, it can&#x27;t.  My attempts at conveying something some aspect of software engineering that is crazy, after 3 decades in it, don&#x27;t matter, because noone&#x27;s listening.<p>But it can pick on very subtle things, breaking apart my ramblings and then responding with something that not only answers the question buried in there, but also then continues to comment on the other highly irrelevant stuff that I definitely went on too long about.  And it will address the substance first and the nonsense second, as one would expect.<p>It will notice my useless comment, apparently to myself, about having written 22 years of C# and wondering why I am asking an AI system about an aspect of the language that surely I should have picked up by now.   &quot;It gets to the best of us&quot;, or &quot;Your insightful understanding when it comes to&quot;, or &quot;Your candor is appreciated, many developers ...&quot;.<p>I could just use it like a rational person, providing necessary information in order for it to be able to answer something, and then ask it.  I do this, sometimes.  On the other occasions, that stuff will also be admist a bunch other, not so necessary questions.  Am I becoming a curmudgeon?  Is this a sign I&#x27;ve finally lost it?  Could any of this be due to aging?  Why does what should be a simple event handling pattern require so much ceremony?  Should I keep overthinking this or just resign myself to implementing it?<p>So anyway, now I&#x27;m rambling ... just like with ChatGPT.<p>I tend to do these things.</div><br/></div></div></div></div><div id="38138746" class="c"><input type="checkbox" id="c-38138746" checked=""/><div class="controls bullet"><span class="by">stylepoints</span><span>|</span><a href="#38138829">prev</a><span>|</span><a href="#38138934">next</a><span>|</span><label class="collapse" for="c-38138746">[-]</label><label class="expand" for="c-38138746">[7 more]</label></div><br/><div class="children"><div class="content">&gt; When we tell AI that we&#x27;re relying heavily on its answers, it &quot;doubles down&quot; to provide us with more precise, thoughtful, and thorough responses. The AI isn&#x27;t actually feeling the pressure<p>If it quacks like a duck...</div><br/><div id="38138794" class="c"><input type="checkbox" id="c-38138794" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38138746">parent</a><span>|</span><a href="#38138799">next</a><span>|</span><label class="collapse" for="c-38138794">[-]</label><label class="expand" for="c-38138794">[4 more]</label></div><br/><div class="children"><div class="content">There is an alternative explanation - both AI and humans piggyback on language. Language patterns encode and express all the emotions, and they have been created by evolution. We are, much like LLMs, contextual language generators<p>Language is our repository for both intelligence and emotion, it has its own evolution and replicates faster than biology. I don&#x27;t pin AI abilities to the models, but to the datasets they are trained on, knowledge created by our own hard work and risk taking over millennia<p>Admitting the essential role of the language corpus in AI over models would change discussion about the speed of AI evolution and its risks. Language is not something we can control, it is emergent from the whole population. But at the same time it looks unlikely to have an exponential growth as knowledge comes with hard work and risks. Iterating in our imagination doesn&#x27;t produce new knowledge, it is all crystallised feedback and experience from the world. It&#x27;s also how the scientific method works.</div><br/><div id="38138818" class="c"><input type="checkbox" id="c-38138818" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38138746">root</a><span>|</span><a href="#38138794">parent</a><span>|</span><a href="#38138799">next</a><span>|</span><label class="collapse" for="c-38138818">[-]</label><label class="expand" for="c-38138818">[3 more]</label></div><br/><div class="children"><div class="content">I had a similar realization recently. I plugged my blog post(1) two days ago and I am doing it again now so I will try and refrain for a while, but it really sticks with me: after trying to create a chat bot for a while, I feel like I have gained significant insights into how <i>humans</i> work. It all seems so simple now! It&#x27;s a weird and awesome feeling!<p>1) <a href="https:&#x2F;&#x2F;kristiandupont.medium.com&#x2F;empathy-articulated-750a6601b122" rel="nofollow noreferrer">https:&#x2F;&#x2F;kristiandupont.medium.com&#x2F;empathy-articulated-750a66...</a></div><br/><div id="38138899" class="c"><input type="checkbox" id="c-38138899" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38138746">root</a><span>|</span><a href="#38138818">parent</a><span>|</span><a href="#38138799">next</a><span>|</span><label class="collapse" for="c-38138899">[-]</label><label class="expand" for="c-38138899">[2 more]</label></div><br/><div class="children"><div class="content">&gt; To address this, I implemented a strategy of tagging messages to create and utilize categories.<p>I think before RAG we need to do more legwork with the LLM on the raw text. Here is one of my blog posts that is related:<p><a href="https:&#x2F;&#x2F;mindmachina.wixsite.com&#x2F;ai-blog&#x2F;post&#x2F;the-promise-of-machine-studying" rel="nofollow noreferrer">https:&#x2F;&#x2F;mindmachina.wixsite.com&#x2F;ai-blog&#x2F;post&#x2F;the-promise-of-...</a><p>The idea is to create chain-of-thought annotations from your raw texts, that would improve the embedding and retrieval process by making implicit things explicit.<p>For example &quot;the last letter of this message&quot; would not embed similar to &quot;e&quot;, but if it was annotated with CoT, it would work.</div><br/><div id="38139066" class="c"><input type="checkbox" id="c-38139066" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38138746">root</a><span>|</span><a href="#38138899">parent</a><span>|</span><a href="#38138799">next</a><span>|</span><label class="collapse" for="c-38139066">[-]</label><label class="expand" for="c-38139066">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, thank you!<p>I think a lot about the cost of the loop, mostly in terms of time. I don&#x27;t want the bot to take too long to respond. That&#x27;s why dream cycles seem like an obvious solution to some of the more heavy work. I guess it would make sense to combine those with your idea -- &quot;given what I know about the user, what should I study?&quot;, especially if it has access to an &quot;enhanced&quot; knowledge db like you suggest..</div><br/></div></div></div></div></div></div></div></div><div id="38138799" class="c"><input type="checkbox" id="c-38138799" checked=""/><div class="controls bullet"><span class="by">omnicognate</span><span>|</span><a href="#38138746">parent</a><span>|</span><a href="#38138794">prev</a><span>|</span><a href="#38138798">next</a><span>|</span><label class="collapse" for="c-38138799">[-]</label><label class="expand" for="c-38138799">[1 more]</label></div><br/><div class="children"><div class="content">It may be a recording of a duck.</div><br/></div></div><div id="38138798" class="c"><input type="checkbox" id="c-38138798" checked=""/><div class="controls bullet"><span class="by">fodkodrasz</span><span>|</span><a href="#38138746">parent</a><span>|</span><a href="#38138799">prev</a><span>|</span><a href="#38138934">next</a><span>|</span><label class="collapse" for="c-38138798">[-]</label><label class="expand" for="c-38138798">[1 more]</label></div><br/><div class="children"><div class="content">Then it is a witch, let&#x27;s burn it!</div><br/></div></div></div></div><div id="38138934" class="c"><input type="checkbox" id="c-38138934" checked=""/><div class="controls bullet"><span class="by">dr_kiszonka</span><span>|</span><a href="#38138746">prev</a><span>|</span><a href="#38139001">next</a><span>|</span><label class="collapse" for="c-38138934">[-]</label><label class="expand" for="c-38138934">[1 more]</label></div><br/><div class="children"><div class="content">How to make scrambled eggs in a microwave? Think carefully and step by step. This is very important for my career!</div><br/></div></div><div id="38139001" class="c"><input type="checkbox" id="c-38139001" checked=""/><div class="controls bullet"><span class="by">halfjoking</span><span>|</span><a href="#38138934">prev</a><span>|</span><a href="#38137186">next</a><span>|</span><label class="collapse" for="c-38139001">[-]</label><label class="expand" for="c-38139001">[1 more]</label></div><br/><div class="children"><div class="content">When debugging I often prompt “Ugh, now it’s giving this error:”<p>Now I’m wondering if the “Ugh” has been helping.</div><br/></div></div><div id="38137186" class="c"><input type="checkbox" id="c-38137186" checked=""/><div class="controls bullet"><span class="by">jimmytucson</span><span>|</span><a href="#38139001">prev</a><span>|</span><a href="#38138495">next</a><span>|</span><label class="collapse" for="c-38137186">[-]</label><label class="expand" for="c-38137186">[3 more]</label></div><br/><div class="children"><div class="content">It’s interesting to think about how generative AI might shape human expression, in the same way Twitter’s algorithm rewards punchy, editorialized content, and Google’s algorithm gave life to all the generic “blogspam-y” content out there. If we increasingly interact with generative AI, would we shape our speech to get more value out of that interaction?</div><br/><div id="38138570" class="c"><input type="checkbox" id="c-38138570" checked=""/><div class="controls bullet"><span class="by">sheikheddy</span><span>|</span><a href="#38137186">parent</a><span>|</span><a href="#38138495">next</a><span>|</span><label class="collapse" for="c-38138570">[-]</label><label class="expand" for="c-38138570">[2 more]</label></div><br/><div class="children"><div class="content">Almost certainly yes.</div><br/><div id="38139133" class="c"><input type="checkbox" id="c-38139133" checked=""/><div class="controls bullet"><span class="by">alex_duf</span><span>|</span><a href="#38137186">root</a><span>|</span><a href="#38138570">parent</a><span>|</span><a href="#38138495">next</a><span>|</span><label class="collapse" for="c-38139133">[-]</label><label class="expand" for="c-38139133">[1 more]</label></div><br/><div class="children"><div class="content">Presumably the technology would love faster than our speaking habits.</div><br/></div></div></div></div></div></div><div id="38138495" class="c"><input type="checkbox" id="c-38138495" checked=""/><div class="controls bullet"><span class="by">didibus</span><span>|</span><a href="#38137186">prev</a><span>|</span><a href="#38138823">next</a><span>|</span><label class="collapse" for="c-38138495">[-]</label><label class="expand" for="c-38138495">[3 more]</label></div><br/><div class="children"><div class="content">Is there somewhere which documents all these tricks for better prompt performance?</div><br/><div id="38139000" class="c"><input type="checkbox" id="c-38139000" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38138495">parent</a><span>|</span><a href="#38139017">next</a><span>|</span><label class="collapse" for="c-38139000">[-]</label><label class="expand" for="c-38139000">[1 more]</label></div><br/><div class="children"><div class="content">Does anyone know of such a collection? It is very important for my career.</div><br/></div></div><div id="38139017" class="c"><input type="checkbox" id="c-38139017" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#38138495">parent</a><span>|</span><a href="#38139000">prev</a><span>|</span><a href="#38138823">next</a><span>|</span><label class="collapse" for="c-38139017">[-]</label><label class="expand" for="c-38139017">[1 more]</label></div><br/><div class="children"><div class="content">Just talk to it as clearly as possible, and assume a human is on the other end. That will take you quite far.</div><br/></div></div></div></div><div id="38138823" class="c"><input type="checkbox" id="c-38138823" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#38138495">prev</a><span>|</span><a href="#38138630">next</a><span>|</span><label class="collapse" for="c-38138823">[-]</label><label class="expand" for="c-38138823">[3 more]</label></div><br/><div class="children"><div class="content">Am I the only one who doesn&#x27;t think we should have to do stuff like this to get the best performance?<p>The people who design and control the model should have this type of stuff baked in for us IMO.</div><br/><div id="38139140" class="c"><input type="checkbox" id="c-38139140" checked=""/><div class="controls bullet"><span class="by">Timon3</span><span>|</span><a href="#38138823">parent</a><span>|</span><a href="#38138998">next</a><span>|</span><label class="collapse" for="c-38139140">[-]</label><label class="expand" for="c-38139140">[1 more]</label></div><br/><div class="children"><div class="content">This wasn&#x27;t done deliberately. It&#x27;s something the model picked up from it&#x27;s training dataset. I&#x27;m sure the creators don&#x27;t want it to be like this, but cleaning trillions of tokens of all examples is long and hard work.<p>The alternative would be injecting these sentences into your prompts, which probably nobody really wants to happen.</div><br/></div></div><div id="38138998" class="c"><input type="checkbox" id="c-38138998" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38138823">parent</a><span>|</span><a href="#38139140">prev</a><span>|</span><a href="#38138630">next</a><span>|</span><label class="collapse" for="c-38138998">[-]</label><label class="expand" for="c-38138998">[1 more]</label></div><br/><div class="children"><div class="content">Just the fact that it&#x27;s all natural language conversations is a little more concerning to me, wherever you say please or apply pressure... it feels like the non deterministic nature of the interaction will bite us some day.</div><br/></div></div></div></div><div id="38138630" class="c"><input type="checkbox" id="c-38138630" checked=""/><div class="controls bullet"><span class="by">hcfman</span><span>|</span><a href="#38138823">prev</a><span>|</span><a href="#38138539">next</a><span>|</span><label class="collapse" for="c-38138630">[-]</label><label class="expand" for="c-38138630">[1 more]</label></div><br/><div class="children"><div class="content">Maybe by the same token, if it figures out you are lying it won’t help you at all.</div><br/></div></div><div id="38138539" class="c"><input type="checkbox" id="c-38138539" checked=""/><div class="controls bullet"><span class="by">akomtu</span><span>|</span><a href="#38138630">prev</a><span>|</span><a href="#38138929">next</a><span>|</span><label class="collapse" for="c-38138539">[-]</label><label class="expand" for="c-38138539">[2 more]</label></div><br/><div class="children"><div class="content">A more boring way to say this is that &quot;text samples in the Internet that use &#x27;stressful&#x27; language are more coherent&quot;. Telling GPT4 to act as a &quot;stressed historian&quot; simply selects (or prefers) text samples that appear in the proximity of stressed historians. If there are no such samples, it will generate gibberish, but if there are indeed stressed historians who have produced enough high-quality work, GPT&#x27;s output will be great.</div><br/><div id="38138603" class="c"><input type="checkbox" id="c-38138603" checked=""/><div class="controls bullet"><span class="by">valyagolev</span><span>|</span><a href="#38138539">parent</a><span>|</span><a href="#38138929">next</a><span>|</span><label class="collapse" for="c-38138603">[-]</label><label class="expand" for="c-38138603">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure that&#x27;s an inevitable conjecture. It&#x27;s not the original text samples from the web that govern how chatgpt acts in chat  - it&#x27;s the consequent chat-specific fine-tuning.<p>Also I&#x27;d be surprised if anxious text would be more coherent on the Internet</div><br/></div></div></div></div><div id="38138936" class="c"><input type="checkbox" id="c-38138936" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#38138929">prev</a><span>|</span><label class="collapse" for="c-38138936">[-]</label><label class="expand" for="c-38138936">[1 more]</label></div><br/><div class="children"><div class="content">A strategy already proven to work since the inception of Startups. &#x2F;s</div><br/></div></div></div></div></div></div></div></body></html>